<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2026-02-03</h1>
<h3>Title: PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering</h3>
<ul>
<li><strong>Authors: </strong>MinGyu Jeon, SuWan Cho, JaeYoung Shu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00007">https://arxiv.org/abs/2602.00007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00007">https://arxiv.org/pdf/2602.00007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00007]] PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering(https://arxiv.org/abs/2602.00007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.</li>
</ul>

<h3>Title: Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA</h3>
<ul>
<li><strong>Authors: </strong>Samuel Thio, Matthew Lewis, Spiros Denaxas, Richard JB Dobson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00009">https://arxiv.org/abs/2602.00009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00009">https://arxiv.org/pdf/2602.00009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00009]] Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA(https://arxiv.org/abs/2602.00009)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.</li>
</ul>

<h3>Title: OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Siebenmann (1), Javier Argota Sánchez-Vaquerizo (1), Stefan Arisona (2), Krystian Samp (2), Luis Gisler (2), Dirk Helbing (1 and 3) ((1) Professorship of Computational Social Science, ETH Zurich, (2) Esri R&amp;D Center Zurich, (3) Complexity Science Hub, Vienna)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00012">https://arxiv.org/abs/2602.00012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00012">https://arxiv.org/pdf/2602.00012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00012]] OGD4All: A Framework for Accessible Interaction with Geospatial Open Government Data Based on Large Language Models(https://arxiv.org/abs/2602.00012)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust, large language model</a></li>
<li><strong>Abstract: </strong>We present OGD4All, a transparent, auditable, and reproducible framework based on Large Language Models (LLMs) to enhance citizens' interaction with geospatial Open Government Data (OGD). The system combines semantic data retrieval, agentic reasoning for iterative code generation, and secure sandboxed execution that produces verifiable multimodal outputs. Evaluated on a 199-question benchmark covering both factual and unanswerable questions, across 430 City-of-Zurich datasets and 11 LLMs, OGD4All reaches 98% analytical correctness and 94% recall while reliably rejecting questions unsupported by available data, which minimizes hallucination risks. Statistical robustness tests, as well as expert feedback, show reliability and social relevance. The proposed approach shows how LLMs can provide explainable, multimodal access to public data, advancing trustworthy AI for open governance.</li>
</ul>

<h3>Title: G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xun Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00015">https://arxiv.org/abs/2602.00015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00015">https://arxiv.org/pdf/2602.00015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00015]] G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models(https://arxiv.org/abs/2602.00015)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.</li>
</ul>

<h3>Title: PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems</h3>
<ul>
<li><strong>Authors: </strong>Jiongchi Yu, Yuhan Ma, Xiaoyu Zhang, Junjie Wang, Qiang Hu, Chao Shen, Xiaofei Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00016">https://arxiv.org/abs/2602.00016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00016">https://arxiv.org/pdf/2602.00016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00016]] PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems(https://arxiv.org/abs/2602.00016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., "Unemployment") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.</li>
</ul>

<h3>Title: ELLMPEG: An Edge-based Agentic LLM Video Processing Tool</h3>
<ul>
<li><strong>Authors: </strong>Zoha Azimi, Reza Farahani, Radu Prodan, Christian Timmerer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00028">https://arxiv.org/abs/2602.00028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00028">https://arxiv.org/pdf/2602.00028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00028]] ELLMPEG: An Edge-based Agentic LLM Video Processing Tool(https://arxiv.org/abs/2602.00028)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), the foundation of generative AI systems like ChatGPT, are transforming many fields and applications, including multimedia, enabling more advanced content generation, analysis, and interaction. However, cloud-based LLM deployments face three key limitations: high computational and energy demands, privacy and reliability risks from remote processing, and recurring API costs. Recent advances in agentic AI, especially in structured reasoning and tool use, offer a better way to exploit open and locally deployed tools and LLMs. This paper presents ELLMPEG, an edge-enabled agentic LLM framework for the automated generation of video-processing commands. ELLMPEG integrates tool-aware Retrieval-Augmented Generation (RAG) with iterative self-reflection to produce and locally verify executable FFmpeg and VVenC commands directly at the edge, eliminating reliance on external cloud APIs. To evaluate ELLMPEG, we collect a dedicated prompt dataset comprising 480 diverse queries covering different categories of FFmpeg and the Versatile Video Codec (VVC) encoder (VVenC) commands. We validate command generation accuracy and evaluate four open-source LLMs based on command validity, tokens generated per second, inference time, and energy efficiency. We also execute the generated commands to assess their runtime correctness and practical applicability. Experimental results show that Qwen2.5, when augmented with the ELLMPEG framework, achieves an average command-generation accuracy of 78 % with zero recurring API cost, outperforming all other open-source models across both the FFmpeg and VVenC datasets.</li>
</ul>

<h3>Title: RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Takato Yasuno</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00030">https://arxiv.org/abs/2602.00030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00030">https://arxiv.org/pdf/2602.00030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00030]] RAPTOR-AI for Disaster OODA Loop: Hierarchical Multimodal RAG with Experience-Driven Agentic Decision-Making(https://arxiv.org/abs/2602.00030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective humanitarian assistance and disaster relief (HADR) requires rapid situational understanding, reliable decision support, and the ability to generalize across diverse and previously unseen disaster contexts. This work introduces an agentic Retrieval-Augmented Generation (RAG) framework designed to support the three canonical phases of disaster response: initial rescue, mid-term recovery, and long-term reconstruction. To achieve robust multimodal grounding, we construct a hierarchical knowledge base that integrates textual disaster manuals, historical lessons (e.g., the 2011 Tohoku earthquake), and both aerial and ground-level imagery. Our system builds on the open-source multimodal implementation, which processes 46 tsunami-related PDFs (2,378 pages) using BLIP-based image captioning, ColVBERT embeddings, and long-context summarization to generate an efficient, structured multimodal retrieval tree optimized for disaster knowledge preservation. An agentic controller dynamically selects retrieval strategies (e.g., RAPTOR, ColBERT) through entropy-aware scene abstraction, enabling adaptive reasoning across heterogeneous inputs. Additionally, a lightweight LoRA-based post-training method injects experiential knowledge from past disasters, enhancing the models' capacity to support both expert and non-expert responders. Experiments on real disaster datasets demonstrate improved situational grounding, enhanced task decomposition accuracy, and superior usability for emergency operations. Incorporating recent advances in long-context RAG systems, agentic information retrieval, and contemporary emergency response AI, our system achieves substantial gains through adaptive retrieval-augmented generation with self-reasoning and multimodal chain-of-thought capabilities.</li>
</ul>

<h3>Title: Enhancing few-shot time series forecasting with LLM-guided diffusion</h3>
<ul>
<li><strong>Authors: </strong>Haonan Shi, Dehua Shuai, Liming Wang, Xiyang Liu, Long Tian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00040">https://arxiv.org/abs/2602.00040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00040">https://arxiv.org/pdf/2602.00040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00040]] Enhancing few-shot time series forecasting with LLM-guided diffusion(https://arxiv.org/abs/2602.00040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Time series forecasting in specialized domains is often constrained by limited data availability, where conventional models typically require large-scale datasets to effectively capture underlying temporal dynamics. To tackle this few-shot challenge, we propose LTSM-DIFF (Large-scale Temporal Sequential Memory with Diffusion), a novel learning framework that integrates the expressive power of large language models with the generative capability of diffusion models. Specifically, the LTSM module is fine-tuned and employed as a temporal memory mechanism, extracting rich sequential representations even under data-scarce conditions. These representations are then utilized as conditional guidance for a joint probability diffusion process, enabling refined modeling of complex temporal patterns. This design allows knowledge transfer from the language domain to time series tasks, substantially enhancing both generalization and robustness. Extensive experiments across diverse benchmarks demonstrate that LTSM-DIFF consistently achieves state-of-the-art performance in data-rich scenarios, while also delivering significant improvements in few-shot forecasting. Our work establishes a new paradigm for time series analysis under data scarcity.</li>
</ul>

<h3>Title: Lightweight Edge Learning via Dataset Pruning</h3>
<ul>
<li><strong>Authors: </strong>Laha Ale, Hu Luo, Mingsheng Cao, Shichao Li, Huanlai Xing, Haifeng Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00047">https://arxiv.org/abs/2602.00047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00047">https://arxiv.org/pdf/2602.00047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00047]] Lightweight Edge Learning via Dataset Pruning(https://arxiv.org/abs/2602.00047)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Edge learning facilitates ubiquitous intelligence by enabling model training and adaptation directly on data-generating devices, thereby mitigating privacy risks and communication latency. However, the high computational and energy overhead of on-device training hinders its deployment on battery-powered mobile systems with strict thermal and memory budgets. While prior research has extensively optimized model architectures for efficient inference, the training phase remains bottlenecked by the processing of massive, often redundant, local datasets. In this work, we propose a data-centric optimization framework that leverages dataset pruning to achieve resource-efficient edge learning. Unlike standard methods that process all available data, our approach constructs compact, highly informative training subsets via a lightweight, on-device importance evaluation. Specifically, we utilize average loss statistics derived from a truncated warm-up phase to rank sample importance, deterministically retaining only the most critical data points under a dynamic pruning ratio. This mechanism is model-agnostic and operates locally without inter-device communication. Extensive experiments on standard image classification benchmarks demonstrate that our framework achieves a near-linear reduction in training latency and energy consumption proportional to the pruning ratio, with negligible degradation in model accuracy. These results validate dataset pruning as a vital, complementary paradigm for enhancing the sustainability and scalability of learning on resource-constrained mobile edge devices.</li>
</ul>

<h3>Title: Comparison of Multiple Classifiers for Android Malware Detection with Emphasis on Feature Insights Using CICMalDroid 2020 Dataset</h3>
<ul>
<li><strong>Authors: </strong>Md Min-Ha-Zul Abedin, Tazqia Mehrub</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00058">https://arxiv.org/abs/2602.00058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00058">https://arxiv.org/pdf/2602.00058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00058]] Comparison of Multiple Classifiers for Android Malware Detection with Emphasis on Feature Insights Using CICMalDroid 2020 Dataset(https://arxiv.org/abs/2602.00058)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Accurate Android malware detection was critical for protecting users at scale. Signature scanners lagged behind fast release cycles on public app stores. We aimed to build a trustworthy detector by pairing a comprehensive dataset with a rigorous, transparent evaluation, and to identify interpretable drivers of decisions. We used CICMalDroid2020, which contained 17,341 apps across Benign, Adware, Banking, SMS malware, and Riskware. We extracted 301 static and 263 dynamic features into a 564 dimensional hybrid vector, then evaluated seven classifiers under three schemes, original features, principal component analysis, PCA, and linear discriminant analysis, LDA, with a 70 percent training and 30 percent test split. Results showed that gradient boosting on the original features performed best. XGBoost achieved 0.9747 accuracy, 0.9703 precision, 0.9731 recall, and 0.9716 F1, and the confusion matrix indicated rare benign labels for malicious apps. HistGradientBoosting reached 0.9741 accuracy and 0.9708 F1, while CatBoost and Random Forest were slightly lower at 0.9678 and 0.9687 accuracy with 0.9636 and 0.9637 F1. KNN and SVM lagged. PCA reduced performance for all models, with XGBoost dropping to 0.9164 accuracy and 0.8988 F1. LDA maintained mid 90s accuracy and clarified separable clusters in projections. A depth two surrogate tree highlighted package name, main activity, and target SDK as key drivers. These findings established high fidelity supervised baselines for Android malware detection and indicated that rich hybrid features with gradient boosting offered a practical and interpretable foundation for deployment.</li>
</ul>

<h3>Title: The Impact of Machine Learning Uncertainty on the Robustness of Counterfactual Explanations</h3>
<ul>
<li><strong>Authors: </strong>Leonidas Christodoulou, Chang Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00063">https://arxiv.org/abs/2602.00063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00063">https://arxiv.org/pdf/2602.00063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00063]] The Impact of Machine Learning Uncertainty on the Robustness of Counterfactual Explanations(https://arxiv.org/abs/2602.00063)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations are widely used to interpret machine learning predictions by identifying minimal changes to input features that would alter a model's decision. However, most existing counterfactual methods have not been tested when model and data uncertainty change, resulting in explanations that may be unstable or invalid under real-world variability. In this work, we investigate the robustness of common combinations of machine learning models and counterfactual generation algorithms in the presence of both aleatoric and epistemic uncertainty. Through experiments on synthetic and real-world tabular datasets, we show that counterfactual explanations are highly sensitive to model uncertainty. In particular, we find that even small reductions in model accuracy - caused by increased noise or limited data - can lead to large variations in the generated counterfactuals on average and on individual instances. These findings underscore the need for uncertainty-aware explanation methods in domains such as finance and the social sciences.</li>
</ul>

<h3>Title: SPGCL: Effective Graph Contrastive Learning via SVD-Guided Structural Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Hao Deng, Yingping Li, Shuiping Gou, Bo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00064">https://arxiv.org/abs/2602.00064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00064">https://arxiv.org/pdf/2602.00064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00064]] SPGCL: Effective Graph Contrastive Learning via SVD-Guided Structural Perturbation(https://arxiv.org/abs/2602.00064)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) can be highly sensitive to structural noise, including spurious or missing edges caused by adversarial attacks or non-adversarial imperfections. Existing graph contrastive learning methods typically rely on either random perturbations (e.g., edge dropping) to generate diverse views or purely spectral augmentations (e.g., SVD) to preserve global structural priors. However, random perturbations are structure-agnostic and may remove critical edges, while SVD-based views often become dense and lack sufficient diversity. To bridge this gap, we propose SPGCL, a robust graph contrastive learning framework via SVD-guided structural perturbation. SPGCL couples lightweight stochastic edge removal with an SVD-guided refinement step that can recover mistakenly removed informative edges and introduce semantically meaningful missing links while avoiding graph densification through sparse top-ranked edge selection and merging. By balancing edge removal and recovery rates, SPGCL explicitly controls structural discrepancy between views so that contrastive signals reflect semantic structural differences rather than edge-count gaps. We further incorporate a contrastive fusion module regularized by a global similarity constraint to better align the two views. Extensive experiments on ten benchmark datasets demonstrate that SPGCL consistently improves robustness and accuracy of base GNNs, outperforming state-of-the-art graph contrastive learning and structure learning methods.</li>
</ul>

<h3>Title: Generative AI-enhanced Probabilistic Multi-Fidelity Surrogate Modeling Via Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Jice Zeng, David Barajas-Solano, Hui Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00072">https://arxiv.org/abs/2602.00072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00072">https://arxiv.org/pdf/2602.00072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00072]] Generative AI-enhanced Probabilistic Multi-Fidelity Surrogate Modeling Via Transfer Learning(https://arxiv.org/abs/2602.00072)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The performance of machine learning surrogates is critically dependent on data quality and quantity. This presents a major challenge, as high-fidelity (HF) data is often scarce and computationally expensive to acquire, while low-fidelity (LF) data is abundant but less accurate. To address this data scarcity problem, we develop a probabilistic multi-fidelity surrogate framework based on generative transfer learning. We employ a normalizing flow (NF) generative model as the backbone, which is trained in two phases: (i) the NF is first pretrained on a large LF dataset to learn a probabilistic forward model; (ii) the pretrained model is then fine-tuned on a small HF dataset, allowing it to correct for LF-HF discrepancies via knowledge transfer. To relax the dimension-preserving constraint of standard bijective NFs, we integrate surjective (dimension-reducing) layers with standard coupling blocks. This architecture enables learned dimension reduction while preserving the ability to train with exact likelihoods. The resulting surrogate provides fast probabilistic predictions with quantified uncertainty and significantly outperforms LF-only baselines while using fewer HF evaluations. We validate the approach on a reinforced concrete slab benchmark, combining many coarse-mesh (LF) simulations with a limited set of fine-mesh (HF) simulations. The proposed model achieves probabilistic predictions with HF accuracy, demonstrating a practical path toward data-efficient, generative AI-driven surrogates for complex engineering systems.</li>
</ul>

<h3>Title: Why LoRA Resists Label Noise: A Theoretical Framework for Noise-Robust Parameter-Efficient Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Brady Steele</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00084">https://arxiv.org/abs/2602.00084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00084">https://arxiv.org/pdf/2602.00084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00084]] Why LoRA Resists Label Noise: A Theoretical Framework for Noise-Robust Parameter-Efficient Fine-Tuning(https://arxiv.org/abs/2602.00084)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning methods like Low-Rank Adaptation (LoRA) have become the dominant paradigm for adapting large pretrained models. We present a theoretical framework explaining an underexplored property: LoRA's inherent resistance to label noise. Our analysis reveals three key insights. First, we prove that rank-$r$ LoRA cannot memorize all possible label assignments once the sample size exceeds $O(r(d+k-r))$, limiting its capacity to fit arbitrary noise. Second, we derive an optimal rank balancing approximation bias and noise-induced variance, showing it decreases with noise rate. Third, we establish temporal separation: clean patterns are learned early while noise memorization occurs later. We propose RACT (Rank-Aware Curriculum Training), leveraging rank discrepancy for noise detection. Experiments validate our predictions, with RACT achieving 91.1% F1 for noise detection on AG News while maintaining 91.46% accuracy, competitive with baselines that lack noise detection capability.</li>
</ul>

<h3>Title: CARE-RFT: Confidence-Anchored Reinforcement Finetuning for Reliable Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shuozhe Li, Jincheng Cao, Bodun Hu, Aryan Mokhtari, Leqi Liu, Amy Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00085">https://arxiv.org/abs/2602.00085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00085">https://arxiv.org/pdf/2602.00085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00085]] CARE-RFT: Confidence-Anchored Reinforcement Finetuning for Reliable Reasoning in Large Language Models(https://arxiv.org/abs/2602.00085)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement finetuning (RFT) has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, we identify a critical trade-off: while unconstrained RFT achieves strong reasoning performance, it severely compromises model trustworthiness by amplifying hallucination and worsening calibration; conversely, RKL-constrained RFT preserves trustworthiness but limits reasoning gains due to its unbounded penalty on exploratory deviations. To resolve this tension, we introduce CARE-RFT (Confidence-Anchored Regularized Reinforcement Finetuning), a novel method that replaces standard reverse KL regularization with a skew reverse KL divergence. CARE-RFT provides a confidence-sensitive penalty: it is bounded for confident, consistently rewarded explorations to enable reasoning, while unbounded elsewhere to preserve calibration. Extensive experiments across multiple model scales and RFT algorithms show that CARE-RFT achieves a superior balance, matching the reasoning performance of unconstrained RFT while recovering the trustworthiness and calibration of the base model. Our work establishes that careful, confidence-aware regularization is key to building both capable and trustworthy reasoning models.</li>
</ul>

<h3>Title: ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization</h3>
<ul>
<li><strong>Authors: </strong>Haolin Pan, Lianghong Huang, Jinyuan Dong, Mingjie Xing, Yanjun Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PF, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00087">https://arxiv.org/abs/2602.00087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00087">https://arxiv.org/pdf/2602.00087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00087]] ECCO: Evidence-Driven Causal Reasoning for Compiler Optimization(https://arxiv.org/abs/2602.00087)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Compiler auto-tuning faces a dichotomy between traditional black-box search methods, which lack semantic guidance, and recent Large Language Model (LLM) approaches, which often suffer from superficial pattern matching and causal opacity. In this paper, we introduce ECCO, a framework that bridges interpretable reasoning with combinatorial search. We first propose a reverse engineering methodology to construct a Chain-of-Thought dataset, explicitly mapping static code features to verifiable performance evidence. This enables the model to learn the causal logic governing optimization decisions rather than merely imitating sequences. Leveraging this interpretable prior, we design a collaborative inference mechanism where the LLM functions as a strategist, defining optimization intents that dynamically guide the mutation operations of a genetic algorithm. Experimental results on seven datasets demonstrate that ECCO significantly outperforms the LLVM opt -O3 baseline, achieving an average 24.44% reduction in cycles.</li>
</ul>

<h3>Title: From Numbers to Prompts: A Cognitive Symbolic Transition Mechanism for Lightweight Time-Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Namkyung Yoon, Hwangnam Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00088">https://arxiv.org/abs/2602.00088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00088">https://arxiv.org/pdf/2602.00088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00088]] From Numbers to Prompts: A Cognitive Symbolic Transition Mechanism for Lightweight Time-Series Forecasting(https://arxiv.org/abs/2602.00088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have achieved remarkable success in time series prediction tasks, but their substantial computational and memory requirements limit deployment on lightweight platforms. In this paper, we propose the Symbolic Transition Mechanism (STM) a novel framework that bridges numeric time series data and language models through symbolic abstraction and prompt engineering. STM transforms continuous time series values into symbol tokens with quantization techniques based on human cognitive structures, and captures temporal dynamics through structured transformations of symbols, enabling fast engineering based predictions in which language models focus on critical parts of time series data. STM is a general purpose mechanisms that ensure the integrity of backbone language models, but they significantly improve their efficiency by inferring the dynamic and structured patterns inherent in time series data. We evaluated STM on various time series datasets, paired with four small language models (SLM) with limited computational environments. For all models, STM achieves error reductions of up to 69% in MAE and 90% in MSE compared to the default backbone SLM without STM. These results demonstrate the potential of STM as an efficient, adaptable layer for symbol-driven time series prediction using foundation models. The accuracy improvements were made at negligible resource costs, with maximum GPU memory of the base model increasing by approximately 0.06% and latency overhead increasing by only 0.64%.</li>
</ul>

<h3>Title: Interpreting and Controlling Model Behavior via Constitutions for Atomic Concept Edits</h3>
<ul>
<li><strong>Authors: </strong>Neha Kalibhat, Zi Wang, Prasoon Bajpai, Drew Proud, Wenjun Zeng, Been Kim, Mani Malek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00092">https://arxiv.org/abs/2602.00092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00092">https://arxiv.org/pdf/2602.00092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00092]] Interpreting and Controlling Model Behavior via Constitutions for Atomic Concept Edits(https://arxiv.org/abs/2602.00092)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce a black-box interpretability framework that learns a verifiable constitution: a natural language summary of how changes to a prompt affect a model's specific behavior, such as its alignment, correctness, or adherence to constraints. Our method leverages atomic concept edits (ACEs), which are targeted operations that add, remove, or replace an interpretable concept in the input prompt. By systematically applying ACEs and observing the resulting effects on model behavior across various tasks, our framework learns a causal mapping from edits to predictable outcomes. This learned constitution provides deep, generalizable insights into the model. Empirically, we validate our approach across diverse tasks, including mathematical reasoning and text-to-image alignment, for controlling and understanding model behavior. We found that for text-to-image generation, GPT-Image tends to focus on grammatical adherence, while Imagen 4 prioritizes atmospheric coherence. In mathematical reasoning, distractor variables confuse GPT-5 but leave Gemini 2.5 models and o4-mini largely unaffected. Moreover, our results show that the learned constitutions are highly effective for controlling model behavior, achieving an average of 1.86 times boost in success rate over methods that do not use constitutions.</li>
</ul>

<h3>Title: Trade-offs Between Individual and Group Fairness in Machine Learning: A Comprehensive Review</h3>
<ul>
<li><strong>Authors: </strong>Sandra Benítez-Peña, Blas Kolic, Victoria Menendez, Belén Pulido</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00094">https://arxiv.org/abs/2602.00094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00094">https://arxiv.org/pdf/2602.00094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00094]] Trade-offs Between Individual and Group Fairness in Machine Learning: A Comprehensive Review(https://arxiv.org/abs/2602.00094)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Algorithmic fairness has become a central concern in computational decision-making systems, where ensuring equitable outcomes is essential for both ethical and legal reasons. Two dominant notions of fairness have emerged in the literature: Group Fairness (GF), which focuses on mitigating disparities across demographic subpopulations, and Individual Fairness (IF), which emphasizes consistent treatment of similar individuals. These notions have traditionally been studied in isolation. In contrast, this survey examines methods that jointly address GF and IF, integrating both perspectives within unified frameworks and explicitly characterizing the trade-offs between them. We provide a systematic and critical review of hybrid fairness approaches, organizing existing methods according to the fairness mechanisms they employ and the algorithmic and mathematical strategies used to reconcile multiple fairness criteria. For each class of methods, we examine their theoretical foundations, optimization mechanisms, and empirical evaluation practices, and discuss their limitations. Additionally, we discuss the challenges and identify open research directions for developing principled, context-aware hybrid fairness methods. By synthesizing insights across the literature, this survey aims to serve as a comprehensive resource for researchers and practitioners seeking to design hybrid algorithms that provide reliable fairness guarantees at both the individual and group levels.</li>
</ul>

<h3>Title: EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions</h3>
<ul>
<li><strong>Authors: </strong>Weiyu Sun, Liangliang Chen, Yongnuo Cai, Huiru Xie, Yi Zeng, Ying Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00095">https://arxiv.org/abs/2602.00095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00095">https://arxiv.org/pdf/2602.00095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00095]] EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions(https://arxiv.org/abs/2602.00095)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) hold significant promise for revolutionizing traditional education and reducing teachers' workload. However, accurately interpreting unconstrained STEM student handwritten solutions with intertwined mathematical formulas, diagrams, and textual reasoning poses a significant challenge due to the lack of authentic and domain-specific benchmarks. Additionally, current evaluation paradigms predominantly rely on the outcomes of downstream tasks (e.g., auto-grading), which often probe only a subset of the recognized content, thereby failing to capture the MLLMs' understanding of complex handwritten logic as a whole. To bridge this gap, we release EDU-CIRCUIT-HW, a dataset consisting of 1,300+ authentic student handwritten solutions from a university-level STEM course. Utilizing the expert-verified verbatim transcriptions and grading reports of student solutions, we simultaneously evaluate various MLLMs' upstream recognition fidelity and downstream auto-grading performance. Our evaluation uncovers an astonishing scale of latent failures within MLLM-recognized student handwritten content, highlighting the models' insufficient reliability for auto-grading and other understanding-oriented applications in high-stakes educational settings. In solution, we present a case study demonstrating that leveraging identified error patterns to preemptively detect and rectify recognition errors, with only minimal human intervention (approximately 4% of the total solutions), can significantly enhance the robustness of the deployed AI-enabled grading system on unseen student solutions.</li>
</ul>

<h3>Title: Mirage2Matter: A Physically Grounded Gaussian World Model from Video</h3>
<ul>
<li><strong>Authors: </strong>Zhengqing Gao, Ziwen Li, Xin Wang, Jiaxin Huang, Zhenyang Ren, Mingkai Shao, Hanlue Zhang, Tianyu Huang, Yongkang Cheng, Yandong Guo, Runqi Lin, Yuanyuan Wang, Tongliang Liu, Kun Zhang, Mingming Gong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00096">https://arxiv.org/abs/2602.00096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00096">https://arxiv.org/pdf/2602.00096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00096]] Mirage2Matter: A Physically Grounded Gaussian World Model from Video(https://arxiv.org/abs/2602.00096)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The scalability of embodied intelligence is fundamentally constrained by the scarcity of real-world interaction data. While simulation platforms provide a promising alternative, existing approaches often suffer from a substantial visual and physical gap to real environments and rely on expensive sensors, precise robot calibration, or depth measurements, limiting their practicality at scale. We present Simulate Anything, a graphics-driven world modeling and simulation framework that enables efficient generation of high-fidelity embodied training data using only multi-view environment videos and off-the-shelf assets. Our approach reconstructs real-world environments into a photorealistic scene representation using 3D Gaussian Splatting (3DGS), seamlessly capturing fine-grained geometry and appearance from video. We then leverage generative models to recover a physically realistic representation and integrate it into a simulation environment via a precision calibration target, enabling accurate scale alignment between the reconstructed scene and the real world. Together, these components provide a unified, editable, and physically grounded world model. Vision Language Action (VLA) models trained on our simulated data achieve strong zero-shot performance on downstream tasks, matching or even surpassing results obtained with real-world data, highlighting the potential of reconstruction-driven world modeling for scalable and practical embodied intelligence training.</li>
</ul>

<h3>Title: Efficient UAV trajectory prediction: A multi-modal deep diffusion framework</h3>
<ul>
<li><strong>Authors: </strong>Yuan Gao, Xinyu Guo, Wenjing Xie, Zifan Wang, Hongwen Yu, Gongyang Li, Shugong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00107">https://arxiv.org/abs/2602.00107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00107">https://arxiv.org/pdf/2602.00107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00107]] Efficient UAV trajectory prediction: A multi-modal deep diffusion framework(https://arxiv.org/abs/2602.00107)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion</a></li>
<li><strong>Abstract: </strong>To meet the requirements for managing unauthorized UAVs in the low-altitude economy, a multi-modal UAV trajectory prediction method based on the fusion of LiDAR and millimeter-wave radar information is proposed. A deep fusion network for multi-modal UAV trajectory prediction, termed the Multi-Modal Deep Fusion Framework, is designed. The overall architecture consists of two modality-specific feature extraction networks and a bidirectional cross-attention fusion module, aiming to fully exploit the complementary information of LiDAR and radar point clouds in spatial geometric structure and dynamic reflection characteristics. In the feature extraction stage, the model employs independent but structurally identical feature encoders for LiDAR and radar. After feature extraction, the model enters the Bidirectional Cross-Attention Mechanism stage to achieve information complementarity and semantic alignment between the two modalities. To verify the effectiveness of the proposed model, the MMAUD dataset used in the CVPR 2024 UG2+ UAV Tracking and Pose-Estimation Challenge is adopted as the training and testing dataset. Experimental results show that the proposed multi-modal fusion model significantly improves trajectory prediction accuracy, achieving a 40% improvement compared to the baseline model. In addition, ablation experiments are conducted to demonstrate the effectiveness of different loss functions and post-processing strategies in improving model performance. The proposed model can effectively utilize multi-modal data and provides an efficient solution for unauthorized UAV trajectory prediction in the low-altitude economy.</li>
</ul>

<h3>Title: Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios</h3>
<ul>
<li><strong>Authors: </strong>John J. Howard (SAIC Identity and Data Sciences Laboratory), Richard O. Plesh (SAIC Identity and Data Sciences Laboratory), Yevgeniy B. Sirotin (SAIC Identity and Data Sciences Laboratory), Jerry L. Tipton (SAIC Identity and Data Sciences Laboratory), Arun R. Vemury (U.S. Department of Homeland Security, Science and Technology Directorate)</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00109">https://arxiv.org/abs/2602.00109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00109">https://arxiv.org/pdf/2602.00109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00109]] Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios(https://arxiv.org/abs/2602.00109)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Presentation attack detection (PAD) subsystems are an important part of effective and user-friendly remote identity validation (RIV) systems. However, ensuring robust performance across diverse environmental and procedural conditions remains a critical challenge. This paper investigates the impact of low-light conditions and automated image acquisition on the robustness of commercial PAD systems using a scenario test of RIV. Our results show that PAD systems experience a significant decline in performance when utilized in low-light or auto-capture scenarios, with a model-predicted increase in error rates by a factor of about four under low-light conditions and a doubling of those odds under auto-capture workflows. Specifically, only one of the tested systems was robust to these perturbations, maintaining a maximum bona fide presentation classification error rate below 3% across all scenarios. Our findings emphasize the importance of testing across diverse environments to ensure robust and reliable PAD performance in real-world applications.</li>
</ul>

<h3>Title: Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yu Li, Guilherme N. DeSouza, Praveen Rao, Chi-Ren Shyu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00110">https://arxiv.org/abs/2602.00110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00110">https://arxiv.org/pdf/2602.00110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00110]] Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer(https://arxiv.org/abs/2602.00110)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Visual transformers have driven major progress in remote sensing image analysis, particularly in object detection and segmentation. Recent vision-language and multimodal models further extend these capabilities by incorporating auxiliary information, including captions, question and answer pairs, and metadata, which broadens applications beyond conventional computer vision tasks. However, these models are typically optimized for semantic alignment between visual and textual content rather than geospatial understanding, and therefore are not suited for representing or reasoning with structured geospatial layers. In this study, we propose a novel model that enhances remote sensing imagery processing with guidance from auxiliary geospatial information. Our approach introduces a geospatial embedding mechanism that transforms diverse geospatial data into embedding patches that are spatially aligned with image patches. To facilitate cross-modal interaction, we design a guided attention module that dynamically integrates multimodal information by computing attention weights based on correlations with auxiliary data, thereby directing the model toward the most relevant regions. In addition, the module assigns distinct roles to individual attention heads, allowing the model to capture complementary aspects of the guidance information and improving the interpretability of its predictions. Experimental results demonstrate that the proposed framework outperforms existing pretrained geospatial foundation models in predicting disease prevalence, highlighting its effectiveness in multimodal geospatial understanding.</li>
</ul>

<h3>Title: AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment</h3>
<ul>
<li><strong>Authors: </strong>S. Kalaycioglu, C. Hong, K. Zhai, H. Xie, J.N. Wong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00113">https://arxiv.org/abs/2602.00113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00113">https://arxiv.org/pdf/2602.00113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00113]] AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment(https://arxiv.org/abs/2602.00113)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate, reproducible burn assessment is critical for treatment planning, healing monitoring, and medico-legal documentation, yet conventional visual inspection and 2D photography are subjective and limited for longitudinal comparison. This paper presents an AI-enabled burn assessment and management platform that integrates multi-view photogrammetry, 3D surface reconstruction, and deep learning-based segmentation within a structured clinical workflow. Using standard multi-angle images from consumer-grade cameras, the system reconstructs patient-specific 3D burn surfaces and maps burn regions onto anatomy to compute objective metrics in real-world units, including surface area, TBSA, depth-related geometric proxies, and volumetric change. Successive reconstructions are spatially aligned to quantify healing progression over time, enabling objective tracking of wound contraction and depth reduction. The platform also supports structured patient intake, guided image capture, 3D analysis and visualization, treatment recommendations, and automated report generation. Simulation-based evaluation demonstrates stable reconstructions, consistent metric computation, and clinically plausible longitudinal trends, supporting a scalable, non-invasive approach to objective, geometry-aware burn assessment and decision support in acute and outpatient care.</li>
</ul>

<h3>Title: 1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization</h3>
<ul>
<li><strong>Authors: </strong>Yunwei Bai, Ying Kiat Tan, Yao Shu, Tsuhan Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00114">https://arxiv.org/abs/2602.00114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00114">https://arxiv.org/pdf/2602.00114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00114]] 1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization(https://arxiv.org/abs/2602.00114)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Few-shot learning (FSL) challenges model generalization to novel classes based on just a few shots of labeled examples, a testbed where traditional test-time augmentations fail to be effective. We introduce 1S-DAug, a one-shot generative augmentation operator that synthesizes diverse yet faithful variants from just one example image at test time. 1S-DAug couples traditional geometric perturbations with controlled noise injection and a denoising diffusion process conditioned on the original image. The generated images are then encoded and aggregated, alongside the original image, into a combined representation for more robust FSL predictions. Integrated as a training-free model-agnostic plugin, 1S-DAug consistently improves FSL across standard benchmarks of 4 different datasets without any model parameter update, including achieving over 10% proportional accuracy improvement on the miniImagenet 5-way-1-shot benchmark. Codes will be released.</li>
</ul>

<h3>Title: IC-EO: Interpretable Code-based assistant for Earth Observation</h3>
<ul>
<li><strong>Authors: </strong>Lamia Lahouel, Laurynas Lopata, Simon Gruening, Gabriele Meoni, Gaetan Petit, Sylvain Lobry</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00117">https://arxiv.org/abs/2602.00117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00117">https://arxiv.org/pdf/2602.00117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00117]] IC-EO: Interpretable Code-based assistant for Earth Observation(https://arxiv.org/abs/2602.00117)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite recent advances in computer vision, Earth Observation (EO) analysis remains difficult to perform for the laymen, requiring expert knowledge and technical capabilities. Furthermore, many systems return black-box predictions that are difficult to audit or reproduce. Leveraging recent advances in tool LLMs, this study proposes a conversational, code-generating agent that transforms natural-language queries into executable, auditable Python workflows. The agent operates over a unified easily extendable API for classification, segmentation, detection (oriented bounding boxes), spectral indices, and geospatial operators. With our proposed framework, it is possible to control the results at three levels: (i) tool-level performance on public EO benchmarks; (ii) at the agent-level to understand the capacity to generate valid, hallucination-free code; and (iii) at the task-level on specific use cases. In this work, we select two use-cases of interest: land-composition mapping and post-wildfire damage assessment. The proposed agent outperforms general-purpose LLM/VLM baselines (GPT-4o, LLaVA), achieving 64.2% vs. 51.7% accuracy on land-composition and 50% vs. 0% on post-wildfire analysis, while producing results that are transparent and easy to interpret. By outputting verifiable code, the approach turns EO analysis into a transparent, reproducible process.</li>
</ul>

<h3>Title: Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance</h3>
<ul>
<li><strong>Authors: </strong>Divya Acharya, Pierre Bernab'e, Antoine Chevrot, Helge Spieker, Arnaud Gotlieb, Bruno Legeard</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00124">https://arxiv.org/abs/2602.00124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00124">https://arxiv.org/pdf/2602.00124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00124]] Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance(https://arxiv.org/abs/2602.00124)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The detection of anomalies is crucial to ensuring the safety and security of maritime vessel traffic surveillance. Although autoencoders are popular for anomaly detection, their effectiveness in identifying collective and contextual anomalies is limited, especially in the maritime domain, where anomalies depend on vessel-specific contexts derived from self-reported AIS messages. To address these limitations, we propose a novel solution: the context-aware autoencoder. By integrating context-specific thresholds, our method improves detection accuracy and reduces computational cost. We compare four context-aware autoencoder variants and a conventional autoencoder using a case study focused on fishing status anomalies in maritime surveillance. Results demonstrate the significant impact of context on reconstruction loss and anomaly detection. The context-aware autoencoder outperforms others in detecting anomalies in time series data. By incorporating context-specific thresholds and recognizing the importance of context in anomaly detection, our approach offers a promising solution to improve accuracy in maritime vessel traffic surveillance systems.</li>
</ul>

<h3>Title: D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Dmytro Filatov, Valentyn Fedorov, Vira Filatova, Andrii Zelenchuk</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00126">https://arxiv.org/abs/2602.00126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00126">https://arxiv.org/pdf/2602.00126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00126]] D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection(https://arxiv.org/abs/2602.00126)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Unsupervised anomaly detection (UAD) is a key ingredient of automated visual inspection in modern manufacturing. The reconstruction-based methods appeal because they have basic architectural design and they process data quickly but they produce oversmoothed results for high-frequency details. As a result, subtle defects are partially reconstructed rather than highlighted, which limits segmentation accuracy. We build on this line of work and introduce D3R-Net, a Dual-Domain Denoising Reconstruction framework that couples a self-supervised 'healing' task with frequency-aware regularization. During training, the network receives synthetically corrupted normal images and is asked to reconstruct the clean targets, which prevents trivial identity mapping and pushes the model to learn the manifold of defect-free textures. In addition to the spatial mean squared error, we employ a Fast Fourier Transform (FFT) magnitude loss that encourages consistency in the frequency domain. The implementation also allows an optional structural similarity (SSIM) term, which we study in an ablation. On the MVTec AD Hazelnut benchmark, D3R-Net with the FFT loss improves localization consistency over a spatial-only baseline: PRO AUC increases from 0.603 to 0.687, while image-level ROC AUC remains robust. Evaluated across fifteen MVTec categories, the FFT variant raises the average pixel ROC AUC from 0.733 to 0.751 and PRO AUC from 0.417 to 0.468 compared to the MSE-only baseline, at roughly 20 FPS on a single GPU. The network is trained from scratch and uses a lightweight convolutional autoencoder backbone, providing a practical alternative to heavy pre-trained feature embedding methods.</li>
</ul>

<h3>Title: ALIGN: Aligned Delegation with Performance Guarantees for Multi-Agent LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Tong Zhu, Baiting Chen, Jin Zhou, Hua Zhou, Sriram Sankararaman, Xiaowu Dai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00127">https://arxiv.org/abs/2602.00127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00127">https://arxiv.org/pdf/2602.00127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00127]] ALIGN: Aligned Delegation with Performance Guarantees for Multi-Agent LLM Reasoning(https://arxiv.org/abs/2602.00127)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>LLMs often underperform on complex reasoning tasks when relying on a single generation-and-selection pipeline. Inference-time ensemble methods can improve performance by sampling diverse reasoning paths or aggregating multiple candidate answers, but they typically treat candidates independently and provide no formal guarantees that ensembling improves reasoning quality. We propose a novel method, Aligned Delegation for Multi-Agent LLM Reasoning (ALIGN), which formulates LLM reasoning as an aligned delegation game. In ALIGN, a principal delegates a task to multiple agents that generate candidate solutions under designed incentives, and then selects among their outputs to produce a final answer. This formulation induces structured interaction among agents while preserving alignment between agent and principal objectives. We establish theoretical guarantees showing that, under a fair comparison with equal access to candidate solutions, ALIGN provably improves expected performance over single-agent generation. Our analysis accommodates correlated candidate answers and relaxes independence assumptions that are commonly used in prior work. Empirical results across a broad range of LLM reasoning benchmarks consistently demonstrate that ALIGN outperforms strong single-agent and ensemble baselines.</li>
</ul>

<h3>Title: Quantum Model Parallelism for MRI-Based Classification of Alzheimer's Disease Stages</h3>
<ul>
<li><strong>Authors: </strong>Emine Akpinar, Murat Oduncuoglu</a></li>
<li><strong>Subjects: </strong>cs.LG, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00128">https://arxiv.org/abs/2602.00128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00128">https://arxiv.org/pdf/2602.00128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00128]] Quantum Model Parallelism for MRI-Based Classification of Alzheimer's Disease Stages(https://arxiv.org/abs/2602.00128)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With increasing life expectancy, AD has become a major global health concern. While classical AI-based methods have been developed for early diagnosis and stage classification of AD, growing data volumes and limited computational resources necessitate faster, more efficient approaches. Quantum-based AI methods, which leverage superposition and entanglement principles along with high-dimensional Hilbert space, can surpass classical approaches' limitations and offer higher accuracy for high-dimensional, heterogeneous, and noisy data. In this study, a Quantum-Based Parallel Model (QBPM) architecture is proposed for the efficient classification of AD stages using MRI datasets, inspired by the principles of classical model parallelism. The proposed model leverages quantum advantages by employing two distinct quantum circuits, each incorporating rotational and entanglement blocks, running in parallel on the same quantum simulator. The classification performance of the model was evaluated on two different datasets to assess its overall robustness and generalization capability. The proposed model demonstrated high classification accuracy across both datasets, highlighting its overall robustness and generalization capability. Results obtained under high-level Gaussian noise, simulating real-world conditions, further provided experimental evidence for the model's applicability not only in theoretical but also in practical scenarios. Moreover, compared with five different classical transfer learning methods, the proposed model demonstrated its efficiency as an alternative to classical approaches by achieving higher classification accuracy and comparable execution time while utilizing fewer circuit parameters. The results indicate that the proposed QBPM architecture represents an innovative and powerful approach for the classification of stages in complex diseases such as Alzheimer's.</li>
</ul>

<h3>Title: Monte Carlo Tree Search for Execution-Guided Program Repair with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00129">https://arxiv.org/abs/2602.00129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00129">https://arxiv.org/pdf/2602.00129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00129]] Monte Carlo Tree Search for Execution-Guided Program Repair with Large Language Models(https://arxiv.org/abs/2602.00129)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automated program repair with large language models remains challenging at the repository level due to long-horizon reasoning requirements and the limitations of autoregressive decoding. We present CodePilot, a hybrid framework that integrates Monte Carlo Tree Search (MCTS) with large language models to enable execution-guided program repair for real-world GitHub issues. CodePilot performs hierarchical fault localization from repository to file and function level, explores diverse patch trajectories using MCTS, and leverages execution feedback as a reward signal to guide search and refinement. The framework further incorporates confidence-calibrated generation to selectively refine low-confidence outputs. Experiments on SWE-bench Lite demonstrate that CodePilot achieves a 24.67% issue resolution rate using open-weight models, outperforming comparable baselines. These results suggest that combining symbolic search with neural language models is an effective strategy for scalable, execution-aware software engineering automation.</li>
</ul>

<h3>Title: Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Xuan Rao, Mingming Ha, Bo Zhao, Derong Liu, Cesare Alippi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00144">https://arxiv.org/abs/2602.00144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00144">https://arxiv.org/pdf/2602.00144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00144]] Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers(https://arxiv.org/abs/2602.00144)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Class-incremental learning (CIL) with Vision Transformers (ViTs) faces a major computational bottleneck during the classifier reconstruction phase, where most existing methods rely on costly iterative stochastic gradient descent (SGD). We observe that analytic Regularized Gaussian Discriminant Analysis (RGDA) provides a Bayes-optimal alternative with accuracy comparable to SGD-based classifiers; however, its quadratic inference complexity limits its use in large-scale CIL scenarios. To overcome this, we propose Low-Rank Factorized RGDA (LR-RGDA), a scalable classifier that combines RGDA's expressivity with the efficiency of linear classifiers. By exploiting the low-rank structure of the covariance via the Woodbury matrix identity, LR-RGDA decomposes the discriminant function into a global affine term refined by a low-rank quadratic perturbation, reducing the inference complexity from $\mathcal{O}(Cd^2)$ to $\mathcal{O}(d^2 + Crd^2)$, where $C$ is the class number, $d$ the feature dimension, and $r \ll d$ the subspace rank. To mitigate representation drift caused by backbone updates, we further introduce Hopfield-based Distribution Compensator (HopDC), a training-free mechanism that uses modern continuous Hopfield Networks to recalibrate historical class statistics through associative memory dynamics on unlabeled anchors, accompanied by a theoretical bound on the estimation error. Extensive experiments on diverse CIL benchmarks demonstrate that our framework achieves state-of-the-art performance, providing a scalable solution for large-scale class-incremental learning with ViTs. Code: this https URL.</li>
</ul>

<h3>Title: Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields</h3>
<ul>
<li><strong>Authors: </strong>Shiqian Li, Ruihong Shen, Junfeng Ni, Chang Pan, Chi Zhang, Yixin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00148">https://arxiv.org/abs/2602.00148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00148">https://arxiv.org/pdf/2602.00148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00148]] Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields(https://arxiv.org/abs/2602.00148)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in complex real-world scenarios. To address these issues, we introduce Neural Gaussian Force Field (NGFF), an end-to-end neural framework that integrates 3D Gaussian perception with physics-based dynamic modeling to generate interactive, physically realistic 4D videos from multi-view RGB inputs, achieving two orders of magnitude faster than prior Gaussian simulators. To support training, we also present GSCollision, a 4D Gaussian dataset featuring diverse materials, multi-object interactions, and complex scenes, totaling over 640k rendered physical videos (~4 TB). Evaluations on synthetic and real 3D scenarios show NGFF's strong generalization and robustness in physical reasoning, advancing video prediction towards physics-grounded world models.</li>
</ul>

<h3>Title: Reversible Diffusion Decoding for Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xinyun Wang, Min Zhang, Sen Cui, Zhikang Chen, Bo Jiang, Kun Kuang, Mingbao Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00150">https://arxiv.org/abs/2602.00150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00150">https://arxiv.org/pdf/2602.00150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00150]] Reversible Diffusion Decoding for Diffusion Language Models(https://arxiv.org/abs/2602.00150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal this http URL propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable this http URL reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.</li>
</ul>

<h3>Title: Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion</h3>
<ul>
<li><strong>Authors: </strong>Boyu Li, Kuangji Zuo, Lincong Li, Yonghui Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00152">https://arxiv.org/abs/2602.00152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00152">https://arxiv.org/pdf/2602.00152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00152]] Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion(https://arxiv.org/abs/2602.00152)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The demand for accurate on-device pattern recognition in edge applications is intensifying, yet existing approaches struggle to reconcile accuracy with computational constraints. To address this challenge, a resource-aware hierarchical network based on multi-spectral fusion and interpretable modules, namely the Hierarchical Parallel Pseudo-image Enhancement Fusion Network (HPPI-Net), is proposed for real-time, on-device Human Activity Recognition (HAR). Deployed on an ARM Cortex-M4 microcontroller for low-power real-time inference, HPPI-Net achieves 96.70% accuracy while utilizing only 22.3 KiB of RAM and 439.5 KiB of ROM after optimization. HPPI-Net employs a two-layer architecture. The first layer extracts preliminary features using Fast Fourier Transform (FFT) spectrograms, while the second layer selectively activates either a dedicated module for stationary activity recognition or a parallel LSTM-MobileNet network (PLMN) for dynamic states. PLMN fuses FFT, Wavelet, and Gabor spectrograms through three parallel LSTM encoders and refines the concatenated features using Efficient Channel Attention (ECA) and Depthwise Separable Convolution (DSC), thereby offering channel-level interpretability while substantially reducing multiply-accumulate operations. Compared with MobileNetV3, HPPI-Net improves accuracy by 1.22% and reduces RAM usage by 71.2% and ROM usage by 42.1%. These results demonstrate that HPPI-Net achieves a favorable accuracy-efficiency trade-off and provides explainable predictions, establishing a practical solution for wearable, industrial, and smart home HAR on memory-constrained edge platforms.</li>
</ul>

<h3>Title: ReasoningBomb: A Stealthy Denial-of-Service Attack by Inducing Pathologically Long Reasoning in Large Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaogeng Liu, Xinyan Wang, Yechao Zhang, Sanjay Kariyappa, Chong Xiang, Muhao Chen, G. Edward Suh, Chaowei Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00154">https://arxiv.org/abs/2602.00154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00154">https://arxiv.org/pdf/2602.00154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00154]] ReasoningBomb: A Stealthy Denial-of-Service Attack by Inducing Pathologically Long Reasoning in Large Reasoning Models(https://arxiv.org/abs/2602.00154)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large reasoning models (LRMs) extend large language models with explicit multi-step reasoning traces, but this capability introduces a new class of prompt-induced inference-time denial-of-service (PI-DoS) attacks that exploit the high computational cost of reasoning. We first formalize inference cost for LRMs and define PI-DoS, then prove that any practical PI-DoS attack should satisfy three properties: (1) a high amplification ratio, where each query induces a disproportionately long reasoning trace relative to its own length; (ii) stealthiness, in which prompts and responses remain on the natural language manifold and evade distribution shift detectors; and (iii) optimizability, in which the attack supports efficient optimization without being slowed by its own success. Under this framework, we present ReasoningBomb, a reinforcement-learning-based PI-DoS framework that is guided by a constant-time surrogate reward and trains a large reasoning-model attacker to generate short natural prompts that drive victim LRMs into pathologically long and often effectively non-terminating reasoning. Across seven open-source models (including LLMs and LRMs) and three commercial LRMs, ReasoningBomb induces 18,759 completion tokens on average and 19,263 reasoning tokens on average across reasoning models. It outperforms the the runner-up baseline by 35% in completion tokens and 38% in reasoning tokens, while inducing 6-7x more tokens than benign queries and achieving 286.7x input-to-output amplification ratio averaged across all samples. Additionally, our method achieves 99.8% bypass rate on input-based detection, 98.7% on output-based detection, and 98.4% against strict dual-stage joint detection.</li>
</ul>

<h3>Title: First Steps, Lasting Impact: Platform-Aware Forensics for the Next Generation of Analysts</h3>
<ul>
<li><strong>Authors: </strong>Vinayak Jain, Sneha Sudhakaran, Saranyan Senthivel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00160">https://arxiv.org/abs/2602.00160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00160">https://arxiv.org/pdf/2602.00160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00160]] First Steps, Lasting Impact: Platform-Aware Forensics for the Next Generation of Analysts(https://arxiv.org/abs/2602.00160)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The reliability of cyber forensic evidence acquisition is strongly influenced by the underlying operating systems, Windows, macOS, and Linux - due to inherent variations in file system structures, encryption protocols, and forensic tool compatibility. Disk forensics, one of the most widely used techniques in digital investigations, faces distinct obstacles on each platform. Windows, with its predominantly NTFS and FAT file systems, typically supports reliable disk imaging and analysis through established tools such as FTK Imager and Autopsy/Sleuth Kit. However, encryption features frequently pose challenges to evidence acquisition. Conversely, Linux environments, which rely on file systems like ext4 and XFS, generally offer greater transparency, yet the transient nature of log retention often complicates forensic analysis. In instances where anti-forensic strategies such as encryption and compression render traditional disk forensics insufficient, memory forensics becomes crucial. While memory forensic methodologies demonstrate robustness across Windows and Linux platforms forms through frameworks like Volatility, platform-specific difficulties persist. Memory analysis on Linux systems benefits from tools like LiME, snapshot utilities, and dd for memory acquisition; nevertheless, live memory acquisition on Linux can still present challenges. This research systematically assesses both disk and memory forensic acquisition techniques across samples representing Windows and Linux systems. By identifying effective combinations of forensic tools and configurations tailored to each operating system, the study aims to improve the accuracy and reliability of evidence collection. It further evaluates current forensic tools and highlights a persistent gap: consistently assuring forensic input reliability and footprint integrity.</li>
</ul>

<h3>Title: Block removal for large language models through constrained binary optimization</h3>
<ul>
<li><strong>Authors: </strong>David Jansen, Roman Rausch, David Montero, Roman Orus</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00161">https://arxiv.org/abs/2602.00161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00161">https://arxiv.org/pdf/2602.00161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00161]] Block removal for large language models through constrained binary optimization(https://arxiv.org/abs/2602.00161)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Compressing resource-intensive large language models by removing whole transformer blocks is a seemingly simple idea, but identifying which blocks to remove constitutes an exponentially difficult combinatorial problem. In this paper, we formulate block removal as a constrained binary optimization problem that can be mapped to a physical system (Ising model), whose energies are a strong proxy for downstream model performance. This formulation enables an efficient ranking of a large number of candidate block-removal configurations and yields many high-quality, non-trivial solutions beyond consecutive regions. We demonstrate that our approach outperforms state-of-the-art block-removal methods across several benchmarks, with performance gains persisting after short retraining, and reaching improvements of up to 6 points on the MMLU benchmark. Our method requires only forward and backward passes for a few active parameters, together with an (at least approximate) Ising solver, and can be readily applied to any architecture. We illustrate this generality on the recent NVIDIA-Nemotron-3-Nano-30B-A3B-FP8 model, which exhibits a highly inhomogeneous and challenging block structure.</li>
</ul>

<h3>Title: Benford's Law as a Distributional Prior for Post-Training Quantization of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Arthur Negrão, Pedro Silva, Vander L. S. Freitas, Gladston Moreira, Eduardo Luz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00165">https://arxiv.org/abs/2602.00165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00165">https://arxiv.org/pdf/2602.00165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00165]] Benford's Law as a Distributional Prior for Post-Training Quantization of Large Language Models(https://arxiv.org/abs/2602.00165)</code><input type="text"></li>
<li><strong>Keywords: </strong>data-free, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The rapid growth of Large Language Models (LLMs) intensifies the need for effective compression, with weight quantization being the most widely adopted technique. Standard uniform quantizers assume that parameters are evenly distributed, an assumption at odds with the highly skewed distributions observed in practice. We propose Benford-Quant, a simple, data-free non-uniform quantizer inspired by Benford's Law, which predicts that leading digits follow a logarithmic distribution. Benford-Quant replaces the uniform grid with a log-spaced codebook, dedicating more resolution to the frequent small-magnitude weights. We provide both theoretical intuition and empirical evidence: (i) weights in transformer transformational layers adhere closely to Benford statistics, while normalization layers systematically deviate; (ii) on Small Language Models (SLMs), Benford-Quant consistently improves perplexity, reducing 4-bit perplexity on Gemma-270M by more than 10%; and (iii) on larger LLMs, it remains competitive, with differences explained by over-parameterization effects. Our results indicate that incorporating a Benford-inspired prior into quantization grids is a low-cost modification that yields accuracy gains in aggressive few-bit regimes. Although it is not able to surpass the state of the art in tasks such as perplexity and LAMBADA, the Benford-Quant approach can be hybridized with other quantization methods-such as SmoothQuant and Activation-Aware Quantization-without major pipeline modification, potentially improving their performance.</li>
</ul>

<h3>Title: Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints</h3>
<ul>
<li><strong>Authors: </strong>Evan Chen, Wenzhi Fang, Shiqiang Wang, Christopher Brinton</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00166">https://arxiv.org/abs/2602.00166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00166">https://arxiv.org/pdf/2602.00166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00166]] Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints(https://arxiv.org/abs/2602.00166)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Locally deployed Small Language Models (SLMs) must continually support diverse tasks under strict memory and computation constraints, making selective reliance on cloud Large Language Models (LLMs) unavoidable. Regulating cloud assistance during continual learning is challenging, as naive reward-based reinforcement learning often yields unstable offloading behavior and exacerbates catastrophic forgetting as task distributions shift. We propose DA-GRPO, a dual-advantage extension of Group Relative Policy Optimization that incorporates cloud-usage constraints directly into advantage computation, avoiding fixed reward shaping and external routing models. This design enables the local model to jointly learn task competence and collaboration behavior, allowing cloud requests to emerge naturally during post-training while respecting a prescribed assistance budget. Experiments on mathematical reasoning and code generation benchmarks show that DA-GRPO improves post-switch accuracy, substantially reduces forgetting, and maintains stable cloud usage compared to prior collaborative and routing-based approaches.</li>
</ul>

<h3>Title: YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ranjan Sapkota, Manoj Karkee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00168">https://arxiv.org/abs/2602.00168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00168">https://arxiv.org/pdf/2602.00168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00168]] YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation(https://arxiv.org/abs/2602.00168)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.</li>
</ul>

<h3>Title: Learning Robust Reasoning through Guided Adversarial Self-Play</h3>
<ul>
<li><strong>Authors: </strong>Shuozhe Li, Vaishnav Tadiparthi, Kwonjoon Lee, Nakul Agarwal, Hossein Nourkhiz Mahjoub, Ehsan Moradi Pari, Lizhang Chen, Amy Zhang, Liu Leqi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00173">https://arxiv.org/abs/2602.00173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00173">https://arxiv.org/pdf/2602.00173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00173]] Learning Robust Reasoning through Guided Adversarial Self-Play(https://arxiv.org/abs/2602.00173)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from verifiable rewards (RLVR) produces strong reasoning models, yet they can fail catastrophically when the conditioning context is fallible (e.g., corrupted chain-of-thought, misleading partial solutions, or mild input perturbations), since standard RLVR optimizes final-answer correctness only under clean conditioning. We introduce GASP (Guided Adversarial Self-Play), a robustification method that explicitly trains detect-and-repair capabilities using only outcome verification. Without human labels or external teachers, GASP forms an adversarial self-play game within a single model: a polluter learns to induce failure via locally coherent corruptions, while an agent learns to diagnose and recover under the same corrupted conditioning. To address the scarcity of successful recoveries early in training, we propose in-distribution repair guidance, an imitation term on self-generated repairs that increases recovery probability while preserving previously acquired capabilities. Across four open-weight models (1.5B--8B), GASP transforms strong-but-brittle reasoners into robust ones that withstand misleading and perturbed context while often improving clean accuracy. Further analysis shows that adversarial corruptions induce an effective curriculum, and in-distribution guidance enables rapid recovery learning with minimal representational drift.</li>
</ul>

<h3>Title: Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Zhao, Xuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00174">https://arxiv.org/abs/2602.00174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00174">https://arxiv.org/pdf/2602.00174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00174]] Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation(https://arxiv.org/abs/2602.00174)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We propose an intra-class subdivision pixel contrastive learning (SPCL) framework for cardiac image segmentation to address representation contamination at boundaries. The novel concept ``Unconcerned sample'' is proposed to distinguish pixel representations at the inner and boundary regions within the same class, facilitating a clearer characterization of intra-class variations. A novel boundary contrastive loss for boundary representations is proposed to enhance representation discrimination across boundaries. The advantages of the unconcerned sample and boundary contrastive loss are analyzed theoretically. Experimental results in public cardiac datasets demonstrate that SPCL significantly improves segmentation performance, outperforming existing methods with respect to segmentation quality and boundary precision. Our code is available at this https URL.</li>
</ul>

<h3>Title: The Illusion of Forgetting: Attack Unlearned Diffusion via Initial Latent Variable Optimization</h3>
<ul>
<li><strong>Authors: </strong>Manyi Li, Yufan Liu, Lai Jiang, Bing Li, Yuming Li, Weiming Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00175">https://arxiv.org/abs/2602.00175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00175">https://arxiv.org/pdf/2602.00175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00175]] The Illusion of Forgetting: Attack Unlearned Diffusion via Initial Latent Variable Optimization(https://arxiv.org/abs/2602.00175)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, diffusion</a></li>
<li><strong>Abstract: </strong>Although unlearning-based defenses claim to purge Not-Safe-For-Work (NSFW) concepts from diffusion models (DMs), we reveals that this "forgetting" is largely an illusion. Unlearning partially disrupts the mapping between linguistic symbols and the underlying knowledge, which remains intact as dormant memories. We find that the distributional discrepancy in the denoising process serves as a measurable indicator of how much of the mapping is retained, also reflecting the strength of unlearning. Inspired by this, we propose IVO (Initial Latent Variable Optimization), a concise and powerful attack framework that reactivates these dormant memories by reconstructing the broken mappings. Through Image Inversion}, Adversarial Optimization and Reused Attack, IVO optimizes initial latent variables to realign the noise distribution of unlearned models with their original unsafe states. Extensive experiments across 8 widely used unlearning techniques demonstrate that IVO achieves superior attack success rates and strong semantic consistency, exposing fundamental flaws in current defenses. The code is available at this http URL. Warning: This paper has unsafe images that may offend some readers.</li>
</ul>

<h3>Title: Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation</h3>
<ul>
<li><strong>Authors: </strong>Feng Tian, Yixuan Li, Weili Zeng, Weitian Zhang, Yichao Yan, Xiaokang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00176">https://arxiv.org/abs/2602.00176</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00176">https://arxiv.org/pdf/2602.00176</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00176]] Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation(https://arxiv.org/abs/2602.00176)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion posterior sampling solves inverse problems by combining a pretrained diffusion prior with measurement-consistency guidance, but it often fails to recover fine details because measurement terms are applied in a manner that is weakly coupled to the diffusion noise level. At high noise, data-consistency gradients computed from inaccurate estimates can be geometrically incongruent with the posterior geometry, inducing early-step drift, spurious high-frequency artifacts, plus sensitivity to schedules and ill-conditioned operators. To address these concerns, we propose a noise--frequency Continuation framework that constructs a continuous family of intermediate posteriors whose likelihood enforces measurement consistency only within a noise-dependent frequency band. This principle is instantiated with a stabilized posterior sampler that combines a diffusion predictor, band-limited likelihood guidance, and a multi-resolution consistency strategy that aggressively commits reliable coarse corrections while conservatively adopting high-frequency details only when they become identifiable. Across super-resolution, inpainting, and deblurring, our method achieves state-of-the-art performance and improves motion deblurring PSNR by up to 5 dB over strong baselines.</li>
</ul>

<h3>Title: How Understanding Forecast Uncertainty Resolves the Explainability Problem in Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Joseph L. Breeden</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00179">https://arxiv.org/abs/2602.00179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00179">https://arxiv.org/pdf/2602.00179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00179]] How Understanding Forecast Uncertainty Resolves the Explainability Problem in Machine Learning Models(https://arxiv.org/abs/2602.00179)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>For applications of machine learning in critical decisions, explainability is a primary concern, and often a regulatory requirement. Local linear methods for generating explanations, such as LIME and SHAP, have been criticized for being unstable near decision boundaries. In this paper, we explain that such concerns reflect a misunderstanding of the problem. The forecast uncertainty is high at decision boundaries, so consequently, the explanatory instability is high. The correct approach is to change the sequence of events and questions being asked. Nonlinear models can be highly predictive in some regions while having little or no predictability in others. Therefore, the first question is whether a usable forecast exists. When there is a forecast with low enough uncertainty to be useful, an explanation can be sought via a local linear approximation. In such cases, the explanatory instability is correspondingly low. When no usable forecast exists, the decision must fall to a simpler overall model such as traditional logistic regression. Additionally, these results show that some methods that purport to be explainable everywhere, such as ReLU networks or any piecewise linear model, have only an illusory explainability, because the forecast uncertainty at the segment boundaries is too high to be useful. Explaining an unusable forecast is pointless.</li>
</ul>

<h3>Title: EigenAI: Deterministic Inference, Verifiable Results</h3>
<ul>
<li><strong>Authors: </strong>David Ribeiro Alves, Vishnu Patankar, Matheus Pereira, Jamie Stephens, Nima Vaziri, Sreeram Kannan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00182">https://arxiv.org/abs/2602.00182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00182">https://arxiv.org/pdf/2602.00182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00182]] EigenAI: Deterministic Inference, Verifiable Results(https://arxiv.org/abs/2602.00182)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>EigenAI is a verifiable AI platform built on top of the EigenLayer restaking ecosystem. At a high level, it combines a deterministic large-language model (LLM) inference engine with a cryptoeconomically secured optimistic re-execution protocol so that every inference result can be publicly audited, reproduced, and, if necessary, economically enforced. An untrusted operator runs inference on a fixed GPU architecture, signs and encrypts the request and response, and publishes the encrypted log to EigenDA. During a challenge window, any watcher may request re-execution through EigenVerify; the result is then deterministically recomputed inside a trusted execution environment (TEE) with a threshold-released decryption key, allowing a public challenge with private data. Because inference itself is bit-exact, verification reduces to a byte-equality check, and a single honest replica suffices to detect fraud. We show how this architecture yields sovereign agents -- prediction-market judges, trading bots, and scientific assistants -- that enjoy state-of-the-art performance while inheriting security from Ethereum's validator base.</li>
</ul>

<h3>Title: RPP: A Certified Poisoned-Sample Detection Framework for Backdoor Attacks under Dataset Imbalance</h3>
<ul>
<li><strong>Authors: </strong>Miao Lin, Feng Yu, Rui Ning, Lusi Li, Jiawei Chen, Qian Lou, Mengxin Zheng, Chunsheng Xin, Hongyi Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00183">https://arxiv.org/abs/2602.00183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00183">https://arxiv.org/pdf/2602.00183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00183]] RPP: A Certified Poisoned-Sample Detection Framework for Backdoor Attacks under Dataset Imbalance(https://arxiv.org/abs/2602.00183)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Deep neural networks are highly susceptible to backdoor attacks, yet most defense methods to date rely on balanced data, overlooking the pervasive class imbalance in real-world scenarios that can amplify backdoor threats. This paper presents the first in-depth investigation of how the dataset imbalance amplifies backdoor vulnerability, showing that (i) the imbalance induces a majority-class bias that increases susceptibility and (ii) conventional defenses degrade significantly as the imbalance grows. To address this, we propose Randomized Probability Perturbation (RPP), a certified poisoned-sample detection framework that operates in a black-box setting using only model output probabilities. For any inspected sample, RPP determines whether the input has been backdoor-manipulated, while offering provable within-domain detectability guarantees and a probabilistic upper bound on the false positive rate. Extensive experiments on five benchmarks (MNIST, SVHN, CIFAR-10, TinyImageNet and ImageNet10) covering 10 backdoor attacks and 12 baseline defenses show that RPP achieves significantly higher detection accuracy than state-of-the-art defenses, particularly under dataset imbalance. RPP establishes a theoretical and practical foundation for defending against backdoor attacks in real-world environments with imbalanced data.</li>
</ul>

<h3>Title: GEPC: Group-Equivariant Posterior Consistency for Out-of-Distribution Detection in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yadang Alexis Rouzoumka, Jean Pinsolle, Eugénie Terreaux, Christèle Morisseau, Jean-Philippe Ovarlez, Chengfang Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00191">https://arxiv.org/abs/2602.00191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00191">https://arxiv.org/pdf/2602.00191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00191]] GEPC: Group-Equivariant Posterior Consistency for Out-of-Distribution Detection in Diffusion Models(https://arxiv.org/abs/2602.00191)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models learn a time-indexed score field $\mathbf{s}_\theta(\mathbf{x}_t,t)$ that often inherits approximate equivariances (flips, rotations, circular shifts) from in-distribution (ID) data and convolutional backbones. Most diffusion-based out-of-distribution (OOD) detectors exploit score magnitude or local geometry (energies, curvature, covariance spectra) and largely ignore equivariances. We introduce Group-Equivariant Posterior Consistency (GEPC), a training-free probe that measures how consistently the learned score transforms under a finite group $\mathcal{G}$, detecting equivariance breaking even when score magnitude remains unchanged. At the population level, we propose the ideal GEPC residual, which averages an equivariance-residual functional over $\mathcal{G}$, and we derive ID upper bounds and OOD lower bounds under mild assumptions. GEPC requires only score evaluations and produces interpretable equivariance-breaking maps. On OOD image benchmark datasets, we show that GEPC achieves competitive or improved AUROC compared to recent diffusion-based baselines while remaining computationally lightweight. On high-resolution synthetic aperture radar imagery where OOD corresponds to targets or anomalies in clutter, GEPC yields strong target-background separation and visually interpretable equivariance-breaking maps. Code is available at this https URL.</li>
</ul>

<h3>Title: Reducing Memorisation in Generative Models via Riemannian Bayesian Inference</h3>
<ul>
<li><strong>Authors: </strong>Johanna Marie Gegenfurtner, Albert Kjøller Jacobsen, Naima Elosegui Borras, Alejandro Valverde Mahou, Georgios Arvanitidis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00199">https://arxiv.org/abs/2602.00199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00199">https://arxiv.org/pdf/2602.00199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00199]] Reducing Memorisation in Generative Models via Riemannian Bayesian Inference(https://arxiv.org/abs/2602.00199)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Modern generative models can produce realistic samples, however, balancing memorisation and generalisation remains an open problem. We approach this challenge from a Bayesian perspective by focusing on the parameter space of flow matching and diffusion models and constructing a predictive posterior that better captures the variability of the data distribution. In particular, we capture the geometry of the loss using a Riemannian metric and leverage a flexible approximate posterior that adapts to the local structure of the loss landscape. This approach allows us to sample generative models that resemble the original model, but exhibit reduced memorisation. Empirically, we demonstrate that the proposed approach reduces memorisation while preserving generalisation. Further, we provide a theoretical analysis of our method, which explains our findings. Overall, our work illustrates how considering the geometry of the loss enables effective use of the parameter space, even for complex high-dimensional generative models.</li>
</ul>

<h3>Title: Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images</h3>
<ul>
<li><strong>Authors: </strong>Shanwen Wang, Xin Sun, Danfeng Hong, Fei Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00202">https://arxiv.org/abs/2602.00202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00202">https://arxiv.org/pdf/2602.00202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00202]] Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images(https://arxiv.org/abs/2602.00202)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>The semi-supervised semantic segmentation (S4) can learn rich visual knowledge from low-cost unlabeled images. However, traditional S4 architectures all face the challenge of low-quality pseudo-labels, especially for the teacher-student this http URL propose a novel SemiEarth model that introduces vision-language models (VLMs) to address the S4 issues for the remote sensing (RS) domain. Specifically, we invent a VLM pseudo-label purifying (VLM-PP) structure to purify the teacher network's pseudo-labels, achieving substantial improvements. Especially in multi-class boundary regions of RS images, the VLM-PP module can significantly improve the quality of pseudo-labels generated by the teacher, thereby correctly guiding the student model's learning. Moreover, since VLM-PP equips VLMs with open-world capabilities and is independent of the S4 architecture, it can correct mispredicted categories in low-confidence pseudo-labels whenever a discrepancy arises between its prediction and the pseudo-label. We conducted extensive experiments on multiple RS datasets, which demonstrate that our SemiEarth achieves SOTA performance. More importantly, unlike previous SOTA RS S4 methods, our model not only achieves excellent performance but also offers good interpretability. The code is released at this https URL.</li>
</ul>

<h3>Title: Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs</h3>
<ul>
<li><strong>Authors: </strong>Waleed Khan Mohammed, Zahirul Arief Irfan Bin Shahrul Anuar, Mousa Sufian Mousa Mitani, Hezerul Abdul Karim, Nouar AlDahoul</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00204">https://arxiv.org/abs/2602.00204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00204">https://arxiv.org/pdf/2602.00204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00204]] Semantic-Aware Advanced Persistent Threat Detection Using Autoencoders on LLM-Encoded System Logs(https://arxiv.org/abs/2602.00204)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Advanced Persistent Threats (APTs) are among the most challenging cyberattacks to detect. They are carried out by highly skilled attackers who carefully study their targets and operate in a stealthy, long-term manner. Because APTs exhibit "low-and-slow" behavior, traditional statistical methods and shallow machine learning techniques often fail to detect them. Previous research on APT detection has explored machine learning approaches and provenance graph analysis. However, provenance-based methods often fail to capture the semantic intent behind system activities. This paper proposes a novel anomaly detection approach that leverages semantic embeddings generated by Large Language Models (LLMs). The method enhances APT detection by extracting meaningful semantic representations from unstructured system log data. First, raw system logs are transformed into high-dimensional semantic embeddings using a pre-trained transformer model. These embeddings are then analyzed using an Autoencoder (AE) to identify anomalous and potentially malicious patterns. The proposed method is evaluated using the DARPA Transparent Computing (TC) dataset, which contains realistic APT attack scenarios generated by red teams in live environments. Experimental results show that the AE trained on LLM-derived embeddings outperforms widely used unsupervised baseline methods, including Isolation Forest (IForest), One-Class Support Vector Machine (OC-SVM), and Principal Component Analysis (PCA). Performance is measured using the Area Under the Receiver Operating Characteristic Curve (AUC-ROC), where the proposed approach consistently achieves superior results, even in complex threat scenarios. These findings highlight the importance of semantic understanding in detecting non-linear and stealthy attack behaviors that are often missed by conventional detection techniques.</li>
</ul>

<h3>Title: Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm Behaviors and Their Complementarity</h3>
<ul>
<li><strong>Authors: </strong>Jordan Levy, Paul Saves, Moncef Garouani, Nicolas Verstaevel, Benoit Gaudou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00208">https://arxiv.org/abs/2602.00208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00208">https://arxiv.org/pdf/2602.00208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00208]] Analyzing Shapley Additive Explanations to Understand Anomaly Detection Algorithm Behaviors and Their Complementarity(https://arxiv.org/abs/2602.00208)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Unsupervised anomaly detection is a challenging problem due to the diversity of data distributions and the lack of labels. Ensemble methods are often adopted to mitigate these challenges by combining multiple detectors, which can reduce individual biases and increase robustness. Yet building an ensemble that is genuinely complementary remains challenging, since many detectors rely on similar decision cues and end up producing redundant anomaly scores. As a result, the potential of ensemble learning is often limited by the difficulty of identifying models that truly capture different types of irregularities. To address this, we propose a methodology for characterizing anomaly detectors through their decision mechanisms. Using SHapley Additive exPlanations, we quantify how each model attributes importance to input features, and we use these attribution profiles to measure similarity between detectors. We show that detectors with similar explanations tend to produce correlated anomaly scores and identify largely overlapping anomalies. Conversely, explanation divergence reliably indicates complementary detection behavior. Our results demonstrate that explanation-driven metrics offer a different criterion than raw outputs for selecting models in an ensemble. However, we also demonstrate that diversity alone is insufficient; high individual model performance remains a prerequisite for effective ensembles. By explicitly targeting explanation diversity while maintaining model quality, we are able to construct ensembles that are more diverse, more complementary, and ultimately more effective for unsupervised anomaly detection.</li>
</ul>

<h3>Title: Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zafar Iqbal, Anwar Ul Haq, Srimannarayana Grandhi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00211">https://arxiv.org/abs/2602.00211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00211">https://arxiv.org/pdf/2602.00211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00211]] Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning(https://arxiv.org/abs/2602.00211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Unsupervised deformable image registration requires aligning complex anatomical structures without reference labels, making interpretability and reliability critical. Existing deep learning methods achieve considerable accuracy but often lack transparency, leading to error drift and reduced clinical trust. We propose a novel Multi-Hop Visual Chain of Reasoning (VCoR) framework that reformulates registration as a progressive reasoning process. Inspired by the iterative nature of clinical decision-making, each visual reasoning hop integrates a Localized Spatial Refinement (LSR) module to enrich feature representations and a Cross-Reference Attention (CRA) mechanism that leads the iterative refinement process, preserving anatomical consistency. This multi-hop strategy enables robust handling of large deformations and produces a transparent sequence of intermediate predictions with a theoretical bound. Beyond accuracy, our framework offers built-in interpretability by estimating uncertainty via the stability and convergence of deformation fields across hops. Extensive evaluations on two challenging public datasets, DIR-Lab 4D CT (lung) and IXI T1-weighted MRI (brain), demonstrate that VCoR achieves competitive registration accuracy while offering rich intermediate visualizations and confidence measures. By embedding an implicit visual reasoning paradigm, we present an interpretable, reliable, and clinically viable unsupervised medical image registration.</li>
</ul>

<h3>Title: TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce</h3>
<ul>
<li><strong>Authors: </strong>Mehul Goenka, Tejas Pathak, Siddharth Asthana</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00213">https://arxiv.org/abs/2602.00213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00213">https://arxiv.org/pdf/2602.00213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00213]] TessPay: Verify-then-Pay Infrastructure for Trusted Agentic Commerce(https://arxiv.org/abs/2602.00213)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>The global economy is entering the era of Agentic Commerce, where autonomous agents can discover services, negotiate prices, and transact value. However adoption towards agentic commerce faces a foundational trust gap: current systems are built for direct human interactions rather than agent-driven operations. It lacks core primitives across three critical stages of agentic transactions. First, Task Delegation lacks means to translate user intent into defined scopes, discover appropriate agents, and securely authorize actions. Second, Payment Settlement for tasks is processed before execution, lacking verifiable evidence to validate the agent's work. Third, Audit Mechanisms fail to capture the full transaction lifecycle, preventing clear accountability for disputes. While emerging standards address fragments of this trust gap, there still remains a critical need for a unified infrastructure that binds the entire transaction lifecycle. To resolve this gap, we introduce TessPay, a unified infrastructure that replaces implicit trust with a 'Verify-then-Pay' architecture. It is a two plane architecture separating control and verification from settlement. TessPay operationalizes trust across four distinct stages: Before execution, agents are anchored in a canonical registry and user intent is captured as verifiable mandates, enabling stakeholder accountability. During execution, funds are locked in escrow while the agent executes the task and generates cryptographic evidence (TLS Notary, TEE etc.) to support Proof of Task Execution (PoTE). At settlement, the system verifies this evidence and releases funds only when the PoTE satisfies verification predicates; modular rail adapters ensure this PoTE-gated escrow remains chain-agnostic across heterogeneous payment rails. After settlement, TessPay preserves a tamper-evident audit trail to enable clear accountability for dispute resolution.</li>
</ul>

<h3>Title: A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification</h3>
<ul>
<li><strong>Authors: </strong>Juan A. Olmos, Antoine Manzanera, Fabio Martínez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00214">https://arxiv.org/abs/2602.00214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00214">https://arxiv.org/pdf/2602.00214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00214]] A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification(https://arxiv.org/abs/2602.00214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Prostate cancer (PCa) is one of the most common cancers in men worldwide. Bi-parametric MRI (bp-MRI) and clinical variables are crucial for PCa identification and improving treatment decisions. However, this process is subjective to expert interpretations. Furthermore, most existing computer-aided diagnosis methods focus on imaging-based models, overlooking the clinical context and suffering from data scarcity, limiting their ability to learn robust representations. We propose a geometric multimodal Foundation Model (FM), named MFM-Geom, that learns representations from bp-MRI and clinical reports, encoding visual findings and information from the context of clinical variables. In the representations classification head, the approach leverages symmetric positive definite (SPD) matrices and Riemannian deep learning to integrate imaging-text representations from a biomedical multimodal FM. Using 10% of the training data, MFM-Geom outperformed baseline class token embedding-based classification (+8.3%, AUC-PR of 90.67). Generalization on external dataset confirmed the robustness of fine-tuning biomedical FM, achieving an AUC-PR of 90.6.</li>
</ul>

<h3>Title: Dispersion Loss Counteracts Embedding Condensation and Improves Generalization in Small Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chen Liu, Xingzhi Sun, Xi Xiao, Alexandre Van Tassel, Ke Xu, Kristof Reimann, Danqi Liao, Mark Gerstein, Tianyang Wang, Xiao Wang, Smita Krishnaswamy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00217">https://arxiv.org/abs/2602.00217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00217">https://arxiv.org/pdf/2602.00217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00217]] Dispersion Loss Counteracts Embedding Condensation and Improves Generalization in Small Language Models(https://arxiv.org/abs/2602.00217)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) achieve remarkable performance through ever-increasing parameter counts, but scaling incurs steep computational costs. To better understand LLM scaling, we study representational differences between LLMs and their smaller counterparts, with the goal of replicating the representational qualities of larger models in the smaller models. We observe a geometric phenomenon which we term $\textbf{embedding condensation}$, where token embeddings collapse into a narrow cone-like subspace in some language models. Through systematic analyses across multiple Transformer families, we show that small models such as $\texttt{GPT2}$ and $\texttt{Qwen3-0.6B}$ exhibit severe condensation, whereas the larger models such as $\texttt{GPT2-xl}$ and $\texttt{Qwen3-32B}$ are more resistant to this phenomenon. Additional observations show that embedding condensation is not reliably mitigated by knowledge distillation from larger models. To fight against it, we formulate a dispersion loss that explicitly encourages embedding dispersion during training. Experiments demonstrate that it mitigates condensation, recovers dispersion patterns seen in larger models, and yields performance gains across 10 benchmarks. We believe this work offers a principled path toward improving smaller Transformers without additional parameters.</li>
</ul>

<h3>Title: GRIP2: A Robust and Powerful Deep Knockoff Method for Feature Selection</h3>
<ul>
<li><strong>Authors: </strong>Bob Junyi Zou, Lu Tian</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00218">https://arxiv.org/abs/2602.00218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00218">https://arxiv.org/pdf/2602.00218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00218]] GRIP2: A Robust and Powerful Deep Knockoff Method for Feature Selection(https://arxiv.org/abs/2602.00218)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Identifying truly predictive covariates while strictly controlling false discoveries remains a fundamental challenge in nonlinear, highly correlated, and low signal-to-noise regimes, where deep learning based feature selection methods are most attractive. We propose Group Regularization Importance Persistence in 2 Dimensions (GRIP2), a deep knockoff feature importance statistic that integrates first-layer feature activity over a two-dimensional regularization surface controlling both sparsity strength and sparsification geometry. To approximate this surface integral in a single training run, we introduce efficient block-stochastic sampling, which aggregates feature activity magnitudes across diverse regularization regimes along the optimization trajectory. The resulting statistics are antisymmetric by construction, ensuring finite-sample FDR control. In extensive experiments on synthetic and semi-real data, GRIP2 demonstrates improved robustness to feature correlation and noise level: in high correlation and low signal-to-noise ratio regimes where standard deep learning based feature selectors may struggle, our method retains high power and stability. Finally, on real-world HIV drug resistance data, GRIP2 recovers known resistance-associated mutations with power better than established linear baselines, confirming its reliability in practice.</li>
</ul>

<h3>Title: Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Saeid Jamshidi, Omar Abdul Wahab, Foutse Khomh, Kawser Wazed Nafi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00219">https://arxiv.org/abs/2602.00219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00219">https://arxiv.org/pdf/2602.00219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00219]] Tri-LLM Cooperative Federated Zero-Shot Intrusion Detection with Semantic Disagreement and Trust-Aware Aggregation(https://arxiv.org/abs/2602.00219)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has become an effective paradigm for privacy-preserving, distributed Intrusion Detection Systems (IDS) in cyber-physical and Internet of Things (IoT) networks, where centralized data aggregation is often infeasible due to privacy and bandwidth constraints. Despite its advantages, most existing FL-based IDS assume closed-set learning and lack mechanisms such as uncertainty estimation, semantic generalization, and explicit modeling of epistemic ambiguity in zero-day attack scenarios. Additionally, robustness to heterogeneous and unreliable clients remains a challenge in practical applications. This paper introduces a semantics-driven federated IDS framework that incorporates language-derived semantic supervision into federated optimization, enabling open-set and zero-shot intrusion detection for previously unseen attack behaviors. The approach constructs semantic attack prototypes using a Tri-LLM ensemble of GPT-4o, DeepSeek-V3, and LLaMA-3-8B, aligning distributed telemetry features with high-level attack concepts. Inter-LLM semantic disagreement is modeled as epistemic uncertainty for zero-day risk estimation, while a trust-aware aggregation mechanism dynamically weights client updates based on reliability. Experimental results show stable semantic alignment across heterogeneous clients and consistent convergence. The framework achieves over 80% zero-shot detection accuracy on unseen attack patterns, improving zero-day discrimination by more than 10% compared to similarity-based baselines, while maintaining low aggregation instability in the presence of unreliable or compromised clients.</li>
</ul>

<h3>Title: DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Hu, Niket Tandon, Akhil Arora</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00238">https://arxiv.org/abs/2602.00238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00238">https://arxiv.org/pdf/2602.00238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00238]] DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking(https://arxiv.org/abs/2602.00238)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: this https URL</li>
</ul>

<h3>Title: Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust and Efficient Edge-Native Weather Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Md Muhtasim Munif Fahim, Soyda Humyra Yesmin, Saiful Islam, Md. Palash Bin Faruque, Md. A. Salam, Md. Mahfuz Uddin, Samiul Islam, Tofayel Ahmed, Md. Binyamin, Md. Rezaul Karim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00240">https://arxiv.org/abs/2602.00240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00240">https://arxiv.org/pdf/2602.00240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00240]] Green-NAS: A Global-Scale Multi-Objective Neural Architecture Search for Robust and Efficient Edge-Native Weather Forecasting(https://arxiv.org/abs/2602.00240)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce Green-NAS, a multi-objective NAS (neural architecture search) framework designed for low-resource environments using weather forecasting as a case study. By adhering to 'Green AI' principles, the framework explicitly minimizes computational energy costs and carbon footprints, prioritizing sustainable deployment over raw computational scale. The Green-NAS architecture search method is optimized for both model accuracy and efficiency to find lightweight models with high accuracy and very few model parameters; this is accomplished through an optimization process that simultaneously optimizes multiple objectives. Our best-performing model, Green-NAS-A, achieved an RMSE of 0.0988 (i.e., within 1.4% of our manually tuned baseline) using only 153k model parameters, which is 239 times fewer than other globally applied weather forecasting models, such as GraphCast. In addition, we also describe how the use of transfer learning will improve the weather forecasting accuracy by approximately 5.2%, in comparison to a naive approach of training a new model for each city, when there is limited historical weather data available for that city.</li>
</ul>

<h3>Title: CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Samyak Jha, Junho Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00247">https://arxiv.org/abs/2602.00247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00247">https://arxiv.org/pdf/2602.00247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00247]] CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models(https://arxiv.org/abs/2602.00247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Efficient inference in Large Vision-Language Models is constrained by the high cost of processing thousands of visual tokens, yet it remains unclear which tokens and computations can be safely removed. While attention scores are commonly used to estimate visual token importance, they are an imperfect proxy for actual contribution. We show that Attention Contribution, which weights attention probabilities by value vector magnitude, provides a more accurate criterion for visual token selection. Our empirical analysis reveals that visual attention sinks are functionally heterogeneous, comprising Probability Dumps with low contribution that can be safely pruned, and Structural Anchors with high contribution essential for maintaining model performance. Further, we identify substantial redundancy in Feed-Forward Networks (FFNs) associated with visual tokens, particularly in intermediate layers where image tokens exhibit linear behavior. Based on our findings, we introduce CAPA (Contribution-Aware Pruning and FFN Approximation), a dual-strategy framework that prunes visual tokens using attention contribution at critical functional transitions and reduces FFN computation through efficient linear approximations. Experiments on various benchmarks across baselines show that CAPA achieves competent efficiency--performance trade-offs with improved robustness.</li>
</ul>

<h3>Title: SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Rishav Pramanik, Ian E. Nielsen, Jeff Smith, Saurav Pandit, Ravi P. Ramachandran, Zhaozheng Yin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00249">https://arxiv.org/abs/2602.00249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00249">https://arxiv.org/pdf/2602.00249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00249]] SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis(https://arxiv.org/abs/2602.00249)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid progress of text-to-image (T2I) models has unlocked unprecedented creative potential, yet their ability to faithfully render complex prompts involving multiple objects, attributes, and spatial relationships remains a significant bottleneck. Progress is hampered by a lack of adequate evaluation methods; current benchmarks are often restricted to closed-set vocabularies, lack fine-grained diagnostic capabilities, and fail to provide the interpretable feedback necessary to diagnose and remedy specific compositional failures. We solve these challenges by introducing SANEval (Spatial, Attribute, and Numeracy Evaluation), a comprehensive benchmark that establishes a scalable new pipeline for open-vocabulary compositional evaluation. SANEval combines a large language model (LLM) for deep prompt understanding with an LLM-enhanced, open-vocabulary object detector to robustly evaluate compositional adherence, unconstrained by a fixed vocabulary. Through extensive experiments on six state-of-the-art T2I models, we demonstrate that SANEval's automated evaluations provide a more faithful proxy for human assessment; our metric achieves a Spearman's rank correlation with statistically different results than those of existing benchmarks across tasks of attribute binding, spatial relations, and numeracy. To facilitate future research in compositional T2I generation and evaluation, we will release the SANEval dataset and our open-source evaluation pipeline.</li>
</ul>

<h3>Title: TABES: Trajectory-Aware Backward-on-Entropy Steering for Masked Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Shreshth Saini, Avinab Saha, Balu Adsumilli, Neil Birkbeck, Yilin Wang, Alan C. Bovik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00250">https://arxiv.org/abs/2602.00250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00250">https://arxiv.org/pdf/2602.00250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00250]] TABES: Trajectory-Aware Backward-on-Entropy Steering for Masked Diffusion Models(https://arxiv.org/abs/2602.00250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Masked Diffusion Models (MDMs) have emerged as a promising non-autoregressive paradigm for generative tasks, offering parallel decoding and bidirectional context utilization. However, current sampling methods rely on simple confidence-based heuristics that ignore the long-term impact of local decisions, leading to trajectory lock-in where early hallucinations cascade into global incoherence. While search-based methods mitigate this, they incur prohibitive computational costs ($O(K)$ forward passes per step). In this work, we propose Backward-on-Entropy (BoE) Steering, a gradient-guided inference framework that approximates infinite-horizon lookahead via a single backward pass. We formally derive the Token Influence Score (TIS) from a first-order expansion of the trajectory cost functional, proving that the gradient of future entropy with respect to input embeddings serves as an optimal control signal for minimizing uncertainty. To ensure scalability, we introduce \texttt{ActiveQueryAttention}, a sparse adjoint primitive that exploits the structure of the masking objective to reduce backward pass complexity. BoE achieves a superior Pareto frontier for inference-time scaling compared to existing unmasking methods, demonstrating that gradient-guided steering offers a mathematically principled and efficient path to robust non-autoregressive generation. We will release the code.</li>
</ul>

<h3>Title: Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Huanran Li, Daniel Pimentel-Alarcón</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00262">https://arxiv.org/abs/2602.00262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00262">https://arxiv.org/pdf/2602.00262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00262]] Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning(https://arxiv.org/abs/2602.00262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Subspace clustering aims to group data points that lie in a union of low-dimensional subspaces and finds wide application in computer vision, hyperspectral imaging, and recommendation systems. However, most existing methods assume fully observed data, limiting their effectiveness in real-world scenarios with missing entries. In this paper, we propose a contrastive self-supervised framework, Contrastive Subspace Clustering (CSC), designed for clustering incomplete data. CSC generates masked views of partially observed inputs and trains a deep neural network using a SimCLR-style contrastive loss to learn invariant embeddings. These embeddings are then clustered using sparse subspace clustering. Experiments on six benchmark datasets show that CSC consistently outperforms both classical and deep learning baselines, demonstrating strong robustness to missing data and scalability to large datasets.</li>
</ul>

<h3>Title: PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Gemma Canet Tarrés, Manel Baradad, Francesc Moreno-Noguer, Yumeng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00267">https://arxiv.org/abs/2602.00267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00267">https://arxiv.org/pdf/2602.00267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00267]] PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories(https://arxiv.org/abs/2602.00267)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative AI have dramatically improved photorealistic image synthesis, yet they fall short for studio-level multi-object compositing. This task demands simultaneous (i) near-perfect preservation of each item's identity, (ii) precise background and color fidelity, (iii) layout and design elements control, and (iv) complete, appealing displays showcasing all objects. However, current state-of-the-art models often alter object details, omit or duplicate objects, and produce layouts with incorrect relative sizing or inconsistent item presentations. To bridge this gap, we introduce PLACID, a framework that transforms a collection of object images into an appealing multi-object composite. Our approach makes two main contributions. First, we leverage a pretrained image-to-video (I2V) diffusion model with text control to preserve objects consistency, identities, and background details by exploiting temporal priors from videos. Second, we propose a novel data curation strategy that generates synthetic sequences where randomly placed objects smoothly move to their target positions. This synthetic data aligns with the video model's temporal priors during training. At inference, objects initialized at random positions consistently converge into coherent layouts guided by text, with the final frame serving as the composite image. Extensive quantitative evaluations and user studies demonstrate that PLACID surpasses state-of-the-art methods in multi-object compositing, achieving superior identity, background, and color preservation, with less omitted objects and visually appealing results.</li>
</ul>

<h3>Title: RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Salehi, Karthik Pattabiraman</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.RO, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00270">https://arxiv.org/abs/2602.00270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00270">https://arxiv.org/pdf/2602.00270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00270]] RVDebloater: Mode-based Adaptive Firmware Debloating for Robotic Vehicles(https://arxiv.org/abs/2602.00270)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>As the number of embedded devices grows and their functional requirements increase, embedded firmware is becoming increasingly larger, thereby expanding its attack surface. Despite the increase in firmware size, many embedded devices, such as robotic vehicles (RVs), operate in distinct modes, each requiring only a small subset of the firmware code at runtime. We refer to such devices as mode-based embedded devices. Debloating is an approach to reduce attack surfaces by removing or restricting unneeded code, but existing techniques suffer from significant limitations, such as coarse granularity and irreversible code removal, limiting their applicability. To address these limitations, we propose RVDebloater, a novel adaptive debloating technique for mode-based embedded devices that automatically identifies unneeded firmware code for each mode using either static or dynamic analysis, and dynamically debloats the firmware for each mode at the function level at runtime. RVDebloater introduces a new software-based enforcement approach that supports diverse mode-based embedded devices. We implemented RVDebloater using the LLVM compiler and evaluated its efficiency and effectiveness on six different RVs, including both simulated and real ones, with different real-world missions. We find that device requirements change throughout its lifetime for each mode, and that many critical firmware functions can be restricted in other modes, with an average of 85% of functions not being required. The results showed that none of the missions failed after debloating with RVDebloater, indicating that it neither incurred false positives nor false negatives. Further, RVDebloater prunes the firmware call graph by an average of 45% across different firmware. Finally, RVDebloater incurred an average performance overhead of 3.9% and memory overhead of 4% (approximately 0.25 MB) on real RVs.</li>
</ul>

<h3>Title: Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Philip Müller, Nicholas Popovič, Michael Färber, Peter Steinbach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00279">https://arxiv.org/abs/2602.00279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00279">https://arxiv.org/pdf/2602.00279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00279]] Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering(https://arxiv.org/abs/2602.00279)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Existing UQ approaches remain weakly validated in scientific QA, a domain relying on fact-retrieval and reasoning capabilities. We introduce the first large-scale benchmark for evaluating UQ metrics in reasoning-demanding QA studying calibration of UQ methods, providing an extensible open-source framework to reproducibly assess calibration. Our study spans up to 20 large language models of base, instruction-tuned and reasoning variants. Our analysis covers seven scientific QA datasets, including both multiple-choice and arithmetic question answering tasks, using prompting to emulate an open question answering setting. We evaluate and compare methods representative of prominent approaches on a total of 685,000 long-form responses, spanning different reasoning complexities representative of domain-specific tasks. At the token level, we find that instruction tuning induces strong probability mass polarization, reducing the reliability of token-level confidences as estimates of uncertainty. Models further fine-tuned for reasoning are exposed to the same effect, but the reasoning process appears to mitigate it depending on the provider. At the sequence level, we show that verbalized approaches are systematically biased and poorly correlated with correctness, while answer frequency (consistency across samples) yields the most reliable calibration. In the wake of our analysis, we study and report the misleading effect of relying exclusively on ECE as a sole measure for judging performance of UQ methods on benchmark datasets. Our findings expose critical limitations of current UQ methods for LLMs and standard practices in benchmarking thereof.</li>
</ul>

<h3>Title: Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective</h3>
<ul>
<li><strong>Authors: </strong>Shaorong Zhang, Longxuan Yu, Rob Brekelmans, Luhan Tang, Salman Asif, Greg Ver Steeg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00286">https://arxiv.org/abs/2602.00286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00286">https://arxiv.org/pdf/2602.00286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00286]] Generation Order and Parallel Decoding in Masked Diffusion Models: An Information-Theoretic Perspective(https://arxiv.org/abs/2602.00286)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Masked Diffusion Models (MDMs) significantly accelerate inference by trading off sequential determinism. However, the theoretical mechanisms governing generation order and the risks inherent in parallelization remain under-explored. In this work, we provide a unified information-theoretic framework to decouple and analyze two fundamental sources of failure: order sensitivity and parallelization bias. Our analysis yields three key insights: (1) The benefits of Easy-First decoding (prioritizing low-entropy tokens) are magnified as model error increases; (2) factorized parallel decoding introduces intrinsic sampling errors that can lead to arbitrary large Reverse KL divergence, capturing "incoherence" failures that standard Forward KL metrics overlook; and (3) while verification can eliminate sampling error, it incurs an exponential cost governed by the total correlation within a block. Conversely, heuristics like remasking, though computationally efficient, cannot guarantee distributional correctness. Experiments on a controlled Block-HMM and large-scale MDMs (LLaDA) for arithmetic reasoning validate our theoretical framework.</li>
</ul>

<h3>Title: TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs</h3>
<ul>
<li><strong>Authors: </strong>Baiqi Li, Kangyi Zhao, Ce Zhang, Chancharik Mitra, Jean de Dieu Nyandwi, Gedas Bertasius</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00288">https://arxiv.org/abs/2602.00288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00288">https://arxiv.org/pdf/2602.00288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00288]] TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs(https://arxiv.org/abs/2602.00288)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at this https URL .</li>
</ul>

<h3>Title: LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification</h3>
<ul>
<li><strong>Authors: </strong>Rory Driscoll, Alexandros Christoforos, Chadbourne Davis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00292">https://arxiv.org/abs/2602.00292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00292">https://arxiv.org/pdf/2602.00292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00292]] LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification(https://arxiv.org/abs/2602.00292)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>While sequential reasoning enhances the capability of Vision-Language Models (VLMs) to execute complex multimodal tasks, their reliability in grounding these reasoning chains within actual visual evidence remains insufficiently explored. We introduce LogicGaze, a novel benchmark framework designed to rigorously interrogate whether VLMs can validate sequential causal chains against visual inputs, specifically targeting the pervasive issue of hallucination. Curated from 40,000 video segments from ShareGPT4Video and a subset of Flickr30k imagery, LogicGaze integrates causal sequences with visually contradictory yet linguistically plausible perturbations, compelling models to verify the authenticity of each reasoning step. Our tripartite evaluation protocol - Causal Validation, Grounded Narrative Synthesis, and Perturbation Rejection - exposes significant vulnerabilities in state-of-the-art VLMs such as Qwen2.5-VL-72B. LogicGaze advocates for robust, trustworthy multimodal reasoning, with all resources publicly available in an anonymized repository.</li>
</ul>

<h3>Title: Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation</h3>
<ul>
<li><strong>Authors: </strong>Franz A. Heinsen, Leo Kozachkov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00294">https://arxiv.org/abs/2602.00294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00294">https://arxiv.org/pdf/2602.00294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00294]] Self-Attention at Constant Cost per Token via Symmetry-Aware Taylor Approximation(https://arxiv.org/abs/2602.00294)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The most widely used artificial intelligence (AI) models today are Transformers employing self-attention. In its standard form, self-attention incurs costs that increase with context length, driving demand for storage, compute, and energy that is now outstripping society's ability to provide them. To help address this issue, we show that self-attention is efficiently computable to arbitrary precision with constant cost per token, achieving orders-of-magnitude reductions in memory use and computation. We derive our formulation by decomposing the conventional formulation's Taylor expansion into expressions over symmetric chains of tensor products. We exploit their symmetry to obtain feed-forward transformations that efficiently map queries and keys to coordinates in a minimal polynomial-kernel feature basis. Notably, cost is fixed inversely in proportion to head size, enabling application over a greater number of heads per token than otherwise feasible. We implement our formulation and empirically validate its correctness. Our work enables unbounded token generation at modest fixed cost, substantially reducing the infrastructure and energy demands of large-scale Transformer models. The mathematical techniques we introduce are of independent interest.</li>
</ul>

<h3>Title: Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xilin Gong, Shu Yang, Zehua Cao, Lynne Billard, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00300">https://arxiv.org/abs/2602.00300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00300">https://arxiv.org/pdf/2602.00300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00300]] Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models(https://arxiv.org/abs/2602.00300)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representations. However, our work shows that LLMs tend to rely on inherent linguistic patterns, which can override contextual information encoded in the hidden representations during decoding. For example, even when a hidden representation encodes the contextual attribute "purple" for "broccoli", LLMs still generate "green" in their explanations, reflecting a strong prior association. This behavior reveals a systematic unfaithfulness in Patchscopes. To systematically study this issue, we first designed a dataset to evaluate the faithfulness of Patchscopes under biased cases, and our results show that there is an 18.84\% faithfulness decrease on average. We then propose Bias Alignment through Logit Recalibration (BALOR), which treats the output logits from an unpatched prompt as capturing model bias and contrasts them with logits obtained under patched contextual information. By recalibrating the logit distribution through this contrast, BALOR suppresses model bias and amplifies contextual information during generation. Experiments across multiple LLMs demonstrate that BALOR consistently outperforms existing baselines, achieving up to 33\% relative performance improvement.</li>
</ul>

<h3>Title: Semantics-Preserving Evasion of LLM Vulnerability Detectors</h3>
<ul>
<li><strong>Authors: </strong>Luze Sun, Alina Oprea, Eric Wong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00305">https://arxiv.org/abs/2602.00305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00305">https://arxiv.org/pdf/2602.00305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00305]] Semantics-Preserving Evasion of LLM Vulnerability Detectors(https://arxiv.org/abs/2602.00305)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>LLM-based vulnerability detectors are increasingly deployed in security-critical code review, yet their resilience to evasion under behavior-preserving edits remains poorly understood. We evaluate detection-time integrity under a semantics-preserving threat model by instantiating diverse behavior-preserving code transformations on a unified C/C++ benchmark (N=5000), and introduce a metric of joint robustness across different attack methods/carriers. Across models, we observe a systemic failure of semantic invariant adversarial transformations: even state-of-the-art vulnerability detectors perform well on clean inputs while predictions flip under behavior-equivalent edits. Universal adversarial strings optimized on a single surrogate model remain effective when transferred to black-box APIs, and gradient access can further amplify evasion success. These results show that even high-performing detectors are vulnerable to low-cost, semantics-preserving evasion. Our carrier-based metrics provide practical diagnostics for evaluating LLM-based code detectors.</li>
</ul>

<h3>Title: Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Samuel Church, Joshua D. Warner, Danyal Maqbool, Xin Tie, Junjie Hu, Meghan G. Lubner, Tyler J. Bradshaw</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00309">https://arxiv.org/abs/2602.00309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00309">https://arxiv.org/pdf/2602.00309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00309]] Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation(https://arxiv.org/abs/2602.00309)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The development of machine learning models for CT imaging depends on the availability of large, high-quality, and diverse annotated datasets. Although large volumes of CT images and reports are readily available in clinical picture archiving and communication systems (PACS), 3D segmentations of critical findings are costly to obtain, typically requiring extensive manual annotation by radiologists. On the other hand, it is common for radiologists to provide limited annotations of findings during routine reads, such as line measurements and arrows, that are often stored in PACS as GSPS objects. We posit that these sparse annotations can be extracted along with CT volumes and converted into 3D segmentations using promptable segmentation models, a paradigm we term Opportunistic Promptable Segmentation. To enable this paradigm, we propose SAM2CT, the first promptable segmentation model designed to convert radiologist annotations into 3D segmentations in CT volumes. SAM2CT builds upon SAM2 by extending the prompt encoder to support arrow and line inputs and by introducing Memory-Conditioned Memories (MCM), a memory encoding strategy tailored to 3D medical volumes. On public lesion segmentation benchmarks, SAM2CT outperforms existing promptable segmentation models and similarly trained baselines, achieving Dice similarity coefficients of 0.649 for arrow prompts and 0.757 for line prompts. Applying the model to pre-existing GSPS annotations from a clinical PACS (N = 60), SAM2CT generates 3D segmentations that are clinically acceptable or require only minor adjustments in 87% of cases, as scored by radiologists. Additionally, SAM2CT demonstrates strong zero-shot performance on select Emergency Department findings. These results suggest that large-scale mining of historical GSPS annotations represents a promising and scalable approach for generating 3D CT segmentation datasets.</li>
</ul>

<h3>Title: On the Assessment of Sensitivity of Autonomous Vehicle Perception</h3>
<ul>
<li><strong>Authors: </strong>Apostol Vassilev, Munawar Hasan, Edward Griffor, Honglan Jin, Pavel Piliptchak, Mahima Arora, Thoshitha Gamage</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00314">https://arxiv.org/abs/2602.00314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00314">https://arxiv.org/pdf/2602.00314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00314]] On the Assessment of Sensitivity of Autonomous Vehicle Perception(https://arxiv.org/abs/2602.00314)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The viability of automated driving is heavily dependent on the performance of perception systems to provide real-time accurate and reliable information for robust decision-making and maneuvers. These systems must perform reliably not only under ideal conditions, but also when challenged by natural and adversarial driving factors. Both of these types of interference can lead to perception errors and delays in detection and classification. Hence, it is essential to assess the robustness of the perception systems of automated vehicles (AVs) and explore strategies for making perception more reliable. We approach this problem by evaluating perception performance using predictive sensitivity quantification based on an ensemble of models, capturing model disagreement and inference variability across multiple models, under adverse driving scenarios in both simulated environments and real-world conditions. A notional architecture for assessing perception performance is proposed. A perception assessment criterion is developed based on an AV's stopping distance at a stop sign on varying road surfaces, such as dry and wet asphalt, and vehicle speed. Five state-of-the-art computer vision models are used, including YOLO (v8-v9), DEtection TRansformer (DETR50, DETR101), Real-Time DEtection TRansformer (RT-DETR)in our experiments. Diminished lighting conditions, e.g., resulting from the presence of fog and low sun altitude, have the greatest impact on the performance of the perception models. Additionally, adversarial road conditions such as occlusions of roadway objects increase perception sensitivity and model performance drops when faced with a combination of adversarial road conditions and inclement weather conditions. Also, it is demonstrated that the greater the distance to a roadway object, the greater the impact on perception performance, hence diminished perception robustness.</li>
</ul>

<h3>Title: Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors</h3>
<ul>
<li><strong>Authors: </strong>Arian Khorasani, Nathaniel Chen, Yug D Oswal, Akshat Santhana Gopalan, Egemen Kolemen, Ravid Shwartz-Ziv</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00315">https://arxiv.org/abs/2602.00315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00315">https://arxiv.org/pdf/2602.00315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00315]] Beyond the Loss Curve: Scaling Laws, Active Learning, and the Limits of Learning from Exact Posteriors(https://arxiv.org/abs/2602.00315)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>How close are neural networks to the best they could possibly do? Standard benchmarks cannot answer this because they lack access to the true posterior p(y|x). We use class-conditional normalizing flows as oracles that make exact posteriors tractable on realistic images (AFHQ, ImageNet). This enables five lines of investigation. Scaling laws: Prediction error decomposes into irreducible aleatoric uncertainty and reducible epistemic error; the epistemic component follows a power law in dataset size, continuing to shrink even when total loss plateaus. Limits of learning: The aleatoric floor is exactly measurable, and architectures differ markedly in how they approach it: ResNets exhibit clean power-law scaling while Vision Transformers stall in low-data regimes. Soft labels: Oracle posteriors contain learnable structure beyond class labels: training with exact posteriors outperforms hard labels and yields near-perfect calibration. Distribution shift: The oracle computes exact KL divergence of controlled perturbations, revealing that shift type matters more than shift magnitude: class imbalance barely affects accuracy at divergence values where input noise causes catastrophic degradation. Active learning: Exact epistemic uncertainty distinguishes genuinely informative samples from inherently ambiguous ones, improving sample efficiency. Our framework reveals that standard metrics hide ongoing learning, mask architectural differences, and cannot diagnose the nature of distribution shift.</li>
</ul>

<h3>Title: MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes</h3>
<ul>
<li><strong>Authors: </strong>Rodrigo Batista, Luís Filipe Cunha, Purificação Silvano, Nuno Guimarães, Alípio Jorge, Evelin Amorim, Ricardo Campos</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00316">https://arxiv.org/abs/2602.00316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00316">https://arxiv.org/pdf/2602.00316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00316]] MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes(https://arxiv.org/abs/2602.00316)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Municipal meeting minutes are official documents of local governance, exhibiting heterogeneous formats and writing styles. Effective information retrieval (IR) requires identifying metadata such as meeting number, date, location, participants, and start/end times, elements that are rarely standardized or easy to extract automatically. Existing named entity recognition (NER) models are ill-suited to this task, as they are not adapted to such domain-specific categories. In this paper, we propose a two-stage pipeline for metadata extraction from municipal minutes. First, a question answering (QA) model identifies the opening and closing text segments containing metadata. Transformer-based models (BERTimbau and XLM-RoBERTa with and without a CRF layer) are then applied for fine-grained entity extraction and enhanced through deslexicalization. To evaluate our proposed pipeline, we benchmark both open-weight (Phi) and closed-weight (Gemini) LLMs, assessing predictive performance, inference cost, and carbon footprint. Our results demonstrate strong in-domain performance, better than larger general-purpose LLMs. However, cross-municipality evaluation reveals reduced generalization reflecting the variability and linguistic complexity of municipal records. This work establishes the first benchmark for metadata extraction from municipal meeting minutes, providing a solid foundation for future research in this domain.</li>
</ul>

<h3>Title: Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection</h3>
<ul>
<li><strong>Authors: </strong>Kunal Mukherjee, Zulfikar Alom, Tran Gia Bao Ngo, Cuneyt Gurcan Akcora, Murat Kantarcioglu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00318">https://arxiv.org/abs/2602.00318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00318">https://arxiv.org/pdf/2602.00318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00318]] Optimal Transport-Guided Adversarial Attacks on Graph Neural Network-Based Bot Detection(https://arxiv.org/abs/2602.00318)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rise of bot accounts on social media poses significant risks to public discourse. To address this threat, modern bot detectors increasingly rely on Graph Neural Networks (GNNs). However, the effectiveness of these GNN-based detectors in real-world settings remains poorly understood. In practice, attackers continuously adapt their strategies as well as must operate under domain-specific and temporal constraints, which can fundamentally limit the applicability of existing attack methods. As a result, there is a critical need for robust GNN-based bot detection methods under realistic, constraint-aware attack scenarios. To address this gap, we introduce BOCLOAK to systematically evaluate the robustness of GNN-based social bot detection via both edge editing and node injection adversarial attacks under realistic constraints. BOCLOAK constructs a probability measure over spatio-temporal neighbor features and learns an optimal transport geometry that separates human and bot behaviors. It then decodes transport plans into sparse, plausible edge edits that evade detection while obeying real-world constraints. We evaluate BOCLOAK across three social bot datasets, five state-of-the-art bot detectors, three adversarial defenses, and compare it against four leading graph adversarial attack baselines. BOCLOAK achieves up to 80.13% higher attack success rates while using 99.80% less GPU memory under realistic real-world constraints. Most importantly, BOCLOAK shows that optimal transport provides a lightweight, principled framework for bridging the gap between adversarial attacks and real-world bot detection.</li>
</ul>

<h3>Title: Detecting AI-Generated Content in Academic Peer Reviews</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Shen, Kai Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00319">https://arxiv.org/abs/2602.00319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00319">https://arxiv.org/pdf/2602.00319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00319]] Detecting AI-Generated Content in Academic Peer Reviews(https://arxiv.org/abs/2602.00319)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.</li>
</ul>

<h3>Title: Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Gopal, Kostis Kaffes</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00328">https://arxiv.org/abs/2602.00328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00328">https://arxiv.org/pdf/2602.00328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00328]] Harvest: Opportunistic Peer-to-Peer GPU Caching for LLM Inference(https://arxiv.org/abs/2602.00328)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) inference is increasingly constrained by GPU memory capacity rather than compute throughput, driven by growing model sizes and the linear growth of the key-value (KV) cache during autoregressive decoding. Existing approaches mitigate memory pressure by offloading model state and KV tensors to host memory, but incur substantial latency due to limited PCIe bandwidth. We present Harvest, an opportunistic GPU cache management framework that exploits high-bandwidth peer-to-peer GPU interconnects to dynamically place model weights and KV cache in unused GPU memory. Harvest treats peer GPU memory as a transient cache tier, preserving correctness while reducing data movement overhead under dynamic memory availability. We demonstrate significant throughput speedup of more than 2 times by using Harvest to accelerate the retrieval of two widely-used inference components: expert layer weights and KV cache entries.</li>
</ul>

<h3>Title: Efficient and accurate steering of Large Language Models through attention-guided feature learning</h3>
<ul>
<li><strong>Authors: </strong>Parmida Davarmanesh, Ashia Wilson, Adityanarayanan Radhakrishnan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00333">https://arxiv.org/abs/2602.00333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00333">https://arxiv.org/pdf/2602.00333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00333]] Efficient and accurate steering of Large Language Models through attention-guided feature learning(https://arxiv.org/abs/2602.00333)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Steering, or direct manipulation of internal activations to guide LLM responses toward specific semantic concepts, is emerging as a promising avenue for both understanding how semantic concepts are stored within LLMs and advancing LLM capabilities. Yet, existing steering methods are remarkably brittle, with seemingly non-steerable concepts becoming completely steerable based on subtle algorithmic choices in how concept-related features are extracted. In this work, we introduce an attention-guided steering framework that overcomes three core challenges associated with steering: (1) automatic selection of relevant token embeddings for extracting concept-related features; (2) accounting for heterogeneity of concept-related features across LLM activations; and (3) identification of layers most relevant for steering. Across a steering benchmark of 512 semantic concepts, our framework substantially improved steering over previous state-of-the-art (nearly doubling the number of successfully steered concepts) across model architectures and sizes (up to 70 billion parameter models). Furthermore, we use our framework to shed light on the distribution of concept-specific features across LLM layers. Overall, our framework opens further avenues for developing efficient, highly-scalable fine-tuning algorithms for industry-scale LLMs.</li>
</ul>

<h3>Title: Adaptive Momentum and Nonlinear Damping for Neural Network Training</h3>
<ul>
<li><strong>Authors: </strong>Aikaterini Karoni, Rajit Rajpal, Benedict Leimkuhler, Gabriel Stoltz</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00334">https://arxiv.org/abs/2602.00334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00334">https://arxiv.org/pdf/2602.00334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00334]] Adaptive Momentum and Nonlinear Damping for Neural Network Training(https://arxiv.org/abs/2602.00334)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose a continuous-time scheme for large-scale optimization that introduces individual, adaptive momentum coefficients regulated by the kinetic energy of each model parameter. This approach automatically adjusts to local landscape curvature to maintain stability without sacrificing convergence speed. We demonstrate that our adaptive friction can be related to cubic damping, a suppression mechanism from structural dynamics. Furthermore, we introduce two specific optimization schemes by augmenting the continuous dynamics of mSGD and Adam with a cubic damping term. Empirically, our methods demonstrate robustness and match or outperform Adam on training ViT, BERT, and GPT2 tasks where mSGD typically struggles. We further provide theoretical results establishing the exponential convergence of the proposed schemes.</li>
</ul>

<h3>Title: HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects</h3>
<ul>
<li><strong>Authors: </strong>Abdurrahman Elmaghbub, Bechir Hamdaoui</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00338">https://arxiv.org/abs/2602.00338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00338">https://arxiv.org/pdf/2602.00338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00338]] HEEDFUL: Leveraging Sequential Transfer Learning for Robust WiFi Device Fingerprinting Amid Hardware Warm-Up Effects(https://arxiv.org/abs/2602.00338)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep Learning-based RF fingerprinting approaches struggle to perform well in cross-domain scenarios, particularly during hardware warm-up. This often-overlooked vulnerability has been jeopardizing their reliability and their adoption in practical settings. To address this critical gap, in this work, we first dive deep into the anatomy of RF fingerprints, revealing insights into the temporal fingerprinting variations during and post hardware stabilization. Introducing HEEDFUL, a novel framework harnessing sequential transfer learning and targeted impairment estimation, we then address these challenges with remarkable consistency, eliminating blind spots even during challenging warm-up phases. Our evaluation showcases HEEDFUL's efficacy, achieving remarkable classification accuracies of up to 96% during the initial device operation intervals-far surpassing traditional models. Furthermore, cross-day and cross-protocol assessments confirm HEEDFUL's superiority, achieving and maintaining high accuracy during both the stable and initial warm-up phases when tested on WiFi signals. Additionally, we release WiFi type B and N RF fingerprint datasets that, for the first time, incorporate both the time-domain representation and real hardware impairments of the frames. This underscores the importance of leveraging hardware impairment data, enabling a deeper understanding of fingerprints and facilitating the development of more robust RF fingerprinting solutions.</li>
</ul>

<h3>Title: ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Ignacy Kolton, Kacper Marzol, Paweł Batorski, Marcin Mazur, Paul Swoboda, Przemysław Spurek</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00350">https://arxiv.org/abs/2602.00350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00350">https://arxiv.org/pdf/2602.00350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00350]] ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models(https://arxiv.org/abs/2602.00350)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, diffusion</a></li>
<li><strong>Abstract: </strong>Machine unlearning is a key defense mechanism for removing unauthorized concepts from text-to-image diffusion models, yet recent evidence shows that latent visual information often persists after unlearning. Existing adversarial approaches for exploiting this leakage are constrained by fundamental limitations: optimization-based methods are computationally expensive due to per-instance iterative search. At the same time, reasoning-based and heuristic techniques lack direct feedback from the target model's latent visual representations. To address these challenges, we introduce ReLAPSe, a policy-based adversarial framework that reformulates concept restoration as a reinforcement learning problem. ReLAPSe trains an agent using Reinforcement Learning with Verifiable Rewards (RLVR), leveraging the diffusion model's noise prediction loss as a model-intrinsic and verifiable feedback signal. This closed-loop design directly aligns textual prompt manipulation with latent visual residuals, enabling the agent to learn transferable restoration strategies rather than optimizing isolated prompts. By pioneering the shift from per-instance optimization to global policy learning, ReLAPSe achieves efficient, near-real-time recovery of fine-grained identities and styles across multiple state-of-the-art unlearning methods, providing a scalable tool for rigorous red-teaming of unlearned diffusion models. Some experimental evaluations involve sensitive visual concepts, such as nudity. Code is available at this https URL</li>
</ul>

<h3>Title: Planning with Language and Generative Models: Toward General Reward-Guided Wireless Network Design</h3>
<ul>
<li><strong>Authors: </strong>Chenyang Yuan, Xiaoyuan Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00357">https://arxiv.org/abs/2602.00357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00357">https://arxiv.org/pdf/2602.00357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00357]] Planning with Language and Generative Models: Toward General Reward-Guided Wireless Network Design(https://arxiv.org/abs/2602.00357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Intelligent access point (AP) deployment remains challenging in next-generation wireless networks due to complex indoor geometries and signal propagation. We firstly benchmark general-purpose large language models (LLMs) as agentic optimizers for AP planning and find that, despite strong wireless domain knowledge, their dependence on external verifiers results in high computational costs and limited scalability. Motivated by these limitations, we study generative inference models guided by a unified reward function capturing core AP deployment objectives across diverse floorplans. We show that diffusion samplers consistently outperform alternative generative approaches. The diffusion process progressively improves sampling by smoothing and sharpening the reward landscape, rather than relying on iterative refinement, which is effective for non-convex and fragmented objectives. Finally, we introduce a large-scale real-world dataset for indoor AP deployment, requiring over $50k$ CPU hours to train general reward functions, and evaluate in- and out-of-distribution generalization and robustness. Our results suggest that diffusion-based generative inference with a unified reward function provides a scalable and domain-agnostic foundation for indoor AP deployment planning.</li>
</ul>

<h3>Title: "Someone Hid It": Query-Agnostic Black-Box Attacks on LLM-Based Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Jiate Li, Defu Cao, Li Li, Wei Yang, Yuehan Qin, Chenxiao Yu, Tiannuo Yang, Ryan A. Rossi, Yan Liu, Xiyang Hu, Yue Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00364">https://arxiv.org/abs/2602.00364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00364">https://arxiv.org/pdf/2602.00364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00364]] "Someone Hid It": Query-Agnostic Black-Box Attacks on LLM-Based Retrieval(https://arxiv.org/abs/2602.00364)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been serving as effective backbones for retrieval systems, including Retrieval-Augmentation-Generation (RAG), Dense Information Retriever (IR), and Agent Memory Retrieval. Recent studies have demonstrated that such LLM-based Retrieval (LLMR) is vulnerable to adversarial attacks, which manipulates documents by token-level injections and enables adversaries to either boost or diminish these documents in retrieval tasks. However, existing attack studies mainly (1) presume a known query is given to the attacker, and (2) highly rely on access to the victim model's parameters or interactions, which are hardly accessible in real-world scenarios, leading to limited validity. To further explore the secure risks of LLMR, we propose a practical black-box attack method that generates transferable injection tokens based on zero-shot surrogate LLMs without need of victim queries or victim models knowledge. The effectiveness of our attack raises such a robustness issue that similar effects may arise from benign or unintended document edits in the real world. To achieve our attack, we first establish a theoretical framework of LLMR and empirically verify it. Under the framework, we simulate the transferable attack as a min-max problem, and propose an adversarial learning mechanism that finds optimal adversarial tokens with learnable query samples. Our attack is validated to be effective on benchmark datasets across popular LLM retrievers.</li>
</ul>

<h3>Title: Post-Training Probability Manifold Correction via Structured SVD Pruning and Self-Referential Distillation</h3>
<ul>
<li><strong>Authors: </strong>Aaron R. Flouro, Shawn P. Chadwick</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00372">https://arxiv.org/abs/2602.00372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00372">https://arxiv.org/pdf/2602.00372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00372]] Post-Training Probability Manifold Correction via Structured SVD Pruning and Self-Referential Distillation(https://arxiv.org/abs/2602.00372)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are expensive to deploy. We introduce Sparse Knowledge Distillation (SparseKD), a post-training method that compresses transformer models by combining structured SVD pruning with self-referential knowledge distillation. The key insight is simple: instead of using an external teacher, the model teaches itself by matching its own probability distribution from before compression. This self-referential setup enables surprisingly strong quality recovery after aggressive pruning. Our experiments reveal an unexpected finding: self-referential distillation alone, applied post-training under an identical objective and fixed calibration dataset, improves model quality by 39% relative to the original converged checkpoint. When combined with structured pruning, SparseKD achieves 15-65% parameter reduction with acceptable quality trade-offs. Kernel profiling shows that speedups arise entirely from reduced dense matrix multiplication in feed-forward layers while attention remains unchanged, making this approach complementary to attention optimizations. We validate across two model families (0.6B and 3.8B parameters) with multi-seed experiments confirming high reproducibility. SparseKD requires no external super-teacher, no architectural changes, and no custom inference kernels, making it immediately deployable with existing infrastructure.</li>
</ul>

<h3>Title: DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhaochen Hong, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00377">https://arxiv.org/abs/2602.00377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00377">https://arxiv.org/pdf/2602.00377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00377]] DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models(https://arxiv.org/abs/2602.00377)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Existing knowledge probing methods rely on pre-defined queries, limiting extraction to known concepts. We introduce DecompressionLM, a stateless framework for zero-shot concept graph extraction that discovers what language models encode without pre-specified queries or shared cross-sequence state. Our method targets three limitations of common decoding-based probing approaches: cross-sequence coupling that concentrates probability mass on high-frequency prefixes, competitive decoding effects that suppress long-tail concepts, and scalability constraints arising from sequential exploration. Using Van der Corput low-discrepancy sequences with arithmetic decoding, DecompressionLM enables deterministic, embarrassingly parallel generation without shared state across sequences. Across two model families and five quantization variants, we find that activation-aware quantization (AWQ-4bit) expands concept coverage by 30-170%, while uniform quantization (GPTQ-Int4) induces 71-86% coverage collapse -- divergent behaviors not reliably reflected by explanation-level perplexity. Corpus-based verification further reveals a 17-point hallucination gap between top- and bottom-ranked MMLU-Pro Law models. DecompressionLM establishes concept coverage as a complementary evaluation dimension for assessing knowledge breadth and factual grounding in compressed models useful for their deployment.</li>
</ul>

<h3>Title: Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sercan Karakaş</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00380">https://arxiv.org/abs/2602.00380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00380">https://arxiv.org/pdf/2602.00380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00380]] Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models(https://arxiv.org/abs/2602.00380)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study evaluates whether state-of-the-art large language models capture the binding relations of Turkish reflexive pronouns. We construct a balanced set of 100 sentences that pit local against non-local antecedents for the reflexives kendi and kendisi, and test two contrasting systems: an OpenAI chain-of-thought model designed for multi-step reasoning and Trendyol-LLM-7B-base-v0.1, a LLaMA-2-derived model extensively fine-tuned on Turkish data. Antecedent choice is assessed using a combined sentence-level perplexity and forced-choice paradigm. Trendyol-LLM favours local bindings in approximately 70% of trials, exhibiting a strong locality bias, whereas o1 Mini distributes its choices almost evenly between local and long-distance readings, revealing a marked contrast in binding behaviour across the two systems.</li>
</ul>

<h3>Title: RePaint-Enhanced Conditional Diffusion Model for Parametric Engineering Designs under Performance and Parameter Constraints</h3>
<ul>
<li><strong>Authors: </strong>Ke Wang, Nguyen Gia Hien Vu, Yifan Tang, Mostafa Rahmani Dehaghani, G. Gary Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00384">https://arxiv.org/abs/2602.00384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00384">https://arxiv.org/pdf/2602.00384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00384]] RePaint-Enhanced Conditional Diffusion Model for Parametric Engineering Designs under Performance and Parameter Constraints(https://arxiv.org/abs/2602.00384)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper presents a RePaint-enhanced framework that integrates a pre-trained performance-guided denoising diffusion probabilistic model (DDPM) for performance- and parameter-constraint engineering design generation. The proposed method enables the generation of missing design components based on a partial reference design while satisfying performance constraints, without retraining the underlying model. By applying mask-based resampling during inference process, RePaint allows efficient and controllable repainting of partial designs under both performance and parameter constraints, which is not supported by conventional DDPM-base methods. The framework is evaluated on two representative design problems, parametric ship hull design and airfoil design, demonstrating its ability to generate novel designs with expected performance based on a partial reference design. Results show that the method achieves accuracy comparable to or better than pre-trained models while enabling controlled novelty through fixing partial designs. Overall, the proposed approach provides an efficient, training-free solution for parameter-constraint-aware generative design in engineering applications.</li>
</ul>

<h3>Title: Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects</h3>
<ul>
<li><strong>Authors: </strong>Bsher Karbouj, Adam Michael Altenbuchner, Joerg Krueger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00385">https://arxiv.org/abs/2602.00385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00385">https://arxiv.org/pdf/2602.00385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00385]] Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects(https://arxiv.org/abs/2602.00385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Object detection is a crucial component in autonomous vehicle systems. It enables the vehicle to perceive and understand its environment by identifying and locating various objects around it. By utilizing advanced imaging and deep learning techniques, autonomous vehicle systems can rapidly and accurately identify objects based on their features. Different deep learning methods vary in their ability to accurately detect and classify objects in autonomous vehicle systems. Selecting the appropriate method significantly impacts system performance, robustness, and efficiency in real-world driving scenarios. While several generic deep learning architectures like YOLO, SSD, and Faster R-CNN have been proposed, guidance on their suitability for specific autonomous driving applications is often limited. The choice of method affects detection accuracy, processing speed, environmental robustness, sensor integration, scalability, and edge case handling. This study provides a comprehensive experimental analysis comparing two prominent object detection models: YOLOv5 (a one-stage detector) and Faster R-CNN (a two-stage detector). Their performance is evaluated on a diverse dataset combining real and synthetic images, considering various metrics including mean Average Precision (mAP), recall, and inference speed. The findings reveal that YOLOv5 demonstrates superior performance in terms of mAP, recall, and training efficiency, particularly as dataset size and image resolution increase. However, Faster R-CNN shows advantages in detecting small, distant objects and performs well in challenging lighting conditions. The models' behavior is also analyzed under different confidence thresholds and in various real-world scenarios, providing insights into their applicability for autonomous driving systems.</li>
</ul>

<h3>Title: A Fragile Guardrail: Diffusion LLM's Safety Blessing and Its Failure Mode</h3>
<ul>
<li><strong>Authors: </strong>Zeyuan He, Yupeng Chen, Lang Lin, Yihan Wang, Shenxu Chang, Eric Sommerlade, Philip Torr, Junchi Yu, Adel Bibi, Jialin Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00388">https://arxiv.org/abs/2602.00388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00388">https://arxiv.org/pdf/2602.00388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00388]] A Fragile Guardrail: Diffusion LLM's Safety Blessing and Its Failure Mode(https://arxiv.org/abs/2602.00388)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (D-LLMs) offer an alternative to autoregressive LLMs (AR-LLMs) and have demonstrated advantages in generation efficiency. Beyond the utility benefits, we argue that D-LLMs exhibit a previously underexplored safety blessing: their diffusion-style generation confers intrinsic robustness against jailbreak attacks originally designed for AR-LLMs. In this work, we provide an initial analysis of the underlying mechanism, showing that the diffusion trajectory induces a stepwise reduction effect that progressively suppresses unsafe generations. This robustness, however, is not absolute. We identify a simple yet effective failure mode, termed context nesting, where harmful requests are embedded within structured benign contexts, effectively bypassing the stepwise reduction mechanism. Empirically, we show that this simple strategy is sufficient to bypass D-LLMs' safety blessing, achieving state-of-the-art attack success rates across models and benchmarks. Most notably, it enables the first successful jailbreak of Gemini Diffusion, to our knowledge, exposing a critical vulnerability in commercial D-LLMs. Together, our results characterize both the origins and the limits of D-LLMs' safety blessing, constituting an early-stage red-teaming of D-LLMs.</li>
</ul>

<h3>Title: Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data</h3>
<ul>
<li><strong>Authors: </strong>Alberto Mario Ceballos-Arroyo, Shrikanth M. Yadav, Chu-Hsuan Lin, Jisoo Kim, Geoffrey S. Young, Huaizu Jiang, Lei Qin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00391">https://arxiv.org/abs/2602.00391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00391">https://arxiv.org/pdf/2602.00391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00391]] Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data(https://arxiv.org/abs/2602.00391)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>In this study, we develop a novel methodology for annotating the brain vasculature using dynamic 4D-CTA head scans. By using multiple time points from dynamic CTA acquisitions, we subtract bone and soft tissue to enhance the visualization of arteries and veins, reducing the effort required to obtain manual annotations of brain vessels. We then train deep learning models on our ground truth annotations by using the same segmentation for multiple phases from the dynamic 4D-CTA collection, effectively enlarging our dataset by 4 to 5 times and inducing robustness to contrast phases. In total, our dataset comprises 110 training images from 25 patients and 165 test images from 14 patients. In comparison with two similarly-sized datasets for CTA-based brain vessel segmentation, a nnUNet model trained on our dataset can achieve significantly better segmentations across all vascular regions, with an average mDC of 0.846 for arteries and 0.957 for veins in the TopBrain dataset. Furthermore, metrics such as average directed Hausdorff distance (adHD) and topology sensitivity (tSens) reflected similar trends: using our dataset resulted in low error margins (aDHD of 0.304 mm for arteries and 0.078 for veins) and high sensitivity (tSens of 0.877 for arteries and 0.974 for veins), indicating excellent accuracy in capturing vessel morphology. Our code and model weights are available online: this https URL</li>
</ul>

<h3>Title: Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Bromonschenkel, Alessandro L. Koerich, Thiago M. Paixão, Hilário Tomaz Alves de Oliveira</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00393">https://arxiv.org/abs/2602.00393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00393">https://arxiv.org/pdf/2602.00393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00393]] Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset(https://arxiv.org/abs/2602.00393)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Image captioning (IC) refers to the automatic generation of natural language descriptions for images, with applications ranging from social media content generation to assisting individuals with visual impairments. While most research has been focused on English-based models, low-resource languages such as Brazilian Portuguese face significant challenges due to the lack of specialized datasets and models. Several studies create datasets by automatically translating existing ones to mitigate resource scarcity. This work addresses this gap by proposing a cross-native-translated evaluation of Transformer-based vision and language models for Brazilian Portuguese IC. We use a version of Flickr30K comprised of captions manually created by native Brazilian Portuguese speakers and compare it to a version with captions automatically translated from English to Portuguese. The experiments include a cross-context approach, where models trained on one dataset are tested on the other to assess the translation impact. Additionally, we incorporate attention maps for model inference interpretation and use the CLIP-Score metric to evaluate the image-description alignment. Our findings show that Swin-DistilBERTimbau consistently outperforms other models, demonstrating strong generalization across datasets. ViTucano, a Brazilian Portuguese pre-trained VLM, surpasses larger multilingual models (GPT-4o, LLaMa 3.2 Vision) in traditional text-based evaluation metrics, while GPT-4 models achieve the highest CLIP-Score, highlighting improved image-text alignment. Attention analysis reveals systematic biases, including gender misclassification, object enumeration errors, and spatial inconsistencies. The datasets and the models generated and analyzed during the current study are available in: this https URL.</li>
</ul>

<h3>Title: Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Aayush Gautam, Mukul Gagrani, Junyoung Park, Mingu Lee, Chiris Lott, Narasimha Reddy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00397">https://arxiv.org/abs/2602.00397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00397">https://arxiv.org/pdf/2602.00397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00397]] Fast Forward: Accelerating LLM Prefill with Predictive FFN Sparsity(https://arxiv.org/abs/2602.00397)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The prefill stage of large language model (LLM) inference is a key computational bottleneck for long-context workloads. At short-to-moderate context lengths (1K--16K tokens), Feed-Forward Networks (FFNs) dominate this cost, accounting for most of the total FLOPs. Existing FFN sparsification methods, designed for autoregressive decoding, fail to exploit the prefill stage's parallelism and often degrade accuracy. To address this, we introduce FastForward, a predictive sparsity framework that accelerates LLM prefill through block-wise, context-aware FFN sparsity. FastForward combines (1) a lightweight expert predictor to select high-importance neurons per block, (2) an error compensation network to correct sparsity-induced errors, and (3) a layer-wise sparsity scheduler to allocate compute based on token-mixing importance. Across LLaMA and Qwen models up to 8B parameters, FastForward delivers up to 1.45$\times$ compute-bound speedup at 50% FFN sparsity with $<$ 6% accuracy loss compared to the dense baseline on LongBench, substantially reducing Time-to-First-Token (TTFT) for efficient, long-context LLM inference on constrained hardware.</li>
</ul>

<h3>Title: MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers</h3>
<ul>
<li><strong>Authors: </strong>Ajay Jaiswal, Lauren Hannah, Han-Byul Kim, Duc Hoang, Arnav Kundu, Mehrdad Farajtabar, Minsik Cho</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00398">https://arxiv.org/abs/2602.00398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00398">https://arxiv.org/pdf/2602.00398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00398]] MemoryLLM: Plug-n-Play Interpretable Feed-Forward Memory for Transformers(https://arxiv.org/abs/2602.00398)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Understanding how transformer components operate in LLMs is important, as it is at the core of recent technological advances in artificial intelligence. In this work, we revisit the challenges associated with interpretability of feed-forward modules (FFNs) and propose MemoryLLM, which aims to decouple FFNs from self-attention and enables us to study the decoupled FFNs as context-free token-wise neural retrieval memory. In detail, we investigate how input tokens access memory locations within FFN parameters and the importance of FFN memory across different downstream tasks. MemoryLLM achieves context-free FFNs by training them in isolation from self-attention directly using the token embeddings. This approach allows FFNs to be pre-computed as token-wise lookups (ToLs), enabling on-demand transfer between VRAM and storage, additionally enhancing inference efficiency. We also introduce Flex-MemoryLLM, positioning it between a conventional transformer design and MemoryLLM. This architecture bridges the performance gap caused by training FFNs with context-free token-wise embeddings.</li>
</ul>

<h3>Title: Fed-Listing: Federated Label Distribution Inference in Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Suprim Nakarmi, Junggab Son, Yue Zhao, Zuobin Xiong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00407">https://arxiv.org/abs/2602.00407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00407">https://arxiv.org/pdf/2602.00407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00407]] Fed-Listing: Federated Label Distribution Inference in Graph Neural Networks(https://arxiv.org/abs/2602.00407)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, steal, federate</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have been intensively studied for their expressive representation and learning performance on graph-structured data, enabling effective modeling of complex relational dependencies among nodes and edges in various domains. However, the standalone GNNs can unleash threat surfaces and privacy implications, as some sensitive graph-structured data is collected and processed in a centralized setting. To solve this issue, Federated Graph Neural Networks (FedGNNs) are proposed to facilitate collaborative learning over decentralized local graph data, aiming to preserve user privacy. Yet, emerging research indicates that even in these settings, shared model updates, particularly gradients, can unintentionally leak sensitive information of local users. Numerous privacy inference attacks have been explored in traditional federated learning and extended to graph settings, but the problem of label distribution inference in FedGNNs remains largely underexplored. In this work, we introduce Fed-Listing (Federated Label Distribution Inference in GNNs), a novel gradient-based attack designed to infer the private label statistics of target clients in FedGNNs without access to raw data or node features. Fed-Listing only leverages the final-layer gradients exchanged during training to uncover statistical patterns that reveal class proportions in a stealthy manner. An auxiliary shadow dataset is used to generate diverse label partitioning strategies, simulating various client distributions, on which the attack model is obtained. Extensive experiments on four benchmark datasets and three GNN architectures show that Fed-Listing significantly outperforms existing baselines, including random guessing and Decaf, even under challenging non-i.i.d. scenarios. Moreover, applying defense mechanisms can barely reduce our attack performance, unless the model's utility is severely degraded.</li>
</ul>

<h3>Title: Variational Approach for Job Shop Scheduling</h3>
<ul>
<li><strong>Authors: </strong>Seung Heon Oh, Jiwon Baek, Ki Young Cho, Hee Chang Yoon, Jong Hun Woo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00408">https://arxiv.org/abs/2602.00408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00408">https://arxiv.org/pdf/2602.00408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00408]] Variational Approach for Job Shop Scheduling(https://arxiv.org/abs/2602.00408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a novel Variational Graph-to-Scheduler (VG2S) framework for solving the Job Shop Scheduling Problem (JSSP), a critical task in manufacturing that directly impacts operational efficiency and resource utilization. Conventional Deep Reinforcement Learning (DRL) approaches often face challenges such as non-stationarity during training and limited generalization to unseen problem instances because they optimize representation learning and policy execution simultaneously. To address these issues, we introduce variational inference to the JSSP domain for the first time and derive a probabilistic objective based on the Evidence of Lower Bound (ELBO) with maximum entropy reinforcement learning. By mathematically decoupling representation learning from policy optimization, the VG2S framework enables the agent to learn robust structural representations of scheduling instances through a variational graph encoder. This approach significantly enhances training stability and robustness against hyperparameter variations. Extensive experiments demonstrate that the proposed method exhibits superior zero-shot generalization compared with state-of-the-art DRL baselines and traditional dispatching rules, particularly on large-scale and challenging benchmark instances such as DMU and SWV.</li>
</ul>

<h3>Title: SpyDir: Spy Device Localization Through Accurate Direction Finding</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Chen, Wenyi Morty Zhang, Wei Sun, Dinesh Bharadia, Roshan Ayyalasomayajula</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00411">https://arxiv.org/abs/2602.00411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00411">https://arxiv.org/pdf/2602.00411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00411]] SpyDir: Spy Device Localization Through Accurate Direction Finding(https://arxiv.org/abs/2602.00411)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Hidden spy cameras have become a great privacy threat recently, as these low-cost, low-power, and small form-factor IoT devices can quietly monitor human activities in the indoor environment without generating any side-channel information. As such, it is difficult to detect and even more challenging to localize them in the rich-scattering indoor environment. To this end, this paper presents the design, implementation, and evaluation of SpyDir, a system that can accurately localize the hidden spy IoT devices by harnessing the electromagnetic emanations automatically and unintentionally emitted from them. Our system design mainly consists of a portable switching antenna array to sniff the spectrum-spread emanations, an emanation enhancement algorithm through non-coherent averaging that can de-correlate the correlated noise effect due to the square-wave emanation structure, and a multipath-resolving algorithm that can exploit the relative channels using a novel optimization-based sparse AoA derivation. Our real-world experimental evaluation across different indoor environments demonstrates an average AoA error of 6.30 deg, whereas the baseline algorithm yields 21.06 deg, achieving over a 3.3 times improvement in accuracy, and a mean localization error of 19.86cm over baseline algorithms of 206.79cm (MUSIC) and 294.75cm (SpotFi), achieving over a 10.41 times and 14.8 times improvement in accuracy.</li>
</ul>

<h3>Title: Robustness of AutoML on Dirty Categorical Data</h3>
<ul>
<li><strong>Authors: </strong>Marcos L. P. Bueno, Joaquin Vanschoren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00412">https://arxiv.org/abs/2602.00412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00412">https://arxiv.org/pdf/2602.00412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00412]] Robustness of AutoML on Dirty Categorical Data(https://arxiv.org/abs/2602.00412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The goal of automated machine learning (AutoML) is to reduce trial and error when doing machine learning (ML). Although AutoML methods for classification are able to deal with data imperfections, such as outliers, multiple scales and missing data, their behavior is less known on dirty categorical datasets. These datasets often have several categorical features with high cardinality arising from issues such as lack of curation and automated collection. Recent research has shown that ML models can benefit from morphological encoders for dirty categorical data, leading to significantly superior predictive performance. However the effects of using such encoders in AutoML methods are not known at the moment. In this paper, we propose a pipeline that transforms categorical data into numerical data so that an AutoML can handle categorical data transformed by more advanced encoding schemes. We benchmark the current robustness of AutoML methods on a set of dirty datasets and compare it with the proposed pipeline. This allows us to get insight on differences in predictive performance. We also look at the ML pipelines built by AutoMLs in order to gain insight beyond the best model as typically returned by these methods.</li>
</ul>

<h3>Title: Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure</h3>
<ul>
<li><strong>Authors: </strong>Trishna Chakraborty, Udita Ghosh, Aldair Ernesto Gongora, Ruben Glatt, Yue Dong, Jiachen Li, Amit K. Roy-Chowdhury, Chengyu Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00414">https://arxiv.org/abs/2602.00414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00414">https://arxiv.org/pdf/2602.00414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00414]] Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure(https://arxiv.org/abs/2602.00414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Laboratories are prone to severe injuries from minor unsafe actions, yet continuous safety monitoring -- beyond mandatory pre-lab safety training -- is limited by human availability. Vision language models (VLMs) offer promise for autonomous laboratory safety monitoring, but their effectiveness in realistic settings is unclear due to the lack of visual evaluation data, as most safety incidents are documented primarily as unstructured text. To address this gap, we first introduce a structured data generation pipeline that converts textual laboratory scenarios into aligned triples of (image, scene graph, ground truth), using large language models as scene graph architects and image generation models as renderers. Our experiments on the synthetic dataset of 1,207 samples across 362 unique scenarios and seven open- and closed-source models show that VLMs perform effectively given textual scene graph, but degrade substantially in visual-only settings indicating difficulty in extracting structured object relationships directly from pixels. To overcome this, we propose a post-training context-engineering approach, scene-graph-guided alignment, to bridge perceptual gaps in VLMs by translating visual inputs into structured scene graphs better aligned with VLM reasoning, improving hazard detection performance in visual only settings.</li>
</ul>

<h3>Title: Text is All You Need for Vision-Language Model Jailbreaking</h3>
<ul>
<li><strong>Authors: </strong>Yihang Chen, Zhao Xu, Youyuan Jiang, Tianle Zheng, Cho-Jui Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00420">https://arxiv.org/abs/2602.00420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00420">https://arxiv.org/pdf/2602.00420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00420]] Text is All You Need for Vision-Language Model Jailbreaking(https://arxiv.org/abs/2602.00420)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) are increasingly equipped with robust safety safeguards to prevent responses to harmful or disallowed prompts. However, these defenses often focus on analyzing explicit textual inputs or relevant visual scenes. In this work, we introduce Text-DJ, a novel jailbreak attack that bypasses these safeguards by exploiting the model's Optical Character Recognition (OCR) capability. Our methodology consists of three stages. First, we decompose a single harmful query into multiple and semantically related but more benign sub-queries. Second, we pick a set of distraction queries that are maximally irrelevant to the harmful query. Third, we present all decomposed sub-queries and distraction queries to the LVLM simultaneously as a grid of images, with the position of the sub-queries being middle within the grid. We demonstrate that this method successfully circumvents the safety alignment of state-of-the-art LVLMs. We argue this attack succeeds by (1) converting text-based prompts into images, bypassing standard text-based filters, and (2) inducing distractions, where the model's safety protocols fail to link the scattered sub-queries within a high number of irrelevant queries. Overall, our findings expose a critical vulnerability in LVLMs' OCR capabilities that are not robust to dispersed, multi-image adversarial inputs, highlighting the need for defenses for fragmented multimodal inputs.</li>
</ul>

<h3>Title: Federated-inspired Single-cell Batch Integration in Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Quang-Huy Nguyen, Zongliang Yue, Hao Chen, Wei-Shinn Ku, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00423">https://arxiv.org/abs/2602.00423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00423">https://arxiv.org/pdf/2602.00423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00423]] Federated-inspired Single-cell Batch Integration in Latent Space(https://arxiv.org/abs/2602.00423)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Advances in single-cell RNA sequencing enable the rapid generation of massive, high-dimensional datasets, yet the accumulation of data across experiments introduces batch effects that obscure true biological signals. Existing batch correction approaches either insufficiently correct batch effects or require centralized retraining on the complete dataset, limiting their applicability in distributed and continually evolving single-cell data settings. We introduce scBatchProx, a post-hoc optimization method inspired by federated learning principles for refining cell-level embeddings produced by arbitrary upstream methods. Treating each batch as a client, scBatchProx learns batch-conditioned adapters under proximal regularization, correcting batch structure directly in latent space without requiring raw expression data or centralized optimization. The method is lightweight and deployable, optimizing batch-specific adapter parameters only. Extensive experiments show that scBatchProx consistently yields relative gains of approximately 3-8% in overall embedding quality, with batch correction and biological conservation improving in 90% and 85% of data-method pairs, respectively. We envision this work as a step toward the practical refinement of learned representations in dynamic single-cell data systems.</li>
</ul>

<h3>Title: Open Materials Generation with Inference-Time Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Philipp Hoellmer, Stefano Martiniani</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00424">https://arxiv.org/abs/2602.00424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00424">https://arxiv.org/pdf/2602.00424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00424]] Open Materials Generation with Inference-Time Reinforcement Learning(https://arxiv.org/abs/2602.00424)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Continuous-time generative models for crystalline materials enable inverse materials design by learning to predict stable crystal structures, but incorporating explicit target properties into the generative process remains challenging. Policy-gradient reinforcement learning (RL) provides a principled mechanism for aligning generative models with downstream objectives but typically requires access to the score, which has prevented its application to flow-based models that learn only velocity fields. We introduce Open Materials Generation with Inference-time Reinforcement Learning (OMatG-IRL), a policy-gradient RL framework that operates directly on the learned velocity fields and eliminates the need for the explicit computation of the score. OMatG-IRL leverages stochastic perturbations of the underlying generation dynamics preserving the baseline performance of the pretrained generative model while enabling exploration and policy-gradient estimation at inference time. Using OMatG-IRL, we present the first application of RL to crystal structure prediction (CSP). Our method enables effective reinforcement of an energy-based objective while preserving diversity through composition conditioning, and it achieves performance competitive with score-based RL approaches. Finally, we show that OMatG-IRL can learn time-dependent velocity-annealing schedules, enabling accurate CSP with order-of-magnitude improvements in sampling efficiency and, correspondingly, reduction in generation time.</li>
</ul>

<h3>Title: LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference</h3>
<ul>
<li><strong>Authors: </strong>Vikram Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00426">https://arxiv.org/abs/2602.00426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00426">https://arxiv.org/pdf/2602.00426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00426]] LLMs as High-Dimensional Nonlinear Autoregressive Models with Attention: Training, Alignment and Inference(https://arxiv.org/abs/2602.00426)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) based on transformer architectures are typically described through collections of architectural components and training procedures, obscuring their underlying computational structure. This review article provides a concise mathematical reference for researchers seeking an explicit, equation-level description of LLM training, alignment, and generation. We formulate LLMs as high-dimensional nonlinear autoregressive models with attention-based dependencies. The framework encompasses pretraining via next-token prediction, alignment methods such as reinforcement learning from human feedback (RLHF), direct preference optimization (DPO), rejection sampling fine-tuning (RSFT), and reinforcement learning from verifiable rewards (RLVR), as well as autoregressive generation during inference. Self-attention emerges naturally as a repeated bilinear--softmax--linear composition, yielding highly expressive sequence models. This formulation enables principled analysis of alignment-induced behaviors (including sycophancy), inference-time phenomena (such as hallucination, in-context learning, chain-of-thought prompting, and retrieval-augmented generation), and extensions like continual learning, while serving as a concise reference for interpretation and further theoretical development.</li>
</ul>

<h3>Title: When Agents "Misremember" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems</h3>
<ul>
<li><strong>Authors: </strong>Naen Xu, Hengyu An, Shuo Shi, Jinghuai Zhang, Chunyi Zhou, Changjiang Li, Tianyu Du, Zhihui Fu, Jun Wang, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00428">https://arxiv.org/abs/2602.00428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00428">https://arxiv.org/pdf/2602.00428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00428]] When Agents "Misremember" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems(https://arxiv.org/abs/2602.00428)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.</li>
</ul>

<h3>Title: Towards a Cognitive-Support Tool for Threat Hunters</h3>
<ul>
<li><strong>Authors: </strong>Alessandra Maciel Paz Milani, Norman Anderson, Margaret-Anne Storey</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00432">https://arxiv.org/abs/2602.00432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00432">https://arxiv.org/pdf/2602.00432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00432]] Towards a Cognitive-Support Tool for Threat Hunters(https://arxiv.org/abs/2602.00432)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Cybersecurity increasingly relies on threat hunters to proactively identify adversarial activity, yet the cognitive work underlying threat hunting remains underexplored or insufficiently supported by existing tools. Building on prior studies that examined how threat hunters construct and share mental models during investigations, we derived a set of design propositions to support their cognitive and collaborative work. In this paper, we present the Threat Hunter Board, a prototype tool that operationalizes these design propositions by enabling threat hunters to externalize reasoning, organize investigative leads, and maintain continuity across sessions. Using a design science paradigm, we describe the solution design rationale and artifact development. In addition, we propose six design heuristics that form a solution-evaluation framework for assessing cognitive support in threat hunting tools. An initial evaluation using a cognitive walkthrough provides early evidence of feasibility, while future work will focus on user-based validation with professional threat hunters.</li>
</ul>

<h3>Title: DISK: Dynamic Inference SKipping for World Models</h3>
<ul>
<li><strong>Authors: </strong>Anugunj Naman, Gaibo Zhang, Ayushman Singh, Yaguang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00440">https://arxiv.org/abs/2602.00440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00440">https://arxiv.org/pdf/2602.00440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00440]] DISK: Dynamic Inference SKipping for World Models(https://arxiv.org/abs/2602.00440)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We present DISK, a training-free adaptive inference method for autoregressive world models. DISK coordinates two coupled diffusion transformers for video and ego-trajectory via dual-branch controllers with cross-modal skip decisions, preserving motion-appearance consistency without retraining. We extend higher-order latent-difference skip testing to the autoregressive chain-of-forward regime and propagate controller statistics through rollout loops for long-horizon stability. When integrated into closed-loop driving rollouts on 1500 NuPlan and NuScenes samples using an NVIDIA L40S GPU, DISK achieves 2x speedup on trajectory diffusion and 1.6x speedup on video diffusion while maintaining L2 planning error, visual quality (FID/FVD), and NAVSIM PDMS scores, demonstrating practical long-horizon video-and-trajectory prediction at substantially reduced cost.</li>
</ul>

<h3>Title: Towards Building Non-Fine-Tunable Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Ziyao Wang, Nizhang Li, Pingzhi Li, Guoheng Sun, Tianlong Chen, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00446">https://arxiv.org/abs/2602.00446</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00446">https://arxiv.org/pdf/2602.00446</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00446]] Towards Building Non-Fine-Tunable Foundation Models(https://arxiv.org/abs/2602.00446)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-sourcing foundation models (FMs) enables broad reuse but also exposes model trainers to economic and safety risks from unrestricted downstream fine-tuning. We address this problem by building non-fine-tunable foundation models: models that remain broadly usable in their released form while yielding limited adaptation gains under task-agnostic unauthorized fine-tuning. We propose Private Mask Pre-Training (PMP), a pre-training framework that concentrates representation learning into a sparse subnetwork identified early in training. The binary mask defining this subnetwork is kept private, and only the final dense weights are released. This forces unauthorized fine-tuning without access to the mask to update parameters misaligned with pretraining subspace, inducing an intrinsic mismatch between the fine-tuning objective and the pre-training geometry. We provide theoretical analysis showing that this mismatch destabilizes gradient-based adaptation and bounds fine-tuning gains. Empirical results on large language models demonstrating that PMP preserves base model performance while consistently degrading unauthorized fine-tuning across a wide range of downstream tasks, with the strength of non-fine-tunability controlled by the mask ratio.</li>
</ul>

<h3>Title: Model Optimization for Multi-Camera 3D Detection and Tracking</h3>
<ul>
<li><strong>Authors: </strong>Ethan Anderson (1), Justin Silva (1), Kyle Zheng (1), Sameer Pusegaonkar (2), Yizhou Wang (2), Zheng Tang (2), Sujit Biswas (2) ((1) Clemson University, (2) NVIDIA)</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00450">https://arxiv.org/abs/2602.00450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00450">https://arxiv.org/pdf/2602.00450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00450]] Model Optimization for Multi-Camera 3D Detection and Tracking(https://arxiv.org/abs/2602.00450)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Outside-in multi-camera perception is increasingly important in indoor environments, where networks of static cameras must support multi-target tracking under occlusion and heterogeneous viewpoints. We evaluate Sparse4D, a query-based spatiotemporal 3D detection and tracking framework that fuses multi-view features in a shared world frame and propagates sparse object queries via instance memory. We study reduced input frame rates, post-training quantization (INT8 and FP8), transfer to the WILDTRACK benchmark, and Transformer Engine mixed-precision fine-tuning. To better capture identity stability, we report Average Track Duration (AvgTrackDur), which measures identity persistence in seconds. Sparse4D remains stable under moderate FPS reductions, but below 2 FPS, identity association collapses even when detections are stable. Selective quantization of the backbone and neck offers the best speed-accuracy trade-off, while attention-related modules are consistently sensitive to low precision. On WILDTRACK, low-FPS pretraining yields large zero-shot gains over the base checkpoint, while small-scale fine-tuning provides limited additional benefit. Transformer Engine mixed precision reduces latency and improves camera scalability, but can destabilize identity propagation, motivating stability-aware validation.</li>
</ul>

<h3>Title: Stabilizing Decentralized Federated Fine-Tuning via Topology-Aware Alternating LoRA</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Wang, Xiaotian Li, Zhixiang Zhou, Chen Li, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00451">https://arxiv.org/abs/2602.00451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00451">https://arxiv.org/pdf/2602.00451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00451]] Stabilizing Decentralized Federated Fine-Tuning via Topology-Aware Alternating LoRA(https://arxiv.org/abs/2602.00451)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Decentralized federated learning (DFL), a serverless variant of federated learning, poses unique challenges for parameter-efficient fine-tuning due to the factorized structure of low-rank adaptation (LoRA). Unlike linear parameters, decentralized aggregation of LoRA updates introduces topology-dependent cross terms that can destabilize training under dynamic communication graphs. We propose \texttt{TAD-LoRA}, a Topology-Aware Decentralized Low-Rank Adaptation framework that coordinates the updates and mixing of LoRA factors to control inter-client misalignment. We theoretically prove the convergence of \texttt{TAD-LoRA} under non-convex objectives, explicitly characterizing the trade-off between topology-induced cross-term error and block-coordinate representation bias governed by the switching interval of alternative training. Experiments under various communication conditions validate our analysis, showing that \texttt{TAD-LoRA} achieves robust performance across different communication scenarios, remaining competitive in strongly connected topologies and delivering clear gains under moderately and weakly connected topologies, with particularly strong results on the MNLI dataset.</li>
</ul>

<h3>Title: FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards</h3>
<ul>
<li><strong>Authors: </strong>Ziyao Wang, Daeun Jung, Yexiao He, Guoheng Sun, Zheyu Shen, Myungjin Lee, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00453">https://arxiv.org/abs/2602.00453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00453">https://arxiv.org/pdf/2602.00453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00453]] FedMOA: Federated GRPO for Personalized Reasoning LLMs under Heterogeneous Rewards(https://arxiv.org/abs/2602.00453)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>Group Relative Policy Optimization (GRPO) has recently emerged as an effective approach for improving the reasoning capabilities of large language models through online multi-objective reinforcement learning. While personalization on private data is increasingly vital, traditional Reinforcement Learning (RL) alignment is often memory-prohibitive for on-device federated learning due to the overhead of maintaining a separate critic network. GRPO's critic-free architecture enables feasible on-device training, yet transitioning to a federated setting introduces systemic challenges: heterogeneous reward definitions, imbalanced multi-objective optimization, and high training costs. We propose FedMOA, a federated GRPO framework for multi-objective alignment under heterogeneous rewards. FedMOA stabilizes local training through an online adaptive weighting mechanism via hypergradient descent, which prioritizes primary reasoning as auxiliary objectives saturate. On the server side, it utilizes a task- and accuracy-aware aggregation strategy to prioritize high-quality updates. Experiments on mathematical reasoning and code generation benchmarks demonstrate that FedMOA consistently outperforms federated averaging, achieving accuracy gains of up to 2.2% while improving global performance, personalization, and multi-objective balance.</li>
</ul>

<h3>Title: What Matters to an LLM? Behavioral and Computational Evidences from Summarization</h3>
<ul>
<li><strong>Authors: </strong>Yongxin Zhou, Changshun Wu, Philippe Mulhem, Didier Schwab, Maxime Peyrard</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00459">https://arxiv.org/abs/2602.00459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00459">https://arxiv.org/pdf/2602.00459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00459]] What Matters to an LLM? Behavioral and Computational Evidences from Summarization(https://arxiv.org/abs/2602.00459)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are now state-of-the-art at summarization, yet the internal notion of importance that drives their information selections remains hidden. We propose to investigate this by combining behavioral and computational analyses. Behaviorally, we generate a series of length-controlled summaries for each document and derive empirical importance distributions based on how often each information unit is selected. These reveal that LLMs converge on consistent importance patterns, sharply different from pre-LLM baselines, and that LLMs cluster more by family than by size. Computationally, we identify that certain attention heads align well with empirical importance distributions, and that middle-to-late layers are strongly predictive of importance. Together, these results provide initial insights into what LLMs prioritize in summarization and how this priority is internally represented, opening a path toward interpreting and ultimately controlling information selection in these models.</li>
</ul>

<h3>Title: LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Benno Krojer, Shravan Nayak, Oscar Mañas, Vaibhav Adlakha, Desmond Elliott, Siva Reddy, Marius Mosbach</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00462">https://arxiv.org/abs/2602.00462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00462">https://arxiv.org/pdf/2602.00462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00462]] LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs(https://arxiv.org/abs/2602.00462)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.</li>
</ul>

<h3>Title: PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhang, Shen Chen, Jiale Zhou, Lei Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00463">https://arxiv.org/abs/2602.00463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00463">https://arxiv.org/pdf/2602.00463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00463]] PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting(https://arxiv.org/abs/2602.00463)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning layer parses text into structured spatial relationships, while a self-optimization layer refines visual details via iterative MLLM feedback. Second, our panorama sliding mechanism initializes globally consistent 3D Gaussian Splatting point clouds by strategically sampling overlapping perspectives. By incorporating depth and semantic coherence losses during training, we greatly improve the quality and detail fidelity of rendered scenes. Our experiments demonstrate that PSGS outperforms existing methods in panorama generation and produces more appealing 3D scenes, offering a robust solution for scalable immersive content creation.</li>
</ul>

<h3>Title: PAIR-Former: Budgeted Relational MIL for miRNA Target Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Yin, Baiming Chen, Jia Fei, Mingjun Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00465">https://arxiv.org/abs/2602.00465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00465">https://arxiv.org/pdf/2602.00465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00465]] PAIR-Former: Budgeted Relational MIL for miRNA Target Prediction(https://arxiv.org/abs/2602.00465)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Functional miRNA--mRNA targeting is a large-bag prediction problem: each transcript yields a heavy-tailed pool of candidate target sites (CTSs), yet only a pair-level label is observed. We formalize this regime as \emph{Budgeted Relational Multi-Instance Learning (BR-MIL)}, where at most $K$ instances per bag may receive expensive encoding and relational processing under a hard compute budget. We propose \textbf{PAIR-Former} (Pool-Aware Instance-Relational Transformer), a BR-MIL pipeline that performs a cheap full-pool scan, selects up to $K$ diverse CTSs on CPU, and applies a permutation-invariant Set Transformer aggregator on the selected tokens. On miRAW, PAIR-Former outperforms strong pooling baselines at a practical operating budget ($K^\star{=}64$) while providing a controllable accuracy--compute trade-off as $K$ varies. We further provide theory linking budgeted selection to (i) approximation error decreasing with $K$ and (ii) generalization terms governed by $K$ in the expensive relational component.</li>
</ul>

<h3>Title: ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Chen, Fangzheng Lyu, Sicheng Wang, Cuizhen Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00470">https://arxiv.org/abs/2602.00470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00470">https://arxiv.org/pdf/2602.00470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00470]] ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation(https://arxiv.org/abs/2602.00470)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Individual tree crown segmentation is an important task in remote sensing for forest biomass estimation and ecological monitoring. However, accurate delineation in dense, overlapping canopies remains a bottleneck. While supervised deep learning methods suffer from high annotation costs and limited generalization, emerging foundation models (e.g., Segment Anything Model) often lack domain knowledge, leading to under-segmentation in dense clusters. To bridge this gap, we propose ZS-TreeSeg, a Zero-Shot framework that adapts from two mature tasks: 1) Canopy Semantic segmentation; and 2) Cells instance segmentation. By modeling tree crowns as star-convex objects within a topological flow field using Cellpose-SAM, the ZS-TreeSeg framework forces the mathematical separation of touching tree crown instances based on vector convergence. Experiments on the NEON and BAMFOREST datasets and visual inspection demonstrate that our framework generalizes robustly across diverse sensor types and canopy densities, which can offer a training-free solution for tree crown instance segmentation and labels generation.</li>
</ul>

<h3>Title: Parallel Stochastic Gradient-Based Planning for World Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Psenka, Michael Rabbat, Aditi Krishnapriyan, Yann LeCun, Amir Bar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00475">https://arxiv.org/abs/2602.00475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00475">https://arxiv.org/pdf/2602.00475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00475]] Parallel Stochastic Gradient-Based Planning for World Models(https://arxiv.org/abs/2602.00475)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>World models simulate environment dynamics from raw sensory inputs like video. However, using them for planning can be challenging due to the vast and unstructured search space. We propose a robust and highly parallelizable planner that leverages the differentiability of the learned world model for efficient optimization, solving long-horizon control tasks from visual input. Our method treats states as optimization variables ("virtual states") with soft dynamics constraints, enabling parallel computation and easier optimization. To facilitate exploration and avoid local optima, we introduce stochasticity into the states. To mitigate sensitive gradients through high-dimensional vision-based world models, we modify the gradient structure to descend towards valid plans while only requiring action-input gradients. Our planner, which we call GRASP (Gradient RelAxed Stochastic Planner), can be viewed as a stochastic version of a non-condensed or collocation-based optimal controller. We provide theoretical justification and experiments on video-based world models, where our resulting planner outperforms existing planning algorithms like the cross-entropy method (CEM) and vanilla gradient-based optimization (GD) on long-horizon experiments, both in success rate and time to convergence.</li>
</ul>

<h3>Title: Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly</h3>
<ul>
<li><strong>Authors: </strong>Hengchang Liu, Zhao Yang, Bing Su</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00476">https://arxiv.org/abs/2602.00476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00476">https://arxiv.org/pdf/2602.00476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00476]] Diffusion LMs Can Approximate Optimal Infilling Lengths Implicitly(https://arxiv.org/abs/2602.00476)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models (DLMs) provide a bidirectional generation framework naturally suited for infilling, yet their performance is constrained by the pre-specified infilling length. In this paper, we reveal that DLMs possess an inherent ability to discover the correct infilling length. We identify two key statistical phenomena in the first-step denoising confidence: a local \textit{Oracle Peak} that emerges near the ground-truth length and a systematic \textit{Length Bias} that often obscures this signal. By leveraging this signal and calibrating the bias, our training-free method \textbf{CAL} (\textbf{C}alibrated \textbf{A}daptive \textbf{L}ength) enables DLMs to approximate the optimal length through an efficient search before formal decoding. Empirical evaluations demonstrate that CAL improves Pass@1 by up to 47.7\% over fixed-length baselines and 40.5\% over chat-based adaptive methods in code infilling, while boosting BLEU-2 and ROUGE-L by up to 8.5\% and 9.9\% in text infilling. These results demonstrate that CAL paves the way for robust DLM infilling without requiring any specialized training. Code is available at this https URL.</li>
</ul>

<h3>Title: Intention-Adaptive LLM Fine-Tuning for Text Revision Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhexiong Liu, Diane Litman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00477">https://arxiv.org/abs/2602.00477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00477">https://arxiv.org/pdf/2602.00477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00477]] Intention-Adaptive LLM Fine-Tuning for Text Revision Generation(https://arxiv.org/abs/2602.00477)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved impressive capabilities in various context-based text generation tasks, such as summarization and reasoning; however, their applications in intention-based generation tasks remain underexplored. One such example is revision generation, which requires the generated text to explicitly reflect the writer's actual intentions. Identifying intentions and generating desirable revisions are challenging due to their complex and diverse nature. Although prior work has employed LLMs to generate revisions with few-shot learning, they struggle with handling entangled multi-intent scenarios. While fine-tuning LLMs using intention-based instructions appears promising, it demands large amounts of annotated data, which is expensive and scarce in the revision community. To address these challenges, we propose Intention-Tuning, an intention-adaptive layer-wise LLM fine-tuning framework that dynamically selects a subset of LLM layers to learn the intentions and subsequently transfers their representations to revision generation. Experimental results suggest that Intention-Tuning is effective and efficient on small revision corpora, outperforming several PEFT baselines.</li>
</ul>

<h3>Title: AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Zhang, Yuchen Yang, Ran Yan, Zhiyu Mei, Liyuan Zhang, Daifeng Li, Wei Fu, Jiaxuan Gao, Shusheng Xu, Yi Wu, Binhang Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00482">https://arxiv.org/abs/2602.00482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00482">https://arxiv.org/pdf/2602.00482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00482]] AREAL-DTA: Dynamic Tree Attention for Efficient Reinforcement Learning of Large Language Models(https://arxiv.org/abs/2602.00482)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) based post-training for large language models (LLMs) is computationally expensive, as it generates many rollout sequences that could frequently share long token prefixes. Existing RL frameworks usually process these sequences independently, repeatedly recomputing identical prefixes during forward and backward passes during policy model training, leading to substantial inefficiencies in computation and memory usage. Although prefix sharing naturally induces a tree structure over rollouts, prior tree-attention-based solutions rely on fully materialized attention masks and scale poorly in RL settings. In this paper, we introduce AREAL-DTA to efficiently exploit prefix sharing in RL training. AREAL-DTA employs a depth-first-search (DFS)-based execution strategy that dynamically traverses the rollout prefix tree during both forward and backward computation, materializing only a single root-to-leaf path at a time. To further improve scalability, AREAL-DTA incorporates a load-balanced distributed batching mechanism that dynamically constructs and processes prefix trees across multiple GPUs. Across the popular RL post-training workload, AREAL-DTA achieves up to $8.31\times$ in $\tau^2$-bench higher training throughput.</li>
</ul>

<h3>Title: GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association</h3>
<ul>
<li><strong>Authors: </strong>Rong-Lin Jian, Ming-Chi Luo, Chen-Wei Huang, Chia-Ming Lee, Yu-Fan Lin, Chih-Chung Hsu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00484">https://arxiv.org/abs/2602.00484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00484">https://arxiv.org/pdf/2602.00484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00484]] GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association(https://arxiv.org/abs/2602.00484)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-object tracking (MOT) in sports is highly challenging due to irregular player motion, uniform appearances, and frequent occlusions. These difficulties are further exacerbated by the geometric distortion and extreme scale variation introduced by static fisheye cameras. In this work, we present GTATrack, a hierarchical tracking framework that win first place in the SoccerTrack Challenge 2025. GTATrack integrates two core components: Deep Expansion IoU (Deep-EIoU) for motion-agnostic online association and Global Tracklet Association (GTA) for trajectory-level refinement. This two-stage design enables both robust short-term matching and long-term identity consistency. Additionally, a pseudo-labeling strategy is used to boost detector recall on small and distorted targets. The synergy between local association and global reasoning effectively addresses identity switches, occlusions, and tracking fragmentation. Our method achieved a winning HOTA score of 0.60 and significantly reduced false positives to 982, demonstrating state-of-the-art accuracy in fisheye-based soccer tracking. Our code is available at this https URL.</li>
</ul>

<h3>Title: OD-DEAL: Dynamic Expert-Guided Adversarial Learning with Online Decomposition for Scalable Capacitated Vehicle Routing</h3>
<ul>
<li><strong>Authors: </strong>Dongbin Jiao, Zisheng Chen, Xianyi Wang, Jintao Shi, Shengcai Liu, Shi Yan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00488">https://arxiv.org/abs/2602.00488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00488">https://arxiv.org/pdf/2602.00488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00488]] OD-DEAL: Dynamic Expert-Guided Adversarial Learning with Online Decomposition for Scalable Capacitated Vehicle Routing(https://arxiv.org/abs/2602.00488)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Solving large-scale capacitated vehicle routing problems (CVRP) is hindered by the high complexity of heuristics and the limited generalization of neural solvers on massive graphs. We propose OD-DEAL, an adversarial learning framework that tightly integrates hybrid genetic search (HGS) and online barycenter clustering (BCC) decomposition, and leverages high-fidelity knowledge distillation to transfer expert heuristic behavior. OD-DEAL trains a graph attention network (GAT)-based generative policy through a minimax game, in which divide-and-conquer strategies from a hybrid expert are distilled into dense surrogate rewards. This enables high-quality, clustering-free inference on large-scale instances. Empirical results demonstrate that OD-DEAL achieves state-of-the-art (SOTA) real-time CVRP performance, solving 10000-node instances with near-constant neural scaling. This uniquely enables the sub-second, heuristic-quality inference required for dynamic large-scale deployment.</li>
</ul>

<h3>Title: HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion</h3>
<ul>
<li><strong>Authors: </strong>Chia-Ming Lee, Yu-Hao Ho, Yu-Fan Lin, Jen-Wei Lee, Li-Wei Kang, Chih-Chung Hsu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00490">https://arxiv.org/abs/2602.00490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00490">https://arxiv.org/pdf/2602.00490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00490]] HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion(https://arxiv.org/abs/2602.00490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Hyperspectral image (HSI) fusion aims to reconstruct a high-resolution HSI (HR-HSI) by combining the rich spectral information of a low-resolution HSI (LR-HSI) with the fine spatial details of a high-resolution multispectral image (HR-MSI). Although recent deep learning methods have achieved notable progress, they still suffer from limited receptive fields, redundant spectral bands, and the quadratic complexity of self-attention, which restrict both efficiency and robustness. To overcome these challenges, we propose the Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT). The framework introduces two key modules: (i) a Hierarchical Dense-Residue Transformer Block (HDRTB) that progressively enlarges windows and employs dense-residue connections for multi-scale feature aggregation, and (ii) a Spatial-Spectral Correlation Layer (SSCL) that explicitly factorizes spatial and spectral dependencies, reducing self-attention to linear complexity while mitigating spectral redundancy. Extensive experiments on benchmark datasets demonstrate that HSSDCT delivers superior reconstruction quality with significantly lower computational costs, achieving new state-of-the-art performance in HSI fusion. Our code is available at this https URL.</li>
</ul>

<h3>Title: From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas</h3>
<ul>
<li><strong>Authors: </strong>Zhaokun Yan, Zhaohan Liu, Wuzheng Dong, Lijie Feng, Chengxiao Dai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00491">https://arxiv.org/abs/2602.00491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00491">https://arxiv.org/pdf/2602.00491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00491]] From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas(https://arxiv.org/abs/2602.00491)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Public health reasoning requires population level inference grounded in scientific evidence, expert consensus, and safety constraints. However, it remains underexplored as a structured machine learning problem with limited supervised signals and benchmarks. We introduce \textbf{GlobalHealthAtlas}, a large scale multilingual dataset of 280,210 instances spanning 15 public health domains and 17 languages, stratified into three difficulty levels from health literacy to epidemiological and policy reasoning. Instances are derived from openly available public health sources and labeled by language, domain, and difficulty to support supervised learning and slice based evaluation. We further propose large language model (LLM) assisted construction and quality control pipeline with retrieval, duplication, evidence grounding checks, and label validation to improve consistency at scale. Finally, we present a domain aligned evaluator distilled from high confidence judgments of diverse LLMs to assess outputs along six dimensions: Accuracy, Reasoning, Completeness, Consensus Alignment, Terminology Norms, and Insightfulness. Together, these contributions enable reproducible training and evaluation of LLMs for safety critical public health reasoning beyond conventional QA benchmarks.</li>
</ul>

<h3>Title: Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design</h3>
<ul>
<li><strong>Authors: </strong>Hanjing Shi, Dominic DiFranzo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00497">https://arxiv.org/abs/2602.00497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00497">https://arxiv.org/pdf/2602.00497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00497]] Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design(https://arxiv.org/abs/2602.00497)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.</li>
</ul>

<h3>Title: RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding</h3>
<ul>
<li><strong>Authors: </strong>Jiahe Wu, Bing Cao, Qilong Wang, Qinghua Hu, Dongdong Li, Pengfei Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00504">https://arxiv.org/abs/2602.00504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00504">https://arxiv.org/pdf/2602.00504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00504]] RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding(https://arxiv.org/abs/2602.00504)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLM) are primarily pre-trained on the RGB modality, thereby limiting their performance on other modalities, such as infrared, depth, and event data, which are crucial for complex scenarios. To address this, we propose RGBX-R1, a framework to enhance MLLM's perception and reasoning capacities across various X visual modalities. Specifically, we employ an Understand-Associate-Validate (UAV) prompting strategy to construct the Visual Modality Chain-of-Thought (VM-CoT), which aims to expand the MLLMs' RGB understanding capability into X modalities. To progressively enhance reasoning capabilities, we introduce a two-stage training paradigm: Cold-Start Supervised Fine-Tuning (CS-SFT) and Spatio-Temporal Reinforcement Fine-Tuning (ST-RFT). CS-SFT supervises the reasoning process with the guidance of VM-CoT, equipping the MLLM with fundamental modality cognition. Building upon GRPO, ST-RFT employs a Modality-understanding Spatio-Temporal (MuST) reward to reinforce modality reasoning. Notably, we construct the first RGBX-Grounding benchmark, and extensive experiments verify our superiority in multimodal understanding and spatial perception, outperforming baselines by 22.71% on three RGBX grounding tasks.</li>
</ul>

<h3>Title: Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jingrui Zhang, Feng Liang, Yong Zhang, Wei Wang, Runhao Zeng, Xiping Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00505">https://arxiv.org/abs/2602.00505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00505">https://arxiv.org/pdf/2602.00505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00505]] Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models(https://arxiv.org/abs/2602.00505)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the remarkable success of large language models (LLMs) in natural language understanding and generation, multimodal large language models (MLLMs) have rapidly advanced in their ability to process data across multiple modalities. While most existing efforts focus on scaling up language models or constructing higher-quality training data, limited attention has been paid to effectively integrating cross-modal knowledge into the language space. In vision-language models, for instance, aligning modalities using only high-level visual features often discards the rich semantic information present in mid- and low-level features, limiting the model's ability of cross-modality understanding. To address this issue, we propose SparseCut, a general cross-modal fusion architecture for MLLMs, introducing sparse shortcut connections between the cross-modal encoder and the LLM. These shortcut connections enable the efficient and hierarchical integration of visual features at multiple levels, facilitating richer semantic fusion without increasing computational overhead. We further introduce an efficient multi-grained feature fusion module, which performs the fusion of visual features before routing them through the shortcuts. This preserves the original language context and does not increase the overall input length, thereby avoiding an increase in computational complexity for the LLM. Experiments demonstrate that SparseCut significantly enhances the performance of MLLMs across various multimodal benchmarks with generality and scalability for different base LLMs.</li>
</ul>

<h3>Title: DuoGen: Towards General Purpose Interleaved Multimodal Generation</h3>
<ul>
<li><strong>Authors: </strong>Min Shi, Xiaohui Zeng, Jiannan Huang, Yin Cui, Francesco Ferroni, Jialuo Li, Shubham Pachori, Zhaoshuo Li, Yogesh Balaji, Haoxiang Wang, Tsung-Yi Lin, Xiao Fu, Yue Zhao, Chieh-Yun Chen, Ming-Yu Liu, Humphrey Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00508">https://arxiv.org/abs/2602.00508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00508">https://arxiv.org/pdf/2602.00508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00508]] DuoGen: Towards General Purpose Interleaved Multimodal Generation(https://arxiv.org/abs/2602.00508)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Interleaved multimodal generation enables capabilities beyond unimodal generation models, such as step-by-step instructional guides, visual planning, and generating visual drafts for reasoning. However, the quality of existing interleaved generation models under general instructions remains limited by insufficient training data and base model capacity. We present DuoGen, a general-purpose interleaved generation framework that systematically addresses data curation, architecture design, and evaluation. On the data side, we build a large-scale, high-quality instruction-tuning dataset by combining multimodal conversations rewritten from curated raw websites, and diverse synthetic examples covering everyday scenarios. Architecturally, DuoGen leverages the strong visual understanding of a pretrained multimodal LLM and the visual generation capabilities of a diffusion transformer (DiT) pretrained on video generation, avoiding costly unimodal pretraining and enabling flexible base model selection. A two-stage decoupled strategy first instruction-tunes the MLLM, then aligns DiT with it using curated interleaved image-text sequences. Across public and newly proposed benchmarks, DuoGen outperforms prior open-source models in text quality, image fidelity, and image-context alignment, and also achieves state-of-the-art performance on text-to-image and image editing among unified generation models. Data and code will be released at this https URL.</li>
</ul>

<h3>Title: Minerva: Reinforcement Learning with Verifiable Rewards for Cyber Threat Intelligence LLMs</h3>
<ul>
<li><strong>Authors: </strong>Md Tanvirul Alam, Aritran Piplai, Ionut Cardei, Nidhi Rastogi, Peter J Worth Jr</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00513">https://arxiv.org/abs/2602.00513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00513">https://arxiv.org/pdf/2602.00513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00513]] Minerva: Reinforcement Learning with Verifiable Rewards for Cyber Threat Intelligence LLMs(https://arxiv.org/abs/2602.00513)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Cyber threat intelligence (CTI) analysts routinely convert noisy, unstructured security artifacts into standardized, automation-ready representations. Although large language models (LLMs) show promise for this task, existing approaches remain brittle when producing structured CTI outputs and have largely relied on supervised fine-tuning (SFT). In contrast, CTI standards and community-maintained resources define canonical identifiers and schemas that enable deterministic verification of model outputs. We leverage this structure to study reinforcement learning with verifiable rewards (RLVR) for CTI tasks. We introduce \textit{Minerva}, a unified dataset and training pipeline spanning multiple CTI subtasks, each paired with task-specific verifiers that score structured outputs and identifier predictions. To address reward sparsity during rollout, we propose a lightweight self-training mechanism that generates additional verified trajectories and distills them back into the model. Experiments across LLM backbones show consistent improvements in accuracy and robustness over SFT across multiple benchmarks.</li>
</ul>

<h3>Title: Contrastive Learning for Privacy Enhancements in Industrial Internet of Things</h3>
<ul>
<li><strong>Authors: </strong>Lin Liu, Rita Machacy, Simi Kuniyilh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00515">https://arxiv.org/abs/2602.00515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00515">https://arxiv.org/pdf/2602.00515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00515]] Contrastive Learning for Privacy Enhancements in Industrial Internet of Things(https://arxiv.org/abs/2602.00515)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The Industrial Internet of Things (IIoT) integrates intelligent sensing, communication, and analytics into industrial environments, including manufacturing, energy, and critical infrastructure. While IIoT enables predictive maintenance and cross-site optimization of modern industrial control systems, such as those in manufacturing and energy, it also introduces significant privacy and confidentiality risks due to the sensitivity of operational data. Contrastive learning, a self-supervised representation learning paradigm, has recently emerged as a promising approach for privacy-preserving analytics by reducing reliance on labeled data and raw data sharing. Although contrastive learning-based privacy-preserving techniques have been explored in the Internet of Things (IoT) domain, this paper offers a comprehensive review of these techniques specifically for privacy preservation in Industrial Internet of Things (IIoT) systems. It emphasizes the unique characteristics of industrial data, system architectures, and various application scenarios. Additionally, the paper discusses solutions and open challenges and outlines future research directions.</li>
</ul>

<h3>Title: SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation</h3>
<ul>
<li><strong>Authors: </strong>Kunal Mahatha, Jose Dolz, Christian Desrosiers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00516">https://arxiv.org/abs/2602.00516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00516">https://arxiv.org/pdf/2602.00516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00516]] SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation(https://arxiv.org/abs/2602.00516)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>We argue that existing training-free segmentation methods rely on an implicit and limiting assumption, that segmentation is a spectral graph partitioning problem over diffusion-derived affinities. Such approaches, based on global graph partitioning and eigenvector-based formulations of affinity matrices, suffer from several fundamental drawbacks, they require pre-selecting the number of clusters, induce boundary oversmoothing due to spectral relaxation, and remain highly sensitive to noisy or multi-modal affinity distributions. Moreover, many prior works neglect the importance of local neighborhood structure, which plays a crucial role in stabilizing affinity propagation and preserving fine-grained contours. To address these limitations, we reformulate training-free segmentation as a stochastic flow equilibrium problem over diffusion-induced affinity graphs, where segmentation emerges from a stochastic propagation process that integrates global diffusion attention with local neighborhoods extracted from stable diffusion, yielding a sparse yet expressive affinity structure. Building on this formulation, we introduce a Markov propagation scheme that performs random-walk-based label diffusion with an adaptive pruning strategy that suppresses unreliable transitions while reinforcing confident affinity paths. Experiments across seven widely used semantic segmentation benchmarks demonstrate that our method achieves state-of-the-art zero-shot performance, producing sharper boundaries, more coherent regions, and significantly more stable masks compared to prior spectral-clustering-based approaches.</li>
</ul>

<h3>Title: NEST: Nested Event Stream Transformer for Sequences of Multisets</h3>
<ul>
<li><strong>Authors: </strong>Minghui Sun, Haoyu Gong, Xingyu You, Jillian Hurst, Benjamin Goldstein, Matthew Engelhard</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00520">https://arxiv.org/abs/2602.00520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00520">https://arxiv.org/pdf/2602.00520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00520]] NEST: Nested Event Stream Transformer for Sequences of Multisets(https://arxiv.org/abs/2602.00520)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Event stream data often exhibit hierarchical structure in which multiple events co-occur, resulting in a sequence of multisets (i.e., bags of events). In electronic health records (EHRs), for example, medical events are grouped into a sequence of clinical encounters with well-defined temporal structure, but the order and timing of events within each encounter may be unknown or unreliable. Most existing foundation models (FMs) for event stream data flatten this hierarchy into a one-dimensional sequence, leading to (i) computational inefficiency associated with dense attention and learning spurious within-set relationships, and (ii) lower-quality set-level representations from heuristic post-training pooling for downstream tasks. Here, we show that preserving the original hierarchy in the FM architecture provides a useful inductive bias that improves both computational efficiency and representation quality. We then introduce Nested Event Stream Transformer (NEST), a FM for event streams comprised of sequences of multisets. Building on this architecture, we formulate Masked Set Modeling (MSM), an efficient paradigm that promotes improved set-level representation learning. Experiments on real-world multiset sequence data show that NEST captures real-world dynamics while improving both pretraining efficiency and downstream performance.</li>
</ul>

<h3>Title: MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Chaoran Xu, Chengkan Lv, Qiyu Chen, Feng Zhang, Zhengtao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00522">https://arxiv.org/abs/2602.00522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00522">https://arxiv.org/pdf/2602.00522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00522]] MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval(https://arxiv.org/abs/2602.00522)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF, freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. The code will be publicly released at this https URL.</li>
</ul>

<h3>Title: Physiology as Language: Translating Respiration to Sleep EEG</h3>
<ul>
<li><strong>Authors: </strong>Kaiwen Zha, Chao Li, Hao He, Peng Cao, Tianhong Li, Ali Mirzazadeh, Ellen Zhang, Jong Woo Lee, Yoon Kim, Dina Katabi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00526">https://arxiv.org/abs/2602.00526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00526">https://arxiv.org/pdf/2602.00526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00526]] Physiology as Language: Translating Respiration to Sleep EEG(https://arxiv.org/abs/2602.00526)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel cross-physiology translation task: synthesizing sleep electroencephalography (EEG) from respiration signals. To address the significant complexity gap between the two modalities, we propose a waveform-conditional generative framework that preserves fine-grained respiratory dynamics while constraining the EEG target space through discrete tokenization. Trained on over 28,000 individuals, our model achieves a 7% Mean Absolute Error in EEG spectrogram reconstruction. Beyond reconstruction, the synthesized EEG supports downstream tasks with performance comparable to ground truth EEG on age estimation (MAE 5.0 vs. 5.1 years), sex detection (AUROC 0.81 vs. 0.82), and sleep staging (Accuracy 0.84 vs. 0.88), significantly outperforming baselines trained directly on breathing. Finally, we demonstrate that the framework generalizes to contactless sensing by synthesizing EEG from wireless radio-frequency reflections, highlighting the feasibility of remote, non-contact neurological assessment during sleep.</li>
</ul>

<h3>Title: Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Zhang, Antoine Simoulin, Kai Li, Sana Lakdawala, Shiqing Yu, Arpit Mittal, Hongyu Fu, Yu Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00531">https://arxiv.org/abs/2602.00531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00531">https://arxiv.org/pdf/2602.00531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00531]] Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment(https://arxiv.org/abs/2602.00531)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.7 AP for novel classes on COCO2017 and 24.8 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 27.6% and 6.9%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.</li>
</ul>

<h3>Title: Invertible Memory Flow Networks</h3>
<ul>
<li><strong>Authors: </strong>Liyu Zerihun, Alexandr Plashchinsky</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00535">https://arxiv.org/abs/2602.00535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00535">https://arxiv.org/pdf/2602.00535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00535]] Invertible Memory Flow Networks(https://arxiv.org/abs/2602.00535)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long sequence neural memory remains a challenging problem. RNNs and their variants suffer from vanishing gradients, and Transformers suffer from quadratic scaling. Furthermore, compressing long sequences into a finite fixed representation remains an intractable problem due to the difficult optimization landscape. Invertible Memory Flow Networks (IMFN) make long sequence compression tractable through factorization: instead of learning end-to-end compression, we decompose the problem into pairwise merges using a binary tree of "sweeper" modules. Rather than learning to compress long sequences, each sweeper learns a much simpler 2-to-1 compression task, achieving O(log N) depth with sublinear error accumulation in sequence length. For online inference, we distilled into a constant-cost recurrent student achieving O(1) sequential steps. Empirical results validate IMFN on long MNIST sequences and UCF-101 videos, demonstrating compression of high-dimensional data over long sequences.</li>
</ul>

<h3>Title: SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal</h3>
<ul>
<li><strong>Authors: </strong>Yifan Zhang, Qian Chen, Yi Liu, Wengen Li, Jihong Guan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00536">https://arxiv.org/abs/2602.00536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00536">https://arxiv.org/pdf/2602.00536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00536]] SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal(https://arxiv.org/abs/2602.00536)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Cloud contamination severely degrades the usability of remote sensing imagery and poses a fundamental challenge for downstream Earth observation tasks. Recently, diffusion-based models have emerged as a dominant paradigm for remote sensing cloud removal due to their strong generative capability and stable optimization. However, existing diffusion-based approaches often suffer from limited sampling efficiency and insufficient exploitation of structural and temporal priors in multi-temporal remote sensing scenarios. In this work, we propose SADER, a structure-aware diffusion framework for multi-temporal remote sensing cloud removal. SADER first develops a scalable Multi-Temporal Conditional Diffusion Network (MTCDN) to fully capture multi-temporal and multimodal correlations via temporal fusion and hybrid attention. Then, a cloud-aware attention loss is introduced to emphasize cloud-dominated regions by accounting for cloud thickness and brightness discrepancies. In addition, a deterministic resampling strategy is designed for continuous diffusion models to iteratively refine samples under fixed sampling steps by replacing outliers through guided correction. Extensive experiments on multiple multi-temporal datasets demonstrate that SADER consistently outperforms state-of-the-art cloud removal methods across all evaluation metrics. The code of SADER is publicly available at this https URL.</li>
</ul>

<h3>Title: OpenDDI: A Comprehensive Benchmark for DDI Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xinmo Jin, Bowen Fan, Xunkai Li, Henan Sun, YuXin Zeng, Zekai Chen, Yuxuan Sun, Jia Li, Qiangqiang Dai, Hongchao Qin, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00539">https://arxiv.org/abs/2602.00539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00539">https://arxiv.org/pdf/2602.00539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00539]] OpenDDI: A Comprehensive Benchmark for DDI Prediction(https://arxiv.org/abs/2602.00539)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Drug-Drug Interactions (DDIs) significantly influence therapeutic efficacy and patient safety. As experimental discovery is resource-intensive and time-consuming, efficient computational methodologies have become essential. The predominant paradigm formulates DDI prediction as a drug graph-based link prediction task. However, further progress is hindered by two fundamental challenges: (1) lack of high-quality data: most studies rely on small-scale DDI datasets and single-modal drug representations; (2) lack of standardized evaluation: inconsistent scenarios, varied metrics, and diverse baselines. To address the above issues, we propose OpenDDI, a comprehensive benchmark for DDI prediction. Specifically, (1) from the data perspective, OpenDDI unifies 6 widely used DDI datasets and 2 existing forms of drug representation, while additionally contributing 3 new large-scale LLM-augmented datasets and a new multimodal drug representation covering 5 modalities. (2) From the evaluation perspective, OpenDDI unifies 20 SOTA model baselines across 3 downstream tasks, with standardized protocols for data quality, effectiveness, generalization, robustness, and efficiency. Based on OpenDDI, we conduct a comprehensive evaluation and derive 10 valuable insights for DDI prediction while exposing current limitations to provide critical guidance for this rapidly evolving field. Our code is available at this https URL</li>
</ul>

<h3>Title: NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Saeid, Amir Salarpour, Pedram MohajerAnsari, Mert D. Pesé</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00542">https://arxiv.org/abs/2602.00542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00542">https://arxiv.org/pdf/2602.00542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00542]] NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation(https://arxiv.org/abs/2602.00542)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present NPNet, a fully non-parametric approach for 3D point-cloud classification and part segmentation. NPNet contains no learned weights; instead, it builds point features using deterministic operators such as farthest point sampling, k-nearest neighbors, and pooling. Our key idea is an adaptive Gaussian-Fourier positional encoding whose bandwidth and Gaussian-cosine mixing are chosen from the input geometry, helping the method remain stable across different scales and sampling densities. For segmentation, we additionally incorporate fixed-frequency Fourier features to provide global context alongside the adaptive encoding. Across ModelNet40/ModelNet-R, ScanObjectNN, and ShapeNetPart, NPNet achieves strong performance among non-parametric baselines, and it is particularly effective in few-shot settings on ModelNet40. NPNet also offers favorable memory use and inference time compared to prior non-parametric methods</li>
</ul>

<h3>Title: Reasoning by Commented Code for Table Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Seho Pyo, Jiheon Seok, Jaejin Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00543">https://arxiv.org/abs/2602.00543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00543">https://arxiv.org/pdf/2602.00543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00543]] Reasoning by Commented Code for Table Question Answering(https://arxiv.org/abs/2602.00543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Table Question Answering (TableQA) poses a significant challenge for large language models (LLMs) because conventional linearization of tables often disrupts the two-dimensional relationships intrinsic to structured data. Existing methods, which depend on end-to-end answer generation or single-line program queries, typically exhibit limited numerical accuracy and reduced interpretability. This work introduces a commented, step-by-step code-generation framework that incorporates explicit reasoning into the Python program-generation process. The approach decomposes TableQA reasoning into multi-line executable programs with concise natural language comments, thereby promoting clearer reasoning and increasing the likelihood of generating correct code. On the WikiTableQuestions benchmark, the proposed method achieves 70.9\% accuracy using Qwen2.5-Coder-7B-Instruct, surpassing the Repanda baseline (67.6\%). Integrating the proposed framework with a robust end-to-end TableQA model via a lightweight answer-selection mechanism yields further improvements. This combined approach achieves up to 84.3\% accuracy on the WikiTableQuestions benchmark.</li>
</ul>

<h3>Title: Beyond the Node: Clade-level Selection for Efficient MCTS in Automatic Heuristic Design</h3>
<ul>
<li><strong>Authors: </strong>Kezhao Lai, Yutao Lai, Hai-Lin Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00549">https://arxiv.org/abs/2602.00549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00549">https://arxiv.org/pdf/2602.00549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00549]] Beyond the Node: Clade-level Selection for Efficient MCTS in Automatic Heuristic Design(https://arxiv.org/abs/2602.00549)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Monte Carlo Tree Search (MCTS) shows promise in Large Language Model (LLM) based Automatic Heuristic Design (AHD), it suffers from a critical over-exploitation tendency under the limited computational budgets required for heuristic evaluation. To address this limitation, we propose Clade-AHD, an efficient framework that replaces node-level point estimates with clade-level Bayesian beliefs. By aggregating descendant evaluations into Beta distributions and performing Thompson Sampling over these beliefs, Clade-AHD explicitly models uncertainty to guide exploration, enabling more reliable decision-making under sparse and noisy evaluations. Extensive experiments on complex combinatorial optimization problems demonstrate that Clade-AHD consistently outperforms state-of-the-art methods while significantly reducing computational cost. The source code is publicly available at: this https URL.</li>
</ul>

<h3>Title: A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora</h3>
<ul>
<li><strong>Authors: </strong>Liu Kaipeng, Wu Ling</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00554">https://arxiv.org/abs/2602.00554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00554">https://arxiv.org/pdf/2602.00554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00554]] A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora(https://arxiv.org/abs/2602.00554)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study investigates how the Bidirectional Encoder Representations from Transformers model processes four fundamental Argument Structure Constructions. We employ a multi-dimensional analytical framework, which integrates MDS, t-SNE as dimensionality reduction, Generalized Discrimination Value (GDV) as cluster separation metrics, Fisher Discriminant Ratio (FDR) as linear diagnostic probing, and attention mechanism analysis. Our results reveal a hierarchical representational structure. Construction-specific information emerges in early layers, forms maximally separable clusters in middle layers, and is maintained through later processing stages.</li>
</ul>

<h3>Title: Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Wenbin Xing, Quanxing Zha, Lizheng Zu, Mengran Li, Ming Li, Junchi Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00559">https://arxiv.org/abs/2602.00559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00559">https://arxiv.org/pdf/2602.00559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00559]] Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models(https://arxiv.org/abs/2602.00559)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current research on video hallucination mitigation primarily focuses on isolated error types, leaving compositional hallucinations, arising from incorrect reasoning over multiple interacting spatial and temporal factors largely underexplored. We introduce OmniVCHall, a benchmark designed to systematically evaluate both isolated and compositional hallucinations in video multimodal large language models (VLLMs). OmniVCHall spans diverse video domains, introduces a novel camera-based hallucination type, and defines a fine-grained taxonomy, together with adversarial answer options (e.g., "All are correct" and "None of the above") to prevent shortcut reasoning. The evaluations of 39 representative VLLMs reveal that even advanced models (e.g., Qwen3-VL and GPT-5) exhibit substantial performance degradation. We propose TriCD, a contrastive decoding framework with a triple-pathway calibration mechanism. An adaptive perturbation controller dynamically selects distracting operations to construct negative video variants, while a saliency-guided enhancement module adaptively reinforces grounded token-wise visual evidences. These components are optimized via reinforcement learning to encourage precise decision-making under compositional hallucination settings. Experimental results show that TriCD consistently improves performance across two representative backbones, achieving an average accuracy improvement of over 10%. The data and code can be find at this https URL.</li>
</ul>

<h3>Title: Forget by Uncertainty: Orthogonal Entropy Unlearning for Quantized Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Tian Zhang, Yujia Tong, Junhao Dong, Ke Xu, Yuze Wang, Jingling Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00567">https://arxiv.org/abs/2602.00567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00567">https://arxiv.org/pdf/2602.00567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00567]] Forget by Uncertainty: Orthogonal Entropy Unlearning for Quantized Neural Networks(https://arxiv.org/abs/2602.00567)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The deployment of quantized neural networks on edge devices, combined with privacy regulations like GDPR, creates an urgent need for machine unlearning in quantized models. However, existing methods face critical challenges: they induce forgetting by training models to memorize incorrect labels, conflating forgetting with misremembering, and employ scalar gradient reweighting that cannot resolve directional conflicts between gradients. We propose OEU, a novel Orthogonal Entropy Unlearning framework with two key innovations: 1) Entropy-guided unlearning maximizes prediction uncertainty on forgotten data, achieving genuine forgetting rather than confident misprediction, and 2) Gradient orthogonal projection eliminates interference by projecting forgetting gradients onto the orthogonal complement of retain gradients, providing theoretical guarantees for utility preservation under first-order approximation. Extensive experiments demonstrate that OEU outperforms existing methods in both forgetting effectiveness and retain accuracy.</li>
</ul>

<h3>Title: GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Luo, Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00570">https://arxiv.org/abs/2602.00570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00570">https://arxiv.org/pdf/2602.00570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00570]] GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates(https://arxiv.org/abs/2602.00570)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Vision-language tracking has gained increasing attention in many scenarios. This task simultaneously deals with visual and linguistic information to localize objects in videos. Despite its growing utility, the development of vision-language tracking methods remains in its early stage. Current vision-language trackers usually employ Transformer architectures for interactive integration of template, search, and text features. However, persistent challenges about low-semantic images including prevalent image blurriness, low resolution and so on, may compromise model performance through degraded cross-modal understanding. To solve this problem, language assistance is usually used to deal with the obstacles posed by low-semantic images. However, due to the existing gap between current textual and visual features, direct concatenation and fusion of these features may have limited effectiveness. To address these challenges, we introduce a pioneering Generative Language-AssisteD tracking model, GLAD, which utilizes diffusion models for the generative multi-modal fusion of text description and template image to bolster compatibility between language and image and enhance template image semantic information. Our approach demonstrates notable improvements over the existing fusion paradigms. Blurry and semantically ambiguous template images can be restored to improve multi-modal features in the generative fusion paradigm. Experiments show that our method establishes a new state-of-the-art on multiple benchmarks and achieves an impressive inference speed. The code and models will be released at: this https URL</li>
</ul>

<h3>Title: Data Distribution as a Lever for Guiding Optimizers Toward Superior Generalization in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tushaar Gangavarapu, Jiping Li, Christopher Vattheuer, Zhangyang Wang, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00576">https://arxiv.org/abs/2602.00576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00576">https://arxiv.org/pdf/2602.00576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00576]] Data Distribution as a Lever for Guiding Optimizers Toward Superior Generalization in LLMs(https://arxiv.org/abs/2602.00576)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Can modifying the training data distribution guide optimizers toward solutions with improved generalization when training large language models (LLMs)? In this work, we theoretically analyze an in-context linear regression model with multi-head linear self-attention, and compare the training dynamics of two gradient based optimizers, namely gradient descent (GD) and sharpness-aware minimization (SAM), the latter exhibiting superior generalization properties but is prohibitively expensive for training even medium-sized LLMs. We show, for the first time, that SAM induces a lower simplicity bias (SB)-the tendency of an optimizer to preferentially learn simpler features earlier in training-and identify this reduction as a key factor underlying its improved generalization performance. Motivated by this insight, we demonstrate that altering the training data distribution by upsampling or augmenting examples learned later in training similarly reduces SB and leads to improved generalization. Our extensive experiments show that our strategy improves the performance of multiple LLMs-including Phi2-2.7B , Llama3.2-1B, Gemma3-1B-PT, and Qwen3-0.6B-Base-achieving relative accuracy gains up to 18% when fine-tuned with AdamW and Muon on mathematical reasoning tasks.</li>
</ul>

<h3>Title: Sparsity-Aware Unlearning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuze Wang, Yujia Tong, Ke Xu, Jingling Yuan, Jiawei Jiang, Chuang Hu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00577">https://arxiv.org/abs/2602.00577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00577">https://arxiv.org/pdf/2602.00577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00577]] Sparsity-Aware Unlearning for Large Language Models(https://arxiv.org/abs/2602.00577)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) inevitably memorize sensitive information during training, posing significant privacy risks. Machine unlearning has emerged as a promising solution to selectively remove such information without full retraining. However, existing methods are designed for dense models and overlook model sparsification-an essential technique for efficient LLM deployment. We find that unlearning effectiveness degrades substantially on sparse models. Through empirical analysis, we reveal that this degradation occurs because existing unlearning methods require updating all parameters, yet sparsification prunes substantial weights to zero, fundamentally limiting the model's forgetting capacity. To address this challenge, we propose Sparsity-Aware Unlearning (SAU), which decouples unlearning from sparsification objectives through gradient masking that redirects updates to surviving weights, combined with importance-aware redistribution to compensate for pruned parameters. Extensive experiments demonstrate that SAU significantly outperforms existing methods on sparse LLMs, achieving effective forgetting while preserving model utility.</li>
</ul>

<h3>Title: Bridging Degradation Discrimination and Generation for Universal Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>JiaKui Hu, Zhengjian Yao, Lujia Jin, Yanye Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00579">https://arxiv.org/abs/2602.00579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00579">https://arxiv.org/pdf/2602.00579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00579]] Bridging Degradation Discrimination and Generation for Universal Image Restoration(https://arxiv.org/abs/2602.00579)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Universal image restoration is a critical task in low-level vision, requiring the model to remove various degradations from low-quality images to produce clean images with rich detail. The challenges lie in sampling the distribution of high-quality images and adjusting the outputs on the basis of the degradation. This paper presents a novel approach, Bridging Degradation discrimination and Generation (BDG), which aims to address these challenges concurrently. First, we propose the Multi-Angle and multi-Scale Gray Level Co-occurrence Matrix (MAS-GLCM) and demonstrate its effectiveness in performing fine-grained discrimination of degradation types and levels. Subsequently, we divide the diffusion training process into three distinct stages: generation, bridging, and restoration. The objective is to preserve the diffusion model's capability of restoring rich textures while simultaneously integrating the discriminative information from the MAS-GLCM into the restoration process. This enhances its proficiency in addressing multi-task and multi-degraded scenarios. Without changing the architecture, BDG achieves significant performance gains in all-in-one restoration and real-world super-resolution tasks, primarily evidenced by substantial improvements in fidelity without compromising perceptual quality. The code and pretrained models are provided in this https URL.</li>
</ul>

<h3>Title: MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangdong Li, Ye Lou, Ao Gao, Wei Zhang, Siyang Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00583">https://arxiv.org/abs/2602.00583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00583">https://arxiv.org/pdf/2602.00583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00583]] MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation(https://arxiv.org/abs/2602.00583)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The lack of large-scale, demographically diverse face images with precise Action Unit (AU) occurrence and intensity annotations has long been recognized as a fundamental bottleneck in developing generalizable AU recognition systems. In this paper, we propose MAUGen, a diffusion-based multi-modal framework that jointly generates a large collection of photorealistic facial expressions and anatomically consistent AU labels, including both occurrence and intensity, conditioned on a single descriptive text prompt. Our MAUGen involves two key modules: (1) a Multi-modal Representation Learning (MRL) module that captures the relationships among the paired textual description, facial identity, expression image, and AU activations within a unified latent space; and (2) a Diffusion-based Image label Generator (DIG) that decodes the joint representation into aligned facial image-label pairs across diverse identities. Under this framework, we introduce Multi-Identity Facial Action (MIFA), a large-scale multimodal synthetic dataset featuring comprehensive AU annotations and identity variations. Extensive experiments demonstrate that MAUGen outperforms existing methods in synthesizing photorealistic, demographically diverse facial images along with semantically aligned AU labels.</li>
</ul>

<h3>Title: SEER: Transformer-based Robust Time Series Forecasting via Automated Patch Enhancement and Replacement</h3>
<ul>
<li><strong>Authors: </strong>Xiangfei Qiu, Xvyuan Liu, Tianen Shen, Xingjian Wu, Hanyin Cheng, Bin Yang, Jilin Hu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00589">https://arxiv.org/abs/2602.00589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00589">https://arxiv.org/pdf/2602.00589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00589]] SEER: Transformer-based Robust Time Series Forecasting via Automated Patch Enhancement and Replacement(https://arxiv.org/abs/2602.00589)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Time series forecasting is important in many fields that require accurate predictions for decision-making. Patching techniques, commonly used and effective in time series modeling, help capture temporal dependencies by dividing the data into patches. However, existing patch-based methods fail to dynamically select patches and typically use all patches during the prediction process. In real-world time series, there are often low-quality issues during data collection, such as missing values, distribution shifts, anomalies and white noise, which may cause some patches to contain low-quality information, negatively impacting the prediction results. To address this issue, this study proposes a robust time series forecasting framework called SEER. Firstly, we propose an Augmented Embedding Module, which improves patch-wise representations using a Mixture-of-Experts (MoE) architecture and obtains series-wise token representations through a channel-adaptive perception mechanism. Secondly, we introduce a Learnable Patch Replacement Module, which enhances forecasting robustness and model accuracy through a two-stage process: 1) a dynamic filtering mechanism eliminates negative patch-wise tokens; 2) a replaced attention module substitutes the identified low-quality patches with global series-wise token, further refining their representations through a causal attention mechanism. Comprehensive experimental results demonstrate the SOTA performance of SEER.</li>
</ul>

<h3>Title: From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking</h3>
<ul>
<li><strong>Authors: </strong>Yifan Jiang, Cong Zhang, Bofei Zhang, Yifan Yang, Bingzhang Wang, Yew-Soon Ong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00593">https://arxiv.org/abs/2602.00593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00593">https://arxiv.org/pdf/2602.00593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00593]] From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking(https://arxiv.org/abs/2602.00593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite progress on general tasks, VLMs struggle with challenges demanding both detailed visual grounding and deliberate knowledge-based reasoning, a synergy not captured by existing benchmarks that evaluate these skills separately. To close this gap, we introduce Pix2Fact, a new visual question-answering benchmark designed to evaluate expert-level perception and knowledge-intensive multi-hop reasoning. Pix2Fact contains 1,000 high-resolution (4K+) images spanning 8 daily-life scenarios and situations, with questions and answers meticulously crafted by annotators holding PhDs from top global universities working in partnership with a professional data annotation firm. Each question requires detailed visual grounding, multi-hop reasoning, and the integration of external knowledge to answer. Our evaluation of 9 state-of-the-art VLMs, including proprietary models like Gemini-3-Pro and GPT-5, reveals the substantial challenge posed by Pix2Fact: the most advanced model achieves only 24.0% average accuracy, in stark contrast to human performance of 56%. This significant gap underscores the limitations of current models in replicating human-level visual comprehension. We believe Pix2Fact will serve as a critical benchmark to drive the development of next-generation multimodal agents that combine fine-grained perception with robust, knowledge-based reasoning.</li>
</ul>

<h3>Title: Kernelized Edge Attention: Addressing Semantic Attention Blurring in Temporal Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Govind Waghmare, Srini Rohan Gujulla Leel, Nikhil Tumbde, Sumedh B G, Sonia Gupta, Srikanta Bedathur</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00596">https://arxiv.org/abs/2602.00596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00596">https://arxiv.org/pdf/2602.00596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00596]] Kernelized Edge Attention: Addressing Semantic Attention Blurring in Temporal Graph Neural Networks(https://arxiv.org/abs/2602.00596)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Temporal Graph Neural Networks (TGNNs) aim to capture the evolving structure and timing of interactions in dynamic graphs. Although many models incorporate time through encodings or architectural design, they often compute attention over entangled node and edge representations, failing to reflect their distinct temporal behaviors. Node embeddings evolve slowly as they aggregate long-term structural context, while edge features reflect transient, timestamped interactions (e.g. messages, trades, or transactions). This mismatch results in semantic attention blurring, where attention weights cannot distinguish between slowly drifting node states and rapidly changing, information-rich edge interactions. As a result, models struggle to capture fine-grained temporal dependencies and provide limited transparency into how temporal relevance is computed. This paper introduces KEAT (Kernelized Edge Attention for Temporal Graphs), a novel attention formulation that modulates edge features using a family of continuous-time kernels, including Laplacian, RBF, and learnable MLP variant. KEAT preserves the distinct roles of nodes and edges, and integrates seamlessly with both Transformer-style (e.g., DyGFormer) and message-passing (e.g., TGN) architectures. It achieves up to 18% MRR improvement over the recent DyGFormer and 7% over TGN on link prediction tasks, enabling more accurate, interpretable and temporally aware message passing in TGNNs.</li>
</ul>

<h3>Title: Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling</h3>
<ul>
<li><strong>Authors: </strong>Chaoqun Cui, Shijing Wang, Liangbin Huang, Qingqing Gu, Zhaolong Huang, Xiao Zeng, Wenji Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00597">https://arxiv.org/abs/2602.00597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00597">https://arxiv.org/pdf/2602.00597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00597]] Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling(https://arxiv.org/abs/2602.00597)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.</li>
</ul>

<h3>Title: Direct Preference Optimization with Rating Information: Practical Algorithms and Provable Gains</h3>
<ul>
<li><strong>Authors: </strong>Luca Viano, Ruida Zhou, Yifan Sun, Mahdi Namazifar, Volkan Cevher, Shoham Sabach, Mohammad Ghavamzadeh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00603">https://arxiv.org/abs/2602.00603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00603">https://arxiv.org/pdf/2602.00603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00603]] Direct Preference Optimization with Rating Information: Practical Algorithms and Provable Gains(https://arxiv.org/abs/2602.00603)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The class of direct preference optimization (DPO) algorithms has emerged as a promising approach for solving the alignment problem in foundation models. These algorithms work with very limited feedback in the form of pairwise preferences and fine-tune models to align with these preferences without explicitly learning a reward model. While the form of feedback used by these algorithms makes the data collection process easy and relatively more accurate, its ambiguity in terms of the quality of responses could have negative implications. For example, it is not clear if a decrease (increase) in the likelihood of preferred (dispreferred) responses during the execution of these algorithms could be interpreted as a positive or negative phenomenon. In this paper, we study how to design algorithms that can leverage additional information in the form of rating gap, which informs the learner how much the chosen response is better than the rejected one. We present new algorithms that can achieve faster statistical rates than DPO in presence of accurate rating gap information. Moreover, we theoretically prove and empirically show that the performance of our algorithms is robust to inaccuracy in rating gaps. Finally, we demonstrate the solid performance of our methods in comparison to a number of DPO-style algorithms across a wide range of LLMs and evaluation benchmarks.</li>
</ul>

<h3>Title: Actor-Dual-Critic Dynamics for Zero-sum and Identical-Interest Stochastic Games</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Said Donmez, Yuksel Arslantas, Muhammed O. Sayin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00606">https://arxiv.org/abs/2602.00606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00606">https://arxiv.org/pdf/2602.00606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00606]] Actor-Dual-Critic Dynamics for Zero-sum and Identical-Interest Stochastic Games(https://arxiv.org/abs/2602.00606)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose a novel independent and payoff-based learning framework for stochastic games that is model-free, game-agnostic, and gradient-free. The learning dynamics follow a best-response-type actor-critic architecture, where agents update their strategies (actors) using feedback from two distinct critics: a fast critic that intuitively responds to observed payoffs under limited information, and a slow critic that deliberatively approximates the solution to the underlying dynamic programming problem. Crucially, the learning process relies on non-equilibrium adaptation through smoothed best responses to observed payoffs. We establish convergence to (approximate) equilibria in two-agent zero-sum and multi-agent identical-interest stochastic games over an infinite horizon. This provides one of the first payoff-based and fully decentralized learning algorithms with theoretical guarantees in both settings. Empirical results further validate the robustness and effectiveness of the proposed approach across both classes of games.</li>
</ul>

<h3>Title: Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars</h3>
<ul>
<li><strong>Authors: </strong>Yitong Zhang, Yongmin Li, Yuetong Liu, Jia Li, Xiaoran Jia, Zherui Li, Ge Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00612">https://arxiv.org/abs/2602.00612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00612">https://arxiv.org/pdf/2602.00612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00612]] Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars(https://arxiv.org/abs/2602.00612)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion Large Language Models (dLLMs) have demonstrated promising generative capabilities and are increasingly used to produce formal languages defined by context-free grammars, such as source code and chemical expressions. However, as probabilistic models, they still struggle to generate syntactically valid outputs reliably. A natural and promising direction to address this issue is to adapt constrained decoding techniques to enforce grammatical correctness during generation. However, applying these techniques faces two primary obstacles. On the one hand, the non-autoregressive nature of dLLMs renders most existing constrained decoding approaches inapplicable. On the other hand, current approaches specifically designed for dLLMs may allow intermediate outputs that are impossible to complete into valid sentences, which significantly limits their reliability in practice. To address these challenges, we present LAVE, a constrained decoding approach specifically designed for dLLMs. Our approach leverages a key property of dLLMs, namely their ability to predict token distributions for all positions in parallel during each forward pass. Whenever a new token is proposed by model, LAVE performs lookahead using these distributions to efficiently and reliably verify the validity of the proposed token. This design ensures reliable constraints by reliably preserving the potential for intermediate outputs to be extended into valid sentences. Extensive experiments across four widely used dLLMs and three representative benchmarks demonstrate that LAVE consistently outperforms existing baselines and achieves substantial improvements in syntactic correctness, while incurring negligible runtime overhead.</li>
</ul>

<h3>Title: Transformer-Based Model for Multilingual Hope Speech Detection</h3>
<ul>
<li><strong>Authors: </strong>Nsrin Ashraf, Mariam Labib, Hamada Nayel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00613">https://arxiv.org/abs/2602.00613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00613">https://arxiv.org/pdf/2602.00613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00613]] Transformer-Based Model for Multilingual Hope Speech Detection(https://arxiv.org/abs/2602.00613)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This paper describes a system that has been submitted to the "PolyHope-M" at RANLP2025. In this work various transformers have been implemented and evaluated for hope speech detection for English and Germany. RoBERTa has been implemented for English, while the multilingual model XLM-RoBERTa has been implemented for both English and German languages. The proposed system using RoBERTa reported a weighted f1-score of 0.818 and an accuracy of 81.8% for English. On the other hand, XLM-RoBERTa achieved a weighted f1-score of 0.786 and an accuracy of 78.5%. These results reflects the importance of improvement of pre-trained large language models and how these models enhancing the performance of different natural language processing tasks.</li>
</ul>

<h3>Title: Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Yian Zhao, Rushi Ye, Ruochong Zheng, Zesen Cheng, Chaoran Feng, Jiashu Yang, Pengchong Qiao, Chang Liu, Jie Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00618">https://arxiv.org/abs/2602.00618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00618">https://arxiv.org/pdf/2602.00618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00618]] Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting(https://arxiv.org/abs/2602.00618)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to adapt to the diverse content-style balance requirements from different users. In this work, we introduce a creative intensity-tunable 3D style transfer paradigm, dubbed \textbf{Tune-Your-Style}, which allows users to flexibly adjust the style intensity injected into the scene to match their desired content-style balance, thus enhancing the customizability of 3D style transfer. To achieve this goal, we first introduce Gaussian neurons to explicitly model the style intensity and parameterize a learnable style tuner to achieve intensity-tunable style injection. To facilitate the learning of tunable stylization, we further propose the tunable stylization guidance, which obtains multi-view consistent stylized views from diffusion models through cross-view style alignment, and then employs a two-stage optimization strategy to provide stable and efficient guidance by modulating the balance between full-style guidance from the stylized views and zero-style guidance from the initial rendering. Extensive experiments demonstrate that our method not only delivers visually appealing results, but also exhibits flexible customizability for 3D style transfer. Project page is available at this https URL.</li>
</ul>

<h3>Title: Jailbreaking LLMs via Calibration</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Lu, Yongkang Guo, Yuqing Kong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00619">https://arxiv.org/abs/2602.00619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00619">https://arxiv.org/pdf/2602.00619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00619]] Jailbreaking LLMs via Calibration(https://arxiv.org/abs/2602.00619)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower "Jailbreak Tax" compared with existing methods, especially on the safety-hardened gpt-oss-120b.</li>
</ul>

<h3>Title: Rethinking Zero-Shot Time Series Classification: From Task-specific Classifiers to In-Context Inference</h3>
<ul>
<li><strong>Authors: </strong>Juntao Fang, Shifeng Xie, Shengbin Nie, Yuhui Ling, Yuming Liu, Zijian Li, Keli Zhang, Lujia Pan, Themis Palpanas, Ruichu Cai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00620">https://arxiv.org/abs/2602.00620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00620">https://arxiv.org/pdf/2602.00620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00620]] Rethinking Zero-Shot Time Series Classification: From Task-specific Classifiers to In-Context Inference(https://arxiv.org/abs/2602.00620)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The zero-shot evaluation of time series foundation models (TSFMs) for classification typically uses a frozen encoder followed by a task-specific classifier. However, this practice violates the training-free premise of zero-shot deployment and introduces evaluation bias due to classifier-dependent training choices. To address this issue, we propose TIC-FM, an in-context learning framework that treats the labeled training set as context and predicts labels for all test instances in a single forward pass, without parameter updates. TIC-FM pairs a time series encoder and a lightweight projection adapter with a split-masked latent memory Transformer. We further provide theoretical justification that in-context inference can subsume trained classifiers and can emulate gradient-based classifier training within a single forward pass. Experiments on 128 UCR datasets show strong accuracy, with consistent gains in the extreme low-label situation, highlighting training-free transfer</li>
</ul>

<h3>Title: Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering</h3>
<ul>
<li><strong>Authors: </strong>Guangtao Lyu, Xinyi Cheng, Qi Liu, Chenghao Xu, Jiexi Yan, Muli Yang, Fen Fang, Cheng Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00621">https://arxiv.org/abs/2602.00621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00621">https://arxiv.org/pdf/2602.00621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00621]] Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering(https://arxiv.org/abs/2602.00621)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>LVLMs achieve remarkable multimodal understanding and generation but remain susceptible to hallucinations. Existing mitigation methods predominantly focus on output-level adjustments, leaving the internal mechanisms that give rise to these hallucinations largely unexplored. To gain a deeper understanding, we adopt a representation-level perspective by introducing sparse autoencoders (SAEs) to decompose dense visual embeddings into sparse, interpretable neurons. Through neuron-level analysis, we identify distinct neuron types, including always-on neurons and image-specific neurons. Our findings reveal that hallucinations often result from disruptions or spurious activations of image-specific neurons, while always-on neurons remain largely stable. Moreover, selectively enhancing or suppressing image-specific neurons enables controllable intervention in LVLM outputs, improving visual grounding and reducing hallucinations. Building on these insights, we propose Contrastive Neuron Steering (CNS), which identifies image-specific neurons via contrastive analysis between clean and noisy inputs. CNS selectively amplifies informative neurons while suppressing perturbation-induced activations, producing more robust and semantically grounded visual representations. This not only enhances visual understanding but also effectively mitigates hallucinations. By operating at the prefilling stage, CNS is fully compatible with existing decoding-stage methods. Extensive experiments on both hallucination-focused and general multimodal benchmarks demonstrate that CNS consistently reduces hallucinations while preserving overall multimodal understanding.</li>
</ul>

<h3>Title: MoDEx: Mixture of Depth-specific Experts for Multivariate Long-term Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hyekyung Yoon, Minhyuk Lee, Imseung Park, Myungjoo Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00624">https://arxiv.org/abs/2602.00624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00624">https://arxiv.org/pdf/2602.00624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00624]] MoDEx: Mixture of Depth-specific Experts for Multivariate Long-term Time Series Forecasting(https://arxiv.org/abs/2602.00624)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Multivariate long-term time series forecasting (LTSF) supports critical applications such as traffic-flow management, solar-power scheduling, and electricity-transformer monitoring. The existing LTSF paradigms follow a three-stage pipeline of embedding, backbone refinement, and long-horizon prediction. However, the behaviors of individual backbone layers remain underexplored. We introduce layer sensitivity, a gradient-based metric inspired by GradCAM and effective receptive field theory, which quantifies both positive and negative contributions of each time point to a layer's latent features. Applying this metric to a three-layer MLP backbone reveals depth-specific specialization in modeling temporal dynamics in the input sequence. Motivated by these insights, we propose MoDEx, a lightweight Mixture of Depth-specific Experts, which replaces complex backbones with depth-specific MLP experts. MoDEx achieves state-of-the-art accuracy on seven real-world benchmarks, ranking first in 78 percent of cases, while using significantly fewer parameters and computational resources. It also integrates seamlessly into transformer variants, consistently boosting their performance and demonstrating robust generalizability as an efficient and high-performance LTSF framework.</li>
</ul>

<h3>Title: FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization</h3>
<ul>
<li><strong>Authors: </strong>Benxiang Zhai, Yifang Xu, Guofeng Zhang, Yang Li, Sidan Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00627">https://arxiv.org/abs/2602.00627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00627">https://arxiv.org/pdf/2602.00627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00627]] FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization(https://arxiv.org/abs/2602.00627)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Benefiting from the significant advancements in text-to-image diffusion models, research in personalized image generation, particularly customized portrait generation, has also made great strides recently. However, existing methods either require time-consuming fine-tuning and lack generalizability or fail to achieve high fidelity in facial details. To address these issues, we propose FaceSnap, a novel method based on Stable Diffusion (SD) that requires only a single reference image and produces extremely consistent results in a single inference stage. This method is plug-and-play and can be easily extended to different SD models. Specifically, we design a new Facial Attribute Mixer that can extract comprehensive fused information from both low-level specific features and high-level abstract features, providing better guidance for image generation. We also introduce a Landmark Predictor that maintains reference identity across landmarks with different poses, providing diverse yet detailed spatial control conditions for image generation. Then we use an ID-preserving module to inject these into the UNet. Experimental results demonstrate that our approach performs remarkably in personalized and customized portrait generation, surpassing other state-of-the-art methods in this domain.</li>
</ul>

<h3>Title: From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Louis Schiekiera, Max Zimmer, Christophe Roux, Sebastian Pokutta, Fritz Günther</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00628">https://arxiv.org/abs/2602.00628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00628">https://arxiv.org/pdf/2602.00628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00628]] From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs(https://arxiv.org/abs/2602.00628)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We investigate the extent to which an LLM's hidden-state geometry can be recovered from its behavior in psycholinguistic experiments. Across eight instruction-tuned transformer models, we run two experimental paradigms -- similarity-based forced choice and free association -- over a shared 5,000-word vocabulary, collecting 17.5M+ trials to build behavior-based similarity matrices. Using representational similarity analysis, we compare behavioral geometries to layerwise hidden-state similarity and benchmark against FastText, BERT, and cross-model consensus. We find that forced-choice behavior aligns substantially more with hidden-state geometry than free association. In a held-out-words regression, behavioral similarity (especially forced choice) predicts unseen hidden-state similarities beyond lexical baselines and cross-model consensus, indicating that behavior-only measurements retain recoverable information about internal semantic geometry. Finally, we discuss implications for the ability of behavioral tasks to uncover hidden cognitive states.</li>
</ul>

<h3>Title: S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Lingsong Wang, Mancheng Meng, Ziyan Wu, Terrence Chen, Fan Yang, Dinggang Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00635">https://arxiv.org/abs/2602.00635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00635">https://arxiv.org/pdf/2602.00635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00635]] S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning(https://arxiv.org/abs/2602.00635)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Existing face parsing methods usually misclassify occlusions as facial components. This is because occlusion is a high-level concept, it does not refer to a concrete category of object. Thus, constructing a real-world face dataset covering all categories of occlusion object is almost impossible and accurate mask annotation is labor-intensive. To deal with the problems, we present S$^3$POT, a contrast-driven framework synergizing face generation with self-supervised spatial prompting, to achieve occlusion segmentation. The framework is inspired by the insights: 1) Modern face generators' ability to realistically reconstruct occluded regions, creating an image that preserve facial geometry while eliminating occlusion, and 2) Foundation segmentation models' (e.g., SAM) capacity to extract precise mask when provided with appropriate prompts. In particular, S$^3$POT consists of three modules: Reference Generation (RF), Feature enhancement (FE), and Prompt Selection (PS). First, a reference image is produced by RF using structural guidance from parsed mask. Second, FE performs contrast of tokens between raw and reference images to obtain an initial prompt, then modifies image features with the prompt by cross-attention. Third, based on the enhanced features, PS constructs a set of positive and negative prompts and screens them with a self-attention network for a mask decoder. The network is learned under the guidance of three novel and complementary objective functions without occlusion ground truth mask involved. Extensive experiments on a dedicatedly collected dataset demonstrate S$^3$POT's superior performance and the effectiveness of each module.</li>
</ul>

<h3>Title: Formal Semantic Control over Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yingji Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00638">https://arxiv.org/abs/2602.00638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00638">https://arxiv.org/pdf/2602.00638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00638]] Formal Semantic Control over Language Models(https://arxiv.org/abs/2602.00638)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This thesis advances semantic representation learning to render language representations or models more semantically and geometrically interpretable, and to enable localised, quasi-symbolic, compositional control through deliberate shaping of their latent space geometry. We pursue this goal within a VAE framework, exploring two complementary research directions: (i) Sentence-level learning and control: disentangling and manipulating specific semantic features in the latent space to guide sentence generation, with explanatory text serving as the testbed; and (ii) Reasoning-level learning and control: isolating and steering inference behaviours in the latent space to control NLI. In this direction, we focus on Explanatory NLI tasks, in which two premises (explanations) are provided to infer a conclusion. The overarching objective is to move toward language models whose internal semantic representations can be systematically interpreted, precisely structured, and reliably directed. We introduce a set of novel theoretical frameworks and practical methodologies, together with corresponding experiments, to demonstrate that our approaches enhance both the interpretability and controllability of latent spaces for natural language across the thesis.</li>
</ul>

<h3>Title: Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization</h3>
<ul>
<li><strong>Authors: </strong>Yifang Xu, Benxiang Zhai, Chenyu Zhang, Ming Li, Yang Li, Sidan Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00639">https://arxiv.org/abs/2602.00639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00639">https://arxiv.org/pdf/2602.00639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00639]] Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization(https://arxiv.org/abs/2602.00639)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Portrait customization (PC) has recently garnered significant attention due to its potential applications. However, existing PC methods lack precise identity (ID) preservation and face control. To address these tissues, we propose Diff-PC, a diffusion-based framework for zero-shot PC, which generates realistic portraits with high ID fidelity, specified facial attributes, and diverse backgrounds. Specifically, our approach employs the 3D face predictor to reconstruct the 3D-aware facial priors encompassing the reference ID, target expressions, and poses. To capture fine-grained face details, we design ID-Encoder that fuses local and global facial features. Subsequently, we devise ID-Ctrl using the 3D face to guide the alignment of ID features. We further introduce ID-Injector to enhance ID fidelity and facial controllability. Finally, training on our collected ID-centric dataset improves face similarity and text-to-image (T2I) alignment. Extensive experiments demonstrate that Diff-PC surpasses state-of-the-art methods in ID preservation, facial control, and T2I consistency. Furthermore, our method is compatible with multi-style foundation models.</li>
</ul>

<h3>Title: LegalOne: A Family of Foundation Models for Reliable Legal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haitao Li, Yifan Chen, Shuo Miao, Qian Dong, Jia Chen, Yiran Hu, Junjie Chen, Minghao Qin, Qingyao Ai, Yiqun Liu, Cheng Luo, Quan Zhou, Ya Zhang, Jikun Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00642">https://arxiv.org/abs/2602.00642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00642">https://arxiv.org/pdf/2602.00642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00642]] LegalOne: A Family of Foundation Models for Reliable Legal Reasoning(https://arxiv.org/abs/2602.00642)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications.</li>
</ul>

<h3>Title: CoRe-Fed: Bridging Collaborative and Representation Fairness via Federated Embedding Distillation</h3>
<ul>
<li><strong>Authors: </strong>Noorain Mukhtiar, Adnan Mahmood, Quan Z. Sheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00647">https://arxiv.org/abs/2602.00647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00647">https://arxiv.org/pdf/2602.00647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00647]] CoRe-Fed: Bridging Collaborative and Representation Fairness via Federated Embedding Distillation(https://arxiv.org/abs/2602.00647)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>With the proliferation of distributed data sources, Federated Learning (FL) has emerged as a key approach to enable collaborative intelligence through decentralized model training while preserving data privacy. However, conventional FL algorithms often suffer from performance disparities across clients caused by heterogeneous data distributions and unequal participation, which leads to unfair outcomes. Specifically, we focus on two core fairness challenges, i.e., representation bias, arising from misaligned client representations, and collaborative bias, stemming from inequitable contribution during aggregation, both of which degrade model performance and generalizability. To mitigate these disparities, we propose CoRe-Fed, a unified optimization framework that bridges collaborative and representation fairness via embedding-level regularization and fairness-aware aggregation. Initially, an alignment-driven mechanism promotes semantic consistency between local and global embeddings to reduce representational divergence. Subsequently, a dynamic reward-penalty-based aggregation strategy adjusts each client's weight based on participation history and embedding alignment to ensure contribution-aware aggregation. Extensive experiments across diverse models and datasets demonstrate that CoRe-Fed improves both fairness and model performance over the state-of-the-art baseline algorithms.</li>
</ul>

<h3>Title: A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mohammadreza Gholipour Shahraki, Mehdi Rezaeian, Mohammad Ghasemzadeh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00650">https://arxiv.org/abs/2602.00650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00650">https://arxiv.org/pdf/2602.00650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00650]] A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation(https://arxiv.org/abs/2602.00650)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of 3D medical images such as MRI and CT is essential for clinical diagnosis and treatment planning. Foundation models like the Segment Anything Model (SAM) provide powerful general-purpose representations but struggle in medical imaging due to domain shift, their inherently 2D design, and the high computational cost of fine-tuning. To address these challenges, we propose Mamba-SAM, a novel and efficient hybrid architecture that combines a frozen SAM encoder with the linear-time efficiency and long-range modeling capabilities of Mamba-based State Space Models (SSMs). We investigate two parameter-efficient adaptation strategies. The first is a dual-branch architecture that explicitly fuses general features from a frozen SAM encoder with domain-specific representations learned by a trainable VMamba encoder using cross-attention. The second is an adapter-based approach that injects lightweight, 3D-aware Tri-Plane Mamba (TPMamba) modules into the frozen SAM ViT encoder to implicitly model volumetric context. Within this framework, we introduce Multi-Frequency Gated Convolution (MFGC), which enhances feature representation by jointly analyzing spatial and frequency-domain information via 3D discrete cosine transforms and adaptive gating. Extensive experiments on the ACDC cardiac MRI dataset demonstrate the effectiveness of the proposed methods. The dual-branch Mamba-SAM-Base model achieves a mean Dice score of 0.906, comparable to UNet++ (0.907), while outperforming all baselines on Myocardium (0.910) and Left Ventricle (0.971) segmentation. The adapter-based TP MFGC variant offers superior inference speed (4.77 FPS) with strong accuracy (0.880 Dice). These results show that hybridizing foundation models with efficient SSM-based architectures provides a practical and effective solution for 3D medical image segmentation.</li>
</ul>

<h3>Title: Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment</h3>
<ul>
<li><strong>Authors: </strong>Lukas Kuhn, Giuseppe Serra, Florian Buettner</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00653">https://arxiv.org/abs/2602.00653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00653">https://arxiv.org/pdf/2602.00653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00653]] Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment(https://arxiv.org/abs/2602.00653)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision-language models have transformed multimodal representation learning, yet dominant contrastive approaches like CLIP require large batch sizes, careful negative sampling, and extensive hyperparameter tuning. We introduce NOVA, a NOn-contrastive Vision-language Alignment framework based on joint embedding prediction with distributional regularization. NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg). This eliminates the need for negative sampling, momentum encoders, or stop-gradients, reducing the training objective to a single hyperparameter. We evaluate NOVA on zeroshot chest X-ray classification using ClinicalBERT as the text encoder and Vision Transformers trained from scratch on MIMIC-CXR. On zero-shot classification across three benchmark datasets, NOVA outperforms multiple standard baselines while exhibiting substantially more consistent training runs. Our results demonstrate that non-contrastive vision-language pretraining offers a simpler, more stable, and more effective alternative to contrastive methods.</li>
</ul>

<h3>Title: PHAT: Modeling Period Heterogeneity for Multivariate Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Ma, Guanjun Wang, Qihe Huang, Sheng Huang, Haofeng Ma, Zhengyang Zhou, Pengkun Wang, Binwu Wang, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00654">https://arxiv.org/abs/2602.00654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00654">https://arxiv.org/pdf/2602.00654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00654]] PHAT: Modeling Period Heterogeneity for Multivariate Time Series Forecasting(https://arxiv.org/abs/2602.00654)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While existing multivariate time series forecasting models have advanced significantly in modeling periodicity, they largely neglect the periodic heterogeneity common in real-world data, where variates exhibit distinct and dynamically changing periods. To effectively capture this periodic heterogeneity, we propose PHAT (Period Heterogeneity-Aware Transformer). Specifically, PHAT arranges multivariate inputs into a three-dimensional "periodic bucket" tensor, where the dimensions correspond to variate group characteristics with similar periodicity, time steps aligned by phase, and offsets within the period. By restricting interactions within buckets and masking cross-bucket connections, PHAT effectively avoids interference from inconsistent periods. We also propose a positive-negative attention mechanism, which captures periodic dependencies from two perspectives: periodic alignment and periodic deviation. Additionally, the periodic alignment attention scores are decomposed into positive and negative components, with a modulation term encoding periodic priors. This modulation constrains the attention mechanism to more faithfully reflect the underlying periodic trends. A mathematical explanation is provided to support this property. We evaluate PHAT comprehensively on 14 real-world datasets against 18 baselines, and the results show that it significantly outperforms existing methods, achieving highly competitive forecasting performance. Our sources is available at GitHub.</li>
</ul>

<h3>Title: Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ahsan Raza Siyal, Markus Haltmeier, Ruth Steiger, Elke Ruth Gizewski, Astrid Ellen Grams</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00661">https://arxiv.org/abs/2602.00661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00661">https://arxiv.org/pdf/2602.00661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00661]] Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting(https://arxiv.org/abs/2602.00661)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Spatiotemporal forecasting of complex three-dimensional phenomena (4D: 3D + time) is fundamental to applications in medical imaging, fluid and material dynamics, and geophysics. In contrast to unconstrained neural forecasting models, we propose a Schrödinger-inspired, physics-guided neural architecture that embeds an explicit time-evolution operator within a deep convolutional framework for 4D prediction. From observed volumetric sequences, the model learns voxelwise amplitude, phase, and potential fields that define a complex-valued wavefunction $\psi = A e^{i\phi}$, which is evolved forward in time using a differentiable, unrolled Schrödinger time stepper. This physics-guided formulation yields several key advantages: (i) temporal stability arising from the structured evolution operator, which mitigates drift and error accumulation in long-horizon forecasting; (ii) an interpretable latent representation, where phase encodes transport dynamics, amplitude captures structural intensity, and the learned potential governs spatiotemporal interactions; and (iii) natural compatibility with deformation-based synthesis, which is critical for preserving anatomical fidelity in medical imaging applications. By integrating physical priors directly into the learning process, the proposed approach combines the expressivity of deep networks with the robustness and interpretability of physics-based modeling. We demonstrate accurate and stable prediction of future 4D states, including volumetric intensities and deformation fields, on synthetic benchmarks that emulate realistic shape deformations and topological changes. To our knowledge, this is the first end-to-end 4D neural forecasting framework to incorporate a Schrödinger-type evolution operator, offering a principled pathway toward interpretable, stable, and anatomically consistent spatiotemporal prediction.</li>
</ul>

<h3>Title: Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Lakshan Cooray, Deshan Sumanathilaka, Pattigadapa Venkatesh Raju</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00665">https://arxiv.org/abs/2602.00665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00665">https://arxiv.org/pdf/2602.00665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00665]] Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation(https://arxiv.org/abs/2602.00665)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.</li>
</ul>

<h3>Title: zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing</h3>
<ul>
<li><strong>Authors: </strong>Rong Fu, Jia Yee Tan, Wenxin Zhang, Youjin Wang, Ziyu Kong, Zeli Su, Zhaolu Kang, Shuning Zhang, Xianda Li, Kun Liu, Simon Fong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00667">https://arxiv.org/abs/2602.00667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00667">https://arxiv.org/pdf/2602.00667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00667]] zkCraft: Prompt-Guided LLM as a Zero-Shot Mutation Pattern Oracle for TCCT-Powered ZK Fuzzing(https://arxiv.org/abs/2602.00667)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Zero-knowledge circuits enable privacy-preserving and scalable systems but are difficult to implement correctly due to the tight coupling between witness computation and circuit constraints. We present zkCraft, a practical framework that combines deterministic, R1CS-aware localization with proof-bearing search to detect semantic inconsistencies. zkCraft encodes candidate constraint edits into a single Row-Vortex polynomial and replaces repeated solver queries with a Violation IOP that certifies the existence of edits together with a succinct proof. Deterministic LLM-driven mutation templates bias exploration toward edge cases while preserving auditable algebraic verification. Evaluation on real Circom code shows that proof-bearing localization detects diverse under- and over-constrained faults with low false positives and reduces costly solver interaction. Our approach bridges formal verification and automated debugging, offering a scalable path for robust ZK circuit development.</li>
</ul>

<h3>Title: Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation</h3>
<ul>
<li><strong>Authors: </strong>Marina Crespo Aguirre, Jonathan Williams-Ramirez, Dina Zemlyanker, Xiaoling Hu, Lucas J. Deden-Binder, Rogeny Herisse, Mark Montine, Theresa R. Connors, Christopher Mount, Christine L. MacDonald, C. Dirk Keene, Caitlin S. Latimer, Derek H. Oakley, Bradley T. Hyman, Ana Lawry Aguila, Juan Eugenio Iglesias</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00669">https://arxiv.org/abs/2602.00669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00669">https://arxiv.org/pdf/2602.00669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00669]] Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation(https://arxiv.org/abs/2602.00669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Neuropathological analyses benefit from spatially precise volumetric reconstructions that enhance anatomical delineation and improve morphometric accuracy. Our prior work has shown the feasibility of reconstructing 3D brain volumes from 2D dissection photographs. However these outputs sometimes exhibit coarse, overly smooth reconstructions of structures, especially under high anisotropy (i.e., reconstructions from thick slabs). Here, we introduce a computationally efficient super-resolution step that imputes slices to generate anatomically consistent isotropic volumes from anisotropic 3D reconstructions of dissection photographs. By training on domain-randomized synthetic data, we ensure that our method generalizes across dissection protocols and remains robust to large slab thicknesses. The imputed volumes yield improved automated segmentations, achieving higher Dice scores, particularly in cortical and white matter regions. Validation on surface reconstruction and atlas registration tasks demonstrates more accurate cortical surfaces and MRI registration. By enhancing the resolution and anatomical fidelity of photograph-based reconstructions, our approach strengthens the bridge between neuropathology and neuroimaging. Our method is publicly available at this https URL</li>
</ul>

<h3>Title: Video Understanding: Through A Temporal Lens</h3>
<ul>
<li><strong>Authors: </strong>Thong Thanh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00683">https://arxiv.org/abs/2602.00683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00683">https://arxiv.org/pdf/2602.00683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00683]] Video Understanding: Through A Temporal Lens(https://arxiv.org/abs/2602.00683)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This thesis explores the central question of how to leverage temporal relations among video elements to advance video understanding. Addressing the limitations of existing methods, the work presents a five-fold contribution: (1) an automatic annotation framework that utilizes large vision-language models and a noise-robust contrastive learning objective with a subtractive angular margin; (2) a parameter-efficient fine-tuning strategy using "recurrent adapters" to capture temporal dynamics in low-data regimes; (3) the integration of State Space Layers (SSL) for efficient long-form video modeling, supported by the introduction of two new long-term benchmarks for egocentric and feature-length content; (4) a novel contrastive learning framework designed to explicitly model fine-grained relations between motions and video moments; and (5) a comprehensive empirical study on Large Vision-Language Models (LVLMs) that identifies the visual-language interface as a bottleneck for temporal reasoning, leading to a new "temporal-oriented recipe" for upscaled video understanding. Collectively, these contributions demonstrate that explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.</li>
</ul>

<h3>Title: Provably Protecting Fine-Tuned LLMs from Training Data Extraction</h3>
<ul>
<li><strong>Authors: </strong>Tom Segal, Asaf Shabtai, Yuval Elovici</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00688">https://arxiv.org/abs/2602.00688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00688">https://arxiv.org/pdf/2602.00688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00688]] Provably Protecting Fine-Tuned LLMs from Training Data Extraction(https://arxiv.org/abs/2602.00688)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) on sensitive datasets raises privacy concerns, as training data extraction (TDE) attacks can expose highly confidential information. Existing defenses against such attacks either lack formal privacy guarantees or incur substantial utility degradation. We observe that fine-tuning induces widespread probability shifts, yet preserving only a small subset of influential token-level deviations is sufficient; the remaining shifts can be aggressively smoothed with minimal impact on utility. Motivated by this insight, we propose SCP-$\Delta_r$, a Near Access Freeness (NAF)-based algorithm that operates on relative probabilities and explicitly smooths low-impact tokens using a base model. SCP-$\Delta_r$ achieves orders-of-magnitude better theoretical bounds than existing NAF based methods and provides strong empirical protection against TDE attacks with minimal performance loss.</li>
</ul>

<h3>Title: Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries</h3>
<ul>
<li><strong>Authors: </strong>Genqiang Wu, Xiaoying Zhang, Yu Qi, Hao Wang, Jikui Wang, Yeping He</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00689">https://arxiv.org/abs/2602.00689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00689">https://arxiv.org/pdf/2602.00689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00689]] Computing Maximal Per-Record Leakage and Leakage-Distortion Functions for Privacy Mechanisms under Entropy-Constrained Adversaries(https://arxiv.org/abs/2602.00689)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>The exponential growth of data collection necessitates robust privacy protections that preserve data utility. We address information disclosure against adversaries with bounded prior knowledge, modeled by an entropy constraint $H(X) \geq b$. Within this information privacy framework -- which replaces differential privacy's independence assumption with a bounded-knowledge model -- we study three core problems: maximal per-record leakage, the primal leakage-distortion tradeoff (minimizing worst-case leakage under distortion $D$), and the dual distortion minimization (minimizing distortion under leakage constraint $L$). These problems resemble classical information-theoretic ones (channel capacity, rate-distortion) but are more complex due to high dimensionality and the entropy constraint. We develop efficient alternating optimization algorithms that exploit convexity-concavity duality, with theoretical guarantees including local convergence for the primal problem and convergence to a stationary point for the dual. Experiments on binary symmetric channels and modular sum queries validate the algorithms, showing improved privacy-utility tradeoffs over classical differential privacy mechanisms. This work provides a computational framework for auditing privacy risks and designing certified mechanisms under realistic adversary assumptions.</li>
</ul>

<h3>Title: Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Fabio Turazza, Marcello Pietri, Natalia Selini Hadjidimitriou, Marco Mamei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00694">https://arxiv.org/abs/2602.00694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00694">https://arxiv.org/pdf/2602.00694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00694]] Forecasting Energy Availability in Local Energy Communities via LSTM Federated Learning(https://arxiv.org/abs/2602.00694)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Local Energy Communities are emerging as crucial players in the landscape of sustainable development. A significant challenge for these communities is achieving self-sufficiency through effective management of the balance between energy production and consumption. To meet this challenge, it is essential to develop and implement forecasting models that deliver accurate predictions, which can then be utilized by optimization and planning algorithms. However, the application of forecasting solutions is often hindered by privacy constrains and regulations as the users participating in the Local Energy Community can be (rightfully) reluctant sharing their consumption patterns with others. In this context, the use of Federated Learning (FL) can be a viable solution as it allows to create a forecasting model without the need to share privacy sensitive information among the users. In this study, we demonstrate how FL and long short-term memory (LSTM) networks can be employed to achieve this objective, highlighting the trade-off between data sharing and forecasting accuracy.</li>
</ul>

<h3>Title: StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components</h3>
<ul>
<li><strong>Authors: </strong>Zhongtian Huang, Zhi Chen, Zi Huang, Xin Yu, Daniel Smith, Chaitanya Purushothama, Erik Van Oosterom, Alex Wu, William Salter, Yan Li, Scott Chapman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00703">https://arxiv.org/abs/2602.00703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00703">https://arxiv.org/pdf/2602.00703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00703]] StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components(https://arxiv.org/abs/2602.00703)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Sorghum is a globally important cereal grown widely in water-limited and stress-prone regions. Its strong drought tolerance makes it a priority crop for climate-resilient agriculture. Improving water-use efficiency in sorghum requires precise characterisation of stomatal traits, as stomata control of gas exchange, transpiration and photosynthesis have a major influence on crop performance. Automated analysis of sorghum stomata is difficult because the stomata are small (often less than 40 $\mu$m in length in grasses such as sorghum) and vary in shape across genotypes and leaf surfaces. Automated segmentation contributes to high-throughput stomatal phenotyping, yet current methods still face challenges related to nested small structures and annotation bottlenecks. In this paper, we propose a semi-supervised instance segmentation framework tailored for analysis of sorghum stomatal components. We collect and annotate a sorghum leaf imagery dataset containing 11,060 human-annotated patches, covering the three stomatal components (pore, guard cell and complex area) across multiple genotypes and leaf surfaces. To improve the detection of tiny structures, we split high-resolution microscopy images into overlapping small patches. We then apply a pseudo-labelling strategy to unannotated images, producing an additional 56,428 pseudo-labelled patches. Benchmarking across semantic and instance segmentation models shows substantial performance gains: for semantic models the top mIoU increases from 65.93% to 70.35%, whereas for instance models the top AP rises from 28.30% to 46.10%. These results demonstrate that combining patch-based preprocessing with semi-supervised learning significantly improves the segmentation of fine stomatal structures. The proposed framework supports scalable extraction of stomatal traits and facilitates broader adoption of AI-driven phenotyping in crop science.</li>
</ul>

<h3>Title: LocalV: Exploiting Information Locality for IP-level Verilog Generation</h3>
<ul>
<li><strong>Authors: </strong>Hanqi Lyu, Di Huang, Yaoyu Zhu, Kangcheng Liu, Bohan Dou, Chongxiao Li, Pengwei Jin, Shuyao Cheng, Rui Zhang, Zidong Du, Qi Guo, Xing Hu, Yunji Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00704">https://arxiv.org/abs/2602.00704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00704">https://arxiv.org/pdf/2602.00704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00704]] LocalV: Exploiting Information Locality for IP-level Verilog Generation(https://arxiv.org/abs/2602.00704)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The generation of Register-Transfer Level (RTL) code is a crucial yet labor-intensive step in digital hardware design, traditionally requiring engineers to manually translate complex specifications into thousands of lines of synthesizable Hardware Description Language (HDL) code. While Large Language Models (LLMs) have shown promise in automating this process, existing approaches-including fine-tuned domain-specific models and advanced agent-based systems-struggle to scale to industrial IP-level design tasks. We identify three key challenges: (1) handling long, highly detailed documents, where critical interface constraints become buried in unrelated submodule descriptions; (2) generating long RTL code, where both syntactic and semantic correctness degrade sharply with increasing output length; and (3) navigating the complex debugging cycles required for functional verification through simulation and waveform analysis. To overcome these challenges, we propose LocalV, a multi-agent framework that leverages information locality in modular hardware design. LocalV decomposes the long-document to long-code generation problem into a set of short-document, short-code tasks, enabling scalable generation and debugging. Specifically, LocalV integrates hierarchical document partitioning, task planning, localized code generation, interface-consistent merging, and AST-guided locality-aware debugging. Experiments on RealBench, an IP-level Verilog generation benchmark, demonstrate that LocalV substantially outperforms state-of-the-art (SOTA) LLMs and agents, achieving a pass rate of 45.0% compared to 21.6%.</li>
</ul>

<h3>Title: From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Ranjith Krishnamurthy, Oshando Johnson, Goran Piskachev, Eric Bodden</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00711">https://arxiv.org/abs/2602.00711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00711">https://arxiv.org/pdf/2602.00711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00711]] From Detection to Prevention: Explaining Security-Critical Code to Avoid Vulnerabilities(https://arxiv.org/abs/2602.00711)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Security vulnerabilities often arise unintentionally during development due to a lack of security expertise and code complexity. Traditional tools, such as static and dynamic analysis, detect vulnerabilities only after they are introduced in code, leading to costly remediation. This work explores a proactive strategy to prevent vulnerabilities by highlighting code regions that implement security-critical functionality -- such as data access, authentication, and input handling -- and providing guidance for their secure implementation. We present an IntelliJ IDEA plugin prototype that uses code-level software metrics to identify potentially security-critical methods and large language models (LLMs) to generate prevention-oriented explanations. Our initial evaluation on the Spring-PetClinic application shows that the selected metrics identify most known security-critical methods, while an LLM provides actionable, prevention-focused insights. Although these metrics capture structural properties rather than semantic aspects of security, this work lays the foundation for code-level security-aware metrics and enhanced explanations.</li>
</ul>

<h3>Title: Federated Learning at the Forefront of Fairness: A Multifaceted Perspective</h3>
<ul>
<li><strong>Authors: </strong>Noorain Mukhtiar, Adnan Mahmood, Yipeng Zhou, Jian Yang, Jing Teng, Quan Z. Sheng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00718">https://arxiv.org/abs/2602.00718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00718">https://arxiv.org/pdf/2602.00718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00718]] Federated Learning at the Forefront of Fairness: A Multifaceted Perspective(https://arxiv.org/abs/2602.00718)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, fair</a></li>
<li><strong>Abstract: </strong>Fairness in Federated Learning (FL) is emerging as a critical factor driven by heterogeneous clients' constraints and balanced model performance across various scenarios. In this survey, we delineate a comprehensive classification of the state-of-the-art fairness-aware approaches from a multifaceted perspective, i.e., model performance-oriented and capability-oriented. Moreover, we provide a framework to categorize and address various fairness concerns and associated technical aspects, examining their effectiveness in balancing equity and performance within FL frameworks. We further examine several significant evaluation metrics leveraged to measure fairness quantitatively. Finally, we explore exciting open research directions and propose prospective solutions that could drive future advancements in this important area, laying a solid foundation for researchers working toward fairness in FL.</li>
</ul>

<h3>Title: Rethinking Hallucinations: Correctness, Consistency, and Prompt Multiplicity</h3>
<ul>
<li><strong>Authors: </strong>Prakhar Ganesh, Reza Shokri, Golnoosh Farnadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00723">https://arxiv.org/abs/2602.00723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00723">https://arxiv.org/pdf/2602.00723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00723]] Rethinking Hallucinations: Correctness, Consistency, and Prompt Multiplicity(https://arxiv.org/abs/2602.00723)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are known to "hallucinate" by generating false or misleading outputs. Hallucinations pose various harms, from erosion of trust to widespread misinformation. Existing hallucination evaluation, however, focuses only on correctness and often overlooks consistency, necessary to distinguish and address these harms. To bridge this gap, we introduce prompt multiplicity, a framework for quantifying consistency in LLM evaluations. Our analysis reveals significant multiplicity (over 50% inconsistency in benchmarks like Med-HALT), suggesting that hallucination-related harms have been severely misunderstood. Furthermore, we study the role of consistency in hallucination detection and mitigation. We find that: (a) detection techniques detect consistency, not correctness, and (b) mitigation techniques like RAG, while beneficial, can introduce additional inconsistencies. By integrating prompt multiplicity into hallucination evaluation, we provide an improved framework of potential harms and uncover critical limitations in current detection and mitigation strategies.</li>
</ul>

<h3>Title: Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation</h3>
<ul>
<li><strong>Authors: </strong>Qihe Pan, Yiming Wu, Xing Zhao, Liang Xie, Guodao Sun, Ronghua Liang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00729">https://arxiv.org/abs/2602.00729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00729">https://arxiv.org/pdf/2602.00729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00729]] Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation(https://arxiv.org/abs/2602.00729)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently shown strong progress in generative tasks, offering a more stable alternative to GAN-based approaches for makeup transfer. Existing methods often suffer from limited datasets, poor disentanglement between identity and makeup features, and weak controllability. To address these issues, we make three contributions. First, we construct a curated high-quality dataset using a train-generate-filter-retrain strategy that combines synthetic, realistic, and filtered samples to improve diversity and fidelity. Second, we design a diffusion-based framework that disentangles identity and makeup features, ensuring facial structure and skin tone are preserved while applying accurate and diverse cosmetic styles. Third, we propose a text-guided mechanism that allows fine-grained and region-specific control, enabling users to modify eyes, lips, or face makeup with natural language prompts. Experiments on benchmarks and real-world scenarios demonstrate improvements in fidelity, identity preservation, and flexibility. Examples of our dataset can be found at: this https URL.</li>
</ul>

<h3>Title: EchoReview: Learning Peer Review from the Echoes of Scientific Citations</h3>
<ul>
<li><strong>Authors: </strong>Yinuo Zhang, Dingcheng Huang, Haifeng Suo, Yizhuo Li, Ziya Zhao, Junhao Xu, Zhiying Tu, Dianhui Chu, Deming Zhai, Xianming Liu, Xiaoyan Yu, Dianbo Sui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00733">https://arxiv.org/abs/2602.00733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00733">https://arxiv.org/pdf/2602.00733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00733]] EchoReview: Learning Peer Review from the Echoes of Scientific Citations(https://arxiv.org/abs/2602.00733)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.</li>
</ul>

<h3>Title: Pareto-Conditioned Diffusion Models for Offline Multi-Objective Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jatan Shrestha, Santeri Heiskanen, Kari Hepola, Severi Rissanen, Pekka Jääskeläinen, Joni Pajarinen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00737">https://arxiv.org/abs/2602.00737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00737">https://arxiv.org/pdf/2602.00737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00737]] Pareto-Conditioned Diffusion Models for Offline Multi-Objective Optimization(https://arxiv.org/abs/2602.00737)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Multi-objective optimization (MOO) arises in many real-world applications where trade-offs between competing objectives must be carefully balanced. In the offline setting, where only a static dataset is available, the main challenge is generalizing beyond observed data. We introduce Pareto-Conditioned Diffusion (PCD), a novel framework that formulates offline MOO as a conditional sampling problem. By conditioning directly on desired trade-offs, PCD avoids the need for explicit surrogate models. To effectively explore the Pareto front, PCD employs a reweighting strategy that focuses on high-performing samples and a reference-direction mechanism to guide sampling towards novel, promising regions beyond the training data. Experiments on standard offline MOO benchmarks show that PCD achieves highly competitive performance and, importantly, demonstrates greater consistency across diverse tasks than existing offline MOO approaches.</li>
</ul>

<h3>Title: Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries</h3>
<ul>
<li><strong>Authors: </strong>Zhengyan Qin, Liyuan Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00739">https://arxiv.org/abs/2602.00739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00739">https://arxiv.org/pdf/2602.00739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00739]] Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries(https://arxiv.org/abs/2602.00739)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>We propose a diffusion-based algorithm for separating the inter and outer layer surfaces from double-layered point clouds, particularly those exhibiting the "double surface artifact" caused by truncation in Truncated Signed Distance Function (TSDF) fusion during indoor or medical 3D reconstruction. This artifact arises from asymmetric truncation thresholds, leading to erroneous inter and outer shells in the fused volume, which our method addresses by extracting the true inter layer to mitigate challenges like overlapping surfaces and disordered normals. We focus on point clouds with \emph{open boundaries} (i.e., sampled surfaces with topological openings/holes through which particles may escape), rather than point clouds with \emph{missing surface regions} where no samples exist. Our approach enables robust processing of both watertight and open-boundary models, achieving extraction of the inter layer from 20,000 inter and 20,000 outer points in approximately 10 seconds. This solution is particularly effective for applications requiring accurate surface representations, such as indoor scene modeling and medical imaging, where double-layered point clouds are prevalent, and it accommodates both closed (watertight) and open-boundary surface geometries. Our goal is \emph{post-hoc} inter/outer shell separation as a lightweight module after TSDF fusion; we do not aim to replace full variational or learning-based reconstruction pipelines.</li>
</ul>

<h3>Title: ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement</h3>
<ul>
<li><strong>Authors: </strong>Ziyan Xiao, Yinghao Zhu, Liang Peng, Lequan Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00740">https://arxiv.org/abs/2602.00740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00740">https://arxiv.org/pdf/2602.00740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00740]] ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement(https://arxiv.org/abs/2602.00740)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns "how to revise" rather than just "what to revise". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.</li>
</ul>

<h3>Title: CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Liang Wang, Xinyi Mou, Xiaoyou Liu, Xuanjing Huang, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00742">https://arxiv.org/abs/2602.00742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00742">https://arxiv.org/pdf/2602.00742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00742]] CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs(https://arxiv.org/abs/2602.00742)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>User modeling characterizes individuals through their preferences and behavioral patterns to enable personalized simulation and generation with Large Language Models (LLMs) in contemporary approaches. However, existing methods, whether prompt-based or training-based methods, face challenges in balancing personalization quality against computational and data efficiency. We propose a novel framework CURP, which employs a bidirectional user encoder and a discrete prototype codebook to extract multi-dimensional user traits. This design enables plug-and-play personalization with a small number of trainable parameters (about 20M parameters, about 0.2\% of the total model size). Through extensive experiments on variant generation tasks, we show that CURP achieves superior performance and generalization compared to strong baselines, while offering better interpretability and scalability. The code are available at this https URL</li>
</ul>

<h3>Title: Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Shengrui Li, Fei Zhao, Kaiyan Zhao, Jieying Ye, Haifeng Liu, Fangcheng Shi, Zheyong Xie, Yao Hu, Shaosheng Cao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00747">https://arxiv.org/abs/2602.00747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00747">https://arxiv.org/pdf/2602.00747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00747]] Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training(https://arxiv.org/abs/2602.00747)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at this https URL.</li>
</ul>

<h3>Title: HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression</h3>
<ul>
<li><strong>Authors: </strong>Xiangming Wang, Benteng Sun, Yungeng Liu, Haijin Zeng, Yongyong Chen, Jingyong Su, Jie Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00749">https://arxiv.org/abs/2602.00749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00749">https://arxiv.org/pdf/2602.00749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00749]] HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression(https://arxiv.org/abs/2602.00749)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Hyperspectral images (HSIs) capture richer spatial-spectral information beyond RGB, yet real-world HSIs often suffer from a composite mix of degradations, such as noise, blur, and missing bands. Existing generative approaches for HSI restoration like diffusion models require hundreds of iterative steps, making them computationally impractical for high-dimensional HSIs. While regression models tend to produce oversmoothed results, failing to preserve critical structural details. We break this impasse by introducing HSI-VAR, rethinking HSI restoration as an autoregressive generation problem, where spectral and spatial dependencies can be progressively modeled rather than globally reconstructed. HSI-VAR incorporates three key innovations: (1) Latent-condition alignment, which couples semantic consistency between latent priors and conditional embeddings for precise reconstruction; (2) Degradation-aware guidance, which uniquely encodes mixed degradations as linear combinations in the embedding space for automatic control, remarkably achieving a nearly $50\%$ reduction in computational cost at inference; (3) A spatial-spectral adaptation module that refines details across both domains in the decoding phase. Extensive experiments on nine all-in-one HSI restoration benchmarks confirm HSI-VAR's state-of-the-art performance, achieving a 3.77 dB PSNR improvement on \textbf{\textit{ICVL}} and offering superior structure preservation with an inference speed-up of up to $95.5 \times$ compared with diffusion-based methods, making it a highly practical solution for real-world HSI restoration.</li>
</ul>

<h3>Title: Bypassing Prompt Injection Detectors through Evasive Injections</h3>
<ul>
<li><strong>Authors: </strong>Md Jahedur Rahman, Ihsen Alouani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00750">https://arxiv.org/abs/2602.00750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00750">https://arxiv.org/pdf/2602.00750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00750]] Bypassing Prompt Injection Detectors through Evasive Injections(https://arxiv.org/abs/2602.00750)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used in interactive and retrieval-augmented systems, but they remain vulnerable to task drift; deviations from a user's intended instruction due to injected secondary prompts. Recent work has shown that linear probes trained on activation deltas of LLMs' hidden layers can effectively detect such drift. In this paper, we evaluate the robustness of these detectors against adversarially optimised suffixes. We generate universal suffixes that cause poisoned inputs to evade detection across multiple probes simultaneously. Our experiments on Phi-3 3.8B and Llama-3 8B show that a single suffix can achieve high attack success rates; up to 93.91% and 99.63%, respectively, when all probes must be fooled, and nearly perfect success (>90%) under majority vote setting. These results demonstrate that activation delta-based task drift detectors are highly vulnerable to adversarial suffixes, highlighting the need for stronger defences against adaptive attacks. We also propose a defence technique where we generate multiple suffixes and randomly append one of them to the prompts while making forward passes of the LLM and train logistic regression models with these activations. We found this approach to be highly effective against such attacks.</li>
</ul>

<h3>Title: GraphNNK -- Graph Classification and Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Zeljko Bolevic, Milos Brajovic, Isidora Stankovic, Ljubisa Stankovic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00753">https://arxiv.org/abs/2602.00753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00753">https://arxiv.org/pdf/2602.00753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00753]] GraphNNK -- Graph Classification and Interpretability(https://arxiv.org/abs/2602.00753)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have become a standard approach for learning from graph-structured data. However, their reliance on parametric classifiers (most often linear softmax layers) limits interpretability and sometimes hinders generalization. Recent work on interpolation-based methods, particularly Non-Negative Kernel regression (NNK), has demonstrated that predictions can be expressed as convex combinations of similar training examples in the embedding space, yielding both theoretical results and interpretable explanations.</li>
</ul>

<h3>Title: Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ali El Lahib, Ying-Jieh Xia, Zehan Li, Yuxuan Wang, Xinyu Pi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00758">https://arxiv.org/abs/2602.00758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00758">https://arxiv.org/pdf/2602.00758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00758]] Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting(https://arxiv.org/abs/2602.00758)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Search-engine date filters are widely used to enforce pre-cutoff retrieval in retrospective evaluations of search-augmented forecasters. We show this approach is unreliable: auditing Google Search with a before: filter, 71% of questions return at least one page containing strong post-cutoff leakage, and for 41%, at least one page directly reveals the answer. Using a large language model (LLM), gpt-oss-120b, to forecast with these leaky documents, we demonstrate an inflated prediction accuracy (Brier score 0.108 vs. 0.242 with leak-free documents). We characterize common leakage mechanisms, including updated articles, related-content modules, unreliable metadata/timestamps, and absence-based signals, and argue that date-restricted search is insufficient for temporal evaluation. We recommend stronger retrieval safeguards or evaluation on frozen, time-stamped web snapshots to ensure credible retrospective forecasting.</li>
</ul>

<h3>Title: Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhipeng Chen, Xiaobo Qin, Wayne Xin Zhao, Youbin Wu, Ji-Rong Wen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00759">https://arxiv.org/abs/2602.00759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00759">https://arxiv.org/pdf/2602.00759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00759]] Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning(https://arxiv.org/abs/2602.00759)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.</li>
</ul>

<h3>Title: WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yuheng Shao, Junjie Xiong, Chaoran Wu, Xiyuan Wang, Ziyu Zhou, Yang Ouyang, Qinyi Tao, Quan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00762">https://arxiv.org/abs/2602.00762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00762">https://arxiv.org/pdf/2602.00762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00762]] WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs(https://arxiv.org/abs/2602.00762)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.</li>
</ul>

<h3>Title: Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints</h3>
<ul>
<li><strong>Authors: </strong>Dylan Yves, Khush Agarwal, Jonathan Hoyin Chan, Patcharapit Promoppatum, Aroonkamon Pattanasiricharoen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00763">https://arxiv.org/abs/2602.00763</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00763">https://arxiv.org/pdf/2602.00763</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00763]] Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints(https://arxiv.org/abs/2602.00763)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate nerve localization is critical for the success of ultrasound-guided regional anesthesia, yet manual identification remains challenging due to low image contrast, speckle noise, and inter-patient anatomical variability. This study evaluates deep learning-based nerve segmentation in ultrasound images of the brachial plexus using a U-Net architecture, with a focus on how dataset composition and annotation strategy influence segmentation performance. We find that training on combined data from multiple ultrasound machines (SIEMENS ACUSON NX3 Elite and Philips EPIQ5) provides regularization benefits for lower-performing acquisition sources, though it does not surpass single-source training when matched to the target domain. Extending the task from binary nerve segmentation to multi-class supervision (artery, vein, nerve, muscle) results in decreased nerve-specific Dice scores, with performance drops ranging from 9% to 61% depending on dataset, likely due to class imbalance and boundary ambiguity. Additionally, we observe a moderate positive correlation between nerve size and segmentation accuracy (Pearson r=0.587, p<0.001), indicating that smaller nerves remain a primary challenge. These findings provide methodological guidance for developing robust ultrasound nerve segmentation systems under realistic clinical data constraints.</li>
</ul>

<h3>Title: Eliciting Trustworthiness Priors of Large Language Models via Economic Games</h3>
<ul>
<li><strong>Authors: </strong>Siyu Yan, Lusha Zhu, Jian-Qiao Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00769">https://arxiv.org/abs/2602.00769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00769">https://arxiv.org/pdf/2602.00769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00769]] Eliciting Trustworthiness Priors of Large Language Models via Economic Games(https://arxiv.org/abs/2602.00769)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.</li>
</ul>

<h3>Title: Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Zhang, Jialian Li, Yichi Zhang, Xiao Yang, Yinpeng Dong, Hang Su</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00770">https://arxiv.org/abs/2602.00770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00770">https://arxiv.org/pdf/2602.00770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00770]] Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models(https://arxiv.org/abs/2602.00770)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have achieved remarkable performance on reasoning tasks, motivating research into how this ability evolves during training. Prior work has primarily analyzed this evolution via explicit generation outcomes, treating the reasoning process as a black box and obscuring internal changes. To address this opacity, we introduce a representational perspective to investigate the dynamics of the model's internal states. Through comprehensive experiments across models at various training stages, we discover that post-training yields only limited improvement in static initial representation quality. Furthermore, we reveal that, distinct from non-reasoning tasks, reasoning involves a significant continuous distributional shift in representations during generation. Comparative analysis indicates that post-training empowers models to drive this transition toward a better distribution for task solving. To clarify the relationship between internal states and external outputs, statistical analysis confirms a high correlation between generation correctness and the final representations; while counterfactual experiments identify the semantics of the generated tokens, rather than additional computation during inference or intrinsic parameter differences, as the dominant driver of the transition. Collectively, we offer a novel understanding of the reasoning process and the effect of training on reasoning enhancement, providing valuable insights for future model analysis and optimization.</li>
</ul>

<h3>Title: Provable Model Provenance Set for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaoqi Qiu, Hao Zeng, Zhiyu Hou, Hongxin Wei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00772">https://arxiv.org/abs/2602.00772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00772">https://arxiv.org/pdf/2602.00772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00772]] Provable Model Provenance Set for Large Language Models(https://arxiv.org/abs/2602.00772)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing prevalence of unauthorized model usage and misattribution has increased the need for reliable model provenance analysis. However, existing methods largely rely on heuristic fingerprint-matching rules that lack provable error control and often overlook the existence of multiple sources, leaving the reliability of their provenance claims unverified. In this work, we first formalize the model provenance problem with provable guarantees, requiring rigorous coverage of all true provenances at a prescribed confidence level. Then, we propose the Model Provenance Set (MPS), which employs a sequential test-and-exclusion procedure to adaptively construct a small set satisfying the guarantee. The key idea of MPS is to test the significance of provenance existence within a candidate pool, thereby establishing a provable asymptotic guarantee at a user-specific confidence level. Extensive experiments demonstrate that MPS effectively achieves target provenance coverage while strictly limiting the inclusion of unrelated models, and further reveal its potential for practical provenance analysis in attribution and auditing tasks.</li>
</ul>

<h3>Title: A novel VAE-DML fusion framework for casual analysis of greenwashing in the mining industry</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Lu, Zhen Peng, Xiqiang Xia, Jie Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00774">https://arxiv.org/abs/2602.00774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00774">https://arxiv.org/pdf/2602.00774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00774]] A novel VAE-DML fusion framework for casual analysis of greenwashing in the mining industry(https://arxiv.org/abs/2602.00774)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Against the backdrop of the global green transition and "dual carbon" goals, mining industry chain enterprises are pivotal entities in terms of resource consumption and environmental impact. Their environmental performance directly affects regional ecological security and is closely tied to national resource strategies and green transformation outcomes. Ensuring the authenticity and reliability of their environmental disclosure is thus a core and urgent issue for sustainable development and national strategic this http URL a corporate governance perspective, this study examines equity balance as a fundamental governance mechanism, investigating its inhibitory effect on greenwashing behavior among these enterprises and the underlying pathways involved. Methodologically, the paper innovatively employs a Variational Autoencoder (VAE) and a Double Machine Learning (DML) model to construct counterfactual scenarios, mitigating endogeneity concerns and precisely identifying the causal relationship between equity balance and greenwashing. The findings indicate, first, a significant negative causal relationship between equity balance and corporate greenwashing, confirming its substantive governance effect. Second, this inhibitory effect exhibits notable heterogeneity, manifesting more strongly in western regions, upstream segments of the industrial chain, and industries with high environmental sensitivity. Third, the governance effect demonstrates clear temporal dynamics, with the strongest impact occurring in the current period, followed by a diminishing yet statistically significant lagged effect, and ultimately a stable long-term cumulative influence. Finally, mechanism analysis reveals that equity balance operates through three distinct channels to curb greenwashing: alleviating management performance pressure, enhancing the stability of the executive team, and intensifying media scrutiny.</li>
</ul>

<h3>Title: Stable Time Series Prediction of Enterprise Carbon Emissions Based on Causal Inference</h3>
<ul>
<li><strong>Authors: </strong>Zitao Hong, Zhen Peng, Xueping Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, econ.EM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00775">https://arxiv.org/abs/2602.00775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00775">https://arxiv.org/pdf/2602.00775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00775]] Stable Time Series Prediction of Enterprise Carbon Emissions Based on Causal Inference(https://arxiv.org/abs/2602.00775)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Against the backdrop of ongoing carbon peaking and carbon neutrality goals, accurate prediction of enterprise carbon emission trends constitutes an essential foundation for energy structure optimization and low-carbon transformation decision-making. Nevertheless, significant heterogeneity persists across regions, industries and individual enterprises regarding energy structure, production scale, policy intensity and governance efficacy, resulting in pronounced distribution shifts and non-stationarity in carbon emission data across both temporal and spatial dimensions. Such cross-regional and cross-enterprise data drift not only compromises the accuracy of carbon emission reporting but substantially undermines the guidance value of predictive models for production planning and carbon quota trading decisions. To address this critical challenge, we integrate causal inference perspectives with stable learning methodologies and time-series modelling, proposing a stable temporal prediction mechanism tailored to distribution shift environments. This mechanism incorporates enterprise-level energy inputs, capital investment, labour deployment, carbon pricing, governmental interventions and policy implementation intensity, constructing a risk consistency-constrained stable learning framework that extracts causal stable features (robust against external perturbations yet demonstrating long-term stable effects on carbon dioxide emissions) from multi-environment samples across diverse policies, regions and industrial sectors. Furthermore, through adaptive normalization and sample reweighting strategies, the approach dynamically rectifies temporal non-stationarity induced by economic fluctuations and policy transitions, ultimately enhancing model generalization capability and explainability in complex environments.</li>
</ul>

<h3>Title: HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference</h3>
<ul>
<li><strong>Authors: </strong>Xuan Ai, Qingqing Yang, Peng Wang, Lei Deng, Lin Zhang, Renhai Chen, Gong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00777">https://arxiv.org/abs/2602.00777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00777">https://arxiv.org/pdf/2602.00777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00777]] HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference(https://arxiv.org/abs/2602.00777)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often rely on rigid patterns or aggressive pruning, failing to achieve an optimal balance between efficiency and accuracy. In this paper, we introduce {\bf HyLRA} ({\bf Hy}brid {\bf L}ayer {\bf R}euse {\bf A}ttention), a novel framework driven by layer-wise sparsity profiling. Our empirical analysis uncovers a dual characteristic in attention mechanics: \textit{intra-layer sensitivity}, where specific layers necessitate full attention to prevent feature distortion, and \textit{inter-layer similarity}, where consecutive layers share substantial critical tokens. Based on these observations, HyLRA employs an offline dynamic programming approach to derive an optimal layer-wise policy. This hybrid strategy retains full attention for sensitive layers to ensure robustness, while enabling tolerant layers to bypass quadratic calculations by directly reusing top-$k$ indices from preceding layers. This approach allows LLMs to restrict computation to the most critical tokens, effectively overcoming the quadratic bottleneck of dense attention. Extensive evaluations demonstrate that HyLRA improves inference throughput by 6\%--46\% while maintaining comparable performance (with $<1\%$ accuracy degradation), consistently outperforming state-of-the-art sparse attention methods. HyLRA is open source at \href{this https URL}{\texttt{/r/unified-cache-management-CF80/}}</li>
</ul>

<h3>Title: Sporadic Gradient Tracking over Directed Graphs: A Theoretical Perspective on Decentralized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Shahryar Zehtabi, Dong-Jun Han, Seyyedali Hosseinalipour, Christopher Brinton</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00791">https://arxiv.org/abs/2602.00791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00791">https://arxiv.org/pdf/2602.00791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00791]] Sporadic Gradient Tracking over Directed Graphs: A Theoretical Perspective on Decentralized Federated Learning(https://arxiv.org/abs/2602.00791)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Decentralized Federated Learning (DFL) enables clients with local data to collaborate in a peer-to-peer manner to train a generalized model. In this paper, we unify two branches of work that have separately solved important challenges in DFL: (i) gradient tracking techniques for mitigating data heterogeneity and (ii) accounting for diverse availability of resources across clients. We propose $\textit{Sporadic Gradient Tracking}$ ($\texttt{Spod-GT}$), the first DFL algorithm that incorporates these factors over general directed graphs by allowing (i) client-specific gradient computation frequencies and (ii) heterogeneous and asymmetric communication frequencies. We conduct a rigorous convergence analysis of our methodology with relaxed assumptions on gradient estimation variance and gradient diversity of clients, providing consensus and optimality guarantees for GT over directed graphs despite intermittent client participation. Through numerical experiments on image classification datasets, we demonstrate the efficacy of $\texttt{Spod-GT}$ compared to well-known GT baselines.</li>
</ul>

<h3>Title: Latent Shadows: The Gaussian-Discrete Duality in Masked Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Guinan Chen, Xunpeng Huang, Ying Sun, Shijin Wang, Yanyong Zhang, Chao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00792">https://arxiv.org/abs/2602.00792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00792">https://arxiv.org/pdf/2602.00792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00792]] Latent Shadows: The Gaussian-Discrete Duality in Masked Diffusion(https://arxiv.org/abs/2602.00792)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Masked discrete diffusion is a dominant paradigm for high-quality language modeling where tokens are iteratively corrupted to a mask state, yet its inference efficiency is bottlenecked by the lack of deterministic sampling tools. While diffusion duality enables deterministic distillation for uniform models, these approaches generally underperform masked models and rely on complex integral operators. Conversely, in the masked domain, prior methods typically assume the absence of deterministic trajectories, forcing a reliance on stochastic distillation. To bridge this gap, we establish explicit Masked Diffusion Duality, proving that the masked process arises as the projection of a continuous Gaussian process via a novel maximum-value index preservation mechanism. Furthermore, we introduce Masked Consistency Distillation (MCD), a principled framework that leverages this duality to analytically construct the deterministic coupled trajectories required for consistency distillation, bypassing numerical ODE solvers. This result strictly improves upon prior stochastic distillation methods, achieving a 16$\times$ inference speedup without compromising generation quality. Our findings not only provide a solid theoretical foundation connecting masked and continuous diffusion, but also unlock the full potential of consistency distillation for high-performance discrete generation. Our code is available at this https URL.</li>
</ul>

<h3>Title: DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Li, Xianjing Meng, Qiangchang Wang, Zhongyi Han, Zhibin Wu, Yilong Yin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00795">https://arxiv.org/abs/2602.00795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00795">https://arxiv.org/pdf/2602.00795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00795]] DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning(https://arxiv.org/abs/2602.00795)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Few-shot learning (FSL) aims to generalize to novel categories with only a few samples. Recent approaches incorporate large language models (LLMs) to enrich visual representations with semantic embeddings derived from class names. However, they overlook progressive and adaptive alignment between vision and language from low-level to high-level semantics, resulting in limited semantic gains. To address these challenges, we propose Dual-level Vision-Language Alignment with Reinforcement Learning gating (DVLA-RL), which consists of Dual-level Semantic Construction (DSC) and RL-gated Attention (RLA). Specifically, DSC conditions LLMs on both class names and support samples to generate discriminative attributes, progressively selects the most relevant ones, and then synthesizes them into coherent class descriptions. This process provides complementary low-level attributes and high-level descriptions, enabling both fine-grained grounding and holistic class understanding. To dynamically integrate dual-level semantics along with the visual network layers, RLA formulates cross-modal fusion as a sequential decision process. A lightweight policy trained with episodic REINFORCE adaptively adjusts the contributions of self-attention and cross-attention to integrate textual and visual tokens. As a result, shallow layers refine local attributes and deep layers emphasize global semantics, enabling more precise cross-modal alignment. This achieves class-specific discrimination and generalized representations with merely a few support samples. DVLA-RL achieves new state-of-the-art performance across nine benchmarks in three diverse FSL scenarios.</li>
</ul>

<h3>Title: JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation</h3>
<ul>
<li><strong>Authors: </strong>Yebin Yang, Huaijin Wu, Fu Guo, Lin Yao, Xiaohan Qin, Jingzhi Wang, Debing Zhang, Junchi Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00800">https://arxiv.org/abs/2602.00800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00800">https://arxiv.org/pdf/2602.00800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00800]] JTok: On Token Embedding as another Axis of Scaling Law via Joint Token Self-modulation(https://arxiv.org/abs/2602.00800)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>LLMs have traditionally scaled along dense dimensions, where performance is coupled with near-linear increases in computational cost. While MoE decouples capacity from compute, it introduces large memory overhead and hardware efficiency challenges. To overcome these, we propose token-indexed parameters as a novel, orthogonal scaling axis that decouple model capacity from FLOPs. Specifically, we introduce Joint-Token (JTok) and Mixture of Joint-Token (JTok-M), which augment Transformer layers with modulation vectors retrieved from auxiliary embedding tables. These vectors modulate the backbone via lightweight, element-wise operations, incurring negligible FLOPs overhead. Extensive experiments on both dense and MoE backbones, spanning from 650M (190M + 460M embedding) to 61B (17B + 44B embedding) total parameters, demonstrate that our approach consistently reduces validation loss and significantly improves downstream task performance (e.g., +4.1 on MMLU, +8.3 on ARC, +8.9 on CEval). Rigorous isoFLOPs analysis further confirms that JTok-M fundamentally shifts the quality-compute Pareto frontier, achieving comparable model quality with 35% less compute relative to vanilla MoE architectures, and we validate that token-indexed parameters exhibit a predictable power-law scaling behavior. Moreover, our efficient implementation ensures that the overhead introduced by JTok and JTok-M remains marginal.</li>
</ul>

<h3>Title: Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Xianzhe Fan, Shengliang Deng, Xiaoyang Wu, Yuxiang Lu, Zhuoling Li, Mi Yan, Yujia Zhang, Zhizheng Zhang, He Wang, Hengshuang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00807">https://arxiv.org/abs/2602.00807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00807">https://arxiv.org/pdf/2602.00807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00807]] Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds(https://arxiv.org/abs/2602.00807)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing Vision-Language-Action (VLA) models typically take 2D images as visual input, which limits their spatial understanding in complex scenes. How can we incorporate 3D information to enhance VLA capabilities? We conduct a pilot study across different observation spaces and visual representations. The results show that explicitly lifting visual input into point clouds yields representations that better complement their corresponding 2D representations. To address the challenges of (1) scarce 3D data and (2) the domain gap induced by cross-environment differences and depth-scale biases, we propose Any3D-VLA. It unifies the simulator, sensor, and model-estimated point clouds within a training pipeline, constructs diverse inputs, and learns domain-agnostic 3D representations that are fused with the corresponding 2D representations. Simulation and real-world experiments demonstrate Any3D-VLA's advantages in improving performance and mitigating the domain gap. Our project homepage is available at this https URL.</li>
</ul>

<h3>Title: Mobile Exergames: Activity Recognition Based on Smartphone Sensors</h3>
<ul>
<li><strong>Authors: </strong>David Craveiro, Hugo Silva</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00809">https://arxiv.org/abs/2602.00809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00809">https://arxiv.org/pdf/2602.00809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00809]] Mobile Exergames: Activity Recognition Based on Smartphone Sensors(https://arxiv.org/abs/2602.00809)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Smartphone sensors can be extremely useful in providing information on the activities and behaviors of persons. Human activity recognition is increasingly used for games, medical, or surveillance. In this paper, we propose a proof-of-concept 2D endless game called Duck Catch & Fit, which implements a detailed activity recognition system that uses a smartphone accelerometer, gyroscope, and magnetometer sensors. The system applies feature extraction and learning mechanism to detect human activities like staying, side movements, and fake side movements. In addition, a voice recognition system is combined to recognize the word "fire" and raise the game's complexity. The results show that it is possible to use machine learning techniques to recognize human activity with high recognition levels. Also, the combination of movement-based and voice-based integrations contributes to a more immersive gameplay.</li>
</ul>

<h3>Title: Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Konstantinos Moutselos, Ilias Maglogiannis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00821">https://arxiv.org/abs/2602.00821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00821">https://arxiv.org/pdf/2602.00821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00821]] Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis(https://arxiv.org/abs/2602.00821)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, biometric, extraction, federate, transformer, generative</a></li>
<li><strong>Abstract: </strong>The deployment of Federated Learning (FL) for clinical dermatology is hindered by the competing requirements of protecting patient privacy and preserving diagnostic features. Traditional de-identification methods often degrade pathological fidelity, while standard generative editing techniques rely on computationally intensive inversion processes unsuitable for resource-constrained edge devices. We propose a framework for identity-agnostic pathology preservation that serves as a client-side privacy-preserving utility. By leveraging inversion-free Rectified Flow Transformers (FlowEdit), the system performs high-fidelity identity transformation in near real-time (less than 20s), facilitating local deployment on clinical nodes. We introduce a "Segment-by-Synthesis" mechanism that generates counterfactual healthy and pathological twin pairs locally. This enables the extraction of differential erythema masks that are decoupled from biometric markers and semantic artifacts (e.g. jewelry). Pilot validation on high-resolution clinical samples demonstrates an Intersection over Union (IoU) stability greater than 0.67 across synthetic identities. By generating privacy-compliant synthetic surrogates at the edge, this framework mitigates the risk of gradient leakage at the source, providing a secure pathway for high-precision skin image analysis in federated environments.</li>
</ul>

<h3>Title: TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation</h3>
<ul>
<li><strong>Authors: </strong>Mingwei Li, Hehe Fan, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00839">https://arxiv.org/abs/2602.00839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00839">https://arxiv.org/pdf/2602.00839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00839]] TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation(https://arxiv.org/abs/2602.00839)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Monocular normal estimation for transparent objects is critical for laboratory automation, yet it remains challenging due to complex light refraction and reflection. These optical properties often lead to catastrophic failures in conventional depth and normal sensors, hindering the deployment of embodied AI in scientific environments. We propose TransNormal, a novel framework that adapts pre-trained diffusion priors for single-step normal regression. To handle the lack of texture in transparent surfaces, TransNormal integrates dense visual semantics from DINOv3 via a cross-attention mechanism, providing strong geometric cues. Furthermore, we employ a multi-task learning objective and wavelet-based regularization to ensure the preservation of fine-grained structural details. To support this task, we introduce TransNormal-Synthetic, a physics-based dataset with high-fidelity normal maps for transparent labware. Extensive experiments demonstrate that TransNormal significantly outperforms state-of-the-art methods: on the ClearGrasp benchmark, it reduces mean error by 24.4% and improves 11.25° accuracy by 22.8%; on ClearPose, it achieves a 15.2% reduction in mean error. The code and dataset will be made publicly available at this https URL.</li>
</ul>

<h3>Title: Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Jintao Cheng, Weibin Li, Zhijian He, Jin Wu, Chi Man Vong, Wei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00841">https://arxiv.org/abs/2602.00841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00841">https://arxiv.org/pdf/2602.00841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00841]] Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition(https://arxiv.org/abs/2602.00841)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual Place Recognition (VPR) demands representations robust to drastic environmental and viewpoint shifts. Current aggregation paradigms, however, either rely on data-hungry supervision or simplistic first-order statistics, often neglecting intrinsic structural correlations. In this work, we propose a Second-Order Geometric Statistics framework that inherently captures geometric stability without training. We conceptualize scenes as covariance descriptors on the Symmetric Positive Definite (SPD) manifold, where perturbations manifest as tractable congruence transformations. By leveraging geometry-aware Riemannian mappings, we project these descriptors into a linearized Euclidean embedding, effectively decoupling signal structure from noise. Our approach introduces a training-free framework built upon fixed, pre-trained backbones, achieving strong zero-shot generalization without parameter updates. Extensive experiments confirm that our method achieves highly competitive performance against state-of-the-art baselines, particularly excelling in challenging zero-shot scenarios.</li>
</ul>

<h3>Title: Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Zicheng Kong, Dehua Ma, Zhenbo Xu, Alven Yang, Yiwei Ru, Haoran Wang, Zixuan Zhou, Fuqing Bie, Liuyu Xiang, Huijia Wu, Jian Zhao, Zhaofeng He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00846">https://arxiv.org/abs/2602.00846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00846">https://arxiv.org/pdf/2602.00846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00846]] Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis(https://arxiv.org/abs/2602.00846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have shown remarkable capabilities, yet their performance is often capped by the coarse nature of existing alignment techniques. A critical bottleneck remains the lack of effective reward models (RMs): existing RMs are predominantly vision-centric, return opaque scalar scores, and rely on costly human annotations. We introduce \textbf{Omni-RRM}, the first open-source rubric-grounded reward model that produces structured, multi-dimension preference judgments with dimension-wise justifications across \textbf{text, image, video, and audio}. At the core of our approach is \textbf{Omni-Preference}, a large-scale dataset built via a fully automated pipeline: we synthesize candidate response pairs by contrasting models of different capabilities, and use strong teacher models to \emph{reconcile and filter} preferences while providing a modality-aware \emph{rubric-grounded rationale} for each pair. This eliminates the need for human-labeled training preferences. Omni-RRM is trained in two stages: supervised fine-tuning to learn the rubric-grounded outputs, followed by reinforcement learning (GRPO) to sharpen discrimination on difficult, low-contrast pairs. Comprehensive evaluations show that Omni-RRM achieves state-of-the-art accuracy on video (80.2\% on ShareGPT-V) and audio (66.8\% on Audio-HH-RLHF) benchmarks, and substantially outperforms existing open-source RMs on image tasks, with a 17.7\% absolute gain over its base model on overall accuracy. Omni-RRM also improves downstream performance via Best-of-$N$ selection and transfers to text-only preference benchmarks. Our data, code, and models are available at this https URL.</li>
</ul>

<h3>Title: Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Gong, Yanda Chen, Julia Hirschberg, Chen Zhao, He He, Zhou Yu, Kathleen Mckeown</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00848">https://arxiv.org/abs/2602.00848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00848">https://arxiv.org/pdf/2602.00848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00848]] Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation(https://arxiv.org/abs/2602.00848)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.</li>
</ul>

<h3>Title: RMFlow: Refined Mean Flow by a Noise-Injection Step for Multimodal Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Huang, Shih-Hsin Wang, Andrea L. Bertozzi, Bao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00849">https://arxiv.org/abs/2602.00849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00849">https://arxiv.org/pdf/2602.00849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00849]] RMFlow: Refined Mean Flow by a Noise-Injection Step for Multimodal Generation(https://arxiv.org/abs/2602.00849)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Mean flow (MeanFlow) enables efficient, high-fidelity image generation, yet its single-function evaluation (1-NFE) generation often cannot yield compelling results. We address this issue by introducing RMFlow, an efficient multimodal generative model that integrates a coarse 1-NFE MeanFlow transport with a subsequent tailored noise-injection refinement step. RMFlow approximates the average velocity of the flow path using a neural network trained with a new loss function that balances minimizing the Wasserstein distance between probability paths and maximizing sample likelihood. RMFlow achieves near state-of-the-art results on text-to-image, context-to-molecule, and time-series generation using only 1-NFE, at a computational cost comparable to the baseline MeanFlows.</li>
</ul>

<h3>Title: Investigating the Robustness of Subtask Distillation under Spurious Correlation</h3>
<ul>
<li><strong>Authors: </strong>Pattarawat Chormai, Klaus-Robert Müller, Grégoire Montavon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00852">https://arxiv.org/abs/2602.00852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00852">https://arxiv.org/pdf/2602.00852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00852]] Investigating the Robustness of Subtask Distillation under Spurious Correlation(https://arxiv.org/abs/2602.00852)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Subtask distillation is an emerging paradigm in which compact, specialized models are extracted from large, general-purpose 'foundation models' for deployment in environments with limited resources or in standalone computer systems. Although distillation uses a teacher model, it still relies on a dataset that is often limited in size and may lack representativeness or exhibit spurious correlations. In this paper, we evaluate established distillation methods, as well as the recent SubDistill method, when using data with spurious correlations for distillation. As the strength of the correlations increases, we observe a widening gap between advanced methods, such as SubDistill, which remain fairly robust, and some baseline methods, which degrade to near-random performance. Overall, our study underscores the challenges of knowledge distillation when applied to imperfect, real-world datasets, particularly those with spurious correlations.</li>
</ul>

<h3>Title: Unifying Adversarial Robustness and Training Across Text Scoring Models</h3>
<ul>
<li><strong>Authors: </strong>Manveer Singh Tamber, Hosna Oyarhoseini, Jimmy Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00857">https://arxiv.org/abs/2602.00857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00857">https://arxiv.org/pdf/2602.00857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00857]] Unifying Adversarial Robustness and Training Across Text Scoring Models(https://arxiv.org/abs/2602.00857)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Research on adversarial robustness in language models is currently fragmented across applications and attacks, obscuring shared vulnerabilities. In this work, we propose unifying the study of adversarial robustness in text scoring models spanning dense retrievers, rerankers, and reward models. This motivates adapting both attacks and adversarial training methods across model roles. Unlike open-ended generation, text scoring failures are directly testable: an attack succeeds when an irrelevant or rejected text outscores a relevant or chosen one. Using this principled lens of text scoring, we demonstrate that current adversarial training formulations for language models are often short-sighted, failing to effectively generalize across attacks. To address this, we introduce multiple adversarial training methods for text scoring models and show that combining complementary training methods can yield strong robustness while also improving task effectiveness. We also highlight the practical value of our approach for RLHF, showing that our adversarially trained reward models mitigate reward hacking and support the training of better-aligned LLMs. We provide our code and models for further study.</li>
</ul>

<h3>Title: Improving Flow Matching by Aligning Flow Divergence</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Huang, Taos Transue, Shih-Hsin Wang, William Feldman, Hong Zhang, Bao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00869">https://arxiv.org/abs/2602.00869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00869">https://arxiv.org/pdf/2602.00869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00869]] Improving Flow Matching by Aligning Flow Divergence(https://arxiv.org/abs/2602.00869)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Conditional flow matching (CFM) stands out as an efficient, simulation-free approach for training flow-based generative models, achieving remarkable performance for data generation. However, CFM is insufficient to ensure accuracy in learning probability paths. In this paper, we introduce a new partial differential equation characterization for the error between the learned and exact probability paths, along with its solution. We show that the total variation gap between the two probability paths is bounded above by a combination of the CFM loss and an associated divergence loss. This theoretical insight leads to the design of a new objective function that simultaneously matches the flow and its divergence. Our new approach improves the performance of the flow-based generative model by a noticeable margin without sacrificing generation efficiency. We showcase the advantages of this enhanced training approach over CFM on several important benchmark tasks, including generative modeling for dynamical systems, DNA sequences, and videos. Code is available at \href{this https URL}{Utah-Math-Data-Science}.</li>
</ul>

<h3>Title: Dynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hao Mark Chen, Zhiwen Mo, Royson Lee, Qianzhou Wang, Da Li, Shell Xu Hu, Wayne Luk, Timothy Hospedales, Hongxiang Fan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00879">https://arxiv.org/abs/2602.00879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00879">https://arxiv.org/pdf/2602.00879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00879]] Dynamic Expert Sharing: Decoupling Memory from Parallelism in Mixture-of-Experts Diffusion LLMs(https://arxiv.org/abs/2602.00879)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Among parallel decoding paradigms, diffusion large language models (dLLMs) have emerged as a promising candidate that balances generation quality and throughput. However, their integration with Mixture-of-Experts (MoE) architectures is constrained by an expert explosion: as the number of tokens generated in parallel increases, the number of distinct experts activated grows nearly linearly. This results in substantial memory traffic that pushes inference into a memory-bound regime, negating the efficiency gains of both MoE and parallel decoding. To address this challenge, we propose Dynamic Expert Sharing (DES), a novel technique that shifts MoE optimization from token-centric pruning and conventional expert skipping methods to sequence-level coreset selection. To maximize expert reuse, DES identifies a compact, high-utility set of experts to satisfy the requirements of an entire parallel decoding block. We introduce two innovative selection strategies: (1) Intra-Sequence Sharing (DES-Seq), which adapts optimal allocation to the sequence level, and (2) Saliency-Aware Voting (DES-Vote), a novel mechanism that allows tokens to collectively elect a coreset based on aggregated router weights. Extensive experiments on MoE dLLMs demonstrate that DES reduces unique expert activations by over 55% and latency by up to 38%, while retaining 99% of vanilla accuracy, effectively decoupling memory overhead from the degree of parallelism.</li>
</ul>

<h3>Title: DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models</h3>
<ul>
<li><strong>Authors: </strong>Alicja Polowczyk, Agnieszka Polowczyk, Piotr Borycki, Joanna Waczyńska, Jacek Tabor, Przemysław Spurek</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00883">https://arxiv.org/abs/2602.00883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00883">https://arxiv.org/pdf/2602.00883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00883]] DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models(https://arxiv.org/abs/2602.00883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite impressive results from recent text-to-image models like FLUX, visual and anatomical artifacts remain a significant hurdle for practical and professional use. Existing methods for artifact reduction, typically work in a post-hoc manner, consequently failing to intervene effectively during the core image formation process. Notably, current techniques require problematic and invasive modifications to the model weights, or depend on a computationally expensive and time-consuming process of regional refinement. To address these limitations, we propose DIAMOND, a training-free method that applies trajectory correction to mitigate artifacts during inference. By reconstructing an estimate of the clean sample at every step of the generative trajectory, DIAMOND actively steers the generation process away from latent states that lead to artifacts. Furthermore, we extend the proposed method to standard Diffusion Models, demonstrating that DIAMOND provides a robust, zero-shot path to high-fidelity, artifact-free image synthesis without the need for additional training or weight modifications in modern generative architectures. Code is available at this https URL</li>
</ul>

<h3>Title: Reliability-Aware Determinantal Point Processes for Robust Informative Data Selection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Sarlak, Abolfazl Razi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00885">https://arxiv.org/abs/2602.00885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00885">https://arxiv.org/pdf/2602.00885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00885]] Reliability-Aware Determinantal Point Processes for Robust Informative Data Selection in Large Language Models(https://arxiv.org/abs/2602.00885)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Informative data selection is a key requirement for large language models (LLMs) to minimize the amount of data required for fine-tuning, network distillation, and token pruning, enabling fast and efficient deployment, especially under computational and communication constraints. Traditional subset selection methods, including those based on Determinantal Point Processes (DPP), focus on maximizing diversity but assume that selected data batches are always available error-free. This presumption prohibits their use under partial storage outage, imperfect communication, and stochastic access failures. Furthermore, we show that the original formulation collapses under such conditions. To address this gap, we introduce ProbDPP, a novel reliability-aware implementation of k-DPP that accounts for probabilistic data access by recasting the objective function with a regularization term that remains well-posed and decomposes into a geometric diversity term and unreliability cost. The resulting objective facilitates robust selection of diverse data batches under uncertainty. Furthermore, we frame this reliability-aware diversity maximization as a combinatorial semi-bandit problem and propose a UCB-style algorithm to efficiently learn the unknown reliability online. Theoretical analysis provides regret bounds for the proposed approach, ensuring performance guarantees.</li>
</ul>

<h3>Title: EffGen: Enabling Small Language Models as Capable Autonomous Agents</h3>
<ul>
<li><strong>Authors: </strong>Gaurav Srivastava, Aafiya Hussain, Chi Wang, Yingyan Celine Lin, Xuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00887">https://arxiv.org/abs/2602.00887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00887">https://arxiv.org/pdf/2602.00887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00887]] EffGen: Enabling Small Language Models as Capable Autonomous Agents(https://arxiv.org/abs/2602.00887)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (this https URL) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at this https URL.</li>
</ul>

<h3>Title: OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection</h3>
<ul>
<li><strong>Authors: </strong>Kunal Mahatha, Ali Bahri, Pierre Marza, Sahar Dastani, Maria Vakalopoulou, Stergios Christodoulidis, Jose Dolz, Christian Desrosiers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00904">https://arxiv.org/abs/2602.00904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00904">https://arxiv.org/pdf/2602.00904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00904]] OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection(https://arxiv.org/abs/2602.00904)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>State space models (SSMs) have recently emerged as an alternative to transformers due to their unique ability of modeling global relationships in text with linear complexity. However, their success in vision tasks has been limited due to their causal formulation, which is suitable for sequential text but detrimental in the spatial domain where causality breaks the inherent spatial relationships among pixels or patches. As a result, standard SSMs fail to capture local spatial coherence, often linking non-adjacent patches while ignoring neighboring ones that are visually correlated. To address these limitations, we introduce OCTOPUS , a novel architecture that preserves both global context and local spatial structure within images, while maintaining the linear complexity of SSMs. OCTOPUS performs discrete reoccurrence along eight principal orientations, going forward or backward in the horizontal, vertical, and diagonal directions, allowing effective information exchange across all spatially connected regions while maintaining independence among unrelated patches. This design enables multi-directional recurrence, capturing both global context and local spatial structure with SSM-level efficiency. In our classification and segmentation benchmarks, OCTOPUS demonstrates notable improvements in boundary preservation and region consistency, as evident from the segmentation results, while maintaining relatively better classification accuracy compared to existing V-SSM based models. These results suggest that OCTOPUS appears as a foundation method for multi-directional recurrence as a scalable and effective mechanism for building spatially aware and computationally efficient vision architectures.</li>
</ul>

<h3>Title: Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing</h3>
<ul>
<li><strong>Authors: </strong>Anxin Guo, Jingwei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DS, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00906">https://arxiv.org/abs/2602.00906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00906">https://arxiv.org/pdf/2602.00906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00906]] Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing(https://arxiv.org/abs/2602.00906)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models often hallucinate with high confidence on "random facts" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing this problem in the regime where facts are sparse in the universe of plausible claims, we establish a rate-distortion theorem: the optimal memory efficiency is characterized by the minimum KL divergence between score distributions on facts and non-facts. This theoretical framework provides a distinctive explanation for hallucination: even with optimal training, perfect data, and a simplified "closed world" setting, the information-theoretically optimal strategy under limited capacity is not to abstain or forget, but to assign high confidence to some non-facts, resulting in hallucination. We validate this theory empirically on synthetic data, showing that hallucinations persist as a natural consequence of lossy compression.</li>
</ul>

<h3>Title: PyGALAX: An Open-Source Python Toolkit for Advanced Explainable Geospatial Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Pingping Wang (1), Yihong Yuan (1), Lingcheng Li (2), Yongmei Lu (1) ((1) Department of Geography and Environmental Studies, Texas State University, USA, (2) Atmospheric, Climate, and Earth Sciences Division, Pacific Northwest National Laboratory, USA)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00907">https://arxiv.org/abs/2602.00907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00907">https://arxiv.org/pdf/2602.00907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00907]] PyGALAX: An Open-Source Python Toolkit for Advanced Explainable Geospatial Machine Learning(https://arxiv.org/abs/2602.00907)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>PyGALAX is a Python package for geospatial analysis that integrates automated machine learning (AutoML) and explainable artificial intelligence (XAI) techniques to analyze spatial heterogeneity in both regression and classification tasks. It automatically selects and optimizes machine learning models for different geographic locations and contexts while maintaining interpretability through SHAP (SHapley Additive exPlanations) analysis. PyGALAX builds upon and improves the GALAX framework (Geospatial Analysis Leveraging AutoML and eXplainable AI), which has proven to outperform traditional geographically weighted regression (GWR) methods. Critical enhancements in PyGALAX from the original GALAX framework include automatic bandwidth selection and flexible kernel function selection, providing greater flexibility and robustness for spatial modeling across diverse datasets and research questions. PyGALAX not only inherits all the functionalities of the original GALAX framework but also packages them into an accessible, reproducible, and easily deployable Python toolkit while providing additional options for spatial modeling. It effectively addresses spatial non-stationarity and generates transparent insights into complex spatial relationships at both global and local scales, making advanced geospatial machine learning methods accessible to researchers and practitioners in geography, urban planning, environmental science, and related fields.</li>
</ul>

<h3>Title: Efficient Deep Learning for Medical Imaging: Bridging the Gap Between High-Performance AI and Clinical Deployment</h3>
<ul>
<li><strong>Authors: </strong>Cuong Manh Nguyen, Truong-Son Hy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00910">https://arxiv.org/abs/2602.00910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00910">https://arxiv.org/pdf/2602.00910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00910]] Efficient Deep Learning for Medical Imaging: Bridging the Gap Between High-Performance AI and Clinical Deployment(https://arxiv.org/abs/2602.00910)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning has revolutionized medical image analysis, playing a vital role in modern clinical applications. However, the deployment of large-scale models in real-world clinical settings remains challenging due to high computational costs, latency constraints, and patient data privacy concerns associated with cloud-based processing. To address these bottlenecks, this review provides a comprehensive synthesis of efficient and lightweight deep learning architectures specifically tailored for the medical domain. We categorize the landscape of modern efficient models into three primary streams: Convolutional Neural Networks (CNNs), Lightweight Transformers, and emerging Linear Complexity Models. Furthermore, we examine key model compression strategies (including pruning, quantization, knowledge distillation, and low-rank factorization) and evaluate their efficacy in maintaining diagnostic performance while reducing hardware requirements. By identifying current limitations and discussing the transition toward on-device intelligence, this review serves as a roadmap for researchers and practitioners aiming to bridge the gap between high-performance AI and resource-constrained clinical environments.</li>
</ul>

<h3>Title: Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts</h3>
<ul>
<li><strong>Authors: </strong>Víctor Yeste, Paolo Rosso</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00913">https://arxiv.org/abs/2602.00913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00913">https://arxiv.org/pdf/2602.00913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00913]] Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts(https://arxiv.org/abs/2602.00913)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\rightarrow$HO$\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.</li>
</ul>

<h3>Title: A Baseline Multimodal Approach to Emotion Recognition in Conversations</h3>
<ul>
<li><strong>Authors: </strong>Víctor Yeste, Rodrigo Rivas-Arévalo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00914">https://arxiv.org/abs/2602.00914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00914">https://arxiv.org/pdf/2602.00914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00914]] A Baseline Multimodal Approach to Emotion Recognition in Conversations(https://arxiv.org/abs/2602.00914)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.</li>
</ul>

<h3>Title: Early Classification of Time Series in Non-Stationary Cost Regimes</h3>
<ul>
<li><strong>Authors: </strong>Aurélien Renault, Alexis Bondu, Antoine Cornuéjols, Vincent Lemaire</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00918">https://arxiv.org/abs/2602.00918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00918">https://arxiv.org/pdf/2602.00918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00918]] Early Classification of Time Series in Non-Stationary Cost Regimes(https://arxiv.org/abs/2602.00918)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Early Classification of Time Series (ECTS) addresses decision-making problems in which predictions must be made as early as possible while maintaining high accuracy. Most existing ECTS methods assume that the time-dependent decision costs governing the learning objective are known, fixed, and correctly specified. In practice, however, these costs are often uncertain and may change over time, leading to mismatches between training-time and deployment-time objectives. In this paper, we study ECTS under two practically relevant forms of cost non-stationarity: drift in the balance between misclassification and decision delay costs, and stochastic realizations of decision costs that deviate from the nominal training-time model. To address these challenges, we revisit representative ECTS approaches and adapt them to an online learning setting. Focusing on separable methods, we update only the triggering model during deployment, while keeping the classifier fixed. We propose several online adaptations and baselines, including bandit-based and RL-based approaches, and conduct controlled experiments on synthetic data to systematically evaluate robustness under cost non-stationarity. Our results demonstrate that online learning can effectively improve the robustness of ECTS methods to cost drift, with RL-based strategies exhibiting strong and stable performance across varying cost regimes.</li>
</ul>

<h3>Title: Beyond What Seems Necessary: Hidden Gains from Scaling Training-Time Reasoning Length under Outcome Supervision</h3>
<ul>
<li><strong>Authors: </strong>Yihao Xue, Allan Zhang, Jianhao Huang, Amit Sahai, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00927">https://arxiv.org/abs/2602.00927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00927">https://arxiv.org/pdf/2602.00927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00927]] Beyond What Seems Necessary: Hidden Gains from Scaling Training-Time Reasoning Length under Outcome Supervision(https://arxiv.org/abs/2602.00927)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Training LLMs to think and reason for longer has become a key ingredient in building state-of-the-art models that can solve complex problems previously out of reach. Recent efforts pursue this in different ways, such as RL fine-tuning to elicit long CoT or scaling latent reasoning through architectural recurrence. This makes reasoning length an important scaling knob. In this work, we identify a novel phenomenon (both theoretically and experimentally): under outcome-only supervision, out-of-distribution (OOD) performance can continue improving as training-time reasoning length (e.g., the token budget in RL, or the loop count in looped Transformers) increases, even after in-distribution (ID) performance has saturated. This suggests that robustness may require a larger budget than ID validation alone would indicate. We provide theoretical explanations via two mechanisms: (i) self-iteration can induce a stronger inductive bias in the hypothesis class, reshaping ID-optimal solutions in ways that improve OOD generalization; and (ii) when shortcut solutions that work for ID samples but not for OOD samples persist in the hypothesis class, regularization can reduce the learned solution's reliance on these shortcuts as the number of self-iterations increases. We complement the theory with empirical evidence from two realizations of scaling training-time reasoning length: increasing the number of loops in looped Transformers on a synthetic task, and increasing token budgets during RL fine-tuning of LLMs on mathematical reasoning.</li>
</ul>

<h3>Title: Continuous-Utility Direct Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal, Zihao He, Muhammad Usman Rafique, Asad Aali, Muhammad Ali Jamshed, John M. Cioffi, Emily Fox</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00931">https://arxiv.org/abs/2602.00931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00931">https://arxiv.org/pdf/2602.00931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00931]] Continuous-Utility Direct Preference Optimization(https://arxiv.org/abs/2602.00931)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model reasoning is often treated as a monolithic capability, relying on binary preference supervision that fails to capture partial progress or fine-grained reasoning quality. We introduce Continuous Utility Direct Preference Optimization (CU-DPO), a framework that aligns models to a portfolio of prompt-based cognitive strategies by replacing binary labels with continuous scores that capture fine-grained reasoning quality. We prove that learning with K strategies yields a Theta(K log K) improvement in sample complexity over binary preferences, and that DPO converges to the entropy-regularized utility-maximizing policy. To exploit this signal, we propose a two-stage training pipeline: (i) strategy selection, which optimizes the model to choose the best strategy for a given problem via best-vs-all comparisons, and (ii) execution refinement, which trains the model to correctly execute the selected strategy using margin-stratified pairs. On mathematical reasoning benchmarks, CU-DPO improves strategy selection accuracy from 35-46 percent to 68-78 percent across seven base models, yielding consistent downstream reasoning gains of up to 6.6 points on in-distribution datasets with effective transfer to out-of-distribution tasks.</li>
</ul>

<h3>Title: SALAAD: Sparse And Low-Rank Adaptation via ADMM</h3>
<ul>
<li><strong>Authors: </strong>Hao Ma, Melis Ilayda Bal, Liang Zhang, Bingcong Li, Niao He, Melanie Zeilinger, Michael Muehlebach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00942">https://arxiv.org/abs/2602.00942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00942">https://arxiv.org/pdf/2602.00942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00942]] SALAAD: Sparse And Low-Rank Adaptation via ADMM(https://arxiv.org/abs/2602.00942)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern large language models are increasingly deployed under compute and memory constraints, making flexible control of model capacity a central challenge. While sparse and low-rank structures naturally trade off capacity and performance, existing approaches often rely on heuristic designs that ignore layer and matrix heterogeneity or require model-specific architectural modifications. We propose SALAAD, a plug-and-play framework applicable to different model architectures that induces sparse and low-rank structures during training. By formulating structured weight learning under an augmented Lagrangian framework and introducing an adaptive controller that dynamically balances the training loss and structural constraints, SALAAD preserves the stability of standard training dynamics while enabling explicit control over the evolution of effective model capacity during training. Experiments across model scales show that SALAAD substantially reduces memory consumption during deployment while achieving performance comparable to ad-hoc methods. Moreover, a single training run yields a continuous spectrum of model capacities, enabling smooth and elastic deployment across diverse memory budgets without the need for retraining.</li>
</ul>

<h3>Title: Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images</h3>
<ul>
<li><strong>Authors: </strong>Xiang Zhang, Boxuan Zhang, Alireza Naghizadeh, Mohab Mohamed, Dongfang Liu, Ruixiang Tang, Dimitris Metaxas, Dongfang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00949">https://arxiv.org/abs/2602.00949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00949">https://arxiv.org/pdf/2602.00949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00949]] Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images(https://arxiv.org/abs/2602.00949)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Chimeric antigen receptor (CAR)-T and NK cell immunotherapies have transformed cancer treatment, and recent studies suggest that the quality of the CAR-T/NK cell immunological synapse (IS) may serve as a functional biomarker for predicting therapeutic efficacy. Accurate detection and segmentation of CAR-T/NK IS structures using artificial neural networks (ANNs) can greatly increase the speed and reliability of IS quantification. However, a persistent challenge is the limited size of annotated microscopy datasets, which restricts the ability of ANNs to generalize. To address this challenge, we integrate two complementary data-augmentation frameworks. First, we employ Instance Aware Automatic Augmentation (IAAA), an automated, instance-preserving augmentation method that generates synthetic CAR-T/NK IS images and corresponding segmentation masks by applying optimized augmentation policies to original IS data. IAAA supports multiple imaging modalities (e.g., fluorescence and brightfield) and can be applied directly to CAR-T/NK IS images derived from patient samples. In parallel, we introduce a Semantic-Aware AI Augmentation (SAAA) pipeline that combines a diffusion-based mask generator with a Pix2Pix conditional image synthesizer. This second method enables the creation of diverse, anatomically realistic segmentation masks and produces high-fidelity CAR-T/NK IS images aligned with those masks, further expanding the training corpus beyond what IAAA alone can provide. Together, these augmentation strategies generate synthetic images whose visual and structural properties closely match real IS data, significantly improving CAR-T/NK IS detection and segmentation performance. By enhancing the robustness and accuracy of IS quantification, this work supports the development of more reliable imaging-based biomarkers for predicting patient response to CAR-T/NK immunotherapy.</li>
</ul>

<h3>Title: Optimal Budgeted Adaptation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jing Wang, Jie Shen, Dean Foster, Zohar Karnin, Jeremy C Weiss</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00952">https://arxiv.org/abs/2602.00952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00952">https://arxiv.org/pdf/2602.00952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00952]] Optimal Budgeted Adaptation of Large Language Models(https://arxiv.org/abs/2602.00952)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The trade-off between labeled data availability and downstream accuracy remains a central challenge in fine-tuning large language models (LLMs). We propose a principled framework for \emph{budget-aware supervised fine-tuning} by casting LLM adaptation as a contextual Stackelberg game. In our formulation, the learner (leader) commits to a scoring policy and a label-querying strategy, while an adaptive environment (follower) selects challenging supervised alternatives in response. To explicitly address label efficiency, we incorporate a finite supervision budget directly into the learning objective. Our algorithm operates in the full-feedback regime and achieves $\tilde{O}(d\sqrt{T})$ regret under standard linear contextual assumptions. We extend the framework with a Largest-Latency-First (LLF) confidence gate that selectively queries labels, achieving a budget-aware regret bound of $\tilde{O}(\sqrt{dB} + c\sqrt{B})$ with $B=\beta T$.</li>
</ul>

<h3>Title: SAGE: Agentic Framework for Interpretable and Clinically Translatable Computational Pathology Biomarker Discovery</h3>
<ul>
<li><strong>Authors: </strong>Sahar Almahfouz Nasser, Juan Francisco Pesantez Borja, Jincheng Liu, Tanvir Hasan, Zenghan Wang, Suman Ghosh, Sandeep Manandhar, Shikhar Shiromani, Twisha Shah, Naoto Tokuyama, Anant Madabhushi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00953">https://arxiv.org/abs/2602.00953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00953">https://arxiv.org/pdf/2602.00953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00953]] SAGE: Agentic Framework for Interpretable and Clinically Translatable Computational Pathology Biomarker Discovery(https://arxiv.org/abs/2602.00953)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Despite significant progress in computational pathology, many AI models remain black-box and difficult to interpret, posing a major barrier to clinical adoption due to limited transparency and explainability. This has motivated continued interest in engineered image-based biomarkers, which offer greater interpretability but are often proposed based on anecdotal evidence or fragmented prior literature rather than systematic biological validation. We introduce SAGE (Structured Agentic system for hypothesis Generation and Evaluation), an agentic AI system designed to identify interpretable, engineered pathology biomarkers by grounding them in biological evidence. SAGE integrates literature-anchored reasoning with multimodal data analysis to correlate image-derived features with molecular biomarkers, such as gene expression, and clinically relevant outcomes. By coordinating specialized agents for biological contextualization and empirical hypothesis validation, SAGE prioritizes transparent, biologically supported biomarkers and advances the clinical translation of computational pathology.</li>
</ul>

<h3>Title: Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification</h3>
<ul>
<li><strong>Authors: </strong>Faisal Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00956">https://arxiv.org/abs/2602.00956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00956">https://arxiv.org/pdf/2602.00956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00956]] Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification(https://arxiv.org/abs/2602.00956)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Early and accurate diagnosis of Alzheimer's disease (AD) remains a critical challenge in neuroimaging-based clinical decision support systems. In this work, we propose a novel hybrid deep learning framework that integrates Topological Data Analysis (TDA) with a DenseNet121 backbone for four-class Alzheimer's disease classification using structural MRI data from the OASIS dataset. TDA is employed to capture complementary topological characteristics of brain structures that are often overlooked by conventional neural networks, while DenseNet121 efficiently learns hierarchical spatial features from MRI slices. The extracted deep and topological features are fused to enhance class separability across the four AD stages. Extensive experiments conducted on the OASIS-1 Kaggle MRI dataset demonstrate that the proposed TDA+DenseNet121 model significantly outperforms existing state-of-the-art approaches. The model achieves an accuracy of 99.93% and an AUC of 100%, surpassing recently published CNN-based, transfer learning, ensemble, and multi-scale architectures. These results confirm the effectiveness of incorporating topological insights into deep learning pipelines and highlight the potential of the proposed framework as a robust and highly accurate tool for automated Alzheimer's disease diagnosis.</li>
</ul>

<h3>Title: Probing the Knowledge Boundary: An Interactive Agentic Framework for Deep Knowledge Extraction</h3>
<ul>
<li><strong>Authors: </strong>Yuheng Yang, Siqi Zhu, Tao Feng, Ge Liu, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00959">https://arxiv.org/abs/2602.00959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00959">https://arxiv.org/pdf/2602.00959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00959]] Probing the Knowledge Boundary: An Interactive Agentic Framework for Deep Knowledge Extraction(https://arxiv.org/abs/2602.00959)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can be seen as compressed knowledge bases, but it remains unclear what knowledge they truly contain and how far their knowledge boundaries extend. Existing benchmarks are mostly static and provide limited support for systematic knowledge probing. In this paper, we propose an interactive agentic framework to systematically extract and quantify the knowledge of LLMs. Our method includes four adaptive exploration policies to probe knowledge at different granularities. To ensure the quality of extracted knowledge, we introduce a three-stage knowledge processing pipeline that combines vector-based filtering to remove exact duplicates, LLM-based adjudication to resolve ambiguous semantic overlaps, and domain-relevance auditing to retain valid knowledge units. Through extensive experiments, we find that recursive taxonomy is the most effective exploration strategy. We also observe a clear knowledge scaling law, where larger models consistently extract more knowledge. In addition, we identify a Pass@1-versus-Pass@k trade-off: domain-specialized models achieve higher initial accuracy but degrade rapidly, while general-purpose models maintain stable performance during extended extraction. Finally, our results show that differences in training data composition lead to distinct and measurable knowledge profiles across model families.</li>
</ul>

<h3>Title: Multimodal Scientific Learning Beyond Diffusions and Flows</h3>
<ul>
<li><strong>Authors: </strong>Leonardo Ferreira Guilhoto, Akshat Kaushal, Paris Perdikaris</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, stat.CO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00960">https://arxiv.org/abs/2602.00960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00960">https://arxiv.org/pdf/2602.00960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00960]] Multimodal Scientific Learning Beyond Diffusions and Flows(https://arxiv.org/abs/2602.00960)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Scientific machine learning (SciML) increasingly requires models that capture multimodal conditional uncertainty arising from ill-posed inverse problems, multistability, and chaotic dynamics. While recent work has favored highly expressive implicit generative models such as diffusion and flow-based methods, these approaches are often data-hungry, computationally costly, and misaligned with the structured solution spaces frequently found in scientific problems. We demonstrate that Mixture Density Networks (MDNs) provide a principled yet largely overlooked alternative for multimodal uncertainty quantification in SciML. As explicit parametric density estimators, MDNs impose an inductive bias tailored to low-dimensional, multimodal physics, enabling direct global allocation of probability mass across distinct solution branches. This structure delivers strong data efficiency, allowing reliable recovery of separated modes in regimes where scientific data is scarce. We formalize these insights through a unified probabilistic framework contrasting explicit and implicit distribution networks, and demonstrate empirically that MDNs achieve superior generalization, interpretability, and sample efficiency across a range of inverse, multistable, and chaotic scientific regression tasks.</li>
</ul>

<h3>Title: On the Spectral Flattening of Quantized Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Junlin Huang, Wenyi Fang, Zhenheng Tang, Yuxin Wang, Xueze Kang, Yang Zheng, Bo Li, Xiaowen Chu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00969">https://arxiv.org/abs/2602.00969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00969">https://arxiv.org/pdf/2602.00969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00969]] On the Spectral Flattening of Quantized Embeddings(https://arxiv.org/abs/2602.00969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) at ultra-low precision is critically impeded by instability rooted in the conflict between discrete quantization constraints and the intrinsic heavy-tailed spectral nature of linguistic data. By formalizing the connection between Zipfian statistics and random matrix theory, we prove that the power-law decay in the singular value spectra of embeddings is a fundamental requisite for semantic encoding. We derive theoretical bounds showing that uniform quantization introduces a noise floor that disproportionately truncates this spectral tail, which induces spectral flattening and a strictly provable increase in the stable rank of representations. Empirical validation across diverse architectures including GPT-2 and TinyLlama corroborates that this geometric degradation precipitates representational collapse. This work not only quantifies the spectral sensitivity of LLMs but also establishes spectral fidelity as a necessary condition for stable low-bit optimization.</li>
</ul>

<h3>Title: Verification Required: The Impact of Information Credibility on AI Persuasion</h3>
<ul>
<li><strong>Authors: </strong>Saaduddin Mahmud, Eugene Bagdasarian, Shlomo Zilberstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00970">https://arxiv.org/abs/2602.00970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00970">https://arxiv.org/pdf/2602.00970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00970]] Verification Required: The Impact of Information Credibility on AI Persuasion(https://arxiv.org/abs/2602.00970)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.</li>
</ul>

<h3>Title: Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Meng Luo, Bobo Li, Shanqing Xu, Shize Zhang, Qiuchan Chen, Menglu Han, Wenhao Chen, Yanxiang Huang, Hao Fei, Mong-Li Lee, Wynne Hsu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00971">https://arxiv.org/abs/2602.00971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00971">https://arxiv.org/pdf/2602.00971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00971]] Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning(https://arxiv.org/abs/2602.00971)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite rapid progress in multimodal large language models (MLLMs), their capability for deep emotional understanding remains limited. We argue that genuine affective intelligence requires explicit modeling of Theory of Mind (ToM), the cognitive substrate from which emotions arise. To this end, we introduce HitEmotion, a ToM-grounded hierarchical benchmark that diagnoses capability breakpoints across increasing levels of cognitive depth. Second, we propose a ToM-guided reasoning chain that tracks mental states and calibrates cross-modal evidence to achieve faithful emotional reasoning. We further introduce TMPO, a reinforcement learning method that uses intermediate mental states as process-level supervision to guide and strengthen model reasoning. Extensive experiments show that HitEmotion exposes deep emotional reasoning deficits in state-of-the-art models, especially on cognitively demanding tasks. In evaluation, the ToM-guided reasoning chain and TMPO improve end-task accuracy and yield more faithful, more coherent rationales. In conclusion, our work provides the research community with a practical toolkit for evaluating and enhancing the cognition-based emotional understanding capabilities of MLLMs. Our dataset and code are available at: this https URL.</li>
</ul>

<h3>Title: Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals</h3>
<ul>
<li><strong>Authors: </strong>Pengyue Yang, Jiawen Wen, Haolin Jin, Linghan Huang, Huaming Chen, Ling Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00977">https://arxiv.org/abs/2602.00977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00977">https://arxiv.org/pdf/2602.00977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00977]] Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals(https://arxiv.org/abs/2602.00977)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in domains where errors carry high social, scientific, or safety costs. Yet standard confidence estimators, such as token likelihood, semantic similarity and multi-sample consistency, remain brittle under distribution shift, domain-specialised text, and compute limits. In this work, we present Structural Confidence, a single-pass, model-agnostic framework that enhances output correctness prediction based on multi-scale structural signals derived from a model's final-layer hidden-state trajectory. By combining spectral, local-variation, and global shape descriptors, our method captures internal stability patterns that are missed by probabilities and sentence embeddings. We conduct extensive, cross-domain evaluation across four heterogeneous benchmarks-FEVER (fact verification), SciFact (scientific claims), WikiBio-hallucination (biographical consistency), and TruthfulQA (truthfulness-oriented QA). Our Structural Confidence framework demonstrates strong performance compared with established baselines in terms of AUROC and AUPR. More importantly, unlike sampling-based consistency methods which require multiple stochastic generations and an auxiliary model, our approach uses a single deterministic forward pass, offering a practical basis for efficient, robust post-hoc confidence estimation in socially impactful, resource-constrained LLM applications.</li>
</ul>

<h3>Title: GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability</h3>
<ul>
<li><strong>Authors: </strong>Xueyi Li, Zhuoneng Zhou, Zitao Liu, Yongdong Wu, Weiqi Luo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00979">https://arxiv.org/abs/2602.00979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00979">https://arxiv.org/pdf/2602.00979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00979]] GradingAttack: Attacking Large Language Models Towards Short Answer Grading Ability(https://arxiv.org/abs/2602.00979)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable potential for automatic short answer grading (ASAG), significantly boosting student assessment efficiency and scalability in educational scenarios. However, their vulnerability to adversarial manipulation raises critical concerns about automatic grading fairness and reliability. In this paper, we introduce GradingAttack, a fine-grained adversarial attack framework that systematically evaluates the vulnerability of LLM based ASAG models. Specifically, we align general-purpose attack methods with the specific objectives of ASAG by designing token-level and prompt-level strategies that manipulate grading outcomes while maintaining high camouflage. Furthermore, to quantify attack camouflage, we propose a novel evaluation metric that balances attack success and camouflage. Experiments on multiple datasets demonstrate that both attack strategies effectively mislead grading models, with prompt-level attacks achieving higher success rates and token-level attacks exhibiting superior camouflage capability. Our findings underscore the need for robust defenses to ensure fairness and reliability in ASAG. Our code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025</h3>
<ul>
<li><strong>Authors: </strong>Phu-Hoa Pham, Chi-Nguyen Tran, Dao Sy Duy Minh, Nguyen Lam Phu Quy, Huynh Trung Kiet</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.NE, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00982">https://arxiv.org/abs/2602.00982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00982">https://arxiv.org/pdf/2602.00982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00982]] Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025(https://arxiv.org/abs/2602.00982)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.</li>
</ul>

<h3>Title: DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Batuhan K. Karaman, Aditya Rawal, Suhaila Shakiah, Mohammad Ghavamzadeh, Mingyi Hong, Arijit Biswas, Ruida Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00983">https://arxiv.org/abs/2602.00983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00983">https://arxiv.org/pdf/2602.00983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00983]] DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning(https://arxiv.org/abs/2602.00983)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.</li>
</ul>

<h3>Title: Sparse Reward Subsystem in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guowei Xu, Mert Yuksekgonul, James Zou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00986">https://arxiv.org/abs/2602.00986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00986">https://arxiv.org/pdf/2602.00986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00986]] Sparse Reward Subsystem in Large Language Models(https://arxiv.org/abs/2602.00986)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.</li>
</ul>

<h3>Title: DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework</h3>
<ul>
<li><strong>Authors: </strong>Abhijit Chakraborty, Ashish Raj Shekhar, Shiven Agarwal, Vivek Gupta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00996">https://arxiv.org/abs/2602.00996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00996">https://arxiv.org/pdf/2602.00996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00996]] DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework(https://arxiv.org/abs/2602.00996)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.</li>
</ul>

<h3>Title: Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhikun Xu, Xiaodong Yu, Ben Zhou, Jiang Liu, Jialian Wu, Ze Wang, Ximeng Sun, Hao Chen, Zicheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.00998">https://arxiv.org/abs/2602.00998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.00998">https://arxiv.org/pdf/2602.00998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.00998]] Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning(https://arxiv.org/abs/2602.00998)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) perform strongly on mathematical benchmarks yet often misapply lemmas, importing conclusions without validating assumptions. We formalize lemma$-$judging as a structured prediction task: given a statement and a candidate lemma, the model must output a precondition check and a conclusion$-$utility check, from which a usefulness decision is derived. We present RULES, which encodes this specification via a two$-$section output and trains with reinforcement learning plus section$-$aware loss masking to assign penalty to the section responsible for errors. Training and evaluation draw on diverse natural language and formal proof corpora; robustness is assessed with a held$-$out perturbation suite; and end$-$to$-$end evaluation spans competition$-$style, perturbation$-$aligned, and theorem$-$based problems across various LLMs. Results show consistent in$-$domain gains over both a vanilla model and a single$-$label RL baseline, larger improvements on applicability$-$breaking perturbations, and parity or modest gains on end$-$to$-$end tasks; ablations indicate that the two$-$section outputs and section$-$aware reinforcement are both necessary for robustness.</li>
</ul>

<h3>Title: CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound</h3>
<ul>
<li><strong>Authors: </strong>Vagish Kumar, Souvik Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01000">https://arxiv.org/abs/2602.01000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01000">https://arxiv.org/pdf/2602.01000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01000]] CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound(https://arxiv.org/abs/2602.01000)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.</li>
</ul>

<h3>Title: ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhishen Sun, Sizhe Dang, Guang Dai, Haishan Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01003">https://arxiv.org/abs/2602.01003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01003">https://arxiv.org/pdf/2602.01003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01003]] ESSAM: A Novel Competitive Evolution Strategies Approach to Reinforcement Learning for Memory Efficient LLMs Fine-Tuning(https://arxiv.org/abs/2602.01003)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has become a key training step for improving mathematical reasoning in large language models (LLMs), but it often has high GPU memory usage, which makes it hard to use in settings with limited resources. To reduce these issues, we propose Evolution Strategies with Sharpness-Aware Maximization (ESSAM), a full parameter fine-tuning framework that tightly combines the zero-order search in parameter space from Evolution Strategies (ES) with the Sharpness-Aware Maximization (SAM) to improve generalization. We conduct fine-tuning experiments on the mainstream mathematica reasoning task GSM8K. The results show that ESSAM achieves an average accuracy of 78.27\% across all models and its overall performance is comparable to RL methods. It surpasses classic RL algorithm PPO with an accuracy of 77.72\% and is comparable to GRPO with an accuracy of 78.34\%, and even surpassing them on some models. In terms of GPU memory usage, ESSAM reduces the average GPU memory usage by $18\times$ compared to PPO and by $10\times$ compared to GRPO, achieving an extremely low GPU memory usage.</li>
</ul>

<h3>Title: SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning</h3>
<ul>
<li><strong>Authors: </strong>Zihao Zhao, Shengting Cao, Muchao Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01004">https://arxiv.org/abs/2602.01004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01004">https://arxiv.org/pdf/2602.01004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01004]] SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning(https://arxiv.org/abs/2602.01004)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) have demonstrated significant progress in reasoning capabilities and shown promising effectiveness in video anomaly understanding (VAU) tasks. However, existing MLLM-based approaches remain largely focused on surface-level descriptions of anomalies, lacking deep reasoning over abnormal behaviors like explicit self-reflection and self-correction. To address that, we propose Self-Reflection-Enhanced Reasoning for Video Anomaly Understanding (SRVAU-R1), a reflection-aware learning framework that incorporates reflection in MLLM reasoning. Specifically, SRVAU-R1 introduces the first reflection-oriented Chain-of-Thought dataset tailored for VAU, providing structured supervision with initial reasoning, self-reflection, and revised reasoning. Based on that, it includes a novel reflection-aware learning paradigm with supervised fine-tuning and reinforcement fine-tuning to enhance multi-modal reasoning for VAU. Extensive experiments on multiple video anomaly benchmarks demonstrate that SRVAU-R1 consistently outperforms existing methods, achieving significant improvements in both temporal anomaly localization accuracy and reasoning quality.</li>
</ul>

<h3>Title: LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems</h3>
<ul>
<li><strong>Authors: </strong>Haoran Li, Chenhan Xiao, Lihao Mai, Yang Weng, Erik Blasch</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01009">https://arxiv.org/abs/2602.01009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01009">https://arxiv.org/pdf/2602.01009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01009]] LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems(https://arxiv.org/abs/2602.01009)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Foundation models have transformed language, vision, and time series data analysis, yet progress on dynamic predictions for physical systems remains limited. Given the complexity of physical constraints, two challenges stand out. $(i)$ Physics-computation scalability: physics-informed learning can enforce physical regularization, but its computation (e.g., ODE integration) does not scale to extensive systems. $(ii)$ Knowledge-sharing efficiency: the attention mechanism is primarily computed within each system, which limits the extraction of shared ODE structures across systems. We show that enforcing ODE consistency does not require expensive nonlinear integration: a token-wise locally linear ODE representation preserves physical fidelity while scaling to foundation-model regimes. Thus, we propose novel token representations that respect locally linear ODE evolution. Such linearity substantially accelerates integration while accurately approximating the local data manifold. Second, we introduce a simple yet effective inter-system attention that augments attention with a common structure hub (CSH) that stores shared tokens and aggregates knowledge across systems. The resulting model, termed LASS-ODE (\underline{LA}rge-\underline{S}cale \underline{S}mall \underline{ODE}), is pretrained on our $40$GB ODE trajectory collections to enable strong in-domain performance, zero-shot generalization across diverse ODE systems, and additional improvements through fine-tuning.</li>
</ul>

<h3>Title: LocalScore: Local Density-Aware Similarity Scoring for Biometrics</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Su, Minchul Kim, Jie Zhu, Christopher Perry, Feng Liu, Anil Jain, Xiaoming Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01012">https://arxiv.org/abs/2602.01012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01012">https://arxiv.org/pdf/2602.01012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01012]] LocalScore: Local Density-Aware Similarity Scoring for Biometrics(https://arxiv.org/abs/2602.01012)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>Open-set biometrics faces challenges with probe subjects who may not be enrolled in the gallery, as traditional biometric systems struggle to detect these non-mated probes. Despite the growing prevalence of multi-sample galleries in real-world deployments, most existing methods collapse intra-subject variability into a single global representation, leading to suboptimal decision boundaries and poor open-set robustness. To address this issue, we propose LocalScore, a simple yet effective scoring algorithm that explicitly incorporates the local density of the gallery feature distribution using the k-th nearest neighbors. LocalScore is architecture-agnostic, loss-independent, and incurs negligible computational overhead, making it a plug-and-play solution for existing biometric systems. Extensive experiments across multiple modalities demonstrate that LocalScore consistently achieves substantial gains in open-set retrieval (FNIR@FPIR reduced from 53% to 40%) and verification (TAR@FAR improved from 51% to 74%). We further provide theoretical analysis and empirical validation explaining when and why the method achieves the most significant gains based on dataset characteristics.</li>
</ul>

<h3>Title: Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident</h3>
<ul>
<li><strong>Authors: </strong>Conrad Borchers, Jill-Jênn Vie, Roger Azevedo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01015">https://arxiv.org/abs/2602.01015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01015">https://arxiv.org/pdf/2602.01015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01015]] Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident(https://arxiv.org/abs/2602.01015)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly embedded in AI-based tutoring systems. Can they faithfully model novice reasoning and metacognitive judgments? Existing evaluations emphasize problem-solving accuracy, overlooking the fragmented and imperfect reasoning that characterizes human learning. We evaluate LLMs as novices using 630 think-aloud utterances from multi-step chemistry tutoring problems with problem-solving logs of student hint use, attempts, and problem context. We compare LLM-generated reasoning to human learner utterances under minimal and extended contextual prompting, and assess the models' ability to predict step-level learner success. Although GPT-4.1 generates fluent and contextually appropriate continuations, its reasoning is systematically over-coherent, verbose, and less variable than human think-alouds. These effects intensify with a richer problem-solving context during prompting. Learner performance was consistently overestimated. These findings highlight epistemic limitations of simulating learning with LLMs. We attribute these limitations to LLM training data, including expert-like solutions devoid of expressions of affect and working memory constraints during problem solving. Our evaluation framework can guide future design of adaptive systems that more faithfully support novice learning and self-regulation using generative artificial intelligence.</li>
</ul>

<h3>Title: How Does Unfaithful Reasoning Emerge from Autoregressive Training? A Study of Synthetic Experiments</h3>
<ul>
<li><strong>Authors: </strong>Fuxin Wang, Amr Alazali, Yiqiao Zhong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01017">https://arxiv.org/abs/2602.01017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01017">https://arxiv.org/pdf/2602.01017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01017]] How Does Unfaithful Reasoning Emerge from Autoregressive Training? A Study of Synthetic Experiments(https://arxiv.org/abs/2602.01017)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-thought (CoT) reasoning generated by large language models (LLMs) is often unfaithful: intermediate steps can be logically inconsistent or fail to reflect the causal relationship leading to the final answer. Despite extensive empirical observations, a fundamental understanding of CoT is lacking--what constitutes faithful CoT reasoning, and how unfaithfulness emerges from autoregressive training. We study these questions using well-controlled synthetic experiments, training small transformers on noisy data to solve modular arithmetic expressions step by step, a task we term Arithmetic Expression Reasoning. We find that models can learn faithful reasoning that causally follows the underlying arithmetic rules, but only when the training noise is below a critical threshold, a phenomenon attributable to simplicity bias. At higher noise levels, training dynamics exhibit a transition from faithful stepwise reasoning to unfaithful skip-step reasoning via an intermediate mixed mode characterized by a transient increase in prediction entropy. Mechanistic analysis reveals that models learn to encode internal uncertainty by resolving inconsistent reasoning steps, which suggests the emergence of implicit self-verification from autoregressive training.</li>
</ul>

<h3>Title: Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kaiyuan Cui, Yige Li, Yutao Wu, Xingjun Ma, Sarah Erfani, Christopher Leckie, Hanxun Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01025">https://arxiv.org/abs/2602.01025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01025">https://arxiv.org/pdf/2602.01025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01025]] Toward Universal and Transferable Jailbreak Attacks on Vision-Language Models(https://arxiv.org/abs/2602.01025)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) extend large language models (LLMs) with vision encoders, enabling text generation conditioned on both images and text. However, this multimodal integration expands the attack surface by exposing the model to image-based jailbreaks crafted to induce harmful responses. Existing gradient-based jailbreak methods transfer poorly, as adversarial patterns overfit to a single white-box surrogate and fail to generalise to black-box models. In this work, we propose Universal and transferable jailbreak (UltraBreak), a framework that constrains adversarial patterns through transformations and regularisation in the vision space, while relaxing textual targets through semantic-based objectives. By defining its loss in the textual embedding space of the target LLM, UltraBreak discovers universal adversarial patterns that generalise across diverse jailbreak objectives. This combination of vision-level regularisation and semantically guided textual supervision mitigates surrogate overfitting and enables strong transferability across both models and attack targets. Extensive experiments show that UltraBreak consistently outperforms prior jailbreak methods. Further analysis reveals why earlier approaches fail to transfer, highlighting that smoothing the loss landscape via semantic objectives is crucial for enabling universal and transferable jailbreaks. The code is publicly available in our \href{this https URL}{GitHub repository}.</li>
</ul>

<h3>Title: SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xin Nie, Haicheng Zhang, Liang Dong, Beining Feng, Jinhong Weng, Guiling Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01027">https://arxiv.org/abs/2602.01027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01027">https://arxiv.org/pdf/2602.01027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01027]] SFMP: Fine-Grained, Hardware-Friendly and Search-Free Mixed-Precision Quantization for Large Language Models(https://arxiv.org/abs/2602.01027)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixed-precision quantization is a promising approach for compressing large language models under tight memory budgets. However, existing mixed-precision methods typically suffer from one of two limitations: they either rely on expensive discrete optimization to determine precision allocation, or introduce hardware inefficiencies due to irregular memory layouts. We propose SFMP, a search-free and hardware-friendly mixed-precision quantization framework for large language models. The framework is built upon four novel ideas: Fractional bit-width, which extends integer bit-width for weight matrix to fractional value and transforms discrete precision allocation as a continuous problem; 2)Block-wise mixed-precision, enabling fine-grained precision within weight matrices while remaining hardware-friendly; 3)Row-column weight reordering, which aggregates salient weights via row and column reordering, incurring only a small activation reordering overhead during inference; 4)Unified GEMM kernel, which supports mixed-precision GEMM at arbitrary average bit-width. Extensive experiments demonstrate that SFMP outperforms state-of-the-art layer-wise mixed-precision methods under the same memory constraints, while significantly reducing quantization cost and improving inference efficiency. Code is available at this https URL</li>
</ul>

<h3>Title: Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations</h3>
<ul>
<li><strong>Authors: </strong>Sheng-Lun Wei, Yu-Ling Liao, Yen-Hua Chang, Hen-Hsen Huang, Hsin-Hsi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01030">https://arxiv.org/abs/2602.01030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01030">https://arxiv.org/pdf/2602.01030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01030]] Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations(https://arxiv.org/abs/2602.01030)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $\kappa$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at this https URL.</li>
</ul>

<h3>Title: GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration</h3>
<ul>
<li><strong>Authors: </strong>Chentian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01033">https://arxiv.org/abs/2602.01033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01033">https://arxiv.org/pdf/2602.01033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01033]] GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration(https://arxiv.org/abs/2602.01033)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automatic calibration of multi-camera systems, namely the accurate estimation of spatial extrinsic parameters, is fundamental for 3D reconstruction, panoramic perception, and multi-view data fusion. Existing methods typically rely on calibration targets, explicit geometric modeling, or task-specific neural networks. Such approaches often exhibit limited robustness and applicability in complex dynamic environments or online scenarios, making them difficult to deploy in practical applications. To address this, this paper proposes GMAC, a multi-camera extrinsic estimation framework based on the implicit geometric representations learned by multi-view reconstruction networks. GMAC models extrinsics as global variables constrained by the latent multi-view geometric structure and prunes and structurally reconfigures existing networks so that their latent features can directly support extrinsic prediction through a lightweight regression head, without requiring a completely new network design. Furthermore, GMAC jointly optimizes cross-view reprojection consistency and multi-view cycle consistency, ensuring geometric coherence across cameras while improving prediction accuracy and optimization stability. Experiments on both synthetic and real-world multi-camera datasets demonstrate that GMAC achieves accurate and stable extrinsic estimation without explicit 3D reconstruction or manual calibration, providing a new solution for efficient deployment and online calibration of multi-camera systems.</li>
</ul>

<h3>Title: FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence</h3>
<ul>
<li><strong>Authors: </strong>Chentian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01035">https://arxiv.org/abs/2602.01035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01035">https://arxiv.org/pdf/2602.01035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01035]] FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence(https://arxiv.org/abs/2602.01035)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Real-time multi-view point cloud reconstruction is a core problem in 3D vision and immersive perception, with wide applications in VR, AR, robotic navigation, digital twins, and computer interaction. Despite advances in multi-camera systems and high-resolution depth sensors, fusing large-scale multi-view depth observations into high-quality point clouds under strict real-time constraints remains challenging. Existing methods relying on voxel-based fusion, temporal accumulation, or global optimization suffer from high computational complexity, excessive memory usage, and limited scalability, failing to simultaneously achieve real-time performance, reconstruction quality, and multi-camera extensibility. We propose FUSE-Flow, a frame-wise, stateless, and linearly scalable point cloud streaming reconstruction framework. Each frame independently generates point cloud fragments, fused via two weights, measurement confidence and 3D distance consistency to suppress noise while preserving geometric details. For large-scale multi-camera efficiency, we introduce an adaptive spatial hashing-based weighted aggregation method: 3D space is adaptively partitioned by local point cloud density, representative points are selected per cell, and weighted fusion is performed to handle both sparse and dense regions. With GPU parallelization, FUSE-Flow achieves high-throughput, low-latency point cloud generation and fusion with linear complexity. Experiments demonstrate that the framework improves reconstruction stability and geometric fidelity in overlapping, depth-discontinuous, and dynamic scenes, while maintaining real-time frame rates on modern GPUs, verifying its effectiveness, robustness, and scalability.</li>
</ul>

<h3>Title: VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Guangshuo Qin, Zhiteng Li, Zheng Chen, Weihang Zhang, Linghe Kong, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01037">https://arxiv.org/abs/2602.01037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01037">https://arxiv.org/pdf/2602.01037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01037]] VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models(https://arxiv.org/abs/2602.01037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts(MoE) Vision-Language Models (VLMs) offer remarkable performance but incur prohibitive memory and computational costs, making compression essential. Post-Training Quantization (PTQ) is an effective training-free technique to address the massive memory and computation overhead. Existing quantization paradigms fall short as they are oblivious to two critical forms of heterogeneity: the inherent discrepancy between vision and language tokens, and the non-uniform contribution of different experts. To bridge this gap, we propose Visual Expert Quantization (VEQ), a dual-aware quantization framework designed to simultaneously accommodate cross-modal differences and heterogeneity between experts. Specifically, VEQ incorporates 1)Modality-expert-aware Quantization, which utilizes expert activation frequency to prioritize error minimization for pivotal experts, and 2)Modality-affinity-aware Quantization, which constructs an enhanced Hessian matrix by integrating token-expert affinity with modality information to guide the calibration process. Extensive experiments across diverse benchmarks verify that VEQ consistently outperforms state-of-the-art baselines. Specifically, under the W3A16 configuration, our method achieves significant average accuracy gains of 2.04\% on Kimi-VL and 3.09\% on Qwen3-VL compared to the previous SOTA quantization methods, demonstrating superior robustness across various multimodal tasks. Our code will be available at this https URL.</li>
</ul>

<h3>Title: From Videos to Conversations: Egocentric Instructions for Task Assistance</h3>
<ul>
<li><strong>Authors: </strong>Lavisha Aggarwal, Vikas Bahirwani, Andrea Colaco</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01038">https://arxiv.org/abs/2602.01038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01038">https://arxiv.org/pdf/2602.01038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01038]] From Videos to Conversations: Egocentric Instructions for Task Assistance(https://arxiv.org/abs/2602.01038)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Many everyday tasks, ranging from appliance repair and cooking to car maintenance, require expert knowledge, particularly for complex, multi-step procedures. Despite growing interest in AI agents for augmented reality (AR) assistance, progress remains limited by the scarcity of large-scale multimodal conversational datasets grounded in real-world task execution, in part due to the cost and logistical complexity of human-assisted data collection. In this paper, we present a framework to automatically transform single person instructional videos into two-person multimodal task-guidance conversations. Our fully automatic pipeline, based on large language models, provides a scalable and cost efficient alternative to traditional data collection approaches. Using this framework, we introduce HowToDIV, a multimodal dataset comprising 507 conversations, 6,636 question answer pairs, and 24 hours of video spanning multiple domains. Each session consists of a multi-turn expert-novice interaction. Finally, we report baseline results using Gemma 3 and Qwen 2.5 on HowToDIV, providing an initial benchmark for multimodal procedural task assistance.</li>
</ul>

<h3>Title: Adaptive Dual-Weighting Framework for Federated Learning via Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Ling, Hailiang Zhao, Chao Zhang, Xiang Ao, Ziqi Wang, Cheng Zhang, Zhen Qin, Xinkui Zhao, Kingsum Chow, Yuanqing Wu, MengChu Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01039">https://arxiv.org/abs/2602.01039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01039">https://arxiv.org/pdf/2602.01039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01039]] Adaptive Dual-Weighting Framework for Federated Learning via Out-of-Distribution Detection(https://arxiv.org/abs/2602.01039)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative model training across large-scale distributed service nodes while preserving data privacy, making it a cornerstone of intelligent service systems in edge-cloud environments. However, in real-world service-oriented deployments, data generated by heterogeneous users, devices, and application scenarios are inherently non-IID. This severe data heterogeneity critically undermines the convergence stability, generalization ability, and ultimately the quality of service delivered by the global model. To address this challenge, we propose FLood, a novel FL framework inspired by out-of-distribution (OOD) detection. FLood dynamically counteracts the adverse effects of heterogeneity through a dual-weighting mechanism that jointly governs local training and global aggregation. At the client level, it adaptively reweights the supervised loss by upweighting pseudo-OOD samples, thereby encouraging more robust learning from distributionally misaligned or challenging data. At the server level, it refines model aggregation by weighting client contributions according to their OOD confidence scores, prioritizing updates from clients with higher in-distribution consistency and enhancing the global model's robustness and convergence stability. Extensive experiments across multiple benchmarks under diverse non-IID settings demonstrate that FLood consistently outperforms state-of-the-art FL methods in both accuracy and generalization. Furthermore, FLood functions as an orthogonal plug-in module: it seamlessly integrates with existing FL algorithms to boost their performance under heterogeneity without modifying their core optimization logic. These properties make FLood a practical and scalable solution for deploying reliable intelligent services in real-world federated environments.</li>
</ul>

<h3>Title: Superposition unifies power-law training dynamics</h3>
<ul>
<li><strong>Authors: </strong>Zixin Jessie Chen, Hao Chen, Yizhou Liu, Jeff Gore</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01045">https://arxiv.org/abs/2602.01045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01045">https://arxiv.org/pdf/2602.01045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01045]] Superposition unifies power-law training dynamics(https://arxiv.org/abs/2602.01045)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate the role of feature superposition in the emergence of power-law training dynamics using a teacher-student framework. We first derive an analytic theory for training without superposition, establishing that the power-law training exponent depends on both the input data statistics and channel importance. Remarkably, we discover that a superposition bottleneck induces a transition to a universal power-law exponent of $\sim 1$, independent of data and channel statistics. This one over time training with superposition represents an up to tenfold acceleration compared to the purely sequential learning that takes place in the absence of superposition. Our finding that superposition leads to rapid training with a data-independent power law exponent may have important implications for a wide range of neural networks that employ superposition, including production-scale large language models.</li>
</ul>

<h3>Title: ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Lin, Shizhao Sun, Danqing Huang, Ting Liu, Ji Li, Jiang Bian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01046">https://arxiv.org/abs/2602.01046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01046">https://arxiv.org/pdf/2602.01046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01046]] ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction(https://arxiv.org/abs/2602.01046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Automated redesign without manual adjustments marks a key step forward in the design workflow. In this work, we focus on a foundational redesign task termed design layout editing, which seeks to autonomously modify the geometric composition of a design based on user intents. To overcome the ambiguity of user needs expressed in natural language, we introduce four basic and important editing actions and standardize the format of editing operations. The underexplored task presents a unique challenge: satisfying specified editing operations while simultaneously preserving the layout structure of unedited elements. Besides, the scarcity of triplet (original design, editing operation, edited design) samples poses another formidable challenge. To this end, we present ReLayout, a novel framework for versatile and structure-preserving design layout editing that operates without triplet data. Specifically, ReLayout first introduces the relation graph, which contains the position and size relationships among unedited elements, as the constraint for layout structure preservation. Then, relation-aware design reconstruction (RADR) is proposed to bypass the data challenge. By learning to reconstruct a design from its elements, a relation graph, and a synthesized editing operation, RADR effectively emulates the editing process in a self-supervised manner. A multi-modal large language model serves as the backbone for RADR, unifying multiple editing actions within a single model and thus achieving versatile editing after fine-tuning. Qualitative, quantitative results and user studies show that ReLayout significantly outperforms the baseline models in terms of editing quality, accuracy, and layout structure preservation.</li>
</ul>

<h3>Title: SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes</h3>
<ul>
<li><strong>Authors: </strong>Rong Fu, Wenxin Zhang, Muge Qi, Yang Li, Yabin Jin, Jiekai Wu, Jiaxuan Lu, Chunlei Meng, Youjin Wang, Zeli Su, Juntao Gao, Li Bao, Qi Zhao, Wei Luo, Simon Fong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01051">https://arxiv.org/abs/2602.01051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01051">https://arxiv.org/pdf/2602.01051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01051]] SwiftRepertoire: Few-Shot Immune-Signature Synthesis via Dynamic Kernel Codes(https://arxiv.org/abs/2602.01051)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Repertoire-level analysis of T cell receptors offers a biologically grounded signal for disease detection and immune monitoring, yet practical deployment is impeded by label sparsity, cohort heterogeneity, and the computational burden of adapting large encoders to new tasks. We introduce a framework that synthesizes compact task-specific parameterizations from a learned dictionary of prototypes conditioned on lightweight task descriptors derived from repertoire probes and pooled embedding statistics. This synthesis produces small adapter modules applied to a frozen pretrained backbone, enabling immediate adaptation to novel tasks with only a handful of support examples and without full model fine-tuning. The architecture preserves interpretability through motif-aware probes and a calibrated motif discovery pipeline that links predictive decisions to sequence-level signals. Together, these components yield a practical, sample-efficient, and interpretable pathway for translating repertoire-informed models into diverse clinical and research settings where labeled data are scarce and computational resources are constrained.</li>
</ul>

<h3>Title: Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Bo Deng, Yitong Tang, Jiake Li, Yuxin Huang, Li Wang, Yu Zhang, Yufei Zhan, Hua Lu, Xiaoshen Zhang, Jieyun Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01055">https://arxiv.org/abs/2602.01055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01055">https://arxiv.org/pdf/2602.01055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01055]] Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis(https://arxiv.org/abs/2602.01055)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Ultrasound (US) imaging exhibits substantial heterogeneity across anatomical structures and acquisition protocols, posing significant challenges to the development of generalizable analysis models. Most existing methods are task-specific, limiting their suitability as clinically deployable foundation models. To address this limitation, the Foundation Model Challenge for Ultrasound Image Analysis (FM\_UIA~2026) introduces a large-scale multi-task benchmark comprising 27 subtasks across segmentation, classification, detection, and regression. In this paper, we present the official baseline for FM\_UIA~2026 based on a unified Multi-Head Multi-Task Learning (MH-MTL) framework that supports all tasks within a single shared network. The model employs an ImageNet-pretrained EfficientNet--B4 backbone for robust feature extraction, combined with a Feature Pyramid Network (FPN) to capture multi-scale contextual information. A task-specific routing strategy enables global tasks to leverage high-level semantic features, while dense prediction tasks exploit spatially detailed FPN representations. Training incorporates a composite loss with task-adaptive learning rate scaling and a cosine annealing schedule. Validation results demonstrate the feasibility and robustness of this unified design, establishing a strong and extensible baseline for ultrasound foundation model research. The code and dataset are publicly available at \href{this https URL}{GitHub}.</li>
</ul>

<h3>Title: DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification</h3>
<ul>
<li><strong>Authors: </strong>Ying Shu, Pujian Zhan, Huiqi Yang, Hehe Fan, Youfang Lin, Kai Lv</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01059">https://arxiv.org/abs/2602.01059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01059">https://arxiv.org/pdf/2602.01059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01059]] DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification(https://arxiv.org/abs/2602.01059)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Both fine-grained discriminative details and global semantic features can contribute to solving person re-identification challenges, such as occlusion and pose variations. Vision foundation models (\textit{e.g.}, DINO) excel at mining local textures, and vision-language models (\textit{e.g.}, CLIP) capture strong global semantic difference. Existing methods predominantly rely on a single paradigm, neglecting the potential benefits of their integration. In this paper, we analyze the complementary roles of these two architectures and propose a framework to synergize their strengths by a \textbf{D}ual-\textbf{R}egularized Bidirectional \textbf{Transformer} (\textbf{DRFormer}). The dual-regularization mechanism ensures diverse feature extraction and achieves a better balance in the contributions of the two models. Extensive experiments on five benchmarks show that our method effectively harmonizes local and global representations, achieving competitive performance against state-of-the-art methods.</li>
</ul>

<h3>Title: Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Bin Han, Deuksin Kwon, Jonathan Gratch</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01063">https://arxiv.org/abs/2602.01063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01063">https://arxiv.org/pdf/2602.01063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01063]] Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents(https://arxiv.org/abs/2602.01063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.</li>
</ul>

<h3>Title: Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ruihan Jin, Pengpeng Shao, Zhengqi Wen, Jinyang Wu, Mingkuan Feng, Shuo Yang, Chu Yuan Zhang, Jianhua Tao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01064">https://arxiv.org/abs/2602.01064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01064">https://arxiv.org/pdf/2602.01064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01064]] Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs(https://arxiv.org/abs/2602.01064)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of \textbf{Knowledge Purification}, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.</li>
</ul>

<h3>Title: From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Chaoqun Cui, Shijing Wang, Liangbin Huang, Qingqing Gu, Zhaolong Huang, Xiao Zeng, Wenji Mao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01068">https://arxiv.org/abs/2602.01068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01068">https://arxiv.org/pdf/2602.01068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01068]] From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization(https://arxiv.org/abs/2602.01068)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.</li>
</ul>

<h3>Title: PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors</h3>
<ul>
<li><strong>Authors: </strong>Seema K. Poudel, Sunny K. Khadka</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01069">https://arxiv.org/abs/2602.01069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01069">https://arxiv.org/pdf/2602.01069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01069]] PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors(https://arxiv.org/abs/2602.01069)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Segmentation of microscopy images constitutes an ill-posed inverse problem due to measurement noise, weak object boundaries, and limited labeled data. Although deep neural networks provide flexible nonparametric estimators, unconstrained empirical risk minimization often leads to unstable solutions and poor generalization. In this work, image segmentation is formulated as a PDE-constrained optimization problem that integrates physically motivated priors into deep learning models through variational regularization. The proposed framework minimizes a composite objective function consisting of a data fidelity term and penalty terms derived from reaction-diffusion equations and phase-field interface energies, all implemented as differentiable residual losses. Experiments are conducted on the LIVECell dataset, a high-quality, manually annotated collection of phase-contrast microscopy images. Training is performed on two cell types, while evaluation is carried out on a distinct, unseen cell type to assess generalization. A UNet architecture is used as the unconstrained baseline model. Experimental results demonstrate consistent improvements in segmentation accuracy and boundary fidelity compared to unconstrained deep learning baselines. Moreover, the PDE-regularized models exhibit enhanced stability and improved generalization in low-sample regimes, highlighting the advantages of incorporating structured priors. The proposed approach illustrates how PDE-constrained optimization can strengthen data-driven learning frameworks, providing a principled bridge between variational methods, statistical learning, and scientific machine learning.</li>
</ul>

<h3>Title: PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Haopeng Li, Shitong Shao, Wenliang Zhong, Zikai Zhou, Lichen Bai, Hui Xiong, Zeke Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01077">https://arxiv.org/abs/2602.01077</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01077">https://arxiv.org/pdf/2602.01077</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01077]] PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers(https://arxiv.org/abs/2602.01077)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: this https URL.</li>
</ul>

<h3>Title: MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Haitao Zhang, Yingying Wang, Jiaxiang Wang, Haote Xu, Hongyang Zhang, Yirong Chen, Yue Huang, Xinghao Ding</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01081">https://arxiv.org/abs/2602.01081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01081">https://arxiv.org/pdf/2602.01081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01081]] MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization(https://arxiv.org/abs/2602.01081)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Medical Anomaly Detection (MedAD) presents a significant opportunity to enhance diagnostic accuracy using Large Multimodal Models (LMMs) to interpret and answer questions based on medical images. However, the reliance on Supervised Fine-Tuning (SFT) on simplistic and fragmented datasets has hindered the development of models capable of plausible reasoning and robust multimodal generalization. To overcome this, we introduce MedAD-38K, the first large-scale, multi-modal, and multi-center benchmark for MedAD featuring diagnostic Chain-of-Thought (CoT) annotations alongside structured Visual Question-Answering (VQA) pairs. On this foundation, we propose a two-stage training framework. The first stage, Cognitive Injection, uses SFT to instill foundational medical knowledge and align the model with a structured think-then-answer paradigm. Given that standard policy optimization can produce reasoning that is disconnected from the final answer, the second stage incorporates Consistency Group Relative Policy Optimization (Con-GRPO). This novel algorithm incorporates a crucial consistency reward to ensure the generated reasoning process is relevant and logically coherent with the final diagnosis. Our proposed model, MedAD-R1, achieves state-of-the-art (SOTA) performance on the MedAD-38K benchmark, outperforming strong baselines by more than 10\%. This superior performance stems from its ability to generate transparent and logically consistent reasoning pathways, offering a promising approach to enhancing the trustworthiness and interpretability of AI for clinical decision support.</li>
</ul>

<h3>Title: Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models</h3>
<ul>
<li><strong>Authors: </strong>Zhiqi Zhang, Xinhao Zhong, Yi Sun, Shuoyang Sun, Bin Chen, Shu-Tao Xia, Xuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01089">https://arxiv.org/abs/2602.01089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01089">https://arxiv.org/pdf/2602.01089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01089]] Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models(https://arxiv.org/abs/2602.01089)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images, yet their tendency to reproduce undesirable concepts, such as NSFW content, copyrighted styles, or specific objects, poses growing concerns for safe and controllable deployment. While existing concept erasure approaches primarily focus on DDPM-based diffusion models and rely on costly fine-tuning, the recent emergence of flow matching models introduces a fundamentally different generative paradigm for which prior methods are not directly applicable. In this paper, we propose Differential Vector Erasure (DVE), a training-free concept erasure method specifically designed for flow matching models. Our key insight is that semantic concepts are implicitly encoded in the directional structure of the velocity field governing the generative flow. Leveraging this observation, we construct a differential vector field that characterizes the directional discrepancy between a target concept and a carefully chosen anchor concept. During inference, DVE selectively removes concept-specific components by projecting the velocity field onto the differential direction, enabling precise concept suppression without affecting irrelevant semantics. Extensive experiments on FLUX demonstrate that DVE consistently outperforms existing baselines on a wide range of concept erasure tasks, including NSFW suppression, artistic style removal, and object erasure, while preserving image quality and diversity.</li>
</ul>

<h3>Title: PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space</h3>
<ul>
<li><strong>Authors: </strong>Jinghong Zheng, Changlong Jiang, Yang Xiao, Jiaqi Li, Haohong Kuang, Hang Xu, Ran Wang, Zhiguo Cao, Min Du, Joey Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01095">https://arxiv.org/abs/2602.01095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01095">https://arxiv.org/pdf/2602.01095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01095]] PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space(https://arxiv.org/abs/2602.01095)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D human pose lifting from a single RGB image is a challenging task in 3D vision. Existing methods typically establish a direct joint-to-joint mapping from 2D to 3D poses based on 2D features. This formulation suffers from two fundamental limitations: inevitable error propagation from input predicted 2D pose to 3D predictions and inherent difficulties in handling self-occlusion cases. In this paper, we propose PandaPose, a 3D human pose lifting approach via propagating 2D pose prior to 3D anchor space as the unified intermediate representation. Specifically, our 3D anchor space comprises: (1) Joint-wise 3D anchors in the canonical coordinate system, providing accurate and robust priors to mitigate 2D pose estimation inaccuracies. (2) Depth-aware joint-wise feature lifting that hierarchically integrates depth information to resolve self-occlusion ambiguities. (3) The anchor-feature interaction decoder that incorporates 3D anchors with lifted features to generate unified anchor queries encapsulating joint-wise 3D anchor set, visual cues and geometric depth information. The anchor queries are further employed to facilitate anchor-to-joint ensemble prediction. Experiments on three well-established benchmarks (i.e., Human3.6M, MPI-INF-3DHP and 3DPW) demonstrate the superiority of our proposition. The substantial reduction in error by $14.7\%$ compared to SOTA methods on the challenging conditions of Human3.6M and qualitative comparisons further showcase the effectiveness and robustness of our approach.</li>
</ul>

<h3>Title: Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Felix Breiteneder, Mohammad Belal, Muhammad Saad Saeed, Shahed Masoudian, Usman Naseem, Kulshrestha Juhi, Markus Schedl, Shah Nawaz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01101">https://arxiv.org/abs/2602.01101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01101">https://arxiv.org/pdf/2602.01101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01101]] Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning(https://arxiv.org/abs/2602.01101)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Internet memes are powerful tools for communication, capable of spreading political, psychological, and sociocultural ideas. However, they can be harmful and can be used to disseminate hate toward targeted individuals or groups. Although previous studies have focused on designing new detection methods, these often rely on modal-complete data, such as text and images. In real-world settings, however, modalities like text may be missing due to issues like poor OCR quality, making existing methods sensitive to missing information and leading to performance deterioration. To address this gap, in this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of harmful meme detection methods in the presence of modal-incomplete data. Specifically, we propose a new baseline method that learns a shared representation for multiple modalities by projecting them independently. These shared representations can then be leveraged when data is modal-incomplete. Experimental results on two benchmark datasets demonstrate that our method outperforms existing approaches when text is missing. Moreover, these results suggest that our method allows for better integration of visual features, reducing dependence on text and improving robustness in scenarios where textual information is missing. Our work represents a significant step forward in enabling the real-world application of harmful meme detection, particularly in situations where a modality is absent.</li>
</ul>

<h3>Title: Single-Edge Node Injection Threats to GNN-Based Security Monitoring in Industrial Graph Systems</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Liang, Ranhui Yan, Jia Cai, You-Gan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01113">https://arxiv.org/abs/2602.01113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01113">https://arxiv.org/pdf/2602.01113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01113]] Single-Edge Node Injection Threats to GNN-Based Security Monitoring in Industrial Graph Systems(https://arxiv.org/abs/2602.01113)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) are increasingly adopted in industrial graph-based monitoring systems (e.g., Industrial internet of things (IIoT) device graphs, power-grid topology models, and manufacturing communication networks) to support anomaly detection, state estimation, and asset classification. In such settings, an adversary that compromises a small number of edge devices may inject counterfeit nodes (e.g., rogue sensors, virtualized endpoints, or spoofed substations) to bias downstream decisions while evading topology- and homophily-based sanitization. This paper formulates deployment-oriented node-injection attacks under constrained resources and proposes the \emph{Single-Edge Graph Injection Attack} (SEGIA), in which each injected node attaches to the operational graph through a single edge. SEGIA integrates a pruned SGC surrogate, multi-hop neighborhood sampling, and reverse graph convolution-based feature synthesis with a similarity-regularized objective to preserve local homophily and survive edge pruning. Theoretical analysis and extensive evaluations across datasets and defenses show at least $25\%$ higher attack success than representative baselines under substantially smaller edge budgets. These results indicate a system-level risk in industrial GNN deployments and motivate lightweight admission validation and neighborhood-consistency monitoring.</li>
</ul>

<h3>Title: Logic-Oriented Retriever Enhancement via Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Zhang, Yuan-Hao Jiang, Changyong Qi, Rui Jia, Yonghe Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01116">https://arxiv.org/abs/2602.01116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01116">https://arxiv.org/pdf/2602.01116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01116]] Logic-Oriented Retriever Enhancement via Contrastive Learning(https://arxiv.org/abs/2602.01116)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) struggle in knowledge-intensive tasks, as retrievers often overfit to surface similarity and fail on queries involving complex logical relations. The capacity for logical analysis is inherent in model representations but remains underutilized in standard training. LORE (Logic ORiented Retriever Enhancement) introduces fine-grained contrastive learning to activate this latent capacity, guiding embeddings toward evidence aligned with logical structure rather than shallow similarity. LORE requires no external upervision, resources, or pre-retrieval analysis, remains index-compatible, and consistently improves retrieval utility and downstream generation while maintaining efficiency. The datasets and code are publicly available at this https URL.</li>
</ul>

<h3>Title: LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions</h3>
<ul>
<li><strong>Authors: </strong>Jingjing Wang, Qirui Hu, Chong Bao, Yuke Zhu, Hujun Bao, Zhaopeng Cui, Guofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01118">https://arxiv.org/abs/2602.01118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01118">https://arxiv.org/pdf/2602.01118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01118]] LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions(https://arxiv.org/abs/2602.01118)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Inverse rendering in urban scenes is pivotal for applications like autonomous driving and digital twins. Yet, it faces significant challenges due to complex illumination conditions, including multi-illumination and indirect light and shadow effects. However, the effects of these challenges on intrinsic decomposition and 3D reconstruction have not been explored due to the lack of appropriate datasets. In this paper, we present LightCity, a novel high-quality synthetic urban dataset featuring diverse illumination conditions with realistic indirect light and shadow effects. LightCity encompasses over 300 sky maps with highly controllable illumination, varying scales with street-level and aerial perspectives over 50K images, and rich properties such as depth, normal, material components, light and indirect light, etc. Besides, we leverage LightCity to benchmark three fundamental tasks in the urban environments and conduct a comprehensive analysis of these benchmarks, laying a robust foundation for advancing related research.</li>
</ul>

<h3>Title: ChronoSpike: An Adaptive Spiking Graph Neural Network for Dynamic Graphs</h3>
<ul>
<li><strong>Authors: </strong>Md Abrar Jahin, Taufikur Rahman Fuad, Jay Pujara, Craig Knoblock</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01124">https://arxiv.org/abs/2602.01124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01124">https://arxiv.org/pdf/2602.01124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01124]] ChronoSpike: An Adaptive Spiking Graph Neural Network for Dynamic Graphs(https://arxiv.org/abs/2602.01124)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Dynamic graph representation learning requires capturing both structural relationships and temporal evolution, yet existing approaches face a fundamental trade-off: attention-based methods achieve expressiveness at $O(T^2)$ complexity, while recurrent architectures suffer from gradient pathologies and dense state storage. Spiking neural networks offer event-driven efficiency but remain limited by sequential propagation, binary information loss, and local aggregation that misses global context. We propose ChronoSpike, an adaptive spiking graph neural network that integrates learnable LIF neurons with per-channel membrane dynamics, multi-head attentive spatial aggregation on continuous features, and a lightweight Transformer temporal encoder, enabling both fine-grained local modeling and long-range dependency capture with linear memory complexity $O(T \cdot d)$. On three large-scale benchmarks, ChronoSpike outperforms twelve state-of-the-art baselines by $2.0\%$ Macro-F1 and $2.4\%$ Micro-F1 while achieving $3-10\times$ faster training than recurrent methods with a constant 105K-parameter budget independent of graph size. We provide theoretical guarantees for membrane potential boundedness, gradient flow stability under contraction factor $\rho < 1$, and BIBO stability; interpretability analyses reveal heterogeneous temporal receptive fields and a learned primacy effect with $83-88\%$ sparsity.</li>
</ul>

<h3>Title: WinFLoRA: Incentivizing Client-Adaptive Aggregation in Federated LoRA under Privacy Heterogeneity</h3>
<ul>
<li><strong>Authors: </strong>Mengsha Kou, Xiaoyu Xia, Ziqi Wang, Ibrahim Khalil, Runkun Luo, Jingwen Zhou, Minhui Xue</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01126">https://arxiv.org/abs/2602.01126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01126">https://arxiv.org/pdf/2602.01126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01126]] WinFLoRA: Incentivizing Client-Adaptive Aggregation in Federated LoRA under Privacy Heterogeneity(https://arxiv.org/abs/2602.01126)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) increasingly underpin intelligent web applications, from chatbots to search and recommendation, where efficient specialization is essential. Low-Rank Adaptation (LoRA) enables such adaptation with minimal overhead, while federated LoRA allows web service providers to fine-tune shared models without data sharing. However, in privacy-sensitive deployments, clients inject varying levels of differential privacy (DP) noise, creating privacy heterogeneity that misaligns individual incentives and global performance. In this paper, we propose WinFLoRA, a privacy-heterogeneous federated LoRA that utilizes aggregation weights as incentives with noise awareness. Specifically, the noises from clients are estimated based on the uploaded LoRA adapters. A larger weight indicates greater influence on the global model and better downstream task performance, rewarding lower-noise contributions. By up-weighting low-noise updates, WinFLoRA improves global accuracy while accommodating clients' heterogeneous privacy requirements. Consequently, WinFLoRA aligns heterogeneous client utility in terms of privacy and downstream performance with global model objectives without third-party involvement. Extensive evaluations demonstrate that across multiple LLMs and datasets, WinFLoRA achieves up to 52.58% higher global accuracy and up to 2.56x client utility than state-of-the-art benchmarks. Source code is publicly available at this https URL.</li>
</ul>

<h3>Title: Tangent Space Fine-Tuning for Directional Preference Alignment in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mete Erdogan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01128">https://arxiv.org/abs/2602.01128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01128">https://arxiv.org/pdf/2602.01128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01128]] Tangent Space Fine-Tuning for Directional Preference Alignment in Large Language Models(https://arxiv.org/abs/2602.01128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Our goal is to enable large language models (LLMs) to balance multiple human preference dimensions; such as helpfulness, safety, and verbosity, through principled and controllable alignment. Existing preference optimization methods, including Direct Preference Optimization (DPO), collapse feedback into a single scalar reward, fixing one balance among objectives and preventing traversal of the Pareto front. Recent work by Ortiz-Jimenez et al. (2023) showed that fine-tuning can be viewed in a model's tangent space, where linearized updates act as additive vectors that can be composed to jointly perform well on multiple tasks. Building on this formulation, we extend this idea to preference alignment and propose Tangent-Space Direct Preference Optimization (TS-DPO), which performs DPO within this locally linear regime to learn per-objective update directions. These directions can be linearly combined at inference to generate user-specified behaviors without additional optimization. Evaluated on the helpfulness-verbosity trade-off using the HelpSteer and UltraFeedback datasets, TS-DPO achieves broader Pareto-optimal coverage and smoother preference control than scalarized DPO. Canonical Correlation Analysis (CCA) further shows that tangent-space training amplifies canonical directions aligned with distinct preferences, improving disentanglement.</li>
</ul>

<h3>Title: SMCP: Secure Model Context Protocol</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Hou, Shenao Wang, Yifan Zhang, Ziluo Xue, Yanjie Zhao, Cai Fu, Haoyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01129">https://arxiv.org/abs/2602.01129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01129">https://arxiv.org/pdf/2602.01129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01129]] SMCP: Secure Model Context Protocol(https://arxiv.org/abs/2602.01129)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Agentic AI systems built around large language models (LLMs) are moving away from closed, single-model frameworks and toward open ecosystems that connect a variety of agents, external tools, and resources. The Model Context Protocol (MCP) has emerged as a standard to unify tool access, allowing agents to discover, invoke, and coordinate with tools more flexibly. However, as MCP becomes more widely adopted, it also brings a new set of security and privacy challenges. These include risks such as unauthorized access, tool poisoning, prompt injection, privilege escalation, and supply chain attacks, any of which can impact different parts of the protocol workflow. While recent research has examined possible attack surfaces and suggested targeted countermeasures, there is still a lack of systematic, protocol-level security improvements for MCP. To address this, we introduce the Secure Model Context Protocol (SMCP), which builds on MCP by adding unified identity management, robust mutual authentication, ongoing security context propagation, fine-grained policy enforcement, and comprehensive audit logging. In this paper, we present the main components of SMCP, explain how it helps reduce security risks, and illustrate its application with practical examples. We hope that this work will contribute to the development of agentic systems that are not only powerful and adaptable, but also secure and dependable.</li>
</ul>

<h3>Title: Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation</h3>
<ul>
<li><strong>Authors: </strong>Abhilekh Borah, Shubhra Ghosh, Kedar Joshi, Aditya Kumar Guru, Kripabandhu Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01132">https://arxiv.org/abs/2602.01132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01132">https://arxiv.org/pdf/2602.01132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01132]] Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation(https://arxiv.org/abs/2602.01132)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Tasks such as solving arithmetic equations, evaluating truth tables, and completing syllogisms are handled well by large language models (LLMs) in their standard form, but they often fail when the same problems are posed in logically equivalent yet obfuscated formats. To study this vulnerability, we introduce Logifus, a structure-preserving logical obfuscation framework, and, utilizing this, we present LogiQAte, a first-of-its-kind diagnostic benchmark with 1,108 questions across four reasoning tasks: (i) Obfus FOL (first-order logic entailment under equivalence-preserving rewrites), (ii) Obfus Blood Relation (family-graph entailment under indirect relational chains), (iii) Obfus Number Series (pattern induction under symbolic substitutions), and (iv) Obfus Direction Sense (navigation reasoning under altered directions and reference frames). Across all the tasks, evaluating six state-of-the-art models, we find that obfuscation severely degrades zero-shot performance, with performance dropping on average by 47% for GPT-4o, 27% for GPT-5, and 22% for reasoning model, o4-mini. Our findings reveal that current LLMs parse questions without deep understanding, highlighting the urgency of building models that genuinely comprehend and preserve meaning beyond surface form.</li>
</ul>

<h3>Title: TRACE: Scalable Amortized Causal Discovery from Single Sequences via Autoregressive Density Estimation</h3>
<ul>
<li><strong>Authors: </strong>Hugo Math, Rainer Lienhart</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01135">https://arxiv.org/abs/2602.01135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01135">https://arxiv.org/pdf/2602.01135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01135]] TRACE: Scalable Amortized Causal Discovery from Single Sequences via Autoregressive Density Estimation(https://arxiv.org/abs/2602.01135)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study causal discovery from a single observed sequence of discrete events generated by a stochastic process, as encountered in vehicle logs, manufacturing systems, or patient trajectories. This regime is particularly challenging due to the absence of repeated samples, high dimensionality, and long-range temporal dependencies of the single observation during inference. We introduce TRACE, a scalable framework that repurposes autoregressive models as pretrained density estimators for conditional mutual information estimation. TRACE infers the summary causal graph between event types in a sequence, scaling linearly with the event vocabulary and supporting delayed causal effects, while being fully parallel on GPUs. We establish its theoretical identifiability under imperfect autoregressive models. Experiments demonstrate robust performance across different baselines and varying vocabulary sizes including an application to root-cause analysis in vehicle diagnostics with over 29,100 event types.</li>
</ul>

<h3>Title: A Unified Matrix-Spectral Framework for Stability and Interpretability in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Ronald Katende</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01136">https://arxiv.org/abs/2602.01136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01136">https://arxiv.org/pdf/2602.01136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01136]] A Unified Matrix-Spectral Framework for Stability and Interpretability in Deep Learning(https://arxiv.org/abs/2602.01136)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>We develop a unified matrix-spectral framework for analyzing stability and interpretability in deep neural networks. Representing networks as data-dependent products of linear operators reveals spectral quantities governing sensitivity to input perturbations, label noise, and training dynamics. We introduce a Global Matrix Stability Index that aggregates spectral information from Jacobians, parameter gradients, Neural Tangent Kernel operators, and loss Hessians into a single stability scale controlling forward sensitivity, attribution robustness, and optimization conditioning. We further show that spectral entropy refines classical operator-norm bounds by capturing typical, rather than purely worst-case, sensitivity. These quantities yield computable diagnostics and stability-oriented regularization principles. Synthetic experiments and controlled studies on MNIST, CIFAR-10, and CIFAR-100 confirm that modest spectral regularization substantially improves attribution stability even when global spectral summaries change little. The results establish a precise connection between spectral concentration and analytic stability, providing practical guidance for robustness-aware model design and training.</li>
</ul>

<h3>Title: Self-Generative Adversarial Fine-Tuning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shiguang Wu, Yaqing Wang, Quanming Yao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01137">https://arxiv.org/abs/2602.01137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01137">https://arxiv.org/pdf/2602.01137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01137]] Self-Generative Adversarial Fine-Tuning for Large Language Models(https://arxiv.org/abs/2602.01137)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) for alignment typically relies on supervised fine-tuning or reinforcement learning from human feedback, both limited by the cost and scarcity of high-quality annotations. Recent self-play and synthetic data approaches reduce this dependence but often rely on heuristic assumptions or ungrounded self-evaluation, which can cause bias accumulation and performance drift. In this paper, we propose Self-Generative Adversarial LLM (SGALM), a unified fine-tuning framework that formulates alignment as a generative adversarial game within a single LLM. SGALM jointly evolves generation and discrimination capabilities without external reward models. Theoretical and empirical results demonstrate that SGALM achieves state-of-the-art performance, serves as an effective alignment algorithm and a robust synthetic data engine.</li>
</ul>

<h3>Title: Key Principles of Graph Machine Learning: Representation, Robustness, and Generalization</h3>
<ul>
<li><strong>Authors: </strong>Yassine Abbahaddou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01139">https://arxiv.org/abs/2602.01139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01139">https://arxiv.org/pdf/2602.01139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01139]] Key Principles of Graph Machine Learning: Representation, Robustness, and Generalization(https://arxiv.org/abs/2602.01139)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have emerged as powerful tools for learning representations from structured data. Despite their growing popularity and success across various applications, GNNs encounter several challenges that limit their performance. in their generalization, robustness to adversarial perturbations, and the effectiveness of their representation learning capabilities. In this dissertation, I investigate these core aspects through three main contributions: (1) developing new representation learning techniques based on Graph Shift Operators (GSOs, aiming for enhanced performance across various contexts and applications, (2) introducing generalization-enhancing methods through graph data augmentation, and (3) developing more robust GNNs by leveraging orthonormalization techniques and noise-based defenses against adversarial attacks. By addressing these challenges, my work provides a more principled understanding of the limitations and potential of GNNs.</li>
</ul>

<h3>Title: Generalized Radius and Integrated Codebook Transforms for Differentiable Vector Quantization</h3>
<ul>
<li><strong>Authors: </strong>Haochen You, Heng Zhang, Hongyang He, Yuqi Li, Baojing Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01140">https://arxiv.org/abs/2602.01140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01140">https://arxiv.org/pdf/2602.01140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01140]] Generalized Radius and Integrated Codebook Transforms for Differentiable Vector Quantization(https://arxiv.org/abs/2602.01140)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vector quantization (VQ) underpins modern generative and representation models by turning continuous latents into discrete tokens. Yet hard nearest-neighbor assignments are non-differentiable and are typically optimized with heuristic straight-through estimators, which couple the update step size to the quantization gap and train each code in isolation, leading to unstable gradients and severe codebook under-utilization at scale. In this paper, we introduce GRIT-VQ (Generalized Radius and Integrated Transform-Vector Quantization), a unified surrogate framework that keeps hard assignments in the forward pass while making VQ fully differentiable. GRIT-VQ replaces the straight-through estimator with a radius-based update that moves latents along the quantization direction with a controllable, geometry-aware step, and applies a data-agnostic integrated transform to the codebook so that all codes are updated through shared parameters instead of independently. Our theoretical analysis clarifies the fundamental optimization dynamics introduced by GRIT-VQ, establishing conditions for stable gradient flow, coordinated codebook evolution, and reliable avoidance of collapse across a broad family of quantizers. Across image reconstruction, image generation, and recommendation tokenization benchmarks, GRIT-VQ consistently improves reconstruction error, generative quality, and recommendation accuracy while substantially increasing codebook utilization compared to existing VQ variants.</li>
</ul>

<h3>Title: Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing</h3>
<ul>
<li><strong>Authors: </strong>Jialong Sun, Zeming Wei, Jiaxuan Zou, Jiacheng Gong, Guanheng Wang, Chengyang Dong, Jialong Li, Bo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01150">https://arxiv.org/abs/2602.01150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01150">https://arxiv.org/pdf/2602.01150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01150]] Statistical MIA: Rethinking Membership Inference Attack for Reliable Unlearning Auditing(https://arxiv.org/abs/2602.01150)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer</a></li>
<li><strong>Abstract: </strong>Machine unlearning (MU) is essential for enforcing the right to be forgotten in machine learning systems. A key challenge of MU is how to reliably audit whether a model has truly forgotten specified training data. Membership Inference Attacks (MIAs) are widely used for unlearning auditing, where samples that evade membership detection are often regarded as successfully forgotten. After carefully revisiting the reliability of MIA, we show that this assumption is flawed: failed membership inference does not imply true forgetting. We theoretically demonstrate that MIA-based auditing, when formulated as a binary classification problem, inevitably incurs statistical errors whose magnitude cannot be observed during the auditing process. This leads to overly optimistic evaluations of unlearning performance, while incurring substantial computational overhead due to shadow model training. To address these limitations, we propose Statistical Membership Inference Attack (SMIA), a novel training-free and highly effective auditing framework. SMIA directly compares the distributions of member and non-member data using statistical tests, eliminating the need for learned attack models. Moreover, SMIA outputs both a forgetting rate and a corresponding confidence interval, enabling quantified reliability of the auditing results. Extensive experiments show that SMIA provides more reliable auditing with significantly lower computational cost than existing MIA-based approaches. Notably, the theoretical guarantees and empirical effectiveness of SMIA suggest it as a new paradigm for reliable machine unlearning auditing.</li>
</ul>

<h3>Title: Multi-Horizon Electricity Price Forecasting with Deep Learning in the Australian National Electricity Market</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Osman Gani, Zhipeng He, Chun Ouyang, Sara Khalifa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01157">https://arxiv.org/abs/2602.01157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01157">https://arxiv.org/pdf/2602.01157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01157]] Multi-Horizon Electricity Price Forecasting with Deep Learning in the Australian National Electricity Market(https://arxiv.org/abs/2602.01157)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate electricity price forecasting (EPF) is essential for operational planning, trading, and flexible asset scheduling in liberalised power systems, yet remains challenging due to volatility, heavy-tailed spikes, and frequent regime shifts. While deep learning (DL) has been increasingly adopted in EPF to capture complex and nonlinear price dynamics, several important gaps persist: (i) limited attention to multi-day horizons beyond day-ahead forecasting, (ii) insufficient exploration of state-of-the-art (SOTA) time series DL models, and (iii) a predominant reliance on aggregated horizon-level evaluation that obscures time-of-day forecasting variation. To address these gaps, we propose a novel EPF framework that extends the forecast horizon to multi-day-ahead by systematically building forecasting models that leverage benchmarked SOTA time series DL models. We conduct a comprehensive evaluation to analyse time-of-day forecasting performance by integrating model assessment at intraday interval levels across all five regions in the Australian National Electricity Market (NEM). The results show that no single model consistently dominates across regions, metrics, and horizons. Overall, standard DL models deliver superior performance in most regions, while SOTA time series DL models demonstrate greater robustness to forecast horizon extension. Intraday interval-level evaluation reveals pronounced diurnal error patterns, indicating that absolute errors peak during the evening ramp, relative errors inflate during midday negative-price regimes, and directional accuracy degrades during periods of frequent trend changes. These findings suggest that future research on DL-based EPF can benefit from enriched feature representations and modelling strategies that enhance longer-term forecasting robustness while maintaining sensitivity to intraday volatility and structural price dynamics.</li>
</ul>

<h3>Title: Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs</h3>
<ul>
<li><strong>Authors: </strong>Daniel Yezid Guarnizo Orjuela, Leonardo Scappatura, Veronica Di Gennaro, Riccardo Andrea Izzo, Gianluca Bardaro, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01158">https://arxiv.org/abs/2602.01158</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01158">https://arxiv.org/pdf/2602.01158</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01158]] Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs(https://arxiv.org/abs/2602.01158)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Vision-Language-Action (VLA) models have emerged as a dominant paradigm for generalist robotic manipulation, unifying perception and control within a single end-to-end architecture. However, despite their success in controlled environments, reliable real-world deployment is severely hindered by their fragility to visual disturbances. While existing literature extensively addresses physical occlusions caused by scene geometry, a critical mode remains largely unexplored: image corruptions. These sensor-level artifacts, ranging from electronic noise and dead pixels to lens contaminants, directly compromise the integrity of the visual signal prior to interpretation. In this work, we quantify this vulnerability, demonstrating that state-of-the-art VLAs such as $\pi_{0.5}$ and SmolVLA, suffer catastrophic performance degradation, dropping from 90\% success rates to as low as 2\%, under common signal artifacts. To mitigate this, we introduce the Corruption Restoration Transformer (CRT), a plug-and-play and model-agnostic vision transformer designed to immunize VLA models against sensor disturbances. Leveraging an adversarial training objective, CRT restores clean observations from corrupted inputs without requiring computationally expensive fine-tuning of the underlying model. Extensive experiments across the LIBERO and Meta-World benchmarks demonstrate that CRT effectively recovers lost performance, enabling VLAs to maintain near-baseline success rates, even under severe visual corruption.</li>
</ul>

<h3>Title: DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Xue, Jiuan Zhou, Yu Cheng, Zhaoxia Yin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01160">https://arxiv.org/abs/2602.01160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01160">https://arxiv.org/pdf/2602.01160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01160]] DTAMS: High-Capacity Generative Steganography via Dynamic Multi-Timestep Selection and Adaptive Deviation Mapping in Latent Diffusion(https://arxiv.org/abs/2602.01160)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction, diffusion, generative</a></li>
<li><strong>Abstract: </strong>With the rapid development of AIGC technologies, generative image steganography has attracted increasing attention due to its high imperceptibility and flexibility. However, existing generative steganography methods often maintain acceptable security and robustness only at relatively low embedding rates, severely limiting the practical applicability of steganographic systems. To address this issue, we propose a novel DTAMS framework that achieves high embedding rates while ensuring strong robustness and security. Specifically, a dynamic multi-timestep adaptive embedding mechanism is constructed based on transition-cost modeling in diffusion models, enabling automatic selection of optimal embedding timesteps to improve embedding rates while preserving overall performance. Meanwhile, we propose a global sub-interval mapping strategy that jointly considers mapping errors and the frequency distribution of secret information, converting point-wise perturbations into interval-level statistical mappings to suppress error accumulation and distribution drift during multi-step diffusion processes. Furthermore, a multi-dimensional joint constraint mechanism is introduced to mitigate distortions caused by repeated latent-pixel transformations by jointly regularizing embedding errors at the pixel, latent, and semantic levels. Experiments demonstrate that the proposed method achieves an embedding rate of 12 bpp while maintaining excellent security and robustness. Across all evaluated conditions, DTAMS reduces the average extraction error rate by 59.39%, representing a significant improvement over SOTA methods.</li>
</ul>

<h3>Title: Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Reem I. Masoud, Chen Feng, Shunta Asano, Saied Alshahrani, Philip Colin Treleaven, Miguel R. D. Rodrigues</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01161">https://arxiv.org/abs/2602.01161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01161">https://arxiv.org/pdf/2602.01161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01161]] Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models(https://arxiv.org/abs/2602.01161)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The global deployment of large language models (LLMs) has raised concerns about cultural misalignment, yet the linguistic properties of fine-tuning datasets used for cultural adaptation remain poorly understood. We adopt a dataset-centric view of cultural alignment and ask which linguistic properties of fine-tuning data are associated with cultural performance, whether these properties are predictive prior to training, and how these effects vary across models. We compute lightweight linguistic, semantic, and structural metrics for Arabic, Chinese, and Japanese datasets and apply principal component analysis separately within each language. This design ensures that the resulting components capture variation among datasets written in the same language rather than differences between languages. The resulting components correspond to broadly interpretable axes related to semantic coherence, surface-level lexical and syntactic diversity, and lexical or structural richness, though their composition varies across languages. We fine-tune three major LLM families (LLaMA, Mistral, DeepSeek) and evaluate them on benchmarks of cultural knowledge, values, and norms. While PCA components correlate with downstream performance, these associations are strongly model-dependent. Through controlled subset interventions, we show that lexical-oriented components (PC3) are the most robust, yielding more consistent performance across models and benchmarks, whereas emphasizing semantic or diversity extremes (PC1-PC2) is often neutral or harmful.</li>
</ul>

<h3>Title: Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Nipuna Abeykoon, Ashen Weerathunga, Pubudu Wijesinghe, Parameswari Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01162">https://arxiv.org/abs/2602.01162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01162">https://arxiv.org/pdf/2602.01162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01162]] Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages(https://arxiv.org/abs/2602.01162)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models trained predominantly on high-resource languages exhibit systematic biases toward dominant typological patterns, leading to structural non-conformance when translating into typologically divergent low-resource languages. We present a framework that leverages linguistic typology to improve translation quality without parallel training data or model retraining. The framework consists of two components: the Universal Metalinguistic Framework (UMF), which represents languages as structured profiles across 16 typological dimensions with divergence-weighted scoring, and the Computational Engine, which operates through linguistic disambiguation during generation and typological compliance scoring during selection. Evaluation across nine language pairs demonstrates intervention rates strongly correlating with typological distance from English. In experiments on 341 English sentences each having different morphological and syntactic phenomena, the framework shows an intervention precision of 48.16% for conservatively treated languages, 28.15% for morphologically dense languages, and 86.26% for structurally profiled languages. The framework requires no parallel training data and operates with any LLM capable of producing multiple candidate outputs, enabling practical deployment for under-resourced languages.</li>
</ul>

<h3>Title: Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chunliang Hua, Zeyuan Yang, Lei Zhang, Jiayang Sun, Fengwen Chen, Chunlan Zeng, Xiao Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01163">https://arxiv.org/abs/2602.01163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01163">https://arxiv.org/pdf/2602.01163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01163]] Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models(https://arxiv.org/abs/2602.01163)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Safe UAV emergency landing requires more than just identifying flat terrain; it demands understanding complex semantic risks (e.g., crowds, temporary structures) invisible to traditional geometric sensors. In this paper, we propose a novel framework leveraging Remote Sensing (RS) imagery and Multimodal Large Language Models (MLLMs) for global context-aware landing site assessment. Unlike local geometric methods, our approach employs a coarse-to-fine pipeline: first, a lightweight semantic segmentation module efficiently pre-screens candidate areas; second, a vision-language reasoning agent fuses visual features with Point-of-Interest (POI) data to detect subtle hazards. To validate this approach, we construct and release the Emergency Landing Site Selection (ELSS) benchmark. Experiments demonstrate that our framework significantly outperforms geometric baselines in risk identification accuracy. Furthermore, qualitative results confirm its ability to generate human-like, interpretable justifications, enhancing trust in automated decision-making. The benchmark dataset is publicly accessible at this https URL.</li>
</ul>

<h3>Title: PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Shahem Sultan, Shahem Fadi, Yousef Melhim, Ibrahim Alsarraj, Besher Hassan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01169">https://arxiv.org/abs/2602.01169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01169">https://arxiv.org/pdf/2602.01169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01169]] PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues(https://arxiv.org/abs/2602.01169)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenge of improving interaction quality in dialogue based learning by detecting and recommending effective pedagogical strategies in tutor student conversations. We introduce PedagoSense, a pedology grounded system that combines a two stage strategy classifier with large language model generation. The system first detects whether a pedagogical strategy is present using a binary classifier, then performs fine grained classification to identify the specific strategy. In parallel, it recommends an appropriate strategy from the dialogue context and uses an LLM to generate a response aligned with that strategy. We evaluate on human annotated tutor student dialogues, augmented with additional non pedagogical conversations for the binary task. Results show high performance for pedagogical strategy detection and consistent gains when using data augmentation, while analysis highlights where fine grained classes remain challenging. Overall, PedagoSense bridges pedagogical theory and practical LLM based response generation for more adaptive educational technologies.</li>
</ul>

<h3>Title: EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment</h3>
<ul>
<li><strong>Authors: </strong>Lancheng Gao, Ziheng Jia, Zixuan Xing, Wei Sun, Huiyu Duan, Guangtao Zhai, Xiongkuo Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01173">https://arxiv.org/abs/2602.01173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01173">https://arxiv.org/pdf/2602.01173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01173]] EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment(https://arxiv.org/abs/2602.01173)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Understanding the multi-dimensional attributes and intensity nuances of image-evoked emotions is pivotal for advancing machine empathy and empowering diverse human-computer interaction applications. However, existing models are still limited to coarse-grained emotion perception or deficient reasoning capabilities. To bridge this gap, we introduce EEmoDB, the largest image-evoked emotion understanding dataset to date. It features $5$ analysis dimensions spanning $5$ distinct task categories, facilitating comprehensive interpretation. Specifically, we compile $1.2M$ question-answering (QA) pairs (EEmoDB-QA) from $125k$ images via automated generation, alongside a $36k$ dataset (EEmoDB-Assess) curated from $25k$ images for fine-grained assessment. Furthermore, we propose EEmo-Logic, an all-in-one multimodal large language model (MLLM) developed via instruction fine-tuning and task-customized group relative preference optimization (GRPO) with novel reward design. Extensive experiments demonstrate that EEmo-Logic achieves robust performance in in-domain and cross-domain datasets, excelling in emotion QA and fine-grained assessment. The code is available at this https URL.</li>
</ul>

<h3>Title: Analyzing and Improving Diffusion Models for Time-Series Data Imputation: A Proximal Recursion Perspective</h3>
<ul>
<li><strong>Authors: </strong>Zhichao Chen, Hao Wang, Fangyikang Wang, Licheng Pan, Zhengnan Li, Yunfei Teng, Haoxuan Li, Zhouchen Lin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01182">https://arxiv.org/abs/2602.01182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01182">https://arxiv.org/pdf/2602.01182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01182]] Analyzing and Improving Diffusion Models for Time-Series Data Imputation: A Proximal Recursion Perspective(https://arxiv.org/abs/2602.01182)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have shown promise for Time-Series Data Imputation (TSDI); however, their performance remains inconsistent in complex scenarios. We attribute this to two primary obstacles: (1) non-stationary temporal dynamics, which can bias the inference trajectory and lead to outlier-sensitive imputations; and (2) objective inconsistency, since imputation favors accurate pointwise recovery whereas DMs are inherently trained to generate diverse samples. To better understand these issues, we analyze DM-based TSDI process through a proximal-operator perspective and uncover that an implicit Wasserstein distance regularization inherent in the process hinders the model's ability to counteract non-stationarity and dissipative regularizer, thereby amplifying diversity at the expense of fidelity. Building on this insight, we propose a novel framework called SPIRIT (Semi-Proximal Transport Regularized time-series Imputation). Specifically, we introduce entropy-induced Bregman divergence to relax the mass preserving constraint in the Wasserstein distance, formulate the semi-proximal transport (SPT) discrepancy, and theoretically prove the robustness of SPT against non-stationarity. Subsequently, we remove the dissipative structure and derive the complete SPIRIT workflow, with SPT serving as the proximal operator. Extensive experiments demonstrate the effectiveness of the proposed SPIRIT approach.</li>
</ul>

<h3>Title: Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion</h3>
<ul>
<li><strong>Authors: </strong>Chunming He, Rihan Zhang, Fengyang Xiao, Dingming Zhang, Zhiwen Cao, Sina Farsiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01183">https://arxiv.org/abs/2602.01183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01183">https://arxiv.org/pdf/2602.01183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01183]] Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion(https://arxiv.org/abs/2602.01183)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Biological learning proceeds from easy to difficult tasks, gradually reinforcing perception and robustness. Inspired by this principle, we address Context-Entangled Content Segmentation (CECS), a challenging setting where objects share intrinsic visual patterns with their surroundings, as in camouflaged object detection. Conventional segmentation networks predominantly rely on architectural enhancements but often ignore the learning dynamics that govern robustness under entangled data distributions. We introduce CurriSeg, a dual-phase learning framework that unifies curriculum and anti-curriculum principles to improve representation reliability. In the Curriculum Selection phase, CurriSeg dynamically selects training data based on the temporal statistics of sample losses, distinguishing hard-but-informative samples from noisy or ambiguous ones, thus enabling stable capability enhancement. In the Anti-Curriculum Promotion phase, we design Spectral-Blindness Fine-Tuning, which suppresses high-frequency components to enforce dependence on low-frequency structural and contextual cues and thus strengthens generalization. Extensive experiments demonstrate that CurriSeg achieves consistent improvements across diverse CECS benchmarks without adding parameters or increasing total training time, offering a principled view of how progression and challenge interplay to foster robust and context-aware segmentation. Code will be released.</li>
</ul>

<h3>Title: FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems</h3>
<ul>
<li><strong>Authors: </strong>Fabio Turazza, Marcello Pietri, Marco Picone, Marco Mamei</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01185">https://arxiv.org/abs/2602.01185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01185">https://arxiv.org/pdf/2602.01185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01185]] FedBGS: A Blockchain Approach to Segment Gossip Learning in Decentralized Systems(https://arxiv.org/abs/2602.01185)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, attack, federate</a></li>
<li><strong>Abstract: </strong>Privacy-Preserving Federated Learning (PPFL) is a Decentralized machine learning paradigm that enables multiple participants to collaboratively train a global model without sharing their data with the integration of cryptographic and privacy-based techniques to enhance the security of the global system. This privacy-oriented approach makes PPFL a highly suitable solution for training shared models in sectors where data privacy is a critical concern. In traditional FL, local models are trained on edge devices, and only model updates are shared with a central server, which aggregates them to improve the global model. However, despite the presence of the aforementioned privacy techniques, in the classical Federated structure, the issue of the server as a single-point-of-failure remains, leading to limitations both in terms of security and scalability. This paper introduces FedBGS, a fully Decentralized Blockchain-based framework that leverages Segmented Gossip Learning through Federated Analytics. The proposed system aims to optimize blockchain usage while providing comprehensive protection against all types of attacks, ensuring both privacy, security and non-IID data handling in Federated environments.</li>
</ul>

<h3>Title: The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics</h3>
<ul>
<li><strong>Authors: </strong>Fabio Turazza, Marco Picone, Marco Mamei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01186">https://arxiv.org/abs/2602.01186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01186">https://arxiv.org/pdf/2602.01186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01186]] The Gaussian-Head OFL Family: One-Shot Federated Learning from Client Global Statistics(https://arxiv.org/abs/2602.01186)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, data-free</a></li>
<li><strong>Abstract: </strong>Classical Federated Learning relies on a multi-round iterative process of model exchange and aggregation between server and clients, with high communication costs and privacy risks from repeated model transmissions. In contrast, one-shot federated learning (OFL) alleviates these limitations by reducing communication to a single round, thereby lowering overhead and enhancing practical deployability. Nevertheless, most existing one-shot approaches remain either impractical or constrained, for example, they often depend on the availability of a public dataset, assume homogeneous client models, or require uploading additional data or model information. To overcome these issues, we introduce the Gaussian-Head OFL (GH-OFL) family, a suite of one-shot federated methods that assume class-conditional Gaussianity of pretrained embeddings. Clients transmit only sufficient statistics (per-class counts and first/second-order moments) and the server builds heads via three components: (i) Closed-form Gaussian heads (NB/LDA/QDA) computed directly from the received statistics; (ii) FisherMix, a linear head with cosine margin trained on synthetic samples drawn in an estimated Fisher subspace; and (iii) Proto-Hyper, a lightweight low-rank residual head that refines Gaussian logits via knowledge distillation on those synthetic samples. In our experiments, GH-OFL methods deliver state-of-the-art robustness and accuracy under strong non-IID skew while remaining strictly data-free.</li>
</ul>

<h3>Title: Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation</h3>
<ul>
<li><strong>Authors: </strong>Shashini Nilukshi, Deshan Sumanathilaka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01193">https://arxiv.org/abs/2602.01193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01193">https://arxiv.org/pdf/2602.01193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01193]] Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation(https://arxiv.org/abs/2602.01193)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.</li>
</ul>

<h3>Title: EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hao Chen, Tao Han, Jie Zhang, Song Guo, Fenghua Ling, Lei Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01194">https://arxiv.org/abs/2602.01194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01194">https://arxiv.org/pdf/2602.01194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01194]] EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting(https://arxiv.org/abs/2602.01194)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long-term weather forecasting is critical for socioeconomic planning and disaster preparedness. While recent approaches employ finetuning to extend prediction horizons, they remain constrained by the issues of catastrophic forgetting, error accumulation, and high training overhead. To address these limitations, we present a novel pipeline across pretraining, finetuning and forecasting to enhance long-context modeling while reducing computational overhead. First, we introduce an Efficient Multi-scale Transformer (EMFormer) to extract multi-scale features through a single convolution in both training and inference. Based on the new architecture, we further employ an accumulative context finetuning to improve temporal consistency without degrading short-term accuracy. Additionally, we propose a composite loss that dynamically balances different terms via a sinusoidal weighting, thereby adaptively guiding the optimization trajectory throughout pretraining and finetuning. Experiments show that our approach achieves strong performance in weather forecasting and extreme event prediction, substantially improving long-term forecast accuracy. Moreover, EMFormer demonstrates strong generalization on vision benchmarks (ImageNet-1K and ADE20K) while delivering a 5.69x speedup over conventional multi-scale modules.</li>
</ul>

<h3>Title: Unraveling the Hidden Dynamical Structure in Recurrent Neural Policies</h3>
<ul>
<li><strong>Authors: </strong>Jin Li, Yue Wu, Mengsha Huang, Yuhao Sun, Hao He, Xianyuan Zhan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01196">https://arxiv.org/abs/2602.01196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01196">https://arxiv.org/pdf/2602.01196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01196]] Unraveling the Hidden Dynamical Structure in Recurrent Neural Policies(https://arxiv.org/abs/2602.01196)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recurrent neural policies are widely used in partially observable control and meta-RL tasks. Their abilities to maintain internal memory and adapt quickly to unseen scenarios have offered them unparalleled performance when compared to non-recurrent counterparts. However, until today, the underlying mechanisms for their superior generalization and robustness performance remain poorly understood. In this study, by analyzing the hidden state domain of recurrent policies learned over a diverse set of training methods, model architectures, and tasks, we find that stable cyclic structures consistently emerge during interaction with the environment. Such cyclic structures share a remarkable similarity with \textit{limit cycles} in dynamical system analysis, if we consider the policy and the environment as a joint hybrid dynamical system. Moreover, we uncover that the geometry of such limit cycles also has a structured correspondence with the policies' behaviors. These findings offer new perspectives to explain many nice properties of recurrent policies: the emergence of limit cycles stabilizes both the policies' internal memory and the task-relevant environmental states, while suppressing nuisance variability arising from environmental uncertainty; the geometry of limit cycles also encodes relational structures of behaviors, facilitating easier skill adaptation when facing non-stationary environments.</li>
</ul>

<h3>Title: Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Haoran Lai, Zihang Jiang, Kun Zhang, Qingsong Yao, Rongsheng Wang, Zhiyang He, Xiaodong Tao, Wei Wei, Shaohua Kevin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01200">https://arxiv.org/abs/2602.01200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01200">https://arxiv.org/pdf/2602.01200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01200]] Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis(https://arxiv.org/abs/2602.01200)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\% on CT-RATE and 44.99\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.</li>
</ul>

<h3>Title: Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse</h3>
<ul>
<li><strong>Authors: </strong>Zizhuo Fu, Wenxuan Zeng, Runsheng Wang, Meng Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01203">https://arxiv.org/abs/2602.01203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01203">https://arxiv.org/pdf/2602.01203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01203]] Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse(https://arxiv.org/abs/2602.01203)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often assign disproportionate attention to the first token, a phenomenon known as the attention sink. Several recent approaches aim to address this issue, including Sink Attention in GPT-OSS and Gated Attention in Qwen3-Next. However, a comprehensive analysis of the relationship among these attention mechanisms is lacking. In this work, we provide both theoretical and empirical evidence demonstrating that the sink in Vanilla Attention and Sink Attention naturally construct a Mixture-of-Experts (MoE) mechanism within attention layers. This insight explains the head collapse phenomenon observed in prior work, where only a fixed subset of attention heads contributes to generation. To mitigate head collapse, we propose a sink-aware training algorithm with an auxiliary load balancing loss designed for attention layers. Extensive experiments show that our method achieves effective head load balancing and improves model performance across Vanilla Attention, Sink Attention, and Gated Attention. We hope this study offers a new perspective on attention mechanisms and encourages further exploration of the inherent MoE structure within attention layers.</li>
</ul>

<h3>Title: ASTER: Agentic Scaling with Tool-integrated Extended Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xuqin Zhang, Quan He, Zhenrui Zheng, Zongzhang Zhang, Xu He, Dong Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01204">https://arxiv.org/abs/2602.01204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01204">https://arxiv.org/pdf/2602.01204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01204]] ASTER: Agentic Scaling with Tool-integrated Extended Reasoning(https://arxiv.org/abs/2602.01204)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has emerged as a dominant paradigm for eliciting long-horizon reasoning in Large Language Models (LLMs). However, scaling Tool-Integrated Reasoning (TIR) via RL remains challenging due to interaction collapse: a pathological state where models fail to sustain multi-turn tool usage, instead degenerating into heavy internal reasoning with only trivial, post-hoc code verification. We systematically study three questions: (i) how cold-start SFT induces an agentic, tool-using behavioral prior, (ii) how the interaction density of cold-start trajectories shapes exploration and downstream RL outcomes, and (iii) how the RL interaction budget affects learning dynamics and generalization under varying inference-time budgets. We then introduce ASTER (Agentic Scaling with Tool-integrated Extended Reasoning), a framework that circumvents this collapse through a targeted cold-start strategy prioritizing interaction-dense trajectories. We find that a small expert cold-start set of just 4K interaction-dense trajectories yields the strongest downstream performance, establishing a robust prior that enables superior exploration during extended RL training. Extensive evaluations demonstrate that ASTER-4B achieves state-of-the-art results on competitive mathematical benchmarks, reaching 90.0% on AIME 2025, surpassing leading frontier open-source models, including DeepSeek-V3.2-Exp.</li>
</ul>

<h3>Title: Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Kai Zhang, Jiayi Liao, Chengpeng Li, Ziyuan Xie, Sihang Li, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01208">https://arxiv.org/abs/2602.01208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01208">https://arxiv.org/pdf/2602.01208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01208]] Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling(https://arxiv.org/abs/2602.01208)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-Time Scaling (TTS) has emerged as an effective paradigm for improving the reasoning performance of large language models (LLMs). However, existing methods -- most notably majority voting and heuristic token-level scoring -- treat reasoning traces or tokens equally, thereby being susceptible to substantial variations in trajectory quality and localized logical failures. In this work, we introduce \textbf{Chronos}, a lightweight and plug-and-play chronological reasoning scorer that models each trajectory as a time series. Specifically, Chronos learns to capture trajectory features of token probabilities, assigns quality scores accordingly, and employs a weighted voting mechanism. Extensive evaluations on both in-domain and out-of-domain benchmarks demonstrate that Chronos consistently delivers substantial gains across a variety of models, with negligible computational overhead. Notably, Chronos@128 achieves relative improvements of 34.21\% over Pass@1 and 22.70\% over Maj@128 on HMMT25 using Qwen3-4B-Thinking-2507, highlighting its effectiveness.</li>
</ul>

<h3>Title: SimpleGPT: Improving GPT via A Simple Normalization Strategy</h3>
<ul>
<li><strong>Authors: </strong>Marco Chen, Xianbiao Qi, Yelin He, Jiaquan Ye, Rong Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01212">https://arxiv.org/abs/2602.01212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01212">https://arxiv.org/pdf/2602.01212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01212]] SimpleGPT: Improving GPT via A Simple Normalization Strategy(https://arxiv.org/abs/2602.01212)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we revisit Transformer optimization through the lens of second-order geometry and establish a direct connection between architectural design, activation scale, the Hessian matrix, and the maximum tolerable learning rate. We introduce a simple normalization strategy, termed SimpleNorm, which stabilizes intermediate activation scales by construction. Then, by analyzing the Hessian of the loss with respect to network activations, we theoretically show that SimpleNorm significantly reduces the spectral norm of the Hessian, thereby permitting larger stable learning rates. We validate our theoretical findings through extensive experiments on large GPT models at parameter scales 1B, 1.4B, 7B and 8B. Empirically, SimpleGPT, our SimpleNorm-based network, tolerates learning rates 3$\times$-10$\times$ larger than standard convention, consistently demonstrates strong optimization stability, and achieves substantially better performance than well-established baselines. Specifically, when training 7B-scale models for 60K steps, SimpleGPT achieves a training loss that is 0.08 lower than that of LLaMA2 with QKNorm, reducing the loss from 2.290 to 2.208. Our source code will be released at this https URL.</li>
</ul>

<h3>Title: Learning from Anonymized and Incomplete Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Lucas Lange, Adrian Böttinger, Victor Christen, Anushka Vidanage, Peter Christen, Erhard Rahm</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01217">https://arxiv.org/abs/2602.01217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01217">https://arxiv.org/pdf/2602.01217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01217]] Learning from Anonymized and Incomplete Tabular Data(https://arxiv.org/abs/2602.01217)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>User-driven privacy allows individuals to control whether and at what granularity their data is shared, leading to datasets that mix original, generalized, and missing values within the same records and attributes. While such representations are intuitive for privacy, they pose challenges for machine learning, which typically treats non-original values as new categories or as missing, thereby discarding generalization semantics. For learning from such tabular data, we propose novel data transformation strategies that account for heterogeneous anonymization and evaluate them alongside standard imputation and LLM-based approaches. We employ multiple datasets, privacy configurations, and deployment scenarios, demonstrating that our method reliably regains utility. Our results show that generalized values are preferable to pure suppression, that the best data preparation strategy depends on the scenario, and that consistent data representations are crucial for maintaining downstream utility. Overall, our findings highlight that effective learning is tied to the appropriate handling of anonymized values.</li>
</ul>

<h3>Title: MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-$k$ Activations</h3>
<ul>
<li><strong>Authors: </strong>Qishuai Wen, Zhiyuan Huang, Xianghan Meng, Wei He, Chun-Guang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01219">https://arxiv.org/abs/2602.01219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01219">https://arxiv.org/pdf/2602.01219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01219]] MiTA Attention: Efficient Fast-Weight Scaling via a Mixture of Top-$k$ Activations(https://arxiv.org/abs/2602.01219)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The attention operator in Transformers can be viewed as a two-layer fast-weight MLP, whose weights are dynamically instantiated from input tokens and whose width equals sequence length $N$. As the context extends, the expressive capacity of such an $N$-width MLP increases, but scaling its fast weights becomes prohibitively expensive for extremely long sequences. Recently, this fast-weight scaling perspective has motivated the Mixture-of-Experts (MoE) attention, which partitions the sequence into fast-weight experts and sparsely routes the tokens to them. In this paper, we elevate this perspective to a unifying framework for a wide range of efficient attention methods by interpreting them as scaling fast weights through routing and/or compression. Then we propose a compress-and-route strategy, which compresses the $N$-width MLP into a narrower one using a small set of landmark queries and constructs deformable experts by gathering top-$k$ activated key-value pairs for each landmark query. We call this strategy a Mixture of Top-$k$ Activations (MiTA), and refer to the resulting efficient mechanism as MiTA attention. Preliminary experiments on vision tasks demonstrate the promise of our MiTA attention and motivate further investigation on its optimization and broader applications in more challenging settings.</li>
</ul>

<h3>Title: Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics</h3>
<ul>
<li><strong>Authors: </strong>Shuyu Chen, Mingxun Zhou, Haoyu Niu, Guopeng Lin, Weili Han</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01225">https://arxiv.org/abs/2602.01225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01225">https://arxiv.org/pdf/2602.01225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01225]] Bifrost: A Much Simpler Secure Two-Party Data Join Protocol for Secure Data Analytics(https://arxiv.org/abs/2602.01225)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Secure data join enables two parties with vertically distributed data to securely compute the joined table, allowing the parties to perform downstream Secure multi-party computation-based Data Analytics (SDA), such as training machine learning models, based on the joined table. While Circuit-based Private Set Intersection (CPSI) can be used for secure data join, it introduces redundant dummy rows in the joined table, which results in high overhead in the downstream SDA tasks. iPrivJoin addresses this issue but introduces significant communication overhead in the redundancy removal process, as it relies on the cryptographic primitive OPPRF for data encoding and multiple rounds of oblivious shuffles. In this paper, we propose a much simpler secure data join protocol, Bifrost, which outputs (the secret shares of) a redundancy-free joined table. The highlight of Bifrost lies in its simplicity: it builds upon two conceptually simple building blocks, an ECDH-PSI protocol and a two-party oblivious shuffle protocol. The lightweight protocol design allows Bifrost to avoid the need for OPPRF. We also proposed a simple optimization named \textit{dual mapping} that reduces the rounds of oblivious shuffle needed from two to one. Experiments on datasets of up to 100 GB show that Bifrost achieves $2.54 \sim 22.32\times$ speedup and reduces the communication by $84.15\% \sim 88.97\%$ compared to the SOTA redundancy-free secure data join protocol iPrivJoin. Notably, the communication size of Bifrost is nearly equal to the size of the input data. In the two-step SDA pipeline evaluation (secure join and SDA), the redundancy-free property of Bifrost not only avoids the catastrophic error rate blowup in the downstream tasks caused by the dummy rows in the joined table (as introduced in CPSI), but also shows up to $2.80\times$ speed-up in the SDA process with up to $73.15\%$ communication reduction.</li>
</ul>

<h3>Title: Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Ke Sun, Guangsheng Bao, Han Cui, Yue Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01240">https://arxiv.org/abs/2602.01240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01240">https://arxiv.org/pdf/2602.01240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01240]] Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection(https://arxiv.org/abs/2602.01240)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Zero-shot methods detect LLM-generated text by computing statistical signatures using a surrogate model. Existing approaches typically employ a fixed surrogate for all inputs regardless of the unknown source. We systematically examine this design and find that detection performance varies substantially depending on surrogate-source alignment. We observe that while no single surrogate achieves optimal performance universally, a well-matched surrogate typically exists within a diverse pool for any given input. This finding transforms robust detection into a routing problem: selecting the most appropriate surrogate for each input. We propose DetectRouter, a prototype-based framework that learns text-detector affinity through two-stage training. The first stage constructs discriminative prototypes from white-box models; the second generalizes to black-box sources by aligning geometric distances with observed detection scores. Experiments on EvoBench and MAGE benchmarks demonstrate consistent improvements across multiple detection criteria and model families.</li>
</ul>

<h3>Title: PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian</h3>
<ul>
<li><strong>Authors: </strong>Jamshid Mozafari, Seyed Parsa Mousavinasab, Adam Jatowt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01246">https://arxiv.org/abs/2602.01246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01246">https://arxiv.org/pdf/2602.01246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01246]] PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian(https://arxiv.org/abs/2602.01246)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Reasoning-focused Question Answering (QA) has advanced rapidly with Large Language Models (LLMs), yet high-quality benchmarks for low-resource languages remain scarce. Persian, spoken by roughly 130 million people, lacks a comprehensive open-domain resource for evaluating reasoning-capable QA systems. We introduce PARSE, the first open-domain Persian reasoning QA benchmark, containing 10,800 questions across Boolean, multiple-choice, and factoid formats, with diverse reasoning types, difficulty levels, and answer structures. The benchmark is built via a controlled LLM-based generation pipeline and validated through human evaluation. We also ensure linguistic and factual quality through multi-stage filtering, annotation, and consistency checks. We benchmark multilingual and Persian LLMs under multiple prompting strategies and show that Persian prompts and structured prompting (CoT for Boolean/multiple-choice; few-shot for factoid) improve performance. Fine-tuning further boosts results, especially for Persian-specialized models. These findings highlight how PARSE supports both fair comparison and practical model adaptation. PARSE fills a critical gap in Persian QA research and provides a strong foundation for developing and evaluating reasoning-capable LLMs in low-resource settings.</li>
</ul>

<h3>Title: Mechanistic Interpretability of Brain-to-Speech Models Across Speech Modes</h3>
<ul>
<li><strong>Authors: </strong>Maryam Maghsoudi, Ayushi Mishra</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01247">https://arxiv.org/abs/2602.01247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01247">https://arxiv.org/pdf/2602.01247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01247]] Mechanistic Interpretability of Brain-to-Speech Models Across Speech Modes(https://arxiv.org/abs/2602.01247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Brain-to-speech decoding models demonstrate robust performance in vocalized, mimed, and imagined speech; yet, the fundamental mechanisms via which these models capture and transmit information across different speech modalities are less explored. In this work, we use mechanistic interpretability to causally investigate the internal representations of a neural speech decoder. We perform cross-mode activation patching of internal activations across speech modes, and use tri-modal interpolation to examine whether speech representations vary discretely or continuously. We use coarse-to-fine causal tracing and causal scrubbing to find localized causal structure, allowing us to find internal subspaces that are sufficient for cross-mode transfer. In order to determine how finely distributed these effects are within layers, we perform neuron-level activation patching. We discover that small but not distributed subsets of neurons, rather than isolated units, affect the cross-mode transfer. Our results show that speech modes lie on a shared continuous causal manifold, and cross-mode transfer is mediated by compact, layer-specific subspaces rather than diffuse activity. Together, our findings give a causal explanation for how speech modality information is organized and used in brain-to-speech decoding models, revealing hierarchical and direction-dependent representational structure across speech modes.</li>
</ul>

<h3>Title: OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth</h3>
<ul>
<li><strong>Authors: </strong>Jaehyeon Cho, Jhonghyun An</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01268">https://arxiv.org/abs/2602.01268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01268">https://arxiv.org/pdf/2602.01268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01268]] OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth(https://arxiv.org/abs/2602.01268)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent monocular foundation models excel at zero-shot depth estimation, yet their outputs are inherently relative rather than metric, limiting direct use in robotics and autonomous driving. We leverage the fact that relative depth preserves global layout and boundaries: by calibrating it with sparse range measurements, we transform it into a pseudo metric depth prior. Building on this prior, we design a refinement network that follows the prior where reliable and deviates where necessary, enabling accurate metric predictions from very few labeled samples. The resulting system is particularly effective when curated validation data are unavailable, sustaining stable scale and sharp edges across few-shot regimes. These findings suggest that coupling foundation priors with sparse anchors is a practical route to robust, deployment-ready depth completion under real-world label scarcity.</li>
</ul>

<h3>Title: Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Boxuan Zhang, Weipu Zhang, Zhaohan Feng, Wei Xiao, Jian Sun, Jie Chen, Gang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01270">https://arxiv.org/abs/2602.01270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01270">https://arxiv.org/pdf/2602.01270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01270]] Mixture-of-World Models: Scaling Multi-Task Reinforcement Learning with Modular Latent Dynamics(https://arxiv.org/abs/2602.01270)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A fundamental challenge in multi-task reinforcement learning (MTRL) is achieving sample efficiency in visual domains where tasks exhibit substantial heterogeneity in both observations and dynamics. Model-based reinforcement learning offers a promising path to improved sample efficiency through world models, but standard monolithic architectures struggle to capture diverse task dynamics, resulting in poor reconstruction and prediction accuracy. We introduce Mixture-of-World Models (MoW), a scalable architecture that combines modular variational autoencoders for task-adaptive visual compression, a hybrid Transformer-based dynamics model with task-conditioned experts and a shared backbone, and a gradient-based task clustering strategy for efficient parameter allocation. On the Atari 100k benchmark, a single MoW agent trained once on 26 Atari games achieves a mean human-normalized score of 110.4%, competitive with the score of 114.2% achieved by STORM, an ensemble of 26 task-specific models, while using 50% fewer parameters. On Meta-World, MoW achieves a 74.5% average success rate within 300 thousand environment steps, establishing a new state of the art. These results demonstrate that MoW provides a scalable and parameter-efficient foundation for generalist world models.</li>
</ul>

<h3>Title: Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Xun Zhang, Kaicheng Yang, Hongliang Lu, Haotong Qin, Yong Guo, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01273">https://arxiv.org/abs/2602.01273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01273">https://arxiv.org/pdf/2602.01273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01273]] Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution(https://arxiv.org/abs/2602.01273)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, data-free, transformer</a></li>
<li><strong>Abstract: </strong>Recently, Diffusion Transformers (DiTs) have emerged in Real-World Image Super-Resolution (Real-ISR) to generate high-quality textures, yet their heavy inference burden hinders real-world deployment. While Post-Training Quantization (PTQ) is a promising solution for acceleration, existing methods in super-resolution mostly focus on U-Net architectures, whereas generic DiT quantization is typically designed for text-to-image tasks. Directly applying these methods to DiT-based super-resolution models leads to severe degradation of local textures. Therefore, we propose Q-DiT4SR, the first PTQ framework specifically tailored for DiT-based Real-ISR. We propose H-SVD, a hierarchical SVD that integrates a global low-rank branch with a local block-wise rank-1 branch under a matched parameter budget. We further propose Variance-aware Spatio-Temporal Mixed Precision: VaSMP allocates cross-layer weight bit-widths in a data-free manner based on rate-distortion theory, while VaTMP schedules intra-layer activation precision across diffusion timesteps via dynamic programming (DP) with minimal calibration. Experiments on multiple real-world datasets demonstrate that our Q-DiT4SR achieves SOTA performance under both W4A6 and W4A4 settings. Notably, the W4A4 quantization configuration reduces model size by 5.8$\times$ and computational operations by over 60$\times$. Our code and models will be available at this https URL.</li>
</ul>

<h3>Title: PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length</h3>
<ul>
<li><strong>Authors: </strong>Situo Zhang, Yifan Zhang, Zichen Zhu, Hankun Wang, Da Ma, Danyang Zhang, Lu Chen, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01274">https://arxiv.org/abs/2602.01274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01274">https://arxiv.org/pdf/2602.01274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01274]] PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length(https://arxiv.org/abs/2602.01274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.</li>
</ul>

<h3>Title: TF-Lane: Traffic Flow Module for Robust Lane Perception</h3>
<ul>
<li><strong>Authors: </strong>Yihan Xie, Han Xia, Zhen Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01277">https://arxiv.org/abs/2602.01277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01277">https://arxiv.org/pdf/2602.01277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01277]] TF-Lane: Traffic Flow Module for Robust Lane Perception(https://arxiv.org/abs/2602.01277)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Autonomous driving systems require robust lane perception capabilities, yet existing vision-based detection methods suffer significant performance degradation when visual sensors provide insufficient cues, such as in occluded or lane-missing scenarios. While some approaches incorporate high-definition maps as supplementary information, these solutions face challenges of high subscription costs and limited real-time performance. To address these limitations, we explore an innovative information source: traffic flow, which offers real-time capabilities without additional costs. This paper proposes a TrafficFlow-aware Lane perception Module (TFM) that effectively extracts real-time traffic flow features and seamlessly integrates them with existing lane perception algorithms. This solution originated from real-world autonomous driving conditions and was subsequently validated on open-source algorithms and datasets. Extensive experiments on four mainstream models and two public datasets (Nuscenes and OpenLaneV2) using standard evaluation metrics show that TFM consistently improves performance, achieving up to +4.1% mAP gain on the Nuscenes dataset.</li>
</ul>

<h3>Title: DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction</h3>
<ul>
<li><strong>Authors: </strong>Zhengbo Zhang, Yihe Tian, Wanke Xia, Lin Chen, Yue Sun, Kun Ding, Ying Wang, Bing Xu, Shiming Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01278">https://arxiv.org/abs/2602.01278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01278">https://arxiv.org/pdf/2602.01278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01278]] DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction(https://arxiv.org/abs/2602.01278)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate extraction of rural roads from high-resolution remote sensing imagery is essential for infrastructure planning and sustainable development. However, this task presents unique challenges in rural settings due to several factors. These include high intra-class variability and low inter-class separability from diverse surface materials, frequent vegetation occlusions that disrupt spatial continuity, and narrow road widths that exacerbate detection difficulties. Existing methods, primarily optimized for structured urban environments, often underperform in these scenarios as they overlook such distinctive characteristics. To address these challenges, we propose DSFC-Net, a dual-encoder framework that synergistically fuses spatial and frequency-domain information. Specifically, a CNN branch is employed to capture fine-grained local road boundaries and short-range continuity, while a novel Spatial-Frequency Hybrid Transformer (SFT) is introduced to robustly model global topological dependencies against vegetation occlusions. Distinct from standard attention mechanisms that suffer from frequency bias, the SFT incorporates a Cross-Frequency Interaction Attention (CFIA) module that explicitly decouples high- and low-frequency information via a Laplacian Pyramid strategy. This design enables the dynamic interaction between spatial details and frequency-aware global contexts, effectively preserving the connectivity of narrow roads. Furthermore, a Channel Feature Fusion Module (CFFM) is proposed to bridge the two branches by adaptively recalibrating channel-wise feature responses, seamlessly integrating local textures with global semantics for accurate segmentation. Comprehensive experiments on the WHU-RuR+, DeepGlobe, and Massachusetts datasets validate the superiority of DSFC-Net over state-of-the-art approaches.</li>
</ul>

<h3>Title: Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons</h3>
<ul>
<li><strong>Authors: </strong>Xianhui Zhang, Chengyu Xie, Linxia Zhu, Yonghui Yang, Weixiang Zhao, Zifeng Cheng, Cong Wang, Fei Shen, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01283">https://arxiv.org/abs/2602.01283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01283">https://arxiv.org/pdf/2602.01283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01283]] Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons(https://arxiv.org/abs/2602.01283)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multilingual safety remains significantly imbalanced, leaving non-high-resource (NHR) languages vulnerable compared to robust high-resource (HR) ones. Moreover, the neural mechanisms driving safety alignment remain unclear despite observed cross-lingual representation transfer. In this paper, we find that LLMs contain a set of cross-lingual shared safety neurons (SS-Neurons), a remarkably small yet critical neuronal subset that jointly regulates safety behavior across languages. We first identify monolingual safety neurons (MS-Neurons) and validate their causal role in safety refusal behavior through targeted activation and suppression. Our cross-lingual analyses then identify SS-Neurons as the subset of MS-Neurons shared between HR and NHR languages, serving as a bridge to transfer safety capabilities from HR to NHR domains. We observe that suppressing these neurons causes concurrent safety drops across NHR languages, whereas reinforcing them improves cross-lingual defensive consistency. Building on these insights, we propose a simple neuron-oriented training strategy that targets SS-Neurons based on language resource distribution and model architecture. Experiments demonstrate that fine-tuning this tiny neuronal subset outperforms state-of-the-art methods, significantly enhancing NHR safety while maintaining the model's general capabilities. The code and dataset will be available athttps://github.com/1518630367/SS-Neuron-Expansion.</li>
</ul>

<h3>Title: Multi-LLM Adaptive Conformal Inference for Reliable LLM Responses</h3>
<ul>
<li><strong>Authors: </strong>Kangjun Noh, Seongchan Lee, Ilmun Kim, Kyungwoo Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01285">https://arxiv.org/abs/2602.01285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01285">https://arxiv.org/pdf/2602.01285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01285]] Multi-LLM Adaptive Conformal Inference for Reliable LLM Responses(https://arxiv.org/abs/2602.01285)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensuring factuality is essential for the safe use of Large Language Models (LLMs) in high-stakes domains such as medicine and law. Conformal inference provides distribution-free guarantees, but existing approaches are either overly conservative, discarding many true-claims, or rely on adaptive error rates and simple linear models that fail to capture complex group structures. To address these challenges, we reformulate conformal inference in a multiplicative filtering setting, modeling factuality as a product of claim-level scores. Our method, Multi-LLM Adaptive Conformal Inference (MACI), leverages ensembles to produce more accurate factuality-scores, which in our experiments led to higher retention, while validity is preserved through group-conditional calibration. Experiments show that MACI consistently achieves user-specified coverage with substantially higher retention and lower time cost than baselines. Our repository is available at this https URL</li>
</ul>

<h3>Title: EDIS: Diagnosing LLM Reasoning via Entropy Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Chenghua Zhu, Siyan Wu, Xiangkang Zeng, Zishan Xu, Zhaolu Kang, Yifu Guo, Yuquan Lu, Junduan Huang, Guojing Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01288">https://arxiv.org/abs/2602.01288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01288">https://arxiv.org/pdf/2602.01288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01288]] EDIS: Diagnosing LLM Reasoning via Entropy Dynamics(https://arxiv.org/abs/2602.01288)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Entropy-based confidence signals are increasingly leveraged to improve reasoning in large language models (LLMs), yet existing approaches treat confidence as a static quantity -- typically aggregated over tokens. We show that the \emph{temporal evolution} of confidence during generation carries richer information than aggregate statistics alone. Analyzing token-level entropy trajectories, we identify characteristic patterns distinguishing correct from incorrect reasoning: erroneous solutions exhibit unstable dynamics, including burst spikes (sustained uncertainty growth) and peak-valley spikes (sharp rebounds following transient confidence). These patterns persist across models and training stages, suggesting they reflect intrinsic properties of reasoning failure rather than superficial noise. To formalize this observation, we introduce the Entropy Dynamics Instability Score (\textbf{EDIS}), a trajectory-level metric quantifying instability in entropy evolution. EDIS serves as an effective diagnostic signal for inference-time selection, substantially improving reasoning accuracy, and offers a promising direction for training-time sample curation. Our findings establish entropy dynamics as an underexplored yet informative lens for understanding and improving LLM reasoning.</li>
</ul>

<h3>Title: Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Dung Anh Hoang, Cuong Pham anh Trung Le, Jianfei Cai, Toan Do</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01289">https://arxiv.org/abs/2602.01289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01289">https://arxiv.org/pdf/2602.01289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01289]] Gradient-Aligned Calibration for Post-Training Quantization of Diffusion Models(https://arxiv.org/abs/2602.01289)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown remarkable performance in image synthesis by progressively estimating a smooth transition from a Gaussian distribution of noise to a real image. Unfortunately, their practical deployment is limited by slow inference speed, high memory usage, and the computational demands of the noise estimation process. Post-training quantization (PTQ) emerges as a promising solution to accelerate sampling and reduce memory overhead for diffusion models. Existing PTQ methods for diffusion models typically apply uniform weights to calibration samples across timesteps, which is sub-optimal since data at different timesteps may contribute differently to the diffusion process. Additionally, due to varying activation distributions and gradients across timesteps, a uniform quantization approach is sub-optimal. Each timestep requires a different gradient direction for optimal quantization, and treating them equally can lead to conflicting gradients that degrade performance. In this paper, we propose a novel PTQ method that addresses these challenges by assigning appropriate weights to calibration samples. Specifically, our approach learns to assign optimal weights to calibration samples to align the quantized model's gradients across timesteps, facilitating the quantization process. Extensive experiments on CIFAR-10, LSUN-Bedrooms, and ImageNet demonstrate the superiority of our method compared to other PTQ methods for diffusion models.</li>
</ul>

<h3>Title: Interaction-Consistent Object Removal via MLLM-Based Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ching-Kai Huang, Wen-Chieh Lin, Yan-Cen Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01298">https://arxiv.org/abs/2602.01298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01298">https://arxiv.org/pdf/2602.01298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01298]] Interaction-Consistent Object Removal via MLLM-Based Reasoning(https://arxiv.org/abs/2602.01298)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Image-based object removal often erases only the named target, leaving behind interaction evidence that renders the result semantically inconsistent. We formalize this problem as Interaction-Consistent Object Removal (ICOR), which requires removing not only the target object but also associated interaction elements, such as lighting-dependent effects, physically connected objects, targetproduced elements, and contextually linked objects. To address this task, we propose Reasoning-Enhanced Object Removal with MLLM (REORM), a reasoningenhanced object removal framework that leverages multimodal large language models to infer which elements must be jointly removed. REORM features a modular design that integrates MLLM-driven analysis, mask-guided removal, and a self-correction mechanism, along with a local-deployment variant that supports accurate editing under limited resources. To support evaluation, we introduce ICOREval, a benchmark consisting of instruction-driven removals with rich interaction dependencies. On ICOREval, REORM outperforms state-of-the-art image editing systems, demonstrating its effectiveness in producing interactionconsistent results.</li>
</ul>

<h3>Title: ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation</h3>
<ul>
<li><strong>Authors: </strong>Ayushman Sarkar, Zhenyu Yu, Chu Chen, Wei Tang, Kangning Cui, Mohd Yamani Idna Idris</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01303">https://arxiv.org/abs/2602.01303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01303">https://arxiv.org/pdf/2602.01303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01303]] ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation(https://arxiv.org/abs/2602.01303)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating coherent visual stories requires maintaining subject identity across multiple images while preserving frame-specific semantics. Recent training-free methods concatenate identity and frame prompts into a unified representation, but this often introduces inter-frame semantic interference that weakens identity preservation in complex stories. We propose ReDiStory, a training-free framework that improves multi-frame story generation via inference-time prompt embedding reorganization. ReDiStory explicitly decomposes text embeddings into identity-related and frame-specific components, then decorrelates frame embeddings by suppressing shared directions across frames. This reduces cross-frame interference without modifying diffusion parameters or requiring additional supervision. Under identical diffusion backbones and inference settings, ReDiStory improves identity consistency while maintaining prompt fidelity. Experiments on the ConsiStory+ benchmark show consistent gains over 1Prompt1Story on multiple identity consistency metrics. Code is available at: this https URL</li>
</ul>

<h3>Title: Protocol Agent: What If Agents Could Use Cryptography In Everyday Life?</h3>
<ul>
<li><strong>Authors: </strong>Marco De Rossi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01304">https://arxiv.org/abs/2602.01304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01304">https://arxiv.org/pdf/2602.01304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01304]] Protocol Agent: What If Agents Could Use Cryptography In Everyday Life?(https://arxiv.org/abs/2602.01304)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, fair</a></li>
<li><strong>Abstract: </strong>We often assume that agent-to-agent interaction will mirror human conversation. However, agents operate fundamentally differently. What if they could develop communication patterns that are more efficient and better aligned with their capabilities? While cryptographic primitives that could profoundly improve everyday interactions already exist, humans can't use them because they are too complex and the math can't be done in one's head. Examples range from proving your age (or other attributes) without showing your ID, to filing an anonymous report within a group while proving you are a legitimate member, to splitting a dinner bill fairly without revealing salaries. What if agents could create protocols "on the fly" by recognizing which primitive fits an everyday situation, proposing it to an agentic counterpart, persuading them to participate, and then executing the protocol correctly using appropriate computation tools? Protocol Agent frames this problem by introducing a benchmark that spans: (1) cryptographic primitive recognition, (2) negotiation skills, (3) implementation correctness, (4) correct computation and (5) security strength. We evaluate current open-weight and state-of-the-art models on this benchmark, propose a dataset-generation approach to improve these capabilities, and measure the impact of supervised fine-tuning (SFT) on benchmark performance, with tuned models outperforming base models by a wide margin.</li>
</ul>

<h3>Title: DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling</h3>
<ul>
<li><strong>Authors: </strong>Ayushman Sarkar, Zhenyu Yu, Mohd Yamani Idna Idris</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01306">https://arxiv.org/abs/2602.01306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01306">https://arxiv.org/pdf/2602.01306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01306]] DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling(https://arxiv.org/abs/2602.01306)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Maintaining visual and semantic consistency across frames is a key challenge in text-to-image storytelling. Existing training-free methods, such as One-Prompt-One-Story, concatenate all prompts into a single sequence, which often induces strong embedding correlation and leads to color leakage, background blending, and identity drift. We propose DeCorStory, a training-free inference-time framework that explicitly reduces inter-frame semantic interference. DeCorStory applies Gram-Schmidt prompt embedding decorrelation to orthogonalize frame-level semantics, followed by singular value reweighting to strengthen prompt-specific information and identity-preserving cross-attention to stabilize character identity during diffusion. The method requires no model modification or fine-tuning and can be seamlessly integrated into existing diffusion pipelines. Experiments demonstrate consistent improvements in prompt-image alignment, identity consistency, and visual diversity, achieving state-of-the-art performance among training-free baselines. Code is available at: this https URL</li>
</ul>

<h3>Title: EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chuanrui Hu, Tong Li, Xingze Gao, Hongda Chen, Dannong Xu, Yi Bai, Tianwei Lin, Xinda Zhao, Xiaohong Li, Jiaqi An, Yunyun Han, Jian Pei, Yafeng Deng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01313">https://arxiv.org/abs/2602.01313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01313">https://arxiv.org/pdf/2602.01313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01313]] EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models(https://arxiv.org/abs/2602.01313)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.</li>
</ul>

<h3>Title: TxRay: Agentic Postmortem of Live Blockchain Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ziyue Wang, Jiangshan Yu, Kaihua Qin, Dawn Song, Arthur Gervais, Liyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01317">https://arxiv.org/abs/2602.01317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01317">https://arxiv.org/pdf/2602.01317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01317]] TxRay: Agentic Postmortem of Live Blockchain Attacks(https://arxiv.org/abs/2602.01317)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to reported exploits. Many exploits arise from permissionless opportunities that any participant can trigger using only public state and standard interfaces, which we call Anyone-Can-Take (ACT) opportunities. Despite on-chain transparency, postmortem analysis remains slow and manual: investigations start from limited evidence, sometimes only a single transaction hash, and must reconstruct the exploit lifecycle by recovering related transactions, contract code, and state dependencies. We present TxRay, a Large Language Model (LLM) agentic postmortem system that uses tool calls to reconstruct live ACT attacks from limited evidence. Starting from one or more seed transactions, TxRay recovers the exploit lifecycle, derives an evidence-backed root cause, and generates a runnable, self-contained Proof of Concept (PoC) that deterministically reproduces the incident. TxRay self-checks postmortems by encoding incident-specific semantic oracles as executable assertions. To evaluate PoC correctness and quality, we develop PoCEvaluator, an independent agentic execution-and-review evaluator. On 114 incidents from DeFiHackLabs, TxRay produces an expert-aligned root cause and an executable PoC for 105 incidents, achieving 92.11% end-to-end reproduction. Under PoCEvaluator, 98.1% of TxRay PoCs avoid hard-coding attacker addresses, a +24.8pp lift over DeFiHackLabs. In a live deployment, TxRay delivers validated root causes in 40 minutes and PoCs in 59 minutes at median latency. TxRay's oracle-validated PoCs enable attack imitation, improving coverage by 15.6% and 65.5% over STING and APE.</li>
</ul>

<h3>Title: PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding</h3>
<ul>
<li><strong>Authors: </strong>Panagiotis Koromilas, Andreas D. Demou, James Oldfield, Yannis Panagakis, Mihalis Nicolaou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01322">https://arxiv.org/abs/2602.01322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01322">https://arxiv.org/pdf/2602.01322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01322]] PolySAE: Modeling Feature Interactions in Sparse Autoencoders via Polynomial Decoding(https://arxiv.org/abs/2602.01322)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) have emerged as a promising method for interpreting neural network representations by decomposing activations into sparse combinations of dictionary atoms. However, SAEs assume that features combine additively through linear reconstruction, an assumption that cannot capture compositional structure: linear models cannot distinguish whether "Starbucks" arises from the composition of "star" and "coffee" features or merely their co-occurrence. This forces SAEs to allocate monolithic features for compound concepts rather than decomposing them into interpretable constituents. We introduce PolySAE, which extends the SAE decoder with higher-order terms to model feature interactions while preserving the linear encoder essential for interpretability. Through low-rank tensor factorization on a shared projection subspace, PolySAE captures pairwise and triple feature interactions with small parameter overhead (3% on GPT2). Across four language models and three SAE variants, PolySAE achieves an average improvement of approximately 8% in probing F1 while maintaining comparable reconstruction error, and produces 2-10$\times$ larger Wasserstein distances between class-conditional feature distributions. Critically, learned interaction weights exhibit negligible correlation with co-occurrence frequency ($r = 0.06$ vs. $r = 0.82$ for SAE feature covariance), suggesting that polynomial terms capture compositional structure, such as morphological binding and phrasal composition, largely independent of surface statistics.</li>
</ul>

<h3>Title: DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas</h3>
<ul>
<li><strong>Authors: </strong>Zirui Wu, Lin Zheng, Zhihui Xie, Jiacheng Ye, Jiahui Gao, Shansan Gong, Yansong Feng, Zhenguo Li, Wei Bi, Guorui Zhou, Lingpeng Kong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01326">https://arxiv.org/abs/2602.01326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01326">https://arxiv.org/pdf/2602.01326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01326]] DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas(https://arxiv.org/abs/2602.01326)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion Language Models (DLMs) present a compelling alternative to autoregressive models, offering flexible, any-order infilling without specialized prompting design. However, their practical utility is blocked by a critical limitation: the requirement of a fixed-length masked sequence for generation. This constraint severely degrades code infilling performance when the predefined mask size mismatches the ideal completion length. To address this, we propose DreamOn, a novel diffusion framework that enables dynamic, variable-length generation. DreamOn augments the diffusion process with two length control states, allowing the model to autonomously expand or contract the output length based solely on its own predictions. We integrate this mechanism into existing DLMs with minimal modifications to the training objective and no architectural changes. Built upon Dream-Coder-7B and DiffuCoder-7B, DreamOn achieves infilling performance on par with state-of-the-art autoregressive models on HumanEval-Infilling and SantaCoder-FIM and matches oracle performance achieved with ground-truth length. Our work removes a fundamental barrier to the practical deployment of DLMs, significantly advancing their flexibility and applicability for variable-length generation. Our code is available at this https URL.</li>
</ul>

<h3>Title: Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yu Xu, Yuxin Zhang, Juan Cao, Lin Gao, Chunyu Wang, Oliver Deussen, Tong-Yee Lee, Fan Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01335">https://arxiv.org/abs/2602.01335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01335">https://arxiv.org/pdf/2602.01335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01335]] Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning(https://arxiv.org/abs/2602.01335)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.</li>
</ul>

<h3>Title: High-accuracy sampling for diffusion models and log-concave distributions</h3>
<ul>
<li><strong>Authors: </strong>Fan Chen, Sinho Chewi, Constantinos Daskalakis, Alexander Rakhlin</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01338">https://arxiv.org/abs/2602.01338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01338">https://arxiv.org/pdf/2602.01338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01338]] High-accuracy sampling for diffusion models and log-concave distributions(https://arxiv.org/abs/2602.01338)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We present algorithms for diffusion model sampling which obtain $\delta$-error in $\mathrm{polylog}(1/\delta)$ steps, given access to $\widetilde O(\delta)$-accurate score estimates in $L^2$. This is an exponential improvement over all previous results. Specifically, under minimal data assumptions, the complexity is $\widetilde O(d\,\mathrm{polylog}(1/\delta))$ where $d$ is the dimension of the data; under a non-uniform $L$-Lipschitz condition, the complexity is $\widetilde O(\sqrt{dL}\,\mathrm{polylog}(1/\delta))$; and if the data distribution has intrinsic dimension $d_\star$, then the complexity reduces to $\widetilde O(d_\star\,\mathrm{polylog}(1/\delta))$. Our approach also yields the first $\mathrm{polylog}(1/\delta)$ complexity sampler for general log-concave distributions using only gradient evaluations.</li>
</ul>

<h3>Title: Finding Differentially Private Second Order Stationary Points in Stochastic Minimax Optimization</h3>
<ul>
<li><strong>Authors: </strong>Difei Xu, Youming Tao, Meng Ding, Chenglin Fan, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01339">https://arxiv.org/abs/2602.01339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01339">https://arxiv.org/pdf/2602.01339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01339]] Finding Differentially Private Second Order Stationary Points in Stochastic Minimax Optimization(https://arxiv.org/abs/2602.01339)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We provide the first study of the problem of finding differentially private (DP) second-order stationary points (SOSP) in stochastic (non-convex) minimax optimization. Existing literature either focuses only on first-order stationary points for minimax problems or on SOSP for classical stochastic minimization problems. This work provides, for the first time, a unified and detailed treatment of both empirical and population risks. Specifically, we propose a purely first-order method that combines a nested gradient descent--ascent scheme with SPIDER-style variance reduction and Gaussian perturbations to ensure privacy. A key technical device is a block-wise ($q$-period) analysis that controls the accumulation of stochastic variance and privacy noise without summing over the full iteration horizon, yielding a unified treatment of both empirical-risk and population formulations. Under standard smoothness, Hessian-Lipschitzness, and strong concavity assumptions, we establish high-probability guarantees for reaching an $(\alpha,\sqrt{\rho_\Phi \alpha})$-approximate second-order stationary point with $\alpha = \mathcal{O}( (\frac{\sqrt{d}}{n\varepsilon})^{2/3})$ for empirical risk objectives and $\mathcal{O}(\frac{1}{n^{1/3}} + (\frac{\sqrt{d}}{n\varepsilon})^{1/2})$ for population objectives, matching the best known rates for private first-order stationarity.</li>
</ul>

<h3>Title: MTC-VAE: Multi-Level Temporal Compression with Content Awareness</h3>
<ul>
<li><strong>Authors: </strong>Yubo Dong, Linchao Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01340">https://arxiv.org/abs/2602.01340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01340">https://arxiv.org/pdf/2602.01340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01340]] MTC-VAE: Multi-Level Temporal Compression with Content Awareness(https://arxiv.org/abs/2602.01340)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Latent Video Diffusion Models (LVDMs) rely on Variational Autoencoders (VAEs) to compress videos into compact latent representations. For continuous Variational Autoencoders (VAEs), achieving higher compression rates is desirable; yet, the efficiency notably declines when extra sampling layers are added without expanding the dimensions of hidden channels. In this paper, we present a technique to convert fixed compression rate VAEs into models that support multi-level temporal compression, providing a straightforward and minimal fine-tuning approach to counteract performance decline at elevated compression this http URL, we examine how varying compression levels impact model performance over video segments with diverse characteristics, offering empirical evidence on the effectiveness of our proposed approach. We also investigate the integration of our multi-level temporal compression VAE with diffusion-based generative models, DiT, highlighting successful concurrent training and compatibility within these frameworks. This investigation illustrates the potential uses of multi-level temporal compression.</li>
</ul>

<h3>Title: Privocracy: Online Democracy through Private Voting</h3>
<ul>
<li><strong>Authors: </strong>Pedro Camponês, Hugo Pereira, Adrian Persaud, Kevin Gallagher, Santiago Torres-Arias</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01341">https://arxiv.org/abs/2602.01341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01341">https://arxiv.org/pdf/2602.01341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01341]] Privocracy: Online Democracy through Private Voting(https://arxiv.org/abs/2602.01341)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>In traditional access control policies, every access granted and administrative account introduces an additional vulnerability, as a corruption of a high-privilege user can compromise several sensitive files. Privocracy is an access control mechanism that minimizes the need to attribute high privileges by triggering a secure e-voting procedure to run commands that require using sensitive resources. With Privocracy an organization can distribute trust in resource access, minimizing the system vulnerabilities from single points of failure, all while maintaining the high flexibility of discretionary access control policies. The Privocracy voting mechanism achieves everlasting privacy, ensuring votes remain confidential regardless of an adversary's computational power, while addressing the dependability requirements of a practical and secure system. The procedure incorporates useful features such as vote delegation to reduce voter fatigue, rapid voting rounds to enable quick action during emergencies, and selective vote auditing for application-level accountability. Our experimental results demonstrate that Privocracy processes votes efficiently and can be deployed on commodity hardware.</li>
</ul>

<h3>Title: Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization</h3>
<ul>
<li><strong>Authors: </strong>Poushali Sengupta, Mayank Raikwar, Sabita Maharjan, Frank Eliassen, Yan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01342">https://arxiv.org/abs/2602.01342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01342">https://arxiv.org/pdf/2602.01342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01342]] Adaptive Quantum-Safe Cryptography for 6G Vehicular Networks via Context-Aware Optimization(https://arxiv.org/abs/2602.01342)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Powerful quantum computers in the future may be able to break the security used for communication between vehicles and other devices (Vehicle-to-Everything, or V2X). New security methods called post-quantum cryptography can help protect these systems, but they often require more computing power and can slow down communication, posing a challenge for fast 6G vehicle networks. In this paper, we propose an adaptive post-quantum cryptography (PQC) framework that predicts short-term mobility and channel variations and dynamically selects suitable lattice-, code-, or hash-based PQC configurations using a predictive multi-objective evolutionary algorithm (APMOEA) to meet vehicular latency and security this http URL, frequent cryptographic reconfiguration in dynamic vehicular environments introduces new attack surfaces during algorithm transitions. A secure monotonic-upgrade protocol prevents downgrade, replay, and desynchronization attacks during transitions. Theoretical results show decision stability under bounded prediction error, latency boundedness under mobility drift, and correctness under small forecast noise. These results demonstrate a practical path toward quantum-safe cryptography in future 6G vehicular networks. Through extensive experiments based on realistic mobility (LuST), weather (ERA5), and NR-V2X channel traces, we show that the proposed framework reduces end-to-end latency by up to 27\%, lowers communication overhead by up to 65\%, and effectively stabilizes cryptographic switching behavior using reinforcement learning. Moreover, under the evaluated adversarial scenarios, the monotonic-upgrade protocol successfully prevents downgrade, replay, and desynchronization attacks.</li>
</ul>

<h3>Title: CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Yu Liu, Wenxiao Zhang, Cong Cao, Fangfang Yuan, Weizhuo Chen, Cheng Hu, Pin Xu, Yuling Yang, Kun Peng, Diandian Guo, Qiang Sun, Yanbing Liu, Jin B. Hong, Zhiyuan Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01348">https://arxiv.org/abs/2602.01348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01348">https://arxiv.org/pdf/2602.01348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01348]] CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering(https://arxiv.org/abs/2602.01348)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) is widely used to ground Large Language Models (LLMs) for multi-hop question answering. Recent work mainly focused on improving answer accuracy via fine-tuning and structured or reinforcement-based optimization. However, reliable reasoning in response generation faces three challenges: 1) Reasoning Collapse. Reasoning in multi-hop QA is inherently complex due to multi-hop composition and is further destabilized by noisy retrieval. 2) Reasoning-answer inconsistency. Due to the intrinsic uncertainty of LLM generation and exposure to evidence--distractor mixtures, models may produce correct answers that are not faithfully supported by their intermediate reasoning or evidence. 3) Loss of format control. Traditional chain-of-thought generation often deviates from required structured output formats, leading to incomplete or malformed structured content. To address these challenges, we propose CRAFT (Calibrated Reasoning with Answer-Faithful Traces), a Group Relative Policy Optimization (GRPO) based reinforcement learning framework that trains models to perform faithful reasoning during response generation. CRAFT employs dual reward mechanisms to optimize multi-hop reasoning: deterministic rewards ensure structural correctness while judge-based rewards verify semantic faithfulness. This optimization framework supports controllable trace variants that enable systematic analysis of how structure and scale affect reasoning performance and faithfulness. Experiments on three multi-hop QA benchmarks show that CRAFT improves both answer accuracy and reasoning faithfulness across model scales, with the CRAFT 7B model achieving competitive performance with closed-source LLMs across multiple reasoning trace settings.</li>
</ul>

<h3>Title: T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Xingzu Zhan, Chen Xie, Honghang Chen, Yixun Lin, Xiaochun Mai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01352">https://arxiv.org/abs/2602.01352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01352">https://arxiv.org/pdf/2602.01352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01352]] T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation(https://arxiv.org/abs/2602.01352)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Text-to-motion generation, which converts motion language descriptions into coherent 3D human motion sequences, has attracted increasing attention in fields, such as avatar animation and humanoid robotic interaction. Though existing models have achieved significant fidelity, they still suffer from two core limitations: (i) They treat motion periodicity and keyframe saliency as independent factors, overlooking their coupling and causing generation drift in long sequences. (ii) They are fragile to semantically equivalent paraphrases, where minor synonym substitutions distort textual embeddings, propagating through the decoder and producing unstable or erroneous motions. In this work, we propose T2M Mamba to address these limitations by (i) proposing Periodicity-Saliency Aware Mamba, which utilizes novel algorithms for keyframe weight estimation via enhanced Density Peaks Clustering and motion periodicity estimation via FFT-accelerated autocorrelation to capture coupled dynamics with minimal computational overhead, and (ii) constructing a Periodic Differential Cross-modal Alignment Module (PDCAM) to enhance robust alignment of textual and motion embeddings. Extensive experiments on HumanML3D and KIT-ML datasets have been conducted, confirming the effectiveness of our approach, achieving an FID of 0.068 and consistent gains on all other metrics.</li>
</ul>

<h3>Title: Your Self-Play Algorithm is Secretly an Adversarial Imitator: Understanding LLM Self-Play through the Lens of Imitation Learning</h3>
<ul>
<li><strong>Authors: </strong>Shangzhe Li, Xuchao Zhang, Chetan Bansal, Weitong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01357">https://arxiv.org/abs/2602.01357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01357">https://arxiv.org/pdf/2602.01357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01357]] Your Self-Play Algorithm is Secretly an Adversarial Imitator: Understanding LLM Self-Play through the Lens of Imitation Learning(https://arxiv.org/abs/2602.01357)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-play post-training methods has emerged as an effective approach for finetuning large language models and turn the weak language model into strong language model without preference data. However, the theoretical foundations for self-play finetuning remain underexplored. In this work, we tackle this by connecting self-play finetuning with adversarial imitation learning by formulating finetuning procedure as a min-max game between the model and a regularized implicit reward player parameterized by the model itself. This perspective unifies self-play imitation and general preference alignment within a common framework. Under this formulation, we present a game-theoretic analysis showing that the self-play finetuning will converge to it's equilibrium. Guided by this theoretical formulation, we propose a new self-play imitation finetuning algorithm based on the $\chi^2$-divergence variational objective with bounded rewards and improved stability. Experiments on various of language model finetuning tasks demonstrate consistent improvements over existing self-play methods and validate our theoretical insights.</li>
</ul>

<h3>Title: PaAno: Patch-Based Representation Learning for Time-Series Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Jinju Park, Seokho Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01359">https://arxiv.org/abs/2602.01359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01359">https://arxiv.org/pdf/2602.01359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01359]] PaAno: Patch-Based Representation Learning for Time-Series Anomaly Detection(https://arxiv.org/abs/2602.01359)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Although recent studies on time-series anomaly detection have increasingly adopted ever-larger neural network architectures such as transformers and foundation models, they incur high computational costs and memory usage, making them impractical for real-time and resource-constrained scenarios. Moreover, they often fail to demonstrate significant performance gains over simpler methods under rigorous evaluation protocols. In this study, we propose Patch-based representation learning for time-series Anomaly detection (PaAno), a lightweight yet effective method for fast and efficient time-series anomaly detection. PaAno extracts short temporal patches from time-series training data and uses a 1D convolutional neural network to embed each patch into a vector representation. The model is trained using a combination of triplet loss and pretext loss to ensure the embeddings capture informative temporal patterns from input patches. During inference, the anomaly score at each time step is computed by comparing the embeddings of its surrounding patches to those of normal patches extracted from the training time-series. Evaluated on the TSB-AD benchmark, PaAno achieved state-of-the-art performance, significantly outperforming existing methods, including those based on heavy architectures, on both univariate and multivariate time-series anomaly detection across various range-wise and point-wise performance measures.</li>
</ul>

<h3>Title: Balancing Understanding and Generation in Discrete Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yue Liu, Yuzhong Zhao, Zheyong Xie, Qixiang Ye, Jianbin Jiao, Yao Hu, Shaosheng Cao, Yunfan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01362">https://arxiv.org/abs/2602.01362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01362">https://arxiv.org/pdf/2602.01362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01362]] Balancing Understanding and Generation in Discrete Diffusion Models(https://arxiv.org/abs/2602.01362)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel. XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities. Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation (FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model, XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at this https URL</li>
</ul>

<h3>Title: When Domains Interact: Asymmetric and Order-Sensitive Cross-Domain Effects in Reinforcement Learning for Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wang Yang, Shouren Wang, Chaoda Song, Chuang Ma, Xinpeng Li, Nengbo Wang, Kaixiong Zhou, Vipin Chaudhary, Xiaotian Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01365">https://arxiv.org/abs/2602.01365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01365">https://arxiv.org/pdf/2602.01365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01365]] When Domains Interact: Asymmetric and Order-Sensitive Cross-Domain Effects in Reinforcement Learning for Reasoning(https://arxiv.org/abs/2602.01365)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Group Relative Policy Optimization (GRPO) has become a key technique for improving reasoning abilities in large language models, yet its behavior under different domain sequencing strategies is poorly understood. In particular, the impact of sequential (one domain at a time) versus mixed-domain (multiple domain at a time) training in GRPO has not been systematically studied. We provide the first systematic analysis of training-order effects across math, science, logic, and puzzle reasoning tasks. We found (1) single-domain generalization is highly asymmetric: training on other domains improves math reasoning by approximately 25\% accuracy, while yielding negligible transfer to logic and puzzle; (2) cross-domain interactions are highly order-dependent: training in the order math$\rightarrow$science achieves 83\% / 41\% accuracy on math / science, while reversing the order to science$\rightarrow$math degrades performance to 77\% / 25\%; (3) no single strategy is universally optimal in multi-domain training: sequential training favors math (up to 84\%), mixed training favors science and logic, and poor ordering can incur large performance gaps (from 70\% to 56\%). Overall, our findings demonstrate that GRPO under multi-domain settings exhibits pronounced asymmetry, order sensitivity, and strategy dependence, highlighting the necessity of domain-aware and order-aware training design.</li>
</ul>

<h3>Title: Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation</h3>
<ul>
<li><strong>Authors: </strong>Pinar Erbil, Alberto Archetti, Eugenio Lomurno, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01367">https://arxiv.org/abs/2602.01367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01367">https://arxiv.org/pdf/2602.01367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01367]] Deep Variational Contrastive Learning for Joint Risk Stratification and Time-to-Event Estimation(https://arxiv.org/abs/2602.01367)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Survival analysis is essential for clinical decision-making, as it allows practitioners to estimate time-to-event outcomes, stratify patient risk profiles, and guide treatment planning. Deep learning has revolutionized this field with unprecedented predictive capabilities but faces a fundamental trade-off between performance and interpretability. While neural networks achieve high accuracy, their black-box nature limits clinical adoption. Conversely, deep clustering-based methods that stratify patients into interpretable risk groups typically sacrifice predictive power. We propose CONVERSE (CONtrastive Variational Ensemble for Risk Stratification and Estimation), a deep survival model that bridges this gap by unifying variational autoencoders with contrastive learning for interpretable risk stratification. CONVERSE combines variational embeddings with multiple intra- and inter-cluster contrastive losses. Self-paced learning progressively incorporates samples from easy to hard, improving training stability. The model supports cluster-specific survival heads, enabling accurate ensemble predictions. Comprehensive evaluation on four benchmark datasets demonstrates that CONVERSE achieves competitive or superior performance compared to existing deep survival methods, while maintaining meaningful patient stratification.</li>
</ul>

<h3>Title: Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Songping Wang, Qinglong Liu, Yueming Lyu, Ning Li, Ziwen He, Caifeng Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01369">https://arxiv.org/abs/2602.01369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01369">https://arxiv.org/pdf/2602.01369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01369]] Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts(https://arxiv.org/abs/2602.01369)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) has demonstrated strong performance in video understanding tasks, yet its adversarial robustness remains underexplored. Existing attack methods often treat MoE as a unified architecture, overlooking the independent and collaborative weaknesses of key components such as routers and expert modules. To fill this gap, we propose Temporal Lipschitz-Guided Attacks (TLGA) to thoroughly investigate component-level vulnerabilities in video MoE models. We first design attacks on the router, revealing its independent weaknesses. Building on this, we introduce Joint Temporal Lipschitz-Guided Attacks (J-TLGA), which collaboratively perturb both routers and experts. This joint attack significantly amplifies adversarial effects and exposes the Achilles' Heel (collaborative weaknesses) of the MoE architecture. Based on these insights, we further propose Joint Temporal Lipschitz Adversarial Training (J-TLAT). J-TLAT performs joint training to further defend against collaborative weaknesses, enhancing component-wise robustness. Our framework is plug-and-play and reduces inference cost by more than 60% compared with dense models. It consistently enhances adversarial robustness across diverse datasets and architectures, effectively mitigating both the independent and collaborative weaknesses of MoE.</li>
</ul>

<h3>Title: PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Leonardo Brusini, Cristian Sbrolli, Eugenio Lomurno, Toshihiko Yamasaki, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01370">https://arxiv.org/abs/2602.01370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01370">https://arxiv.org/pdf/2602.01370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01370]] PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles(https://arxiv.org/abs/2602.01370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Synthetic data offers a scalable solution for vision-language pre-training, yet current state-of-the-art methods typically rely on scaling up a single generative backbone, which introduces generator-specific spectral biases and limits feature diversity. In this work, we introduce PolyGen, a framework that redefines synthetic data construction by prioritizing manifold coverage and compositional rigor over simple dataset size. PolyGen employs a Polylithic approach to train on the intersection of architecturally distinct generators, effectively marginalizing out model-specific artifacts. Additionally, we introduce a Programmatic Hard Negative curriculum that enforces fine-grained syntactic understanding. By structurally reallocating the same data budget from unique captions to multi-source variations, PolyGen achieves a more robust feature space, outperforming the leading single-source baseline (SynthCLIP) by +19.0% on aggregate multi-task benchmarks and on the SugarCrepe++ compositionality benchmark (+9.1%). These results demonstrate that structural diversity is a more data-efficient scaling law than simply increasing the volume of single-source samples.</li>
</ul>

<h3>Title: Context Dependence and Reliability in Autoregressive Language Models</h3>
<ul>
<li><strong>Authors: </strong>Poushali Sengupta, Shashi Raj Pandey, Sabita Maharjan, Frank Eliassen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01378">https://arxiv.org/abs/2602.01378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01378">https://arxiv.org/pdf/2602.01378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01378]] Context Dependence and Reliability in Autoregressive Language Models(https://arxiv.org/abs/2602.01378)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.</li>
</ul>

<h3>Title: On the Power of (Approximate) Reward Models for Inference-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Youheng Zhu, Yiping Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01381">https://arxiv.org/abs/2602.01381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01381">https://arxiv.org/pdf/2602.01381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01381]] On the Power of (Approximate) Reward Models for Inference-Time Scaling(https://arxiv.org/abs/2602.01381)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference-time scaling has recently emerged as a powerful paradigm for improving the reasoning capability of large language models. Among various approaches, Sequential Monte Carlo (SMC) has become a particularly important framework, enabling iterative generation, evaluation, rejection, and resampling of intermediate reasoning trajectories. A central component in this process is the reward model, which evaluates partial solutions and guides the allocation of computation during inference. However, in practice, true reward models are never available. All deployed systems rely on approximate reward models, raising a fundamental question: Why and when do approximate reward models suffice for effective inference-time scaling? In this work, we provide a theoretical answer. We identify the Bellman error of the approximate reward model as the key quantity governing the effectiveness of SMC-based inference-time scaling. For a reasoning process of length $T$, we show that if the Bellman error of the approximate reward model is bounded by $O(1/T)$, then combining this reward model with SMC reduces the computational complexity of reasoning from exponential in $T$ to polynomial in $T$. This yields an exponential improvement in inference efficiency despite using only approximate rewards.</li>
</ul>

<h3>Title: Rethinking Selective Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Almog Tavor, Itay Ebenspanger, Neil Cnaan, Mor Geva</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01395">https://arxiv.org/abs/2602.01395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01395">https://arxiv.org/pdf/2602.01395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01395]] Rethinking Selective Knowledge Distillation(https://arxiv.org/abs/2602.01395)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.</li>
</ul>

<h3>Title: From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Niansong Zhang, Sunwoo Kim, Shreesha Srinath, Zhiru Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01401">https://arxiv.org/abs/2602.01401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01401">https://arxiv.org/pdf/2602.01401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01401]] From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis(https://arxiv.org/abs/2602.01401)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic this http URL position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.</li>
</ul>

<h3>Title: SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Yunjie Pan, Yongyi Yang, Hanmei Yang, Scott Mahlke</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01410">https://arxiv.org/abs/2602.01410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01410">https://arxiv.org/pdf/2602.01410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01410]] SNIP: An Adaptive Mixed Precision Framework for Subbyte Large Language Model Training(https://arxiv.org/abs/2602.01410)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) efficiently while preserving model quality poses significant challenges, particularly with subbyte precision supported by state-of-the-art GPUs. Current mixed-precision training approaches either apply uniform precision to all GEMM operations or rely on heuristic-based methods that fail to generalize during training, leading to suboptimal convergence and instability. To address these challenges, this paper introduces SNIP, a fine-grained adaptive mixed-precision training framework for LLM pretraining that supports subbyte precision. SNIP periodically collects statistics on activations, gradients, and optimizer states to assess the precision loss impact on model quality. We define two key metrics: loss divergence in the forward pass, caused by quantization-induced increases in training loss, and weight divergence in the backward pass, which measures error propagation through gradients affecting model updates. These metrics guide an Integer Linear Programming (ILP) problem that systematically optimizes layerwise precision to minimize overall quality loss while meeting efficiency targets. Experiments on 1B, 3B, 7B and 70B Llama-like models demonstrate that SNIP consistently outperforms existing baselines, reducing FLOPs by up to 80% while preserving model quality across different model sizes and training phases with minimal computational overhead.</li>
</ul>

<h3>Title: Semi-supervised CAPP Transformer Learning via Pseudo-labeling</h3>
<ul>
<li><strong>Authors: </strong>Dennis Gross, Helge Spieker, Arnaud Gotlieb, Emmanuel Stathatos, Panorios Benardos, George-Christopher Vosniakos</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01419">https://arxiv.org/abs/2602.01419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01419">https://arxiv.org/pdf/2602.01419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01419]] Semi-supervised CAPP Transformer Learning via Pseudo-labeling(https://arxiv.org/abs/2602.01419)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>High-level Computer-Aided Process Planning (CAPP) generates manufacturing process plans from part specifications. It suffers from limited dataset availability in industry, reducing model generalization. We propose a semi-supervised learning approach to improve transformer-based CAPP transformer models without manual labeling. An oracle, trained on available transformer behaviour data, filters correct predictions from unseen parts, which are then used for one-shot retraining. Experiments on small-scale datasets with simulated ground truth across the full data distribution show consistent accuracy gains over baselines, demonstrating the method's effectiveness in data-scarce manufacturing environments.</li>
</ul>

<h3>Title: Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weiqing He, Xiang Li, Li Shen, Weijie Su, Qi Long</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01428">https://arxiv.org/abs/2602.01428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01428">https://arxiv.org/pdf/2602.01428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01428]] Improve the Trade-off Between Watermark Strength and Speculative Sampling Efficiency for Language Models(https://arxiv.org/abs/2602.01428)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Watermarking is a principled approach for tracing the provenance of large language model (LLM) outputs, but its deployment in practice is hindered by inference inefficiency. Speculative sampling accelerates inference, with efficiency improving as the acceptance rate between draft and target models increases. Yet recent work reveals a fundamental trade-off: higher watermark strength reduces acceptance, preventing their simultaneous achievement. We revisit this trade-off and show it is not absolute. We introduce a quantitative measure of watermark strength that governs statistical detectability and is maximized when tokens are deterministic functions of pseudorandom numbers. Using this measure, we fully characterize the trade-off as a constrained optimization problem and derive explicit Pareto curves for two existing watermarking schemes. Finally, we introduce a principled mechanism that injects pseudorandomness into draft-token acceptance, ensuring maximal watermark strength while maintaining speculative sampling efficiency. Experiments further show that this approach improves detectability without sacrificing efficiency. Our findings uncover a principle that unites speculative sampling and watermarking, paving the way for their efficient and practical deployment.</li>
</ul>

<h3>Title: DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Hasan Ferdous, Md Osman Gani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01433">https://arxiv.org/abs/2602.01433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01433">https://arxiv.org/pdf/2602.01433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01433]] DCD: Decomposition-based Causal Discovery from Autocorrelated and Non-Stationary Temporal Data(https://arxiv.org/abs/2602.01433)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Multivariate time series in domains such as finance, climate science, and healthcare often exhibit long-term trends, seasonal patterns, and short-term fluctuations, complicating causal inference under non-stationarity and autocorrelation. Existing causal discovery methods typically operate on raw observations, making them vulnerable to spurious edges and misattributed temporal dependencies. We introduce a decomposition-based causal discovery framework that separates each time series into trend, seasonal, and residual components and performs component-specific causal analysis. Trend components are assessed using stationarity tests, seasonal components using kernel-based dependence measures, and residual components using constraint-based causal discovery. The resulting component-level graphs are integrated into a unified multi-scale causal structure. This approach isolates long- and short-range causal effects, reduces spurious associations, and improves interpretability. Across extensive synthetic benchmarks and real-world climate data, our framework more accurately recovers ground-truth causal structure than state-of-the-art baselines, particularly under strong non-stationarity and temporal autocorrelation.</li>
</ul>

<h3>Title: CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses</h3>
<ul>
<li><strong>Authors: </strong>Max Manolov, Tony Gao, Siddharth Shukla, Cheng-Ting Chou, Ryan Lagasse</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01438">https://arxiv.org/abs/2602.01438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01438">https://arxiv.org/pdf/2602.01438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01438]] CIPHER: Cryptographic Insecurity Profiling via Hybrid Evaluation of Responses(https://arxiv.org/abs/2602.01438)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to assist developers with code, yet their implementations of cryptographic functionality often contain exploitable flaws. Minor design choices (e.g., static initialization vectors or missing authentication) can silently invalidate security guarantees. We introduce CIPHER(\textbf{C}ryptographic \textbf{I}nsecurity \textbf{P}rofiling via \textbf{H}ybrid \textbf{E}valuation of \textbf{R}esponses), a benchmark for measuring cryptographic vulnerability incidence in LLM-generated Python code under controlled security-guidance conditions. CIPHER uses insecure/neutral/secure prompt variants per task, a cryptography-specific vulnerability taxonomy, and line-level attribution via an automated scoring pipeline. Across a diverse set of widely used LLMs, we find that explicit ``secure'' prompting reduces some targeted issues but does not reliably eliminate cryptographic vulnerabilities overall. The benchmark and reproducible scoring pipeline will be publicly released upon publication.</li>
</ul>

<h3>Title: TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse</h3>
<ul>
<li><strong>Authors: </strong>Perry Dong, Kuo-Han Hung, Alexander Swerdlow, Dorsa Sadigh, Chelsea Finn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01439">https://arxiv.org/abs/2602.01439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01439">https://arxiv.org/pdf/2602.01439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01439]] TQL: Scaling Q-Functions with Transformers by Preventing Attention Collapse(https://arxiv.org/abs/2602.01439)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite scale driving substantial recent advancements in machine learning, reinforcement learning (RL) methods still primarily use small value functions. Naively scaling value functions -- including with a transformer architecture, which is known to be highly scalable -- often results in learning instability and worse performance. In this work, we ask what prevents transformers from scaling effectively for value functions? Through empirical analysis, we identify the critical failure mode in this scaling: attention scores collapse as capacity increases. Our key insight is that we can effectively prevent this collapse and stabilize training by controlling the entropy of the attention scores, thereby enabling the use of larger models. To this end, we propose Transformer Q-Learning (TQL), a method that unlocks the scaling potential of transformers in learning value functions in RL. Our approach yields up to a 43% improvement in performance when scaling from the smallest to the largest network sizes, while prior methods suffer from performance degradation.</li>
</ul>

<h3>Title: The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks</h3>
<ul>
<li><strong>Authors: </strong>Donald Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01442">https://arxiv.org/abs/2602.01442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01442">https://arxiv.org/pdf/2602.01442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01442]] The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks(https://arxiv.org/abs/2602.01442)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Removing ''important'' high-gradient components from a neural network can improve generalization, while removing unimportant'' low-gradient components can destroy it. We demonstrate this paradox by formalizing the \textit{Gradient-Causal Gap} in Transformers trained on algorithmic tasks. While gradient magnitude and causal importance align on simple tasks ($\rho=0.73$ for reversal), this relationship collapses as task complexity increases ($\rho=0.32$ for sorting), sometimes becoming inverted ($\rho=-0.11$). Pruning experiments reveal that gradient magnitude is not merely inaccurate but \textit{unpredictably} so. Removing low-gradient ''Hidden Heroes'' consistently devastates OOD accuracy ($-32\%$). Removing high-gradient ''Gradient Bloats'' is a coin flip: harmless in most seeds (indicating optimization noise), catastrophic in others (indicating overfitting circuits). This unpredictability means gradient-based pruning cannot reliably preserve model capabilities.</li>
</ul>

<h3>Title: A Meta-Knowledge-Augmented LLM Framework for Hyperparameter Optimization in Time-Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ons Saadallah, Mátyás andó, Tamás Gábor Orosz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01445">https://arxiv.org/abs/2602.01445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01445">https://arxiv.org/pdf/2602.01445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01445]] A Meta-Knowledge-Augmented LLM Framework for Hyperparameter Optimization in Time-Series Forecasting(https://arxiv.org/abs/2602.01445)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hyperparameter optimization (HPO) plays a central role in the performance of deep learning models, yet remains computationally expensive and difficult to interpret, particularly for time-series forecasting. While Bayesian Optimization (BO) is a standard approach, it typically treats tuning tasks independently and provides limited insight into its decisions. Recent advances in large language models (LLMs) offer new opportunities to incorporate structured prior knowledge and reasoning into optimization pipelines. We introduce LLM-AutoOpt, a hybrid HPO framework that combines BO with LLM-based contextual reasoning. The framework encodes dataset meta-features, model descriptions, historical optimization outcomes, and target objectives as structured meta-knowledge within LLM prompts, using BO to initialize the search and mitigate cold-start effects. This design enables context-aware and stable hyperparameter refinement while exposing the reasoning behind optimization decisions. Experiments on a multivariate time series forecasting benchmark demonstrate that LLM-AutoOpt achieves improved predictive performance and more interpretable optimization behavior compared to BO and LLM baselines without meta-knowledge.</li>
</ul>

<h3>Title: SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction</h3>
<ul>
<li><strong>Authors: </strong>Hieu Minh Duong, Rupa Ghosh, Cong Hoan Nguyen, Eugene Levin, Todd Gary, Long Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01447">https://arxiv.org/abs/2602.01447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01447">https://arxiv.org/pdf/2602.01447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01447]] SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction(https://arxiv.org/abs/2602.01447)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.</li>
</ul>

<h3>Title: Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Penghao Deng, Jidong J. Yang, Jiachen Bian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01452">https://arxiv.org/abs/2602.01452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01452">https://arxiv.org/pdf/2602.01452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01452]] Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles(https://arxiv.org/abs/2602.01452)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding where drivers direct their visual attention during driving, as characterized by gaze behavior, is critical for developing next-generation advanced driver-assistance systems and improving road safety. This paper tackles this challenge as a semantic identification task from the road scenes captured by a vehicle's front-view camera. Specifically, the collocation of gaze points with object semantics is investigated using three distinct vision-based approaches: direct object detection (YOLOv13), segmentation-assisted classification (SAM2 paired with EfficientNetV2 versus YOLOv13), and query-based Vision-Language Models, VLMs (Qwen2.5-VL-7b versus Qwen2.5-VL-32b). The results demonstrate that the direct object detection (YOLOv13) and Qwen2.5-VL-32b significantly outperform other approaches, achieving Macro F1-Scores over 0.84. The large VLM (Qwen2.5-VL-32b), in particular, exhibited superior robustness and performance for identifying small, safety-critical objects such as traffic lights, especially in adverse nighttime conditions. Conversely, the segmentation-assisted paradigm suffers from a "part-versus-whole" semantic gap that led to large failure in recall. The results reveal a fundamental trade-off between the real-time efficiency of traditional detectors and the richer contextual understanding and robustness offered by large VLMs. These findings provide critical insights and practical guidance for the design of future human-aware intelligent driver monitoring systems.</li>
</ul>

<h3>Title: Understanding vision transformer robustness through the lens of out-of-distribution detection</h3>
<ul>
<li><strong>Authors: </strong>Joey Kuang, Alexander Wong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01459">https://arxiv.org/abs/2602.01459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01459">https://arxiv.org/pdf/2602.01459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01459]] Understanding vision transformer robustness through the lens of out-of-distribution detection(https://arxiv.org/abs/2602.01459)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Vision transformers have shown remarkable performance in vision tasks, but enabling them for accessible and real-time use is still challenging. Quantization reduces memory and inference costs at the risk of performance loss. Strides have been made to mitigate low precision issues mainly by understanding in-distribution (ID) task behaviour, but the attention mechanism may provide insight on quantization attributes by exploring out-of-distribution (OOD) situations. We investigate the behaviour of quantized small-variant popular vision transformers (DeiT, DeiT3, and ViT) on common OOD datasets. ID analyses show the initial instabilities of 4-bit models, particularly of those trained on the larger ImageNet-22k, as the strongest FP32 model, DeiT3, sharply drop 17% from quantization error to be one of the weakest 4-bit models. While ViT shows reasonable quantization robustness for ID calibration, OOD detection reveals more: ViT and DeiT3 pretrained on ImageNet-22k respectively experienced a 15.0% and 19.2% average quantization delta in AUPR-out between full precision to 4-bit while their ImageNet-1k-only counterparts experienced a 9.5% and 12.0% delta. Overall, our results suggest pretraining on large scale datasets may hinder low-bit quantization robustness in OOD detection and that data augmentation may be a more beneficial option.</li>
</ul>

<h3>Title: A Statistical Theory of Gated Attention through the Lens of Hierarchical Mixture of Experts</h3>
<ul>
<li><strong>Authors: </strong>Viet Nguyen, Tuan Minh Pham, Thinh Cao, Tan Dinh, Huy Nguyen, Nhat Ho, Alessandro Rinaldo</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01468">https://arxiv.org/abs/2602.01468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01468">https://arxiv.org/pdf/2602.01468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01468]] A Statistical Theory of Gated Attention through the Lens of Hierarchical Mixture of Experts(https://arxiv.org/abs/2602.01468)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Self-attention has greatly contributed to the success of the widely used Transformer architecture by enabling learning from data with long-range dependencies. In an effort to improve performance, a gated attention model that leverages a gating mechanism within the multi-head self-attention has recently been proposed as a promising alternative. Gated attention has been empirically demonstrated to increase the expressiveness of low-rank mapping in standard attention and even to eliminate the attention sink phenomenon. Despite its efficacy, a clear theoretical understanding of gated attention's benefits remains lacking in the literature. To close this gap, we rigorously show that each entry in a gated attention matrix or a multi-head self-attention matrix can be written as a hierarchical mixture of experts. By recasting learning as an expert estimation problem, we demonstrate that gated attention is more sample-efficient than multi-head self-attention. In particular, while the former needs only a polynomial number of data points to estimate an expert, the latter requires exponentially many data points to achieve the same estimation error. Furthermore, our analysis also provides a theoretical justification for why gated attention yields higher performance when a gate is placed at the output of the scaled dot product attention or the value map rather than at other positions in the multi-head self-attention architecture.</li>
</ul>

<h3>Title: Ebisu: Benchmarking Large Language Models in Japanese Finance</h3>
<ul>
<li><strong>Authors: </strong>Xueqing Peng, Ruoyu Xiang, Fan Zhang, Mingzi Song, Mingyang Jiang, Yan Wang, Lingfei Qian, Taiki Hara, Yuqing Guo, Jimin Huang, Junichi Tsujii, Sophia Ananiadou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01479">https://arxiv.org/abs/2602.01479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01479">https://arxiv.org/pdf/2602.01479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01479]] Ebisu: Benchmarking Large Language Models in Japanese Finance(https://arxiv.org/abs/2602.01479)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.</li>
</ul>

<h3>Title: Predicting and improving test-time scaling laws via reward tail-guided search</h3>
<ul>
<li><strong>Authors: </strong>Muheng Li, Jian Qian, Wenlong Mou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01485">https://arxiv.org/abs/2602.01485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01485">https://arxiv.org/pdf/2602.01485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01485]] Predicting and improving test-time scaling laws via reward tail-guided search(https://arxiv.org/abs/2602.01485)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Test-time scaling has emerged as a critical avenue for enhancing the reasoning capabilities of Large Language Models (LLMs). Though the straight-forward ''best-of-$N$'' (BoN) strategy has already demonstrated significant improvements in performance, it lacks principled guidance on the choice of $N$, budget allocation, and multi-stage decision-making, thereby leaving substantial room for optimization. While many works have explored such optimization, rigorous theoretical guarantees remain limited. In this work, we propose new methodologies to predict and improve scaling properties via tail-guided search. By estimating the tail distribution of rewards, our method predicts the scaling law of LLMs without the need for exhaustive evaluations. Leveraging this prediction tool, we introduce Scaling-Law Guided (SLG) Search, a new test-time algorithm that dynamically allocates compute to identify and exploit intermediate states with the highest predicted potential. We theoretically prove that SLG achieves vanishing regret compared to perfect-information oracles, and achieves expected rewards that would otherwise require a polynomially larger compute budget required when using BoN. Empirically, we validate our framework across different LLMs and reward models, confirming that tail-guided allocation consistently achieves higher reward yields than Best-of-$N$ under identical compute budgets. Our code is available at this https URL.</li>
</ul>

<h3>Title: Multi-Scale Wavelet Transformers for Operator Learning of Dynamical Systems</h3>
<ul>
<li><strong>Authors: </strong>Xuesong Wang, Michael Groom, Rafael Oliveira, He Zhao, Terence O'Kane, Edwin V. Bonilla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01486">https://arxiv.org/abs/2602.01486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01486">https://arxiv.org/pdf/2602.01486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01486]] Multi-Scale Wavelet Transformers for Operator Learning of Dynamical Systems(https://arxiv.org/abs/2602.01486)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent years have seen a surge in data-driven surrogates for dynamical systems that can be orders of magnitude faster than numerical solvers. However, many machine learning-based models such as neural operators exhibit spectral bias, attenuating high-frequency components that often encode small-scale structure. This limitation is particularly damaging in applications such as weather forecasting, where misrepresented high frequencies can induce long-horizon instability. To address this issue, we propose multi-scale wavelet transformers (MSWTs), which learn system dynamics in a tokenized wavelet domain. The wavelet transform explicitly separates low- and high-frequency content across scales. MSWTs leverage a wavelet-preserving downsampling scheme that retains high-frequency features and employ wavelet-based attention to capture dependencies across scales and frequency bands. Experiments on chaotic dynamical systems show substantial error reductions and improved long horizon spectral fidelity. On the ERA5 climate reanalysis, MSWTs further reduce climatological bias, demonstrating their effectiveness in a real-world forecasting setting.</li>
</ul>

<h3>Title: DuoLungo: Usability Study of Duo 2FA</h3>
<ul>
<li><strong>Authors: </strong>Renascence Tarafder Prapty, Gene Tsudik</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01489">https://arxiv.org/abs/2602.01489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01489">https://arxiv.org/pdf/2602.01489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01489]] DuoLungo: Usability Study of Duo 2FA(https://arxiv.org/abs/2602.01489)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Multi-Factor Authentication (MFA) enhances login security by requiring multiple authentication factors. Its adoption has increased in response to more frequent and sophisticated attacks. Duo is widely used by organizations including Fortune 500 companies and major educational institutions, yet its usability has not been examined thoroughly or recently. Earlier studies focused on technical challenges during initial deployment but did not measure core usability metrics such as task completion time or System Usability Scale (SUS) scores. These results are also outdated, originating from a time when MFA was less familiar to typical users. We conducted a long-term, large-scale Duo usability study at the University of California Irvine during the 2024-2025 academic year, involving 2559 participants. Our analysis uses authentication log data and a survey of 57 randomly selected users. The average overhead of a Duo Push task is nearly 8 seconds, which participants described as short to moderate. Overhead varies with time of day, field of study, and education level. The rate of authentication failures due to incomplete Duo tasks is 4.35 percent, and 43.86 percent of survey respondents reported at least one Duo login failure. The Duo SUS score is 70, indicating good usability. Participants generally find Duo easy to use but somewhat annoying, while also reporting an increased sense of account security. They also described common issues and offered suggestions for improvement.</li>
</ul>

<h3>Title: Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability</h3>
<ul>
<li><strong>Authors: </strong>Sahan Sanjaya, Prabhat Mishra</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01491">https://arxiv.org/abs/2602.01491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01491">https://arxiv.org/pdf/2602.01491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01491]] Sleep Reveals the Nonce: Breaking ECDSA using Sleep-Based Power Side-Channel Vulnerability(https://arxiv.org/abs/2602.01491)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction</a></li>
<li><strong>Abstract: </strong>Security of Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the secrecy of the per-signature nonce. Even partial nonce leakage can expose the long-term private key through lattice-based cryptanalysis. In this paper, we introduce a previously unexplored power side-channel vulnerability that exploits sleep-induced power spikes to extract ECDSA nonces. Unlike conventional power-based side-channel attacks, this vulnerability leverages power fluctuations generated during processor context switches invoked by sleep functions. These fluctuations correlate with nonce-dependent operations in scalar multiplication, enabling nonce recovery even under constant-time and masked implementations. We evaluate the attack across multiple cryptographic libraries, RustCrypto, BearSSL, and GoCrypto, and processor architectures, including ARM and RISC-V. Our experiments show that subtle variations in the power envelope during sleep-induced context switches provide sufficient leakage for practical ECDSA nonce extraction, recovering 20 bits of the nonce. These results establish sleep-induced power spikes as a practical cross-platform side-channel threat and highlight the need to reconsider design choices in cryptographic systems.</li>
</ul>

<h3>Title: OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyuan Wang, Hanjiang Hu, Xiyu Deng, Saviz Mowlavi, Yorie Nakahira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01493">https://arxiv.org/abs/2602.01493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01493">https://arxiv.org/pdf/2602.01493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01493]] OpInf-LLM: Parametric PDE Solving with LLMs via Operator Inference(https://arxiv.org/abs/2602.01493)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Solving diverse partial differential equations (PDEs) is fundamental in science and engineering. Large language models (LLMs) have demonstrated strong capabilities in code generation, symbolic reasoning, and tool use, but reliably solving PDEs across heterogeneous settings remains challenging. Prior work on LLM-based code generation and transformer-based foundation models for PDE learning has shown promising advances. However, a persistent trade-off between execution success rate and numerical accuracy arises, particularly when generalization to unseen parameters and boundary conditions is required. In this work, we propose OpInf-LLM, an LLM parametric PDE solving framework based on operator inference. The proposed framework leverages a small amount of solution data to enable accurate prediction of diverse PDE instances, including unseen parameters and configurations, and provides seamless integration with LLMs for natural language specification of PDE solving tasks. Its low computational demands and unified tool interface further enable a high execution success rate across heterogeneous settings. By combining operator inference with LLM capabilities, OpInf-LLM opens new possibilities for generalizable reduced-order modeling in LLM-based PDE solving.</li>
</ul>

<h3>Title: Implementation Challenges in Quantum Key Distribution</h3>
<ul>
<li><strong>Authors: </strong>Abel C. H. Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.PF, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01500">https://arxiv.org/abs/2602.01500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01500">https://arxiv.org/pdf/2602.01500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01500]] Implementation Challenges in Quantum Key Distribution(https://arxiv.org/abs/2602.01500)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>In recent years, quantum computing technologies have steadily matured and have begun to find practical applications across various domains. One important area is network communication security, where Quantum Key Distribution (QKD) enables communicating parties to establish a shared secret that can then be used to generate symmetric keys for subsequent encryption and decryption. This study focuses on implementing and comparing two well-known QKD protocols, namely BB84 and E91, within an actual quantum computing environment. It also proposes the use of SX gate operations to generate uniform quantum superposition states. By leveraging the properties of quantum superposition and quantum entanglement, the study illustrates how communicating parties can securely obtain a shared secret while preventing adversaries from intercepting it. The experiments are conducted using the IBM Quantum Platform to demonstrate the feasibility of the BB84 and E91 protocols on actual quantum hardware. The evaluation considers several metrics, including entropy, Independent and Identically Distributed (IID), and error-rate verifications.</li>
</ul>

<h3>Title: You Need an Encoder for Native Position-Independent Caching</h3>
<ul>
<li><strong>Authors: </strong>Shiju Zhao, Junhao Hu, Jiaqi Zheng, Guihai Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01519">https://arxiv.org/abs/2602.01519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01519">https://arxiv.org/pdf/2602.01519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01519]] You Need an Encoder for Native Position-Independent Caching(https://arxiv.org/abs/2602.01519)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Key-Value (KV) cache of Large Language Models (LLMs) is prefix-based, making it highly inefficient for processing contexts retrieved in arbitrary order. Position-Independent Caching (PIC) has been proposed to enable KV reuse without positional constraints; however, existing approaches often incur substantial accuracy degradation, limiting their practical adoption. To address this issue, we propose native PIC by reintroducing the encoder to prevalent decoder-only LLMs and explicitly training it to support PIC. We further develop COMB, a PIC-aware caching system that integrates seamlessly with existing inference frameworks. Experimental results show that COMB reduces Time-to-First-Token (TTFT) by 51-94% and increases throughput by 3$\times$ with comparable accuracy. Furthermore, the quality improvement when using DeepSeek-V2-Lite-Chat demonstrates the applicability of COMB to other types of decoder-only LLMs. Our code is available at this https URL.</li>
</ul>

<h3>Title: When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Haoran Zhao, Soyeon Caren Han, Eduard Hovy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01522">https://arxiv.org/abs/2602.01522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01522">https://arxiv.org/pdf/2602.01522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01522]] When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning(https://arxiv.org/abs/2602.01522)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable. We show that this instability is not solely due to limited capacity: in the rank-1 regime, optimization is highly sensitive to the update direction. Concretely, pretrained vision and text features form mismatched anisotropic regions, yielding a dominant "gap" direction that acts like a translation component and disproportionately steers early gradients under rank-1 constraints. Analyzing pretrained representations, we identify a modality-gap axis that dominates early gradient flow, while a random rank-1 initialization is unlikely to align with it, leading to weak gradients and training collapse. We propose Gap-Init, a geometry-aware initialization that aligns the rank-1 LoRA direction with an estimated modality-gap vector from a small calibration set, while keeping the initial LoRA update zero. Across multiple vision-language tasks and backbones, Gap-Init consistently stabilizes rank-1 training and can match or outperform strong rank-8 baselines. Our results suggest that at the extreme low-rank limit, initial alignment can matter as much as rank itself.</li>
</ul>

<h3>Title: A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Akifumi Wachi, Hirota Kinoshita, Shokichi Takakura, Rei Higuchi, Taiji Suzuki</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01523">https://arxiv.org/abs/2602.01523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01523">https://arxiv.org/pdf/2602.01523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01523]] A Relative-Budget Theory for Reinforcement Learning with Verifiable Rewards in Large Language Model Reasoning(https://arxiv.org/abs/2602.01523)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) is a dominant paradigm for improving the reasoning abilities of large language models, yet its effectiveness varies across tasks and compute budgets. We propose a \emph{relative-budget} theory explaining this variation through a single quantity called relative budget $\xi := H/\mathbb{E}[T]$, where $H$ is the generation horizon (token budget) and $T$ denotes the number of tokens until the first correct solution under a base policy. We show that $\xi$ determines sample efficiency by controlling reward variance and the likelihood of informative trajectories. Our analysis reveals three regimes: in the \emph{deficient} regime ($\xi \to 0$), informative trajectories are rare and the sample complexity explodes; in the \emph{balanced} regime ($\xi=\Theta(1)$), informative trajectories occur with non-negligible probability and RL is maximally sample-efficient; and in the \emph{ample} regime ($\xi \to \infty$), learning remains stable but marginal gains per iteration diminish. We further provide finite-sample guarantees for online RL that characterize learning progress across these regimes. Specifically, in a case study under idealized distributional assumptions, we show that the relative budget grows linearly over iterations. Our empirical results confirm these predictions in realistic settings, identifying a budget $\xi \in [1.5, 2.0]$ that maximizes learning efficiency and coincides with peak reasoning performance.</li>
</ul>

<h3>Title: Preserving Localized Patch Semantics in VLMs</h3>
<ul>
<li><strong>Authors: </strong>Parsa Esmaeilkhani, Longin Jan Latecki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01530">https://arxiv.org/abs/2602.01530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01530">https://arxiv.org/pdf/2602.01530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01530]] Preserving Localized Patch Semantics in VLMs(https://arxiv.org/abs/2602.01530)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, segmentation</a></li>
<li><strong>Abstract: </strong>Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word "cat"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.</li>
</ul>

<h3>Title: Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units</h3>
<ul>
<li><strong>Authors: </strong>Zhe Ling, Sicheng Yu, Danyu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01533">https://arxiv.org/abs/2602.01533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01533">https://arxiv.org/pdf/2602.01533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01533]] Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units(https://arxiv.org/abs/2602.01533)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\pm 180^{\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\%$, $96.67\%$, and $94.33\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.</li>
</ul>

<h3>Title: FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training</h3>
<ul>
<li><strong>Authors: </strong>Yuehai Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01540">https://arxiv.org/abs/2602.01540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01540">https://arxiv.org/pdf/2602.01540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01540]] FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training(https://arxiv.org/abs/2602.01540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.</li>
</ul>

<h3>Title: Toward Cognitive Supersensing in Multimodal Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Boyi Li, Yifan Shen, Yuanzhe Liu, Yifan Xu, Jiateng Liu, Xinzhuo Li, Zhengyuan Li, Jingyuan Zhu, Yunhan Zhong, Fangzhou Lan, Jianguo Cao, James M. Rehg, Heng Ji, Ismini Lourentzou, Xu Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01541">https://arxiv.org/abs/2602.01541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01541">https://arxiv.org/pdf/2602.01541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01541]] Toward Cognitive Supersensing in Multimodal Large Language Model(https://arxiv.org/abs/2602.01541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.</li>
</ul>

<h3>Title: Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions</h3>
<ul>
<li><strong>Authors: </strong>Sarah Tabassum</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01544">https://arxiv.org/abs/2602.01544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01544">https://arxiv.org/pdf/2602.01544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01544]] Are Security Cues Static? Rethinking Warning and Trust Indicators for Life Transitions(https://arxiv.org/abs/2602.01544)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Security cues, such as warnings and trust signals, are designed as stable interface elements, even though people's lives, contexts, and vulnerabilities change over time. Life transitions including migration, aging, or shifts in institutional environments reshape how risk and trust are understood and acted upon. Yet current systems rarely adapt their security cues to these changing conditions, placing the burden of interpretation on users. In this Works-in-Progress paper, we argue that the static nature of security cues represents a design mismatch with transitional human lives. We draw on prior empirical insights from work on educational migration as a motivating case, and extend the discussion to other life transitions. Building on these insights, we introduce the Transition-Aware Security Cues (TASeC) framework and present speculative design concepts illustrating how security cues might evolve across transition stages. We invite HCI to rethink security cues as longitudinal, life-centered design elements collectively.</li>
</ul>

<h3>Title: Plain Transformers are Surprisingly Powerful Link Predictors</h3>
<ul>
<li><strong>Authors: </strong>Quang Truong, Yu Song, Donald Loveland, Mingxuan Ju, Tong Zhao, Neil Shah, Jiliang Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01553">https://arxiv.org/abs/2602.01553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01553">https://arxiv.org/pdf/2602.01553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01553]] Plain Transformers are Surprisingly Powerful Link Predictors(https://arxiv.org/abs/2602.01553)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Link prediction is a core challenge in graph machine learning, demanding models that capture rich and complex topological dependencies. While Graph Neural Networks (GNNs) are the standard solution, state-of-the-art pipelines often rely on explicit structural heuristics or memory-intensive node embeddings -- approaches that struggle to generalize or scale to massive graphs. Emerging Graph Transformers (GTs) offer a potential alternative but often incur significant overhead due to complex structural encodings, hindering their applications to large-scale link prediction. We challenge these sophisticated paradigms with PENCIL, an encoder-only plain Transformer that replaces hand-crafted priors with attention over sampled local subgraphs, retaining the scalability and hardware efficiency of standard Transformers. Through experimental and theoretical analysis, we show that PENCIL extracts richer structural signals than GNNs, implicitly generalizing a broad class of heuristics and subgraph-based expressivity. Empirically, PENCIL outperforms heuristic-informed GNNs and is far more parameter-efficient than ID-embedding--based alternatives, while remaining competitive across diverse benchmarks -- even without node features. Our results challenge the prevailing reliance on complex engineering techniques, demonstrating that simple design choices are potentially sufficient to achieve the same capabilities.</li>
</ul>

<h3>Title: InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Lv Tang, Tianyi Zheng, Bo Li, Xingyu Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01554">https://arxiv.org/abs/2602.01554</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01554">https://arxiv.org/pdf/2602.01554</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01554]] InfoTok: Regulating Information Flow for Capacity-Constrained Shared Visual Tokenization in Unified MLLMs(https://arxiv.org/abs/2602.01554)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Unified multimodal large language models (MLLMs) integrate image understanding and generation in a single framework, with the visual tokenizer acting as the sole interface that maps visual inputs into tokens for downstream tasks. However, existing shared-token designs are mostly architecture-driven and lack an explicit criterion for what information tokens should preserve to support both understanding and generation. Therefore, we introduce a capacity-constrained perspective, highlighting that in shared-token unified MLLMs the visual tokenizer behaves as a compute-bounded learner, so the token budget should prioritize reusable structure over hard-to-exploit high-entropy variations and redundancy. Motivated by this perspective, we propose InfoTok, an information-regularized visual tokenization mechanism grounded in the Information Bottleneck (IB) principle. InfoTok formulates tokenization as controlling information flow from images to shared tokens to multimodal outputs, yielding a principled trade-off between compression and task relevance via mutual-information regularization. We integrate InfoTok into three representative unified MLLMs without introducing any additional training data. Experiments show consistent improvements on both understanding and generation, supporting information-regularized tokenization as a principled foundation for learning a shared token space in unified MLLMs.</li>
</ul>

<h3>Title: How Implicit Bias Accumulates and Propagates in LLM Long-term Memory</h3>
<ul>
<li><strong>Authors: </strong>Yiming Ma, Lixu Wang, Lionel Z. Wang, Hongkun Yang, Haoming Sun, Xin Xu, Jiaqi Wu, Bin Chen, Wei Dong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01558">https://arxiv.org/abs/2602.01558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01558">https://arxiv.org/pdf/2602.01558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01558]] How Implicit Bias Accumulates and Propagates in LLM Long-term Memory(https://arxiv.org/abs/2602.01558)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Long-term memory mechanisms enable Large Language Models (LLMs) to maintain continuity and personalization across extended interaction lifecycles, but they also introduce new and underexplored risks related to fairness. In this work, we study how implicit bias, defined as subtle statistical prejudice, accumulates and propagates within LLMs equipped with long-term memory. To support systematic analysis, we introduce the Decision-based Implicit Bias (DIB) Benchmark, a large-scale dataset comprising 3,776 decision-making scenarios across nine social domains, designed to quantify implicit bias in long-term decision processes. Using a realistic long-horizon simulation framework, we evaluate six state-of-the-art LLMs integrated with three representative memory architectures on DIB and demonstrate that LLMs' implicit bias does not remain static but intensifies over time and propagates across unrelated domains. We further analyze mitigation strategies and show that a static system-level prompting baseline provides limited and short-lived debiasing effects. To address this limitation, we propose Dynamic Memory Tagging (DMT), an agentic intervention that enforces fairness constraints at memory write time. Extensive experimental results show that DMT substantially reduces bias accumulation and effectively curtails cross-domain bias propagation.</li>
</ul>

<h3>Title: Argument Rarity-based Originality Assessment for AI-Assisted Writing</h3>
<ul>
<li><strong>Authors: </strong>Keito Inoshita, Michiaki Omura, Tsukasa Yamanaka, Go Maeda, Kentaro Tsuji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01560">https://arxiv.org/abs/2602.01560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01560">https://arxiv.org/pdf/2602.01560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01560]] Argument Rarity-based Originality Assessment for AI-Assisted Writing(https://arxiv.org/abs/2602.01560)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) have become capable of effortlessly generating high-quality text, traditional quality-focused writing assessment is losing its significance. If the essential goal of education is to foster critical thinking and original perspectives, assessment must also shift its paradigm from quality to originality. This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth. The framework quantifies the rarity of each component using density estimation and integrates them with a quality adjustment mechanism, thereby treating quality and originality as independent evaluation axes. Experiments using human essays and AI-generated essays revealed a strong negative correlation between quality and claim rarity, demonstrating a quality-originality trade-off where higher-quality texts tend to rely on typical claim patterns. Furthermore, while AI essays achieved comparable levels of structural complexity to human essays, their claim rarity was substantially lower than that of humans, indicating that LLMs can reproduce the form of argumentation but have limitations in the originality of content.</li>
</ul>

<h3>Title: Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd</h3>
<ul>
<li><strong>Authors: </strong>Yejin Son, Saejin Kim, Dongjun Min, Younjae Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01561">https://arxiv.org/abs/2602.01561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01561">https://arxiv.org/pdf/2602.01561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01561]] Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd(https://arxiv.org/abs/2602.01561)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.</li>
</ul>

<h3>Title: FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents</h3>
<ul>
<li><strong>Authors: </strong>Chiwei Zhu, Benfeng Xu, Mingxuan Du, Shaohan Wang, Xiaorui Wang, Zhendong Mao, Yongdong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01566">https://arxiv.org/abs/2602.01566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01566">https://arxiv.org/pdf/2602.01566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01566]] FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents(https://arxiv.org/abs/2602.01566)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at this https URL.</li>
</ul>

<h3>Title: One-Step Diffusion for Perceptual Image Compression</h3>
<ul>
<li><strong>Authors: </strong>Yiwen Jia, Hao Wei, Yanhui Zhou, Chenyang Ge</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01570">https://arxiv.org/abs/2602.01570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01570">https://arxiv.org/pdf/2602.01570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01570]] One-Step Diffusion for Perceptual Image Compression(https://arxiv.org/abs/2602.01570)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at this https URL.</li>
</ul>

<h3>Title: LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States</h3>
<ul>
<li><strong>Authors: </strong>Yeqin Zhang, Yunfei Wang, Jiaxuan Chen, Ke Qin, Yizheng Zhao, Cam-Tu Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01572">https://arxiv.org/abs/2602.01572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01572">https://arxiv.org/pdf/2602.01572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01572]] LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States(https://arxiv.org/abs/2602.01572)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.</li>
</ul>

<h3>Title: SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haobo Wang, Weiqi Luo, Xiaojun Jia, Xiaochun Cao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01574">https://arxiv.org/abs/2602.01574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01574">https://arxiv.org/pdf/2602.01574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01574]] SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models(https://arxiv.org/abs/2602.01574)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.</li>
</ul>

<h3>Title: Generative Visual Code Mobile World Models</h3>
<ul>
<li><strong>Authors: </strong>Woosung Koh, Sungjun Han, Segyu Lee, Se-Young Yun, Jamin Shin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01576">https://arxiv.org/abs/2602.01576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01576">https://arxiv.org/pdf/2602.01576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01576]] Generative Visual Code Mobile World Models(https://arxiv.org/abs/2602.01576)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Mobile Graphical User Interface (GUI) World Models (WMs) offer a promising path for improving mobile GUI agent performance at train- and inference-time. However, current approaches face a critical trade-off: text-based WMs sacrifice visual fidelity, while the inability of visual WMs in precise text rendering led to their reliance on slow, complex pipelines dependent on numerous external models. We propose a novel paradigm: visual world modeling via renderable code generation, where a single Vision-Language Model (VLM) predicts the next GUI state as executable web code that renders to pixels, rather than generating pixels directly. This combines the strengths of both approaches: VLMs retain their linguistic priors for precise text rendering while their pre-training on structured web code enables high-fidelity visual generation. We introduce gWorld (8B, 32B), the first open-weight visual mobile GUI WMs built on this paradigm, along with a data generation framework (gWorld) that automatically synthesizes code-based training data. In extensive evaluation across 4 in- and 2 out-of-distribution benchmarks, gWorld sets a new pareto frontier in accuracy versus model size, outperforming 8 frontier open-weight models over 50.25x larger. Further analyses show that (1) scaling training data via gWorld yields meaningful gains, (2) each component of our pipeline improves data quality, and (3) stronger world modeling improves downstream mobile GUI policy performance.</li>
</ul>

<h3>Title: HACK NDSU: A Real-world Event to Promote Student Interest in Cybersecurity</h3>
<ul>
<li><strong>Authors: </strong>Enrique Garcia, Jeremy Straub</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01580">https://arxiv.org/abs/2602.01580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01580">https://arxiv.org/pdf/2602.01580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01580]] HACK NDSU: A Real-world Event to Promote Student Interest in Cybersecurity(https://arxiv.org/abs/2602.01580)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Hack NDSU let students scan, probe, and hack North Dakota State University's campus network, under professionals' supervision, providing an aspirational experience, potentially motivating them to enter the field. This paper provides a blueprint for educational hacking events against production systems. No prior educational event of this type is known.</li>
</ul>

<h3>Title: Nearly Optimal Active Preference Learning and Its Application to LLM Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yao Zhao, Kwang-Sung Jun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01581">https://arxiv.org/abs/2602.01581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01581">https://arxiv.org/pdf/2602.01581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01581]] Nearly Optimal Active Preference Learning and Its Application to LLM Alignment(https://arxiv.org/abs/2602.01581)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning large language models (LLMs) depends on high-quality datasets of human preference labels, which are costly to collect. Although active learning has been studied to improve sample efficiency relative to passive collection, many existing approaches adopt classical experimental design criteria such as G- or D-optimality. These objectives are not tailored to the structure of preference learning, leaving open the design of problem-specific algorithms. In this work, we identify a simple intuition specific to preference learning that calls into question the suitability of these existing design objectives. Motivated by this insight, we propose two active learning algorithms. The first provides the first instance-dependent label complexity guarantee for this setting, and the second is a simple, practical greedy method. We evaluate our algorithm on real-world preference datasets and observe improved sample efficiency compared to existing methods.</li>
</ul>

<h3>Title: A Lightweight Sparse Interaction Network for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Xu Zhang, Qitong Wang, Peng Wang, Wei Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01585">https://arxiv.org/abs/2602.01585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01585">https://arxiv.org/pdf/2602.01585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01585]] A Lightweight Sparse Interaction Network for Time Series Forecasting(https://arxiv.org/abs/2602.01585)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent work shows that linear models can outperform several transformer models in long-term time-series forecasting (TSF). However, instead of explicitly performing temporal interaction through self-attention, linear models implicitly perform it based on stacked MLP structures, which may be insufficient in capturing the complex temporal dependencies and their performance still has potential for improvement. To this end, we propose a Lightweight Sparse Interaction Network (LSINet) for TSF task. Inspired by the sparsity of self-attention, we propose a Multihead Sparse Interaction Mechanism (MSIM). Different from self-attention, MSIM learns the important connections between time steps through sparsity-induced Bernoulli distribution to capture temporal dependencies for TSF. The sparsity is ensured by the proposed self-adaptive regularization loss. Moreover, we observe the shareability of temporal interactions and propose to perform Shared Interaction Learning (SIL) for MSIM to further enhance efficiency and improve convergence. LSINet is a linear model comprising only MLP structures with low overhead and equipped with explicit temporal interaction mechanisms. Extensive experiments on public datasets show that LSINet achieves both higher accuracy and better efficiency than advanced linear models and transformer models in TSF tasks. The code is available at the link this https URL.</li>
</ul>

<h3>Title: HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Wencan Cheng, Gim Hee Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01586">https://arxiv.org/abs/2602.01586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01586">https://arxiv.org/pdf/2602.01586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01586]] HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation(https://arxiv.org/abs/2602.01586)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.</li>
</ul>

<h3>Title: Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment</h3>
<ul>
<li><strong>Authors: </strong>Zehua Cheng, Jianwei Yang, Wei Dai, Jiahao Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01587">https://arxiv.org/abs/2602.01587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01587">https://arxiv.org/pdf/2602.01587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01587]] Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment(https://arxiv.org/abs/2602.01587)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.</li>
</ul>

<h3>Title: Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework</h3>
<ul>
<li><strong>Authors: </strong>Wenzhuo Zhao, Keren Fu, Jiahao He, Xiaohong Liu, Qijun Zhao, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01593">https://arxiv.org/abs/2602.01593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01593">https://arxiv.org/pdf/2602.01593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01593]] Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework(https://arxiv.org/abs/2602.01593)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the "task-specific" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.</li>
</ul>

<h3>Title: The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation</h3>
<ul>
<li><strong>Authors: </strong>Mingwen Zhang, Minqiang Yang, Changsheng Ma, Yang Yu, Hui Bai, Chen Xu, Xiangzhen Kong, Bin Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01598">https://arxiv.org/abs/2602.01598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01598">https://arxiv.org/pdf/2602.01598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01598]] The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation(https://arxiv.org/abs/2602.01598)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \textbf{when to ask} (via Strategy Anchoring) from \textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.</li>
</ul>

<h3>Title: Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yen-Shan Chen, Zhi Rui Tam, Cheng-Kuang Wu, Yun-Nung Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01600">https://arxiv.org/abs/2602.01600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01600">https://arxiv.org/pdf/2602.01600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01600]] Expected Harm: Rethinking Safety Evaluation of (Mis)Aligned LLMs(https://arxiv.org/abs/2602.01600)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Current evaluations of LLM safety predominantly rely on severity-based taxonomies to assess the harmfulness of malicious queries. We argue that this formulation requires re-examination as it assumes uniform risk across all malicious queries, neglecting Execution Likelihood--the conditional probability of a threat being realized given the model's response. In this work, we introduce Expected Harm, a metric that weights the severity of a jailbreak by its execution likelihood, modeled as a function of execution cost. Through empirical analysis of state-of-the-art models, we reveal a systematic Inverse Risk Calibration: models disproportionately exhibit stronger refusal behaviors for low-likelihood (high-cost) threats while remaining vulnerable to high-likelihood (low-cost) queries. We demonstrate that this miscalibration creates a structural vulnerability: by exploiting this property, we increase the attack success rate of existing jailbreaks by up to $2\times$. Finally, we trace the root cause of this failure using linear probing, which reveals that while models encode severity in their latent space to drive refusal decisions, they possess no distinguishable internal representation of execution cost, making them "blind" to this critical dimension of risk.</li>
</ul>

<h3>Title: Universal Redundancies in Time Series Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Anthony Bao, Venkata Hasith Vattikuti, Jeffrey Lai, William Gilpin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01605">https://arxiv.org/abs/2602.01605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01605">https://arxiv.org/pdf/2602.01605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01605]] Universal Redundancies in Time Series Foundation Models(https://arxiv.org/abs/2602.01605)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Time Series Foundation Models (TSFMs) leverage extensive pretraining to accurately predict unseen time series during inference, without the need for task-specific fine-tuning. Through large-scale evaluations on standard benchmarks, we find that leading transformer-based TSFMs exhibit redundant components in their intermediate layers. We introduce a set of tools for mechanistic interpretability of TSFMs, including ablations of specific components and direct logit attribution on the residual stream. Our findings are consistent across several leading TSFMs with diverse architectures, and across a diverse set of real-world and synthetic time-series datasets. We discover that all models in our study are robust to ablations of entire layers. Furthermore, we develop a theoretical framework framing transformers as kernel regressors, motivating a purely intrinsic strategy for ablating heads based on the stable rank of the per-head projection matrices. Using this approach, we uncover the specific heads responsible for degenerate phenomena widely observed in TSFMs, such as parroting of motifs from the context and seasonality bias. Our study sheds light on the universal properties of this emerging class of architectures for continuous-time sequence modeling.</li>
</ul>

<h3>Title: Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Zeqiao Li, Yijing Wang, Haoyu Wang, Zheng Li, Zhiqiang Zuo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01606">https://arxiv.org/abs/2602.01606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01606">https://arxiv.org/pdf/2602.01606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01606]] Boosting Maximum Entropy Reinforcement Learning via One-Step Flow Matching(https://arxiv.org/abs/2602.01606)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion policies are expressive yet incur high inference latency. Flow Matching (FM) enables one-step generation, but integrating it into Maximum Entropy Reinforcement Learning (MaxEnt RL) is challenging: the optimal policy is an intractable energy-based distribution, and the efficient log-likelihood estimation required to balance exploration and exploitation suffers from severe discretization bias. We propose \textbf{F}low-based \textbf{L}og-likelihood-\textbf{A}ware \textbf{M}aximum \textbf{E}ntropy RL (\textbf{FLAME}), a principled framework that addresses these challenges. First, we derive a Q-Reweighted FM objective that bypasses partition function estimation via importance reweighting. Second, we design a decoupled entropy estimator that rigorously corrects bias, which enables efficient exploration and brings the policy closer to the optimal MaxEnt policy. Third, we integrate the MeanFlow formulation to achieve expressive and efficient one-step control. Empirical results on MuJoCo show that FLAME outperforms Gaussian baselines and matches multi-step diffusion policies with significantly lower inference cost. Code is available at this https URL.</li>
</ul>

<h3>Title: Token Pruning for In-Context Generation in Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Junqing Lin, Xingyu Zheng, Pei Cheng, Bin Fu, Jingwei Sun, Guangzhong Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01609">https://arxiv.org/abs/2602.01609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01609">https://arxiv.org/pdf/2602.01609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01609]] Token Pruning for In-Context Generation in Diffusion Transformers(https://arxiv.org/abs/2602.01609)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.</li>
</ul>

<h3>Title: What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?</h3>
<ul>
<li><strong>Authors: </strong>Weizheng Gu, Chengze Li, Zhuohao Yu, Mengyuan Sun, Zhibang Yang, Wei Wang, Hongrui Jia, Shikun Zhang, Wei Ye</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01611">https://arxiv.org/abs/2602.01611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01611">https://arxiv.org/pdf/2602.01611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01611]] What Do Agents Learn from Trajectory-SFT: Semantics or Interfaces?(https://arxiv.org/abs/2602.01611)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are increasingly evaluated as interactive agents, yet standard agent benchmarks conflate two qualitatively distinct sources of success: semantic tool-use and interface-specific interaction pattern memorization. Because both mechanisms can yield identical task success on the original interface, benchmark scores alone are not identifiable evidence of environment-invariant capability. We propose PIPE, a protocol-level evaluation augmentation for diagnosing interface reliance by minimally rewriting environment interfaces while preserving task semantics and execution behavior. Across 16 environments from AgentBench and AgentGym and a range of open-source and API-based agents, PIPE reveals that trajectory-SFT substantially amplifies interface shortcutting: trained agents degrade sharply under minimal interface rewrites, while non-trajectory-trained models remain largely stable. We further introduce Interface Reliance (IR), a counterbalanced alias-based metric that quantifies preference for training-time interfaces, and show that interface shortcutting exhibits environment-dependent, non-monotonic training dynamics that remain invisible under standard evaluation. Our code is available at this https URL.</li>
</ul>

<h3>Title: A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sergii Kozyrev, Davyd Maiboroda (Minima AI, Inc.)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01613">https://arxiv.org/abs/2602.01613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01613">https://arxiv.org/pdf/2602.01613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01613]] A Practical Tensor-Network Compression Pipeline for Production-Scale Large Language Models(https://arxiv.org/abs/2602.01613)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are limited in deployment by GPU memory and inference latency. We present Minima, a production compression pipeline that learns where and how to structurally compress a Transformer and turns that compression into real serving gains. Minima trains a lightweight convolutional predictor to estimate layer- and patch-level sensitivity, applies a mixture of Tucker, tensor-train, and tensor-ring decompositions to low-sensitivity regions, performs a short healing fine-tune, and executes the resulting operators with custom Triton and CUDA kernels. The reduced memory footprint enables speculative decoding with a small draft model and a larger verifier. On Qwen3-32B at an 8k-token context window, Minima reduces peak VRAM from 64 GiB to 40 GiB. For a single active request, throughput increases from 40 tokens per second (baseline) to 50 tokens per second (Minima) and 75 tokens per second (Minima with speculative decoding). Under 50 parallel requests, throughput is 34, 44, and 53 tokens per second respectively, showing that Minima remains effective under high concurrency even when speculative decoding gains compress. We position Minima relative to recent tensor-network, low-rank plus quantization, and cross-layer sharing methods, and argue that it is a practical step toward more aggressive structural compression via shared tensor backbones with tiny per-layer adapters.</li>
</ul>

<h3>Title: AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems</h3>
<ul>
<li><strong>Authors: </strong>Qi Cheng, Licheng Liu, Yao Zhang, Mu Hong, Yiqun Xie, Xiaowei Jia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01614">https://arxiv.org/abs/2602.01614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01614">https://arxiv.org/pdf/2602.01614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01614]] AgroFlux: A Spatial-Temporal Benchmark for Carbon and Nitrogen Flux Prediction in Agricultural Ecosystems(https://arxiv.org/abs/2602.01614)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Agroecosystem, which heavily influenced by human actions and accounts for a quarter of global greenhouse gas emissions (GHGs), plays a crucial role in mitigating global climate change and securing environmental sustainability. However, we can't manage what we can't measure. Accurately quantifying the pools and fluxes in the carbon, nutrient, and water nexus of the agroecosystem is therefore essential for understanding the underlying drivers of GHG and developing effective mitigation strategies. Conventional approaches like soil sampling, process-based models, and black-box machine learning models are facing challenges such as data sparsity, high spatiotemporal heterogeneity, and complex subsurface biogeochemical and physical processes. Developing new trustworthy approaches such as AI-empowered models, will require the AI-ready benchmark dataset and outlined protocols, which unfortunately do not exist. In this work, we introduce a first-of-its-kind spatial-temporal agroecosystem GHG benchmark dataset that integrates physics-based model simulations from Ecosys and DayCent with real-world observations from eddy covariance flux towers and controlled-environment facilities. We evaluate the performance of various sequential deep learning models on carbon and nitrogen flux prediction, including LSTM-based models, temporal CNN-based model, and Transformer-based models. Furthermore, we explored transfer learning to leverage simulated data to improve the generalization of deep learning models on real-world observations. Our benchmark dataset and evaluation framework contribute to the development of more accurate and scalable AI-driven agroecosystem models, advancing our understanding of ecosystem-climate interactions.</li>
</ul>

<h3>Title: Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function</h3>
<ul>
<li><strong>Authors: </strong>Hanjun Park, Byeong-Seo Min, Jiheon Woo, Min-Wook Jeong, Jongho Shin, Yongwoo Lee, Young-Sik Kim, Yongjune Kim</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01621">https://arxiv.org/abs/2602.01621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01621">https://arxiv.org/pdf/2602.01621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01621]] Efficient Softmax Reformulation for Homomorphic Encryption via Moment Generating Function(https://arxiv.org/abs/2602.01621)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Homomorphic encryption (HE) is a prominent framework for privacy-preserving machine learning, enabling inference directly on encrypted data. However, evaluating softmax, a core component of transformer architectures, remains particularly challenging in HE due to its multivariate structure, the large dynamic range induced by exponential functions, and the need for accurate division during normalization. In this paper, we propose MGF-softmax, a novel softmax reformulation based on the moment generating function (MGF) that replaces the softmax denominator with its moment-based counterpart. This reformulation substantially reduces multiplicative depth while preserving key properties of softmax and asymptotically converging to the exact softmax as the number of input tokens increases. Extensive experiments on Vision Transformers and large language models show that MGF-softmax provides an efficient and accurate approximation of softmax in encrypted inference. In particular, it achieves inference accuracy close to that of high-depth exact methods, while requiring substantially lower computational cost through reduced multiplicative depth.</li>
</ul>

<h3>Title: Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?</h3>
<ul>
<li><strong>Authors: </strong>Susan Liang, Chao Huang, Filippos Bellos, Yolo Yunlong Tang, Qianxiang Shen, Jing Bi, Luchuan Song, Zeliang Zhang, Jason Corso, Chenliang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01623">https://arxiv.org/abs/2602.01623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01623">https://arxiv.org/pdf/2602.01623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01623]] Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?(https://arxiv.org/abs/2602.01623)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.</li>
</ul>

<h3>Title: PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards</h3>
<ul>
<li><strong>Authors: </strong>Minh-Quan Le, Gaurav Mittal, Cheng Zhao, David Gu, Dimitris Samaras, Mei Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01624">https://arxiv.org/abs/2602.01624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01624">https://arxiv.org/pdf/2602.01624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01624]] PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards(https://arxiv.org/abs/2602.01624)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.</li>
</ul>

<h3>Title: Toward Enhancing Representation Learning in Federated Multi-Task Settings</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Setayesh, Mahdi Beitollahi, Yasser H. Khalil, Hongliang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01626">https://arxiv.org/abs/2602.01626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01626">https://arxiv.org/pdf/2602.01626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01626]] Toward Enhancing Representation Learning in Federated Multi-Task Settings(https://arxiv.org/abs/2602.01626)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated multi-task learning (FMTL) seeks to collaboratively train customized models for users with different tasks while preserving data privacy. Most existing approaches assume model congruity (i.e., the use of fully or partially homogeneous models) across users, which limits their applicability in realistic settings. To overcome this limitation, we aim to learn a shared representation space across tasks rather than shared model parameters. To this end, we propose Muscle loss, a novel contrastive learning objective that simultaneously aligns representations from all participating models. Unlike existing multi-view or multi-model contrastive methods, which typically align models pairwise, Muscle loss can effectively capture dependencies across tasks because its minimization is equivalent to the maximization of mutual information among all the models' representations. Building on this principle, we develop FedMuscle, a practical and communication-efficient FMTL algorithm that naturally handles both model and task heterogeneity. Experiments on diverse image and language tasks demonstrate that FedMuscle consistently outperforms state-of-the-art baselines, delivering substantial improvements and robust performance across heterogeneous settings.</li>
</ul>

<h3>Title: Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks</h3>
<ul>
<li><strong>Authors: </strong>Bohan Zeng, Kaixin Zhu, Daili Hua, Bozhou Li, Chengzhuo Tong, Yuran Wang, Xinyi Huang, Yifan Dai, Zixiang Zhang, Yifan Yang, Zhou Liu, Hao Liang, Xiaochen Ma, Ruichuan An, Tianyi Bai, Hongcheng Gao, Junbo Niu, Yang Shi, Xinlong Chen, Yue Ding, Minglei Shi, Kai Zeng, Yiwen Tang, Yuanxing Zhang, Pengfei Wan, Xintao Wang, Wentao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01630">https://arxiv.org/abs/2602.01630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01630">https://arxiv.org/pdf/2602.01630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01630]] Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks(https://arxiv.org/abs/2602.01630)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.</li>
</ul>

<h3>Title: Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Zhao, Yihang Wu, Ahmad Chaddad, Tareef Daqqaq, Reem Kateb</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01633">https://arxiv.org/abs/2602.01633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01633">https://arxiv.org/pdf/2602.01633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01633]] Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification(https://arxiv.org/abs/2602.01633)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\% to 41.69\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: this https URL.</li>
</ul>

<h3>Title: Chance-Constrained Inference for Hallucination Risk Control in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sreenivasan Mohandas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01637">https://arxiv.org/abs/2602.01637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01637">https://arxiv.org/pdf/2602.01637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01637]] Chance-Constrained Inference for Hallucination Risk Control in Large Language Models(https://arxiv.org/abs/2602.01637)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models generate outputs stochastically and may produce fluent but invalid responses, including factual hallucinations. Existing mitigation strategies reduce average error rates but do not provide explicit control over the \emph{frequency} of such failures under repeated use. We formulate inference as a deployment-time risk control problem and introduce \emph{chance-constrained inference}, which directly bounds the probability of hallucinations among accepted generations. Hallucinations are modeled as stochastic constraint violations, and we show that confidence-based selective prediction does not, in general, imply probabilistic risk guarantees. To enforce chance constraints efficiently, we propose a sequential, anytime-valid inference procedure that adaptively certifies feasibility or infeasibility using finite samples, avoiding conservative fixed-sample bounds. Experiments on questions inspired by NaturalQuestions and controlled multi-hop question answering demonstrate reliable risk control, early detection of intrinsically infeasible inputs, and safe composition under repeated use, while confidence-based baselines fail to provide consistent guarantees.</li>
</ul>

<h3>Title: ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Yang, ChenWei He, Xiangzhao Hao, Tianyue Wang, Jiarui Guo, Haiyun Guo, Leigang Qu, Jinqiao Wang, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01639">https://arxiv.org/abs/2602.01639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01639">https://arxiv.org/pdf/2602.01639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01639]] ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval(https://arxiv.org/abs/2602.01639)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.</li>
</ul>

<h3>Title: De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xichen Sun, Wentao Wei, Jiahua Rao, Jiancong Xie, Yuedong Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01643">https://arxiv.org/abs/2602.01643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01643">https://arxiv.org/pdf/2602.01643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01643]] De Novo Molecular Generation from Mass Spectra via Many-Body Enhanced Diffusion(https://arxiv.org/abs/2602.01643)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Molecular structure generation from mass spectrometry is fundamental for understanding cellular metabolism and discovering novel compounds. Although tandem mass spectrometry (MS/MS) enables the high-throughput acquisition of fragment fingerprints, these spectra often reflect higher-order interactions involving the concerted cleavage of multiple atoms and bonds-crucial for resolving complex isomers and non-local fragmentation mechanisms. However, most existing methods adopt atom-centric and pairwise interaction modeling, overlooking higher-order edge interactions and lacking the capacity to systematically capture essential many-body characteristics for structure generation. To overcome these limitations, we present MBGen, a Many-Body enhanced diffusion framework for de novo molecular structure Generation from mass spectra. By integrating a many-body attention mechanism and higher-order edge modeling, MBGen comprehensively leverages the rich structural information encoded in MS/MS spectra, enabling accurate de novo generation and isomer differentiation for novel molecules. Experimental results on the NPLIB1 and MassSpecGym benchmarks demonstrate that MBGen achieves superior performance, with improvements of up to 230% over state-of-the-art methods, highlighting the scientific value and practical utility of many-body modeling for mass spectrometry-based molecular generation. Further analysis and ablation studies show that our approach effectively captures higher-order interactions and exhibits enhanced sensitivity to complex isomeric and non-local fragmentation information.</li>
</ul>

<h3>Title: From Perception to Action: Spatial AI Agents and World Models</h3>
<ul>
<li><strong>Authors: </strong>Gloria Felicia, Nolan Bryant, Handi Putra, Ayaan Gazali, Eliel Lobo, Esteban Rojas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.MA, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01644">https://arxiv.org/abs/2602.01644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01644">https://arxiv.org/pdf/2602.01644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01644]] From Perception to Action: Spatial AI Agents and World Models(https://arxiv.org/abs/2602.01644)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models have become the prevailing approach for agentic reasoning and planning, their success in symbolic domains does not readily translate to the physical world. Spatial intelligence, the ability to perceive 3D structure, reason about object relationships, and act under physical constraints, is an orthogonal capability that proves important for embodied agents. Existing surveys address either agentic architectures or spatial domains in isolation. None provide a unified framework connecting these complementary capabilities. This paper bridges that gap. Through a thorough review of over 2,000 papers, citing 742 works from top-tier venues, we introduce a unified three-axis taxonomy connecting agentic capabilities with spatial tasks across scales. Crucially, we distinguish spatial grounding (metric understanding of geometry and physics) from symbolic grounding (associating images with text), arguing that perception alone does not confer agency. Our analysis reveals three key findings mapped to these axes: (1) hierarchical memory systems (Capability axis) are important for long-horizon spatial tasks. (2) GNN-LLM integration (Task axis) is a promising approach for structured spatial reasoning. (3) World models (Scale axis) are essential for safe deployment across micro-to-macro spatial scales. We conclude by identifying six grand challenges and outlining directions for future research, including the need for unified evaluation frameworks to standardize cross-domain assessment. This taxonomy provides a foundation for unifying fragmented research efforts and enabling the next generation of spatially-aware autonomous systems in robotics, autonomous vehicles, and geospatial intelligence.</li>
</ul>

<h3>Title: Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yinchao Ma, Qiang Zhou, Zhibin Wang, Xianing Chen, Hanqing Yang, Jun Song, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01649">https://arxiv.org/abs/2602.01649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01649">https://arxiv.org/pdf/2602.01649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01649]] Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning(https://arxiv.org/abs/2602.01649)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \textbf{C}ontribution-\textbf{a}ware token \textbf{Co}mpression algorithm for \textbf{VID}eo understanding (\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.</li>
</ul>

<h3>Title: Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaqian Li, Yanshu Li, Kuan-Hao Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01654">https://arxiv.org/abs/2602.01654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01654">https://arxiv.org/pdf/2602.01654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01654]] Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models(https://arxiv.org/abs/2602.01654)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.</li>
</ul>

<h3>Title: Efficient Adversarial Attacks on High-dimensional Offline Bandits</h3>
<ul>
<li><strong>Authors: </strong>Seyed Mohammad Hadi Hosseini, Amir Najafi, Mahdieh Soleymani Baghshah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01658">https://arxiv.org/abs/2602.01658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01658">https://arxiv.org/pdf/2602.01658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01658]] Efficient Adversarial Attacks on High-dimensional Offline Bandits(https://arxiv.org/abs/2602.01658)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Bandit algorithms have recently emerged as a powerful tool for evaluating machine learning models, including generative image models and large language models, by efficiently identifying top-performing candidates without exhaustive comparisons. These methods typically rely on a reward model, often distributed with public weights on platforms such as Hugging Face, to provide feedback to the bandit. While online evaluation is expensive and requires repeated trials, offline evaluation with logged data has become an attractive alternative. However, the adversarial robustness of offline bandit evaluation remains largely unexplored, particularly when an attacker perturbs the reward model (rather than the training data) prior to bandit training. In this work, we fill this gap by investigating, both theoretically and empirically, the vulnerability of offline bandit training to adversarial manipulations of the reward model. We introduce a novel threat model in which an attacker exploits offline data in high-dimensional settings to hijack the bandit's behavior. Starting with linear reward functions and extending to nonlinear models such as ReLU neural networks, we study attacks on two Hugging Face evaluators used for generative model assessment: one measuring aesthetic quality and the other assessing compositional alignment. Our results show that even small, imperceptible perturbations to the reward model's weights can drastically alter the bandit's behavior. From a theoretical perspective, we prove a striking high-dimensional effect: as input dimensionality increases, the perturbation norm required for a successful attack decreases, making modern applications such as image evaluation especially vulnerable. Extensive experiments confirm that naive random perturbations are ineffective, whereas carefully targeted perturbations achieve near-perfect attack success rates ...</li>
</ul>

<h3>Title: From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Miao, Junting Dong, Qin Zhao, Yuhang Yang, Junhao Chen, Yang Long</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01661">https://arxiv.org/abs/2602.01661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01661">https://arxiv.org/pdf/2602.01661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01661]] From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction(https://arxiv.org/abs/2602.01661)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.</li>
</ul>

<h3>Title: Moonworks Lunara Aesthetic II: An Image Variation Dataset</h3>
<ul>
<li><strong>Authors: </strong>Yan Wang, Partho Hassan, Samiha Sadeka, Nada Soliman, M M Sayeef Abdullah, Sabit Hassan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01666">https://arxiv.org/abs/2602.01666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01666">https://arxiv.org/pdf/2602.01666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01666]] Moonworks Lunara Aesthetic II: An Image Variation Dataset(https://arxiv.org/abs/2602.01666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: this https URL.</li>
</ul>

<h3>Title: ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Qianyang Li, Xingjun Zhang, Shaoxun Wang, Jia Wei, Yueqi Xing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01668">https://arxiv.org/abs/2602.01668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01668">https://arxiv.org/pdf/2602.01668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01668]] ASGMamba: Adaptive Spectral Gating Mamba for Multivariate Time Series Forecasting(https://arxiv.org/abs/2602.01668)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Long-term multivariate time series forecasting (LTSF) plays a crucial role in various high-performance computing applications, including real-time energy grid management and large-scale traffic flow simulation. However, existing solutions face a dilemma: Transformer-based models suffer from quadratic complexity, limiting their scalability on long sequences, while linear State Space Models (SSMs) often struggle to distinguish valuable signals from high-frequency noise, leading to wasted state capacity. To bridge this gap, we propose ASGMamba, an efficient forecasting framework designed for resource-constrained supercomputing environments. ASGMamba integrates a lightweight Adaptive Spectral Gating (ASG) mechanism that dynamically filters noise based on local spectral energy, enabling the Mamba backbone to focus its state evolution on robust temporal dynamics. Furthermore, we introduce a hierarchical multi-scale architecture with variable-specific Node Embeddings to capture diverse physical characteristics. Extensive experiments on nine benchmarks demonstrate that ASGMamba achieves state-of-the-art accuracy. While keeping strictly $$\mathcal{O}(L)$$ complexity we significantly reduce the memory usage on long-horizon tasks, thus establishing ASGMamba as a scalable solution for high-throughput forecasting in resource limited this http URL code is available at this https URL</li>
</ul>

<h3>Title: Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss</h3>
<ul>
<li><strong>Authors: </strong>Enguang Fan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01673">https://arxiv.org/abs/2602.01673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01673">https://arxiv.org/pdf/2602.01673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01673]] Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss(https://arxiv.org/abs/2602.01673)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.</li>
</ul>

<h3>Title: SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking</h3>
<ul>
<li><strong>Authors: </strong>Yinchao Ma, Dengqing Yang, Zhangyu He, Wenfei Yang, Tianzhu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01677">https://arxiv.org/abs/2602.01677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01677">https://arxiv.org/pdf/2602.01677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01677]] SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking(https://arxiv.org/abs/2602.01677)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.</li>
</ul>

<h3>Title: Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets</h3>
<ul>
<li><strong>Authors: </strong>Taihei Oki, Shinsaku Sakaue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01682">https://arxiv.org/abs/2602.01682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01682">https://arxiv.org/pdf/2602.01682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01682]] Finite and Corruption-Robust Regret Bounds in Online Inverse Linear Optimization under M-Convex Action Sets(https://arxiv.org/abs/2602.01682)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study online inverse linear optimization, also known as contextual recommendation, where a learner sequentially infers an agent's hidden objective vector from observed optimal actions over feasible sets that change over time. The learner aims to recommend actions that perform well under the agent's true objective, and the performance is measured by the regret, defined as the cumulative gap between the agent's optimal values and those achieved by the learner's recommended actions. Prior work has established a regret bound of $O(d\log T)$, as well as a finite but exponentially large bound of $\exp(O(d\log d))$, where $d$ is the dimension of the optimization problem and $T$ is the time horizon, while a regret lower bound of $\Omega(d)$ is known (Gollapudi et al. 2021; Sakaue et al. 2025). Whether a finite regret bound polynomial in $d$ is achievable or not has remained an open question. We partially resolve this by showing that when the feasible sets are M-convex -- a broad class that includes matroids -- a finite regret bound of $O(d\log d)$ is possible. We achieve this by combining a structural characterization of optimal solutions on M-convex sets with a geometric volume argument. Moreover, we extend our approach to adversarially corrupted feedback in up to $C$ rounds. We obtain a regret bound of $O((C+1)d\log d)$ without prior knowledge of $C$, by monitoring directed graphs induced by the observed feedback to detect corruptions adaptively.</li>
</ul>

<h3>Title: FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Kangcong Li, Peng Ye, Lin Zhang, Chao Wang, Huafeng Qin, Tao Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01683">https://arxiv.org/abs/2602.01683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01683">https://arxiv.org/pdf/2602.01683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01683]] FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding(https://arxiv.org/abs/2602.01683)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical "gist"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.</li>
</ul>

<h3>Title: Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment</h3>
<ul>
<li><strong>Authors: </strong>Byeonghu Na, Hyungho Na, Yeongmin Kim, Suhyeon Jo, HeeSun Bae, Mina Kang, Il-Chul Moon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01685">https://arxiv.org/abs/2602.01685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01685">https://arxiv.org/pdf/2602.01685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01685]] Semantic-aware Wasserstein Policy Regularization for Large Language Model Alignment(https://arxiv.org/abs/2602.01685)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are commonly aligned with human preferences using reinforcement learning from human feedback (RLHF). In this method, LLM policies are generally optimized through reward maximization with Kullback-Leibler (KL) divergence regularization of the reference policy. However, KL and its $f$-divergence variants only compare token probabilities at identical indices, failing to capture semantic similarity. We propose Wasserstein Policy Regularization (WPR), a semantic-aware regularization for the RLHF framework based on the entropy-regularized Wasserstein distance, which incorporates the geometry of the token space. The dual formulation of the distance expresses the regularization as penalty terms applied to the reward via optimal dual variables, which yield a tractable objective compatible with standard RL algorithms. Empirically, our method outperforms KL- and $f$-divergence-based baselines, demonstrating the benefits of semantic-aware policy distances for alignment. Our code is available at this https URL.</li>
</ul>

<h3>Title: Counting Hypothesis: Potential Mechanism of In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Jung H. Lee, Sujith Vijayan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01687">https://arxiv.org/abs/2602.01687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01687">https://arxiv.org/pdf/2602.01687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01687]] Counting Hypothesis: Potential Mechanism of In-Context Learning(https://arxiv.org/abs/2602.01687)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.</li>
</ul>

<h3>Title: Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Cui, Shuai Zhou, Wenqiang Li, Ruifeng Qin, Feng Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01696">https://arxiv.org/abs/2602.01696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01696">https://arxiv.org/pdf/2602.01696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01696]] Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection(https://arxiv.org/abs/2602.01696)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.</li>
</ul>

<h3>Title: $\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Li, Lingling Zhang, Zhitao Gao, Yanrui Wu, Yuxuan Dong, Huan Liu, Bifan Wei, Jun Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01703">https://arxiv.org/abs/2602.01703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01703">https://arxiv.org/pdf/2602.01703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01703]] $\textbf{AGT$^{AO}$}$: Robust and Stabilized LLM Unlearning via Adversarial Gating Training with Adaptive Orthogonality(https://arxiv.org/abs/2602.01703)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have achieved remarkable capabilities, they unintentionally memorize sensitive data, posing critical privacy and security risks. Machine unlearning is pivotal for mitigating these risks, yet existing paradigms face a fundamental dilemma: aggressive unlearning often induces catastrophic forgetting that degrades model utility, whereas conservative strategies risk superficial forgetting, leaving models vulnerable to adversarial recovery. To address this trade-off, we propose $\textbf{AGT$^{AO}$}$ (Adversarial Gating Training with Adaptive Orthogonality), a unified framework designed to reconcile robust erasure with utility preservation. Specifically, our approach introduces $\textbf{Adaptive Orthogonality (AO)}$ to dynamically mitigate geometric gradient conflicts between forgetting and retention objectives, thereby minimizing unintended knowledge degradation. Concurrently, $\textbf{Adversarial Gating Training (AGT)}$ formulates unlearning as a latent-space min-max game, employing a curriculum-based gating mechanism to simulate and counter internal recovery attempts. Extensive experiments demonstrate that $\textbf{AGT$^{AO}$}$ achieves a superior trade-off between unlearning efficacy (KUR $\approx$ 0.01) and model utility (MMLU 58.30). Code is available at this https URL.</li>
</ul>

<h3>Title: Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner</h3>
<ul>
<li><strong>Authors: </strong>Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Yi-An Ma, Lianhui Qin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01705">https://arxiv.org/abs/2602.01705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01705">https://arxiv.org/pdf/2602.01705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01705]] Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner(https://arxiv.org/abs/2602.01705)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this issue, we propose Latent Diffusion Reasoning with Reinforcement Learning (LaDi-RL), a framework that conducts exploration directly in a continuous latent space, where latent variables encode semantic-level reasoning trajectories. By modeling exploration via guided diffusion, multi-step denoising distributes stochasticity and preserves multiple coexisting solution modes without mutual suppression. Furthermore, by decoupling latent-space exploration from text-space generation, we show that latent diffusion-based optimization is more effective than text-space policy optimization alone, while a complementary text policy provides additional gains when combined with latent exploration. Experiments on code generation and mathematical reasoning benchmarks demonstrate consistent improvements in both pass@1 and pass@k over discrete RL baselines, with absolute pass@1 gains of +9.4% on code generation and +5.7% on mathematical reasoning, highlighting diffusion-based latent RL as a principled alternative to discrete token-level RL for reasoning.</li>
</ul>

<h3>Title: Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory</h3>
<ul>
<li><strong>Authors: </strong>Langyuan Cui, Chun Kai Ling, Hwee Tou Ng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01708">https://arxiv.org/abs/2602.01708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01708">https://arxiv.org/pdf/2602.01708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01708]] Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory(https://arxiv.org/abs/2602.01708)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.</li>
</ul>

<h3>Title: ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation</h3>
<ul>
<li><strong>Authors: </strong>Xingshan Zeng, Lingzhi Wang, Weiwen Liu, Liangyou Li, Yasheng Wang, Lifeng Shang, Xin Jiang, Qun Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01709">https://arxiv.org/abs/2602.01709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01709">https://arxiv.org/pdf/2602.01709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01709]] ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation(https://arxiv.org/abs/2602.01709)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \emph{\name}, \emph{\underline{A}gentic \underline{R}isk-Aware \underline{T}est-Time Scaling via \underline{I}terative \underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.</li>
</ul>

<h3>Title: Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis</h3>
<ul>
<li><strong>Authors: </strong>Salma Zahran, Zhou Ao, Zhengyang Zhang, Chen Chi, Chenchen Yuan, Yanming Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cond-mat.mtrl-sci, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01710">https://arxiv.org/abs/2602.01710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01710">https://arxiv.org/pdf/2602.01710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01710]] Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis(https://arxiv.org/abs/2602.01710)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.</li>
</ul>

<h3>Title: MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Mouath Abu-Daoud, Leen Kharouf, Omar El Hajj, Dana El Samad, Mariam Al-Omari, Jihad Mallat, Khaled Saleh, Nizar Habash, Farah E. Shamout</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01714">https://arxiv.org/abs/2602.01714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01714">https://arxiv.org/pdf/2602.01714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01714]] MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark(https://arxiv.org/abs/2602.01714)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.</li>
</ul>

<h3>Title: Mechanistic Indicators of Steering Effectiveness in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Jafari, Hao Xue, Flora Salim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01716">https://arxiv.org/abs/2602.01716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01716">https://arxiv.org/pdf/2602.01716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01716]] Mechanistic Indicators of Steering Effectiveness in Large Language Models(https://arxiv.org/abs/2602.01716)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.</li>
</ul>

<h3>Title: Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift</h3>
<ul>
<li><strong>Authors: </strong>Sora Nakai, Youssef Fadhloun, Kacem Mathlouthi, Kotaro Yoshida, Ganesh Talluri, Ioannis Mitliagkas, Hiroki Naganuma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01718">https://arxiv.org/abs/2602.01718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01718">https://arxiv.org/pdf/2602.01718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01718]] Revisiting Generalization Measures Beyond IID: An Empirical Study under Distributional Shift(https://arxiv.org/abs/2602.01718)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generalization remains a central yet unresolved challenge in deep learning, particularly the ability to predict a model's performance beyond its training distribution using quantities available prior to test-time evaluation. Building on the large-scale study of Jiang et al. (2020). and concerns by Dziugaite et al. (2020). about instability across training configurations, we benchmark the robustness of generalization measures beyond IID regime. We train small-to-medium models over 10,000 hyperparameter configurations and evaluate more than 40 measures computable from the trained model and the available training data alone. We significantly broaden the experimental scope along multiple axes: (i) extending the evaluation beyond the standard IID setting to include benchmarking for robustness across diverse distribution shifts, (ii) evaluating multiple architectures and training recipes, and (iii) newly incorporating calibration- and information-criteria-based measures to assess their alignment with both IID and OOD generalization. We find that distribution shifts can substantially alter the predictive performance of many generalization measures, while a smaller subset remains comparatively stable across settings.</li>
</ul>

<h3>Title: COMI: Coarse-to-fine Context Compression via Marginal Information Gain</h3>
<ul>
<li><strong>Authors: </strong>Jiwei Tang, Shilei Liu, Zhicheng Zhang, Yujin Yuan, Libin Zheng, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01719">https://arxiv.org/abs/2602.01719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01719">https://arxiv.org/pdf/2602.01719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01719]] COMI: Coarse-to-fine Context Compression via Marginal Information Gain(https://arxiv.org/abs/2602.01719)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.</li>
</ul>

<h3>Title: FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yikun Ma, Yiqing Li, Jingwen Ye, Zhongkai Wu, Weidong Zhang, Lin Gao, Zhi Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01723">https://arxiv.org/abs/2602.01723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01723">https://arxiv.org/pdf/2602.01723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01723]] FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization(https://arxiv.org/abs/2602.01723)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.</li>
</ul>

<h3>Title: DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation</h3>
<ul>
<li><strong>Authors: </strong>Tushar Anand, Maheswar Bora, Antitza Dantcheva, Abhijit Das</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01724">https://arxiv.org/abs/2602.01724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01724">https://arxiv.org/pdf/2602.01724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01724]] DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation(https://arxiv.org/abs/2602.01724)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at this https URL.</li>
</ul>

<h3>Title: MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration</h3>
<ul>
<li><strong>Authors: </strong>Lianhai Ren, Yucheng Ding, Xiao Liu, Qianxiao Li, Peng Cheng, Yeyun Gong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01734">https://arxiv.org/abs/2602.01734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01734">https://arxiv.org/pdf/2602.01734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01734]] MSign: An Optimizer Preventing Training Instability in Large Language Models via Stable Rank Restoration(https://arxiv.org/abs/2602.01734)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training instability remains a critical challenge in large language model (LLM) pretraining, often manifesting as sudden gradient explosions that waste significant computational resources. We study training failures in a 5M-parameter NanoGPT model scaled via $\mu$P, identifying two key phenomena preceding collapse: (1) rapid decline in weight matrix stable rank (ratio of squared Frobenius norm to squared spectral norm), and (2) increasing alignment between adjacent layer Jacobians. We prove theoretically that these two conditions jointly cause exponential gradient norm growth with network depth. To break this instability mechanism, we propose MSign, a new optimizer that periodically applies matrix sign operations to restore stable rank. Experiments on models from 5M to 3B parameters demonstrate that MSign effectively prevents training failures with a computational overhead of less than 7.0%.</li>
</ul>

<h3>Title: Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Qinwei Ma, Jingzhe Shi, Jiahao Qiu, Zaiwen Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01736">https://arxiv.org/abs/2602.01736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01736">https://arxiv.org/pdf/2602.01736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01736]] Position: The Inevitable End of One-Architecture-Fits-All-Domains in Time Series Forecasting(https://arxiv.org/abs/2602.01736)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent work has questioned the effectiveness and robustness of neural network architectures for time series forecasting tasks. We summarize these concerns and analyze groundly their inherent limitations: i.e. the irreconcilable conflict between single (or few similar) domains SOTA and generalizability over general domains for time series forecasting neural network architecture designs. Moreover, neural networks architectures for general domain time series forecasting are becoming more and more complicated and their performance has almost saturated in recent years. As a result, network architectures developed aiming at fitting general time series domains are almost not inspiring for real world practices for certain single (or few similar) domains such as Finance, Weather, Traffic, etc: each specific domain develops their own methods that rarely utilize advances in neural network architectures of time series community in recent 2-3 years. As a result, we call for the time series community to shift focus away from research on time series neural network architectures for general domains: these researches have become saturated and away from domain-specific SOTAs over time. We should either (1) focus on deep learning methods for certain specific domain(s), or (2) turn to the development of meta-learning methods for general domains.</li>
</ul>

<h3>Title: Tail-Aware Post-Training Quantization for 3D Geometry Models</h3>
<ul>
<li><strong>Authors: </strong>Sicheng Pan, Chen Tang, Shuzhao Xie, Ke Yang, Weixiang Zhang, Jiawei Li, Bin Chen, Shu-Tao Xia, Zhi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01741">https://arxiv.org/abs/2602.01741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01741">https://arxiv.org/pdf/2602.01741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01741]] Tail-Aware Post-Training Quantization for 3D Geometry Models(https://arxiv.org/abs/2602.01741)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\mathcal{O}(N)$ to $\mathcal{O}(\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.</li>
</ul>

<h3>Title: Softmax Linear Attention: Reclaiming Global Competition</h3>
<ul>
<li><strong>Authors: </strong>Mingwei Xu, Xuan Lin, Xinnan Guo, Wanqing Xu, Wanyun Cui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01744">https://arxiv.org/abs/2602.01744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01744">https://arxiv.org/pdf/2602.01744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01744]] Softmax Linear Attention: Reclaiming Global Competition(https://arxiv.org/abs/2602.01744)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>While linear attention reduces the quadratic complexity of standard Transformers to linear time, it often lags behind in expressivity due to the removal of softmax normalization. This omission eliminates \emph{global competition}, a critical mechanism that enables models to sharply focus on relevant information amidst long-context noise. In this work, we propose \textbf{Softmax Linear Attention (SLA)}, a framework designed to restore this competitive selection without sacrificing efficiency. By lifting the softmax operation from the token level to the head level, SLA leverages attention heads as coarse semantic slots, applying a competitive gating mechanism to dynamically select the most relevant subspaces. This reintroduces the ``winner-take-all'' dynamics essential for precise retrieval and robust long-context understanding. Distinct from prior methods that focus on refining local kernel functions, SLA adopts a broader perspective by exploiting the higher-level multi-head aggregation structure. Extensive experiments demonstrate that SLA consistently enhances state-of-the-art linear baselines (RetNet, GLA, GDN) across language modeling and long-context benchmarks, particularly in challenging retrieval scenarios where it significantly boosts robustness against noise, validating its capability to restore precise focus while maintaining linear complexity.</li>
</ul>

<h3>Title: Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment</h3>
<ul>
<li><strong>Authors: </strong>Hongyi Peng, Han Yu, Xiaoxiao Li, Qiang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01746">https://arxiv.org/abs/2602.01746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01746">https://arxiv.org/pdf/2602.01746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01746]] Rethinking LoRA for Data Heterogeneous Federated Learning: Subspace and State Alignment(https://arxiv.org/abs/2602.01746)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, federate</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) is widely used for federated fine-tuning. Yet under non-IID settings, it can substantially underperform full-parameter fine-tuning. Through with-high-probability robustness analysis, we uncover that this gap can be attributed to two coupled mismatches: (i) update-space mismatch, where clients optimize in a low-rank subspace but aggregation occurs in the full space; and (ii) optimizer-state mismatch, where unsynchronized adaptive states amplify drift across rounds. We propose FedGaLore, which combines client-side GaLore-style gradient-subspace optimization with server-side drift-robust synchronization of projected second-moment states via spectral shared-signal extraction, to address this challenge. Across NLU, vision, and NLG benchmarks, FedGaLore improves robustness and accuracy over state-of-the-art federated LoRA baselines in non-IID settings.</li>
</ul>

<h3>Title: Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training</h3>
<ul>
<li><strong>Authors: </strong>Hongseok Choi, Serynn Kim, Wencke Liermann, Jin Seong, Jin-Xia Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01747">https://arxiv.org/abs/2602.01747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01747">https://arxiv.org/pdf/2602.01747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01747]] Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training(https://arxiv.org/abs/2602.01747)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.</li>
</ul>

<h3>Title: WorldCup Sampling for Multi-bit LLM Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Yidan Wang, Yubing Ren, Yanan Cao, Li Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01752">https://arxiv.org/abs/2602.01752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01752">https://arxiv.org/pdf/2602.01752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01752]] WorldCup Sampling for Multi-bit LLM Watermarking(https://arxiv.org/abs/2602.01752)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.</li>
</ul>

<h3>Title: Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Doohyun Kim, Donghwa Kang, Kyungjae Lee, Hyeongboo Baek, Brent Byunghoon Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01757">https://arxiv.org/abs/2602.01757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01757">https://arxiv.org/pdf/2602.01757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01757]] Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings(https://arxiv.org/abs/2602.01757)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.</li>
</ul>

<h3>Title: MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhang, Yanping Zha, Zizhuo Li, Meiqi Gong, Jiayi Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01760">https://arxiv.org/abs/2602.01760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01760">https://arxiv.org/pdf/2602.01760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01760]] MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement(https://arxiv.org/abs/2602.01760)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.</li>
</ul>

<h3>Title: A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention</h3>
<ul>
<li><strong>Authors: </strong>Xiaowei Ye, Xiaoyu He, Chao Liao, Chen Wu, Pinyan Lu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01763">https://arxiv.org/abs/2602.01763</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01763">https://arxiv.org/pdf/2602.01763</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01763]] A Provable Expressiveness Hierarchy in Hybrid Linear-Full Attention(https://arxiv.org/abs/2602.01763)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformers serve as the foundation of most modern large language models. To mitigate the quadratic complexity of standard full attention, various efficient attention mechanisms, such as linear and hybrid attention, have been developed. A fundamental gap remains: their expressive power relative to full attention lacks a rigorous theoretical characterization. In this work, we theoretically characterize the performance differences among these attention mechanisms. Our theory applies to all linear attention variants that can be formulated as a recurrence, including Mamba, DeltaNet, etc. Specifically, we establish an expressiveness hierarchy: for the sequential function composition-a multi-step reasoning task that must occur within a model's forward pass, an ($L+1$)-layer full attention network is sufficient, whereas any hybrid network interleaving $L-1$ layers of full attention with a substantially larger number ($2^{3L^2}$) of linear attention layers cannot solve it. This result demonstrates a clear separation in expressive power between the two types of attention. Our work provides the first provable separation between hybrid attention and standard full attention, offering a theoretical perspective for understanding the fundamental capabilities and limitations of different attention mechanisms.</li>
</ul>

<h3>Title: GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data</h3>
<ul>
<li><strong>Authors: </strong>Dennis Basile, Dennis Sprute, Helene Dörksen, Holger Flatt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01764">https://arxiv.org/abs/2602.01764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01764">https://arxiv.org/pdf/2602.01764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01764]] GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data(https://arxiv.org/abs/2602.01764)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.</li>
</ul>

<h3>Title: Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency</h3>
<ul>
<li><strong>Authors: </strong>Bingzheng Wang, Xiaoyan Gu, Hongbo Xu, Hongcheng Li, Zimo Yu, Jiang Zhou, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01765">https://arxiv.org/abs/2602.01765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01765">https://arxiv.org/pdf/2602.01765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01765]] Backdoor Sentinel: Detecting and Detoxifying Backdoors in Diffusion Models via Temporal Noise Consistency(https://arxiv.org/abs/2602.01765)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have been widely deployed in AIGC services; however, their reliance on opaque training data and procedures exposes a broad attack surface for backdoor injection. In practical auditing scenarios, due to the protection of intellectual property and commercial confidentiality, auditors are typically unable to access model parameters, rendering existing white-box or query-intensive detection methods impractical. More importantly, even after the backdoor is detected, existing detoxification approaches are often trapped in a dilemma between detoxification effectiveness and generation quality. In this work, we identify a previously unreported phenomenon called temporal noise unconsistency, where the noise predictions between adjacent diffusion timesteps is disrupted in specific temporal segments when the input is triggered, while remaining stable under clean inputs. Leveraging this finding, we propose Temporal Noise Consistency Defense (TNC-Defense), a unified framework for backdoor detection and detoxification. The framework first uses the adjacent timestep noise consistency to design a gray-box detection module, for identifying and locating anomalous diffusion timesteps. Furthermore, the framework uses the identified anomalous timesteps to construct a trigger-agnostic, timestep-aware detoxification module, which directly corrects the backdoor generation path. This effectively suppresses backdoor behavior while significantly reducing detoxification costs. We evaluate the proposed method under five representative backdoor attack scenarios and compare it with state-of-the-art defenses. The results show that TNC-Defense improves the average detection accuracy by $11\%$ with negligible additional overhead, and invalidates an average of $98.5\%$ of triggered samples with only a mild degradation in generation quality.</li>
</ul>

<h3>Title: CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling</h3>
<ul>
<li><strong>Authors: </strong>Runsong Zhao, Shilei Liu, Jiwei Tang, Langming Liu, Haibin Chen, Weidong Zhang, Yujin Yuan, Tong Xiao, Jingbo Zhu, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01766">https://arxiv.org/abs/2602.01766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01766">https://arxiv.org/pdf/2602.01766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01766]] CoMeT: Collaborative Memory Transformer for Efficient Long Context Modeling(https://arxiv.org/abs/2602.01766)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The quadratic complexity and indefinitely growing key-value (KV) cache of standard Transformers pose a major barrier to long-context processing. To overcome this, we introduce the Collaborative Memory Transformer (CoMeT), a novel architecture that enables LLMs to handle arbitrarily long sequences with constant memory usage and linear time complexity. Designed as an efficient, plug-in module, CoMeT can be integrated into pre-trained models with only minimal fine-tuning. It operates on sequential data chunks, using a dual-memory system to manage context: a temporary memory on a FIFO queue for recent events, and a global memory with a gated update rule for long-range dependencies. These memories then act as a dynamic soft prompt for the next chunk. To enable efficient fine-tuning on extremely long contexts, we introduce a novel layer-level pipeline parallelism strategy. The effectiveness of our approach is remarkable: a model equipped with CoMeT and fine-tuned on 32k contexts can accurately retrieve a passkey from any position within a 1M token sequence. On the SCROLLS benchmark, CoMeT surpasses other efficient methods and achieves performance comparable to a full-attention baseline on summarization tasks. Its practical effectiveness is further validated on real-world agent and user behavior QA tasks. The code is available at: this https URL</li>
</ul>

<h3>Title: IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination</h3>
<ul>
<li><strong>Authors: </strong>Yuanshuai Li, Yuping Yan, Jirui Han, Fei Ming, Lingjuan Lv, Yaochu Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01769">https://arxiv.org/abs/2602.01769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01769">https://arxiv.org/pdf/2602.01769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01769]] IRIS: Implicit Reward-Guided Internal Sifting for Mitigating Multimodal Hallucination(https://arxiv.org/abs/2602.01769)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination remains a fundamental challenge for Multimodal Large Language Models (MLLMs). While Direct Preference Optimization (DPO) is a key alignment framework, existing approaches often rely heavily on costly external evaluators for scoring or rewriting, incurring off-policy learnability gaps and discretization loss. Due to the lack of access to internal states, such feedback overlooks the fine-grained conflicts between different modalities that lead to hallucinations during generation. To address this issue, we propose IRIS (Implicit Reward-Guided Internal Sifting), which leverages continuous implicit rewards in the native log-probability space to preserve full information density and capture internal modal competition. This on-policy paradigm eliminates learnability gaps by utilizing self-generated preference pairs. By sifting these pairs based on multimodal implicit rewards, IRIS ensures that optimization is driven by signals that directly resolve modal conflicts. Extensive experiments demonstrate that IRIS achieves highly competitive performance on key hallucination benchmarks using only 5.7k samples, without requiring any external feedback during preference alignment. These results confirm that IRIS provides an efficient and principled paradigm for mitigating MLLM hallucinations.</li>
</ul>

<h3>Title: <SOG_k>: One LLM Token for Explicit Graph Structural Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jingyao Wu, Bin Lu, Zijun Di, Xiaoying Gan, Meng Jin, Luoyi Fu, Xinbing Wang, Chenghu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01771">https://arxiv.org/abs/2602.01771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01771">https://arxiv.org/pdf/2602.01771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01771]] <SOG_k>: One LLM Token for Explicit Graph Structural Understanding(https://arxiv.org/abs/2602.01771)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at this https URL.</li>
</ul>

<h3>Title: Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Mingyue Cheng, Xiaoyu Tao, Qi Liu, Ze Guo, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01776">https://arxiv.org/abs/2602.01776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01776">https://arxiv.org/pdf/2602.01776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01776]] Position: Beyond Model-Centric Prediction -- Agentic Time Series Forecasting(https://arxiv.org/abs/2602.01776)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Time series forecasting has traditionally been formulated as a model-centric, static, and single-pass prediction problem that maps historical observations to future values. While this paradigm has driven substantial progress, it proves insufficient in adaptive and multi-turn settings where forecasting requires informative feature extraction, reasoning-driven inference, iterative refinement, and continual adaptation over time. In this paper, we argue for agentic time series forecasting (ATSF), which reframes forecasting as an agentic process composed of perception, planning, action, reflection, and memory. Rather than focusing solely on predictive models, ATSF emphasizes organizing forecasting as an agentic workflow that can interact with tools, incorporate feedback from outcomes, and evolve through experience accumulation. We outline three representative implementation paradigms -- workflow-based design, agentic reinforcement learning, and a hybrid agentic workflow paradigm -- and discuss the opportunities and challenges that arise when shifting from model-centric prediction to agentic forecasting. Together, this position aims to establish agentic forecasting as a foundation for future research at the intersection of time series forecasting.</li>
</ul>

<h3>Title: Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Kangtao Lv, Jiwei Tang, Langming Liu, Haibin Chen, Weidong Zhang, Shilei Liu, Yongwei Wang, Yujin Yuan, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01778">https://arxiv.org/abs/2602.01778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01778">https://arxiv.org/pdf/2602.01778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01778]] Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model(https://arxiv.org/abs/2602.01778)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.</li>
</ul>

<h3>Title: DDP-WM: Disentangled Dynamics Prediction for Efficient World Models</h3>
<ul>
<li><strong>Authors: </strong>Shicheng Yin, Kaixuan Yin, Weixing Chen, Yang Liu, Guanbin Li, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01780">https://arxiv.org/abs/2602.01780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01780">https://arxiv.org/pdf/2602.01780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01780]] DDP-WM: Disentangled Dynamics Prediction for Efficient World Models(https://arxiv.org/abs/2602.01780)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at this https URL.</li>
</ul>

<h3>Title: Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation</h3>
<ul>
<li><strong>Authors: </strong>Dibyayan Patra, Pasindu Ranasinghe, Bikram Banerjee, Simit Raval</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01783">https://arxiv.org/abs/2602.01783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01783">https://arxiv.org/pdf/2602.01783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01783]] Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation(https://arxiv.org/abs/2602.01783)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.</li>
</ul>

<h3>Title: CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yuling Shi, Chaoxiang Xie, Zhensu Sun, Yeheng Chen, Chenxu Zhang, Longfei Yun, Chengcheng Wan, Hongyu Zhang, David Lo, Xiaodong Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01785">https://arxiv.org/abs/2602.01785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01785">https://arxiv.org/pdf/2602.01785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01785]] CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding(https://arxiv.org/abs/2602.01785)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.</li>
</ul>

<h3>Title: RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse</h3>
<ul>
<li><strong>Authors: </strong>Mingrui Liu, Sixiao Zhang, Cheng Long, Kwok-Yan Lam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01795">https://arxiv.org/abs/2602.01795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01795">https://arxiv.org/pdf/2602.01795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01795]] RedVisor: Reasoning-Aware Prompt Injection Defense via Zero-Copy KV Cache Reuse(https://arxiv.org/abs/2602.01795)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly vulnerable to Prompt Injection (PI) attacks, where adversarial instructions hidden within retrieved contexts hijack the model's execution flow. Current defenses typically face a critical trade-off: prevention-based fine-tuning often degrades general utility via the "alignment tax", while detection-based filtering incurs prohibitive latency and memory costs. To bridge this gap, we propose RedVisor, a unified framework that synthesizes the explainability of detection systems with the seamless integration of prevention strategies. To the best of our knowledge, RedVisor is the first approach to leverage fine-grained reasoning paths to simultaneously detect attacks and guide the model's safe response. We implement this via a lightweight, removable adapter positioned atop the frozen backbone. This adapter serves a dual function: it first generates an explainable analysis that precisely localizes the injection and articulates the threat, which then explicitly conditions the model to reject the malicious command. Uniquely, the adapter is active only during this reasoning phase and is effectively muted during the subsequent response generation. This architecture yields two distinct advantages: (1) it mathematically preserves the backbone's original utility on benign inputs; and (2) it enables a novel KV Cache Reuse strategy, eliminating the redundant prefill computation inherent to decoupled pipelines. We further pioneer the integration of this defense into the vLLM serving engine with custom kernels. Experiments demonstrate that RedVisor outperforms state-of-the-art defenses in detection accuracy and throughput while incurring negligible utility loss.</li>
</ul>

<h3>Title: Spatio-Temporal Transformers for Long-Term NDVI Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ido Faran, Nathan S. Netanyahu, Maxim Shoshany</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01799">https://arxiv.org/abs/2602.01799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01799">https://arxiv.org/pdf/2602.01799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01799]] Spatio-Temporal Transformers for Long-Term NDVI Forecasting(https://arxiv.org/abs/2602.01799)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.</li>
</ul>

<h3>Title: Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention</h3>
<ul>
<li><strong>Authors: </strong>Dvir Samuel, Issar Tzachor, Matan Levy, Micahel Green, Gal Chechik, Rami Ben-Ari</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01801">https://arxiv.org/abs/2602.01801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01801">https://arxiv.org/pdf/2602.01801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01801]] Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention(https://arxiv.org/abs/2602.01801)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.</li>
</ul>

<h3>Title: Sentence Curve Language Models</h3>
<ul>
<li><strong>Authors: </strong>DongNyeong Heo, Heelyoul Choi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01807">https://arxiv.org/abs/2602.01807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01807">https://arxiv.org/pdf/2602.01807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01807]] Sentence Curve Language Models(https://arxiv.org/abs/2602.01807)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.</li>
</ul>

<h3>Title: GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiao Liang, Yunzhu Zhang, Linchao Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01814">https://arxiv.org/abs/2602.01814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01814">https://arxiv.org/pdf/2602.01814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01814]] GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation(https://arxiv.org/abs/2602.01814)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.</li>
</ul>

<h3>Title: Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies</h3>
<ul>
<li><strong>Authors: </strong>Wenjin Hou, Wei Liu, Han Hu, Xiaoxiao Sun, Serena Yeung-Levy, Hehe Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01816">https://arxiv.org/abs/2602.01816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01816">https://arxiv.org/pdf/2602.01816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01816]] Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies(https://arxiv.org/abs/2602.01816)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.</li>
</ul>

<h3>Title: Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It</h3>
<ul>
<li><strong>Authors: </strong>Yaxiang Zhang, Yingru Li, Jiacai Liu, Jiawei Xu, Ziniu Li, Qian Liu, Haoyuan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01826">https://arxiv.org/abs/2602.01826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01826">https://arxiv.org/pdf/2602.01826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01826]] Beyond Precision: Training-Inference Mismatch is an Optimization Problem and Simple LR Scheduling Fixes It(https://arxiv.org/abs/2602.01826)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) for training Large Language Models is notoriously unstable. While recent studies attribute this to "training inference mismatch stemming" from inconsistent hybrid engines, standard remedies, such as Importance Sampling, might fail during extended training runs. In this work, we analyze this instability through the lens of optimization, demonstrating that gradient noise and training-inference mismatch escalate in tandem as training progresses. Meanwhile, we find that the mismatch can be effectively suppressed by shrinking the update size. Taken together, we deduce that the mismatch is not merely a static numerical discrepancy, but a dynamic failure coupled with the model's optimization. Based on this insight, we propose a simple yet effective solution: a specialized Learning Rate (LR) scheduler. Instead of pre-defined decay schedule in traditional LR scheduler, our method dynamically triggers LR decay based on response length, which we identify as a reliable early-warning signal for impending instability. Empirical evidence suggests that by reducing the learning rate as gradient noise rises, we can consistently stabilize RL training and keep the training-inference mismatch at a safe level.</li>
</ul>

<h3>Title: AXE: Low-Cost Cross-Domain Web Structured Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Abdelrahman Mansour, Khaled W. Alshaer, Moataz Elsaban</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01838">https://arxiv.org/abs/2602.01838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01838">https://arxiv.org/pdf/2602.01838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01838]] AXE: Low-Cost Cross-Domain Web Structured Information Extraction(https://arxiv.org/abs/2602.01838)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized "pruning" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.</li>
</ul>

<h3>Title: DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ru Zhang, Xunkai Li, Yaxin Deng, Sicheng Liu, Daohan Su, Qiangqiang Dai, Hongchao Qin, Rong-Hua Li, Guoren Wang, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01839">https://arxiv.org/abs/2602.01839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01839">https://arxiv.org/pdf/2602.01839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01839]] DOGMA: Weaving Structural Information into Data-centric Single-cell Transcriptomics Analysis(https://arxiv.org/abs/2602.01839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, data-centric AI methodology has been a dominant paradigm in single-cell transcriptomics analysis, which treats data representation rather than model complexity as the fundamental bottleneck. In the review of current studies, earlier sequence methods treat cells as independent entities and adapt prevalent ML models to analyze their directly inherited sequence data. Despite their simplicity and intuition, these methods overlook the latent intercellular relationships driven by the functional mechanisms of biological systems and the inherent quality issues of the raw sequence data. Therefore, a series of structured methods has emerged. Although they employ various heuristic rules to capture intricate intercellular relationships and enhance the raw sequencing data, these methods often neglect biological prior knowledge. This omission incurs substantial overhead and yields suboptimal graph representations, thereby hindering the utility of ML models. To address them, we propose DOGMA, a holistic data-centric framework designed for the structural reshaping and semantic enhancement of raw data through multi-level biological prior knowledge. Transcending reliance on stochastic heuristics, DOGMA redefines graph construction by integrating Statistical Anchors with Cell Ontology and Phylogenetic Trees to enable deterministic structure discovery and robust cross-species alignment. Furthermore, Gene Ontology is utilized to bridge the feature-level semantic gap by incorporating functional priors. In complex multi-species and multi-organ benchmarks, DOGMA achieves SOTA performance, exhibiting superior zero-shot robustness and sample efficiency while operating with significantly lower computational cost.</li>
</ul>

<h3>Title: Read As Human: Compressing Context via Parallelizable Close Reading and Skimming</h3>
<ul>
<li><strong>Authors: </strong>Jiwei Tang, Shilei Liu, Zhicheng Zhang, Qingsong Lv, Runsong Zhao, Tingwei Lu, Langming Liu, Haibin Chen, Yujin Yuan, Hai-Tao Zheng, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01840">https://arxiv.org/abs/2602.01840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01840">https://arxiv.org/pdf/2602.01840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01840]] Read As Human: Compressing Context via Parallelizable Close Reading and Skimming(https://arxiv.org/abs/2602.01840)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).</li>
</ul>

<h3>Title: Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jinbin Bai, Yixuan Li, Yuchen Zhu, Yi Xin, Qingyu Shi, Aosong Feng, Xiaohong Liu, Molei Tao, Jianru Xue, Xiangtai Li, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01842">https://arxiv.org/abs/2602.01842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01842">https://arxiv.org/pdf/2602.01842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01842]] Prism: Efficient Test-Time Scaling via Hierarchical Search and Self-Verification for Discrete Diffusion Language Models(https://arxiv.org/abs/2602.01842)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Inference-time compute has re-emerged as a practical way to improve LLM reasoning. Most test-time scaling (TTS) algorithms rely on autoregressive decoding, which is ill-suited to discrete diffusion language models (dLLMs) due to their parallel decoding over the entire sequence. As a result, developing effective and efficient TTS methods to unlock dLLMs' full generative potential remains an underexplored challenge. To address this, we propose Prism (Pruning, Remasking, and Integrated Self-verification Method), an efficient TTS framework for dLLMs that (i) performs Hierarchical Trajectory Search (HTS) which dynamically prunes and reallocates compute in an early-to-mid denoising window, (ii) introduces Local branching with partial remasking to explore diverse implementations while preserving high-confidence tokens, and (iii) replaces external verifiers with Self-Verified Feedback (SVF) obtained via self-evaluation prompts on intermediate completions. Across four mathematical reasoning and code generation benchmarks on three dLLMs, including LLaDA 8B Instruct, Dream 7B Instruct, and LLaDA 2.0-mini, our Prism achieves a favorable performance-efficiency trade-off, matching best-of-N performance with substantially fewer function evaluations (NFE). The code is released at this https URL.</li>
</ul>

<h3>Title: SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Qian Xu, Xi Li, Fei Gao, Jie Guo, Haojuan Yuan, Shuaipeng Fan, Mingjin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01843">https://arxiv.org/abs/2602.01843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01843">https://arxiv.org/pdf/2602.01843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01843]] SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection(https://arxiv.org/abs/2602.01843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.</li>
</ul>

<h3>Title: No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation</h3>
<ul>
<li><strong>Authors: </strong>Furkan Eris</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01845">https://arxiv.org/abs/2602.01845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01845">https://arxiv.org/pdf/2602.01845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01845]] No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation(https://arxiv.org/abs/2602.01845)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $\rho = 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at this https URL</li>
</ul>

<h3>Title: Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ziwei Luo, Ziqi Jin, Lei Wang, Lidong Bing, Thomas B. Schön</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01849">https://arxiv.org/abs/2602.01849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01849">https://arxiv.org/pdf/2602.01849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01849]] Self-Rewarding Sequential Monte Carlo for Masked Diffusion Language Models(https://arxiv.org/abs/2602.01849)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This work presents self-rewarding sequential Monte Carlo (SMC), an inference-time scaling algorithm enabling effective sampling of masked diffusion language models (MDLMs). Our algorithm stems from the observation that most existing MDLMs rely on a confidence-based sampling strategy, where only tokens with the highest prediction confidence are preserved at each step. This restricts the generation to a noise-sensitive, greedy decoding paradigm, resulting in an inevitable collapse in the diversity of possible paths. We address this problem by launching multiple interacting diffusion processes in parallel, referred to as particles, for trajectory exploration. Importantly, we introduce the trajectory-level confidence as a self-rewarding signal for assigning particle importance weights. During sampling, particles are iteratively weighted and resampled to systematically steer generation towards globally confident, high-quality samples. Our self-rewarding SMC is verified on various masked diffusion language models and benchmarks, achieving significant improvement without extra training or reward guidance, while effectively converting parallel inference capacity into improved sampling quality. Our code is available at this https URL.</li>
</ul>

<h3>Title: How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Huanyu Zhang, Xuehai Bai, Chengzu Li, Chen Liang, Haochen Tian, Haodong Li, Ruichuan An, Yifan Zhang, Anna Korhonen, Zhang Zhang, Liang Wang, Tieniu Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01851">https://arxiv.org/abs/2602.01851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01851">https://arxiv.org/pdf/2602.01851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01851]] How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing(https://arxiv.org/abs/2602.01851)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.</li>
</ul>

<h3>Title: FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zeyan Wang, Zhengmao Liu, Yongxin Cai, Chi Li, Xiaoying Tang, Jingchao Chen, Zibin Pan, Jing Qiu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01852">https://arxiv.org/abs/2602.01852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01852">https://arxiv.org/pdf/2602.01852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01852]] FUPareto: Bridging the Forgetting-Utility Gap in Federated Unlearning via Pareto Augmented Optimization(https://arxiv.org/abs/2602.01852)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, membership infer, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Unlearning (FU) aims to efficiently remove the influence of specific client data from a federated model while preserving utility for the remaining clients. However, three key challenges remain: (1) existing unlearning objectives often compromise model utility or increase vulnerability to Membership Inference Attacks (MIA); (2) there is a persistent conflict between forgetting and utility, where further unlearning inevitably harms retained performance; and (3) support for concurrent multi-client unlearning is poor, as gradient conflicts among clients degrade the quality of forgetting. To address these issues, we propose FUPareto, an efficient unlearning framework via Pareto-augmented optimization. We first introduce the Minimum Boundary Shift (MBS) Loss, which enforces unlearning by suppressing the target class logit below the highest non-target class logit; this can improve the unlearning efficiency and mitigate MIA risks. During the unlearning process, FUPareto performs Pareto improvement steps to preserve model utility and executes Pareto expansion to guarantee forgetting. Specifically, during Pareto expansion, the framework integrates a Null-Space Projected Multiple Gradient Descent Algorithm (MGDA) to decouple gradient conflicts. This enables effective, fair, and concurrent unlearning for multiple clients while minimizing utility degradation. Extensive experiments across diverse scenarios demonstrate that FUPareto consistently outperforms state-of-the-art FU methods in both unlearning efficacy and retained utility.</li>
</ul>

<h3>Title: Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Xiangkun Wu, Qianglin Wen, Yingying Zhang, Hongtu Zhu, Ting Li, Chengchun Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01853">https://arxiv.org/abs/2602.01853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01853">https://arxiv.org/pdf/2602.01853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01853]] Designing Time Series Experiments in A/B Testing with Transformer Reinforcement Learning(https://arxiv.org/abs/2602.01853)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A/B testing has become a gold standard for modern technological companies to conduct policy evaluation. Yet, its application to time series experiments, where policies are sequentially assigned over time, remains challenging. Existing designs suffer from two limitations: (i) they do not fully leverage the entire history for treatment allocation; (ii) they rely on strong assumptions to approximate the objective function (e.g., the mean squared error of the estimated treatment effect) for optimizing the design. We first establish an impossibility theorem showing that failure to condition on the full history leads to suboptimal designs, due to the dynamic dependencies in time series experiments. To address both limitations simultaneously, we next propose a transformer reinforcement learning (RL) approach which leverages transformers to condition allocation on the entire history and employs RL to directly optimize the MSE without relying on restrictive assumptions. Empirical evaluations on synthetic data, a publicly available dispatch simulator, and a real-world ridesharing dataset demonstrate that our proposal consistently outperforms existing designs.</li>
</ul>

<h3>Title: Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG</h3>
<ul>
<li><strong>Authors: </strong>Blagoj Hristov, Hristijan Gjoreski, Vesna Ojleska Latkoska, Gorjan Nadzinski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01855">https://arxiv.org/abs/2602.01855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01855">https://arxiv.org/pdf/2602.01855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01855]] Time2Vec-Integrated Transformer for Robust Gesture Recognition from Low-Density sEMG(https://arxiv.org/abs/2602.01855)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Accurate and responsive myoelectric prosthesis control typically relies on complex, dense multi-sensor arrays, which limits consumer accessibility. This paper presents a novel, data-efficient deep learning framework designed to achieve precise and accurate control using minimal sensor hardware. Leveraging an external dataset of 8 subjects, our approach implements a hybrid Transformer optimized for sparse, two-channel surface electromyography (sEMG). Unlike standard architectures that use fixed positional encodings, we integrate Time2Vec learnable temporal embeddings to capture the stochastic temporal warping inherent in biological signals. Furthermore, we employ a normalized additive fusion strategy that aligns the latent distributions of spatial and temporal features, preventing the destructive interference common in standard implementations. A two-stage curriculum learning protocol is utilized to ensure robust feature extraction despite data scarcity. The proposed architecture achieves a state-of-the-art multi-subject F1-score of 95.7% $\pm$ 0.20% for a 10-class movement set, statistically outperforming both a standard Transformer with fixed encodings and a recurrent CNN-LSTM model. Architectural optimization reveals that a balanced allocation of model capacity between spatial and temporal dimensions yields the highest stability. Furthermore, while direct transfer to a new unseen subject led to poor accuracy due to domain shifts, a rapid calibration protocol utilizing only two trials per gesture recovered performance from 21.0% $\pm$ 2.98% to 96.9% $\pm$ 0.52%. By validating that high-fidelity temporal embeddings can compensate for low spatial resolution, this work challenges the necessity of high-density sensing. The proposed framework offers a robust, cost-effective blueprint for next-generation prosthetic interfaces capable of rapid personalization.</li>
</ul>

<h3>Title: Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yuan Wang, Yuhao Wan, Siming Zheng, Bo Li, Qibin Hou, Peng-Tao Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01864">https://arxiv.org/abs/2602.01864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01864">https://arxiv.org/pdf/2602.01864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01864]] Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling(https://arxiv.org/abs/2602.01864)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a "Trust but Verify" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.</li>
</ul>

<h3>Title: PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning</h3>
<ul>
<li><strong>Authors: </strong>Langming Liu, Kangtao Lv, Haibin Chen, Weidong Zhang, Yejing Wang, Shilei Liu, Xin Tong, Yujin Yuan, Yongwei Wang, Wenbo Su, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01875">https://arxiv.org/abs/2602.01875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01875">https://arxiv.org/pdf/2602.01875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01875]] PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning(https://arxiv.org/abs/2602.01875)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of "low-probability truth" and "high-probability falsehood". Recent approaches, such as teaching models to say "I don't know" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is "\textbf{debiasing then learning}." It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making "room" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding</h3>
<ul>
<li><strong>Authors: </strong>Ye Chen, Yupeng Zhu, Xiongzhen Zhang, Zhewen Wan, Yingzhe Li, Wenjun Zhang, Bingbing Ni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01881">https://arxiv.org/abs/2602.01881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01881">https://arxiv.org/pdf/2602.01881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01881]] ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding(https://arxiv.org/abs/2602.01881)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.</li>
</ul>

<h3>Title: ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support</h3>
<ul>
<li><strong>Authors: </strong>Tiantian Chen, Jiaqi Lu, Ying Shen, Lin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01885">https://arxiv.org/abs/2602.01885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01885">https://arxiv.org/pdf/2602.01885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01885]] ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support(https://arxiv.org/abs/2602.01885)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.</li>
</ul>

<h3>Title: Internal Flow Signatures for Self-Checking and Refinement in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sungheon Jeong, Sanggeon Yun, Ryozo Masukawa, Wenjun Haung, Hanning Chen, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01897">https://arxiv.org/abs/2602.01897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01897">https://arxiv.org/pdf/2602.01897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01897]] Internal Flow Signatures for Self-Checking and Refinement in LLMs(https://arxiv.org/abs/2602.01897)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models can generate fluent answers that are unfaithful to the provided context, while many safeguards rely on external verification or a separate judge after generation. We introduce \emph{internal flow signatures} that audit decision formation from depthwise dynamics at a fixed inter-block monitoring boundary. The method stabilizes token-wise motion via bias-centered monitoring, then summarizes trajectories in compact \emph{moving} readout-aligned subspaces constructed from the top token and its close competitors within each depth window. Neighboring window frames are aligned by an orthogonal transport, yielding depth-comparable transported step lengths, turning angles, and subspace drift summaries that are invariant to within-window basis choices. A lightweight GRU validator trained on these signatures performs self-checking without modifying the base model. Beyond detection, the validator localizes a culprit depth event and enables a targeted refinement: the model rolls back to the culprit token and clamps an abnormal transported step at the identified block while preserving the orthogonal residual. The resulting pipeline provides actionable localization and low-overhead self-checking from internal decision dynamics. \emph{Code is available at} \texttt{this http URL}.</li>
</ul>

<h3>Title: Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jiedong Zhuang, Lu Lu, Ming Dai, Rui Hu, Jian Chen, Qiang Liu, Haoji Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01901">https://arxiv.org/abs/2602.01901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01901">https://arxiv.org/pdf/2602.01901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01901]] Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model(https://arxiv.org/abs/2602.01901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.</li>
</ul>

<h3>Title: Learning Sparse Visual Representations via Spatial-Semantic Factorization</h3>
<ul>
<li><strong>Authors: </strong>Theodore Zhengde Zhao, Sid Kiblawi, Jianwei Yang, Naoto Usuyama, Reuben Tan, Noel C Codella, Tristan Naumann, Hoifung Poon, Mu Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01905">https://arxiv.org/abs/2602.01905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01905">https://arxiv.org/pdf/2602.01905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01905]] Learning Sparse Visual Representations via Spatial-Semantic Factorization(https://arxiv.org/abs/2602.01905)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at this https URL.</li>
</ul>

<h3>Title: DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Farhan Ullah, Irfan Ullah, Khalil Khan, Giovanni Pau, JaKeoung Koo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01906">https://arxiv.org/abs/2602.01906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01906">https://arxiv.org/pdf/2602.01906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01906]] DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification(https://arxiv.org/abs/2602.01906)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.</li>
</ul>

<h3>Title: Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wenbo Pan, Zhichao Liu, Xianlong Wang, Haining Yu, Xiaohua Jia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01914">https://arxiv.org/abs/2602.01914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01914">https://arxiv.org/pdf/2602.01914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01914]] Towards Long-Horizon Interpretability: Efficient and Faithful Multi-Token Attribution for Reasoning LLMs(https://arxiv.org/abs/2602.01914)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Token attribution methods provide intuitive explanations for language model outputs by identifying causally important input tokens. However, as modern LLMs increasingly rely on extended reasoning chains, existing schemes face two critical challenges: (1) efficiency bottleneck, where attributing a target span of M tokens within a context of length N requires O(M*N) operations, making long-context attribution prohibitively slow; and (2) faithfulness drop, where intermediate reasoning tokens absorb attribution mass, preventing importance from propagating back to the original input. To address these, we introduce FlashTrace, an efficient multi-token attribution method that employs span-wise aggregation to compute attribution over multi-token targets in a single pass, while maintaining faithfulness. Moreover, we design a recursive attribution mechanism that traces importance through intermediate reasoning chains back to source inputs. Extensive experiments on long-context retrieval (RULER) and multi-step reasoning (MATH, MorehopQA) tasks demonstrate that FlashTrace achieves over 130x speedup over existing baselines while maintaining superior faithfulness. We further analyze the dynamics of recursive attribution, showing that even a single recursive hop improves faithfulness by tracing importance through the reasoning chain.</li>
</ul>

<h3>Title: VLM-Guided Experience Replay</h3>
<ul>
<li><strong>Authors: </strong>Elad Sharony, Tom Jurgenson, Orr Krupnik, Dotan Di Castro, Shie Mannor</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01915">https://arxiv.org/abs/2602.01915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01915">https://arxiv.org/pdf/2602.01915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01915]] VLM-Guided Experience Replay(https://arxiv.org/abs/2602.01915)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) and Vision-Language Models (VLMs) have enabled powerful semantic and multimodal reasoning capabilities, creating new opportunities to enhance sample efficiency, high-level planning, and interpretability in reinforcement learning (RL). While prior work has integrated LLMs and VLMs into various components of RL, the replay buffer, a core component for storing and reusing experiences, remains unexplored. We propose addressing this gap by leveraging VLMs to guide the prioritization of experiences in the replay buffer. Our key idea is to use a frozen, pre-trained VLM (requiring no fine-tuning) as an automated evaluator to identify and prioritize promising sub-trajectories from the agent's experiences. Across scenarios, including game-playing and robotics, spanning both discrete and continuous domains, agents trained with our proposed prioritization method achieve 11-52% higher average success rates and improve sample efficiency by 19-45% compared to previous approaches. this https URL</li>
</ul>

<h3>Title: From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"</h3>
<ul>
<li><strong>Authors: </strong>Hend Al-Khalifa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01919">https://arxiv.org/abs/2602.01919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01919">https://arxiv.org/pdf/2602.01919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01919]] From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted "Vibe Coding"(https://arxiv.org/abs/2602.01919)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.</li>
</ul>

<h3>Title: PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Abdul Joseph Fofanah, Lian Wen, David Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01920">https://arxiv.org/abs/2602.01920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01920">https://arxiv.org/pdf/2602.01920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01920]] PIMPC-GNN: Physics-Informed Multi-Phase Consensus Learning for Enhancing Imbalanced Node Classification in Graph Neural Networks(https://arxiv.org/abs/2602.01920)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) often struggle in class-imbalanced settings, where minority classes are under-represented and predictions are biased toward majorities. We propose \textbf{PIMPC-GNN}, a physics-informed multi-phase consensus framework for imbalanced node classification. Our method integrates three complementary dynamics: (i) thermodynamic diffusion, which spreads minority labels to capture long-range dependencies, (ii) Kuramoto synchronisation, which aligns minority nodes through oscillatory consensus, and (iii) spectral embedding, which separates classes via structural regularisation. These perspectives are combined through class-adaptive ensemble weighting and trained with an imbalance-aware loss that couples balanced cross-entropy with physics-based constraints. Across five benchmark datasets and imbalance ratios from 5-100, PIMPC-GNN outperforms 16 state-of-the-art baselines, achieving notable gains in minority-class recall (up to +12.7\%) and balanced accuracy (up to +8.3\%). Beyond empirical improvements, the framework also provides interpretable insights into consensus dynamics in graph learning. The code is available at \texttt{this https URL}.</li>
</ul>

<h3>Title: Embedding Learning on Multiplex Networks for Link Prediction</h3>
<ul>
<li><strong>Authors: </strong>Orell Trautmann, Olaf Wolkenhauer (SU), Clémence Réda (IBENS)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01922">https://arxiv.org/abs/2602.01922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01922">https://arxiv.org/pdf/2602.01922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01922]] Embedding Learning on Multiplex Networks for Link Prediction(https://arxiv.org/abs/2602.01922)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Over the past years, embedding learning on networks has shown tremendous results in link prediction tasks for complex systems, with a wide range of real-life applications. Learning a representation for each node in a knowledge graph allows us to capture topological and semantic information, which can be processed in downstream analyses later. In the link prediction task, high-dimensional network information is encoded into low-dimensional vectors, which are then fed to a predictor to infer new connections between nodes in the network. As the network complexity (that is, the numbers of connections and types of interactions) grows, embedding learning turns out increasingly challenging. This review covers published models on embedding learning on multiplex networks for link prediction. First, we propose refined taxonomies to classify and compare models, depending on the type of embeddings and embedding techniques. Second, we review and address the problem of reproducible and fair evaluation of embedding learning on multiplex networks for the link prediction task. Finally, we tackle evaluation on directed multiplex networks by proposing a novel and fair testing procedure. This review constitutes a crucial step towards the development of more performant and tractable embedding learning approaches for multiplex networks and their fair evaluation for the link prediction task. We also suggest guidelines on the evaluation of models, and provide an informed perspective on the challenges and tools currently available to address downstream analyses applied to multiplex networks.</li>
</ul>

<h3>Title: Bayesian Integration of Nonlinear Incomplete Clinical Data</h3>
<ul>
<li><strong>Authors: </strong>Lucía González-Zamorano, Nuria Balbás-Esteban, Vanessa Gómez-Verdejo, Albert Belenguer-Llorens, Carlos Sevilla-Salcedo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01924">https://arxiv.org/abs/2602.01924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01924">https://arxiv.org/pdf/2602.01924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01924]] Bayesian Integration of Nonlinear Incomplete Clinical Data(https://arxiv.org/abs/2602.01924)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Multimodal clinical data are characterized by high dimensionality, heterogeneous representations, and structured missingness, posing significant challenges for predictive modeling, data integration, and interpretability. We propose BIONIC (Bayesian Integration of Nonlinear Incomplete Clinical data), a unified probabilistic framework that integrates heterogeneous multimodal data under missingness through a joint generative-discriminative latent architecture. BIONIC uses pretrained embeddings for complex modalities such as medical images and clinical text, while incorporating structured clinical variables directly within a Bayesian multimodal formulation. The proposed framework enables robust learning in partially observed and semi-supervised settings by explicitly modeling modality-level and variable-level missingness, as well as missing labels. We evaluate BIONIC on three multimodal clinical and biomedical datasets, demonstrating strong and consistent discriminative performance compared to representative multimodal baselines, particularly under incomplete data scenarios. Beyond predictive accuracy, BIONIC provides intrinsic interpretability through its latent structure, enabling population-level analysis of modality relevance and supporting clinically meaningful insight.</li>
</ul>

<h3>Title: Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic</h3>
<ul>
<li><strong>Authors: </strong>Kristopher Alex Schlett, Bela Genge, Savio Sciancalepore</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01932">https://arxiv.org/abs/2602.01932</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01932">https://arxiv.org/pdf/2602.01932</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01932]] Things that Matter -- Identifying Interactions and IoT Device Types in Encrypted Matter Traffic(https://arxiv.org/abs/2602.01932)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>Matter is the most recent application-layer standard for the Internet of Things (IoT). As one of its major selling points, Matter's design imposes particular attention to security and privacy: it provides validated secure session establishment protocols, and it uses robust security algorithms to secure communications between IoT devices and Matter controllers. However, to our knowledge, there is no systematic analysis investigating the extent to which a passive attacker, in possession of lower layer keys or exploiting security misconfiguration at those layers, could infer information by passively analyzing encrypted Matter traffic. In this paper, we fill this gap by analyzing the robustness of the Matter IoT standard to encrypted traffic analysis performed by a passive eavesdropper. By using various datasets collected from real-world testbeds and simulated setups, we identify patterns in metadata of the encrypted Matter traffic that allow inferring the specific interactions occurring between end devices and controllers. Moreover, we associate patterns in sequences of interactions to specific types of IoT devices. These patterns can be used to create fingerprints that allow a passive attacker to infer the type of devices used in the network, constituting a serious breach of users privacy. Our results reveal that we can identify specific Matter interactions that occur in encrypted traffic with over $95\%$ accuracy also in the presence of packet losses and delays. Moreover, we can identify Matter device types with a minimum accuracy of $88\%$. The CSA acknowledged our findings, and expressed the willingness to address such vulnerabilities in the next releases of the standard.</li>
</ul>

<h3>Title: COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation</h3>
<ul>
<li><strong>Authors: </strong>Annabelle Sujun Tang, Christopher Priebe, Lianhui Qin, Hadi Esmaeilzadeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01935">https://arxiv.org/abs/2602.01935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01935">https://arxiv.org/pdf/2602.01935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01935]] COLT: Lightweight Multi-LLM Collaboration through Shared MCTS Reasoning for Model Compilation(https://arxiv.org/abs/2602.01935)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Model serving costs dominate AI systems, making compiler optimization essential for scalable deployment. Recent works show that a large language model (LLM) can guide compiler search by reasoning over program structure and optimization history. However, using a single large model throughout the search is expensive, while smaller models are less reliable when used alone. Thus, this paper seeks to answer whether multi-LLM collaborative reasoning relying primarily on small LLMs can match or exceed the performance of a single large model. As such, we propose a lightweight collaborative multi-LLM framework, dubbed COLT, for compiler optimization that enables coordinated reasoning across multiple models within a single Monte Carlo tree search (MCTS) process. A key contribution is the use of a single shared MCTS tree as the collaboration substrate across LLMs, enabling the reuse of transformation prefixes and cross-model value propagation. Hence, we circumvent both heavy internal reasoning mechanisms and conventional agentic machinery that relies on external planners, multiple concurrent LLMs, databases, external memory/versioning of intermediate results, and controllers by simply endogenizing model selection within the lightweight MCTS optimization loop. Every iteration, the acting LLM proposes a joint action: (compiler transformation, model to be queried next). We also introduce a model-aware tree policy that biases search toward smaller models while preserving exploration, and a course-alteration mechanism that escalates to the largest model when the search exhibits persistent regressions attributable to smaller models.</li>
</ul>

<h3>Title: PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Abdul Joseph Fofanah, Lian Wen, David Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01936">https://arxiv.org/abs/2602.01936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01936">https://arxiv.org/pdf/2602.01936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01936]] PIMCST: Physics-Informed Multi-Phase Consensus and Spatio-Temporal Few-Shot Learning for Traffic Flow Forecasting(https://arxiv.org/abs/2602.01936)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate traffic flow prediction remains a fundamental challenge in intelligent transportation systems, particularly in cross-domain, data-scarce scenarios where limited historical data hinders model training and generalisation. The complex spatio-temporal dependencies and nonlinear dynamics of urban mobility networks further complicate few-shot learning across different cities. This paper proposes MCPST, a novel Multi-phase Consensus Spatio-Temporal framework for few-shot traffic forecasting that reconceptualises traffic prediction as a multi-phase consensus learning problem. Our framework introduces three core innovations: (1) a multi-phase engine that models traffic dynamics through diffusion, synchronisation, and spectral embeddings for comprehensive dynamic characterisation; (2) an adaptive consensus mechanism that dynamically fuses phase-specific predictions while enforcing consistency; and (3) a structured meta-learning strategy for rapid adaptation to new cities with minimal data. We establish extensive theoretical guarantees, including representation theorems with bounded approximation errors and generalisation bounds for few-shot adaptation. Through experiments on four real-world datasets, MCPST outperforms fourteen state-of-the-art methods in spatio-temporal graph learning methods, dynamic graph transfer learning methods, prompt-based spatio-temporal prediction methods and cross-domain few-shot settings, improving prediction accuracy while reducing required training data and providing interpretable insights. The implementation code is available at this https URL.</li>
</ul>

<h3>Title: T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation</h3>
<ul>
<li><strong>Authors: </strong>Suhan Guo, Bingxu Wang, Shaodan Zhang, Furao Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01937">https://arxiv.org/abs/2602.01937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01937">https://arxiv.org/pdf/2602.01937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01937]] T-LLM: Teaching Large Language Models to Forecast Time Series via Temporal Distillation(https://arxiv.org/abs/2602.01937)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series forecasting plays a critical role in decision-making across many real-world applications. Unlike data in vision and language domains, time series data is inherently tied to the evolution of underlying processes and can only accumulate as real-world time progresses, limiting the effectiveness of scale-driven pretraining alone. This time-bound constraint poses a challenge for enabling large language models (LLMs) to acquire forecasting capability, as existing approaches primarily rely on representation-level alignment or inference-time temporal modules rather than explicitly teaching forecasting behavior to the LLM. We propose T-LLM, a temporal distillation framework that equips general-purpose LLMs with time series forecasting capability by transferring predictive behavior from a lightweight temporal teacher during training. The teacher combines trend modeling and frequency-domain analysis to provide structured temporal supervision, and is removed entirely at inference, leaving the LLM as the sole forecasting model. Experiments on benchmark datasets and infectious disease forecasting tasks demonstrate that T-LLM consistently outperforms existing LLM-based forecasting methods under full-shot, few-shot, and zero-shot settings, while enabling a simple and efficient deployment pipeline.</li>
</ul>

<h3>Title: Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework</h3>
<ul>
<li><strong>Authors: </strong>Alsharif Abuadbba, Nazatul Sultan, Surya Nepal, Sanjay Jha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01942">https://arxiv.org/abs/2602.01942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01942">https://arxiv.org/pdf/2602.01942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01942]] Human Society-Inspired Approaches to Agentic AI Security: The 4C Framework(https://arxiv.org/abs/2602.01942)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense</a></li>
<li><strong>Abstract: </strong>AI is moving from domain-specific autonomy in closed, predictable settings to large-language-model-driven agents that plan and act in open, cross-organizational environments. As a result, the cybersecurity risk landscape is changing in fundamental ways. Agentic AI systems can plan, act, collaborate, and persist over time, functioning as participants in complex socio-technical ecosystems rather than as isolated software components. Although recent work has strengthened defenses against model and pipeline level vulnerabilities such as prompt injection, data poisoning, and tool misuse, these system centric approaches may fail to capture risks that arise from autonomy, interaction, and emergent behavior. This article introduces the 4C Framework for multi-agent AI security, inspired by societal governance. It organizes agentic risks across four interdependent dimensions: Core (system, infrastructure, and environmental integrity), Connection (communication, coordination, and trust), Cognition (belief, goal, and reasoning integrity), and Compliance (ethical, legal, and institutional governance). By shifting AI security from a narrow focus on system-centric protection to the broader preservation of behavioral integrity and intent, the framework complements existing AI security strategies and offers a principled foundation for building agentic AI systems that are trustworthy, governable, and aligned with human values.</li>
</ul>

<h3>Title: Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity</h3>
<ul>
<li><strong>Authors: </strong>Leonardo Stoppani, Davide Bacciu, Shahab Mokarizadeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01949">https://arxiv.org/abs/2602.01949</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01949">https://arxiv.org/pdf/2602.01949</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01949]] Boundary-Constrained Diffusion Models for Floorplan Generation: Balancing Realism and Diversity(https://arxiv.org/abs/2602.01949)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have become widely popular for automated floorplan generation, producing highly realistic layouts conditioned on user-defined constraints. However, optimizing for perceptual metrics such as the Fréchet Inception Distance (FID) causes limited design diversity. To address this, we propose the Diversity Score (DS), a metric that quantifies layout diversity under fixed constraints. Moreover, to improve geometric consistency, we introduce a Boundary Cross-Attention (BCA) module that enables conditioning on building boundaries. Our experiments show that BCA significantly improves boundary adherence, while prolonged training drives diversity collapse undiagnosed by FID, revealing a critical trade-off between realism and diversity. Out-Of-Distribution evaluations further demonstrate the models' reliance on dataset priors, emphasizing the need for generative systems that explicitly balance fidelity, diversity, and generalization in architectural design tasks.</li>
</ul>

<h3>Title: Deep Multivariate Models with Parametric Conditionals</h3>
<ul>
<li><strong>Authors: </strong>Dmitrij Schlesinger, Boris Flach, Alexander Shekhovtsov</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01953">https://arxiv.org/abs/2602.01953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01953">https://arxiv.org/pdf/2602.01953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01953]] Deep Multivariate Models with Parametric Conditionals(https://arxiv.org/abs/2602.01953)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We consider deep multivariate models for heterogeneous collections of random variables. In the context of computer vision, such collections may e.g. consist of images, segmentations, image attributes, and latent variables. When developing such models, most existing works start from an application task and design the model components and their dependencies to meet the needs of the chosen task. This has the disadvantage of limiting the applicability of the resulting model for other downstream tasks. Here, instead, we propose to represent the joint probability distribution by means of conditional probability distributions for each group of variables conditioned on the rest. Such models can then be used for practically any possible downstream task. Their learning can be approached as training a parametrised Markov chain kernel by maximising the data likelihood of its limiting distribution. This has the additional advantage of allowing a wide range of semi-supervised learning scenarios.</li>
</ul>

<h3>Title: Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Seonghyeon Park, Jewon Yeom, Jaewon Sok, Jeongjae Park, Heejun Kim, Taesup Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01956">https://arxiv.org/abs/2602.01956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01956">https://arxiv.org/pdf/2602.01956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01956]] Efficient Epistemic Uncertainty Estimation for Large Language Models via Knowledge Distillation(https://arxiv.org/abs/2602.01956)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantifying uncertainty in Large Language Models (LLMs) is essential for mitigating hallucinations and enabling risk-aware deployment in safety-critical tasks. However, estimating Epistemic Uncertainty(EU) via Deep Ensembles is computationally prohibitive at the scale of modern models. We propose a framework that leverages the small draft models to efficiently estimate token-level EU, bypassing the need for full-scale ensembling. Theoretically grounded in a Bias-Variance Decomposition, our approach approximates EU via Jensen-Shannon divergence among drafts (variance proxy) and KL divergence between the draft mixture and the target (bias proxy). To further ensure accuracy without significant overhead, we introduce Online Stochastic Distillation (OSD) to efficiently approximate target aggregation and the Data-Diverse Drafts (DDD) strategy to enhance draft diversity for better target approximation. Extensive experiments on GSM8K demonstrate that our method reduces the estimation error (RMSE) by up to 37% compared to baselines. Crucially, our approach achieves Hallucination Detection performance competitive with heavy perturbation-based methods like TokUR while incurring negligible inference costs, offering a practical solution for uncertainty-aware LLM deployment.</li>
</ul>

<h3>Title: Grounding Generated Videos in Feasible Plans via World Models</h3>
<ul>
<li><strong>Authors: </strong>Christos Ziakas, Amir Bar, Alessandra Russo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01960">https://arxiv.org/abs/2602.01960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01960">https://arxiv.org/pdf/2602.01960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01960]] Grounding Generated Videos in Feasible Plans via World Models(https://arxiv.org/abs/2602.01960)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large-scale video generative models have shown emerging capabilities as zero-shot visual planners, yet video-generated plans often violate temporal consistency and physical constraints, leading to failures when mapped to executable actions. To address this, we propose Grounding Video Plans with World Models (GVP-WM), a planning method that grounds video-generated plans into feasible action sequences using a learned action-conditioned world model. At test-time, GVP-WM first generates a video plan from initial and goal observations, then projects the video guidance onto the manifold of dynamically feasible latent trajectories via video-guided latent collocation. In particular, we formulate grounding as a goal-conditioned latent-space trajectory optimization problem that jointly optimizes latent states and actions under world-model dynamics, while preserving semantic alignment with the video-generated plan. Empirically, GVP-WM recovers feasible long-horizon plans from zero-shot image-to-video-generated and motion-blurred videos that violate physical constraints, across navigation and manipulation simulation tasks.</li>
</ul>

<h3>Title: Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Kwun Hang Lau, Fangyuan Zhang, Boyu Ruan, Yingli Zhou, Qintian Guo, Ruiyuan Zhang, Xiaofang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01965">https://arxiv.org/abs/2602.01965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01965">https://arxiv.org/pdf/2602.01965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01965]] Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation(https://arxiv.org/abs/2602.01965)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a "Static Graph Fallacy": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree "hub" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at this https URL.</li>
</ul>

<h3>Title: Self-Consolidation for Self-Evolving Agents</h3>
<ul>
<li><strong>Authors: </strong>Hongzhuo Yu, Fei Zhu, Guo-Sen Xie, Ling Shao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01966">https://arxiv.org/abs/2602.01966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01966">https://arxiv.org/pdf/2602.01966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01966]] Self-Consolidation for Self-Evolving Agents(https://arxiv.org/abs/2602.01966)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language model (LLM) agents have demonstrated impressive problem-solving capabilities, they typically operate as static systems, lacking the ability to evolve through lifelong interaction. Existing attempts to bridge this gap primarily rely on retrieving successful past trajectories as demonstrations. However, this paradigm faces two critical limitations. First, by focusing solely on success, agents overlook the rich pedagogical value embedded in failed attempts, preventing them from identifying and avoiding recurrent pitfalls. Second, continually accumulating textual experiences not only increases the time consumption during retrieval but also inevitably introduces noise and exhausts the largest context window of current LLMs. To address these challenges, we propose a novel self-evolving framework for LLM agents that introduces a complementary evolution mechanism: First, a contrastive reflection strategy is introduced to explicitly summarize error-prone patterns and capture reusable insights. Second, we propose a self-consolidation mechanism that distills non-parametric textual experience into compact learnable parameters. This enables the agent to internalize extensive historical experience directly into its latent space. Extensive experiments demonstrate the advantages of our method in long-term agent evolution.</li>
</ul>

<h3>Title: Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Wonjun Lee, Hyounghun Kim, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01967">https://arxiv.org/abs/2602.01967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01967">https://arxiv.org/pdf/2602.01967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01967]] Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition(https://arxiv.org/abs/2602.01967)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.</li>
</ul>

<h3>Title: Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bin Cao, Huixian Lu, Chenwen Ma, Ting Wang, Ruizhe Li, Jing Fan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01969">https://arxiv.org/abs/2602.01969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01969">https://arxiv.org/pdf/2602.01969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01969]] Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models(https://arxiv.org/abs/2602.01969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.</li>
</ul>

<h3>Title: Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated</h3>
<ul>
<li><strong>Authors: </strong>Muli Yang, Gabriel James Goenawan, Henan Wang, Huaiyuan Qin, Chenghao Xu, Yanhua Yang, Fen Fang, Ying Sun, Joo-Hwee Lim, Hongyuan Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01973">https://arxiv.org/abs/2602.01973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01973">https://arxiv.org/pdf/2602.01973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01973]] Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated(https://arxiv.org/abs/2602.01973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at this https URL.</li>
</ul>

<h3>Title: IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Meng Li, Peisong Wang, Yuantian Shao, Qinghao Hu, Hongjian Fang, Yifan Zhang, Zhihui Wei, Jian Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01975">https://arxiv.org/abs/2602.01975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01975">https://arxiv.org/pdf/2602.01975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01975]] IntraSlice: Towards High-Performance Structural Pruning with Block-Intra PCA for LLMs(https://arxiv.org/abs/2602.01975)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) achieve strong performance across diverse tasks but face deployment challenges due to their massive size. Structured pruning offers acceleration benefits but leads to significant performance degradation. Recent PCA-based pruning methods have alleviated this issue by retaining key activation components, but are only applied between modules in order to fuse the transformation matrix, which introduces extra parameters and severely disrupts activation distributions due to residual connections. To address these issues, we propose IntraSlice, a framework that applies block-wise module-intra PCA compression pruning. By leveraging the structural characteristics of Transformer modules, we design an approximate PCA method whose transformation matrices can be fully fused into the model without additional parameters. We also introduce a PCA-based global pruning ratio estimator that further considers the distribution of compressed activations, building on conventional module importance. We validate our method on Llama2, Llama3, and Phi series across various language benchmarks. Experimental results demonstrate that our approach achieves superior compression performance compared to recent baselines at the same compression ratio or inference speed.</li>
</ul>

<h3>Title: Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing</h3>
<ul>
<li><strong>Authors: </strong>Shuainan Liu, Xuanang Chen, Ben He, Le Sun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01977">https://arxiv.org/abs/2602.01977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01977">https://arxiv.org/pdf/2602.01977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01977]] Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing(https://arxiv.org/abs/2602.01977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.</li>
</ul>

<h3>Title: S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yanrui Du, Sendong Zhao, Yibo Gao, Danyang Zhao, Qika Lin, Ming Ma, Jiayun Li, Yi Jiang, Kai He, Qianyi Xu, Bing Qin, Mengling Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01982">https://arxiv.org/abs/2602.01982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01982">https://arxiv.org/pdf/2602.01982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01982]] S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs(https://arxiv.org/abs/2602.01982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at this https URL.</li>
</ul>

<h3>Title: SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhen-Hao Xie, Jun-Tao Tang, Yu-Cheng Shi, Han-Jia Ye, De-Chuan Zhan, Da-Wei Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01990">https://arxiv.org/abs/2602.01990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01990">https://arxiv.org/pdf/2602.01990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01990]] SAME: Stabilized Mixture-of-Experts for Multimodal Continual Instruction Tuning(https://arxiv.org/abs/2602.01990)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) achieve strong performance through instruction tuning, but real-world deployment requires them to continually expand their capabilities, making Multimodal Continual Instruction Tuning (MCIT) essential. Recent methods leverage sparse expert routing to promote task specialization, but we find that the expert routing process suffers from drift as the data distribution evolves. For example, a grounding query that previously activated localization experts may instead be routed to irrelevant experts after learning OCR tasks. Meanwhile, the grounding-related experts can be overwritten by new tasks and lose their original functionality. Such failure reflects two problems: router drift, where expert selection becomes inconsistent over time, and expert drift, where shared experts are overwritten across tasks. Therefore, we propose StAbilized Mixture-of-Experts (SAME) for MCIT. To address router drift, SAME stabilizes expert selection by decomposing routing dynamics into orthogonal subspaces and updating only task-relevant directions. To mitigate expert drift, we regulate expert updates via curvature-aware scaling using historical input covariance in a rehearsal-free manner. SAME also introduces adaptive expert activation to freeze selected experts during training, reducing redundant computation and cross-task interference. Extensive experiments demonstrate its SOTA performance.</li>
</ul>

<h3>Title: Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Pablo Domingo-Gregorio, Javier Ruiz-Hidalgo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01991">https://arxiv.org/abs/2602.01991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01991">https://arxiv.org/pdf/2602.01991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01991]] Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models(https://arxiv.org/abs/2602.01991)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.</li>
</ul>

<h3>Title: On the Limits of Layer Pruning for Generative Reasoning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Safal Shrestha, Anubhav Shrestha, Aadim Nepal, Minwu Kim, Keith Ross</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.01997">https://arxiv.org/abs/2602.01997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.01997">https://arxiv.org/pdf/2602.01997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.01997]] On the Limits of Layer Pruning for Generative Reasoning in LLMs(https://arxiv.org/abs/2602.01997)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent works have shown that layer pruning can compress large language models (LLMs) while retaining strong performance on classification benchmarks with little or no finetuning. However, existing pruning techniques often suffer severe degradation on generative reasoning tasks. Through a systematic study across multiple model families, we find that tasks requiring multi-step reasoning are particularly sensitive to depth reduction. Beyond surface-level text degeneration, we observe degradation of critical algorithmic capabilities, including arithmetic computation for mathematical reasoning and balanced parenthesis generation for code synthesis. Under realistic post-training constraints, without access to pretraining-scale data or compute, we evaluate a simple mitigation strategy based on supervised finetuning with Self-Generated Responses. This approach achieves strong recovery on classification tasks, retaining up to 90\% of baseline performance, and yields substantial gains of up to 20--30 percentage points on generative benchmarks compared to prior post-pruning techniques. Crucially, despite these gains, recovery for generative reasoning remains fundamentally limited relative to classification tasks and is viable primarily at lower pruning ratios. Overall, we characterize the practical limits of layer pruning for generative reasoning and provide guidance on when depth reduction can be applied effectively under constrained post-training regimes.</li>
</ul>

<h3>Title: SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors</h3>
<ul>
<li><strong>Authors: </strong>Bing He, Jingnan Gao, Yunuo Chen, Ning Cao, Gang Chen, Zhengxue Cheng, Li Song, Wenjun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02000">https://arxiv.org/abs/2602.02000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02000">https://arxiv.org/pdf/2602.02000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02000]] SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors(https://arxiv.org/abs/2602.02000)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: this https URL</li>
</ul>

<h3>Title: UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Guosheng Zhao, Yaozeng Wang, Xiaofeng Wang, Zheng Zhu, Tingdong Yu, Guan Huang, Yongchen Zai, Ji Jiao, Changliang Xue, Xiaole Wang, Zhen Yang, Futang Zhu, Xingang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02002">https://arxiv.org/abs/2602.02002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02002">https://arxiv.org/pdf/2602.02002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02002]] UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving(https://arxiv.org/abs/2602.02002)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream</li>
</ul>

<h3>Title: Logic-Guided Vector Fields for Constrained Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Ali Baheri</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02009">https://arxiv.org/abs/2602.02009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02009">https://arxiv.org/pdf/2602.02009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02009]] Logic-Guided Vector Fields for Constrained Generative Modeling(https://arxiv.org/abs/2602.02009)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Neuro-symbolic systems aim to combine the expressive structure of symbolic logic with the flexibility of neural learning; yet, generative models typically lack mechanisms to enforce declarative constraints at generation time. We propose Logic-Guided Vector Fields (LGVF), a neuro-symbolic framework that injects symbolic knowledge, specified as differentiable relaxations of logical constraints, into flow matching generative models. LGVF couples two complementary mechanisms: (1) a training-time logic loss that penalizes constraint violations along continuous flow trajectories, with weights that emphasize correctness near the target distribution; and (2) an inference-time adjustment that steers sampling using constraint gradients, acting as a lightweight, logic-informed correction to the learned dynamics. We evaluate LGVF on three constrained generation case studies spanning linear, nonlinear, and multi-region feasibility constraints. Across all settings, LGVF reduces constraint violations by 59-82% compared to standard flow matching and achieves the lowest violation rates in each case. In the linear and ring settings, LGVF also improves distributional fidelity as measured by MMD, while in the multi-obstacle setting, we observe a satisfaction-fidelity trade-off, with improved feasibility but increased MMD. Beyond quantitative gains, LGVF yields constraint-aware vector fields exhibiting emergent obstacle-avoidance behavior, routing samples around forbidden regions without explicit path planning.</li>
</ul>

<h3>Title: SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyi Jiang, Andreas Nienkötter</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02013">https://arxiv.org/abs/2602.02013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02013">https://arxiv.org/pdf/2602.02013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02013]] SNAP: A Self-Consistent Agreement Principle with Application to Robust Computation(https://arxiv.org/abs/2602.02013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce SNAP (Self-coNsistent Agreement Principle), a self-supervised framework for robust computation based on mutual agreement. Based on an Agreement-Reliability Hypothesis SNAP assigns weights that quantify agreement, emphasizing trustworthy items and downweighting outliers without supervision or prior knowledge. A key result is the Exponential Suppression of Outlier Weights, ensuring that outliers contribute negligibly to computations, even in high-dimensional settings. We study properties of SNAP weighting scheme and show its practical benefits on vector averaging and subspace estimation. Particularly, we demonstrate that non-iterative SNAP outperforms the iterative Weiszfeld algorithm and two variants of multivariate median of means. SNAP thus provides a flexible, easy-to-use, broadly applicable approach to robust computation.</li>
</ul>

<h3>Title: Rethinking Genomic Modeling Through Optical Character Recognition</h3>
<ul>
<li><strong>Authors: </strong>Hongxin Xiang, Pengsen Ma, Yunkang Cao, Di Yu, Haowen Chen, Xinyu Yang, Xiangxiang Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02014">https://arxiv.org/abs/2602.02014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02014">https://arxiv.org/pdf/2602.02014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02014]] Rethinking Genomic Modeling Through Optical Character Recognition(https://arxiv.org/abs/2602.02014)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \emph{visual DNA encoder} and a \emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\times$ fewer effective tokens, and surpasses models with up to $985\times$ more activated parameters while tuning only 256k \emph{trainable} parameters.</li>
</ul>

<h3>Title: Robust Domain Generalization under Divergent Marginal and Conditional Distributions</h3>
<ul>
<li><strong>Authors: </strong>Jewon Yeom, Kyubyung Chae, Hyunggyu Lim, Yoonna Oh, Dongyoon Yang, Taesup Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02015">https://arxiv.org/abs/2602.02015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02015">https://arxiv.org/pdf/2602.02015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02015]] Robust Domain Generalization under Divergent Marginal and Conditional Distributions(https://arxiv.org/abs/2602.02015)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Domain generalization (DG) aims to learn predictive models that can generalize to unseen domains. Most existing DG approaches focus on learning domain-invariant representations under the assumption of conditional distribution shift (i.e., primarily addressing changes in $P(X\mid Y)$ while assuming $P(Y)$ remains stable). However, real-world scenarios with multiple domains often involve compound distribution shifts where both the marginal label distribution $P(Y)$ and the conditional distribution $P(X\mid Y)$ vary simultaneously. To address this, we propose a unified framework for robust domain generalization under divergent marginal and conditional distributions. We derive a novel risk bound for unseen domains by explicitly decomposing the joint distribution into marginal and conditional components and characterizing risk gaps arising from both sources of divergence. To operationalize this bound, we design a meta-learning procedure that minimizes and validates the proposed risk bound across seen domains, ensuring strong generalization to unseen ones. Empirical evaluations demonstrate that our method achieves state-of-the-art performance not only on conventional DG benchmarks but also in challenging multi-domain long-tailed recognition settings where both marginal and conditional shifts are pronounced.</li>
</ul>

<h3>Title: One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Shuo Lu, Haohan Wang, Wei Feng, Weizhen Wang, Shen Zhang, Yaoyu Li, Ao Ma, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law, Bing Zhan, Yuan Xu, Huizai Yao, Yongcan Yu, Chenyang Si, Jian Liang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02033">https://arxiv.org/abs/2602.02033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02033">https://arxiv.org/pdf/2602.02033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02033]] One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation(https://arxiv.org/abs/2602.02033)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at this https URL.</li>
</ul>

<h3>Title: Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Cristian Sbrolli, Matteo Matteucci, Toshihiko Yamasaki</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02043">https://arxiv.org/abs/2602.02043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02043">https://arxiv.org/pdf/2602.02043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02043]] Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models(https://arxiv.org/abs/2602.02043)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing "a red cube and a blue sphere" with "a blue cube and a red sphere". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., "a monitor to the left of a bicycle on a white background") and LLM-generated Contextual captions (e.g., "In a brightly lit photography studio, a monitor is positioned to the left of a bicycle"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel "Confusion Benchmark" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (this https URL).</li>
</ul>

<h3>Title: On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems</h3>
<ul>
<li><strong>Authors: </strong>Yiming Yang, Xiaoyuan Cheng, Yi He, Kaiyu Li, Wenxuan Yuan, Zhuo Sun</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02045">https://arxiv.org/abs/2602.02045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02045">https://arxiv.org/pdf/2602.02045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02045]] On Stability and Robustness of Diffusion Posterior Sampling for Bayesian Inverse Problems(https://arxiv.org/abs/2602.02045)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently emerged as powerful learned priors for Bayesian inverse problems (BIPs). Diffusion-based solvers rely on a presumed likelihood for the observations in BIPs to guide the generation process. However, the link between likelihood and recovery quality for BIPs is unclear in previous works. We bridge this gap by characterizing the posterior approximation error and proving the \emph{stability} of the diffusion-based solvers. Meanwhile, an immediate result of our findings on stability demonstrates the lack of robustness in diffusion-based solvers, which remains unexplored. This can degrade performance when the presumed likelihood mismatches the unknown true data generation processes. To address this issue, we propose a simple yet effective solution, \emph{robust diffusion posterior sampling}, which is provably \emph{robust} and compatible with existing gradient-based posterior samplers. Empirical results on scientific inverse problems and natural image tasks validate the effectiveness and robustness of our method, showing consistent performance improvements under challenging likelihood misspecifications.</li>
</ul>

<h3>Title: Dissecting Outlier Dynamics in LLM NVFP4 Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Peijie Dong, Ruibo Fan, Yuechen Tao, Di Mou, Wenhu Hu, Zhenheng Tang, Yinghao Yu, Jiamang Wang, Wenbo Su, Guodong Yang, Liping Zhang, Xiaowen Chu, Baochun Li, Bo Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02047">https://arxiv.org/abs/2602.02047</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02047">https://arxiv.org/pdf/2602.02047</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02047]] Dissecting Outlier Dynamics in LLM NVFP4 Pretraining(https://arxiv.org/abs/2602.02047)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, large language model</a></li>
<li><strong>Abstract: </strong>Training large language models using 4-bit arithmetic enhances throughput and memory efficiency. Yet, the limited dynamic range of FP4 increases sensitivity to outliers. While NVFP4 mitigates quantization error via hierarchical microscaling, a persistent loss gap remains compared to BF16. This study conducts a longitudinal analysis of outlier dynamics across architecture during NVFP4 pretraining, focusing on where they localize, why they occur, and how they evolve temporally. We find that, compared with Softmax Attention (SA), Linear Attention (LA) reduces per-tensor heavy tails but still exhibits persistent block-level spikes under block quantization. Our analysis attributes outliers to specific architectural components: Softmax in SA, gating in LA, and SwiGLU in FFN, with "post-QK" operations exhibiting higher sensitivity to quantization. Notably, outliers evolve from transient spikes early in training to a small set of persistent hot channels (i.e., channels with persistently large magnitudes) in later stages. Based on these findings, we introduce Hot-Channel Patch (HCP), an online compensation mechanism that identifies hot channels and reinjects residuals using hardware-efficient kernels. We then develop CHON, an NVFP4 training recipe integrating HCP with post-QK operation protection. On GLA-1.3B model trained for 60B tokens, CHON reduces the loss gap to BF16 from 0.94% to 0.58% while maintaining downstream accuracy.</li>
</ul>

<h3>Title: FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification</h3>
<ul>
<li><strong>Authors: </strong>Nan Qiao, Sheng Yue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02055">https://arxiv.org/abs/2602.02055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02055">https://arxiv.org/pdf/2602.02055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02055]] FORLER: Federated Offline Reinforcement Learning with Q-Ensemble and Actor Rectification(https://arxiv.org/abs/2602.02055)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>In Internet-of-Things systems, federated learning has advanced online reinforcement learning (RL) by enabling parallel policy training without sharing raw data. However, interacting with real environments online can be risky and costly, motivating offline federated RL (FRL), where local devices learn from fixed datasets. Despite its promise, offline FRL may break down under low-quality, heterogeneous data. Offline RL tends to get stuck in local optima, and in FRL, one device's suboptimal policy can degrade the aggregated model, i.e., policy pollution. We present FORLER, combining Q-ensemble aggregation on the server with actor rectification on devices. The server robustly merges device Q-functions to curb policy pollution and shift heavy computation off resource-constrained hardware without compromising privacy. Locally, actor rectification enriches policy gradients via a zeroth-order search for high-Q actions plus a bespoke regularizer that nudges the policy toward them. A $\delta$-periodic strategy further reduces local computation. We theoretically provide safe policy improvement performance guarantees. Extensive experiments show FORLER consistently outperforms strong baselines under varying data quality and heterogeneity.</li>
</ul>

<h3>Title: FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance</h3>
<ul>
<li><strong>Authors: </strong>Hyunsuk Chung, Caren Han, Yerin Choi, Seungyeon Ji, Jinwoo Kim, Eun-Jung Holden, Kyungreem Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02060">https://arxiv.org/abs/2602.02060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02060">https://arxiv.org/pdf/2602.02060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02060]] FiLoRA: Focus-and-Ignore LoRA for Controllable Feature Reliance(https://arxiv.org/abs/2602.02060)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal foundation models integrate heterogeneous signals across modalities, yet it remains poorly understood how their predictions depend on specific internal feature groups and whether such reliance can be deliberately controlled. Existing studies of shortcut and spurious behavior largely rely on post hoc analyses or feature removal, offering limited insight into whether reliance can be modulated without altering task semantics. We introduce FiLoRA (Focus-and-Ignore LoRA), an instruction-conditioned, parameter-efficient adaptation framework that enables explicit control over internal feature reliance while keeping the predictive objective fixed. FiLoRA decomposes adaptation into feature group-aligned LoRA modules and applies instruction-conditioned gating, allowing natural language instructions to act as computation-level control signals rather than task redefinitions. Across text--image and audio--visual benchmarks, we show that instruction-conditioned gating induces consistent and causal shifts in internal computation, selectively amplifying or suppressing core and spurious feature groups without modifying the label space or training objective. Further analyses demonstrate that FiLoRA yields improved robustness under spurious feature interventions, revealing a principled mechanism to regulate reliance beyond correlation-driven learning.</li>
</ul>

<h3>Title: Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data</h3>
<ul>
<li><strong>Authors: </strong>Nikola Cenikj, Özgün Turgut, Alexander Müller, Alexander Steger, Jan Kehrer, Marcus Brugger, Daniel Rueckert, Eimo Martens, Philip Müller</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02067">https://arxiv.org/abs/2602.02067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02067">https://arxiv.org/pdf/2602.02067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02067]] Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data(https://arxiv.org/abs/2602.02067)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at this https URL.</li>
</ul>

<h3>Title: BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling</h3>
<ul>
<li><strong>Authors: </strong>Zisheng Ye, Xiaoyu He, Maoyuan Song, Guoliang Qiu, Chao Liao, Chen Wu, Yonggang Sun, Zhichun Li, Xiaoru Xie, Yuanyong Luo, Hu Liu, Pinyan Lu, Heng Liao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02071">https://arxiv.org/abs/2602.02071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02071">https://arxiv.org/pdf/2602.02071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02071]] BAPS: A Fine-Grained Low-Precision Scheme for Softmax in Attention via Block-Aware Precision reScaling(https://arxiv.org/abs/2602.02071)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>As the performance gains from accelerating quantized matrix multiplication plateau, the softmax operation becomes the critical bottleneck in Transformer inference. This bottleneck stems from two hardware limitations: (1) limited data bandwidth between matrix and vector compute cores, and (2) the significant area cost of high-precision (FP32/16) exponentiation units (EXP2). To address these issues, we introduce a novel low-precision workflow that employs a specific 8-bit floating-point format (HiF8) and block-aware precision rescaling for softmax. Crucially, our algorithmic innovations make low-precision softmax feasible without the significant model accuracy loss that hampers direct low-precision approaches. Specifically, our design (i) halves the required data movement bandwidth by enabling matrix multiplication outputs constrained to 8-bit, and (ii) substantially reduces the EXP2 unit area by computing exponentiations in low (8-bit) precision. Extensive evaluation on language models and multi-modal models confirms the validity of our method. By alleviating the vector computation bottleneck, our work paves the way for doubling end-to-end inference throughput without increasing chip area, and offers a concrete co-design path for future low-precision hardware and software.</li>
</ul>

<h3>Title: AICD Bench: A Challenging Benchmark for AI-Generated Code Detection</h3>
<ul>
<li><strong>Authors: </strong>Daniil Orel, Dilshod Azizov, Indraneil Paul, Yuxia Wang, Iryna Gurevych, Preslav Nakov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02079">https://arxiv.org/abs/2602.02079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02079">https://arxiv.org/pdf/2602.02079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02079]] AICD Bench: A Challenging Benchmark for AI-Generated Code Detection(https://arxiv.org/abs/2602.02079)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly capable of generating functional source code, raising concerns about authorship, accountability, and security. While detecting AI-generated code is critical, existing datasets and benchmarks are narrow, typically limited to binary human-machine classification under in-distribution settings. To bridge this gap, we introduce $\emph{AICD Bench}$, the most comprehensive benchmark for AI-generated code detection. It spans $\emph{2M examples}$, $\emph{77 models}$ across $\emph{11 families}$, and $\emph{9 programming languages}$, including recent reasoning models. Beyond scale, AICD Bench introduces three realistic detection tasks: ($\emph{i}$)~$\emph{Robust Binary Classification}$ under distribution shifts in language and domain, ($\emph{ii}$)~$\emph{Model Family Attribution}$, grouping generators by architectural lineage, and ($\emph{iii}$)~$\emph{Fine-Grained Human-Machine Classification}$ across human, machine, hybrid, and adversarial code. Extensive evaluation on neural and classical detectors shows that performance remains far below practical usability, particularly under distribution shift and for hybrid or adversarial code. We release AICD Bench as a $\emph{unified, challenging evaluation suite}$ to drive the next generation of robust approaches for AI-generated code detection. The data and the code are available at this https URL}.</li>
</ul>

<h3>Title: Closing the Loop: Universal Repository Representation with RPG-Encoder</h3>
<ul>
<li><strong>Authors: </strong>Jane Luo, Chengyu Yin, Xin Zhang, Qingtao Li, Steven Liu, Yiming Huang, Jie Wu, Hao Liu, Yangyu Huang, Yu Kang, Fangkai Yang, Ying Xin, Scarlett Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02084">https://arxiv.org/abs/2602.02084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02084">https://arxiv.org/pdf/2602.02084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02084]] Closing the Loop: Universal Repository Representation with RPG-Encoder(https://arxiv.org/abs/2602.02084)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.</li>
</ul>

<h3>Title: Efficient Swap Regret Minimization in Combinatorial Bandits</h3>
<ul>
<li><strong>Authors: </strong>Andreas Kontogiannis, Vasilis Pollatos, Panayotis Mertikopoulos, Ioannis Panageas</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02087">https://arxiv.org/abs/2602.02087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02087">https://arxiv.org/pdf/2602.02087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02087]] Efficient Swap Regret Minimization in Combinatorial Bandits(https://arxiv.org/abs/2602.02087)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This paper addresses the problem of designing efficient no-swap regret algorithms for combinatorial bandits, where the number of actions $N$ is exponentially large in the dimensionality of the problem. In this setting, designing efficient no-swap regret translates to sublinear -- in horizon $T$ -- swap regret with polylogarithmic dependence on $N$. In contrast to the weaker notion of external regret minimization - a problem which is fairly well understood in the literature - achieving no-swap regret with a polylogarithmic dependence on $N$ has remained elusive in combinatorial bandits. Our paper resolves this challenge, by introducing a no-swap-regret learning algorithm with regret that scales polylogarithmically in $N$ and is tight for the class of combinatorial bandits. To ground our results, we also demonstrate how to implement the proposed algorithm efficiently -- that is, with a per-iteration complexity that also scales polylogarithmically in $N$ -- across a wide range of well-studied applications.</li>
</ul>

<h3>Title: LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs</h3>
<ul>
<li><strong>Authors: </strong>Yikai Zeng, Yingchao Piao, Jianhui Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02090">https://arxiv.org/abs/2602.02090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02090">https://arxiv.org/pdf/2602.02090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02090]] LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs(https://arxiv.org/abs/2602.02090)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.</li>
</ul>

<h3>Title: FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space</h3>
<ul>
<li><strong>Authors: </strong>FSVideo Team, Qingyu Chen, Zhiyuan Fang, Haibin Huang, Xinwei Huang, Tong Jin, Minxuan Lin, Bo Liu, Celong Liu, Chongyang Ma, Xing Mei, Xiaohui Shen, Yaojie Shen, Fuwen Tan, Angtian Wang, Xiao Yang, Yiding Yang, Jiamin Yuan, Lingxi Zhang, Yuxin Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02092">https://arxiv.org/abs/2602.02092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02092">https://arxiv.org/pdf/2602.02092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02092]] FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space(https://arxiv.org/abs/2602.02092)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\times64\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.</li>
</ul>

<h3>Title: No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Liyan Xu, Mo Yu, Fandong Meng, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02103">https://arxiv.org/abs/2602.02103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02103">https://arxiv.org/pdf/2602.02103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02103]] No Global Plan in Chain-of-Thought: Uncover the Latent Planning Horizon of LLMs(https://arxiv.org/abs/2602.02103)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This work stems from prior complementary observations on the dynamics of Chain-of-Thought (CoT): Large Language Models (LLMs) is shown latent planning of subsequent reasoning prior to CoT emergence, thereby diminishing the significance of explicit CoT; whereas CoT remains critical for tasks requiring multi-step reasoning. To deepen the understanding between LLM's internal states and its verbalized reasoning trajectories, we investigate the latent planning strength of LLMs, through our probing method, Tele-Lens, applying to hidden states across diverse task domains. Our empirical results indicate that LLMs exhibit a myopic horizon, primarily conducting incremental transitions without precise global planning. Leveraging this characteristic, we propose a hypothesis on enhancing uncertainty estimation of CoT, which we validate that a small subset of CoT positions can effectively represent the uncertainty of the entire path. We further underscore the significance of exploiting CoT dynamics, and demonstrate that automatic recognition of CoT bypass can be achieved without performance degradation. Our code, data and models are released at this https URL.</li>
</ul>

<h3>Title: Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shaltiel Shmidman, Avi Shmidman, Amir DN Cohen, Moshe Koppel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02104">https://arxiv.org/abs/2602.02104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02104">https://arxiv.org/pdf/2602.02104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02104]] Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs(https://arxiv.org/abs/2602.02104)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.</li>
</ul>

<h3>Title: Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yu Wang, Chuanguang Yang, Zhulin An, Weilun Feng, Jiarui Zhao, Chengqing Yu, Libo Huang, Boyu Diao, Yongjun Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02107">https://arxiv.org/abs/2602.02107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02107">https://arxiv.org/pdf/2602.02107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02107]] Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model(https://arxiv.org/abs/2602.02107)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.</li>
</ul>

<h3>Title: Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Li, Daohai Yu, Gen Luo, Yuxin Zhang, Fei Chao, Rongrong Ji, Yifan Wu, Jiaxin Liu, Ziyang Gong, Zimu Liao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02108">https://arxiv.org/abs/2602.02108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02108">https://arxiv.org/pdf/2602.02108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02108]] Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts(https://arxiv.org/abs/2602.02108)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at this https URL.</li>
</ul>

<h3>Title: Unifying Masked Diffusion Models with Various Generation Orders and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Chunsan Hong, Sanghyun Lee, Jong Chul Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02112">https://arxiv.org/abs/2602.02112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02112">https://arxiv.org/pdf/2602.02112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02112]] Unifying Masked Diffusion Models with Various Generation Orders and Beyond(https://arxiv.org/abs/2602.02112)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Masked diffusion models (MDMs) are a potential alternative to autoregressive models (ARMs) for language generation, but generation quality depends critically on the generation order. Prior work either hard-codes an ordering (e.g., blockwise left-to-right) or learns an ordering policy for a pretrained MDM, which incurs extra cost and can yield suboptimal solutions due to the two-stage optimization. Motivated by this, we propose order-expressive masked diffusion model (OeMDM) for a broad class of diffusion generative processes with various generation orders, enabling the interpretation of MDM, ARM, and block diffusion in a single framework. Furthermore, building on OeMDM, we introduce learnable-order masked diffusion model (LoMDM), which jointly learns the generation ordering and diffusion backbone through a single objective from scratch, enabling the diffusion model to generate text in context-dependent ordering. Empirically, we confirm that LoMDM outperforms various discrete diffusion models across multiple language modeling benchmarks.</li>
</ul>

<h3>Title: Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training</h3>
<ul>
<li><strong>Authors: </strong>Xin Ding, Yun Chen, Sen Zhang, Kao Zhang, Nenglun Chen, Peibei Cao, Yongwei Wang, Fei Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02114">https://arxiv.org/abs/2602.02114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02114">https://arxiv.org/pdf/2602.02114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02114]] Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training(https://arxiv.org/abs/2602.02114)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\times64$ to $256\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.</li>
</ul>

<h3>Title: The Maximum von Neumann Entropy Principle: Theory and Applications in Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Youqi Wu, Farzan Farnia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02117">https://arxiv.org/abs/2602.02117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02117">https://arxiv.org/pdf/2602.02117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02117]] The Maximum von Neumann Entropy Principle: Theory and Applications in Machine Learning(https://arxiv.org/abs/2602.02117)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Von Neumann entropy (VNE) is a fundamental quantity in quantum information theory and has recently been adopted in machine learning as a spectral measure of diversity for kernel matrices and kernel covariance operators. While maximizing VNE under constraints is well known in quantum settings, a principled analogue of the classical maximum entropy framework, particularly its decision theoretic and game theoretic interpretation, has not been explicitly developed for VNE in data driven contexts. In this paper, we extend the minimax formulation of the maximum entropy principle due to Grünwald and Dawid to the setting of von Neumann entropy, providing a game-theoretic justification for VNE maximization over density matrices and trace-normalized positive semidefinite operators. This perspective yields a robust interpretation of maximum VNE solutions under partial information and clarifies their role as least committed inferences in spectral domains. We then illustrate how the resulting Maximum VNE principle applies to modern machine learning problems by considering two representative applications, selecting a kernel representation from multiple normalized embeddings via kernel-based VNE maximization, and completing kernel matrices from partially observed entries. These examples demonstrate how the proposed framework offers a unifying information-theoretic foundation for VNE-based methods in kernel learning.</li>
</ul>

<h3>Title: Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies</h3>
<ul>
<li><strong>Authors: </strong>Olga Graf, Dhrupal Patel, Peter Groß, Charlotte Lempp, Matthias Hein, Fabian Heinemann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02124">https://arxiv.org/abs/2602.02124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02124">https://arxiv.org/pdf/2602.02124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02124]] Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies(https://arxiv.org/abs/2602.02124)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\% of pathological tissue classified as healthy and 0.35\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.</li>
</ul>

<h3>Title: Two-Stage Grid Optimization for Group-wise Quantization of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Junhan Kim, Gukryeol Lee, Seungwoo Son, Jeewook Kim, Yongkweon Jeon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02126">https://arxiv.org/abs/2602.02126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02126">https://arxiv.org/pdf/2602.02126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02126]] Two-Stage Grid Optimization for Group-wise Quantization of LLMs(https://arxiv.org/abs/2602.02126)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Group-wise quantization is an effective strategy for mitigating accuracy degradation in low-bit quantization of large language models (LLMs). Among existing methods, GPTQ has been widely adopted due to its efficiency; however, it neglects input statistics and inter-group correlations when determining group scales, leading to a mismatch with its goal of minimizing layer-wise reconstruction loss. In this work, we propose a two-stage optimization framework for group scales that explicitly minimizes the layer-wise reconstruction loss. In the first stage, performed prior to GPTQ, we initialize each group scale to minimize the group-wise reconstruction loss, thereby incorporating input statistics. In the second stage, we freeze the integer weights obtained via GPTQ and refine the group scales to minimize the layer-wise reconstruction loss. To this end, we employ the coordinate descent algorithm and derive a closed-form update rule, which enables efficient refinement without costly numerical optimization. Notably, our derivation incorporates the quantization errors from preceding layers to prevent error accumulation. Experimental results demonstrate that our method consistently enhances group-wise quantization, achieving higher accuracy with negligible overhead.</li>
</ul>

<h3>Title: Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Nima Shoghi, Yuxuan Liu, Yuning Shen, Rob Brekelmans, Pan Li, Quanquan Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.bio-ph, q-bio.BM, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02128">https://arxiv.org/abs/2602.02128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02128">https://arxiv.org/pdf/2602.02128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02128]] Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics(https://arxiv.org/abs/2602.02128)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.</li>
</ul>

<h3>Title: There Is More to Refusal in Large Language Models than a Single Direction</h3>
<ul>
<li><strong>Authors: </strong>Faaiz Joad, Majd Hawasly, Sabri Boughorbel, Nadir Durrani, Husrev Taha Sencar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02132">https://arxiv.org/abs/2602.02132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02132">https://arxiv.org/pdf/2602.02132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02132]] There Is More to Refusal in Large Language Models than a Single Direction(https://arxiv.org/abs/2602.02132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prior work argues that refusal in large language models is mediated by a single activation-space direction, enabling effective steering and ablation. We show that this account is incomplete. Across eleven categories of refusal and non-compliance, including safety, incomplete or unsupported requests, anthropomorphization, and over-refusal, we find that these refusal behaviors correspond to geometrically distinct directions in activation space. Yet despite this diversity, linear steering along any refusal-related direction produces nearly identical refusal to over-refusal trade-offs, acting as a shared one-dimensional control knob. The primary effect of different directions is not whether the model refuses, but how it refuses.</li>
</ul>

<h3>Title: DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations</h3>
<ul>
<li><strong>Authors: </strong>Minghao Li, Ruihang Wang, Rui Tan, Yonggang Wen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02137">https://arxiv.org/abs/2602.02137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02137">https://arxiv.org/pdf/2602.02137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02137]] DCoPilot: Generative AI-Empowered Policy Adaptation for Dynamic Data Center Operations(https://arxiv.org/abs/2602.02137)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Modern data centers (DCs) hosting artificial intelligence (AI)-dedicated devices operate at high power densities with rapidly varying workloads, making minute-level adaptation essential for safe and energy-efficient operation. However, manually designing piecewise deep reinforcement learning (DRL) agents cannot keep pace with frequent dynamics shifts and service-level agreement (SLA) changes of an evolving DC. This specification-to-policy lag causes a lack of timely, effective control policies, which may lead to service outages. To bridge the gap, we present DCoPilot, a hybrid framework for generative control policies in dynamic DC operation. DCoPilot synergizes two distinct generative paradigms, i.e., a large language model (LLM) that performs symbolic generation of structured reward forms, and a hypernetwork that conducts parametric generation of policy weights. DCoPilot operates through three coordinated phases: (i) simulation scale-up, which stress-tests reward candidates across diverse simulation-ready (SimReady) scenes; (ii) meta policy distillation, where a hypernetwork is trained to output policy weights conditioned on SLA and scene embeddings; and (iii) online adaptation, enabling zero-shot policy generation in response to updated specifications. Evaluated across five control task families spanning diverse DC components, DCoPilot achieves near-zero constraint violations and outperforms all baselines across specification variations. Ablation studies validate the effectiveness of LLM-based unified reward generation in enabling stable hypernetwork convergence.</li>
</ul>

<h3>Title: Learning Generative Selection for Best-of-N</h3>
<ul>
<li><strong>Authors: </strong>Shubham Toshniwal, Aleksander Ficek, Siddhartha Jain, Wei Du, Vahid Noroozi, Sadegh Mahdavi, Somshubra Majumdar, Igor Gitman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02143">https://arxiv.org/abs/2602.02143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02143">https://arxiv.org/pdf/2602.02143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02143]] Learning Generative Selection for Best-of-N(https://arxiv.org/abs/2602.02143)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Scaling test-time compute via parallel sampling can substantially improve LLM reasoning, but is often limited by Best-of-N selection quality. Generative selection methods, such as GenSelect, address this bottleneck, yet strong selection performance remains largely limited to large models. We show that small reasoning models can acquire strong GenSelect capabilities through targeted reinforcement learning. To this end, we synthesize selection tasks from large-scale math and code instruction datasets by filtering to instances with both correct and incorrect candidate solutions, and train 1.7B-parameter models with DAPO to reward correct selections. Across math (AIME24, AIME25, HMMT25) and code (LiveCodeBench) reasoning benchmarks, our models consistently outperform prompting and majority-voting baselines, often approaching or exceeding much larger models. Moreover, these gains generalize to selecting outputs from stronger models despite training only on outputs from weaker models. Overall, our results establish reinforcement learning as a scalable way to unlock strong generative selection in small models, enabling efficient test-time scaling.</li>
</ul>

<h3>Title: HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiayao Wang, Yang Song, Zhendong Zhao, Jiale Zhang, Qilin Wu, Wenliang Yuan, Junwu Zhu, Dongfang Zhao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02147">https://arxiv.org/abs/2602.02147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02147">https://arxiv.org/pdf/2602.02147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02147]] HPE: Hallucinated Positive Entanglement for Backdoor Attacks in Federated Self-Supervised Learning(https://arxiv.org/abs/2602.02147)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated self-supervised learning (FSSL) enables collaborative training of self-supervised representation models without sharing raw unlabeled data. While it serves as a crucial paradigm for privacy-preserving learning, its security remains vulnerable to backdoor attacks, where malicious clients manipulate local training to inject targeted backdoors. Existing FSSL attack methods, however, often suffer from low utilization of poisoned samples, limited transferability, and weak persistence. To address these limitations, we propose a new backdoor attack method for FSSL, namely Hallucinated Positive Entanglement (HPE). HPE first employs hallucination-based augmentation using synthetic positive samples to enhance the encoder's embedding of backdoor features. It then introduces feature entanglement to enforce tight binding between triggers and backdoor samples in the representation space. Finally, selective parameter poisoning and proximity-aware updates constrain the poisoned model within the vicinity of the global model, enhancing its stability and persistence. Experimental results on several FSSL scenarios and datasets show that HPE significantly outperforms existing backdoor attack methods in performance and exhibits strong robustness under various defense mechanisms.</li>
</ul>

<h3>Title: ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Chu Zhao, Enneng Yang, Yuting Liu, Jianzhe Zhao, Guibing Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02150">https://arxiv.org/abs/2602.02150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02150">https://arxiv.org/pdf/2602.02150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02150]] ECHO: Entropy-Confidence Hybrid Optimization for Test-Time Reinforcement Learning(https://arxiv.org/abs/2602.02150)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test-time reinforcement learning generates multiple candidate answers via repeated rollouts and performs online updates using pseudo-labels constructed by majority voting. To reduce overhead and improve exploration, prior work introduces tree structured rollouts, which share reasoning prefixes and branch at key nodes to improve sampling efficiency. However, this paradigm still faces two challenges: (1) high entropy branching can trigger rollout collapse, where the branching budget concentrates on a few trajectories with consecutive high-entropy segments, rapidly reducing the number of effective branches; (2) early pseudo-labels are noisy and biased, which can induce self-reinforcing overfitting, causing the policy to sharpen prematurely and suppress exploration. To address these issues, we propose Entropy Confidence Hybrid Group Relative Policy Optimization (ECHO). During rollout, ECHO jointly leverages local entropy and group level confidence to adaptively control branch width, and further introduces online confidence-based pruning to terminate persistently low confidence branches, avoiding high entropy traps and mitigating collapse. During policy updates, ECHO employs confidence adaptive clipping and an entropy confidence hybrid advantage shaping approach to enhance training robustness and mitigate early stage bias. Experiments demonstrate that ECHO achieves consistent gains on multiple mathematical and visual reasoning benchmarks, and generalizes more effectively under a limited rollout budget.</li>
</ul>

<h3>Title: Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization</h3>
<ul>
<li><strong>Authors: </strong>Yuli Zhou, Qingxuan Chen, Luca Benini, Guolei Sun, Yawei Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02151">https://arxiv.org/abs/2602.02151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02151">https://arxiv.org/pdf/2602.02151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02151]] Revisiting Adaptive Rounding with Vectorized Reparameterization for LLM Quantization(https://arxiv.org/abs/2602.02151)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Adaptive Rounding has emerged as an alternative to round-to-nearest (RTN) for post-training quantization by enabling cross-element error cancellation. Yet, dense and element-wise rounding matrices are prohibitively expensive for billion-parameter large language models (LLMs). We revisit adaptive rounding from an efficiency perspective and propose VQRound, a parameter-efficient optimization framework that reparameterizes the rounding matrix into a compact codebook. Unlike low-rank alternatives, VQRound minimizes the element-wise worst-case error under $L_\infty$ norm, which is critical for handling heavy-tailed weight distributions in LLMs. Beyond reparameterization, we identify rounding initialization as a decisive factor and develop a lightweight end-to-end finetuning pipeline that optimizes codebooks across all layers using only 128 samples. Extensive experiments on OPT, LLaMA, LLaMA2, and Qwen3 models demonstrate that VQRound achieves better convergence than traditional adaptive rounding at the same number of steps while using as little as 0.2% of the trainable parameters. Our results show that adaptive rounding can be made both scalable and fast-fitting. The code is available at this https URL.</li>
</ul>

<h3>Title: Deep learning enables urban change profiling through alignment of historical maps</h3>
<ul>
<li><strong>Authors: </strong>Sidi Wu, Yizi Chen, Maurizio Gribaudi, Konrad Schindler, Clément Mallet, Julien Perret, Lorenz Hurni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02154">https://arxiv.org/abs/2602.02154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02154">https://arxiv.org/pdf/2602.02154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02154]] Deep learning enables urban change profiling through alignment of historical maps(https://arxiv.org/abs/2602.02154)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.</li>
</ul>

<h3>Title: LoopViT: Scaling Visual ARC with Looped Transformers</h3>
<ul>
<li><strong>Authors: </strong>Wen-Jie Shu, Xuerui Qiu, Rui-Jie Zhu, Harold Haodong Chen, Yexin Liu, Harry Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02156">https://arxiv.org/abs/2602.02156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02156">https://arxiv.org/pdf/2602.02156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02156]] LoopViT: Scaling Visual ARC with Looped Transformers(https://arxiv.org/abs/2602.02156)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at this https URL.</li>
</ul>

<h3>Title: Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing</h3>
<ul>
<li><strong>Authors: </strong>Lingkun Long, Yushi Huang, Shihao Bai, Ruihao Gong, Jun Zhang, Ao Zhou, Jianlei Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02159">https://arxiv.org/abs/2602.02159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02159">https://arxiv.org/pdf/2602.02159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02159]] Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing(https://arxiv.org/abs/2602.02159)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\times$ lossless speedup under $32K$ context length. The code is publicly available at: this https URL</li>
</ul>

<h3>Title: D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use</h3>
<ul>
<li><strong>Authors: </strong>Bowen Xu, Shaoyu Wu, Hao Jiang, Kai Liu, Xin Chen, Lulu Hu, Bin Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02160">https://arxiv.org/abs/2602.02160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02160">https://arxiv.org/pdf/2602.02160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02160]] D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use(https://arxiv.org/abs/2602.02160)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\underline{\textbf{D}}ecomposing tasks and \underline{\textbf{Co}}mposing \underline{\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\% accuracy, surpassing the best-performing 8B model by 5.7\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\%, outperforming 70B models despite being 5$\times$ smaller. The source code is available at this https URL.</li>
</ul>

<h3>Title: Interpretable Tabular Foundation Models via In-Context Kernel Regression</h3>
<ul>
<li><strong>Authors: </strong>Ratmir Miftachov, Bruno Charron, Simon Valentin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02162">https://arxiv.org/abs/2602.02162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02162">https://arxiv.org/pdf/2602.02162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02162]] Interpretable Tabular Foundation Models via In-Context Kernel Regression(https://arxiv.org/abs/2602.02162)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Tabular foundation models like TabPFN and TabICL achieve state-of-the-art performance through in-context learning, yet their architectures remain fundamentally opaque. We introduce KernelICL, a framework to enhance tabular foundation models with quantifiable sample-based interpretability. Building on the insight that in-context learning is akin to kernel regression, we make this mechanism explicit by replacing the final prediction layer with kernel functions (Gaussian, dot-product, kNN) so that every prediction is a transparent weighted average of training labels. We introduce a two-dimensional taxonomy that formally unifies standard kernel methods, modern neighbor-based approaches, and attention mechanisms under a single framework, and quantify inspectability via the perplexity of the weight distribution over training samples. On 55 TALENT benchmark datasets, KernelICL achieves performance on par with existing tabular foundation models, demonstrating that explicit kernel constraints on the final layer enable inspectable predictions without sacrificing performance.</li>
</ul>

<h3>Title: Reg4Pru: Regularisation Through Random Token Routing for Token Pruning</h3>
<ul>
<li><strong>Authors: </strong>Julian Wyatt, Ronald Clark, Irina Voiculescu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02163">https://arxiv.org/abs/2602.02163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02163">https://arxiv.org/pdf/2602.02163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02163]] Reg4Pru: Regularisation Through Random Token Routing for Token Pruning(https://arxiv.org/abs/2602.02163)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.</li>
</ul>

<h3>Title: Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Pengfei He, Ash Fox, Lesly Miculicich, Stefan Friedli, Daniel Fabian, Burak Gokturk, Jiliang Tang, Chen-Yu Lee, Tomas Pfister, Long T. Le</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02164">https://arxiv.org/abs/2602.02164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02164">https://arxiv.org/pdf/2602.02164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02164]] Co-RedTeam: Orchestrated Security Discovery and Exploitation with LLM Agents(https://arxiv.org/abs/2602.02164)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown promise in assisting cybersecurity tasks, yet existing approaches struggle with automatic vulnerability discovery and exploitation due to limited interaction, weak execution grounding, and a lack of experience reuse. We propose Co-RedTeam, a security-aware multi-agent framework designed to mirror real-world red-teaming workflows by integrating security-domain knowledge, code-aware analysis, execution-grounded iterative reasoning, and long-term memory. Co-RedTeam decomposes vulnerability analysis into coordinated discovery and exploitation stages, enabling agents to plan, execute, validate, and refine actions based on real execution feedback while learning from prior trajectories. Extensive evaluations on challenging security benchmarks demonstrate that Co-RedTeam consistently outperforms strong baselines across diverse backbone models, achieving over 60% success rate in vulnerability exploitation and over 10% absolute improvement in vulnerability detection. Ablation and iteration studies further confirm the critical role of execution feedback, structured interaction, and memory for building robust and generalizable cybersecurity agents.</li>
</ul>

<h3>Title: Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Lu Cao, Xiquan He, Junying Zeng, Chaoyun Mai, Min Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02171">https://arxiv.org/abs/2602.02171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02171">https://arxiv.org/pdf/2602.02171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02171]] Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks(https://arxiv.org/abs/2602.02171)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.</li>
</ul>

<h3>Title: AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Liang Lin, Feng Xiong, Zengbin Wang, Kun Wang, Junhao Dong, Xuecai Hu, Yong Wang, Xiangxiang Chu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02178">https://arxiv.org/abs/2602.02178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02178">https://arxiv.org/pdf/2602.02178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02178]] AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?(https://arxiv.org/abs/2602.02178)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\% average score across all tasks and models. Our Code is available at this https URL.</li>
</ul>

<h3>Title: SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks</h3>
<ul>
<li><strong>Authors: </strong>Marina Mastroleo, Alberto Archetti, Federico Mastroleo, Matteo Matteucci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02179">https://arxiv.org/abs/2602.02179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02179">https://arxiv.org/pdf/2602.02179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02179]] SurvKAN: A Fully Parametric Survival Model Based on Kolmogorov-Arnold Networks(https://arxiv.org/abs/2602.02179)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Accurate prediction of time-to-event outcomes is critical for clinical decision-making, treatment planning, and resource allocation in modern healthcare. While classical survival models such as Cox remain widely adopted in standard practice, they rely on restrictive assumptions, including linear covariate relationships and proportional hazards over time, that often fail to capture real-world clinical dynamics. Recent deep learning approaches like DeepSurv and DeepHit offer improved expressivity but sacrifice interpretability, limiting clinical adoption where trust and transparency are paramount. Hybrid models incorporating Kolmogorov-Arnold Networks (KANs), such as CoxKAN, have begun to address this trade-off but remain constrained by the semi-parametric Cox framework. In this work we introduce SurvKAN, a fully parametric, time-continuous survival model based on KAN architectures that eliminates the proportional hazards constraint. SurvKAN treats time as an explicit input to a KAN that directly predicts the log-hazard function, enabling end-to-end training on the full survival likelihood. Our architecture preserves interpretability through learnable univariate functions that indicate how individual features influence risk over time. Extensive experiments on standard survival benchmarks demonstrate that SurvKAN achieves competitive or superior performance compared to classical and state-of-the-art baselines across concordance and calibration metrics. Additionally, interpretability analyses reveal clinically meaningful patterns that align with medical domain knowledge.</li>
</ul>

<h3>Title: STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs</h3>
<ul>
<li><strong>Authors: </strong>Weikang Meng, Liangyu Huo, Yadan Luo, Jiawen Guan, Jingyi Zhang, Yingjian Li, Zheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02180">https://arxiv.org/abs/2602.02180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02180">https://arxiv.org/pdf/2602.02180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02180]] STILL: Selecting Tokens for Intra-Layer Hybrid Attention to Linearize LLMs(https://arxiv.org/abs/2602.02180)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Linearizing pretrained large language models (LLMs) primarily relies on intra-layer hybrid attention mechanisms to alleviate the quadratic complexity of standard softmax attention. Existing methods perform token routing based on sliding-window partitions, resulting in position-based selection and fails to capture token-specific global importance. Meanwhile, linear attention further suffers from distribution shift caused by learnable feature maps that distort pretrained feature magnitudes. Motivated by these limitations, we propose STILL, an intra-layer hybrid linearization framework for efficiently linearizing LLMs. STILL introduces a Self-Saliency Score with strong local-global consistency, enabling accurate token selection using sliding-window computation, and retains salient tokens for sparse softmax attention while summarizing the remaining context via linear attention. To preserve pretrained representations, we design a Norm-Preserved Feature Map (NP-Map) that decouples feature direction from magnitude and reinjects pretrained norms. We further adopt a unified training-inference architecture with chunk-wise parallelization and delayed selection to improve hardware efficiency. Experiments show that STILL matches or surpasses the original pretrained model on commonsense and general reasoning tasks, and achieves up to a 86.2% relative improvement over prior linearized attention methods on long-context benchmarks.</li>
</ul>

<h3>Title: Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages</h3>
<ul>
<li><strong>Authors: </strong>Tjaša Arčon (1), Matej Klemen (1), Marko Robnik-Šikonja (1), Kaja Dobrovoljc (1, 2, 3) ((1) University of Ljubljana, Faculty of Computer and Information Science, Slovenia (2) University of Ljubljana, Faculty of Arts, Slovenia, (3) Jožef Stefan Institute, Ljubljana, Slovenia)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02182">https://arxiv.org/abs/2602.02182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02182">https://arxiv.org/pdf/2602.02182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02182]] Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages(https://arxiv.org/abs/2602.02182)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.</li>
</ul>

<h3>Title: Malware Detection Through Memory Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sarah Nassar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02184">https://arxiv.org/abs/2602.02184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02184">https://arxiv.org/pdf/2602.02184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02184]] Malware Detection Through Memory Analysis(https://arxiv.org/abs/2602.02184)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>This paper summarizes the research conducted for a malware detection project using the Canadian Institute for Cybersecurity's MalMemAnalysis-2022 dataset. The purpose of the project was to explore the effectiveness and efficiency of machine learning techniques for the task of binary classification (i.e., benign or malicious) as well as multi-class classification to further include three malware sub-types (i.e., benign, ransomware, spyware, or Trojan horse). The XGBoost model type was the final model selected for both tasks due to the trade-off between strong detection capability and fast inference speed. The binary classifier achieved a testing subset accuracy and F1 score of 99.98\%, while the multi-class version reached an accuracy of 87.54\% and an F1 score of 81.26\%, with an average F1 score over the malware sub-types of 75.03\%. In addition to the high modelling performance, XGBoost is also efficient in terms of classification speed. It takes about 37.3 milliseconds to classify 50 samples in sequential order in the binary setting and about 43.2 milliseconds in the multi-class setting. The results from this research project help advance the efforts made towards developing accurate and real-time obfuscated malware detectors for the goal of improving online privacy and safety. *This project was completed as part of ELEC 877 (AI for Cybersecurity) in the Winter 2024 term.</li>
</ul>

<h3>Title: Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yu Zeng, Wenxuan Huang, Zhen Fang, Shuang Chen, Yufan Shen, Yishuo Cai, Xiaoman Wang, Zhenfei Yin, Lin Chen, Zehui Chen, Shiting Huang, Yiming Zhao, Yao Hu, Philip Torr, Wanli Ouyang, Shaosheng Cao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02185">https://arxiv.org/abs/2602.02185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02185">https://arxiv.org/pdf/2602.02185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02185]] Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models(https://arxiv.org/abs/2602.02185)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in this https URL.</li>
</ul>

<h3>Title: Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision</h3>
<ul>
<li><strong>Authors: </strong>Ziqiao Weng, Jiancheng Yang, Kangxian Xie, Bo Zhou, Weidong Cai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02186">https://arxiv.org/abs/2602.02186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02186">https://arxiv.org/pdf/2602.02186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02186]] Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision(https://arxiv.org/abs/2602.02186)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pulmonary trees extracted from CT images frequently exhibit topological incompleteness, such as missing or disconnected branches, which substantially degrades downstream anatomical analysis and limits the applicability of existing pulmonary tree modeling pipelines. Current approaches typically rely on dense volumetric processing or explicit graph reasoning, leading to limited efficiency and reduced robustness under realistic structural corruption. We propose TopoField, a topology-aware implicit modeling framework that treats topology repair as a first-class modeling problem and enables unified multi-task inference for pulmonary tree analysis. TopoField represents pulmonary anatomy using sparse surface and skeleton point clouds and learns a continuous implicit field that supports topology repair without relying on complete or explicit disconnection annotations, by training on synthetically introduced structural disruptions over \textit{already} incomplete trees. Building upon the repaired implicit representation, anatomical labeling and lung segment reconstruction are jointly inferred through task-specific implicit functions within a single forward this http URL experiments on the Lung3D+ dataset demonstrate that TopoField consistently improves topological completeness and achieves accurate anatomical labeling and lung segment reconstruction under challenging incomplete scenarios. Owing to its implicit formulation, TopoField attains high computational efficiency, completing all tasks in just over one second per case, highlighting its practicality for large-scale and time-sensitive clinical applications. Code and data will be available at this https URL.</li>
</ul>

<h3>Title: ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Jie Xiao, Meng Chen, Qingnan Ren, Song Jingwei, Jiaqi Huang, Yangshen Deng, Chris Tong, Wanyi Chen, Suli Wang, Ziqian Bi, Shuo Lu, Yiqun Duan, Lynn Ai, Eric Yang, Bill Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02192">https://arxiv.org/abs/2602.02192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02192">https://arxiv.org/pdf/2602.02192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02192]] ECHO-2: A Large Scale Distributed Rollout Framework for Cost-efficient Reinforcement Learning(https://arxiv.org/abs/2602.02192)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) is a critical stage in post-training large language models (LLMs), involving repeated interaction between rollout generation, reward evaluation, and centralized learning. Distributing rollout execution offers opportunities to leverage more cost-efficient inference resources, but introduces challenges in wide-area coordination and policy dissemination. We present ECHO-2, a distributed RL framework for post-training with remote inference workers and non-negligible dissemination latency. ECHO-2 combines centralized learning with distributed rollouts and treats bounded policy staleness as a user-controlled parameter, enabling rollout generation, dissemination, and training to overlap. We introduce an overlap-based capacity model that relates training time, dissemination latency, and rollout throughput, yielding a practical provisioning rule for sustaining learner utilization. To mitigate dissemination bottlenecks and lower cost, ECHO-2 employs peer-assisted pipelined broadcast and cost-aware activation of heterogeneous workers. Experiments on GRPO post-training of 4B and 8B models under real wide-area bandwidth regimes show that ECHO-2 significantly improves cost efficiency while preserving RL reward comparable to strong baselines.</li>
</ul>

<h3>Title: SSI-DM: Singularity Skipping Inversion of Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Chen Min, Enze Jiang, Jishen Peng, Zheng Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02193">https://arxiv.org/abs/2602.02193</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02193">https://arxiv.org/pdf/2602.02193</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02193]] SSI-DM: Singularity Skipping Inversion of Diffusion Models(https://arxiv.org/abs/2602.02193)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.</li>
</ul>

<h3>Title: State Rank Dynamics in Linear Attention LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ao Sun, Hongtao Zhang, Heng Zhou, Yixuan Ma, Yiran Qin, Tongrui Su, Yan Liu, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02195">https://arxiv.org/abs/2602.02195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02195">https://arxiv.org/pdf/2602.02195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02195]] State Rank Dynamics in Linear Attention LLMs(https://arxiv.org/abs/2602.02195)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Linear Attention Large Language Models (LLMs) offer a compelling recurrent formulation that compresses context into a fixed-size state matrix, enabling constant-time inference. However, the internal dynamics of this compressed state remain largely opaque. In this work, we present a comprehensive study on the runtime state dynamics of state-of-the-art Linear Attention models. We uncover a fundamental phenomenon termed State Rank Stratification, characterized by a distinct spectral bifurcation among linear attention heads: while one group maintains an effective rank oscillating near zero, the other exhibits rapid growth that converges to an upper bound. Extensive experiments across diverse inference contexts reveal that these dynamics remain strikingly consistent, indicating that the identity of a head,whether low-rank or high-rank,is an intrinsic structural property acquired during pre-training, rather than a transient state dependent on the input data. Furthermore, our diagnostic probes reveal a surprising functional divergence: low-rank heads are indispensable for model reasoning, whereas high-rank heads exhibit significant redundancy. Leveraging this insight, we propose Joint Rank-Norm Pruning, a zero-shot strategy that achieves a 38.9\% reduction in KV-cache overhead while largely maintaining model accuracy.</li>
</ul>

<h3>Title: Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xindian Ma, Yidi Lu, Peng Zhang, Jing Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02197">https://arxiv.org/abs/2602.02197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02197">https://arxiv.org/pdf/2602.02197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02197]] Hierarchical Adaptive Eviction for KV Cache Management in Multimodal Language Models(https://arxiv.org/abs/2602.02197)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The integration of visual information into Large Language Models (LLMs) has enabled Multimodal LLMs (MLLMs), but the quadratic memory and computational costs of Transformer architectures remain a bottleneck. Existing KV cache eviction strategies fail to address the heterogeneous attention distributions between visual and text tokens, leading to suboptimal efficiency or degraded performance. In this paper, we propose Hierarchical Adaptive Eviction (HAE), a KV cache eviction framework that optimizes text-visual token interaction in MLLMs by implementing Dual-Attention Pruning during pre-filling (leveraging visual token sparsity and attention variance) and a Dynamic Decoding Eviction Strategy (inspired by OS Recycle Bins) during decoding. HAE minimizes KV cache usage across layers, reduces computational overhead via index broadcasting, and theoretically ensures superior information integrity and lower error bounds compared to greedy strategies, enhancing efficiency in both comprehension and generation tasks. Empirically, HAE reduces KV-Cache memory by 41\% with minimal accuracy loss (0.3\% drop) in image understanding tasks and accelerates story generation inference by 1.5x while maintaining output quality on Phi3.5-Vision-Instruct model.</li>
</ul>

<h3>Title: QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks</h3>
<ul>
<li><strong>Authors: </strong>Seyed Ali Ghazi Asgar, Narasimha Reddy</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02198">https://arxiv.org/abs/2602.02198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02198">https://arxiv.org/pdf/2602.02198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02198]] QuietPrint: Protecting 3D Printers Against Acoustic Side-Channel Attacks(https://arxiv.org/abs/2602.02198)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack</a></li>
<li><strong>Abstract: </strong>The 3D printing market has experienced significant growth in recent years, with an estimated revenue of 15 billion USD for 2025. Cyber-attacks targeting the 3D printing process whether through the machine itself, the supply chain, or the fabricated components are becoming increasingly common. One major concern is intellectual property (IP) theft, where a malicious attacker gains access to the design file. One method for carrying out such theft is through side-channel attacks. In this work, we investigate the possibility of IP theft via acoustic side channels and propose a novel method to protect 3D printers against such attacks. The primary advantage of our approach is that it requires no additional hardware, such as large speakers or noise-canceling devices. Instead, it secures printed parts by minimal modifications to the G-code.</li>
</ul>

<h3>Title: Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Abhijit Gupta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02201">https://arxiv.org/abs/2602.02201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02201">https://arxiv.org/pdf/2602.02201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02201]] Cardinality-Preserving Structured Sparse Graph Transformers for Molecular Property Prediction(https://arxiv.org/abs/2602.02201)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Drug discovery motivates efficient molecular property prediction under limited labeled data. Chemical space is vast, often estimated at approximately 10^60 drug-like molecules, while only thousands of drugs have been approved. As a result, self-supervised pretraining on large unlabeled molecular corpora has become essential for data-efficient molecular representation learning. We introduce **CardinalGraphFormer**, a graph transformer that incorporates Graphormer-inspired structural biases, including shortest-path distance and centrality, as well as direct-bond edge bias, within a structured sparse attention regime limited to shortest-path distance <= 3. The model further augments this design with a cardinality-preserving unnormalized aggregation channel over the same support set. Pretraining combines contrastive graph-level alignment with masked attribute reconstruction. Under a fully matched evaluation protocol, CardinalGraphFormer improves mean performance across all 11 evaluated tasks and achieves statistically significant gains on 10 of 11 public benchmarks spanning MoleculeNet, OGB, and TDC ADMET tasks when compared to strong reproduced baselines.</li>
</ul>

<h3>Title: Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study</h3>
<ul>
<li><strong>Authors: </strong>Md. Toufique Hasan, Ayman Asad Khan, Mika Saari, Vaishnavi Bankhele, Pekka Abrahamsson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02208">https://arxiv.org/abs/2602.02208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02208">https://arxiv.org/pdf/2602.02208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02208]] Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study(https://arxiv.org/abs/2602.02208)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.</li>
</ul>

<h3>Title: Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Hongzhou Zhu, Min Zhao, Guande He, Hang Su, Chongxuan Li, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02214">https://arxiv.org/abs/2602.02214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02214">https://arxiv.org/pdf/2602.02214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02214]] Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation(https://arxiv.org/abs/2602.02214)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: \href{this https URL}{this https URL}</li>
</ul>

<h3>Title: Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge</h3>
<ul>
<li><strong>Authors: </strong>Yuzheng Xu, Tosho Hirasawa, Tadashi Kozuno, Yoshitaka Ushiku</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02219">https://arxiv.org/abs/2602.02219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02219">https://arxiv.org/pdf/2602.02219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02219]] Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge(https://arxiv.org/abs/2602.02219)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.</li>
</ul>

<h3>Title: MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Ruiqi Liu, Manni Cui, Ziheng Qin, Zhiyuan Yan, Ruoxin Chen, Yi Han, Zhiheng Li, Junkai Chen, ZhiJin Chen, Kaiqing Lin, Jialiang Shen, Lubin Weng, Jing Dong, Yan Wang, Shu Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02222">https://arxiv.org/abs/2602.02222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02222">https://arxiv.org/pdf/2602.02222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02222]] MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection(https://arxiv.org/abs/2602.02222)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, generative</a></li>
<li><strong>Abstract: </strong>High-fidelity generative models have narrowed the perceptual gap between synthetic and real images, posing serious threats to media security. Most existing AI-generated image (AIGI) detectors rely on artifact-based classification and struggle to generalize to evolving generative traces. In contrast, human judgment relies on stable real-world regularities, with deviations from the human cognitive manifold serving as a more generalizable signal of forgery. Motivated by this insight, we reformulate AIGI detection as a Reference-Comparison problem that verifies consistency with the real-image manifold rather than fitting specific forgery cues. We propose MIRROR (Manifold Ideal Reference ReconstructOR), a framework that explicitly encodes reality priors using a learnable discrete memory bank. MIRROR projects an input into a manifold-consistent ideal reference via sparse linear combination, and uses the resulting residuals as robust detection signals. To evaluate whether detectors reach the "superhuman crossover" required to replace human experts, we introduce the Human-AIGI benchmark, featuring a psychophysically curated human-imperceptible subset. Across 14 benchmarks, MIRROR consistently outperforms prior methods, achieving gains of 2.1% on six standard benchmarks and 8.1% on seven in-the-wild benchmarks. On Human-AIGI, MIRROR reaches 89.6% accuracy across 27 generators, surpassing both lay users and visual experts, and further approaching the human perceptual limit as pretrained backbones scale. The code is publicly available at: this https URL</li>
</ul>

<h3>Title: Spectral Superposition: A Theory of Feature Geometry</h3>
<ul>
<li><strong>Authors: </strong>Georgi Ivanov, Narmeen Oozeer, Shivam Raval, Tasana Pejovic, Shriyash Upadhyay, Amir Abdullah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.SP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02224">https://arxiv.org/abs/2602.02224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02224">https://arxiv.org/pdf/2602.02224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02224]] Spectral Superposition: A Theory of Feature Geometry(https://arxiv.org/abs/2602.02224)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Neural networks represent more features than they have dimensions via superposition, forcing features to share representational space. Current methods decompose activations into sparse linear features but discard geometric structure. We develop a theory for studying the geometric structre of features by analyzing the spectra (eigenvalues, eigenspaces, etc.) of weight derived matrices. In particular, we introduce the frame operator $F = WW^\top$, which gives us a spectral measure that describes how each feature allocates norm across eigenspaces. While previous tools could describe the pairwise interactions between features, spectral methods capture the global geometry (``how do all features interact?''). In toy models of superposition, we use this theory to prove that capacity saturation forces spectral localization: features collapse onto single eigenspaces, organize into tight frames, and admit discrete classification via association schemes, classifying all geometries from prior work (simplices, polygons, antiprisms). The spectral measure formalism applies to arbitrary weight matrices, enabling diagnosis of feature localization beyond toy settings. These results point toward a broader program: applying operator theory to interpretability.</li>
</ul>

<h3>Title: Prediction-Powered Risk Monitoring of Deployed Models for Detecting Harmful Distribution Shifts</h3>
<ul>
<li><strong>Authors: </strong>Guangyi Zhang, Yunlong Cai, Guanding Yu, Osvaldo Simeone</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02229">https://arxiv.org/abs/2602.02229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02229">https://arxiv.org/pdf/2602.02229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02229]] Prediction-Powered Risk Monitoring of Deployed Models for Detecting Harmful Distribution Shifts(https://arxiv.org/abs/2602.02229)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study the problem of monitoring model performance in dynamic environments where labeled data are limited. To this end, we propose prediction-powered risk monitoring (PPRM), a semi-supervised risk-monitoring approach based on prediction-powered inference (PPI). PPRM constructs anytime-valid lower bounds on the running risk by combining synthetic labels with a small set of true labels. Harmful shifts are detected via a threshold-based comparison with an upper bound on the nominal risk, satisfying assumption-free finite-sample guarantees in the probability of false alarm. We demonstrate the effectiveness of PPRM through extensive experiments on image classification, large language model (LLM), and telecommunications monitoring tasks.</li>
</ul>

<h3>Title: SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Zhou, Yuchen Fang, Weilin Ruan, Shiyu Wang, James Kwok, Yuxuan Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02230">https://arxiv.org/abs/2602.02230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02230">https://arxiv.org/pdf/2602.02230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02230]] SEDformer: Event-Synchronous Spiking Transformers for Irregular Telemetry Time Series Forecasting(https://arxiv.org/abs/2602.02230)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Telemetry streams from large-scale Internet-connected systems (e.g., IoT deployments and online platforms) naturally form an irregular multivariate time series (IMTS) whose accurate forecasting is operationally vital. A closer examination reveals a defining Sparsity-Event Duality (SED) property of IMTS, i.e., long stretches with sparse or no observations are punctuated by short, dense bursts where most semantic events (observations) occur. However, existing Graph- and Transformer-based forecasters ignore SED: pre-alignment to uniform grids with heavy padding violates sparsity by inflating sequences and forcing computation at non-informative steps, while relational recasting weakens event semantics by disrupting local temporal continuity. These limitations motivate a more faithful and natural modeling paradigm for IMTS that aligns with its SED property. We find that Spiking Neural Networks meet this requirement, as they communicate via sparse binary spikes and update in an event-driven manner, aligning naturally with the SED nature of IMTS. Therefore, we present SEDformer, an SED-enhanced Spiking Transformer for telemetry IMTS forecasting that couples: (1) a SED-based Spike Encoder converts raw observations into event synchronous spikes using an Event-Aligned LIF neuron, (2) an Event-Preserving Temporal Downsampling module compresses long gaps while retaining salient firings and (3) a stack of SED-based Spike Transformer blocks enable intra-series dependency modeling with a membrane-based linear attention driven by EA-LIF spiking features. Experiments on public telemetry IMTS datasets show that SEDformer attains state-of-the-art forecasting accuracy while reducing energy and memory usage, providing a natural and efficient path for modeling IMTS.</li>
</ul>

<h3>Title: LiFlow: Flow Matching for 3D LiDAR Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Andrea Matteazzi, Dietmar Tutsch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02232">https://arxiv.org/abs/2602.02232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02232">https://arxiv.org/pdf/2602.02232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02232]] LiFlow: Flow Matching for 3D LiDAR Scene Completion(https://arxiv.org/abs/2602.02232)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In autonomous driving scenarios, the collected LiDAR point clouds can be challenged by occlusion and long-range sparsity, limiting the perception of autonomous driving systems. Scene completion methods can infer the missing parts of incomplete 3D LiDAR scenes. Recent methods adopt local point-level denoising diffusion probabilistic models, which require predicting Gaussian noise, leading to a mismatch between training and inference initial distributions. This paper introduces the first flow matching framework for 3D LiDAR scene completion, improving upon diffusion-based methods by ensuring consistent initial distributions between training and inference. The model employs a nearest neighbor flow matching loss and a Chamfer distance loss to enhance both local structure and global coverage in the alignment of point clouds. LiFlow achieves state-of-the-art performance across multiple metrics. Code: this https URL.</li>
</ul>

<h3>Title: Geometry- and Relation-Aware Diffusion for EEG Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Laura Yao, Gengwei Zhang, Moajjem Chowdhury, Yunmei Liu, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02238">https://arxiv.org/abs/2602.02238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02238">https://arxiv.org/pdf/2602.02238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02238]] Geometry- and Relation-Aware Diffusion for EEG Super-Resolution(https://arxiv.org/abs/2602.02238)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent electroencephalography (EEG) spatial super-resolution (SR) methods, while showing improved quality by either directly predicting missing signals from visible channels or adapting latent diffusion-based generative modeling to temporal data, often lack awareness of physiological spatial structure, thereby constraining spatial generation performance. To address this issue, we introduce TopoDiff, a geometry- and relation-aware diffusion model for EEG spatial super-resolution. Inspired by how human experts interpret spatial EEG patterns, TopoDiff incorporates topology-aware image embeddings derived from EEG topographic representations to provide global geometric context for spatial generation, together with a dynamic channel-relation graph that encodes inter-electrode relationships and evolves with temporal dynamics. This design yields a spatially grounded EEG spatial super-resolution framework with consistent performance improvements. Across multiple EEG datasets spanning diverse applications, including SEED/SEED-IV for emotion recognition, PhysioNet motor imagery (MI/MM), and TUSZ for seizure detection, our method achieves substantial gains in generation fidelity and leads to notable improvements in downstream EEG task performance.</li>
</ul>

<h3>Title: Interpretability in Deep Time Series Models Demands Semantic Alignment</h3>
<ul>
<li><strong>Authors: </strong>Giovanni De Felice, Riccardo D'Elia, Alberto Termine, Pietro Barbiero, Giuseppe Marra, Silvia Santini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02239">https://arxiv.org/abs/2602.02239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02239">https://arxiv.org/pdf/2602.02239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02239]] Interpretability in Deep Time Series Models Demands Semantic Alignment(https://arxiv.org/abs/2602.02239)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep time series models continue to improve predictive performance, yet their deployment remains limited by their black-box nature. In response, existing interpretability approaches in the field keep focusing on explaining the internal model computations, without addressing whether they align or not with how a human would reason about the studied phenomenon. Instead, we state interpretability in deep time series models should pursue semantic alignment: predictions should be expressed in terms of variables that are meaningful to the end user, mediated by spatial and temporal mechanisms that admit user-dependent constraints. In this paper, we formalize this requirement and require that, once established, semantic alignment must be preserved under temporal evolution: a constraint with no analog in static settings. Provided with this definition, we outline a blueprint for semantically aligned deep time series models, identify properties that support trust, and discuss implications for model design.</li>
</ul>

<h3>Title: SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution</h3>
<ul>
<li><strong>Authors: </strong>Dakshina Tharindu, Aruna Jayasena, Prabhat Mishra</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02243">https://arxiv.org/abs/2602.02243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02243">https://arxiv.org/pdf/2602.02243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02243]] SysFuSS: System-Level Firmware Fuzzing with Selective Symbolic Execution(https://arxiv.org/abs/2602.02243)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Firmware serves as the critical interface between hardware and software in computing systems, making any bugs or vulnerabilities particularly dangerous as they can cause catastrophic system failures. While fuzzing is a promising approach for identifying design flaws and security vulnerabilities, traditional fuzzers are ineffective at detecting firmware vulnerabilities. For example, existing fuzzers focus on user-level fuzzing, which is not suitable for detecting kernel-level vulnerabilities. Existing fuzzers also face a coverage plateau problem when dealing with complex interactions between firmware and hardware. In this paper, we present an efficient firmware verification framework, SysFuSS, that integrates system-level fuzzing with selective symbolic execution. Our approach leverages system-level emulation for initial fuzzing, and automatically transitions to symbolic execution when coverage reaches a plateau. This strategy enables us to generate targeted test cases that can trigger previously unexplored regions in firmware designs. We have evaluated SysFuSS on real-world embedded firmware, including OpenSSL, WolfBoot, WolfMQTT, HTSlib, MXML, and libIEC. Experimental evaluation demonstrates that SysFuSS significantly outperforms state-of-the-art fuzzers in terms of both branch coverage and detection of firmware vulnerabilities. Specifically, SysFuSS can detect 118 known vulnerabilities while state-of-the-art can cover only 13 of them. Moreover, SysFuSS takes significantly less time (up to 3.3X, 1.7X on average) to activate these vulnerabilities.</li>
</ul>

<h3>Title: Alignment-Aware Model Adaptation via Feedback-Guided Optimization</h3>
<ul>
<li><strong>Authors: </strong>Gaurav Bhatt, Aditya Chinchure, Jiawei Zhou, Leonid Sigal</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02258">https://arxiv.org/abs/2602.02258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02258">https://arxiv.org/pdf/2602.02258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02258]] Alignment-Aware Model Adaptation via Feedback-Guided Optimization(https://arxiv.org/abs/2602.02258)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Fine-tuning is the primary mechanism for adapting foundation models to downstream tasks; however, standard approaches largely optimize task objectives in isolation and do not account for secondary yet critical alignment objectives (e.g., safety and hallucination avoidance). As a result, downstream fine-tuning can degrade alignment and fail to correct pre-existing misaligned behavior. We propose an alignment-aware fine-tuning framework that integrates feedback from an external alignment signal through policy-gradient-based regularization. Our method introduces an adaptive gating mechanism that dynamically balances supervised and alignment-driven gradients on a per-sample basis, prioritizing uncertain or misaligned cases while allowing well-aligned examples to follow standard supervised updates. The framework further learns abstention behavior for fully misaligned inputs, incorporating conservative responses directly into the fine-tuned model. Experiments on general and domain-specific instruction-tuning benchmarks demonstrate consistent reductions in harmful and hallucinated outputs without sacrificing downstream task performance. Additional analyses show robustness to adversarial fine-tuning, prompt-based attacks, and unsafe initializations, establishing adaptively gated alignment optimization as an effective approach for alignment-preserving and alignment-recovering model adaptation.</li>
</ul>

<h3>Title: Segment to Focus: Guiding Latent Action Models in the Presence of Distractors</h3>
<ul>
<li><strong>Authors: </strong>Hamza Adnan, Matthew T. Jackson, Alexey Zakharov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02259">https://arxiv.org/abs/2602.02259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02259">https://arxiv.org/pdf/2602.02259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02259]] Segment to Focus: Guiding Latent Action Models in the Presence of Distractors(https://arxiv.org/abs/2602.02259)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Latent Action Models (LAMs) learn to extract action-relevant representations solely from raw observations, enabling reinforcement learning from unlabelled videos and significantly scaling available training data. However, LAMs face a critical challenge in disentangling action-relevant features from action-correlated noise (e.g., background motion). Failing to filter these distractors causes LAMs to capture spurious correlations and build sub-optimal latent action spaces. In this paper, we introduce MaskLAM -- a lightweight modification to LAM training to mitigate this issue by incorporating visual agent segmentation. MaskLAM utilises segmentation masks from pretrained foundation models to weight the LAM reconstruction loss, thereby prioritising salient information over background elements while requiring no architectural modifications. We demonstrate the effectiveness of our method on continuous-control MuJoCo tasks, modified with action-correlated background noise. Our approach yields up to a 4x increase in accrued rewards compared to standard baselines and a 3x improvement in the latent action quality, as evidenced by linear probe evaluation.</li>
</ul>

<h3>Title: Unlocking the Duality between Flow and Field Matching</h3>
<ul>
<li><strong>Authors: </strong>Daniil Shlenskii, Alexander Varlamov, Nazar Buzun, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02261">https://arxiv.org/abs/2602.02261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02261">https://arxiv.org/pdf/2602.02261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02261]] Unlocking the Duality between Flow and Field Matching(https://arxiv.org/abs/2602.02261)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Conditional Flow Matching (CFM) unifies conventional generative paradigms such as diffusion models and flow matching. Interaction Field Matching (IFM) is a newer framework that generalizes Electrostatic Field Matching (EFM) rooted in Poisson Flow Generative Models (PFGM). While both frameworks define generative dynamics, they start from different objects: CFM specifies a conditional probability path in data space, whereas IFM specifies a physics-inspired interaction field in an augmented data space. This raises a basic question: are CFM and IFM genuinely different, or are they two descriptions of the same underlying dynamics? We show that they coincide for a natural subclass of IFM that we call forward-only IFM. Specifically, we construct a bijection between CFM and forward-only IFM. We further show that general IFM is strictly more expressive: it includes EFM and other interaction fields that cannot be realized within the standard CFM formulation. Finally, we highlight how this duality can benefit both frameworks: it provides a probabilistic interpretation of forward-only IFM and yields novel, IFM-driven techniques for CFM.</li>
</ul>

<h3>Title: Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training</h3>
<ul>
<li><strong>Authors: </strong>Paolo Marcandelli, Natansh Mathur, Stefano Markidis, Martina Siena, Stefano Mariani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02264">https://arxiv.org/abs/2602.02264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02264">https://arxiv.org/pdf/2602.02264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02264]] Unsupervised Physics-Informed Operator Learning through Multi-Stage Curriculum Training(https://arxiv.org/abs/2602.02264)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Solving partial differential equations remains a central challenge in scientific machine learning. Neural operators offer a promising route by learning mappings between function spaces and enabling resolution-independent inference, yet they typically require supervised data. Physics-informed neural networks address this limitation through unsupervised training with physical constraints but often suffer from unstable convergence and limited generalization capability. To overcome these issues, we introduce a multi-stage physics-informed training strategy that achieves convergence by progressively enforcing boundary conditions in the loss landscape and subsequently incorporating interior residuals. At each stage the optimizer is re-initialized, acting as a continuation mechanism that restores stability and prevents gradient stagnation. We further propose the Physics-Informed Spline Fourier Neural Operator (PhIS-FNO), combining Fourier layers with Hermite spline kernels for smooth residual evaluation. Across canonical benchmarks, PhIS-FNO attains a level of accuracy comparable to that of supervised learning, using labeled information only along a narrow boundary region, establishing staged, spline-based optimization as a robust paradigm for physics-informed operator learning.</li>
</ul>

<h3>Title: OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data</h3>
<ul>
<li><strong>Authors: </strong>Tan Sang Nguyen, Muhammad Reza Qorib, Hwee Tou Ng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02266">https://arxiv.org/abs/2602.02266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02266">https://arxiv.org/pdf/2602.02266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02266]] OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data(https://arxiv.org/abs/2602.02266)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.</li>
</ul>

<h3>Title: HopFormer: Sparse Graph Transformers with Explicit Receptive Field Control</h3>
<ul>
<li><strong>Authors: </strong>Sanggeon Yun, Raheeb Hassan, Ryozo Masukawa, Sungheon Jeong, Mohsen Imani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02268">https://arxiv.org/abs/2602.02268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02268">https://arxiv.org/pdf/2602.02268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02268]] HopFormer: Sparse Graph Transformers with Explicit Receptive Field Control(https://arxiv.org/abs/2602.02268)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph Transformers typically rely on explicit positional or structural encodings and dense global attention to incorporate graph topology. In this work, we show that neither is essential. We introduce HopFormer, a graph Transformer that injects structure exclusively through head-specific n-hop masked sparse attention, without the use of positional encodings or architectural modifications. This design provides explicit and interpretable control over receptive fields while enabling genuinely sparse attention whose computational cost scales linearly with mask sparsity. Through extensive experiments on both node-level and graph-level benchmarks, we demonstrate that our approach achieves competitive or superior performance across diverse graph structures. Our results further reveal that dense global attention is often unnecessary: on graphs with strong small-world properties, localized attention yields more stable and consistently high performance, while on graphs with weaker small-world effects, global attention offers diminishing returns. Together, these findings challenge prevailing assumptions in graph Transformer design and highlight sparsity-controlled attention as a principled and efficient alternative.</li>
</ul>

<h3>Title: dziribot: rag based intelligent conversational agent for algerian arabic dialect</h3>
<ul>
<li><strong>Authors: </strong>El Batoul Bechiri, Dihia Lanasri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02270">https://arxiv.org/abs/2602.02270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02270">https://arxiv.org/pdf/2602.02270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02270]] dziribot: rag based intelligent conversational agent for algerian arabic dialect(https://arxiv.org/abs/2602.02270)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.</li>
</ul>

<h3>Title: MoLF: Mixture-of-Latent-Flow for Pan-Cancer Spatial Gene Expression Prediction from Histology</h3>
<ul>
<li><strong>Authors: </strong>Susu Hu, Stefanie Speidel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02282">https://arxiv.org/abs/2602.02282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02282">https://arxiv.org/pdf/2602.02282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02282]] MoLF: Mixture-of-Latent-Flow for Pan-Cancer Spatial Gene Expression Prediction from Histology(https://arxiv.org/abs/2602.02282)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Inferring spatial transcriptomics (ST) from histology enables scalable histogenomic profiling, yet current methods are largely restricted to single-tissue models. This fragmentation fails to leverage biological principles shared across cancer types and hinders application to data-scarce scenarios. While pan-cancer training offers a solution, the resulting heterogeneity challenges monolithic architectures. To bridge this gap, we introduce MoLF (Mixture-of-Latent-Flow), a generative model for pan-cancer histogenomic prediction. MoLF leverages a conditional Flow Matching objective to map noise to the gene latent manifold, parameterized by a Mixture-of-Experts (MoE) velocity field. By dynamically routing inputs to specialized sub-networks, this architecture effectively decouples the optimization of diverse tissue patterns. Our experiments demonstrate that MoLF establishes a new state-of-the-art, consistently outperforming both specialized and foundation model baselines on pan-cancer benchmarks. Furthermore, MoLF exhibits zero-shot generalization to cross-species data, suggesting it captures fundamental, conserved histo-molecular mechanisms.</li>
</ul>

<h3>Title: Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management</h3>
<ul>
<li><strong>Authors: </strong>Owen Shen, Patrick Jaillet</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02283">https://arxiv.org/abs/2602.02283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02283">https://arxiv.org/pdf/2602.02283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02283]] Choice-Model-Assisted Q-learning for Delayed-Feedback Revenue Management(https://arxiv.org/abs/2602.02283)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study reinforcement learning for revenue management with delayed feedback, where a substantial fraction of value is determined by customer cancellations and modifications observed days after booking. We propose \emph{choice-model-assisted RL}: a calibrated discrete choice model is used as a fixed partial world model to impute the delayed component of the learning target at decision time. In the fixed-model deployment regime, we prove that tabular Q-learning with model-imputed targets converges to an $O(\varepsilon/(1-\gamma))$ neighborhood of the optimal Q-function, where $\varepsilon$ summarizes partial-model error, with an additional $O(t^{-1/2})$ sampling term. Experiments in a simulator calibrated from 61{,}619 hotel bookings (1{,}088 independent runs) show: (i) no statistically detectable difference from a maturity-buffer DQN baseline in stationary settings; (ii) positive effects under in-family parameter shifts, with significant gains in 5 of 10 shift scenarios after Holm--Bonferroni correction (up to 12.4\%); and (iii) consistent degradation under structural misspecification, where the choice model assumptions are violated (1.4--2.6\% lower revenue). These results characterize when partial behavioral models improve robustness under shift and when they introduce harmful bias.</li>
</ul>

<h3>Title: Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages</h3>
<ul>
<li><strong>Authors: </strong>Isaac Chung, Linda Freienthal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02287">https://arxiv.org/abs/2602.02287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02287">https://arxiv.org/pdf/2602.02287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02287]] Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages(https://arxiv.org/abs/2602.02287)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences. This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at this https URL.</li>
</ul>

<h3>Title: An Optimization Method for Autoregressive Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zheng Li, Jerry Cheng, Huanying Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02288">https://arxiv.org/abs/2602.02288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02288">https://arxiv.org/pdf/2602.02288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02288]] An Optimization Method for Autoregressive Time Series Forecasting(https://arxiv.org/abs/2602.02288)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Current time-series forecasting models are primarily based on transformer-style neural networks. These models achieve long-term forecasting mainly by scaling up the model size rather than through genuinely autoregressive (AR) rollout. From the perspective of large language model training, the traditional training process for time-series forecasting models ignores temporal causality. In this paper, we propose a novel training method for time-series forecasting that enforces two key properties: (1) AR prediction errors should increase with the forecasting horizon. Any violation of this principle is considered random guessing and is explicitly penalized in the loss function, and (2) the method enables models to concatenate short-term AR predictions for forming flexible long-term forecasts. Empirical results demonstrate that our method establishes a new state-of-the-art across multiple benchmarks, achieving an MSE reduction of more than 10% compared to iTransformer and other recent strong baselines. Furthermore, it enables short-horizon forecasting models to perform reliable long-term predictions at horizons over 7.5 times longer. Code is available at this https URL</li>
</ul>

<h3>Title: Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?</h3>
<ul>
<li><strong>Authors: </strong>Alex Argese, Pasquale Lisena, Raphaël Troncy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02290">https://arxiv.org/abs/2602.02290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02290">https://arxiv.org/pdf/2602.02290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02290]] Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?(https://arxiv.org/abs/2602.02290)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.</li>
</ul>

<h3>Title: EvalQReason: A Framework for Step-Level Reasoning Evaluation in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shaima Ahmad Freja, Ferhat Ozgur Catak, Betul Yurdem, Chunming Rong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02295">https://arxiv.org/abs/2602.02295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02295">https://arxiv.org/pdf/2602.02295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02295]] EvalQReason: A Framework for Step-Level Reasoning Evaluation in Large Language Models(https://arxiv.org/abs/2602.02295)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in critical applications requiring reliable reasoning, yet their internal reasoning processes remain difficult to evaluate systematically. Existing methods focus on final-answer correctness, providing limited insight into how reasoning unfolds across intermediate steps. We present EvalQReason, a framework that quantifies LLM reasoning quality through step-level probability distribution analysis without requiring human annotation. The framework introduces two complementary algorithms: Consecutive Step Divergence (CSD), which measures local coherence between adjacent reasoning steps, and Step-to-Final Convergence (SFC), which assesses global alignment with final answers. Each algorithm employs five statistical metrics to capture reasoning dynamics. Experiments across mathematical and medical datasets with open-source 7B-parameter models demonstrate that CSD-based features achieve strong predictive performance for correctness classification, with classical machine learning models reaching F1=0.78 and ROC-AUC=0.82, and sequential neural models substantially improving performance (F1=0.88, ROC-AUC=0.97). CSD consistently outperforms SFC, and sequential architectures outperform classical machine learning approaches. Critically, reasoning dynamics prove domain-specific: mathematical reasoning exhibits clear divergence-based discrimination patterns between correct and incorrect solutions, while medical reasoning shows minimal discriminative signals, revealing fundamental differences in how LLMs process different reasoning types. EvalQReason enables scalable, process-aware evaluation of reasoning reliability, establishing probability-based divergence analysis as a principled approach for trustworthy AI deployment.</li>
</ul>

<h3>Title: Decoupling Generalizability and Membership Privacy Risks in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Xingli Fang, Jung-Eun Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02296">https://arxiv.org/abs/2602.02296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02296">https://arxiv.org/pdf/2602.02296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02296]] Decoupling Generalizability and Membership Privacy Risks in Neural Networks(https://arxiv.org/abs/2602.02296)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense</a></li>
<li><strong>Abstract: </strong>A deep learning model usually has to sacrifice some utilities when it acquires some other abilities or characteristics. Privacy preservation has such trade-off relationships with utilities. The loss disparity between various defense approaches implies the potential to decouple generalizability and privacy risks to maximize privacy gain. In this paper, we identify that the model's generalization and privacy risks exist in different regions in deep neural network architectures. Based on the observations that we investigate, we propose Privacy-Preserving Training Principle (PPTP) to protect model components from privacy risks while minimizing the loss in generalizability. Through extensive evaluations, our approach shows significantly better maintenance in model generalizability while enhancing privacy preservation.</li>
</ul>

<h3>Title: Advancing General-Purpose Reasoning Models with Modular Gradient Surgery</h3>
<ul>
<li><strong>Authors: </strong>Min Cai, Yu Liang, Longzheng Wang, Yan Wang, Yueyang Zhang, Long Xia, Zhiyuan Sun, Xi Ye, Daiting Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02301">https://arxiv.org/abs/2602.02301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02301">https://arxiv.org/pdf/2602.02301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02301]] Advancing General-Purpose Reasoning Models with Modular Gradient Surgery(https://arxiv.org/abs/2602.02301)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\%) and 4.5 (11.1\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.</li>
</ul>

<h3>Title: The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors</h3>
<ul>
<li><strong>Authors: </strong>Raphaël Sarfati, Eric Bigelow, Daniel Wurgaft, Jack Merullo, Atticus Geiger, Owen Lewis, Tom McGrath, Ekdeep Singh Lubana</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02315">https://arxiv.org/abs/2602.02315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02315">https://arxiv.org/pdf/2602.02315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02315]] The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors(https://arxiv.org/abs/2602.02315)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) represent prompt-conditioned beliefs (posteriors over answers and claims), but we lack a mechanistic account of how these beliefs are encoded in representation space, how they update with new evidence, and how interventions reshape them. We study a controlled setting in which Llama-3.2 generates samples from a normal distribution by implicitly inferring its parameters (mean and standard deviation) given only samples from the distribution in context. We find representations of curved "belief manifolds" for these parameters form with sufficient in-context learning and study how the model adapts when the distribution suddenly changes. While standard linear steering often pushes the model off-manifold and induces coupled, out-of-distribution shifts, geometry and field-aware steering better preserves the intended belief family. Our work demonstrates an example of linear field probing (LFP) as a simple approach to tile the data manifold and make interventions that respect the underlying geometry. We conclude that rich structure emerges naturally in LLMs and that purely linear concept representations are often an inadequate abstraction.</li>
</ul>

<h3>Title: Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xiang Li, Yupeng Zheng, Pengfei Li, Yilun Chen, Ya-Qin Zhang, Wenchao Ding</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02318">https://arxiv.org/abs/2602.02318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02318">https://arxiv.org/pdf/2602.02318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02318]] Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation(https://arxiv.org/abs/2602.02318)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Occupancy prediction provides critical geometric and semantic understanding for robotics but faces efficiency-accuracy trade-offs. Current dense methods suffer computational waste on empty voxels, while sparse query-based approaches lack robustness in diverse and complex indoor scenes. In this paper, we propose DiScene, a novel sparse query-based framework that leverages multi-level distillation to achieve efficient and robust occupancy prediction. In particular, our method incorporates two key innovations: (1) a Multi-level Consistent Knowledge Distillation strategy, which transfers hierarchical representations from large teacher models to lightweight students through coordinated alignment across four levels, including encoder-level feature alignment, query-level feature matching, prior-level spatial guidance, and anchor-level high-confidence knowledge transfer and (2) a Teacher-Guided Initialization policy, employing optimized parameter warm-up to accelerate model convergence. Validated on the Occ-Scannet benchmark, DiScene achieves 23.2 FPS without depth priors while outperforming our baseline method, OPUS, by 36.1% and even better than the depth-enhanced version, OPUS†. With depth integration, DiScene† attains new SOTA performance, surpassing EmbodiedOcc by 3.7% with 1.62$\times$ faster inference speed. Furthermore, experiments on the Occ3D-nuScenes benchmark and in-the-wild scenarios demonstrate the versatility of our approach in various environments. Code and models can be accessed at this https URL.</li>
</ul>

<h3>Title: A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method</h3>
<ul>
<li><strong>Authors: </strong>Feiyang Cai, Guijuan He, Yi Hu, Jingjing Wang, Joshua Luo, Tianyu Zhu, Srikanth Pilla, Gang Li, Ling Liu, Feng Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02320">https://arxiv.org/abs/2602.02320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02320">https://arxiv.org/pdf/2602.02320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02320]] A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method(https://arxiv.org/abs/2602.02320)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.</li>
</ul>

<h3>Title: Language Steering for Multilingual In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Neeraja Kirtane, Kuan-Hao Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02326">https://arxiv.org/abs/2602.02326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02326">https://arxiv.org/pdf/2602.02326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02326]] Language Steering for Multilingual In-Context Learning(https://arxiv.org/abs/2602.02326)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.</li>
</ul>

<h3>Title: LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zhenpeng Huang, Jiaqi Li, Zihan Jia, Xinhao Li, Desen Meng, Lingxue Song, Xi Chen, Liang Li, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02341">https://arxiv.org/abs/2602.02341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02341">https://arxiv.org/pdf/2602.02341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02341]] LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization(https://arxiv.org/abs/2602.02341)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.</li>
</ul>

<h3>Title: Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Ziwen Xu, Chenyan Wu, Hengyu Sun, Haiwen Hong, Mengru Wang, Yunzhi Yao, Longtao Huang, Hui Xue, Shumin Deng, Zhixuan Chu, Huajun Chen, Ningyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02343">https://arxiv.org/abs/2602.02343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02343">https://arxiv.org/pdf/2602.02343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02343]] Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics(https://arxiv.org/abs/2602.02343)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at this https URL.</li>
</ul>

<h3>Title: NAB: Neural Adaptive Binning for Sparse-View CT reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Wangduo Xie, Matthew B. Blaschko</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02356">https://arxiv.org/abs/2602.02356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02356">https://arxiv.org/pdf/2602.02356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02356]] NAB: Neural Adaptive Binning for Sparse-View CT reconstruction(https://arxiv.org/abs/2602.02356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \textbf{N}eural \textbf{A}daptive \textbf{B}inning (\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.</li>
</ul>

<h3>Title: Automated Multiple Mini Interview (MMI) Scoring</h3>
<ul>
<li><strong>Authors: </strong>Ryan Huynh, Frank Guerin, Alison Callwood</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02360">https://arxiv.org/abs/2602.02360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02360">https://arxiv.org/pdf/2602.02360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02360]] Automated Multiple Mini Interview (MMI) Scoring(https://arxiv.org/abs/2602.02360)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Assessing soft skills such as empathy, ethical judgment, and communication is essential in competitive selection processes, yet human scoring is often inconsistent and biased. While Large Language Models (LLMs) have improved Automated Essay Scoring (AES), we show that state-of-the-art rationale-based fine-tuning methods struggle with the abstract, context-dependent nature of Multiple Mini-Interviews (MMIs), missing the implicit signals embedded in candidate narratives. We introduce a multi-agent prompting framework that breaks down the evaluation process into transcript refinement and criterion-specific scoring. Using 3-shot in-context learning with a large instruct-tuned model, our approach outperforms specialised fine-tuned baselines (Avg QWK 0.62 vs 0.32) and achieves reliability comparable to human experts. We further demonstrate the generalisability of our framework on the ASAP benchmark, where it rivals domain-specific state-of-the-art models without additional training. These findings suggest that for complex, subjective reasoning tasks, structured prompt engineering may offer a scalable alternative to data-intensive fine-tuning, altering how LLMs can be applied to automated assessment.</li>
</ul>

<h3>Title: ReasonCACHE: Teaching LLMs To Reason Without Weight Updates</h3>
<ul>
<li><strong>Authors: </strong>Sharut Gupta, Phillip Isola, Stefanie Jegelka, David Lopez-Paz, Kartik Ahuja, Mark Ibrahim, Mohammad Pezeshki</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02366">https://arxiv.org/abs/2602.02366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02366">https://arxiv.org/pdf/2602.02366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02366]] ReasonCACHE: Teaching LLMs To Reason Without Weight Updates(https://arxiv.org/abs/2602.02366)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Can Large language models (LLMs) learn to reason without any weight update and only through in-context learning (ICL)? ICL is strikingly sample-efficient, often learning from only a handful of demonstrations, but complex reasoning tasks typically demand many training examples to learn from. However, naively scaling ICL by adding more demonstrations breaks down at this scale: attention costs grow quadratically, performance saturates or degrades with longer contexts, and the approach remains a shallow form of learning. Due to these limitations, practitioners predominantly rely on in-weight learning (IWL) to induce reasoning. In this work, we show that by using Prefix Tuning, LLMs can learn to reason without overloading the context window and without any weight updates. We introduce $\textbf{ReasonCACHE}$, an instantiation of this mechanism that distills demonstrations into a fixed key-value cache. Empirically, across challenging reasoning benchmarks, including GPQA-Diamond, ReasonCACHE outperforms standard ICL and matches or surpasses IWL approaches. Further, it achieves this all while being more efficient across three key axes: data, inference cost, and trainable parameters. We also theoretically prove that ReasonCACHE can be strictly more expressive than low-rank weight update since the latter ties expressivity to input rank, whereas ReasonCACHE bypasses this constraint by directly injecting key-values into the attention mechanism. Together, our findings identify ReasonCACHE as a middle path between in-context and in-weight learning, providing a scalable algorithm for learning reasoning skills beyond the context window without modifying parameters. Our project page: this https URL</li>
</ul>

<h3>Title: C-kNN-LSH: A Nearest-Neighbor Algorithm for Sequential Counterfactual Inference</h3>
<ul>
<li><strong>Authors: </strong>Jing Wang, Jie Shen, Qiaomin Xie, Jeremy C Weiss</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02371">https://arxiv.org/abs/2602.02371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02371">https://arxiv.org/pdf/2602.02371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02371]] C-kNN-LSH: A Nearest-Neighbor Algorithm for Sequential Counterfactual Inference(https://arxiv.org/abs/2602.02371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Estimating causal effects from longitudinal trajectories is central to understanding the progression of complex conditions and optimizing clinical decision-making, such as comorbidities and long COVID recovery. We introduce \emph{C-kNN--LSH}, a nearest-neighbor framework for sequential causal inference designed to handle such high-dimensional, confounded situations. By utilizing locality-sensitive hashing, we efficiently identify ``clinical twins'' with similar covariate histories, enabling local estimation of conditional treatment effects across evolving disease states. To mitigate bias from irregular sampling and shifting patient recovery profiles, we integrate neighborhood estimator with a doubly-robust correction. Theoretical analysis guarantees our estimator is consistent and second-order robust to nuisance error. Evaluated on a real-world Long COVID cohort with 13,511 participants, \emph{C-kNN-LSH} demonstrates superior performance in capturing recovery heterogeneity and estimating policy values compared to existing baselines.</li>
</ul>

<h3>Title: Proof-RM: A Scalable and Generalizable Reward Model for Math Proof</h3>
<ul>
<li><strong>Authors: </strong>Haotong Yang, Zitong Wang, Shijia Kang, Siqi Yang, Wenkai Yu, Xu Niu, Yike Sun, Yi Hu, Zhouchen Lin, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02377">https://arxiv.org/abs/2602.02377</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02377">https://arxiv.org/pdf/2602.02377</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02377]] Proof-RM: A Scalable and Generalizable Reward Model for Math Proof(https://arxiv.org/abs/2602.02377)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality "**question-proof-check**" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.</li>
</ul>

<h3>Title: Unified Personalized Reward Model for Vision Generation</h3>
<ul>
<li><strong>Authors: </strong>Yibin Wang, Yuhang Zang, Feng Han, Jiazi Bu, Yujie Zhou, Cheng Jin, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02380">https://arxiv.org/abs/2602.02380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02380">https://arxiv.org/pdf/2602.02380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02380]] Unified Personalized Reward Model for Vision Generation(https://arxiv.org/abs/2602.02380)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.</li>
</ul>

<h3>Title: Self-Supervised Learning from Structural Invariance</h3>
<ul>
<li><strong>Authors: </strong>Yipeng Zhang, Hafez Ghaemi, Jungyoon Lee, Shahab Bakhtiari, Eilif B. Muller, Laurent Charlin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02381">https://arxiv.org/abs/2602.02381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02381">https://arxiv.org/pdf/2602.02381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02381]] Self-Supervised Learning from Structural Invariance(https://arxiv.org/abs/2602.02381)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Joint-embedding self-supervised learning (SSL), the key paradigm for unsupervised representation learning from visual data, learns from invariances between semantically-related data pairs. We study the one-to-many mapping problem in SSL, where each datum may be mapped to multiple valid targets. This arises when data pairs come from naturally occurring generative processes, e.g., successive video frames. We show that existing methods struggle to flexibly capture this conditional uncertainty. As a remedy, we introduce a latent variable to account for this uncertainty and derive a variational lower bound on the mutual information between paired embeddings. Our derivation yields a simple regularization term for standard SSL objectives. The resulting method, which we call AdaSSL, applies to both contrastive and distillation-based SSL objectives, and we empirically show its versatility in causal representation learning, fine-grained image understanding, and world modeling on videos.</li>
</ul>

<h3>Title: ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Ziyan Zhang, Chao Wang, Zhuo Chen, Chiyi Li, Kai Song</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02382">https://arxiv.org/abs/2602.02382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02382">https://arxiv.org/pdf/2602.02382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02382]] ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs(https://arxiv.org/abs/2602.02382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.</li>
</ul>

<h3>Title: SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Maksim Afanasyev, Illarion Iov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02383">https://arxiv.org/abs/2602.02383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02383">https://arxiv.org/pdf/2602.02383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02383]] SLIME: Stabilized Likelihood Implicit Margin Enforcement for Preference Optimization(https://arxiv.org/abs/2602.02383)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct preference optimization methods have emerged as a computationally efficient alternative to Reinforcement Learning from Human Feedback (RLHF) for aligning Large Language Models (LLMs). Latest approaches have streamlined the alignment process by deriving implicit reward functions, yet they often suffer from a critical objective mismatch: optimizing the relative margin between chosen and rejected responses does not guarantee the preservation of the chosen response's absolute likelihood. This can lead to ``unlearning'', where the model degrades the probability of high-quality outputs to satisfy margin constraints, and ``formatting collapse'' caused by the over-penalization of rejected sequences. In this work, we introduce SLIME (Stabilized Likelihood Implicit Margin Enforcement), a reference-free alignment objective designed to decouple preference learning from generation quality. SLIME incorporates a three-pronged objective: (1) an anchoring term to maximize the likelihood of preferred responses; (2) a stabilizing penalty that prevents the probabilities of rejected tokens from collapsing to zero; and (3) a dual-margin mechanism that combines hard and soft constraints for precise boundary shaping. Our results demonstrate that SLIME achieves superior performance compared to state-of-the-art baselines while maintaining higher generation stability.</li>
</ul>

<h3>Title: Transformers learn factored representations</h3>
<ul>
<li><strong>Authors: </strong>Adam Shai, Loren Amdahl-Culleton, Casper L. Christensen, Henry R. Bigelow, Fernando E. Rosas, Alexander B. Boyd, Eric A. Alt, Kyle J. Ray, Paul M. Riechers</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02385">https://arxiv.org/abs/2602.02385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02385">https://arxiv.org/pdf/2602.02385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02385]] Transformers learn factored representations(https://arxiv.org/abs/2602.02385)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers pretrained via next token prediction learn to factor their world into parts, representing these factors in orthogonal subspaces of the residual stream. We formalize two representational hypotheses: (1) a representation in the product space of all factors, whose dimension grows exponentially with the number of parts, or (2) a factored representation in orthogonal subspaces, whose dimension grows linearly. The factored representation is lossless when factors are conditionally independent, but sacrifices predictive fidelity otherwise, creating a tradeoff between dimensional efficiency and accuracy. We derive precise predictions about the geometric structure of activations for each, including the number of subspaces, their dimensionality, and the arrangement of context embeddings within them. We test between these hypotheses on transformers trained on synthetic processes with known latent structure. Models learn factored representations when factors are conditionally independent, and continue to favor them early in training even when noise or hidden dependencies undermine conditional independence, reflecting an inductive bias toward factoring at the cost of fidelity. This provides a principled explanation for why transformers decompose the world into parts, and suggests that interpretable low dimensional structure may persist even in models trained on complex data.</li>
</ul>

<h3>Title: Personalized Image Generation via Human-in-the-loop Bayesian Optimization</h3>
<ul>
<li><strong>Authors: </strong>Rajalaxmi Rajagopalan, Debottam Dutta, Yu-Lin Wei, Romit Roy Choudhury</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02388">https://arxiv.org/abs/2602.02388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02388">https://arxiv.org/pdf/2602.02388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02388]] Personalized Image Generation via Human-in-the-loop Bayesian Optimization(https://arxiv.org/abs/2602.02388)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Imagine Alice has a specific image $x^\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\ast$, even though the generative model has no information about $x^\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.</li>
</ul>

<h3>Title: Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory</h3>
<ul>
<li><strong>Authors: </strong>Ruiqi Wu, Xuanhua He, Meng Cheng, Tianyu Yang, Yong Zhang, Zhuoliang Kang, Xunliang Cai, Xiaoming Wei, Chunle Guo, Chongyi Li, Ming-Ming Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02393">https://arxiv.org/abs/2602.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02393">https://arxiv.org/pdf/2602.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02393]] Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory(https://arxiv.org/abs/2602.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.</li>
</ul>

<h3>Title: David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Samuel Nellessen, Tal Kachman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02395">https://arxiv.org/abs/2602.02395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02395">https://arxiv.org/pdf/2602.02395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02395]] David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning(https://arxiv.org/abs/2602.02395)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary "tags along" on the trusted privileges of a safety-aligned Operator to induce prohibited tool use through conversation alone. To validate this threat, we present Slingshot, a 'cold-start' reinforcement learning framework that autonomously discovers emergent attack vectors, revealing a critical insight: in our setting, learned attacks tend to converge to short, instruction-like syntactic patterns rather than multi-turn persuasion. On held-out extreme-difficulty tasks, Slingshot achieves a 67.0% success rate against a Qwen2.5-32B-Instruct-AWQ Operator (vs. 1.7% baseline), reducing the expected attempts to first success (on solved tasks) from 52.3 to 1.3. Crucially, Slingshot transfers zero-shot to several model families, including closed-source models like Gemini 2.5 Flash (56.0% attack success rate) and defensive-fine-tuned open-source models like Meta-SecAlign-8B (39.2% attack success rate). Our work establishes Tag-Along Attacks as a first-class, verifiable threat model and shows that effective agentic attacks can be elicited from off-the-shelf open-weight models through environment interaction alone.</li>
</ul>

<h3>Title: An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence</h3>
<ul>
<li><strong>Authors: </strong>Qizhen Zhang, Ankush Garg, Jakob Foerster, Niladri Chatterji, Kshitiz Malik, Mike Lewis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02400">https://arxiv.org/abs/2602.02400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02400">https://arxiv.org/pdf/2602.02400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02400]] An Empirical Study on Noisy Data and LLM Pretraining Loss Divergence(https://arxiv.org/abs/2602.02400)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large-scale pretraining datasets drive the success of large language models (LLMs). However, these web-scale corpora inevitably contain large amounts of noisy data due to unregulated web content or randomness inherent in data. Although LLM pretrainers often speculate that such noise contributes to instabilities in large-scale LLM pretraining and, in the worst cases, loss divergence, this phenomenon remains poorly this http URL this work, we present a systematic empirical study of whether noisy data causes LLM pretraining divergences and how it does so. By injecting controlled synthetic uniformly random noise into otherwise clean datasets, we analyze training dynamics across model sizes ranging from 480M to 5.2B parameters. We show that noisy data indeed induces training loss divergence, and that the probability of divergence depends strongly on the noise type, amount of noise, and model scale. We further find that noise-induced divergences exhibit activation patterns distinct from those caused by high learning rates, and we provide diagnostics that differentiate these two failure modes. Together, these results provide a large-scale, controlled characterization of how noisy data affects loss divergence in LLM pretraining.</li>
</ul>

<h3>Title: Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation</h3>
<ul>
<li><strong>Authors: </strong>Xinshun Wang, Peiming Li, Ziyi Wang, Zhongbin Fang, Zhichao Deng, Songtao Wu, Jason Li, Mengyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02401">https://arxiv.org/abs/2602.02401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02401">https://arxiv.org/pdf/2602.02401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02401]] Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation(https://arxiv.org/abs/2602.02401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.</li>
</ul>

<h3>Title: Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ethan Mendes, Jungsoo Park, Alan Ritter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02405">https://arxiv.org/abs/2602.02405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02405">https://arxiv.org/pdf/2602.02405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02405]] Didactic to Constructive: Turning Expert Solutions into Learnable Reasoning(https://arxiv.org/abs/2602.02405)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Improving the reasoning capabilities of large language models (LLMs) typically relies either on the model's ability to sample a correct solution to be reinforced or on the existence of a stronger model able to solve the problem. However, many difficult problems remain intractable for even current frontier models, preventing the extraction of valid training signals. A promising alternative is to leverage high-quality expert human solutions, yet naive imitation of this data fails because it is fundamentally out of distribution: expert solutions are typically didactic, containing implicit reasoning gaps intended for human readers rather than computational models. Furthermore, high-quality expert solutions are expensive, necessitating generalizable sample-efficient training methods. We propose Distribution Aligned Imitation Learning (DAIL), a two-step method that bridges the distributional gap by first transforming expert solutions into detailed, in-distribution reasoning traces and then applying a contrastive objective to focus learning on expert insights and methodologies. We find that DAIL can leverage fewer than 1000 high-quality expert solutions to achieve 10-25% pass@k gains on Qwen2.5-Instruct and Qwen3 models, improve reasoning efficiency by 2x to 4x, and enable out-of-domain generalization.</li>
</ul>

<h3>Title: Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Apoorv Mohit, Bhavya Aggarwal, Chinmay Gondhalekar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02412">https://arxiv.org/abs/2602.02412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02412">https://arxiv.org/pdf/2602.02412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02412]] Provenance Verification of AI-Generated Images via a Perceptual Hash Registry Anchored on Blockchain(https://arxiv.org/abs/2602.02412)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark</a></li>
<li><strong>Abstract: </strong>The rapid advancement of artificial intelligence has made the generation of synthetic images widely accessible, increasing concerns related to misinformation, digital forgery, and content authenticity on large-scale online platforms. This paper proposes a blockchain-backed framework for verifying AI-generated images through a registry-based provenance mechanism. Each AI-generated image is assigned a digital fingerprint that preserves similarity using perceptual hashing and is registered at creation time by participating generation platforms. The hashes are stored on a hybrid on-chain/off-chain public blockchain using a Merkle Patricia Trie for tamper-resistant storage (on-chain) and a Burkhard-Keller tree (off-chain) to enable efficient similarity search over large image registries. Verification is performed when images are re-uploaded to digital platforms such as social media services, enabling identification of previously registered AI-generated images even after benign transformations or partial modifications. The proposed system does not aim to universally detect all synthetic images, but instead focuses on verifying the provenance of AI-generated content that has been registered at creation time. By design, this approach complements existing watermarking and learning-based detection methods, providing a platform-agnostic, tamper-proof mechanism for scalable content provenance and authenticity verification at the point of large-scale online distribution.</li>
</ul>

<h3>Title: Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank</h3>
<ul>
<li><strong>Authors: </strong>Joshua Mitton, Prarthana Bhattacharyya, Digory Smith, Thomas Christie, Ralph Abboud, Simon Woodhead</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02414">https://arxiv.org/abs/2602.02414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02414">https://arxiv.org/pdf/2602.02414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02414]] Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank(https://arxiv.org/abs/2602.02414)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.</li>
</ul>

<h3>Title: Trust Region Continual Learning as an Implicit Meta-Learner</h3>
<ul>
<li><strong>Authors: </strong>Zekun Wang, Anant Gupta, Christopher J. MacLellan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02417">https://arxiv.org/abs/2602.02417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02417">https://arxiv.org/pdf/2602.02417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02417]] Trust Region Continual Learning as an Implicit Meta-Learner(https://arxiv.org/abs/2602.02417)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Continual learning aims to acquire tasks sequentially without catastrophic forgetting, yet standard strategies face a core tradeoff: regularization-based methods (e.g., EWC) can overconstrain updates when task optima are weakly overlapping, while replay-based methods can retain performance but drift due to imperfect replay. We study a hybrid perspective: \emph{trust region continual learning} that combines generative replay with a Fisher-metric trust region constraint. We show that, under local approximations, the resulting update admits a MAML-style interpretation with a single implicit inner step: replay supplies an old-task gradient signal (query-like), while the Fisher-weighted penalty provides an efficient offline curvature shaping (support-like). This yields an emergent meta-learning property in continual learning: the model becomes an initialization that rapidly \emph{re-converges} to prior task optima after each task transition, without explicitly optimizing a bilevel objective. Empirically, on task-incremental diffusion image generation and continual diffusion-policy control, trust region continual learning achieves the best final performance and retention, and consistently recovers early-task performance faster than EWC, replay, and continual meta-learning baselines.</li>
</ul>

<h3>Title: Poly-attention: a general scheme for higher-order self-attention</h3>
<ul>
<li><strong>Authors: </strong>Sayak Chakrabarti, Toniann Pitassi, Josh Alman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02422">https://arxiv.org/abs/2602.02422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02422">https://arxiv.org/pdf/2602.02422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02422]] Poly-attention: a general scheme for higher-order self-attention(https://arxiv.org/abs/2602.02422)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The self-attention mechanism, at the heart of the Transformer model, is able to effectively model pairwise interactions between tokens. However, numerous recent works have shown that it is unable to perform basic tasks involving detecting triples of correlated tokens, or compositional tasks where multiple input tokens need to be referenced to generate a result. Some higher-dimensional alternatives to self-attention have been proposed to address this, including higher-order attention and Strassen attention, which can perform some of these polyadic tasks in exchange for slower, superquadratic running times. In this work, we define a vast class of generalizations of self-attention, which we call poly-attention mechanisms. Our mechanisms can incorporate arbitrary higher-order (tensor) computations as well as arbitrary relationship structures between the input tokens, and they include the aforementioned alternatives as special cases. We then systematically study their computational complexity and representational strength, including giving new algorithms and matching complexity-theoretic lower bounds on the time complexity of computing the attention matrix exactly as well as approximately, and tightly determining which polyadic tasks they can each perform. Our results give interesting trade-offs between different desiderata for these mechanisms, including a tight relationship between how expressive a mechanism is, and how large the coefficients in the model may be so that the mechanism can be approximated in almost-linear time. Notably, we give a new attention mechanism which can be computed exactly in quadratic time, and which can perform function composition for any fixed number of functions. Prior mechanisms, even for just composing two functions, could only be computed in superquadratic time, and our new lower bounds show that faster algorithms for them are not possible.</li>
</ul>

<h3>Title: SelvaMask: Segmenting Trees in Tropical Forests and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Simon-Olivier Duguay, Hugo Baudchon, Etienne Laliberté, Helene Muller-Landau, Gonzalo Rivas-Torres, Arthur Ouaknine</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02426">https://arxiv.org/abs/2602.02426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02426">https://arxiv.org/pdf/2602.02426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02426]] SelvaMask: Segmenting Trees in Tropical Forests and Beyond(https://arxiv.org/abs/2602.02426)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.</li>
</ul>

<h3>Title: Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Qihao Wen, Jiahao Wang, Yang Nan, Pengfei He, Ravi Tandon, Han Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02427">https://arxiv.org/abs/2602.02427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02427">https://arxiv.org/pdf/2602.02427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02427]] Embedding Perturbation may Better Reflect the Uncertainty in LLM Reasoning(https://arxiv.org/abs/2602.02427)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language Models (LLMs) have achieved significant breakthroughs across diverse domains; however, they can still produce unreliable or misleading outputs. For responsible LLM application, Uncertainty Quantification (UQ) techniques are used to estimate a model's uncertainty about its outputs, indicating the likelihood that those outputs may be problematic. For LLM reasoning tasks, it is essential to estimate the uncertainty not only for the final answer, but also for the intermediate steps of the reasoning, as this can enable more fine-grained and targeted interventions. In this study, we explore what UQ metrics better reflect the LLM's ``intermediate uncertainty''during reasoning. Our study reveals that an LLMs' incorrect reasoning steps tend to contain tokens which are highly sensitive to the perturbations on the preceding token embeddings. In this way, incorrect (uncertain) intermediate steps can be readily identified using this sensitivity score as guidance in practice. In our experiments, we show such perturbation-based metric achieves stronger uncertainty quantification performance compared with baseline methods such as token (generation) probability and token entropy. Besides, different from approaches that rely on multiple sampling, the perturbation-based metrics offer better simplicity and efficiency.</li>
</ul>

<h3>Title: Large Language Models for Mental Health: A Multilingual Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Nishat Raihan, Sadiya Sayara Chowdhury Puspo, Ana-Maria Bucur, Stevie Chancellor, Marcos Zampieri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02440">https://arxiv.org/abs/2602.02440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02440">https://arxiv.org/pdf/2602.02440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02440]] Large Language Models for Mental Health: A Multilingual Evaluation(https://arxiv.org/abs/2602.02440)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.</li>
</ul>

<h3>Title: Conflict-Aware Client Selection for Multi-Server Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Mingwei Hong, Zheng Lin, Zehang Lin, Lin Li, Miao Yang, Xia Du, Zihan Fang, Zhaolu Kang, Dianxin Luan, Shunzhi Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02458">https://arxiv.org/abs/2602.02458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02458">https://arxiv.org/pdf/2602.02458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02458]] Conflict-Aware Client Selection for Multi-Server Federated Learning(https://arxiv.org/abs/2602.02458)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.</li>
</ul>

<h3>Title: Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Gabriele Maraia, Marco Valentino, Fabio Massimo Zanzotto, Leonardo Ranaldi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02462">https://arxiv.org/abs/2602.02462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02462">https://arxiv.org/pdf/2602.02462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02462]] Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models(https://arxiv.org/abs/2602.02462)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.</li>
</ul>

<h3>Title: Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Noam Steinmetz Yalon, Ariel Goldstein, Liad Mudrik, Mor Geva</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02467">https://arxiv.org/abs/2602.02467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02467">https://arxiv.org/pdf/2602.02467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02467]] Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models(https://arxiv.org/abs/2602.02467)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.</li>
</ul>

<h3>Title: Multi-head automated segmentation by incorporating detection head into the contextual layer neural network</h3>
<ul>
<li><strong>Authors: </strong>Edwin Kys, Febian Febian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02471">https://arxiv.org/abs/2602.02471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02471">https://arxiv.org/pdf/2602.02471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02471]] Multi-head automated segmentation by incorporating detection head into the contextual layer neural network(https://arxiv.org/abs/2602.02471)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.</li>
</ul>

<h3>Title: MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</h3>
<ul>
<li><strong>Authors: </strong>Haozhen Zhang, Quanyu Long, Jianzhu Bao, Tao Feng, Weizhi Zhang, Haodong Yue, Wenya Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02474">https://arxiv.org/abs/2602.02474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02474">https://arxiv.org/pdf/2602.02474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02474]] MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents(https://arxiv.org/abs/2602.02474)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.</li>
</ul>

<h3>Title: Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability</h3>
<ul>
<li><strong>Authors: </strong>Xiao Liang, Zhong-Zhi Li, Zhenghao Lin, Eric Hancheng Jiang, Hengyuan Zhang, Yelong Shen, Kai-Wei Chang, Ying Nian Wu, Yeyun Gong, Weizhu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02477">https://arxiv.org/abs/2602.02477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02477">https://arxiv.org/pdf/2602.02477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02477]] Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability(https://arxiv.org/abs/2602.02477)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.</li>
</ul>

<h3>Title: PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss</h3>
<ul>
<li><strong>Authors: </strong>Zehong Ma, Ruihan Xu, Shiliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02493">https://arxiv.org/abs/2602.02493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02493">https://arxiv.org/pdf/2602.02493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02493]] PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss(https://arxiv.org/abs/2602.02493)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at this https URL.</li>
</ul>

<h3>Title: Reward-free Alignment for Conflicting Objectives</h3>
<ul>
<li><strong>Authors: </strong>Peter Chen, Xiaopeng Li, Xi Chen, Tianyi Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2602.02495">https://arxiv.org/abs/2602.02495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2602.02495">https://arxiv.org/pdf/2602.02495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2602.02495]] Reward-free Alignment for Conflicting Objectives(https://arxiv.org/abs/2602.02495)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
