<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-03-05</h1>
<h3>Title: A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Geng, Qing Li, Herbert Woisetschlaeger, Zongxiong Chen, Yuxia Wang, Preslav Nakov, Hans-Arno Jacobsen, Fakhri Karray</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01854">https://arxiv.org/abs/2503.01854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01854">https://arxiv.org/pdf/2503.01854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01854]] A Comprehensive Survey of Machine Unlearning Techniques for Large Language Models(https://arxiv.org/abs/2503.01854)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the machine unlearning techniques within the context of large language models (LLMs), referred to as \textit{LLM unlearning}. LLM unlearning offers a principled approach to removing the influence of undesirable data (e.g., sensitive or illegal information) from LLMs, while preserving their overall utility without requiring full retraining. Despite growing research interest, there is no comprehensive survey that systematically organizes existing work and distills key insights; here, we aim to bridge this gap. We begin by introducing the definition and the paradigms of LLM unlearning, followed by a comprehensive taxonomy of existing unlearning studies. Next, we categorize current unlearning approaches, summarizing their strengths and limitations. Additionally, we review evaluation metrics and benchmarks, providing a structured overview of current assessment methodologies. Finally, we outline promising directions for future research, highlighting key challenges and opportunities in the field.</li>
</ul>

<h3>Title: Optimizing Retrieval-Augmented Generation of Medical Content for Spaced Repetition Learning</h3>
<ul>
<li><strong>Authors: </strong>Jeremi I. Kaczmarek, Jakub Pokrywka, Krzysztof Biedalak, Grzegorz Kurzyp, Łukasz Grzybowski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01859">https://arxiv.org/abs/2503.01859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01859">https://arxiv.org/pdf/2503.01859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01859]] Optimizing Retrieval-Augmented Generation of Medical Content for Spaced Repetition Learning(https://arxiv.org/abs/2503.01859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Advances in Large Language Models revolutionized medical education by enabling scalable and efficient learning solutions. This paper presents a pipeline employing Retrieval-Augmented Generation (RAG) system to prepare comments generation for Poland's State Specialization Examination (PES) based on verified resources. The system integrates these generated comments and source documents with a spaced repetition learning algorithm to enhance knowledge retention while minimizing cognitive overload. By employing a refined retrieval system, query rephraser, and an advanced reranker, our modified RAG solution promotes accuracy more than efficiency. Rigorous evaluation by medical annotators demonstrates improvements in key metrics such as document relevance, credibility, and logical coherence of generated content, proven by a series of experiments presented in the paper. This study highlights the potential of RAG systems to provide scalable, high-quality, and individualized educational resources, addressing non-English speaking users.</li>
</ul>

<h3>Title: Vision Language Models in Medicine</h3>
<ul>
<li><strong>Authors: </strong>Beria Chingnabe Kalpelbe, Angel Gabriel Adaambiik, Wei Peng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.CY, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01863">https://arxiv.org/abs/2503.01863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01863">https://arxiv.org/pdf/2503.01863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01863]] Vision Language Models in Medicine(https://arxiv.org/abs/2503.01863)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, fair, interpretability</a></li>
<li><strong>Abstract: </strong>With the advent of Vision-Language Models (VLMs), medical artificial intelligence (AI) has experienced significant technological progress and paradigm shifts. This survey provides an extensive review of recent advancements in Medical Vision-Language Models (Med-VLMs), which integrate visual and textual data to enhance healthcare outcomes. We discuss the foundational technology behind Med-VLMs, illustrating how general models are adapted for complex medical tasks, and examine their applications in healthcare. The transformative impact of Med-VLMs on clinical practice, education, and patient care is highlighted, alongside challenges such as data scarcity, narrow task generalization, interpretability issues, and ethical concerns like fairness, accountability, and privacy. These limitations are exacerbated by uneven dataset distribution, computational demands, and regulatory hurdles. Rigorous evaluation methods and robust regulatory frameworks are essential for safe integration into healthcare workflows. Future directions include leveraging large-scale, diverse datasets, improving cross-modal generalization, and enhancing interpretability. Innovations like federated learning, lightweight architectures, and Electronic Health Record (EHR) integration are explored as pathways to democratize access and improve clinical relevance. This review aims to provide a comprehensive understanding of Med-VLMs' strengths and limitations, fostering their ethical and balanced adoption in healthcare.</li>
</ul>

<h3>Title: Larger or Smaller Reward Margins to Select Preferences for Alignment?</h3>
<ul>
<li><strong>Authors: </strong>Kexin Huang, Junkang Wu, Ziqian Chen, Xue Wang, Jinyang Gao, Bolin Ding, Jiancan Wu, Xiangnan He, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01864">https://arxiv.org/abs/2503.01864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01864">https://arxiv.org/pdf/2503.01864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01864]] Larger or Smaller Reward Margins to Select Preferences for Alignment?(https://arxiv.org/abs/2503.01864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Preference learning is critical for aligning large language models (LLMs) with human values, with the quality of preference datasets playing a crucial role in this process. While existing metrics primarily assess data quality based on either explicit or implicit reward margins, they often provide contradictory evaluations for the same data. To address this issue, we introduce the alignment potential metric, which quantifies the gap from the model's current implicit reward margin to the target explicit reward margin, thereby estimating the model's potential to align with the preference data. Empirical results demonstrate that training on data selected by this metric consistently enhances alignment performance, surpassing existing metrics across different base models and optimization objectives. Furthermore, our method extends to self-play data generation frameworks, where the metric is used to identify high-quality data within the self-generated content by LLMs. Under this data generation scenario, our method surpasses current state-of-the-art (SOTA) results across various training settings and demonstrates continuous improvements in alignment performance as dataset size and training iterations increase.</li>
</ul>

<h3>Title: Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints</h3>
<ul>
<li><strong>Authors: </strong>Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01865">https://arxiv.org/abs/2503.01865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01865">https://arxiv.org/pdf/2503.01865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01865]] Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints(https://arxiv.org/abs/2503.01865)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Jailbreaking attacks can effectively induce unsafe behaviors in Large Language Models (LLMs); however, the transferability of these attacks across different models remains limited. This study aims to understand and enhance the transferability of gradient-based jailbreaking methods, which are among the standard approaches for attacking white-box models. Through a detailed analysis of the optimization process, we introduce a novel conceptual framework to elucidate transferability and identify superfluous constraints-specifically, the response pattern constraint and the token tail constraint-as significant barriers to improved transferability. Removing these unnecessary constraints substantially enhances the transferability and controllability of gradient-based attacks. Evaluated on Llama-3-8B-Instruct as the source model, our method increases the overall Transfer Attack Success Rate (T-ASR) across a set of target models with varying safety levels from 18.4% to 50.3%, while also improving the stability and controllability of jailbreak behaviors on both source and target models.</li>
</ul>

<h3>Title: Systems and Algorithms for Convolutional Multi-Hybrid Language Models at Scale</h3>
<ul>
<li><strong>Authors: </strong>Jerome Ku, Eric Nguyen, David W. Romero, Garyk Brixi, Brandon Yang, Anton Vorontsov, Ali Taghibakhshi, Amy X. Lu, Dave P. Burke, Greg Brockman, Stefano Massaroli, Christopher Ré, Patrick D. Hsu, Brian L. Hie, Stefano Ermon, Michael Poli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01868">https://arxiv.org/abs/2503.01868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01868">https://arxiv.org/pdf/2503.01868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01868]] Systems and Algorithms for Convolutional Multi-Hybrid Language Models at Scale(https://arxiv.org/abs/2503.01868)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce convolutional multi-hybrid architectures, with a design grounded on two simple observations. First, operators in hybrid models can be tailored to token manipulation tasks such as in-context recall, multi-token recall, and compression, with input-dependent convolutions and attention offering complementary performance. Second, co-designing convolution operators and hardware-aware algorithms enables efficiency gains in regimes where previous alternative architectures struggle to surpass Transformers. At the 40 billion parameter scale, we train end-to-end 1.2 to 2.9 times faster than optimized Transformers, and 1.1 to 1.4 times faster than previous generation hybrids. On H100 GPUs and model width 4096, individual operators in the proposed multi-hybrid StripedHyena 2 architecture achieve two-fold throughput improvement over linear attention and state-space models. Multi-hybrids excel at sequence modeling over byte-tokenized data, as demonstrated by the Evo 2 line of models. We discuss the foundations that enable these results, including architecture design, overlap-add blocked kernels for tensor cores, and dedicated all-to-all and point-to-point context parallelism strategies.</li>
</ul>

<h3>Title: From Small to Large Language Models: Revisiting the Federalist Papers</h3>
<ul>
<li><strong>Authors: </strong>So Won Jeong, Veronika Rockova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01869">https://arxiv.org/abs/2503.01869</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01869">https://arxiv.org/pdf/2503.01869</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01869]] From Small to Large Language Models: Revisiting the Federalist Papers(https://arxiv.org/abs/2503.01869)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>For a long time, the authorship of the Federalist Papers had been a subject of inquiry and debate, not only by linguists and historians but also by statisticians. In what was arguably the first Bayesian case study, Mosteller and Wallace (1963) provided the first statistical evidence for attributing all disputed papers to Madison. Our paper revisits this historical dataset but from a lens of modern language models, both small and large. We review some of the more popular Large Language Model (LLM) tools and examine them from a statistical point of view in the context of text classification. We investigate whether, without any attempt to fine-tune, the general embedding constructs can be useful for stylometry and attribution. We explain differences between various word/phrase embeddings and discuss how to aggregate them in a document. Contrary to our expectations, we exemplify that dimension expansion with word embeddings may not always be beneficial for attribution relative to dimension reduction with topic embeddings. Our experiments demonstrate that default LLM embeddings (even after manual fine-tuning) may not consistently improve authorship attribution accuracy. Instead, Bayesian analysis with topic embeddings trained on ``function words" yields superior out-of-sample classification performance. This suggests that traditional (small) statistical language models, with their interpretability and solid theoretical foundation, can offer significant advantages in authorship attribution tasks. The code used in this analysis is available at this http URL</li>
</ul>

<h3>Title: Can Large Language Models Extract Customer Needs as well as Professional Analysts?</h3>
<ul>
<li><strong>Authors: </strong>Artem Timoshenko, Chengfeng Mao, John R. Hauser</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01870">https://arxiv.org/abs/2503.01870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01870">https://arxiv.org/pdf/2503.01870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01870]] Can Large Language Models Extract Customer Needs as well as Professional Analysts?(https://arxiv.org/abs/2503.01870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Identifying customer needs (CNs) is important for product management, product development, and marketing. Applications rely on professional analysts interpreting textual data (e.g., interview transcripts, online reviews) to understand the nuances of customer experience and concisely formulate "jobs to be done." The task is cognitively complex and time-consuming. Current practice facilitates the process with keyword search and machine learning but relies on human judgment to formulate CNs. We examine whether Large Language Models (LLMs) can automatically extract CNs. Because evaluating CNs requires professional judgment, we partnered with a marketing consulting firm to conduct a blind study of CNs extracted by: (1) a foundational LLM with prompt engineering only (Base LLM), (2) an LLM fine-tuned with professionally identified CNs (SFT LLM), and (3) professional analysts. The SFT LLM performs as well as or better than professional analysts when extracting CNs. The extracted CNs are well-formulated, sufficiently specific to identify opportunities, and justified by source content (no hallucinations). The SFT LLM is efficient and provides more complete coverage of CNs. The Base LLM was not sufficiently accurate or specific. Organizations can rely on SFT LLMs to reduce manual effort, enhance the precision of CN articulation, and provide improved insight for innovation and marketing strategy.</li>
</ul>

<h3>Title: Data Augmentation for Instruction Following Policies via Trajectory Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Niklas Höpner, Ilaria Tiddi, Herke van Hoof</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01871">https://arxiv.org/abs/2503.01871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01871">https://arxiv.org/pdf/2503.01871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01871]] Data Augmentation for Instruction Following Policies via Trajectory Segmentation(https://arxiv.org/abs/2503.01871)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The scalability of instructable agents in robotics or gaming is often hindered by limited data that pairs instructions with agent trajectories. However, large datasets of unannotated trajectories containing sequences of various agent behaviour (play trajectories) are often available. In a semi-supervised setup, we explore methods to extract labelled segments from play trajectories. The goal is to augment a small annotated dataset of instruction-trajectory pairs to improve the performance of an instruction-following policy trained downstream via imitation learning. Assuming little variation in segment length, recent video segmentation methods can effectively extract labelled segments. To address the constraint of segment length, we propose Play Segmentation (PS), a probabilistic model that finds maximum likely segmentations of extended subsegments, while only being trained on individual instruction segments. Our results in a game environment and a simulated robotic gripper setting underscore the importance of segmentation; randomly sampled segments diminish performance, while incorporating labelled segments from PS improves policy performance to the level of a policy trained on twice the amount of labelled data.</li>
</ul>

<h3>Title: FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance</h3>
<ul>
<li><strong>Authors: </strong>Mintong Kang, Vinayshekhar Bannihatti Kumar, Shamik Roy, Abhishek Kumar, Sopan Khosla, Balakrishnan Murali Narayanaswamy, Rashmi Gangadharaiah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01872">https://arxiv.org/abs/2503.01872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01872">https://arxiv.org/pdf/2503.01872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01872]] FairGen: Controlling Sensitive Attributes for Fair Generations in Diffusion Models via Adaptive Latent Guidance(https://arxiv.org/abs/2503.01872)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models often exhibit biases toward specific demographic groups, such as generating more males than females when prompted to generate images of engineers, raising ethical concerns and limiting their adoption. In this paper, we tackle the challenge of mitigating generation bias towards any target attribute value (e.g., "male" for "gender") in diffusion models while preserving generation quality. We propose FairGen, an adaptive latent guidance mechanism which controls the generation distribution during inference. In FairGen, a latent guidance module dynamically adjusts the diffusion process to enforce specific attributes, while a memory module tracks the generation statistics and steers latent guidance to align with the targeted fair distribution of the attribute values. Further, given the limitations of existing datasets in comprehensively assessing bias in diffusion models, we introduce a holistic bias evaluation benchmark HBE, covering diverse domains and incorporating complex prompts across various applications. Extensive evaluations on HBE and Stable Bias datasets demonstrate that FairGen outperforms existing bias mitigation approaches, achieving substantial bias reduction (e.g., 68.5% gender bias reduction on Stable Diffusion 2). Ablation studies highlight FairGen's ability to flexibly and precisely control generation distribution at any user-specified granularity, ensuring adaptive and targeted bias mitigation.</li>
</ul>

<h3>Title: Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis</h3>
<ul>
<li><strong>Authors: </strong>Long Cheng, Qichen Liao, Fan Wu, Junlin Mu, Tengfei Han, Zhe Qiu, Lianqiang Li, Tianyi Liu, Fangzheng Miao, Keming Gao, Liang Wang, Zhen Zhang, Qiande Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.PF, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01873">https://arxiv.org/abs/2503.01873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01873">https://arxiv.org/pdf/2503.01873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01873]] Online Pseudo-average Shifting Attention(PASA) for Robust Low-precision LLM Inference: Algorithms and Numerical Analysis(https://arxiv.org/abs/2503.01873)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Attention calculation is extremely time-consuming for long-sequence inference tasks, such as text or image/video generation, in large models. To accelerate this process, we developed a low-precision, mathematically-equivalent algorithm called PASA, based on Flash Attention. PASA introduces two novel techniques: online pseudo-average shifting and global recovering. These techniques enable the use of half-precision computation throughout the Flash Attention process without incurring overflow instability or unacceptable numerical accuracy loss. This algorithm enhances performance on memory-restricted AI hardware architectures, such as the Ascend Neural-network Processing Unit(NPU), by reducing data movement and increasing computational FLOPs. The algorithm is validated using both designed random benchmarks and real large models. We find that the large bias and amplitude of attention input data are critical factors contributing to numerical overflow ($>65504$ for half precision) in two different categories of large models (Qwen2-7B language models and Stable-Video-Diffusion multi-modal models). Specifically, overflow arises due to the large bias in the sequence dimension and the resonance mechanism between the query and key in the head dimension of the Stable-Video-Diffusion models. The resonance mechanism is defined as phase coincidence or 180-degree phase shift between query and key matrices. It will remarkably amplify the element values of attention score matrix. This issue also applies to the Qwen models. Additionally, numerical accuracy is assessed through root mean square error (RMSE) and by comparing the final generated texts and videos to those produced using high-precision attention.</li>
</ul>

<h3>Title: Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01875">https://arxiv.org/abs/2503.01875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01875">https://arxiv.org/pdf/2503.01875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01875]] Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement(https://arxiv.org/abs/2503.01875)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Time series data are foundational in finance, healthcare, and energy domains. However, most existing methods and datasets remain focused on a narrow spectrum of tasks, such as forecasting or anomaly detection. To bridge this gap, we introduce Time Series Multi-Task Question Answering (Time-MQA), a unified framework that enables natural language queries across multiple time series tasks - numerical analytical tasks and open-ended question answering with reasoning. Central to Time-MQA is the TSQA dataset, a large-scale dataset containing $\sim$200k question-answer pairs derived from diverse time series spanning environment, traffic, etc. This comprehensive resource covers various time series lengths and promotes robust model development. We further demonstrate how continually pre-training large language models (Mistral 7B, Llama-3 8B, and Qwen-2.5 7B) on the TSQA dataset enhanced time series reasoning capabilities, moving beyond mere numeric tasks and enabling more advanced and intuitive interactions with temporal data. The complete TSQA dataset, models, executable codes, user study questionnaires for evaluation, and results have all been open-sourced.</li>
</ul>

<h3>Title: Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zhanpeng He, Yifeng Cao, Matei Ciocarlie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01876">https://arxiv.org/abs/2503.01876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01876">https://arxiv.org/pdf/2503.01876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01876]] Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models(https://arxiv.org/abs/2503.01876)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Human-in-the-loop (HitL) robot deployment has gained significant attention in both academia and industry as a semi-autonomous paradigm that enables human operators to intervene and adjust robot behaviors at deployment time, improving success rates. However, continuous human monitoring and intervention can be highly labor-intensive and impractical when deploying a large number of robots. To address this limitation, we propose a method that allows diffusion policies to actively seek human assistance only when necessary, reducing reliance on constant human oversight. To achieve this, we leverage the generative process of diffusion policies to compute an uncertainty-based metric based on which the autonomous agent can decide to request operator assistance at deployment time, without requiring any operator interaction during training. Additionally, we show that the same method can be used for efficient data collection for fine-tuning diffusion policies in order to improve their autonomous performance. Experimental results from simulated and real-world environments demonstrate that our approach enhances policy performance during deployment for a variety of scenarios.</li>
</ul>

<h3>Title: Starjob: Dataset for LLM-Driven Job Shop Scheduling</h3>
<ul>
<li><strong>Authors: </strong>Henrik Abgaryan, Tristan Cazenave, Ararat Harutyunyan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01877">https://arxiv.org/abs/2503.01877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01877">https://arxiv.org/pdf/2503.01877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01877]] Starjob: Dataset for LLM-Driven Job Shop Scheduling(https://arxiv.org/abs/2503.01877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown remarkable capabilities across various domains, but their potential for solving combinatorial optimization problems remains largely unexplored. In this paper, we investigate the applicability of LLMs to the Job Shop Scheduling Problem (JSSP), a classic challenge in combinatorial optimization that requires efficient job allocation to machines to minimize makespan. To this end, we introduce Starjob, the first supervised dataset for JSSP, comprising 130k instances specifically designed for training LLMs. Leveraging this dataset, we fine-tune the LLaMA 8B 4-bit quantized model with the LoRA method to develop an end-to-end scheduling approach. Our evaluation on standard benchmarks demonstrates that the proposed LLM-based method not only surpasses traditional Priority Dispatching Rules (PDRs) but also achieves notable improvements over state-of-the-art neural approaches like L2D, with an average improvement of 15.36% on DMU and 7.85% on Taillard benchmarks. These results highlight the untapped potential of LLMs in tackling combinatorial optimization problems, paving the way for future advancements in this area.</li>
</ul>

<h3>Title: BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor</h3>
<ul>
<li><strong>Authors: </strong>Mohammed-Khalil Ghali, Abdelrahman Farrag, Sarah Lam, Daehan Won</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01880">https://arxiv.org/abs/2503.01880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01880">https://arxiv.org/pdf/2503.01880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01880]] BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor(https://arxiv.org/abs/2503.01880)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Thematic analysis of social media posts provides a major understanding of public discourse, yet traditional methods often struggle to capture the complexity and nuance of unstructured, large-scale text data. This study introduces a novel methodology for thematic analysis that integrates tweet embeddings from pre-trained language models, dimensionality reduction using and matrix factorization, and generative AI to identify and refine latent themes. Our approach clusters compressed tweet representations and employs generative AI to extract and articulate themes through an agentic Chain of Thought (CoT) prompting, with a secondary LLM for quality assurance. This methodology is applied to tweets from the autistic community, a group that increasingly uses social media to discuss their experiences and challenges. By automating the thematic extraction process, the aim is to uncover key insights while maintaining the richness of the original discourse. This autism case study demonstrates the utility of the proposed approach in improving thematic analysis of social media data, offering a scalable and adaptable framework that can be applied to diverse contexts. The results highlight the potential of combining machine learning and Generative AI to enhance the depth and accuracy of theme identification in online communities.</li>
</ul>

<h3>Title: Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching</h3>
<ul>
<li><strong>Authors: </strong>Antonio Pio Ricciardi, Valentino Maiorca, Luca Moschella, Riccardo Marin, Emanuele Rodolà</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01881">https://arxiv.org/abs/2503.01881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01881">https://arxiv.org/pdf/2503.01881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01881]] Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching(https://arxiv.org/abs/2503.01881)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep Reinforcement Learning (RL) models often fail to generalize when even small changes occur in the environment's observations or task requirements. Addressing these shifts typically requires costly retraining, limiting the reusability of learned policies. In this paper, we build on recent work in semantic alignment to propose a zero-shot method for mapping between latent spaces across different agents trained on different visual and task variations. Specifically, we learn a transformation that maps embeddings from one agent's encoder to another agent's encoder without further fine-tuning. Our approach relies on a small set of "anchor" observations that are semantically aligned, which we use to estimate an affine or orthogonal transform. Once the transformation is found, an existing controller trained for one domain can interpret embeddings from a different (existing) encoder in a zero-shot fashion, skipping additional trainings. We empirically demonstrate that our framework preserves high performance under visual and task domain shifts. We empirically demonstrate zero-shot stitching performance on the CarRacing environment with changing background and task. By allowing modular re-assembly of existing policies, it paves the way for more robust, compositional RL in dynamically changing environments.</li>
</ul>

<h3>Title: Constructing balanced datasets for predicting failure modes in structural systems under seismic hazards</h3>
<ul>
<li><strong>Authors: </strong>Jungho Kim, Taeyong Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01882">https://arxiv.org/abs/2503.01882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01882">https://arxiv.org/pdf/2503.01882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01882]] Constructing balanced datasets for predicting failure modes in structural systems under seismic hazards(https://arxiv.org/abs/2503.01882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate prediction of structural failure modes under seismic excitations is essential for seismic risk and resilience assessment. Traditional simulation-based approaches often result in imbalanced datasets dominated by non-failure or frequently observed failure scenarios, limiting the effectiveness in machine learning-based prediction. To address this challenge, this study proposes a framework for constructing balanced datasets that include distinct failure modes. The framework consists of three key steps. First, critical ground motion features (GMFs) are identified to effectively represent ground motion time histories. Second, an adaptive algorithm is employed to estimate the probability densities of various failure domains in the space of critical GMFs and structural parameters. Third, samples generated from these probability densities are transformed into ground motion time histories by using a scaling factor optimization process. A balanced dataset is constructed by performing nonlinear response history analyses on structural systems with parameters matching the generated samples, subjected to corresponding transformed ground motion time histories. Deep neural network models are trained on balanced and imbalanced datasets to highlight the importance of dataset balancing. To further evaluate the framework's applicability, numerical investigations are conducted using two different structural models subjected to recorded and synthetic ground motions. The results demonstrate the framework's robustness and effectiveness in addressing dataset imbalance and improving machine learning performance in seismic failure mode prediction.</li>
</ul>

<h3>Title: Learning Surrogates for Offline Black-Box Optimization via Gradient Matching</h3>
<ul>
<li><strong>Authors: </strong>Minh Hoang, Azza Fadhel, Aryan Deshwal, Janardhan Rao Doppa, Trong Nghia Hoang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01883">https://arxiv.org/abs/2503.01883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01883">https://arxiv.org/pdf/2503.01883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01883]] Learning Surrogates for Offline Black-Box Optimization via Gradient Matching(https://arxiv.org/abs/2503.01883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Offline design optimization problem arises in numerous science and engineering applications including material and chemical design, where expensive online experimentation necessitates the use of in silico surrogate functions to predict and maximize the target objective over candidate designs. Although these surrogates can be learned from offline data, their predictions are often inaccurate outside the offline data regime. This challenge raises a fundamental question about the impact of imperfect surrogate model on the performance gap between its optima and the true optima, and to what extent the performance loss can be mitigated. Although prior work developed methods to improve the robustness of surrogate models and their associated optimization processes, a provably quantifiable relationship between an imperfect surrogate and the corresponding performance gap, as well as whether prior methods directly address it, remain elusive. To shed light on this important question, we present a theoretical framework to understand offline black-box optimization, by explicitly bounding the optimization quality based on how well the surrogate matches the latent gradient field that underlines the offline data. Inspired by our theoretical analysis, we propose a principled black-box gradient matching algorithm to create effective surrogate models for offline optimization, improving over prior approaches on various real-world benchmarks.</li>
</ul>

<h3>Title: When Continue Learning Meets Multimodal Large Language Model: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Yukang Huo, Hao Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01887">https://arxiv.org/abs/2503.01887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01887">https://arxiv.org/pdf/2503.01887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01887]] When Continue Learning Meets Multimodal Large Language Model: A Survey(https://arxiv.org/abs/2503.01887)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Artificial Intelligence have led to the development of Multimodal Large Language Models (MLLMs). However, adapting these pre-trained models to dynamic data distributions and various tasks efficiently remains a challenge. Fine-tuning MLLMs for specific tasks often causes performance degradation in the model's prior knowledge domain, a problem known as 'Catastrophic Forgetting'. While this issue has been well-studied in the Continual Learning (CL) community, it presents new challenges for MLLMs. This review paper, the first of its kind in MLLM continual learning, presents an overview and analysis of 440 research papers in this this http URL review is structured into four sections. First, it discusses the latest research on MLLMs, covering model innovations, benchmarks, and applications in various fields. Second, it categorizes and overviews the latest studies on continual learning, divided into three parts: non-large language models unimodal continual learning (Non-LLM Unimodal CL), non-large language models multimodal continual learning (Non-LLM Multimodal CL), and continual learning in large language models (CL in LLM). The third section provides a detailed analysis of the current state of MLLM continual learning research, including benchmark evaluations, architectural innovations, and a summary of theoretical and empirical this http URL, the paper discusses the challenges and future directions of continual learning in MLLMs, aiming to inspire future research and development in the field. This review connects the foundational concepts, theoretical insights, method innovations, and practical applications of continual learning for multimodal large models, providing a comprehensive understanding of the research progress and challenges in this field, aiming to inspire researchers in the field and promote the advancement of related technologies.</li>
</ul>

<h3>Title: Enhancing Transformer with GNN Structural Knowledge via Distillation: A Novel Approach</h3>
<ul>
<li><strong>Authors: </strong>Zhihua Duan, Jialin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01888">https://arxiv.org/abs/2503.01888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01888">https://arxiv.org/pdf/2503.01888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01888]] Enhancing Transformer with GNN Structural Knowledge via Distillation: A Novel Approach(https://arxiv.org/abs/2503.01888)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Integrating the structural inductive biases of Graph Neural Networks (GNNs) with the global contextual modeling capabilities of Transformers represents a pivotal challenge in graph representation learning. While GNNs excel at capturing localized topological patterns through message-passing mechanisms, their inherent limitations in modeling long-range dependencies and parallelizability hinder their deployment in large-scale scenarios. Conversely, Transformers leverage self-attention mechanisms to achieve global receptive fields but struggle to inherit the intrinsic graph structural priors of GNNs. This paper proposes a novel knowledge distillation framework that systematically transfers multiscale structural knowledge from GNN teacher models to Transformer student models, offering a new perspective on addressing the critical challenges in cross-architectural distillation. The framework effectively bridges the architectural gap between GNNs and Transformers through micro-macro distillation losses and multiscale feature alignment. This work establishes a new paradigm for inheriting graph structural biases in Transformer architectures, with broad application prospects.</li>
</ul>

<h3>Title: AutoHete: An Automatic and Efficient Heterogeneous Training System for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zihao Zeng, Chubo Liu, Xin He, Juan Hu, Yong Jiang, Fei Huang, Kenli Li, Wei Yang Bryan Lim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01890">https://arxiv.org/abs/2503.01890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01890">https://arxiv.org/pdf/2503.01890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01890]] AutoHete: An Automatic and Efficient Heterogeneous Training System for LLMs(https://arxiv.org/abs/2503.01890)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer-based large language models (LLMs) have demonstrated exceptional capabilities in sequence modeling and text generation, with improvements scaling proportionally with model size. However, the limitations of GPU memory have restricted LLM training accessibility for many researchers. Existing heterogeneous training methods significantly expand the scale of trainable models but introduce substantial communication overheads and CPU workloads. In this work, we propose AutoHete, an automatic and efficient heterogeneous training system compatible with both single-GPU and multi-GPU environments. AutoHete dynamically adjusts activation checkpointing, parameter offloading, and optimizer offloading based on the specific hardware configuration and LLM training needs. Additionally, we design a priority-based scheduling mechanism that maximizes the overlap between operations across training iterations, enhancing throughput. Compared to state-of-the-art heterogeneous training systems, AutoHete delivers a 1.32x~1.91x throughput improvement across various model sizes and training configurations.</li>
</ul>

<h3>Title: MMSciBench: Benchmarking Language Models on Multimodal Scientific Problems</h3>
<ul>
<li><strong>Authors: </strong>Xinwu Ye, Chengfan Li, Siming Chen, Xiangru Tang, Wei Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01891">https://arxiv.org/abs/2503.01891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01891">https://arxiv.org/pdf/2503.01891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01891]] MMSciBench: Benchmarking Language Models on Multimodal Scientific Problems(https://arxiv.org/abs/2503.01891)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) and vision-language models (LVLMs) have shown promise across many tasks, yet their scientific reasoning capabilities remain untested, particularly in multimodal settings. We present MMSciBench, a benchmark for evaluating mathematical and physical reasoning through text-only and text-image formats, with human-annotated difficulty levels, solutions with detailed explanations, and taxonomic mappings. Evaluation of state-of-the-art models reveals significant limitations, with even the best model achieving only \textbf{63.77\%} accuracy and particularly struggling with visual reasoning tasks. Our analysis exposes critical gaps in complex reasoning and visual-textual integration, establishing MMSciBench as a rigorous standard for measuring progress in multimodal scientific understanding. The code for MMSciBench is open-sourced at GitHub, and the dataset is available at Hugging Face.</li>
</ul>

<h3>Title: Recognition of Dysarthria in Amyotrophic Lateral Sclerosis patients using Hypernetworks</h3>
<ul>
<li><strong>Authors: </strong>Loukas Ilias, Dimitris Askounis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01892">https://arxiv.org/abs/2503.01892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01892">https://arxiv.org/pdf/2503.01892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01892]] Recognition of Dysarthria in Amyotrophic Lateral Sclerosis patients using Hypernetworks(https://arxiv.org/abs/2503.01892)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, generative</a></li>
<li><strong>Abstract: </strong>Amyotrophic Lateral Sclerosis (ALS) constitutes a progressive neurodegenerative disease with varying symptoms, including decline in speech intelligibility. Existing studies, which recognize dysarthria in ALS patients by predicting the clinical standard ALSFRS-R, rely on feature extraction strategies and the design of customized convolutional neural networks followed by dense layers. However, recent studies have shown that neural networks adopting the logic of input-conditional computations enjoy a series of benefits, including faster training, better performance, and flexibility. To resolve these issues, we present the first study incorporating hypernetworks for recognizing dysarthria. Specifically, we use audio files, convert them into log-Mel spectrogram, delta, and delta-delta, and pass the resulting image through a pretrained modified AlexNet model. Finally, we use a hypernetwork, which generates weights for a target network. Experiments are conducted on a newly collected publicly available dataset, namely VOC-ALS. Results showed that the proposed approach reaches Accuracy up to 82.66% outperforming strong baselines, including multimodal fusion methods, while findings from an ablation study demonstrated the effectiveness of the introduced methodology. Overall, our approach incorporating hypernetworks obtains valuable advantages over state-of-the-art results in terms of generalization ability, parameter efficiency, and robustness.</li>
</ul>

<h3>Title: LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces</h3>
<ul>
<li><strong>Authors: </strong>Rashid Mushkani, Shravan Nayak, Hugo Berard, Allison Cohen, Shin Koseki, Hadrien Bertrand</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01894">https://arxiv.org/abs/2503.01894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01894">https://arxiv.org/pdf/2503.01894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01894]] LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces(https://arxiv.org/abs/2503.01894)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce the Local Intersectional Visual Spaces (LIVS) dataset, a benchmark for multi-criteria alignment of text-to-image (T2I) models in inclusive urban planning. Developed through a two-year participatory process with 30 community organizations, LIVS encodes diverse spatial preferences across 634 initial concepts, consolidated into six core criteria: Accessibility, Safety, Comfort, Invitingness, Inclusivity, and Diversity, through 37,710 pairwise comparisons. Using Direct Preference Optimization (DPO) to fine-tune Stable Diffusion XL, we observed a measurable increase in alignment with community preferences, though a significant proportion of neutral ratings highlights the complexity of modeling intersectional needs. Additionally, as annotation volume increases, accuracy shifts further toward the DPO-tuned model, suggesting that larger-scale preference data enhances fine-tuning effectiveness. LIVS underscores the necessity of integrating context-specific, stakeholder-driven criteria into generative modeling and provides a resource for evaluating AI alignment methodologies across diverse socio-spatial contexts.</li>
</ul>

<h3>Title: Evaluating System 1 vs. 2 Reasoning Approaches for Zero-Shot Time-Series Forecasting: A Benchmark and Insights</h3>
<ul>
<li><strong>Authors: </strong>Haoxin Liu, Zhiyuan Zhao, Shiduo Li, B. Aditya Prakash</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01895">https://arxiv.org/abs/2503.01895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01895">https://arxiv.org/pdf/2503.01895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01895]] Evaluating System 1 vs. 2 Reasoning Approaches for Zero-Shot Time-Series Forecasting: A Benchmark and Insights(https://arxiv.org/abs/2503.01895)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning ability is crucial for solving challenging tasks. With the advancement of foundation models, such as the emergence of large language models (LLMs), a wide range of reasoning strategies has been proposed, including test-time enhancements, such as Chain-ofThought, and post-training optimizations, as used in DeepSeek-R1. While these reasoning strategies have demonstrated effectiveness across various challenging language or vision tasks, their applicability and impact on time-series forecasting (TSF), particularly the challenging zero-shot TSF, remain largely unexplored. In particular, it is unclear whether zero-shot TSF benefits from reasoning and, if so, what types of reasoning strategies are most effective. To bridge this gap, we propose ReC4TS, the first benchmark that systematically evaluates the effectiveness of popular reasoning strategies when applied to zero-shot TSF tasks. ReC4TS conducts comprehensive evaluations across datasets spanning eight domains, covering both unimodal and multimodal with short-term and longterm forecasting tasks. More importantly, ReC4TS provides key insights: (1) Self-consistency emerges as the most effective test-time reasoning strategy; (2) Group-relative policy optimization emerges as a more suitable approach for incentivizing reasoning ability during post-training; (3) Multimodal TSF benefits more from reasoning strategies compared to unimodal TSF. Beyond these insights, ReC4TS establishes two pioneering starting blocks to support future zero-shot TSF reasoning research: (1) A novel dataset, TimeThinking, containing forecasting samples annotated with reasoning trajectories from multiple advanced LLMs, and (2) A new and simple test-time scaling-law validated on foundational TSF models enabled by self-consistency reasoning strategy. All data and code are publicly accessible at: this https URL</li>
</ul>

<h3>Title: VAEs and GANs: Implicitly Approximating Complex Distributions with Simple Base Distributions and Deep Neural Networks -- Principles, Necessity, and Limitations</h3>
<ul>
<li><strong>Authors: </strong>Yuan-Hao Wei</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01898">https://arxiv.org/abs/2503.01898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01898">https://arxiv.org/pdf/2503.01898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01898]] VAEs and GANs: Implicitly Approximating Complex Distributions with Simple Base Distributions and Deep Neural Networks -- Principles, Necessity, and Limitations(https://arxiv.org/abs/2503.01898)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>This tutorial focuses on the fundamental architectures of Variational Autoencoders (VAE) and Generative Adversarial Networks (GAN), disregarding their numerous variations, to highlight their core principles. Both VAE and GAN utilize simple distributions, such as Gaussians, as a basis and leverage the powerful nonlinear transformation capabilities of neural networks to approximate arbitrarily complex distributions. The theoretical basis lies in that a linear combination of multiple Gaussians can almost approximate any probability distribution, while neural networks enable further refinement through nonlinear transformations. Both methods approximate complex data distributions implicitly. This implicit approximation is crucial because directly modeling high-dimensional distributions explicitly is often intractable. However, the choice of a simple latent prior, while computationally convenient, introduces limitations. In VAEs, the fixed Gaussian prior forces the posterior distribution to align with it, potentially leading to loss of information and reduced expressiveness. This restriction affects both the interpretability of the model and the quality of generated samples.</li>
</ul>

<h3>Title: FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Dang, Zaipeng Duan, Pei An, Xinmin Zhang, Xuzhong Hu, Jie Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01899">https://arxiv.org/abs/2503.01899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01899">https://arxiv.org/pdf/2503.01899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01899]] FASTer: Focal Token Acquiring-and-Scaling Transformer for Long-term 3D Object Detection(https://arxiv.org/abs/2503.01899)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Recent top-performing temporal 3D detectors based on Lidars have increasingly adopted region-based paradigms. They first generate coarse proposals, followed by encoding and fusing regional features. However, indiscriminate sampling and fusion often overlook the varying contributions of individual points and lead to exponentially increased complexity as the number of input frames grows. Moreover, arbitrary result-level concatenation limits the global information extraction. In this paper, we propose a Focal Token Acquring-and-Scaling Transformer (FASTer), which dynamically selects focal tokens and condenses token sequences in an adaptive and lightweight manner. Emphasizing the contribution of individual tokens, we propose a simple but effective Adaptive Scaling mechanism to capture geometric contexts while sifting out focal points. Adaptively storing and processing only focal points in historical frames dramatically reduces the overall complexity. Furthermore, a novel Grouped Hierarchical Fusion strategy is proposed, progressively performing sequence scaling and Intra-Group Fusion operations to facilitate the exchange of global spatial and temporal information. Experiments on the Waymo Open Dataset demonstrate that our FASTer significantly outperforms other state-of-the-art detectors in both performance and efficiency while also exhibiting improved flexibility and robustness. The code is available at this https URL.</li>
</ul>

<h3>Title: LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Ma, Yiyue Qian, Zehong Wang, Zheyuan Zhang, Chuxu Zhang, Yanfang Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01900">https://arxiv.org/abs/2503.01900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01900">https://arxiv.org/pdf/2503.01900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01900]] LLM-Empowered Class Imbalanced Graph Prompt Learning for Online Drug Trafficking Detection(https://arxiv.org/abs/2503.01900)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the market for illicit drugs remains extremely profitable, major online platforms have become direct-to-consumer intermediaries for illicit drug trafficking participants. These online activities raise significant social concerns that require immediate actions. Existing approaches to combating this challenge are generally impractical, due to the imbalance of classes and scarcity of labeled samples in real-world applications. To this end, we propose a novel Large Language Model-empowered Heterogeneous Graph Prompt Learning framework for illicit Drug Trafficking detection, called LLM-HetGDT, that leverages LLM to facilitate heterogeneous graph neural networks (HGNNs) to effectively identify drug trafficking activities in the class-imbalanced scenarios. Specifically, we first pre-train HGNN over a contrastive pretext task to capture the inherent node and structure information over the unlabeled drug trafficking heterogeneous graph (HG). Afterward, we employ LLM to augment the HG by generating high-quality synthetic user nodes in minority classes. Then, we fine-tune the soft prompts on the augmented HG to capture the important information in the minority classes for the downstream drug trafficking detection task. To comprehensively study online illicit drug trafficking activities, we collect a new HG dataset over Twitter, called Twitter-HetDrug. Extensive experiments on this dataset demonstrate the effectiveness, efficiency, and applicability of LLM-HetGDT.</li>
</ul>

<h3>Title: Identifying Sensitive Weights via Post-quantization Integral</h3>
<ul>
<li><strong>Authors: </strong>Yuezhou Hu, Weiyu Huang, Zichen Liang, Chang Chen, Jintao Zhang, Jun Zhu, Jianfei Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01901">https://arxiv.org/abs/2503.01901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01901">https://arxiv.org/pdf/2503.01901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01901]] Identifying Sensitive Weights via Post-quantization Integral(https://arxiv.org/abs/2503.01901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Serving Large Language Models (LLMs) is costly. However, post-training weight quantization can address this problem by both compressing their sizes for limited memory and saving bandwidth for acceleration. As not all weight dimensions are equally important, those methods typically rely on a sensitivity metric, which indicates the element-wise influence of weights on loss function and is used to preprocess original weights for better quantization. In this work, we conduct an empirical study on the accuracy of the sensitivity metric, and find that existing gradient and Hessian based metrics are very inaccurate: they underestimate quantization's impact on the loss function by orders of magnitude, mainly due to the small convergence radius of local 2nd order approximation, \ie, gradient and Hessian term in Taylor's formula. To tackle this problem, we propose Post-quantization Integral (PQI), an accurate metric to estimate posterior sensitivity in a fine-grained manner. To leverage this accurate metric, we further propose ReQuant, a simple yet powerful framework that mainly consists of two Dense-and-Sparse detach components: self-adaptive outlier selection and step-wise significant weights detach. Results show that ReQuant boosts state-of-the-art post-training quantization methods, with a pronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP.</li>
</ul>

<h3>Title: An Empirical Analysis of LLMs for Countering Misinformation</h3>
<ul>
<li><strong>Authors: </strong>Adiba Mahbub Proma, Neeley Pate, James Druckman, Gourab Ghoshal, Hangfeng He, Ehsan Hoque</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01902">https://arxiv.org/abs/2503.01902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01902">https://arxiv.org/pdf/2503.01902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01902]] An Empirical Analysis of LLMs for Countering Misinformation(https://arxiv.org/abs/2503.01902)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) can amplify online misinformation, they also show promise in tackling misinformation. In this paper, we empirically study the capabilities of three LLMs -- ChatGPT, Gemini, and Claude -- in countering political misinformation. We implement a two-step, chain-of-thought prompting approach, where models first identify credible sources for a given claim and then generate persuasive responses. Our findings suggest that models struggle to ground their responses in real news sources, and tend to prefer citing left-leaning sources. We also observe varying degrees of response diversity among models. Our findings highlight concerns about using LLMs for fact-checking through only prompt-engineering, emphasizing the need for more robust guardrails. Our results have implications for both researchers and non-technical users.</li>
</ul>

<h3>Title: PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice</h3>
<ul>
<li><strong>Authors: </strong>Ruoxi Wang, Shuyu Liu, Ling Zhang, Xuequan Zhu, Rui Yang, Xinzhu Zhou, Fei Wu, Zhi Yang, Cheng Jin, Gang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01903">https://arxiv.org/abs/2503.01903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01903">https://arxiv.org/pdf/2503.01903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01903]] PsychBench: A comprehensive and professional benchmark for evaluating the performance of LLM-assisted psychiatric clinical practice(https://arxiv.org/abs/2503.01903)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) offers potential solutions to address problems such as shortage of medical resources and low diagnostic consistency in psychiatric clinical practice. Despite this potential, a robust and comprehensive benchmarking framework to assess the efficacy of LLMs in authentic psychiatric clinical environments is absent. This has impeded the advancement of specialized LLMs tailored to psychiatric applications. In response to this gap, by incorporating clinical demands in psychiatry and clinical data, we proposed a benchmarking system, PsychBench, to evaluate the practical performance of LLMs in psychiatric clinical settings. We conducted a comprehensive quantitative evaluation of 16 LLMs using PsychBench, and investigated the impact of prompt design, chain-of-thought reasoning, input text length, and domain-specific knowledge fine-tuning on model performance. Through detailed error analysis, we identified strengths and potential limitations of the existing models and suggested directions for improvement. Subsequently, a clinical reader study involving 60 psychiatrists of varying seniority was conducted to further explore the practical benefits of existing LLMs as supportive tools for psychiatrists of varying seniority. Through the quantitative and reader evaluation, we show that while existing models demonstrate significant potential, they are not yet adequate as decision-making tools in psychiatric clinical practice. The reader study further indicates that, as an auxiliary tool, LLM could provide particularly notable support for junior psychiatrists, effectively enhancing their work efficiency and overall clinical quality. To promote research in this area, we will make the dataset and evaluation framework publicly available, with the hope of advancing the application of LLMs in psychiatric clinical settings.</li>
</ul>

<h3>Title: What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning Methods</h3>
<ul>
<li><strong>Authors: </strong>Christian Gapp, Elias Tappeiner, Martin Welk, Karl Fritscher, Elke Ruth Gizewski, Rainer Schubert</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01904">https://arxiv.org/abs/2503.01904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01904">https://arxiv.org/pdf/2503.01904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01904]] What are You Looking at? Modality Contribution in Multimodal Medical Deep Learning Methods(https://arxiv.org/abs/2503.01904)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Purpose High dimensional, multimodal data can nowadays be analyzed by huge deep neural networks with little effort. Several fusion methods for bringing together different modalities have been developed. Particularly, in the field of medicine with its presence of high dimensional multimodal patient data, multimodal models characterize the next step. However, what is yet very underexplored is how these models process the source information in detail. Methods To this end, we implemented an occlusion-based both model and performance agnostic modality contribution method that quantitatively measures the importance of each modality in the dataset for the model to fulfill its task. We applied our method to three different multimodal medical problems for experimental purposes. Results Herein we found that some networks have modality preferences that tend to unimodal collapses, while some datasets are imbalanced from the ground up. Moreover, we could determine a link between our metric and the performance of single modality trained nets. Conclusion The information gain through our metric holds remarkable potential to improve the development of multimodal models and the creation of datasets in the future. With our method we make a crucial contribution to the field of interpretability in deep learning based multimodal research and thereby notably push the integrability of multimodal AI into clinical practice. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Learning to Chain Operations by Routing Information Through a Global Workspace</h3>
<ul>
<li><strong>Authors: </strong>Hugo Chateau-Laurent, Rufin VanRullen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01906">https://arxiv.org/abs/2503.01906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01906">https://arxiv.org/pdf/2503.01906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01906]] Learning to Chain Operations by Routing Information Through a Global Workspace(https://arxiv.org/abs/2503.01906)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a model inspired by the Global Workspace Theory that integrates specialized modules to perform a sequential reasoning task. A controller selectively routes information between modules through the workspace using a gating mechanism. This approach allows the model to chain operations by iteratively broadcasting information between specialized domains, mimicking System-2 reasoning. We evaluate the model's performance on a simple addition task, where two addends must be summed. The task can be solved by routing information sequentially through an Input module, an Increment module (multiple times), and finally an Output module. We consider two implementations of this system with increasing complexity. First, using hand-designed modules operating on one-hot digit representations, the controller (a LSTM recurrent network) learns to select the appropriate modules (input, increment, output) in the appropriate sequence. Second, we replace the hand-designed modules with learned representation modules for MNIST images and an increment module trained on the task objectives; here again, the controller learns the appropriate sequential module selection to solve the task. Finally, we show that the Global Workspace model, while having fewer parameters, outperforms LSTMs and Transformers when tested on unseen addition operations (both interpolations and extrapolations of addition operations seen during training). Our results highlight the potential of architectures inspired by the Global Workspace Theory to enhance deep learning's reasoning capabilities.</li>
</ul>

<h3>Title: UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Zhang, Shuang Yang, Bo Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01908">https://arxiv.org/abs/2503.01908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01908">https://arxiv.org/pdf/2503.01908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01908]] UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning(https://arxiv.org/abs/2503.01908)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for handling complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements also amplify the risks of adversarial attacks, particularly when LLM agents can access sensitive external functionalities. Moreover, because LLM agents engage in extensive reasoning or planning before executing final actions, manipulating them into performing targeted malicious actions or invoking specific tools remains a significant challenge. Consequently, directly embedding adversarial strings in malicious instructions or injecting malicious prompts into tool interactions has become less effective against modern LLM agents. In this work, we present UDora, a unified red teaming framework designed for LLM Agents that dynamically leverages the agent's own reasoning processes to compel it toward malicious behavior. Specifically, UDora first samples the model's reasoning for the given task, then automatically identifies multiple optimal positions within these reasoning traces to insert targeted perturbations. Subsequently, it uses the modified reasoning as the objective to optimize the adversarial strings. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets.</li>
</ul>

<h3>Title: Attend or Perish: Benchmarking Attention in Algorithmic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Michal Spiegel, Michal Štefánik, Marek Kadlčík, Josef Kuchař</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01909">https://arxiv.org/abs/2503.01909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01909">https://arxiv.org/pdf/2503.01909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01909]] Attend or Perish: Benchmarking Attention in Algorithmic Reasoning(https://arxiv.org/abs/2503.01909)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Can transformers learn to perform algorithmic tasks reliably across previously unseen input/output domains? While pre-trained language models show solid accuracy on benchmarks incorporating algorithmic reasoning, assessing the reliability of these results necessitates an ability to cleanse models' functional capabilities from memorization. In this paper, we propose an algorithmic benchmark comprising six tasks of infinite input domains where we can also disentangle and trace the correct, robust algorithm necessary for the task. This allows us to assess (i) models' ability to extrapolate to unseen types of inputs, including new lengths, value ranges or input domains, but also (ii) to assess the robustness of the functional mechanism in recent models through the lens of their attention maps. We make the implementation of all our tasks and interoperability methods publicly available at this https URL .</li>
</ul>

<h3>Title: Conceptual Contrastive Edits in Textual and Vision-Language Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Maria Lymperaiou, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01914">https://arxiv.org/abs/2503.01914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01914">https://arxiv.org/pdf/2503.01914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01914]] Conceptual Contrastive Edits in Textual and Vision-Language Retrieval(https://arxiv.org/abs/2503.01914)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>As deep learning models grow in complexity, achieving model-agnostic interpretability becomes increasingly vital. In this work, we employ post-hoc conceptual contrastive edits to expose noteworthy patterns and biases imprinted in representations of retrieval models. We systematically design optimal and controllable contrastive interventions targeting various parts of speech, and effectively apply them to explain both linguistic and visiolinguistic pre-trained models in a black-box manner. Additionally, we introduce a novel metric to assess the per-word impact of contrastive interventions on model outcomes, providing a comprehensive evaluation of each intervention's effectiveness.</li>
</ul>

<h3>Title: Datenschutzkonformer LLM-Einsatz: Eine Open-Source-Referenzarchitektur</h3>
<ul>
<li><strong>Authors: </strong>Marian Lambert, Thomas Schuster, Nico Döring, Robin Krüger</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01915">https://arxiv.org/abs/2503.01915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01915">https://arxiv.org/pdf/2503.01915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01915]] Datenschutzkonformer LLM-Einsatz: Eine Open-Source-Referenzarchitektur(https://arxiv.org/abs/2503.01915)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>The development of Large Language Models (LLMs) has led to significant advancements in natural language processing and enabled numerous applications across various industries. However, many LLM-based solutions operate as open systems relying on cloud services, which pose risks to data confidentiality and security. To address these challenges, organizations require closed LLM systems that comply with data protection regulations while maintaining high performance. In this paper, we present a reference architecture for developing closed, LLM-based systems using open-source technologies. The architecture provides a flexible and transparent solution that meets strict data privacy and security requirements. We analyze the key challenges in implementing such systems, including computing resources, data management, scalability, and security risks. Additionally, we introduce an evaluation pipeline that enables a systematic assessment of system performance and compliance.</li>
</ul>

<h3>Title: NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT</h3>
<ul>
<li><strong>Authors: </strong>Jiaying Hong, Thanet Markchom, Jianfei Xu, Tong Wu, Huizhi Liang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01921">https://arxiv.org/abs/2503.01921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01921">https://arxiv.org/pdf/2503.01921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01921]] NCL-UoR at SemEval-2025 Task 3: Detecting Multilingual Hallucination and Related Observable Overgeneration Text Spans with Modified RefChecker and Modified SeflCheckGPT(https://arxiv.org/abs/2503.01921)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>SemEval-2025 Task 3 (Mu-SHROOM) focuses on detecting hallucinations in content generated by various large language models (LLMs) across multiple languages. This task involves not only identifying the presence of hallucinations but also pinpointing their specific occurrences. To tackle this challenge, this study introduces two methods: modified RefChecker and modified SelfCheckGPT. The modified RefChecker integrates prompt-based factual verification into References, structuring them as claim-based tests rather than single external knowledge sources. The modified SelfCheckGPT incorporates external knowledge to overcome its reliance on internal knowledge. In addition, both methods' original prompt designs are enhanced to identify hallucinated words within LLM-generated texts. Experimental results demonstrate the effectiveness of the approach, achieving a high ranking on the test dataset in detecting hallucinations across various languages, with an average IoU of 0.5310 and an average COR of 0.5669.</li>
</ul>

<h3>Title: Pruning Deep Neural Networks via a Combination of the Marchenko-Pastur Distribution and Regularization</h3>
<ul>
<li><strong>Authors: </strong>Leonid Berlyand, Theo Bourdais, Houman Owhadi, Yitzchak Shmalo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01922">https://arxiv.org/abs/2503.01922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01922">https://arxiv.org/pdf/2503.01922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01922]] Pruning Deep Neural Networks via a Combination of the Marchenko-Pastur Distribution and Regularization(https://arxiv.org/abs/2503.01922)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deep neural networks (DNNs) have brought significant advancements in various applications in recent years, such as image recognition, speech recognition, and natural language processing. In particular, Vision Transformers (ViTs) have emerged as a powerful class of models in the field of deep learning for image classification. In this work, we propose a novel Random Matrix Theory (RMT)-based method for pruning pre-trained DNNs, based on the sparsification of weights and singular vectors, and apply it to ViTs. RMT provides a robust framework to analyze the statistical properties of large matrices, which has been shown to be crucial for understanding and optimizing the performance of DNNs. We demonstrate that our RMT-based pruning can be used to reduce the number of parameters of ViT models (trained on ImageNet) by 30-50\% with less than 1\% loss in accuracy. To our knowledge, this represents the state-of-the-art in pruning for these ViT models. Furthermore, we provide a rigorous mathematical underpinning of the above numerical studies, namely we proved a theorem for fully connected DNNs, and other more general DNN structures, describing how the randomness in the weight matrices of a DNN decreases as the weights approach a local or global minimum (during training). We verify this theorem through numerical experiments on fully connected DNNs, providing empirical support for our theoretical findings. Moreover, we prove a theorem that describes how DNN loss decreases as we remove randomness in the weight layers, and show a monotone dependence of the decrease in loss with the amount of randomness that we remove. Our results also provide significant RMT-based insights into the role of regularization during training and pruning.</li>
</ul>

<h3>Title: Output Length Effect on DeepSeek-R1's Safety in Forced Thinking</h3>
<ul>
<li><strong>Authors: </strong>Xuying Li, Zhuo Li, Yuji Kosuga, Victor Bian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01923">https://arxiv.org/abs/2503.01923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01923">https://arxiv.org/pdf/2503.01923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01923]] Output Length Effect on DeepSeek-R1's Safety in Forced Thinking(https://arxiv.org/abs/2503.01923)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong reasoning capabilities, but their safety under adversarial conditions remains a challenge. This study examines the impact of output length on the robustness of DeepSeek-R1, particularly in Forced Thinking scenarios. We analyze responses across various adversarial prompts and find that while longer outputs can improve safety through self-correction, certain attack types exploit extended generations. Our findings suggest that output length should be dynamically controlled to balance reasoning effectiveness and security. We propose reinforcement learning-based policy adjustments and adaptive token length regulation to enhance LLM safety.</li>
</ul>

<h3>Title: TAET: Two-Stage Adversarial Equalization Training on Long-Tailed Distributions</h3>
<ul>
<li><strong>Authors: </strong>Wang YuHang, Junkang Guo, Aolei Liu, Kaihao Wang, Zaitong Wu, Zhenyu Liu, Wenfei Yin, Jian Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01924">https://arxiv.org/abs/2503.01924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01924">https://arxiv.org/pdf/2503.01924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01924]] TAET: Two-Stage Adversarial Equalization Training on Long-Tailed Distributions(https://arxiv.org/abs/2503.01924)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Adversarial robustness is a critical challenge in deploying deep neural networks for real-world applications. While adversarial training is a widely recognized defense strategy, most existing studies focus on balanced datasets, overlooking the prevalence of long-tailed distributions in real-world data, which significantly complicates robustness. This paper provides a comprehensive analysis of adversarial training under long-tailed distributions and identifies limitations in the current state-of-the-art method, AT-BSL, in achieving robust performance under such conditions. To address these challenges, we propose a novel training framework, TAET, which integrates an initial stabilization phase followed by a stratified equalization adversarial training phase. Additionally, prior work on long-tailed robustness has largely ignored the crucial evaluation metric of balanced accuracy. To bridge this gap, we introduce the concept of balanced robustness, a comprehensive metric tailored for assessing robustness under long-tailed distributions. Extensive experiments demonstrate that our method surpasses existing advanced defenses, achieving significant improvements in both memory and computational efficiency. This work represents a substantial advancement in addressing robustness challenges in real-world applications. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Unnatural Languages Are Not Bugs but Features for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Keyu Duan, Yiran Zhao, Zhili Feng, Jinjie Ni, Tianyu Pang, Qian Liu, Tianle Cai, Longxu Dou, Kenji Kawaguchi, Anirudh Goyal, J. Zico Kolter, Michael Qizhe Shieh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01926">https://arxiv.org/abs/2503.01926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01926">https://arxiv.org/pdf/2503.01926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01926]] Unnatural Languages Are Not Bugs but Features for LLMs(https://arxiv.org/abs/2503.01926)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been observed to process non-human-readable text sequences, such as jailbreak prompts, often viewed as a bug for aligned LLMs. In this work, we present a systematic investigation challenging this perception, demonstrating that unnatural languages - strings that appear incomprehensible to humans but maintain semantic meanings for LLMs - contain latent features usable by models. Notably, unnatural languages possess latent features that can be generalized across different models and tasks during inference. Furthermore, models fine-tuned on unnatural versions of instruction datasets perform on-par with those trained on natural language, achieving 49.71 win rates in Length-controlled AlpacaEval 2.0 in average across various base models. In addition, through comprehensive analysis, we demonstrate that LLMs process unnatural languages by filtering noise and inferring contextual meaning from filtered words.</li>
</ul>

<h3>Title: Road Boundary Detection Using 4D mmWave Radar for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Yuyan Wu, Hae Young Noh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01930">https://arxiv.org/abs/2503.01930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01930">https://arxiv.org/pdf/2503.01930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01930]] Road Boundary Detection Using 4D mmWave Radar for Autonomous Driving(https://arxiv.org/abs/2503.01930)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Detecting road boundaries, the static physical edges of the available driving area, is important for safe navigation and effective path planning in autonomous driving and advanced driver-assistance systems (ADAS). Traditionally, road boundary detection in autonomous driving relies on cameras and LiDAR. However, they are vulnerable to poor lighting conditions, such as nighttime and direct sunlight glare, or prohibitively expensive for low-end vehicles. To this end, this paper introduces 4DRadarRBD, the first road boundary detection method based on 4D mmWave radar which is cost-effective and robust in complex driving scenarios. The main idea is that road boundaries (e.g., fences, bushes, roadblocks), reflect millimeter waves, thus generating point cloud data for the radar. To overcome the challenge that the 4D mmWave radar point clouds contain many noisy points, we initially reduce noisy points via physical constraints for road boundaries and then segment the road boundary points from the noisy points by incorporating a distance-based loss which penalizes for falsely detecting the points far away from the actual road boundaries. In addition, we capture the temporal dynamics of point cloud sequences by utilizing each point's deviation from the vehicle motion-compensated road boundary detection result obtained from the previous frame, along with the spatial distribution of the point cloud for point-wise road boundary segmentation. We evaluated 4DRadarRBD through real-world driving tests and achieved a road boundary point segmentation accuracy of 93$\%$, with a median distance error of up to 0.023 m and an error reduction of 92.6$\%$ compared to the baseline model.</li>
</ul>

<h3>Title: Adversarial Generative Flow Network for Solving Vehicle Routing Problems</h3>
<ul>
<li><strong>Authors: </strong>Ni Zhang, Jingfeng Yang, Zhiguang Cao, Xu Chi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01931">https://arxiv.org/abs/2503.01931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01931">https://arxiv.org/pdf/2503.01931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01931]] Adversarial Generative Flow Network for Solving Vehicle Routing Problems(https://arxiv.org/abs/2503.01931)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent research into solving vehicle routing problems (VRPs) has gained significant traction, particularly through the application of deep (reinforcement) learning for end-to-end solution construction. However, many current construction-based neural solvers predominantly utilize Transformer architectures, which can face scalability challenges and struggle to produce diverse solutions. To address these limitations, we introduce a novel framework beyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks (AGFN). This framework integrates the generative flow network (GFlowNet)-a probabilistic model inherently adept at generating diverse solutions (routes)-with a complementary model for discriminating (or evaluating) the solutions. These models are trained alternately in an adversarial manner to improve the overall solution quality, followed by a proposed hybrid decoding method to construct the solution. We apply the AGFN framework to solve the capacitated vehicle routing problem (CVRP) and travelling salesman problem (TSP), and our experimental results demonstrate that AGFN surpasses the popular construction-based neural solvers, showcasing strong generalization capabilities on synthetic and real-world benchmark instances.</li>
</ul>

<h3>Title: Fine-Tuning Small Language Models for Domain-Specific AI: An Edge AI Perspective</h3>
<ul>
<li><strong>Authors: </strong>Rakshit Aralimatti, Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01933">https://arxiv.org/abs/2503.01933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01933">https://arxiv.org/pdf/2503.01933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01933]] Fine-Tuning Small Language Models for Domain-Specific AI: An Edge AI Perspective(https://arxiv.org/abs/2503.01933)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Deploying large scale language models on edge devices faces inherent challenges such as high computational demands, energy consumption, and potential data privacy risks. This paper introduces the Shakti Small Language Models (SLMs) Shakti-100M, Shakti-250M, and Shakti-500M which target these constraints headon. By combining efficient architectures, quantization techniques, and responsible AI principles, the Shakti series enables on-device intelligence for smartphones, smart appliances, IoT systems, and beyond. We provide comprehensive insights into their design philosophy, training pipelines, and benchmark performance on both general tasks (e.g., MMLU, Hellaswag) and specialized domains (healthcare, finance, and legal). Our findings illustrate that compact models, when carefully engineered and fine-tuned, can meet and often exceed expectations in real-world edge-AI scenarios.</li>
</ul>

<h3>Title: Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Beichter, Nils Friederich, Janik Pinter, Dorina Werling, Kaleb Phipps, Sebastian Beichter, Oliver Neumann, Ralf Mikut, Veit Hagenmeyer, Benedikt Heidrich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01936">https://arxiv.org/abs/2503.01936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01936">https://arxiv.org/pdf/2503.01936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01936]] Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization(https://arxiv.org/abs/2503.01936)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series foundation models provide a universal solution for generating forecasts to support optimization problems in energy systems. Those foundation models are typically trained in a prediction-focused manner to maximize forecast quality. In contrast, decision-focused learning directly improves the resulting value of the forecast in downstream optimization rather than merely maximizing forecasting quality. The practical integration of forecast values into forecasting models is challenging, particularly when addressing complex applications with diverse instances, such as buildings. This becomes even more complicated when instances possess specific characteristics that require instance-specific, tailored predictions to increase the forecast value. To tackle this challenge, we use decision-focused fine-tuning within time series foundation models to offer a scalable and efficient solution for decision-focused learning applied to the dispatchable feeder optimization problem. To obtain more robust predictions for scarce building data, we use Moirai as a state-of-the-art foundation model, which offers robust and generalized results with few-shot parameter-efficient fine-tuning. Comparing the decision-focused fine-tuned Moirai with a state-of-the-art classical prediction-focused fine-tuning Morai, we observe an improvement of 9.45% in average total daily costs.</li>
</ul>

<h3>Title: AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification</h3>
<ul>
<li><strong>Authors: </strong>Xuan Zhang, Yongliang Shen, Zhe Zheng, Linjuan Wu, Wenqi Zhang, Yuchen Yan, Qiuying Peng, Jun Wang, Weiming Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01940">https://arxiv.org/abs/2503.01940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01940">https://arxiv.org/pdf/2503.01940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01940]] AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification(https://arxiv.org/abs/2503.01940)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in tool learning. In real-world scenarios, user queries are often ambiguous and incomplete, requiring effective clarification. However, existing interactive clarification approaches face two critical limitations: reliance on manually constructed datasets and lack of error correction mechanisms during multi-turn clarification. We present AskToAct, which addresses these challenges by exploiting the structural mapping between queries and their tool invocation solutions. Our key insight is that tool parameters naturally represent explicit user intents. By systematically removing key parameters from queries while retaining them as ground truth, we enable automated construction of high-quality training data. We further enhance model robustness by fine-tuning on error-correction augmented data using selective masking mechanism, enabling dynamic error detection during clarification interactions. Comprehensive experiments demonstrate that AskToAct significantly outperforms existing approaches, achieving above 79% accuracy in recovering critical unspecified intents and enhancing clarification efficiency by an average of 48.34% while maintaining high accuracy in tool invocation. Our framework exhibits robust performance across varying complexity levels and successfully generalizes to entirely unseen APIs without additional training, achieving performance comparable to GPT-4 with substantially fewer computational resources.</li>
</ul>

<h3>Title: Protecting DeFi Platforms against Non-Price Flash Loan Attacks</h3>
<ul>
<li><strong>Authors: </strong>Abdulrahman Alhaidari, Balaji Palanisamy, Prashant Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01944">https://arxiv.org/abs/2503.01944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01944">https://arxiv.org/pdf/2503.01944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01944]] Protecting DeFi Platforms against Non-Price Flash Loan Attacks(https://arxiv.org/abs/2503.01944)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, steal</a></li>
<li><strong>Abstract: </strong>Smart contracts in Decentralized Finance (DeFi) platforms are attractive targets for attacks as their vulnerabilities can lead to massive amounts of financial losses. Flash loan attacks, in particular, pose a major threat to DeFi protocols that hold a Total Value Locked (TVL) exceeding \$106 billion. These attacks use the atomicity property of blockchains to drain funds from smart contracts in a single transaction. While existing research primarily focuses on price manipulation attacks, such as oracle manipulation, mitigating non-price flash loan attacks that often exploit smart contracts' zero-day vulnerabilities remains largely unaddressed. These attacks are challenging to detect because of their unique patterns, time sensitivity, and complexity. In this paper, we present FlashGuard, a runtime detection and mitigation method for non-price flash loan attacks. Our approach targets smart contract function signatures to identify attacks in real-time and counterattack by disrupting the attack transaction atomicity by leveraging the short window when transactions are visible in the mempool but not yet confirmed. When FlashGuard detects an attack, it dispatches a stealthy dusting counterattack transaction to miners to change the victim contract's state which disrupts the attack's atomicity and forces the attack transaction to revert. We evaluate our approach using 20 historical attacks and several unseen attacks. FlashGuard achieves an average real-time detection latency of 150.31ms, a detection accuracy of over 99.93\%, and an average disruption time of 410.92ms. FlashGuard could have potentially rescued over \$405.71 million in losses if it were deployed prior to these attack instances. FlashGuard demonstrates significant potential as a DeFi security solution to mitigate and handle rising threats of non-price flash loan attacks.</li>
</ul>

<h3>Title: Analyzing the Safety of Japanese Large Language Models in Stereotype-Triggering Prompts</h3>
<ul>
<li><strong>Authors: </strong>Akito Nakanishi, Yukie Sano, Geng Liu, Francesco Pierri</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01947">https://arxiv.org/abs/2503.01947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01947">https://arxiv.org/pdf/2503.01947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01947]] Analyzing the Safety of Japanese Large Language Models in Stereotype-Triggering Prompts(https://arxiv.org/abs/2503.01947)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) have attracted growing interest for their significant potential, though concerns have rapidly emerged regarding unsafe behaviors stemming from inherent stereotypes and this http URL research on stereotypes in LLMs has primarily relied on indirect evaluation setups, in which models are prompted to select between pairs of sentences associated with particular social groups. Recently, direct evaluation methods have emerged, examining open-ended model responses to overcome limitations of previous approaches, such as annotator this http URL existing studies have focused on English-centric LLMs, whereas research on non-English models--particularly Japanese--remains sparse, despite the growing development and adoption of these this http URL study examines the safety of Japanese LLMs when responding to stereotype-triggering prompts in direct this http URL constructed 3,612 prompts by combining 301 social group terms--categorized by age, gender, and other attributes--with 12 stereotype-inducing templates in this http URL were analyzed from three foundational models trained respectively on Japanese, English, and Chinese this http URL findings reveal that LLM-jp, a Japanese native model, exhibits the lowest refusal rate and is more likely to generate toxic and negative responses compared to other this http URL, prompt format significantly influence the output of all models, and the generated responses include exaggerated reactions toward specific social groups, varying across this http URL findings underscore the insufficient ethical safety mechanisms in Japanese LLMs and demonstrate that even high-accuracy models can produce biased outputs when processing Japanese-language this http URL advocate for improving safety mechanisms and bias mitigation strategies in Japanese LLMs, contributing to ongoing discussions on AI ethics beyond linguistic boundaries.</li>
</ul>

<h3>Title: Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Davide Caffagni, Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.01980">https://arxiv.org/abs/2503.01980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.01980">https://arxiv.org/pdf/2503.01980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.01980]] Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval(https://arxiv.org/abs/2503.01980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Cross-modal retrieval is gaining increasing efficacy and interest from the research community, thanks to large-scale training, novel architectural and learning designs, and its application in LLMs and multimodal LLMs. In this paper, we move a step forward and design an approach that allows for multimodal queries, composed of both an image and a text, and can search within collections of multimodal documents, where images and text are interleaved. Our model, ReT, employs multi-level representations extracted from different layers of both visual and textual backbones, both at the query and document side. To allow for multi-level and cross-modal understanding and feature extraction, ReT employs a novel Transformer-based recurrent cell that integrates both textual and visual features at different layers, and leverages sigmoidal gates inspired by the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR benchmarks show that ReT achieves state-of-the-art performance across diverse settings. Our source code and trained models are publicly available at this https URL.</li>
</ul>

<h3>Title: HoT: Highlighted Chain of Thought for Referencing Supportive Facts from Inputs</h3>
<ul>
<li><strong>Authors: </strong>Tin Nguyen, Logan Bolton, Mohammad Reza Taesiri, Anh Totti Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02003">https://arxiv.org/abs/2503.02003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02003">https://arxiv.org/pdf/2503.02003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02003]] HoT: Highlighted Chain of Thought for Referencing Supportive Facts from Inputs(https://arxiv.org/abs/2503.02003)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>An Achilles heel of Large Language Models (LLMs) is their tendency to hallucinate non-factual statements. A response mixed of factual and non-factual statements poses a challenge for humans to verify and accurately base their decisions on. To combat this problem, we propose Highlighted Chain-of-Thought Prompting (HoT), a technique for prompting LLMs to generate responses with XML tags that ground facts to those provided in the query. That is, given an input question, LLMs would first re-format the question to add XML tags highlighting key facts, and then, generate a response with highlights over the facts referenced from the input. Interestingly, in few-shot settings, HoT outperforms vanilla chain of thought prompting (CoT) on a wide range of 17 tasks from arithmetic, reading comprehension to logical reasoning. When asking humans to verify LLM responses, highlights help time-limited participants to more accurately and efficiently recognize when LLMs are correct. Yet, surprisingly, when LLMs are wrong, HoTs tend to make users believe that an answer is correct.</li>
</ul>

<h3>Title: Morpheus: Text-Driven 3D Gaussian Splat Shape and Color Stylization</h3>
<ul>
<li><strong>Authors: </strong>Jamie Wynn, Zawar Qureshi, Jakub Powierza, Jamie Watson, Mohamed Sayed</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02009">https://arxiv.org/abs/2503.02009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02009">https://arxiv.org/pdf/2503.02009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02009]] Morpheus: Text-Driven 3D Gaussian Splat Shape and Color Stylization(https://arxiv.org/abs/2503.02009)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Exploring real-world spaces using novel-view synthesis is fun, and reimagining those worlds in a different style adds another layer of excitement. Stylized worlds can also be used for downstream tasks where there is limited training data and a need to expand a model's training distribution. Most current novel-view synthesis stylization techniques lack the ability to convincingly change geometry. This is because any geometry change requires increased style strength which is often capped for stylization stability and consistency. In this work, we propose a new autoregressive 3D Gaussian Splatting stylization method. As part of this method, we contribute a new RGBD diffusion model that allows for strength control over appearance and shape stylization. To ensure consistency across stylized frames, we use a combination of novel depth-guided cross attention, feature injection, and a Warp ControlNet conditioned on composite frames for guiding the stylization of new frames. We validate our method via extensive qualitative results, quantitative experiments, and a user study. Code will be released online.</li>
</ul>

<h3>Title: Mind the (Belief) Gap: Group Identity in the World of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Angana Borah, Marwa Houalla, Rada Mihalcea</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02016">https://arxiv.org/abs/2503.02016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02016">https://arxiv.org/pdf/2503.02016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02016]] Mind the (Belief) Gap: Group Identity in the World of LLMs(https://arxiv.org/abs/2503.02016)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social biases and belief-driven behaviors can significantly impact Large Language Models (LLMs) decisions on several tasks. As LLMs are increasingly used in multi-agent systems for societal simulations, their ability to model fundamental group psychological characteristics remains critical yet under-explored. In this study, we present a multi-agent framework that simulates belief congruence, a classical group psychology theory that plays a crucial role in shaping societal interactions and preferences. Our findings reveal that LLMs exhibit amplified belief congruence compared to humans, across diverse contexts. We further investigate the implications of this behavior on two downstream tasks: (1) misinformation dissemination and (2) LLM learning, finding that belief congruence in LLMs increases misinformation dissemination and impedes learning. To mitigate these negative impacts, we propose strategies inspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global citizenship framework. Our results show that the best strategies reduce misinformation dissemination by up to 37% and enhance learning by 11%. Bridging social psychology and AI, our work provides insights to navigate real-world interactions using LLMs while addressing belief-driven biases.</li>
</ul>

<h3>Title: A Lightweight and Secure Deep Learning Model for Privacy-Preserving Federated Learning in Intelligent Enterprises</h3>
<ul>
<li><strong>Authors: </strong>Reza Fotohi, Fereidoon Shams Aliee, Bahar Farahani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02017">https://arxiv.org/abs/2503.02017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02017">https://arxiv.org/pdf/2503.02017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02017]] A Lightweight and Secure Deep Learning Model for Privacy-Preserving Federated Learning in Intelligent Enterprises(https://arxiv.org/abs/2503.02017)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The ever growing Internet of Things (IoT) connections drive a new type of organization, the Intelligent Enterprise. In intelligent enterprises, machine learning based models are adopted to extract insights from data. Due to the efficiency and privacy challenges of these traditional models, a new federated learning (FL) paradigm has emerged. In FL, multiple enterprises can jointly train a model to update a final model. However, firstly, FL trained models usually perform worse than centralized models, especially when enterprises training data is non-IID (Independent and Identically Distributed). Second, due to the centrality of FL and the untrustworthiness of local enterprises, traditional FL solutions are vulnerable to poisoning and inference attacks and violate privacy. Thirdly, the continuous transfer of parameters between enterprises and servers increases communication costs. To this end, the FedAnil+ model is proposed, a novel, lightweight, and secure Federated Deep Learning Model that includes three main phases. In the first phase, the goal is to solve the data type distribution skew challenge. Addressing privacy concerns against poisoning and inference attacks is covered in the second phase. Finally, to alleviate the communication overhead, a novel compression approach is proposed that significantly reduces the size of the updates. The experiment results validate that FedAnil+ is secure against inference and poisoning attacks with better accuracy. In addition, it shows improvements over existing approaches in terms of model accuracy (13%, 16%, and 26%), communication cost (17%, 21%, and 25%), and computation cost (7%, 9%, and 11%).</li>
</ul>

<h3>Title: Advancing Obfuscation Strategies to Counter China's Great Firewall: A Technical and Policy Perspective</h3>
<ul>
<li><strong>Authors: </strong>Li Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02018">https://arxiv.org/abs/2503.02018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02018">https://arxiv.org/pdf/2503.02018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02018]] Advancing Obfuscation Strategies to Counter China's Great Firewall: A Technical and Policy Perspective(https://arxiv.org/abs/2503.02018)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>China's Great Firewall (GFW) exemplifies one of the most extensive and technologically sophisticated internet censorship frameworks worldwide. Serving as a cornerstone of state-directed digital governance, it integrates a multitude of methods - ranging from DNS manipulation and IP blocking to keyword filtering and active surveillance - to control online information flows. These measures, underpinned by both technical proficiency and administrative oversight, form a formidable obstacle to open communication and data privacy. This paper critically examines the GFW's principal detection techniques, including Deep Packet Inspection (DPI), domain name tampering, and traffic fingerprinting, and analyzes how they align with broader governmental mechanisms. In parallel, we evaluate emerging countermeasures that leverage obfuscation, encryption, and routing innovations to circumvent these restrictions. By situating technical strategies within the broader context of governance and human rights, this work underscores the ongoing and evolving contest between state-imposed internet controls and individual efforts to maintain unrestricted access to digital resources.</li>
</ul>

<h3>Title: SLAP: Secure Location-proof and Anonymous Privacy-preserving Spectrum Access</h3>
<ul>
<li><strong>Authors: </strong>Saleh Darzi, Attila A. Yavuz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02019">https://arxiv.org/abs/2503.02019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02019">https://arxiv.org/pdf/2503.02019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02019]] SLAP: Secure Location-proof and Anonymous Privacy-preserving Spectrum Access(https://arxiv.org/abs/2503.02019)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid advancements in wireless technology have significantly increased the demand for communication resources, leading to the development of Spectrum Access Systems (SAS). However, network regulations require disclosing sensitive user information, such as location coordinates and transmission details, raising critical privacy concerns. Moreover, as a database-driven architecture reliant on user-provided data, SAS necessitates robust location verification to counter identity and location spoofing attacks and remains a primary target for denial-of-service (DoS) attacks. Addressing these security challenges while adhering to regulatory requirements is essential. In this paper, we propose SLAP, a novel framework that ensures location privacy and anonymity during spectrum queries, usage notifications, and location-proof acquisition. Our solution includes an adaptive dual-scenario location verification mechanism with architectural flexibility and a fallback option, along with a counter-DoS approach using time-lock puzzles. We prove the security of SLAP and demonstrate its advantages over existing solutions through comprehensive performance evaluations.</li>
</ul>

<h3>Title: Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering</h3>
<ul>
<li><strong>Authors: </strong>Aniruddha Maiti, Samuel Adewumi, Temesgen Alemayehu Tikure, Zichun Wang, Niladri Sengupta, Anastasiia Sukhanova, Ananya Jana</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02032">https://arxiv.org/abs/2503.02032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02032">https://arxiv.org/pdf/2503.02032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02032]] Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering(https://arxiv.org/abs/2503.02032)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study examines how large language models categorize sentences from scientific papers using prompt engineering. We use two advanced web-based models, GPT-4o (by OpenAI) and DeepSeek R1, to classify sentences into predefined relationship categories. DeepSeek R1 has been tested on benchmark datasets in its technical report. However, its performance in scientific text categorization remains unexplored. To address this gap, we introduce a new evaluation method designed specifically for this task. We also compile a dataset of cleaned scientific papers from diverse domains. This dataset provides a platform for comparing the two models. Using this dataset, we analyze their effectiveness and consistency in categorization.</li>
</ul>

<h3>Title: Robustness to Geographic Distribution Shift using Location Encoders</h3>
<ul>
<li><strong>Authors: </strong>Ruth Crasto</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02036">https://arxiv.org/abs/2503.02036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02036">https://arxiv.org/pdf/2503.02036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02036]] Robustness to Geographic Distribution Shift using Location Encoders(https://arxiv.org/abs/2503.02036)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Geographic distribution shift arises when the distribution of locations on Earth in a training dataset is different from what is seen at test time. The most common approaches to tackling geographic distribution shift treat regions delimited by administrative boundaries such as countries or continents as separate domains and apply standard domain adaptation methods, ignoring geographic coordinates that are often available as metadata. This paper proposes the use of location encoders for training models that are more robust to geographic distribution shift. We show how both simple sine-cosine encoders and pre-trained location encoders can be used to improve standard domain adaptation methods for the special case of geographic distribution shift. Our proposed methods achieve state-of-the-art results on geo-tagged imagery datasets from the WILDS benchmark.</li>
</ul>

<h3>Title: Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions</h3>
<ul>
<li><strong>Authors: </strong>Angana Borah, Rada Mihalcea, Verónica Pérez-Rosas</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02038">https://arxiv.org/abs/2503.02038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02038">https://arxiv.org/pdf/2503.02038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02038]] Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions(https://arxiv.org/abs/2503.02038)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing challenges in misinformation exposure and susceptibility vary across demographic groups, as some populations are more vulnerable to misinformation than others. Large language models (LLMs) introduce new dimensions to these challenges through their ability to generate persuasive content at scale and reinforcing existing biases. This study investigates the bidirectional persuasion dynamics between LLMs and humans when exposed to misinformative content. We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments. Additionally, we use a multi-agent LLM framework to analyze the spread of misinformation under persuasion among demographic-oriented LLM agents. Our findings show that demographic factors influence susceptibility to misinformation in LLMs, closely reflecting the demographic-based patterns seen in human susceptibility. We also find that, similar to human demographic groups, multi-agent LLMs exhibit echo chamber behavior. This research explores the interplay between humans and LLMs, highlighting demographic differences in the context of misinformation and offering insights for future interventions.</li>
</ul>

<h3>Title: Dynamic Search for Inference-Time Alignment in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Xiner Li, Masatoshi Uehara, Xingyu Su, Gabriele Scalia, Tommaso Biancalani, Aviv Regev, Sergey Levine, Shuiwang Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02039">https://arxiv.org/abs/2503.02039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02039">https://arxiv.org/pdf/2503.02039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02039]] Dynamic Search for Inference-Time Alignment in Diffusion Models(https://arxiv.org/abs/2503.02039)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown promising generative capabilities across diverse domains, yet aligning their outputs with desired reward functions remains a challenge, particularly in cases where reward functions are non-differentiable. Some gradient-free guidance methods have been developed, but they often struggle to achieve optimal inference-time alignment. In this work, we newly frame inference-time alignment in diffusion as a search problem and propose Dynamic Search for Diffusion (DSearch), which subsamples from denoising processes and approximates intermediate node rewards. It also dynamically adjusts beam width and tree expansion to efficiently explore high-reward generations. To refine intermediate decisions, DSearch incorporates adaptive scheduling based on noise levels and a lookahead heuristic function. We validate DSearch across multiple domains, including biological sequence design, molecular optimization, and image generation, demonstrating superior reward optimization compared to existing approaches.</li>
</ul>

<h3>Title: CareerBERT: Matching Resumes to ESCO Jobs in a Shared Embedding Space for Generic Job Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Julian Rosenberger, Lukas Wolfrum, Sven Weinzierl, Mathias Kraus, Patrick Zschech</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02056">https://arxiv.org/abs/2503.02056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02056">https://arxiv.org/pdf/2503.02056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02056]] CareerBERT: Matching Resumes to ESCO Jobs in a Shared Embedding Space for Generic Job Recommendations(https://arxiv.org/abs/2503.02056)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapidly evolving labor market, driven by technological advancements and economic shifts, presents significant challenges for traditional job matching and consultation services. In response, we introduce an advanced support tool for career counselors and job seekers based on CareerBERT, a novel approach that leverages the power of unstructured textual data sources, such as resumes, to provide more accurate and comprehensive job recommendations. In contrast to previous approaches that primarily focus on job recommendations based on a fixed set of concrete job advertisements, our approach involves the creation of a corpus that combines data from the European Skills, Competences, and Occupations (ESCO) taxonomy and EURopean Employment Services (EURES) job advertisements, ensuring an up-to-date and well-defined representation of general job titles in the labor market. Our two-step evaluation approach, consisting of an application-grounded evaluation using EURES job advertisements and a human-grounded evaluation using real-world resumes and Human Resources (HR) expert feedback, provides a comprehensive assessment of CareerBERT's performance. Our experimental results demonstrate that CareerBERT outperforms both traditional and state-of-the-art embedding approaches while showing robust effectiveness in human expert evaluations. These results confirm the effectiveness of CareerBERT in supporting career consultants by generating relevant job recommendations based on resumes, ultimately enhancing the efficiency of job consultations and expanding the perspectives of job seekers. This research contributes to the field of NLP and job recommendation systems, offering valuable insights for both researchers and practitioners in the domain of career consulting and job matching.</li>
</ul>

<h3>Title: Survey Perspective: The Role of Explainable AI in Threat Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Nidhi Rastogi, Devang Dhanuka, Amulya Saxena, Pranjal Mairal, Le Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02065">https://arxiv.org/abs/2503.02065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02065">https://arxiv.org/pdf/2503.02065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02065]] Survey Perspective: The Role of Explainable AI in Threat Intelligence(https://arxiv.org/abs/2503.02065)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The increasing reliance on AI-based security tools in Security Operations Centers (SOCs) has transformed threat detection and response, yet analysts frequently struggle with alert overload, false positives, and lack of contextual relevance. The inability to effectively analyze AI-generated security alerts lead to inefficiencies in incident response and reduces trust in automated decision-making. In this paper, we show results and analysis of our investigation of how SOC analysts navigate AI-based alerts, their challenges with current security tools, and how explainability (XAI) integrated into their security workflows has the potential to become an effective decision support. In this vein, we conducted an industry survey. Using the survey responses, we analyze how security analysts' process, retrieve, and prioritize alerts. Our findings indicate that most analysts have not yet adopted XAI-integrated tools, but they express high interest in attack attribution, confidence scores, and feature contribution explanations to improve interpretability, and triage efficiency. Based on our findings, we also propose practical design recommendations for XAI-enhanced security alert systems, enabling AI-based cybersecurity solutions to be more transparent, interpretable, and actionable.</li>
</ul>

<h3>Title: Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Jacobi, Gal Niv</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02078">https://arxiv.org/abs/2503.02078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02078">https://arxiv.org/pdf/2503.02078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02078]] Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation(https://arxiv.org/abs/2503.02078)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Understanding and interpreting the internal representations of large language models (LLMs) remains an open challenge. Patchscopes introduced a method for probing internal activations by patching them into new prompts, prompting models to self-explain their hidden representations. We introduce Superscopes, a technique that systematically amplifies superposed features in MLP outputs (multilayer perceptron) and hidden states before patching them into new contexts. Inspired by the "features as directions" perspective and the Classifier-Free Guidance (CFG) approach from diffusion models, Superscopes amplifies weak but meaningful features, enabling the interpretation of internal representations that previous methods failed to explain-all without requiring additional training. This approach provides new insights into how LLMs build context and represent complex concepts, further advancing mechanistic interpretability.</li>
</ul>

<h3>Title: Linear Representations of Political Perspective Emerge in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junsol Kim, James Evans, Aaron Schein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02080">https://arxiv.org/abs/2503.02080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02080">https://arxiv.org/pdf/2503.02080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02080]] Linear Representations of Political Perspective Emerge in Large Language Models(https://arxiv.org/abs/2503.02080)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated the ability to generate text that realistically reflects a range of different subjective human perspectives. This paper studies how LLMs are seemingly able to reflect more liberal versus more conservative viewpoints among other political perspectives in American politics. We show that LLMs possess linear representations of political perspectives within activation space, wherein more similar perspectives are represented closer together. To do so, we probe the attention heads across the layers of three open transformer-based LLMs (\texttt{Llama-2-7b-chat}, \texttt{Mistral-7b-instruct}, \texttt{Vicuna-7b}). We first prompt models to generate text from the perspectives of different U.S.~lawmakers. We then identify sets of attention heads whose activations linearly predict those lawmakers' DW-NOMINATE scores, a widely-used and validated measure of political ideology. We find that highly predictive heads are primarily located in the middle layers, often speculated to encode high-level concepts and tasks. Using probes only trained to predict lawmakers' ideology, we then show that the same probes can predict measures of news outlets' slant from the activations of models prompted to simulate text from those news outlets. These linear probes allow us to visualize, interpret, and monitor ideological stances implicitly adopted by an LLM as it generates open-ended responses. Finally, we demonstrate that by applying linear interventions to these attention heads, we can steer the model outputs toward a more liberal or conservative stance. Overall, our research suggests that LLMs possess a high-level linear representation of American political ideology and that by leveraging recent advances in mechanistic interpretability, we can identify, monitor, and steer the subjective perspective underlying generated text.</li>
</ul>

<h3>Title: Twenty Years of Personality Computing: Threats, Challenges and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Fabio Celli, Aleksandar Kartelj, Miljan Đorđević, Derwin Suhartono, Vladimir Filipović, Veljko Milutinović, Georgios Spathoulas, Alessandro Vinciarelli, Michal Kosinski, Bruno Lepri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02082">https://arxiv.org/abs/2503.02082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02082">https://arxiv.org/pdf/2503.02082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02082]] Twenty Years of Personality Computing: Threats, Challenges and Future Directions(https://arxiv.org/abs/2503.02082)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Personality Computing is a field at the intersection of Personality Psychology and Computer Science. Started in 2005, research in the field utilizes computational methods to understand and predict human personality traits. The expansion of the field has been very rapid and, by analyzing digital footprints (text, images, social media, etc.), it helped to develop systems that recognize and even replicate human personality. While offering promising applications in talent recruiting, marketing and healthcare, the ethical implications of Personality Computing are significant. Concerns include data privacy, algorithmic bias, and the potential for manipulation by personality-aware Artificial Intelligence. This paper provides an overview of the field, explores key methodologies, discusses the challenges and threats, and outlines potential future directions for responsible development and deployment of Personality Computing technologies.</li>
</ul>

<h3>Title: Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction</h3>
<ul>
<li><strong>Authors: </strong>Emam Hossain, Muhammad Hasan Ferdous, Jianwu Wang, Aneesh Subramanian, Md Osman Gani</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02093">https://arxiv.org/abs/2503.02093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02093">https://arxiv.org/pdf/2503.02093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02093]] Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction(https://arxiv.org/abs/2503.02093)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Traditional machine learning and deep learning techniques rely on correlation-based learning, often failing to distinguish spurious associations from true causal relationships, which limits robustness, interpretability, and generalizability. To address these challenges, we propose a causality-driven deep learning framework that integrates Multivariate Granger Causality (MVGC) and PCMCI+ causal discovery algorithms with a hybrid deep learning architecture. Using 43 years (1979-2021) of daily and monthly Arctic Sea Ice Extent (SIE) and ocean-atmospheric datasets, our approach identifies causally significant factors, prioritizes features with direct influence, reduces feature overhead, and improves computational efficiency. Experiments demonstrate that integrating causal features enhances the deep learning model's predictive accuracy and interpretability across multiple lead times. Beyond SIE prediction, the proposed framework offers a scalable solution for dynamic, high-dimensional systems, advancing both theoretical understanding and practical applications in predictive modeling.</li>
</ul>

<h3>Title: Bomfather: An eBPF-based Kernel-level Monitoring Framework for Accurate Identification of Unknown, Unused, and Dynamically Loaded Dependencies in Modern Software Supply Chains</h3>
<ul>
<li><strong>Authors: </strong>Naveen Srinivasan, Nathan Naveen, Neil Naveen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02097">https://arxiv.org/abs/2503.02097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02097">https://arxiv.org/pdf/2503.02097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02097]] Bomfather: An eBPF-based Kernel-level Monitoring Framework for Accurate Identification of Unknown, Unused, and Dynamically Loaded Dependencies in Modern Software Supply Chains(https://arxiv.org/abs/2503.02097)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Inaccuracies in conventional dependency-tracking methods frequently undermine the security and integrity of modern software supply chains. This paper introduces a kernel-level framework leveraging extended Berkeley Packet Filter (eBPF) to capture software build dependencies transparently in real time. Our approach provides tamper-evident, intrinsic identifiers of build-time dependencies by computing cryptographic hashes of files accessed during compilation and constructing Merkle trees based on the observed file content. In contrast to traditional static analysis, this kernel-level methodology accounts for conditional compilation, dead-code, selective library usage, and dynamic dependencies, yielding more precise Software Bills of Materials (SBOMs) and Artifact Dependency Graphs (ADGs). We illustrate how existing SBOMs may omit dynamically loaded or ephemeral dependencies and discuss how kernel-level tracing can mitigate these omissions. The proposed system enhances trustworthiness in software artifacts by offering independently verifiable, kernel-level evidence of build provenance, thereby reducing supply chain risks and facilitating more accurate vulnerability management.</li>
</ul>

<h3>Title: Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection</h3>
<ul>
<li><strong>Authors: </strong>Boyong He, Yuxiang Ji, Qianwen Ye, Zhuoyue Tan, Liaoni Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02101">https://arxiv.org/abs/2503.02101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02101">https://arxiv.org/pdf/2503.02101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02101]] Generalized Diffusion Detector: Mining Robust Features from Diffusion Models for Domain-Generalized Detection(https://arxiv.org/abs/2503.02101)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Domain generalization (DG) for object detection aims to enhance detectors' performance in unseen scenarios. This task remains challenging due to complex variations in real-world applications. Recently, diffusion models have demonstrated remarkable capabilities in diverse scene generation, which inspires us to explore their potential for improving DG tasks. Instead of generating images, our method extracts multi-step intermediate features during the diffusion process to obtain domain-invariant features for generalized detection. Furthermore, we propose an efficient knowledge transfer framework that enables detectors to inherit the generalization capabilities of diffusion models through feature and object-level alignment, without increasing inference time. We conduct extensive experiments on six challenging DG benchmarks. The results demonstrate that our method achieves substantial improvements of 14.0% mAP over existing DG approaches across different domains and corruption types. Notably, our method even outperforms most domain adaptation methods without accessing any target domain data. Moreover, the diffusion-guided detectors show consistent improvements of 15.9% mAP on average compared to the baseline. Our work aims to present an effective approach for domain-generalized detection and provide potential insights for robust visual recognition in real-world scenarios. The code is available at \href{this https URL}{Generalized Diffusion Detector}</li>
</ul>

<h3>Title: Biomedical Foundation Model: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Xiangrui Liu, Yuanyuan Zhang, Yingzhou Lu, Changchang Yin, Xiaoling Hu, Xiaoou Liu, Lulu Chen, Sheng Wang, Alexander Rodriguez, Huaxiu Yao, Yezhou Yang, Ping Zhang, Jintai Chen, Tianfan Fu, Xiao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02104">https://arxiv.org/abs/2503.02104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02104">https://arxiv.org/pdf/2503.02104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02104]] Biomedical Foundation Model: A Survey(https://arxiv.org/abs/2503.02104)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Foundation models, first introduced in 2021, are large-scale pre-trained models (e.g., large language models (LLMs) and vision-language models (VLMs)) that learn from extensive unlabeled datasets through unsupervised methods, enabling them to excel in diverse downstream tasks. These models, like GPT, can be adapted to various applications such as question answering and visual understanding, outperforming task-specific AI models and earning their name due to broad applicability across fields. The development of biomedical foundation models marks a significant milestone in leveraging artificial intelligence (AI) to understand complex biological phenomena and advance medical research and practice. This survey explores the potential of foundation models across diverse domains within biomedical fields, including computational biology, drug discovery and development, clinical informatics, medical imaging, and public health. The purpose of this survey is to inspire ongoing research in the application of foundation models to health science.</li>
</ul>

<h3>Title: Correcting Mode Proportion Bias in Generalized Bayesian Inference via a Weighted Kernel Stein Discrepancy</h3>
<ul>
<li><strong>Authors: </strong>Elham Afzali, Saman Muthukumarana, Liqun Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02108">https://arxiv.org/abs/2503.02108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02108">https://arxiv.org/pdf/2503.02108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02108]] Correcting Mode Proportion Bias in Generalized Bayesian Inference via a Weighted Kernel Stein Discrepancy(https://arxiv.org/abs/2503.02108)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Generalized Bayesian Inference (GBI) provides a flexible framework for updating prior distributions using various loss functions instead of the traditional likelihoods, thereby enhancing the model robustness to model misspecification. However, GBI often suffers the problem associated with intractable likelihoods. Kernelized Stein Discrepancy (KSD), as utilized in a recent study, addresses this challenge by relying only on the gradient of the log-likelihood. Despite this innovation, KSD-Bayes suffers from critical pathologies, including insensitivity to well-separated modes in multimodal posteriors. To address this limitation, we propose a weighted KSD method that retains computational efficiency while effectively capturing multimodal structures. Our method improves the GBI framework for handling intractable multimodal posteriors while maintaining key theoretical properties such as posterior consistency and asymptotic normality. Experimental results demonstrate that our method substantially improves mode sensitivity compared to standard KSD-Bayes, while retaining robust performance in unimodal settings and in the presence of outliers.</li>
</ul>

<h3>Title: Building Machine Learning Challenges for Anomaly Detection in Science</h3>
<ul>
<li><strong>Authors: </strong>Elizabeth G. Campolongo, Yuan-Tang Chou, Ekaterina Govorkova, Wahid Bhimji, Wei-Lun Chao, Chris Harris, Shih-Chieh Hsu, Hilmar Lapp, Mark S. Neubauer, Josephine Namayanja, Aneesh Subramanian, Philip Harris, Advaith Anand, David E. Carlyn, Subhankar Ghosh, Christopher Lawrence, Eric Moreno, Ryan Raikman, Jiaman Wu, Ziheng Zhang, Bayu Adhi, Mohammad Ahmadi Gharehtoragh, Saúl Alonso Monsalve, Marta Babicz, Furqan Baig, Namrata Banerji, William Bardon, Tyler Barna, Tanya Berger-Wolf, Adji Bousso Dieng, Micah Brachman, Quentin Buat, David C.Y. Hui, Phuong Cao, Franco Cerino, Yi-Chun Chang, Shivaji Chaulagain, An-Kai Chen, Deming Chen, Eric Chen, Chia-Jui Chou, Zih-Chen Ciou, Miles Cochran-Branson, Artur Cordeiro Oudot Choi, Michael Coughlin, Matteo Cremonesi, Maria Dadarlat, Peter Darch, Malina Desai, Daniel Diaz, Steven Dillmann, Javier Duarte, Isla Duporge, Urbas Ekka, Saba Entezari Heravi, Hao Fang, Rian Flynn, Geoffrey Fox, Emily Freed, Hang Gao, Jing Gao, Julia Gonski, Matthew Graham, Abolfazl Hashemi, Scott Hauck, James Hazelden, Joshua Henry Peterson, Duc Hoang, Wei Hu, Mirco Huennefeld, David Hyde, Vandana Janeja, Nattapon Jaroenchai, Haoyi Jia, Yunfan Kang, Maksim Kholiavchenko, Elham E. Khoda, Sangin Kim, Aditya Kumar, Bo-Cheng Lai, Trung Le, Chi-Wei Lee, JangHyeon Lee, Shaocheng Lee, Suzan van der Lee, Charles Lewis, Haitong Li, Haoyang Li, Henry Liao, Mia Liu, Xiaolin Liu, Xiulong Liu, Vladimir Loncar, Fangzheng Lyu, Ilya Makarov, Abhishikth Mallampalli Chen-Yu Mao, Alexander Michels, Alexander Migala, Farouk Mokhtar, Mathieu Morlighem</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.IM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02112">https://arxiv.org/abs/2503.02112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02112">https://arxiv.org/pdf/2503.02112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02112]] Building Machine Learning Challenges for Anomaly Detection in Science(https://arxiv.org/abs/2503.02112)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Scientific discoveries are often made by finding a pattern or object that was not predicted by the known rules of science. Oftentimes, these anomalous events or objects that do not conform to the norms are an indication that the rules of science governing the data are incomplete, and something new needs to be present to explain these unexpected outliers. The challenge of finding anomalies can be confounding since it requires codifying a complete knowledge of the known scientific behaviors and then projecting these known behaviors on the data to look for deviations. When utilizing machine learning, this presents a particular challenge since we require that the model not only understands scientific data perfectly but also recognizes when the data is inconsistent and out of the scope of its trained behavior. In this paper, we present three datasets aimed at developing machine learning-based anomaly detection for disparate scientific domains covering astrophysics, genomics, and polar science. We present the different datasets along with a scheme to make machine learning challenges around the three datasets findable, accessible, interoperable, and reusable (FAIR). Furthermore, we present an approach that generalizes to future machine learning challenges, enabling the possibility of large, more compute-intensive challenges that can ultimately lead to scientific discovery.</li>
</ul>

<h3>Title: Fairness and/or Privacy on Social Graphs</h3>
<ul>
<li><strong>Authors: </strong>Bartlomiej Surma, Michael Backes, Yang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02114">https://arxiv.org/abs/2503.02114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02114">https://arxiv.org/pdf/2503.02114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02114]] Fairness and/or Privacy on Social Graphs(https://arxiv.org/abs/2503.02114)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, fair</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have shown remarkable success in various graph-based learning tasks. However, recent studies have raised concerns about fairness and privacy issues in GNNs, highlighting the potential for biased or discriminatory outcomes and the vulnerability of sensitive information. This paper presents a comprehensive investigation of fairness and privacy in GNNs, exploring the impact of various fairness-preserving measures on model performance. We conduct experiments across diverse datasets and evaluate the effectiveness of different fairness interventions. Our analysis considers the trade-offs between fairness, privacy, and accuracy, providing insights into the challenges and opportunities in achieving both fair and private graph learning. The results highlight the importance of carefully selecting and combining fairness-preserving measures based on the specific characteristics of the data and the desired fairness objectives. This study contributes to a deeper understanding of the complex interplay between fairness, privacy, and accuracy in GNNs, paving the way for the development of more robust and ethical graph learning models.</li>
</ul>

<h3>Title: A Hybrid CNN-Transformer Model for Heart Disease Prediction Using Life History Data</h3>
<ul>
<li><strong>Authors: </strong>Ran Hao, Yanlin Xiang, Junliang Du, Qingyuan He, Jiacheng Hu, Ting Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02124">https://arxiv.org/abs/2503.02124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02124">https://arxiv.org/pdf/2503.02124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02124]] A Hybrid CNN-Transformer Model for Heart Disease Prediction Using Life History Data(https://arxiv.org/abs/2503.02124)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study proposed a hybrid model of a convolutional neural network (CNN) and a Transformer to predict and diagnose heart disease. Based on CNN's strength in detecting local features and the Transformer's high capacity in sensing global relations, the model is able to successfully detect risk factors of heart disease from high-dimensional life history data. Experimental results show that the proposed model outperforms traditional benchmark models like support vector machine (SVM), convolutional neural network (CNN), and long short-term memory network (LSTM) on several measures like accuracy, precision, and recall. This demonstrates its strong ability to deal with multi-dimensional and unstructured data. In order to verify the effectiveness of the model, experiments removing certain parts were carried out, and the results of the experiments showed that it is important to use both CNN and Transformer modules in enhancing the model. This paper also discusses the incorporation of additional features and approaches in future studies to enhance the model's performance and enable it to operate effectively in diverse conditions. This study presents novel insights and methods for predicting heart disease using machine learning, with numerous potential applications especially in personalized medicine and health management.</li>
</ul>

<h3>Title: HanDrawer: Leveraging Spatial Information to Render Realistic Hands Using a Conditional Diffusion Model in Single Stage</h3>
<ul>
<li><strong>Authors: </strong>Qifan Fu, Xu Chen, Muhammad Asad, Shanxin Yuan, Changjae Oh, Gregory Slabaugh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02127">https://arxiv.org/abs/2503.02127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02127">https://arxiv.org/pdf/2503.02127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02127]] HanDrawer: Leveraging Spatial Information to Render Realistic Hands Using a Conditional Diffusion Model in Single Stage(https://arxiv.org/abs/2503.02127)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Although diffusion methods excel in text-to-image generation, generating accurate hand gestures remains a major challenge, resulting in severe artifacts, such as incorrect number of fingers or unnatural gestures. To enable the diffusion model to learn spatial information to improve the quality of the hands generated, we propose HanDrawer, a module to condition the hand generation process. Specifically, we apply graph convolutional layers to extract the endogenous spatial structure and physical constraints implicit in MANO hand mesh vertices. We then align and fuse these spatial features with other modalities via cross-attention. The spatially fused features are used to guide a single stage diffusion model denoising process for high quality generation of the hand region. To improve the accuracy of spatial feature fusion, we propose a Position-Preserving Zero Padding (PPZP) fusion strategy, which ensures that the features extracted by HanDrawer are fused into the region of interest in the relevant layers of the diffusion model. HanDrawer learns the entire image features while paying special attention to the hand region thanks to an additional hand reconstruction loss combined with the denoising loss. To accurately train and evaluate our approach, we perform careful cleansing and relabeling of the widely used HaGRID hand gesture dataset and obtain high quality multimodal data. Quantitative and qualitative analyses demonstrate the state-of-the-art performance of our method on the HaGRID dataset through multiple evaluation metrics. Source code and our enhanced dataset will be released publicly if the paper is accepted.</li>
</ul>

<h3>Title: Forgetting Transformer: Softmax Attention with a Forget Gate</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan Lin, Evgenii Nikishin, Xu Owen He, Aaron Courville</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02130">https://arxiv.org/abs/2503.02130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02130">https://arxiv.org/pdf/2503.02130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02130]] Forgetting Transformer: Softmax Attention with a Forget Gate(https://arxiv.org/abs/2503.02130)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>An essential component of modern recurrent sequence models is the forget gate. While Transformers do not have an explicit recurrent form, we show that a forget gate can be naturally incorporated into Transformers by down-weighting the unnormalized attention scores in a data-dependent way. We name this attention mechanism the Forgetting Attention and the resulting model the Forgetting Transformer (FoX). We show that FoX outperforms the Transformer on long-context language modeling, length extrapolation, and short-context downstream tasks, while performing on par with the Transformer on long-context downstream tasks. Moreover, it is compatible with the FlashAttention algorithm and does not require any positional embeddings. Several analyses, including the needle-in-the-haystack test, show that FoX also retains the Transformer's superior long-context capabilities over recurrent sequence models such as Mamba-2, HGRN2, and DeltaNet. We also introduce a "Pro" block design that incorporates some common architectural components in recurrent sequence models and find it significantly improves the performance of both FoX and the Transformer. Our code is available at this https URL.</li>
</ul>

<h3>Title: Video-DPRP: A Differentially Private Approach for Visual Privacy-Preserving Video Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Allassan Tchangmena A Nken, Susan Mckeever, Peter Corcoran, Ihsan Ullah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02132">https://arxiv.org/abs/2503.02132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02132">https://arxiv.org/pdf/2503.02132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02132]] Video-DPRP: A Differentially Private Approach for Visual Privacy-Preserving Video Human Activity Recognition(https://arxiv.org/abs/2503.02132)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Considerable effort has been made in privacy-preserving video human activity recognition (HAR). Two primary approaches to ensure privacy preservation in Video HAR are differential privacy (DP) and visual privacy. Techniques enforcing DP during training provide strong theoretical privacy guarantees but offer limited capabilities for visual privacy assessment. Conversely methods, such as low-resolution transformations, data obfuscation and adversarial networks, emphasize visual privacy but lack clear theoretical privacy assurances. In this work, we focus on two main objectives: (1) leveraging DP properties to develop a model-free approach for visual privacy in videos and (2) evaluating our proposed technique using both differential privacy and visual privacy assessments on HAR tasks. To achieve goal (1), we introduce Video-DPRP: a Video-sample-wise Differentially Private Random Projection framework for privacy-preserved video reconstruction for HAR. By using random projections, noise matrices and right singular vectors derived from the singular value decomposition of videos, Video-DPRP reconstructs DP videos using privacy parameters ($\epsilon,\delta$) while enabling visual privacy assessment. For goal (2), using UCF101 and HMDB51 datasets, we compare Video-DPRP's performance on activity recognition with traditional DP methods, and state-of-the-art (SOTA) visual privacy-preserving techniques. Additionally, we assess its effectiveness in preserving privacy-related attributes such as facial features, gender, and skin color, using the PA-HMDB and VISPR datasets. Video-DPRP combines privacy-preservation from both a DP and visual privacy perspective unlike SOTA methods that typically address only one of these aspects.</li>
</ul>

<h3>Title: Network Traffic Classification Using Machine Learning, Transformer, and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Antari, Yazan Abo-Aisheh, Jehad Shamasneh, Huthaifa I. Ashqar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02141">https://arxiv.org/abs/2503.02141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02141">https://arxiv.org/pdf/2503.02141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02141]] Network Traffic Classification Using Machine Learning, Transformer, and Large Language Models(https://arxiv.org/abs/2503.02141)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This study uses various models to address network traffic classification, categorizing traffic into web, browsing, IPSec, backup, and email. We collected a comprehensive dataset from Arbor Edge Defender (AED) devices, comprising of 30,959 observations and 19 features. Multiple models were evaluated, including Naive Bayes, Decision Tree, Random Forest, Gradient Boosting, XGBoost, Deep Neural Networks (DNN), Transformer, and two Large Language Models (LLMs) including GPT-4o and Gemini with zero- and few-shot learning. Transformer and XGBoost showed the best performance, achieving the highest accuracy of 98.95 and 97.56%, respectively. GPT-4o and Gemini showed promising results with few-shot learning, improving accuracy significantly from initial zero-shot performance. While Gemini Few-Shot and GPT-4o Few-Shot performed well in categories like Web and Email, misclassifications occurred in more complex categories like IPSec and Backup. The study highlights the importance of model selection, fine-tuning, and the balance between training data size and model complexity for achieving reliable classification results.</li>
</ul>

<h3>Title: Measuring Intrinsic Dimension of Token Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Takuya Kataiwa, Cho Hakaze, Tetsushi Ohki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02142">https://arxiv.org/abs/2503.02142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02142">https://arxiv.org/pdf/2503.02142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02142]] Measuring Intrinsic Dimension of Token Embeddings(https://arxiv.org/abs/2503.02142)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this study, we measure the Intrinsic Dimension (ID) of token embedding to estimate the intrinsic dimensions of the manifolds spanned by the representations, so as to evaluate their redundancy quantitatively compared to their extrinsic dimensionality. In detail, (1) we estimate the ID of token embeddings in small-scale language models and also modern large language models, finding that the embedding spaces often reside on lower-dimensional manifolds compared to their extrinsic dimensionality; (2) we measure the ID across various model sizes and observe an increase in redundancy rates as the model scale grows; (3) we measure the dynamics of IDs during the training process, and find a rapid ID drop in the early stages of training. Moreover, (4) when LoRA is applied to the embedding layers, we observe a sudden drop in perplexity around the estimated IDs, suggesting that the ID can serve as a useful guideline for LoRA application.</li>
</ul>

<h3>Title: Four Principles for Physically Interpretable World Models</h3>
<ul>
<li><strong>Authors: </strong>Jordan Peper, Zhenjiang Mao, Yuang Geng, Siyuan Pan, Ivan Ruchkin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02143">https://arxiv.org/abs/2503.02143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02143">https://arxiv.org/pdf/2503.02143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02143]] Four Principles for Physically Interpretable World Models(https://arxiv.org/abs/2503.02143)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>As autonomous systems are increasingly deployed in open and uncertain settings, there is a growing need for trustworthy world models that can reliably predict future high-dimensional observations. The learned latent representations in world models lack direct mapping to meaningful physical quantities and dynamics, limiting their utility and interpretability in downstream planning, control, and safety verification. In this paper, we argue for a fundamental shift from physically informed to physically interpretable world models - and crystallize four principles that leverage symbolic knowledge to achieve these ends: (1) structuring latent spaces according to the physical intent of variables, (2) learning aligned invariant and equivariant representations of the physical world, (3) adapting training to the varied granularity of supervision signals, and (4) partitioning generative outputs to support scalability and verifiability. We experimentally demonstrate the value of each principle on two benchmarks. This paper opens several intriguing research directions to achieve and capitalize on full physical interpretability in world models.</li>
</ul>

<h3>Title: Malware Classification from Memory Dumps Using Machine Learning, Transformers, and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Areej Dweib, Montaser Tanina, Shehab Alawi, Mohammad Dyab, Huthaifa I. Ashqar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02144">https://arxiv.org/abs/2503.02144</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02144">https://arxiv.org/pdf/2503.02144</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02144]] Malware Classification from Memory Dumps Using Machine Learning, Transformers, and Large Language Models(https://arxiv.org/abs/2503.02144)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the performance of various classification models for a malware classification task using different feature sets and data configurations. Six models-Logistic Regression, K-Nearest Neighbors (KNN), Support Vector Machines (SVM), Decision Trees, Random Forest (RF), and Extreme Gradient Boosting (XGB)-were evaluated alongside two deep learning models, Recurrent Neural Networks (RNN) and Transformers, as well as the Gemini zero-shot and few-shot learning methods. Four feature sets were tested including All Features, Literature Review Features, the Top 45 Features from RF, and Down-Sampled with Top 45 Features. XGB achieved the highest accuracy of 87.42% using the Top 45 Features, outperforming all other models. RF followed closely with 87.23% accuracy on the same feature set. In contrast, deep learning models underperformed, with RNN achieving 66.71% accuracy and Transformers reaching 71.59%. Down-sampling reduced performance across all models, with XGB dropping to 81.31%. Gemini zero-shot and few-shot learning approaches showed the lowest performance, with accuracies of 40.65% and 48.65%, respectively. The results highlight the importance of feature selection in improving model performance while reducing computational complexity. Traditional models like XGB and RF demonstrated superior performance, while deep learning and few-shot methods struggled to match their accuracy. This study underscores the effectiveness of traditional machine learning models for structured datasets and provides a foundation for future research into hybrid approaches and larger datasets.</li>
</ul>

<h3>Title: Tabby: Tabular Data Synthesis with Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sonia Cromp, Satya Sai Srinath Namburi GNVV, Mohammed Alkhudhayri, Catherine Cao, Samuel Guo, Nicholas Roberts, Frederic Sala</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02152">https://arxiv.org/abs/2503.02152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02152">https://arxiv.org/pdf/2503.02152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02152]] Tabby: Tabular Data Synthesis with Language Models(https://arxiv.org/abs/2503.02152)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>While advances in large language models (LLMs) have greatly improved the quality of synthetic text data in recent years, synthesizing tabular data has received relatively less attention. We address this disparity with Tabby, a simple but powerful post-training modification to the standard Transformer language model architecture, enabling its use for tabular dataset synthesis. Tabby enables the representation of differences across columns using Gated Mixture-of-Experts, with column-specific sets of parameters. Empirically, Tabby results in data quality near or equal to that of real data. By pairing our novel LLM table training technique, Plain, with Tabby, we observe up to a 44% improvement in quality over previous methods. We also show that Tabby extends beyond tables to more general structured data, reaching parity with real data on a nested JSON dataset as well.</li>
</ul>

<h3>Title: AugFL: Augmenting Federated Learning with Pretrained Models</h3>
<ul>
<li><strong>Authors: </strong>Sheng Yue, Zerui Qin, Yongheng Deng, Ju Ren, Yaoxue Zhang, Junshan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02154">https://arxiv.org/abs/2503.02154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02154">https://arxiv.org/pdf/2503.02154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02154]] AugFL: Augmenting Federated Learning with Pretrained Models(https://arxiv.org/abs/2503.02154)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has garnered widespread interest in recent years. However, owing to strict privacy policies or limited storage capacities of training participants such as IoT devices, its effective deployment is often impeded by the scarcity of training data in practical decentralized learning environments. In this paper, we study enhancing FL with the aid of (large) pre-trained models (PMs), that encapsulate wealthy general/domain-agnostic knowledge, to alleviate the data requirement in conducting FL from scratch. Specifically, we consider a networked FL system formed by a central server and distributed clients. First, we formulate the PM-aided personalized FL as a regularization-based federated meta-learning problem, where clients join forces to learn a meta-model with knowledge transferred from a private PM stored at the server. Then, we develop an inexact-ADMM-based algorithm, AugFL, to optimize the problem with no need to expose the PM or incur additional computational costs to local clients. Further, we establish theoretical guarantees for AugFL in terms of communication complexity, adaptation performance, and the benefit of knowledge transfer in general non-convex cases. Extensive experiments corroborate the efficacy and superiority of AugFL over existing baselines.</li>
</ul>

<h3>Title: LLM-TabFlow: Synthetic Tabular Data Generation with Inter-column Logical Relationship Preservation</h3>
<ul>
<li><strong>Authors: </strong>Yunbo Long, Liming Xu, Alexandra Brintrup</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02161">https://arxiv.org/abs/2503.02161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02161">https://arxiv.org/pdf/2503.02161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02161]] LLM-TabFlow: Synthetic Tabular Data Generation with Inter-column Logical Relationship Preservation(https://arxiv.org/abs/2503.02161)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, fair, diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>Synthetic tabular data have widespread applications in industrial domains such as healthcare, finance, and supply chains, owing to their potential to protect privacy and mitigate data scarcity. However, generating realistic synthetic tabular data while preserving inter-column logical relationships remains a significant challenge for the existing generative models. To address these challenges, we propose LLM-TabFlow, a novel approach that leverages Large Language Model (LLM) reasoning to capture complex inter-column relationships and compress tabular data, while using Score-based Diffusion to model the distribution of the compressed data in latent space. Additionally, we introduce an evaluation framework, which is absent in literature, to fairly assess the performance of synthetic tabular data generation methods in real-world contexts. Using this framework, we conduct extensive experiments on two real-world industrial datasets, evaluating LLM-TabFlow against other five baseline methods, including SMOTE (an interpolation-based approach) and other state-of-the-art generative models. Our results show that LLM-TabFlow outperforms all baselines, fully preserving inter-column relationships while achieving the best balance between data fidelity, utility, and privacy. This study is the first to explicitly address inter-column relationship preservation in synthetic tabular data generation, offering new insights for developing more realistic and reliable tabular data generation methods.</li>
</ul>

<h3>Title: DDAD: A Two-pronged Adversarial Defense Based on Distributional Discrepancy</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Zhang, Benjamin I. P. Rubinstein, Jingfeng Zhang, Feng Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02169">https://arxiv.org/abs/2503.02169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02169">https://arxiv.org/pdf/2503.02169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02169]] DDAD: A Two-pronged Adversarial Defense Based on Distributional Discrepancy(https://arxiv.org/abs/2503.02169)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Statistical adversarial data detection (SADD) detects whether an upcoming batch contains adversarial examples (AEs) by measuring the distributional discrepancies between clean examples (CEs) and AEs. In this paper, we reveal the potential strength of SADD-based methods by theoretically showing that minimizing distributional discrepancy can help reduce the expected loss on AEs. Nevertheless, despite these advantages, SADD-based methods have a potential limitation: they discard inputs that are detected as AEs, leading to the loss of clean information within those inputs. To address this limitation, we propose a two-pronged adversarial defense method, named Distributional-Discrepancy-based Adversarial Defense (DDAD). In the training phase, DDAD first optimizes the test power of the maximum mean discrepancy (MMD) to derive MMD-OPT, and then trains a denoiser by minimizing the MMD-OPT between CEs and AEs. In the inference phase, DDAD first leverages MMD-OPT to differentiate CEs and AEs, and then applies a two-pronged process: (1) directly feeding the detected CEs into the classifier, and (2) removing noise from the detected AEs by the distributional-discrepancy-based denoiser. Extensive experiments show that DDAD outperforms current state-of-the-art (SOTA) defense methods by notably improving clean and robust accuracy on CIFAR-10 and ImageNet-1K against adaptive white-box attacks.</li>
</ul>

<h3>Title: From Data to Uncertainty Sets: a Machine Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Dimitris Bertsimas, Benjamin Boucher</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02173">https://arxiv.org/abs/2503.02173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02173">https://arxiv.org/pdf/2503.02173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02173]] From Data to Uncertainty Sets: a Machine Learning Approach(https://arxiv.org/abs/2503.02173)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>Existing approaches of prescriptive analytics -- where inputs of an optimization model can be predicted by leveraging covariates in a machine learning model -- often attempt to optimize the mean value of an uncertain objective. However, when applied to uncertain constraints, these methods rarely work because satisfying a crucial constraint in expectation may result in a high probability of violation. To remedy this, we leverage robust optimization to protect a constraint against the uncertainty of a machine learning model's output. To do so, we design an uncertainty set based on the model's loss function. Intuitively, this approach attempts to minimize the uncertainty around a prediction. Extending guarantees from the robust optimization literature, we derive strong guarantees on the probability of violation. On synthetic computational experiments, our method requires uncertainty sets with radii up to one order of magnitude smaller than those of other approaches.</li>
</ul>

<h3>Title: Adversarial Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Renato Lui Geh, Zilei Shao, Guy Van den Broeck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02174">https://arxiv.org/abs/2503.02174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02174">https://arxiv.org/pdf/2503.02174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02174]] Adversarial Tokenization(https://arxiv.org/abs/2503.02174)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Current LLM pipelines account for only one possible tokenization for a given string, ignoring exponentially many alternative tokenizations during training and inference. For example, the standard Llama3 tokenization of penguin is [p,enguin], yet [peng,uin] is another perfectly valid alternative. In this paper, we show that despite LLMs being trained solely on one tokenization, they still retain semantic understanding of other tokenizations, raising questions about their implications in LLM safety. Put succinctly, we answer the following question: can we adversarially tokenize an obviously malicious string to evade safety and alignment restrictions? We show that not only is adversarial tokenization an effective yet previously neglected axis of attack, but it is also competitive against existing state-of-the-art adversarial approaches without changing the text of the harmful request. We empirically validate this exploit across three state-of-the-art LLMs and adversarial datasets, revealing a previously unknown vulnerability in subword models.</li>
</ul>

<h3>Title: DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Saeed Ranjbar Alvar, Gursimran Singh, Mohammad Akbari, Yong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02175">https://arxiv.org/abs/2503.02175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02175">https://arxiv.org/pdf/2503.02175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02175]] DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models(https://arxiv.org/abs/2503.02175)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Multimodal Models (LMMs) have emerged as powerful models capable of understanding various data modalities, including text, images, and videos. LMMs encode both text and visual data into tokens that are then combined and processed by an integrated Large Language Model (LLM). Including visual tokens substantially increases the total token count, often by thousands. The increased input length for LLM significantly raises the complexity of inference, resulting in high latency in LMMs. To address this issue, token pruning methods, which remove part of the visual tokens, are proposed. The existing token pruning methods either require extensive calibration and fine-tuning or rely on suboptimal importance metrics which results in increased redundancy among the retained tokens. In this paper, we first formulate token pruning as Max-Min Diversity Problem (MMDP) where the goal is to select a subset such that the diversity among the selected {tokens} is maximized. Then, we solve the MMDP to obtain the selected subset and prune the rest. The proposed method, DivPrune, reduces redundancy and achieves the highest diversity of the selected tokens. By ensuring high diversity, the selected tokens better represent the original tokens, enabling effective performance even at high pruning ratios without requiring fine-tuning. Extensive experiments with various LMMs show that DivPrune achieves state-of-the-art accuracy over 16 image- and video-language datasets. Additionally, DivPrune reduces both the end-to-end latency and GPU memory usage for the tested models. The code is available $\href{this https URL}{\text{here}}$.</li>
</ul>

<h3>Title: h-Edit: Effective and Flexible Diffusion-Based Editing via Doob's h-Transform</h3>
<ul>
<li><strong>Authors: </strong>Toan Nguyen, Kien Do, Duc Kieu, Thin Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02187">https://arxiv.org/abs/2503.02187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02187">https://arxiv.org/pdf/2503.02187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02187]] h-Edit: Effective and Flexible Diffusion-Based Editing via Doob's h-Transform(https://arxiv.org/abs/2503.02187)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce a theoretical framework for diffusion-based image editing by formulating it as a reverse-time bridge modeling problem. This approach modifies the backward process of a pretrained diffusion model to construct a bridge that converges to an implicit distribution associated with the editing target at time 0. Building on this framework, we propose h-Edit, a novel editing method that utilizes Doob's h-transform and Langevin Monte Carlo to decompose the update of an intermediate edited sample into two components: a "reconstruction" term and an "editing" term. This decomposition provides flexibility, allowing the reconstruction term to be computed via existing inversion techniques and enabling the combination of multiple editing terms to handle complex editing tasks. To our knowledge, h-Edit is the first training-free method capable of performing simultaneous text-guided and reward-model-based editing. Extensive experiments, both quantitative and qualitative, show that h-Edit outperforms state-of-the-art baselines in terms of editing effectiveness and faithfulness. Our source code is available at this https URL.</li>
</ul>

<h3>Title: HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D Registration</h3>
<ul>
<li><strong>Authors: </strong>Xiyu Zhang, Jiayi Ma, Jianwei Guo, Wei Hu, Zhaoshuai Qi, Fei Hui, Jiaqi Yang, Yanning Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02195">https://arxiv.org/abs/2503.02195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02195">https://arxiv.org/pdf/2503.02195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02195]] HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D Registration(https://arxiv.org/abs/2503.02195)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Geometric constraints between feature matches are critical in 3D point cloud registration problems. Existing approaches typically model unordered matches as a consistency graph and sample consistent matches to generate hypotheses. However, explicit graph construction introduces noise, posing great challenges for handcrafted geometric constraints to render consistency among matches. To overcome this, we propose HyperGCT, a flexible dynamic Hyper-GNN-learned geometric constraint that leverages high-order consistency among 3D correspondences. To our knowledge, HyperGCT is the first method that mines robust geometric constraints from dynamic hypergraphs for 3D registration. By dynamically optimizing the hypergraph through vertex and edge feature aggregation, HyperGCT effectively captures the correlations among correspondences, leading to accurate hypothesis generation. Extensive experiments on 3DMatch, 3DLoMatch, KITTI-LC, and ETH show that HyperGCT achieves state-of-the-art performance. Furthermore, our method is robust to graph noise, demonstrating a significant advantage in terms of generalization. The code will be released.</li>
</ul>

<h3>Title: ATLaS: Agent Tuning via Learning Critical Steps</h3>
<ul>
<li><strong>Authors: </strong>Zhixun Chen, Ming Li, Yuxuan Huang, Yali Du, Meng Fang, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02197">https://arxiv.org/abs/2503.02197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02197">https://arxiv.org/pdf/2503.02197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02197]] ATLaS: Agent Tuning via Learning Critical Steps(https://arxiv.org/abs/2503.02197)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and weaken generalization to states not covered by the expert data. Additionally, critical steps, such as planning, complex reasoning for intermediate subtasks, and strategic decision-making, are essential to success in agent tasks, so learning these steps is the key to improving LLM agents. For more effective and efficient agent tuning, we propose ATLaS that identifies the critical steps in expert trajectories and finetunes LLMs solely on these steps with reduced costs. By steering the training's focus to a few critical steps, our method mitigates the risk of overfitting entire trajectories and promotes generalization across different environments and tasks. In extensive experiments, an LLM finetuned on only 30% critical steps selected by ATLaS outperforms the LLM finetuned on all steps and recent open-source LLM agents. ATLaS maintains and improves base LLM skills as generalist agents interacting with diverse environments.</li>
</ul>

<h3>Title: Words or Vision: Do Vision-Language Models Have Blind Faith in Text?</h3>
<ul>
<li><strong>Authors: </strong>Ailin Deng, Tri Cao, Zhirui Chen, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02199">https://arxiv.org/abs/2503.02199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02199">https://arxiv.org/pdf/2503.02199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02199]] Words or Vision: Do Vision-Language Models Have Blind Faith in Text?(https://arxiv.org/abs/2503.02199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) excel in integrating visual and textual information for vision-centric tasks, but their handling of inconsistencies between modalities is underexplored. We investigate VLMs' modality preferences when faced with visual data and varied textual inputs in vision-centered settings. By introducing textual variations to four vision-centric tasks and evaluating ten Vision-Language Models (VLMs), we discover a \emph{``blind faith in text''} phenomenon: VLMs disproportionately trust textual data over visual data when inconsistencies arise, leading to significant performance drops under corrupted text and raising safety concerns. We analyze factors influencing this text bias, including instruction prompts, language model size, text relevance, token order, and the interplay between visual and textual certainty. While certain factors, such as scaling up the language model size, slightly mitigate text bias, others like token order can exacerbate it due to positional biases inherited from language models. To address this issue, we explore supervised fine-tuning with text augmentation and demonstrate its effectiveness in reducing text bias. Additionally, we provide a theoretical analysis suggesting that the blind faith in text phenomenon may stem from an imbalance of pure text and multi-modal data during training. Our findings highlight the need for balanced training and careful consideration of modality interactions in VLMs to enhance their robustness and reliability in handling multi-modal data inconsistencies.</li>
</ul>

<h3>Title: Volume-Sorted Prediction Set: Efficient Conformal Prediction for Multi-Target Regression</h3>
<ul>
<li><strong>Authors: </strong>Rui Luo, Zhixin Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02205">https://arxiv.org/abs/2503.02205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02205">https://arxiv.org/pdf/2503.02205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02205]] Volume-Sorted Prediction Set: Efficient Conformal Prediction for Multi-Target Regression(https://arxiv.org/abs/2503.02205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce Volume-Sorted Prediction Set (VSPS), a novel method for uncertainty quantification in multi-target regression that uses conditional normalizing flows with conformal calibration. This approach constructs flexible, non-convex predictive regions with guaranteed coverage probabilities, overcoming limitations of traditional methods. By learning a transformation where the conditional distribution of responses follows a known form, VSPS identifies dense regions in the original space using the Jacobian determinant. This enables the creation of prediction regions that adapt to the true underlying distribution, focusing on areas of high probability density. Experimental results demonstrate that VSPS produces smaller, more informative prediction regions while maintaining robust coverage guarantees, enhancing uncertainty modeling in complex, high-dimensional settings.</li>
</ul>

<h3>Title: CrystalFramer: Rethinking the Role of Frames for SE(3)-Invariant Crystal Structure Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yusei Ito, Tatsunori Taniai, Ryo Igarashi, Yoshitaka Ushiku, Kanta Ono</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02209">https://arxiv.org/abs/2503.02209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02209">https://arxiv.org/pdf/2503.02209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02209]] CrystalFramer: Rethinking the Role of Frames for SE(3)-Invariant Crystal Structure Modeling(https://arxiv.org/abs/2503.02209)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Crystal structure modeling with graph neural networks is essential for various applications in materials informatics, and capturing SE(3)-invariant geometric features is a fundamental requirement for these networks. A straightforward approach is to model with orientation-standardized structures through structure-aligned coordinate systems, or"frames." However, unlike molecules, determining frames for crystal structures is challenging due to their infinite and highly symmetric nature. In particular, existing methods rely on a statically fixed frame for each structure, determined solely by its structural information, regardless of the task under consideration. Here, we rethink the role of frames, questioning whether such simplistic alignment with the structure is sufficient, and propose the concept of dynamic frames. While accommodating the infinite and symmetric nature of crystals, these frames provide each atom with a dynamic view of its local environment, focusing on actively interacting atoms. We demonstrate this concept by utilizing the attention mechanism in a recent transformer-based crystal encoder, resulting in a new architecture called CrystalFramer. Extensive experiments show that CrystalFramer outperforms conventional frames and existing crystal encoders in various crystal property prediction tasks.</li>
</ul>

<h3>Title: Low-Level Matters: An Efficient Hybrid Architecture for Robust Multi-frame Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhihua Shen, Siyang Chen, Han Wang, Tongsu Zhang, Xiaohu Zhang, Xiangpeng Xu, Xia Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02220">https://arxiv.org/abs/2503.02220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02220">https://arxiv.org/pdf/2503.02220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02220]] Low-Level Matters: An Efficient Hybrid Architecture for Robust Multi-frame Infrared Small Target Detection(https://arxiv.org/abs/2503.02220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Multi-frame infrared small target detection (IRSTD) plays a crucial role in low-altitude and maritime surveillance. The hybrid architecture combining CNNs and Transformers shows great promise for enhancing multi-frame IRSTD performance. In this paper, we propose LVNet, a simple yet powerful hybrid architecture that redefines low-level feature learning in hybrid frameworks for multi-frame IRSTD. Our key insight is that the standard linear patch embeddings in Vision Transformers are insufficient for capturing the scale-sensitive local features critical to infrared small targets. To address this limitation, we introduce a multi-scale CNN frontend that explicitly models local features by leveraging the local spatial bias of convolution. Additionally, we design a U-shaped video Transformer for multi-frame spatiotemporal context modeling, effectively capturing the motion characteristics of targets. Experiments on the publicly available datasets IRDST and NUDT-MIRSDT demonstrate that LVNet outperforms existing state-of-the-art methods. Notably, compared to the current best-performing method, LMAFormer, LVNet achieves an improvement of 5.63\% / 18.36\% in nIoU, while using only 1/221 of the parameters and 1/92 / 1/21 of the computational cost. Ablation studies further validate the importance of low-level representation learning in hybrid architectures. Our code and trained models are available at this https URL.</li>
</ul>

<h3>Title: DQO-MAP: Dual Quadrics Multi-Object mapping with Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Li, Ziqin Ye, Yue Hao, Weiyang Lin, Chao Ye</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02223">https://arxiv.org/abs/2503.02223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02223">https://arxiv.org/pdf/2503.02223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02223]] DQO-MAP: Dual Quadrics Multi-Object mapping with Gaussian Splatting(https://arxiv.org/abs/2503.02223)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Accurate object perception is essential for robotic applications such as object navigation. In this paper, we propose DQO-MAP, a novel object-SLAM system that seamlessly integrates object pose estimation and reconstruction. We employ 3D Gaussian Splatting for high-fidelity object reconstruction and leverage quadrics for precise object pose estimation. Both of them management is handled on the CPU, while optimization is performed on the GPU, significantly improving system efficiency. By associating objects with unique IDs, our system enables rapid object extraction from the scene. Extensive experimental results on object reconstruction and pose estimation demonstrate that DQO-MAP achieves outstanding performance in terms of precision, reconstruction quality, and computational efficiency. The code and dataset are available at: this https URL.</li>
</ul>

<h3>Title: One Patient's Annotation is Another One's Initialization: Towards Zero-Shot Surgical Video Segmentation with Cross-Patient Initialization</h3>
<ul>
<li><strong>Authors: </strong>Seyed Amir Mousavi, Utku Ozbulak, Francesca Tozzi, Nikdokht Rashidian, Wouter Willaert, Joris Vankerschaver, Wesley De Neve</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02228">https://arxiv.org/abs/2503.02228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02228">https://arxiv.org/pdf/2503.02228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02228]] One Patient's Annotation is Another One's Initialization: Towards Zero-Shot Surgical Video Segmentation with Cross-Patient Initialization(https://arxiv.org/abs/2503.02228)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Video object segmentation is an emerging technology that is well-suited for real-time surgical video segmentation, offering valuable clinical assistance in the operating room by ensuring consistent frame tracking. However, its adoption is limited by the need for manual intervention to select the tracked object, making it impractical in surgical settings. In this work, we tackle this challenge with an innovative solution: using previously annotated frames from other patients as the tracking frames. We find that this unconventional approach can match or even surpass the performance of using patients' own tracking frames, enabling more autonomous and efficient AI-assisted surgical workflows. Furthermore, we analyze the benefits and limitations of this approach, highlighting its potential to enhance segmentation accuracy while reducing the need for manual input. Our findings provide insights into key factors influencing performance, offering a foundation for future research on optimizing cross-patient frame selection for real-time surgical video analysis.</li>
</ul>

<h3>Title: Empowering Sparse-Input Neural Radiance Fields with Dual-Level Semantic Guidance from Dense Novel Views</h3>
<ul>
<li><strong>Authors: </strong>Yingji Zhong, Kaichen Zhou, Zhihao Li, Lanqing Hong, Zhenguo Li, Dan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02230">https://arxiv.org/abs/2503.02230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02230">https://arxiv.org/pdf/2503.02230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02230]] Empowering Sparse-Input Neural Radiance Fields with Dual-Level Semantic Guidance from Dense Novel Views(https://arxiv.org/abs/2503.02230)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural Radiance Fields (NeRF) have shown remarkable capabilities for photorealistic novel view synthesis. One major deficiency of NeRF is that dense inputs are typically required, and the rendering quality will drop drastically given sparse inputs. In this paper, we highlight the effectiveness of rendered semantics from dense novel views, and show that rendered semantics can be treated as a more robust form of augmented data than rendered RGB. Our method enhances NeRF's performance by incorporating guidance derived from the rendered semantics. The rendered semantic guidance encompasses two levels: the supervision level and the feature level. The supervision-level guidance incorporates a bi-directional verification module that decides the validity of each rendered semantic label, while the feature-level guidance integrates a learnable codebook that encodes semantic-aware information, which is queried by each point via the attention mechanism to obtain semantic-relevant predictions. The overall semantic guidance is embedded into a self-improved pipeline. We also introduce a more challenging sparse-input indoor benchmark, where the number of inputs is limited to as few as 6. Experiments demonstrate the effectiveness of our method and it exhibits superior performance compared to existing approaches.</li>
</ul>

<h3>Title: Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling</h3>
<ul>
<li><strong>Authors: </strong>Hang Zheng, Hongshen Xu, Yuncong Liu, Lu Chen, Pascale Fung, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02233">https://arxiv.org/abs/2503.02233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02233">https://arxiv.org/pdf/2503.02233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02233]] Enhancing LLM Reliability via Explicit Knowledge Boundary Modeling(https://arxiv.org/abs/2503.02233)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) frequently hallucinate due to misaligned self-awareness, generating erroneous outputs when addressing queries beyond their knowledge boundaries. While existing approaches mitigate hallucinations via uncertainty estimation or query rejection, they suffer from computational inefficiency or sacrificed helpfulness. To address these issues, we propose the Explicit Knowledge Boundary Modeling (EKBM) framework, integrating fast and slow reasoning systems to harmonize reliability and usability. The framework first employs a fast-thinking model to generate confidence-labeled responses, enabling immediate use of high-confidence outputs. For uncertain predictions, a slow refinement model conducts targeted reasoning to improve accuracy. To align model behavior with our proposed object, we propose a hybrid training pipeline, enhancing self-awareness without degrading task performance. Evaluations on dialogue state tracking tasks demonstrate that EKBM achieves superior model reliability over uncertainty-based baselines. Further analysis reveals that refinement substantially boosts accuracy while maintaining low computational overhead. Our work establishes a scalable paradigm for advancing LLM reliability and balancing accuracy and practical utility in error-sensitive applications.</li>
</ul>

<h3>Title: Haste Makes Waste: Evaluating Planning Abilities of LLMs for Efficient and Feasible Multitasking with Time Constraints Between Actions</h3>
<ul>
<li><strong>Authors: </strong>Zirui Wu, Xiao Liu, Jiayi Li, Lingpeng Kong, Yansong Feng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02238">https://arxiv.org/abs/2503.02238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02238">https://arxiv.org/pdf/2503.02238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02238]] Haste Makes Waste: Evaluating Planning Abilities of LLMs for Efficient and Feasible Multitasking with Time Constraints Between Actions(https://arxiv.org/abs/2503.02238)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Model-based agents have demonstrated substantial progress in task completion, existing evaluation benchmarks tend to overemphasize single-task performance, with insufficient attention given to the crucial aspects of multitask planning and execution efficiency required in real-world scenarios. To bridge this gap, we present Recipe2Plan, a novel benchmark framework based on real-world cooking scenarios. Unlike conventional benchmarks, Recipe2Plan challenges agents to optimize cooking time through parallel task execution while respecting temporal constraints i.e. specific actions need to be performed within a particular time intervals following the preceding steps. Overly aggressive local parallelization may disrupt this constraint, potentially compromising the entire cooking process. This strict time constraint between actions raises a unique challenge for agents to balance between maximizing concurrent operations and adhering to critical timing constraints. Extensive experiments with state-of-the-art models reveal challenges in maintaining this balance between efficiency and feasibility. The results highlight the need for improved temporal awareness and global multitasking capabilities in large language models. We open-source our benchmark and code at this https URL.</li>
</ul>

<h3>Title: OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale</h3>
<ul>
<li><strong>Authors: </strong>Haoyang Li, Shang Wu, Xiaokang Zhang, Xinmei Huang, Jing Zhang, Fuxin Jiang, Shuai Wang, Tieying Zhang, Jianjun Chen, Rui Shi, Hong Chen, Cuiping Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02240">https://arxiv.org/abs/2503.02240</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02240">https://arxiv.org/pdf/2503.02240</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02240]] OmniSQL: Synthesizing High-quality Text-to-SQL Data at Scale(https://arxiv.org/abs/2503.02240)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Text-to-SQL, the task of translating natural language questions into SQL queries, plays a crucial role in enabling non-experts to interact with databases. While recent advancements in large language models (LLMs) have significantly enhanced text-to-SQL performance, existing approaches face notable limitations in real-world text-to-SQL applications. Prompting-based methods often depend on closed-source LLMs, which are expensive, raise privacy concerns, and lack customization. Fine-tuning-based methods, on the other hand, suffer from poor generalizability due to the limited coverage of publicly available training data. To overcome these challenges, we propose a novel and scalable text-to-SQL data synthesis framework for automatically synthesizing large-scale, high-quality, and diverse datasets without extensive human intervention. Using this framework, we introduce SynSQL-2.5M, the first million-scale text-to-SQL dataset, containing 2.5 million samples spanning over 16,000 synthetic databases. Each sample includes a database, SQL query, natural language question, and chain-of-thought (CoT) solution. Leveraging SynSQL-2.5M, we develop OmniSQL, a powerful open-source text-to-SQL model available in three sizes: 7B, 14B, and 32B. Extensive evaluations across nine datasets demonstrate that OmniSQL achieves state-of-the-art performance, matching or surpassing leading closed-source and open-source LLMs, including GPT-4o and DeepSeek-V3, despite its smaller size. We release all code, datasets, and models to support further research.</li>
</ul>

<h3>Title: Unsupervised Waste Classification By Dual-Encoder Contrastive Learning and Multi-Clustering Voting (DECMCV)</h3>
<ul>
<li><strong>Authors: </strong>Kui Huang, Mengke Song, Shuo Ba, Ling An, Huajie Liang, Huanxi Deng, Yang Liu, Zhenyu Zhang, Chichun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02241">https://arxiv.org/abs/2503.02241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02241">https://arxiv.org/pdf/2503.02241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02241]] Unsupervised Waste Classification By Dual-Encoder Contrastive Learning and Multi-Clustering Voting (DECMCV)(https://arxiv.org/abs/2503.02241)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Waste classification is crucial for improving processing efficiency and reducing environmental pollution. Supervised deep learning methods are commonly used for automated waste classification, but they rely heavily on large labeled datasets, which are costly and inefficient to obtain. Real-world waste data often exhibit category and style biases, such as variations in camera angles, lighting conditions, and types of waste, which can impact the model's performance and generalization ability. Therefore, constructing a bias-free dataset is essential. Manual labeling is not only costly but also inefficient. While self-supervised learning helps address data scarcity, it still depends on some labeled data and generally results in lower accuracy compared to supervised methods. Unsupervised methods show potential in certain cases but typically do not perform as well as supervised models, highlighting the need for an efficient and cost-effective unsupervised approach. This study presents a novel unsupervised method, Dual-Encoder Contrastive Learning with Multi-Clustering Voting (DECMCV). The approach involves using a pre-trained ConvNeXt model for image encoding, leveraging VisionTransformer to generate positive samples, and applying a multi-clustering voting mechanism to address data labeling and domain shift issues. Experimental results demonstrate that DECMCV achieves classification accuracies of 93.78% and 98.29% on the TrashNet and Huawei Cloud datasets, respectively, outperforming or matching supervised models. On a real-world dataset of 4,169 waste images, only 50 labeled samples were needed to accurately label thousands, improving classification accuracy by 29.85% compared to supervised models. This method effectively addresses style differences, enhances model generalization, and contributes to the advancement of automated waste classification.</li>
</ul>

<h3>Title: $\mathbfΦ$-GAN: Physics-Inspired GAN for Generating SAR Images Under Limited Data</h3>
<ul>
<li><strong>Authors: </strong>Xidan Zhang, Yihan Zhuang, Qian Guo, Haodong Yang, Xuelin Qian, Gong Cheng, Junwei Han, Zhongling Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02242">https://arxiv.org/abs/2503.02242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02242">https://arxiv.org/pdf/2503.02242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02242]] $\mathbfΦ$-GAN: Physics-Inspired GAN for Generating SAR Images Under Limited Data(https://arxiv.org/abs/2503.02242)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, generative</a></li>
<li><strong>Abstract: </strong>Approaches for improving generative adversarial networks (GANs) training under a few samples have been explored for natural images. However, these methods have limited effectiveness for synthetic aperture radar (SAR) images, as they do not account for the unique electromagnetic scattering properties of SAR. To remedy this, we propose a physics-inspired regularization method dubbed $\Phi$-GAN, which incorporates the ideal point scattering center (PSC) model of SAR with two physical consistency losses. The PSC model approximates SAR targets using physical parameters, ensuring that $\Phi$-GAN generates SAR images consistent with real physical properties while preventing discriminator overfitting by focusing on PSC-based decision cues. To embed the PSC model into GANs for end-to-end training, we introduce a physics-inspired neural module capable of estimating the physical parameters of SAR targets efficiently. This module retains the interpretability of the physical model and can be trained with limited data. We propose two physical loss functions: one for the generator, guiding it to produce SAR images with physical parameters consistent with real ones, and one for the discriminator, enhancing its robustness by basing decisions on PSC attributes. We evaluate $\Phi$-GAN across several conditional GAN (cGAN) models, demonstrating state-of-the-art performance in data-scarce scenarios on three SAR image datasets.</li>
</ul>

<h3>Title: Making Better Mistakes in CLIP-Based Zero-Shot Classification with Hierarchy-Aware Language Prompts</h3>
<ul>
<li><strong>Authors: </strong>Tong Liang, Jim Davis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02248">https://arxiv.org/abs/2503.02248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02248">https://arxiv.org/pdf/2503.02248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02248]] Making Better Mistakes in CLIP-Based Zero-Shot Classification with Hierarchy-Aware Language Prompts(https://arxiv.org/abs/2503.02248)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies are leveraging advancements in large language models (LLMs) trained on extensive internet-crawled text data to generate textual descriptions of downstream classes in CLIP-based zero-shot image classification. While most of these approaches aim at improving accuracy, our work focuses on ``making better mistakes", of which the mistakes' severities are derived from the given label hierarchy of downstream tasks. Since CLIP's image encoder is trained with language supervising signals, it implicitly captures the hierarchical semantic relationships between different classes. This motivates our goal of making better mistakes in zero-shot classification, a task for which CLIP is naturally well-suited. Our approach (HAPrompts) queries the language model to produce textual representations for given classes as zero-shot classifiers of CLIP to perform image classification on downstream tasks. To our knowledge, this is the first work to introduce making better mistakes in CLIP-based zero-shot classification. Our approach outperforms the related methods in a holistic comparison across five datasets of varying scales with label hierarchies of different heights in our experiments. Our code and LLM-generated image prompts: \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: AxBERT: An Interpretable Chinese Spelling Correction Method Driven by Associative Knowledge Network</h3>
<ul>
<li><strong>Authors: </strong>Fanyu Wang, Hangyu Zhu, Zhenping Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02255">https://arxiv.org/abs/2503.02255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02255">https://arxiv.org/pdf/2503.02255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02255]] AxBERT: An Interpretable Chinese Spelling Correction Method Driven by Associative Knowledge Network(https://arxiv.org/abs/2503.02255)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Deep learning has shown promising performance on various machine learning tasks. Nevertheless, the uninterpretability of deep learning models severely restricts the usage domains that require feature explanations, such as text correction. Therefore, a novel interpretable deep learning model (named AxBERT) is proposed for Chinese spelling correction by aligning with an associative knowledge network (AKN). Wherein AKN is constructed based on the co-occurrence relations among Chinese characters, which denotes the interpretable statistic logic contrasted with uninterpretable BERT logic. And a translator matrix between BERT and AKN is introduced for the alignment and regulation of the attention component in BERT. In addition, a weight regulator is designed to adjust the attention distributions in BERT to appropriately model the sentence semantics. Experimental results on SIGHAN datasets demonstrate that AxBERT can achieve extraordinary performance, especially upon model precision compared to baselines. Our interpretable analysis, together with qualitative reasoning, can effectively illustrate the interpretability of AxBERT.</li>
</ul>

<h3>Title: SSNet: Saliency Prior and State Space Model-based Network for Salient Object Detection in RGB-D Images</h3>
<ul>
<li><strong>Authors: </strong>Gargi Panda, Soumitra Kundu, Saumik Bhattacharya, Aurobinda Routray</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02270">https://arxiv.org/abs/2503.02270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02270">https://arxiv.org/pdf/2503.02270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02270]] SSNet: Saliency Prior and State Space Model-based Network for Salient Object Detection in RGB-D Images(https://arxiv.org/abs/2503.02270)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Salient object detection (SOD) in RGB-D images is an essential task in computer vision, enabling applications in scene understanding, robotics, and augmented reality. However, existing methods struggle to capture global dependency across modalities, lack comprehensive saliency priors from both RGB and depth data, and are ineffective in handling low-quality depth maps. To address these challenges, we propose SSNet, a saliency-prior and state space model (SSM)-based network for the RGB-D SOD task. Unlike existing convolution- or transformer-based approaches, SSNet introduces an SSM-based multi-modal multi-scale decoder module to efficiently capture both intra- and inter-modal global dependency with linear complexity. Specifically, we propose a cross-modal selective scan SSM (CM-S6) mechanism, which effectively captures global dependency between different modalities. Furthermore, we introduce a saliency enhancement module (SEM) that integrates three saliency priors with deep features to refine feature representation and improve the localization of salient objects. To further address the issue of low-quality depth maps, we propose an adaptive contrast enhancement technique that dynamically refines depth maps, making them more suitable for the RGB-D SOD task. Extensive quantitative and qualitative experiments on seven benchmark datasets demonstrate that SSNet outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: A Kolmogorov-Arnold Network for Explainable Detection of Cyberattacks on EV Chargers</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Mohammad Saber, Max Mauro Dias Santos, Mohammad Al Janaideh, Amr Youssef, Deepa Kundur</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02281">https://arxiv.org/abs/2503.02281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02281">https://arxiv.org/pdf/2503.02281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02281]] A Kolmogorov-Arnold Network for Explainable Detection of Cyberattacks on EV Chargers(https://arxiv.org/abs/2503.02281)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>The increasing adoption of Electric Vehicles (EVs) and the expansion of charging infrastructure and their reliance on communication expose Electric Vehicle Supply Equipment (EVSE) to cyberattacks. This paper presents a novel Kolmogorov-Arnold Network (KAN)-based framework for detecting cyberattacks on EV chargers using only power consumption measurements. Leveraging the KAN's capability to model nonlinear, high-dimensional functions and its inherently interpretable architecture, the framework effectively differentiates between normal and malicious charging scenarios. The model is trained offline on a comprehensive dataset containing over 100,000 cyberattack cases generated through an experimental setup. Once trained, the KAN model can be deployed within individual chargers for real-time detection of abnormal charging behaviors indicative of cyberattacks. Our results demonstrate that the proposed KAN-based approach can accurately detect cyberattacks on EV chargers with Precision and F1-score of 99% and 92%, respectively, outperforming existing detection methods. Additionally, the proposed KANs's enable the extraction of mathematical formulas representing KAN's detection decisions, addressing interpretability, a key challenge in deep learning-based cybersecurity frameworks. This work marks a significant step toward building secure and explainable EV charging infrastructure.</li>
</ul>

<h3>Title: A Token-level Text Image Foundation Model for Document Understanding</h3>
<ul>
<li><strong>Authors: </strong>Tongkun Guan, Zining Wang, Pei Fu, Zhengtao Guo, Wei Shen, Kai Zhou, Tiezhu Yue, Chen Duan, Hao Sun, Qianyi Jiang, Junfeng Luo, Xiaokang Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02304">https://arxiv.org/abs/2503.02304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02304">https://arxiv.org/pdf/2503.02304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02304]] A Token-level Text Image Foundation Model for Document Understanding(https://arxiv.org/abs/2503.02304)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, general visual foundation models (VFMs) have witnessed increasing adoption, particularly as image encoders for popular multi-modal large language models (MLLMs). However, without semantically fine-grained supervision, these models still encounter fundamental prediction errors in the context of downstream text-image-related tasks, i.e., perception, understanding and reasoning with images containing small and dense texts. To bridge this gap, we develop TokenOCR, the first token-level visual foundation model specifically tailored for text-image-related tasks, designed to support a variety of traditional downstream applications. To facilitate the pretraining of TokenOCR, we also devise a high-quality data production pipeline that constructs the first token-level image text dataset, TokenIT, comprising 20 million images and 1.8 billion token-mask pairs. Furthermore, leveraging this foundation with exceptional image-as-text capability, we seamlessly replace previous VFMs with TokenOCR to construct a document-level MLLM, TokenVL, for VQA-based document understanding tasks. Finally, extensive experiments demonstrate the effectiveness of TokenOCR and TokenVL. Code, datasets, and weights will be available at this https URL.</li>
</ul>

<h3>Title: Target Return Optimizer for Multi-Game Decision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Kensuke Tatematsu, Akifumi Wachi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02311">https://arxiv.org/abs/2503.02311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02311">https://arxiv.org/pdf/2503.02311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02311]] Target Return Optimizer for Multi-Game Decision Transformer(https://arxiv.org/abs/2503.02311)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Achieving autonomous agents with robust generalization capabilities across diverse games and tasks remains one of the ultimate goals in AI research. Recent advancements in transformer-based offline reinforcement learning, exemplified by the MultiGame Decision Transformer [Lee et al., 2022], have shown remarkable performance across various games or tasks. However, these approaches depend heavily on human expertise, presenting substantial challenges for practical deployment, particularly in scenarios with limited prior game-specific knowledge. In this paper, we propose an algorithm called Multi-Game Target Return Optimizer (MTRO) to autonomously determine game-specific target returns within the Multi-Game Decision Transformer framework using solely offline datasets. MTRO addresses the existing limitations by automating the target return configuration process, leveraging environmental reward information extracted from offline datasets. Notably, MTRO does not require additional training, enabling seamless integration into existing Multi-Game Decision Transformer architectures. Our experimental evaluations on Atari games demonstrate that MTRO enhances the performance of RL policies across a wide array of games, underscoring its potential to advance the field of autonomous agent development.</li>
</ul>

<h3>Title: Incorporating graph neural network into route choice model</h3>
<ul>
<li><strong>Authors: </strong>Yuxun Ma, Toru Seo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02315">https://arxiv.org/abs/2503.02315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02315">https://arxiv.org/pdf/2503.02315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02315]] Incorporating graph neural network into route choice model(https://arxiv.org/abs/2503.02315)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Route choice models are one of the most important foundations for transportation research. Traditionally, theory-based models have been utilized for their great interpretability, such as logit models and Recursive logit models. More recently, machine learning approaches have gained attentions for their better prediction accuracy. In this study, we propose novel hybrid models that integrate the Recursive logit model with Graph Neural Networks (GNNs) to enhance both predictive performance and model interpretability. To the authors' knowldedge, GNNs have not been utilized for route choice modeling, despite their proven effectiveness in capturing road network features and their widespread use in other transportation research areas. We mathematically show that our use of GNN is not only beneficial for enhancing the prediction performance, but also relaxing the Independence of Irrelevant Alternatives property without relying on strong assumptions. This is due to the fact that a specific type of GNN can efficiently capture multiple cross-effect patterns on networks from data. By applying the proposed models to one-day travel trajectory data in Tokyo, we confirmed their higher prediction accuracy compared to the existing models.</li>
</ul>

<h3>Title: PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xueliang Zhao, Wei Wu, Jian Guan, Lingpeng Kong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02324">https://arxiv.org/abs/2503.02324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02324">https://arxiv.org/pdf/2503.02324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02324]] PromptCoT: Synthesizing Olympiad-level Problems for Mathematical Reasoning in Large Language Models(https://arxiv.org/abs/2503.02324)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The ability of large language models to solve complex mathematical problems has progressed significantly, particularly for tasks requiring advanced reasoning. However, the scarcity of sufficiently challenging problems, particularly at the Olympiad level, hinders further advancements. In this work, we introduce PromptCoT, a novel approach for automatically generating high-quality Olympiad-level math problems. The proposed method synthesizes complex problems based on mathematical concepts and the rationale behind problem construction, emulating the thought processes of experienced problem designers. We provide a theoretical analysis demonstrating that an optimal rationale should maximize both the likelihood of rationale generation given the associated concepts and the likelihood of problem generation conditioned on both the rationale and the concepts. Our method is evaluated on standard benchmarks including GSM8K, MATH-500, and AIME2024, where it consistently outperforms existing problem generation methods. Furthermore, we demonstrate that PromptCoT exhibits superior data scalability, consistently maintaining high performance as the dataset size increases, outperforming the baselines. The implementation is available at this https URL.</li>
</ul>

<h3>Title: Limited Effectiveness of LLM-based Data Augmentation for COVID-19 Misinformation Stance Detection</h3>
<ul>
<li><strong>Authors: </strong>Eun Cheol Choi, Ashwin Balasubramanian, Jinhu Qi, Emilio Ferrara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.HC, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02328">https://arxiv.org/abs/2503.02328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02328">https://arxiv.org/pdf/2503.02328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02328]] Limited Effectiveness of LLM-based Data Augmentation for COVID-19 Misinformation Stance Detection(https://arxiv.org/abs/2503.02328)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Misinformation surrounding emerging outbreaks poses a serious societal threat, making robust countermeasures essential. One promising approach is stance detection (SD), which identifies whether social media posts support or oppose misleading claims. In this work, we finetune classifiers on COVID-19 misinformation SD datasets consisting of claims and corresponding tweets. Specifically, we test controllable misinformation generation (CMG) using large language models (LLMs) as a method for data augmentation. While CMG demonstrates the potential for expanding training datasets, our experiments reveal that performance gains over traditional augmentation methods are often minimal and inconsistent, primarily due to built-in safeguards within LLMs. We release our code and datasets to facilitate further research on misinformation detection and generation.</li>
</ul>

<h3>Title: Examining the Mental Health Impact of Misinformation on Social Media Using a Hybrid Transformer-Based Approach</h3>
<ul>
<li><strong>Authors: </strong>Sarvesh Arora, Sarthak Arora, Deepika Kumar, Vallari Agrawal, Vedika Gupta, Dipit Vasdev</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02333">https://arxiv.org/abs/2503.02333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02333">https://arxiv.org/pdf/2503.02333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02333]] Examining the Mental Health Impact of Misinformation on Social Media Using a Hybrid Transformer-Based Approach(https://arxiv.org/abs/2503.02333)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Social media has significantly reshaped interpersonal communication, fostering connectivity while also enabling the proliferation of misinformation. The unchecked spread of false narratives has profound effects on mental health, contributing to increased stress, anxiety, and misinformation-driven paranoia. This study presents a hybrid transformer-based approach using a RoBERTa-LSTM classifier to detect misinformation, assess its impact on mental health, and classify disorders linked to misinformation exposure. The proposed models demonstrate accuracy rates of 98.4, 87.8, and 77.3 in detecting misinformation, mental health implications, and disorder classification, respectively. Furthermore, Pearson's Chi-Squared Test for Independence (p-value = 0.003871) validates the direct correlation between misinformation and deteriorating mental well-being. This study underscores the urgent need for better misinformation management strategies to mitigate its psychological repercussions. Future research could explore broader datasets incorporating linguistic, demographic, and cultural variables to deepen the understanding of misinformation-induced mental health distress.</li>
</ul>

<h3>Title: DeLTa: A Decoding Strategy based on Logit Trajectory Prediction Improves Factuality and Reasoning Ability</h3>
<ul>
<li><strong>Authors: </strong>Yunzhen He, Yusuke Takase, Yoichi Ishibashi, Hidetoshi Shimodaira</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02343">https://arxiv.org/abs/2503.02343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02343">https://arxiv.org/pdf/2503.02343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02343]] DeLTa: A Decoding Strategy based on Logit Trajectory Prediction Improves Factuality and Reasoning Ability(https://arxiv.org/abs/2503.02343)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly being used in real-world applications. However, concerns about the reliability of the content they generate persist, as it frequently deviates from factual correctness or exhibits deficiencies in logical reasoning. This paper proposes a novel decoding strategy aimed at enhancing both factual accuracy and inferential reasoning without requiring any modifications to the architecture or pre-trained parameters of LLMs. Our approach adjusts next-token probabilities by analyzing the trajectory of logits from lower to higher layers in Transformers and applying linear regression. We find that this Decoding by Logit Trajectory-based approach (DeLTa) effectively reinforces factuality and reasoning while mitigating incorrect generation. Experiments on TruthfulQA demonstrate that DeLTa attains up to a 4.9% improvement over the baseline. Furthermore, it enhances performance by up to 8.1% on StrategyQA and 7.3% on GSM8K, both of which demand strong reasoning capabilities.</li>
</ul>

<h3>Title: Add-One-In: Incremental Sample Selection for Large Language Models via a Choice-Based Greedy Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Zhuo Li, Yuhao Du, Xiaoqi Jiao, Yiwen Guo, Yuege Feng, Xiang Wan, Anningzhe Gao, Jinpeng Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02359">https://arxiv.org/abs/2503.02359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02359">https://arxiv.org/pdf/2503.02359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02359]] Add-One-In: Incremental Sample Selection for Large Language Models via a Choice-Based Greedy Paradigm(https://arxiv.org/abs/2503.02359)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Selecting high-quality and diverse training samples from extensive datasets plays a crucial role in reducing training overhead and enhancing the performance of Large Language Models (LLMs). However, existing studies fall short in assessing the overall value of selected data, focusing primarily on individual quality, and struggle to strike an effective balance between ensuring diversity and minimizing data point traversals. Therefore, this paper introduces a novel choice-based sample selection framework that shifts the focus from evaluating individual sample quality to comparing the contribution value of different samples when incorporated into the subset. Thanks to the advanced language understanding capabilities of LLMs, we utilize LLMs to evaluate the value of each option during the selection process. Furthermore, we design a greedy sampling process where samples are incrementally added to the subset, thereby improving efficiency by eliminating the need for exhaustive traversal of the entire dataset with the limited budget. Extensive experiments demonstrate that selected data from our method not only surpass the performance of the full dataset but also achieves competitive results with state-of-the-art (SOTA) studies, while requiring fewer selections. Moreover, we validate our approach on a larger medical dataset, highlighting its practical applicability in real-world applications.</li>
</ul>

<h3>Title: BdSLW401: Transformer-Based Word-Level Bangla Sign Language Recognition Using Relative Quantization Encoding (RQE)</h3>
<ul>
<li><strong>Authors: </strong>Husne Ara Rubaiyeat, Njayou Youssouf, Md Kamrul Hasan, Hasan Mahmud</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02360">https://arxiv.org/abs/2503.02360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02360">https://arxiv.org/pdf/2503.02360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02360]] BdSLW401: Transformer-Based Word-Level Bangla Sign Language Recognition Using Relative Quantization Encoding (RQE)(https://arxiv.org/abs/2503.02360)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Sign language recognition (SLR) for low-resource languages like Bangla suffers from signer variability, viewpoint variations, and limited annotated datasets. In this paper, we present BdSLW401, a large-scale, multi-view, word-level Bangla Sign Language (BdSL) dataset with 401 signs and 102,176 video samples from 18 signers in front and lateral views. To improve transformer-based SLR, we introduce Relative Quantization Encoding (RQE), a structured embedding approach anchoring landmarks to physiological reference points and quantize motion trajectories. RQE improves attention allocation by decreasing spatial variability, resulting in 44.3% WER reduction in WLASL100, 21.0% in SignBD-200, and significant gains in BdSLW60 and SignBD-90. However, fixed quantization becomes insufficient on large-scale datasets (e.g., WLASL2000), indicating the need for adaptive encoding strategies. Further, RQE-SF, an extended variant that stabilizes shoulder landmarks, achieves improvements in pose consistency at the cost of small trade-offs in lateral view recognition. The attention graphs prove that RQE improves model interpretability by focusing on the major articulatory features (fingers, wrists) and the more distinctive frames instead of global pose changes. Introducing BdSLW401 and demonstrating the effectiveness of RQE-enhanced structured embeddings, this work advances transformer-based SLR for low-resource languages and sets a benchmark for future research in this area.</li>
</ul>

<h3>Title: Label-Efficient LiDAR Panoptic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ahmet Selim Çanakçı, Niclas Vödisch, Kürsat Petek, Wolfram Burgard, Abhinav Valada</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02372">https://arxiv.org/abs/2503.02372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02372">https://arxiv.org/pdf/2503.02372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02372]] Label-Efficient LiDAR Panoptic Segmentation(https://arxiv.org/abs/2503.02372)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>A main bottleneck of learning-based robotic scene understanding methods is the heavy reliance on extensive annotated training data, which often limits their generalization ability. In LiDAR panoptic segmentation, this challenge becomes even more pronounced due to the need to simultaneously address both semantic and instance segmentation from complex, high-dimensional point cloud data. In this work, we address the challenge of LiDAR panoptic segmentation with very few labeled samples by leveraging recent advances in label-efficient vision panoptic segmentation. To this end, we propose a novel method, Limited-Label LiDAR Panoptic Segmentation (L3PS), which requires only a minimal amount of labeled data. Our approach first utilizes a label-efficient 2D network to generate panoptic pseudo-labels from a small set of annotated images, which are subsequently projected onto point clouds. We then introduce a novel 3D refinement module that capitalizes on the geometric properties of point clouds. By incorporating clustering techniques, sequential scan accumulation, and ground point separation, this module significantly enhances the accuracy of the pseudo-labels, improving segmentation quality by up to +10.6 PQ and +7.9 mIoU. We demonstrate that these refined pseudo-labels can be used to effectively train off-the-shelf LiDAR segmentation networks. Through extensive experiments, we show that L3PS not only outperforms existing methods but also substantially reduces the annotation burden. We release the code of our work at this https URL.</li>
</ul>

<h3>Title: MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics</h3>
<ul>
<li><strong>Authors: </strong>Haoan Jin, Jiacheng Shi, Hanhui Xu, Kenny Q. Zhu, Mengyue Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02374">https://arxiv.org/abs/2503.02374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02374">https://arxiv.org/pdf/2503.02374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02374]] MedEthicEval: Evaluating Large Language Models Based on Chinese Medical Ethics(https://arxiv.org/abs/2503.02374)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate significant potential in advancing medical applications, yet their capabilities in addressing medical ethics challenges remain underexplored. This paper introduces MedEthicEval, a novel benchmark designed to systematically evaluate LLMs in the domain of medical ethics. Our framework encompasses two key components: knowledge, assessing the models' grasp of medical ethics principles, and application, focusing on their ability to apply these principles across diverse scenarios. To support this benchmark, we consulted with medical ethics researchers and developed three datasets addressing distinct ethical challenges: blatant violations of medical ethics, priority dilemmas with clear inclinations, and equilibrium dilemmas without obvious resolutions. MedEthicEval serves as a critical tool for understanding LLMs' ethical reasoning in healthcare, paving the way for their responsible and effective use in medical contexts.</li>
</ul>

<h3>Title: mmDEAR: mmWave Point Cloud Density Enhancement for Accurate Human Body Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Yang, Songpengcheng Xia, Zengyuan Lai, Lan Sun, Qi Wu, Wenxian Yu, Ling Pei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02375">https://arxiv.org/abs/2503.02375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02375">https://arxiv.org/pdf/2503.02375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02375]] mmDEAR: mmWave Point Cloud Density Enhancement for Accurate Human Body Reconstruction(https://arxiv.org/abs/2503.02375)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Millimeter-wave (mmWave) radar offers robust sensing capabilities in diverse environments, making it a highly promising solution for human body reconstruction due to its privacy-friendly and non-intrusive nature. However, the significant sparsity of mmWave point clouds limits the estimation accuracy. To overcome this challenge, we propose a two-stage deep learning framework that enhances mmWave point clouds and improves human body reconstruction accuracy. Our method includes a mmWave point cloud enhancement module that densifies the raw data by leveraging temporal features and a multi-stage completion network, followed by a 2D-3D fusion module that extracts both 2D and 3D motion features to refine SMPL parameters. The mmWave point cloud enhancement module learns the detailed shape and posture information from 2D human masks in single-view images. However, image-based supervision is involved only during the training phase, and the inference relies solely on sparse point clouds to maintain privacy. Experiments on multiple datasets demonstrate that our approach outperforms state-of-the-art methods, with the enhanced point clouds further improving performance when integrated into existing models.</li>
</ul>

<h3>Title: Teaching Metric Distance to Autoregressive Multimodal Foundational Models</h3>
<ul>
<li><strong>Authors: </strong>Jiwan Chung, Saejin Kim, Yongrae Jo, Jaewoo Park, Dongjun Min, Youngjae Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02379">https://arxiv.org/abs/2503.02379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02379">https://arxiv.org/pdf/2503.02379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02379]] Teaching Metric Distance to Autoregressive Multimodal Foundational Models(https://arxiv.org/abs/2503.02379)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are pronounced in cases of limited training data, highlighting DIST2Loss's effectiveness in resource-constrained settings.</li>
</ul>

<h3>Title: An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02382">https://arxiv.org/abs/2503.02382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02382">https://arxiv.org/pdf/2503.02382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02382]] An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning(https://arxiv.org/abs/2503.02382)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Enhancing the mathematical reasoning capabilities of Large Language Models (LLMs) is of great scientific and practical significance. Researchers typically employ process-supervised reward models (PRMs) to guide the reasoning process, effectively improving the models' reasoning abilities. However, existing methods for constructing process supervision training data, such as manual annotation and per-step Monte Carlo estimation, are often costly or suffer from poor quality. To address these challenges, this paper introduces a framework called EpicPRM, which annotates each intermediate reasoning step based on its quantified contribution and uses an adaptive binary search algorithm to enhance both annotation precision and efficiency. Using this approach, we efficiently construct a high-quality process supervision training dataset named Epic50k, consisting of 50k annotated intermediate steps. Compared to other publicly available datasets, the PRM trained on Epic50k demonstrates significantly superior performance. Getting Epic50k at this https URL.</li>
</ul>

<h3>Title: PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers</h3>
<ul>
<li><strong>Authors: </strong>Wooju Lee, Juhye Park, Dasol Hong, Changki Sung, Youngwoo Seo, Dongwan Kang, Hyun Myung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02388">https://arxiv.org/abs/2503.02388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02388">https://arxiv.org/pdf/2503.02388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02388]] PIDLoc: Cross-View Pose Optimization Network Inspired by PID Controllers(https://arxiv.org/abs/2503.02388)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate localization is essential for autonomous driving, but GNSS-based methods struggle in challenging environments such as urban canyons. Cross-view pose optimization offers an effective solution by directly estimating vehicle pose using satellite-view images. However, existing methods primarily rely on cross-view features at a given pose, neglecting fine-grained contexts for precision and global contexts for robustness against large initial pose errors. To overcome these limitations, we propose PIDLoc, a novel cross-view pose optimization approach inspired by the proportional-integral-derivative (PID) controller. Using RGB images and LiDAR, the PIDLoc comprises the PID branches to model cross-view feature relationships and the spatially aware pose estimator (SPE) to estimate the pose from these relationships. The PID branches leverage feature differences for local context (P), aggregated feature differences for global context (I), and gradients of feature differences for precise pose adjustment (D) to enhance localization accuracy under large initial pose errors. Integrated with the PID branches, the SPE captures spatial relationships within the PID-branch features for consistent localization. Experimental results demonstrate that the PIDLoc achieves state-of-the-art performance in cross-view pose estimation for the KITTI dataset, reducing position error by $37.8\%$ compared with the previous state-of-the-art.</li>
</ul>

<h3>Title: Vision-Language Model IP Protection via Prompt-based Learning</h3>
<ul>
<li><strong>Authors: </strong>Lianyu Wang, Meng Wang, Huazhu Fu, Daoqiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02393">https://arxiv.org/abs/2503.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02393">https://arxiv.org/pdf/2503.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02393]] Vision-Language Model IP Protection via Prompt-based Learning(https://arxiv.org/abs/2503.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) like CLIP (Contrastive Language-Image Pre-Training) have seen remarkable success in visual recognition, highlighting the increasing need to safeguard the intellectual property (IP) of well-trained models. Effective IP protection extends beyond ensuring authorized usage; it also necessitates restricting model deployment to authorized data domains, particularly when the model is fine-tuned for specific target domains. However, current IP protection methods often rely solely on the visual backbone, which may lack sufficient semantic richness. To bridge this gap, we introduce IP-CLIP, a lightweight IP protection strategy tailored to CLIP, employing a prompt-based learning approach. By leveraging the frozen visual backbone of CLIP, we extract both image style and content information, incorporating them into the learning of IP prompt. This strategy acts as a robust barrier, effectively preventing the unauthorized transfer of features from authorized domains to unauthorized ones. Additionally, we propose a style-enhancement branch that constructs feature banks for both authorized and unauthorized domains. This branch integrates self-enhanced and cross-domain features, further strengthening IP-CLIP's capability to block features from unauthorized domains. Finally, we present new three metrics designed to better balance the performance degradation of authorized and unauthorized domains. Comprehensive experiments in various scenarios demonstrate its promising potential for application in IP protection tasks for VLMs.</li>
</ul>

<h3>Title: BHViT: Binarized Hybrid Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Tian Gao, Yu Zhang, Zhiyuan Zhang, Huajun Liu, Kaijie Yin, Chengzhong Xu, Hui Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02394">https://arxiv.org/abs/2503.02394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02394">https://arxiv.org/pdf/2503.02394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02394]] BHViT: Binarized Hybrid Vision Transformer(https://arxiv.org/abs/2503.02394)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Model binarization has made significant progress in enabling real-time and energy-efficient computation for convolutional neural networks (CNN), offering a potential solution to the deployment challenges faced by Vision Transformers (ViTs) on edge devices. However, due to the structural differences between CNN and Transformer architectures, simply applying binary CNN strategies to the ViT models will lead to a significant performance drop. To tackle this challenge, we propose BHViT, a binarization-friendly hybrid ViT architecture and its full binarization model with the guidance of three important observations. Initially, BHViT utilizes the local information interaction and hierarchical feature aggregation technique from coarse to fine levels to address redundant computations stemming from excessive tokens. Then, a novel module based on shift operations is proposed to enhance the performance of the binary Multilayer Perceptron (MLP) module without significantly increasing computational overhead. In addition, an innovative attention matrix binarization method based on quantization decomposition is proposed to evaluate the token's importance in the binarized attention matrix. Finally, we propose a regularization loss to address the inadequate optimization caused by the incompatibility between the weight oscillation in the binary layers and the Adam Optimizer. Extensive experimental results demonstrate that our proposed algorithm achieves SOTA performance among binary ViT methods.</li>
</ul>

<h3>Title: A Binary Classification Social Network Dataset for Graph Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Adnan Ali, Jinglong Li, Huanhuan Chen, AlMotasem Bellah Al Ajlouni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02397">https://arxiv.org/abs/2503.02397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02397">https://arxiv.org/pdf/2503.02397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02397]] A Binary Classification Social Network Dataset for Graph Machine Learning(https://arxiv.org/abs/2503.02397)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Social networks have a vast range of applications with graphs. The available benchmark datasets are citation, co-occurrence, e-commerce networks, etc, with classes ranging from 3 to 15. However, there is no benchmark classification social network dataset for graph machine learning. This paper fills the gap and presents the Binary Classification Social Network Dataset (\textit{BiSND}), designed for graph machine learning applications to predict binary classes. We present the BiSND in \textit{tabular and graph} formats to verify its robustness across classical and advanced machine learning. We employ a diverse set of classifiers, including four traditional machine learning algorithms (Decision Trees, K-Nearest Neighbour, Random Forest, XGBoost), one Deep Neural Network (multi-layer perceptrons), one Graph Neural Network (Graph Convolutional Network), and three state-of-the-art Graph Contrastive Learning methods (BGRL, GRACE, DAENS). Our findings reveal that BiSND is suitable for classification tasks, with F1-scores ranging from 67.66 to 70.15, indicating promising avenues for future enhancements.</li>
</ul>

<h3>Title: Trace of the Times: Rootkit Detection through Temporal Anomalies in Kernel Activity</h3>
<ul>
<li><strong>Authors: </strong>Max Landauer, Leonhard Alton, Martina Lindorfer, Florian Skopik, Markus Wurzenberger, Wolfgang Hotwagner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02402">https://arxiv.org/abs/2503.02402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02402">https://arxiv.org/pdf/2503.02402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02402]] Trace of the Times: Rootkit Detection through Temporal Anomalies in Kernel Activity(https://arxiv.org/abs/2503.02402)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Kernel rootkits provide adversaries with permanent high-privileged access to compromised systems and are often a key element of sophisticated attack chains. At the same time, they enable stealthy operation and are thus difficult to detect. Thereby, they inject code into kernel functions to appear invisible to users, for example, by manipulating file enumerations. Existing detection approaches are insufficient, because they rely on signatures that are unable to detect novel rootkits or require domain knowledge about the rootkits to be detected. To overcome this challenge, our approach leverages the fact that runtimes of kernel functions targeted by rootkits increase when additional code is executed. The framework outlined in this paper injects probes into the kernel to measure time stamps of functions within relevant system calls, computes distributions of function execution times, and uses statistical tests to detect time shifts. The evaluation of our open-source implementation on publicly available data sets indicates high detection accuracy with an F1 score of 98.7\% across five scenarios with varying system states.</li>
</ul>

<h3>Title: InfoGNN: End-to-end deep learning on mesh via graph neural networks</h3>
<ul>
<li><strong>Authors: </strong>Ling Gao, Zhenyu Shu, Shiqing Xin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02414">https://arxiv.org/abs/2503.02414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02414">https://arxiv.org/pdf/2503.02414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02414]] InfoGNN: End-to-end deep learning on mesh via graph neural networks(https://arxiv.org/abs/2503.02414)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D models are widely used in various industries, and mesh data has become an indispensable part of 3D modeling because of its unique advantages. Mesh data can provide an intuitive and practical expression of rich 3D information. However, its disordered, irregular data structure and complex surface information make it challenging to apply with deep learning models directly. Traditional mesh data processing methods often rely on mesh models with many limitations, such as manifold, which restrict their application scopes in reality and do not fully utilize the advantages of mesh models. This paper proposes a novel end-to-end framework for addressing the challenges associated with deep learning in mesh models centered around graph neural networks (GNN) and is titled InfoGNN. InfoGNN treats the mesh model as a graph, which enables it to handle irregular mesh data efficiently. Moreover, we propose InfoConv and InfoMP modules, which utilize the position information of the points and fully use the static information such as face normals, dihedral angles, and dynamic global feature information to fully use all kinds of data. In addition, InfoGNN is an end-to-end framework, and we simplify the network design to make it more efficient, paving the way for efficient deep learning of complex 3D models. We conducted experiments on several publicly available datasets, and the results show that InfoGNN achieves excellent performance in mesh classification and segmentation tasks.</li>
</ul>

<h3>Title: Exploring Model Quantization in GenAI-based Image Inpainting and Detection of Arable Plants</h3>
<ul>
<li><strong>Authors: </strong>Sourav Modak, Ahmet Oğuz Saltık, Anthony Stein</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02420">https://arxiv.org/abs/2503.02420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02420">https://arxiv.org/pdf/2503.02420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02420]] Exploring Model Quantization in GenAI-based Image Inpainting and Detection of Arable Plants(https://arxiv.org/abs/2503.02420)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep learning-based weed control systems often suffer from limited training data diversity and constrained on-board computation, impacting their real-world performance. To overcome these challenges, we propose a framework that leverages Stable Diffusion-based inpainting to augment training data progressively in 10% increments -- up to an additional 200%, thus enhancing both the volume and diversity of samples. Our approach is evaluated on two state-of-the-art object detection models, YOLO11(l) and RT-DETR(l), using the mAP50 metric to assess detection performance. We explore quantization strategies (FP16 and INT8) for both the generative inpainting and detection models to strike a balance between inference speed and accuracy. Deployment of the downstream models on the Jetson Orin Nano demonstrates the practical viability of our framework in resource-constrained environments, ultimately improving detection accuracy and computational efficiency in intelligent weed management systems.</li>
</ul>

<h3>Title: A Transformer-Based Framework for Greek Sign Language Production using Extended Skeletal Motion Representations</h3>
<ul>
<li><strong>Authors: </strong>Chrysa Pratikaki, Panagiotis Filntisis, Athanasios Katsamanis, Anastasios Roussos, Petros Maragos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02421">https://arxiv.org/abs/2503.02421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02421">https://arxiv.org/pdf/2503.02421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02421]] A Transformer-Based Framework for Greek Sign Language Production using Extended Skeletal Motion Representations(https://arxiv.org/abs/2503.02421)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sign Languages are the primary form of communication for Deaf communities across the world. To break the communication barriers between the Deaf and Hard-of-Hearing and the hearing communities, it is imperative to build systems capable of translating the spoken language into sign language and vice versa. Building on insights from previous research, we propose a deep learning model for Sign Language Production (SLP), which to our knowledge is the first attempt on Greek SLP. We tackle this task by utilizing a transformer-based architecture that enables the translation from text input to human pose keypoints, and the opposite. We evaluate the effectiveness of the proposed pipeline on the Greek SL dataset Elementary23, through a series of comparative analyses and ablation studies. Our pipeline's components, which include data-driven gloss generation, training through video to text translation and a scheduling algorithm for teacher forcing - auto-regressive decoding seem to actively enhance the quality of produced SL videos.</li>
</ul>

<h3>Title: Through the Static: Demystifying Malware Visualization via Explainability</h3>
<ul>
<li><strong>Authors: </strong>Matteo Brosolo, Vinod Puthuvath, Mauro Conti</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02441">https://arxiv.org/abs/2503.02441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02441">https://arxiv.org/pdf/2503.02441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02441]] Through the Static: Demystifying Malware Visualization via Explainability(https://arxiv.org/abs/2503.02441)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, robust, extraction, interpretability, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Security researchers grapple with the surge of malicious files, necessitating swift identification and classification of malware strains for effective protection. Visual classifiers and in particular Convolutional Neural Networks (CNNs) have emerged as vital tools for this task. However, issues of robustness and explainability, common in other high risk domain like medicine and autonomous vehicles, remain understudied in current literature. Although deep learning visualization classifiers presented in research obtain great results without the need for expert feature extraction, they have not been properly studied in terms of their replicability. Additionally, the literature is not clear on how these types of classifiers arrive to their answers. Our study addresses these gaps by replicating six CNN models and exploring their pitfalls. We employ Class Activation Maps (CAMs), like GradCAM and HiResCAM, to assess model explainability. We evaluate the CNNs' performance and interpretability on two standard datasets, MalImg and Big2015, and a newly created called VX-Zoo. We employ these different CAM techniques to gauge the explainability of each of the models. With these tools, we investigate the underlying factors contributing to different interpretations of inputs across the different models, empowering human researchers to discern patterns crucial for identifying distinct malware families and explain why CNN models arrive at their conclusions. Other then highlighting the patterns found in the interpretability study, we employ the extracted heatmpas to enhance Visual Transformers classifiers' performance and explanation quality. This approach yields substantial improvements in F1 score, ranging from 2% to 8%, across the datasets compared to benchmark values.</li>
</ul>

<h3>Title: AILS-NTUA at SemEval-2025 Task 3: Leveraging Large Language Models and Translation Strategies for Multilingual Hallucination Detection</h3>
<ul>
<li><strong>Authors: </strong>Dimitra Karkani, Maria Lymperaiou, Giorgos Filandrianos, Nikolaos Spanos, Athanasios Voulodimos, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02442">https://arxiv.org/abs/2503.02442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02442">https://arxiv.org/pdf/2503.02442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02442]] AILS-NTUA at SemEval-2025 Task 3: Leveraging Large Language Models and Translation Strategies for Multilingual Hallucination Detection(https://arxiv.org/abs/2503.02442)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual hallucination detection stands as an underexplored challenge, which the Mu-SHROOM shared task seeks to address. In this work, we propose an efficient, training-free LLM prompting strategy that enhances detection by translating multilingual text spans into English. Our approach achieves competitive rankings across multiple languages, securing two first positions in low-resource languages. The consistency of our results highlights the effectiveness of our translation strategy for hallucination detection, demonstrating its applicability regardless of the source language.</li>
</ul>

<h3>Title: AILS-NTUA at SemEval-2025 Task 4: Parameter-Efficient Unlearning for Large Language Models using Data Chunking</h3>
<ul>
<li><strong>Authors: </strong>Iraklis Premptis, Maria Lymperaiou, Giorgos Filandrianos, Orfeas Menis Mastromichalakis, Athanasios Voulodimos, Giorgos Stamou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02443">https://arxiv.org/abs/2503.02443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02443">https://arxiv.org/pdf/2503.02443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02443]] AILS-NTUA at SemEval-2025 Task 4: Parameter-Efficient Unlearning for Large Language Models using Data Chunking(https://arxiv.org/abs/2503.02443)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Unlearning Sensitive Content from Large Language Models task aims to remove targeted datapoints from trained models while minimally affecting their general knowledge. In our work, we leverage parameter-efficient, gradient-based unlearning using low-rank (LoRA) adaptation and layer-focused fine-tuning. To further enhance unlearning effectiveness, we employ data chunking, splitting forget data into disjoint partitions and merging them with cyclically sampled retain samples at a pre-defined ratio. Our task-agnostic method achieves an outstanding forget-retain balance, ranking first on leaderboards and significantly outperforming baselines and competing systems.</li>
</ul>

<h3>Title: BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modelling</h3>
<ul>
<li><strong>Authors: </strong>Hao Li, Yu-Hao Huang, Chang Xu, Viktor Schlegel, Ren-He Jiang, Riza Batista-Navarro, Goran Nenadic, Jiang Bian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02445">https://arxiv.org/abs/2503.02445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02445">https://arxiv.org/pdf/2503.02445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02445]] BRIDGE: Bootstrapping Text to Control Time-Series Generation via Multi-Agent Iterative Optimization and Diffusion Modelling(https://arxiv.org/abs/2503.02445)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Time-series Generation (TSG) is a prominent research area with broad applications in simulations, data augmentation, and counterfactual analysis. While existing methods have shown promise in unconditional single-domain TSG, real-world applications demand for cross-domain approaches capable of controlled generation tailored to domain-specific constraints and instance-level requirements. In this paper, we argue that text can provide semantic insights, domain information and instance-specific temporal patterns, to guide and improve TSG. We introduce ``Text-Controlled TSG'', a task focused on generating realistic time series by incorporating textual descriptions. To address data scarcity in this setting, we propose a novel LLM-based Multi-Agent framework that synthesizes diverse, realistic text-to-TS datasets. Furthermore, we introduce BRIDGE, a hybrid text-controlled TSG framework that integrates semantic prototypes with text description for supporting domain-level guidance. This approach achieves state-of-the-art generation fidelity on 11 of 12 datasets, and improves controllability by 12.52% on MSE and 6.34% MAE compared to no text input generation, highlighting its potential for generating tailored time-series data.</li>
</ul>

<h3>Title: Joint Tensor and Inter-View Low-Rank Recovery for Incomplete Multiview Clustering</h3>
<ul>
<li><strong>Authors: </strong>Jianyu Wang, Zhengqiao Zhao, Nicolas Dobigeon, Jingdong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02449">https://arxiv.org/abs/2503.02449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02449">https://arxiv.org/pdf/2503.02449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02449]] Joint Tensor and Inter-View Low-Rank Recovery for Incomplete Multiview Clustering(https://arxiv.org/abs/2503.02449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Incomplete multiview clustering (IMVC) has gained significant attention for its effectiveness in handling missing sample challenges across various views in real-world multiview clustering applications. Most IMVC approaches tackle this problem by either learning consensus representations from available views or reconstructing missing samples using the underlying manifold structure. However, the reconstruction of learned similarity graph tensor in prior studies only exploits the low-tubal-rank information, neglecting the exploration of inter-view correlations. This paper propose a novel joint tensor and inter-view low-rank Recovery (JTIV-LRR), framing IMVC as a joint optimization problem that integrates incomplete similarity graph learning and tensor representation recovery. By leveraging both intra-view and inter-view low rank information, the method achieves robust estimation of the complete similarity graph tensor through sparse noise removal and low-tubal-rank constraints along different modes. Extensive experiments on both synthetic and real-world datasets demonstrate the superiority of the proposed approach, achieving significant improvements in clustering accuracy and robustness compared to state-of-the-art methods.</li>
</ul>

<h3>Title: Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization</h3>
<ul>
<li><strong>Authors: </strong>Yilun Qiu, Xiaoyan Zhao, Yang Zhang, Yimeng Bai, Wenjie Wang, Hong Cheng, Fuli Feng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02450">https://arxiv.org/abs/2503.02450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02450">https://arxiv.org/pdf/2503.02450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02450]] Measuring What Makes You Unique: Difference-Aware User Modeling for Enhancing LLM Personalization(https://arxiv.org/abs/2503.02450)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Personalizing Large Language Models (LLMs) has become a critical step in facilitating their widespread application to enhance individual life experiences. In pursuit of personalization, distilling key preference information from an individual's historical data as instructional preference context to customize LLM generation has emerged as a promising direction. However, these methods face a fundamental limitation by overlooking the inter-user comparative analysis, which is essential for identifying the inter-user differences that truly shape preferences. To address this limitation, we propose Difference-aware Personalization Learning (DPL), a novel approach that emphasizes extracting inter-user differences to enhance LLM personalization. DPL strategically selects representative users for comparison and establishes a structured standard to extract meaningful, task-relevant differences for customizing LLM generation. Extensive experiments on real-world datasets demonstrate that DPL significantly enhances LLM personalization. We release our code at this https URL.</li>
</ul>

<h3>Title: Privacy Preservation Techniques (PPTs) in IoT Systems: A Scoping Review and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Emmanuel Alalade, Ashraf Matrawy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02455">https://arxiv.org/abs/2503.02455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02455">https://arxiv.org/pdf/2503.02455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02455]] Privacy Preservation Techniques (PPTs) in IoT Systems: A Scoping Review and Future Directions(https://arxiv.org/abs/2503.02455)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Privacy preservation in Internet of Things (IoT) systems requires the use of privacy-enhancing technologies (PETs) built from innovative technologies such as cryptography and artificial intelligence (AI) to create techniques called privacy preservation techniques (PPTs). These PPTs achieve various privacy goals and address different privacy concerns by mitigating potential privacy threats within IoT systems. This study carried out a scoping review of different types of PPTs used in previous research works on IoT systems between 2010 and early 2023 to further explore the advantages of privacy preservation in these systems. This scoping review looks at privacy goals, possible technologies used for building PET, the integration of PPTs into the computing layer of the IoT architecture, different IoT applications in which PPTs are deployed, and the different privacy types addressed by these techniques within IoT systems. Key findings, such as the prominent privacy goal and privacy type in IoT, are discussed in this survey, along with identified research gaps that could inform future endeavors in privacy research and benefit the privacy research community and other stakeholders in IoT systems.</li>
</ul>

<h3>Title: Exploring Token-Level Augmentation in Vision Transformer for Semi-Supervised Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Dengke Zhang, Quan Tang, Fagui Liu, C. L. Philip Chen, Haiqing Mei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02459">https://arxiv.org/abs/2503.02459</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02459">https://arxiv.org/pdf/2503.02459</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02459]] Exploring Token-Level Augmentation in Vision Transformer for Semi-Supervised Semantic Segmentation(https://arxiv.org/abs/2503.02459)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised semantic segmentation has witnessed remarkable advancements in recent years. However, existing algorithms are based on convolutional neural networks and directly applying them to Vision Transformers poses certain limitations due to conceptual disparities. To this end, we propose TokenMix, a data augmentation technique specifically designed for semi-supervised semantic segmentation with Vision Transformers. TokenMix aligns well with the global attention mechanism by mixing images at the token level, enhancing learning capability for contexutual information among image patches. We further incorporate image augmentation and feature augmentation to promote the diversity of augmentation. Moreover, to enhance consistency regularization, we propose a dual-branch framework where each branch applies both image augmentation and feature augmentation to the input image. We conduct extensive experiments across multiple benchmark datasets, including Pascal VOC 2012, Cityscapes, and COCO. Results suggest that the proposed method outperforms state-of-the-art algorithms with notably observed accuracy improvement, especially under the circumstance of limited fine annotations.</li>
</ul>

<h3>Title: It Helps to Take a Second Opinion: Teaching Smaller LLMs to Deliberate Mutually via Selective Rationale Optimisation</h3>
<ul>
<li><strong>Authors: </strong>Sohan Patnaik, Milan Aggarwal, Sumit Bhatia, Balaji Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02463">https://arxiv.org/abs/2503.02463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02463">https://arxiv.org/pdf/2503.02463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02463]] It Helps to Take a Second Opinion: Teaching Smaller LLMs to Deliberate Mutually via Selective Rationale Optimisation(https://arxiv.org/abs/2503.02463)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Very large language models (LLMs) such as GPT-4 have shown the ability to handle complex tasks by generating and self-refining step-by-step rationales. Smaller language models (SLMs), typically with < 13B parameters, have been improved by using the data generated from very-large LMs through knowledge distillation. However, various practical constraints such as API costs, copyright, legal and ethical policies restrict using large (often opaque) models to train smaller models for commercial use. Limited success has been achieved at improving the ability of an SLM to explore the space of possible rationales and evaluate them by itself through self-deliberation. To address this, we propose COALITION, a trainable framework that facilitates interaction between two variants of the same SLM and trains them to generate and refine rationales optimized for the end-task. The variants exhibit different behaviors to produce a set of diverse candidate rationales during the generation and refinement steps. The model is then trained via Selective Rationale Optimization (SRO) to prefer generating rationale candidates that maximize the likelihood of producing the ground-truth answer. During inference, COALITION employs a controller to select the suitable variant for generating and refining the rationales. On five different datasets covering mathematical problems, commonsense reasoning, and natural language inference, COALITION outperforms several baselines by up to 5%. Our ablation studies reveal that cross-communication between the two variants performs better than using the single model to self-refine the rationales. We also demonstrate the applicability of COALITION for LMs of varying scales (4B to 14B parameters) and model families (Mistral, Llama, Qwen, Phi). We release the code for this work at this https URL.</li>
</ul>

<h3>Title: BioD2C: A Dual-level Semantic Consistency Constraint Framework for Biomedical VQA</h3>
<ul>
<li><strong>Authors: </strong>Zhengyang Ji, Shang Gao, Li Liu, Yifan Jia, Yutao Yue</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02476">https://arxiv.org/abs/2503.02476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02476">https://arxiv.org/pdf/2503.02476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02476]] BioD2C: A Dual-level Semantic Consistency Constraint Framework for Biomedical VQA(https://arxiv.org/abs/2503.02476)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Biomedical visual question answering (VQA) has been widely studied and has demonstrated significant application value and potential in fields such as assistive medical diagnosis. Despite their success, current biomedical VQA models perform multimodal information interaction only at the model level within large language models (LLMs), leading to suboptimal multimodal semantic alignment when dealing with complex tasks. To address this issue, we propose BioD2C: a novel Dual-level Semantic Consistency Constraint Framework for Biomedical VQA, which achieves dual-level semantic interaction alignment at both the model and feature levels, enabling the model to adaptively learn visual features based on the question. Specifically, we firstly integrate textual features into visual features via an image-text fusion mechanism as feature-level semantic interaction, obtaining visual features conditioned on the given text; and then introduce a text-queue-based cross-modal soft semantic loss function to further align the image semantics with the question semantics. Specifically, in this work, we establish a new dataset, BioVGQ, to address inherent biases in prior datasets by filtering manually-altered images and aligning question-answer pairs with multimodal context, and train our model on this dataset. Extensive experimental results demonstrate that BioD2C achieves state-of-the-art (SOTA) performance across multiple downstream datasets, showcasing its robustness, generalizability, and potential to advance biomedical VQA research.</li>
</ul>

<h3>Title: A Novel Streamline-based diffusion MRI Tractography Registration Method with Probabilistic Keypoint Detection</h3>
<ul>
<li><strong>Authors: </strong>Junyi Wang, Mubai Du, Ye Wu, Yijie Li, William M. Wells III, Lauren J. O'Donnell, Fan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02481">https://arxiv.org/abs/2503.02481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02481">https://arxiv.org/pdf/2503.02481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02481]] A Novel Streamline-based diffusion MRI Tractography Registration Method with Probabilistic Keypoint Detection(https://arxiv.org/abs/2503.02481)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Registration of diffusion MRI tractography is an essential step for analyzing group similarities and variations in the brain's white matter (WM). Streamline-based registration approaches can leverage the 3D geometric information of fiber pathways to enable spatial alignment after registration. Existing methods usually rely on the optimization of the spatial distances to identify the optimal transformation. However, such methods overlook point connectivity patterns within the streamline itself, limiting their ability to identify anatomical correspondences across tractography datasets. In this work, we propose a novel unsupervised approach using deep learning to perform streamline-based dMRI tractography registration. The overall idea is to identify corresponding keypoint pairs across subjects for spatial alignment of tractography datasets. We model tractography as point clouds to leverage the graph connectivity along streamlines. We propose a novel keypoint detection method for streamlines, framed as a probabilistic classification task to identify anatomically consistent correspondences across unstructured streamline sets. In the experiments, we compare several existing methods and show highly effective and efficient tractography registration performance.</li>
</ul>

<h3>Title: Deep Robust Reversible Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Jiale Chen, Wei Wang, Chongyang Shi, Li Dong, Yuanman Li, Xiping Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02490">https://arxiv.org/abs/2503.02490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02490">https://arxiv.org/pdf/2503.02490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02490]] Deep Robust Reversible Watermarking(https://arxiv.org/abs/2503.02490)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Robust Reversible Watermarking (RRW) enables perfect recovery of cover images and watermarks in lossless channels while ensuring robust watermark extraction in lossy channels. Existing RRW methods, mostly non-deep learning-based, face complex designs, high computational costs, and poor robustness, limiting their practical use. This paper proposes Deep Robust Reversible Watermarking (DRRW), a deep learning-based RRW scheme. DRRW uses an Integer Invertible Watermark Network (iIWN) to map integer data distributions invertibly, addressing conventional RRW limitations. Unlike traditional RRW, which needs distortion-specific designs, DRRW employs an encoder-noise layer-decoder framework for adaptive robustness via end-to-end training. In inference, cover image and watermark map to an overflowed stego image and latent variables, compressed by arithmetic coding into a bitstream embedded via reversible data hiding for lossless recovery. We introduce an overflow penalty loss to reduce pixel overflow, shortening the auxiliary bitstream while enhancing robustness and stego image quality. An adaptive weight adjustment strategy avoids manual watermark loss weighting, improving training stability and performance. Experiments show DRRW outperforms state-of-the-art RRW methods, boosting robustness and cutting embedding, extraction, and recovery complexities by 55.14\(\times\), 5.95\(\times\), and 3.57\(\times\), respectively. The auxiliary bitstream shrinks by 43.86\(\times\), with reversible embedding succeeding on 16,762 PASCAL VOC 2012 images, advancing practical RRW. DRRW exceeds irreversible robust watermarking in robustness and quality while maintaining reversibility.</li>
</ul>

<h3>Title: Union of Experts: Adapting Hierarchical Routing to Equivalently Decomposed Transformer</h3>
<ul>
<li><strong>Authors: </strong>Yujiao Yang, Jing Lian, Linhui Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02495">https://arxiv.org/abs/2503.02495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02495">https://arxiv.org/pdf/2503.02495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02495]] Union of Experts: Adapting Hierarchical Routing to Equivalently Decomposed Transformer(https://arxiv.org/abs/2503.02495)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) enhances model performance while maintaining computational efficiency, making it well-suited for large-scale applications. However, expert in exist MoE paradigm works as an individual, thereby lacking high-quality expert interactions. Moreover, they have not been effectively extended to attention block, which constrains further efficiency improvements. To tackle these issues, we propose Union-of-Experts (UoE), which decomposes transformer into an equitant group of experts, and then implement dynamic routing on input data and experts. Our approach advances MoE design with three key innovations: (1) We conducted equitant expert decomposition on both MLP blocks and attention blocks based on matrix partition in tensor parallelism. (2) We developed two routing paradigms: patch wise data selection and expert selection, to apply routing across different levels. (3) We design the architecture of UoE model, including Selective Multi-Head Attention (SMHA) and Union-of-MLP-Experts (UoME). (4) We develop parallel implementation of UoE's routing and computation operation, and optimize efficiency based on the hardware processing analysis. The experiments demonstrate that the model employed with UoE surpass Full Attention, state-of-art MoEs and efficient transformers in several tasks across image and natural language domains. The source codes are available at this https URL.</li>
</ul>

<h3>Title: Attack Tree Distance: a practical examination of tree difference measurement within cyber security</h3>
<ul>
<li><strong>Authors: </strong>Nathan D. Schiele, Olga Gadyatskaya</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02499">https://arxiv.org/abs/2503.02499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02499">https://arxiv.org/pdf/2503.02499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02499]] Attack Tree Distance: a practical examination of tree difference measurement within cyber security(https://arxiv.org/abs/2503.02499)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>CONTEXT. Attack treesare a recommended threat modeling tool, but there is no established method to compare them. OBJECTIVE. We aim to establish a method to compare "real" attack trees, based on both the structure of the tree itself and the meaning of the node labels. METHOD. We define four methods of comparison (three novel and one established) and compare them to a dataset of attack trees created from a study run on students (n = 39). These attack trees all follow from the same scenario, but have slightly different labels. RESULTS. We find that applying semantic similarity as a means of comparing node labels is a valid approach. Further, we find that treeedit distance (established) and radical distance (novel) are themost promising methods of comparison in most circumstances. CONCLUSION. We show that these two methods are valid as means of comparing attack trees, and suggest a novel technique for using semantic similarity to compare node labels. We further suggest that these methods can be used to compare attack trees in a real-world scenario, and that they can be used to identify similar attack trees.</li>
</ul>

<h3>Title: LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jianghao Chen, Junhong Wu, Yangyifan Xu, Jiajun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02502">https://arxiv.org/abs/2503.02502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02502">https://arxiv.org/pdf/2503.02502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02502]] LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs(https://arxiv.org/abs/2503.02502)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context modeling has drawn more and more attention in the area of Large Language Models (LLMs). Continual training with long-context data becomes the de-facto method to equip LLMs with the ability to process long inputs. However, it still remains an open challenge to measure the quality of long-context training data. To address this issue, we propose a Long-context data selection framework with Attention-based Dependency Measurement (LADM), which can efficiently identify high-quality long-context data from a large-scale, multi-domain pre-training corpus. LADM leverages the retrieval capabilities of the attention mechanism to capture contextual dependencies, ensuring a comprehensive quality measurement of long-context data. Experimental results show that our LADM framework significantly boosts the performance of LLMs on multiple long-context tasks with only 1B tokens for continual training.</li>
</ul>

<h3>Title: Deepfake Detection via Knowledge Injection</h3>
<ul>
<li><strong>Authors: </strong>Tonghui Li, Yuanfang Guo, Zeming Liu, Heqi Peng, Yunhong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02503">https://arxiv.org/abs/2503.02503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02503">https://arxiv.org/pdf/2503.02503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02503]] Deepfake Detection via Knowledge Injection(https://arxiv.org/abs/2503.02503)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Deepfake detection technologies become vital because current generative AI models can generate realistic deepfakes, which may be utilized in malicious purposes. Existing deepfake detection methods either rely on developing classification methods to better fit the distributions of the training data, or exploiting forgery synthesis mechanisms to learn a more comprehensive forgery distribution. Unfortunately, these methods tend to overlook the essential role of real data knowledge, which limits their generalization ability in processing the unseen real and fake data. To tackle these challenges, in this paper, we propose a simple and novel approach, named Knowledge Injection based deepfake Detection (KID), by constructing a multi-task learning based knowledge injection framework, which can be easily plugged into existing ViT-based backbone models, including foundation models. Specifically, a knowledge injection module is proposed to learn and inject necessary knowledge into the backbone model, to achieve a more accurate modeling of the distributions of real and fake data. A coarse-grained forgery localization branch is constructed to learn the forgery locations in a multi-task learning manner, to enrich the learned forgery knowledge for the knowledge injection module. Two layer-wise suppression and contrast losses are proposed to emphasize the knowledge of real data in the knowledge injection module, to further balance the portions of the real and fake knowledge. Extensive experiments have demonstrated that our KID possesses excellent compatibility with different scales of Vit-based backbone models, and achieves state-of-the-art generalization performance while enhancing the training convergence speed.</li>
</ul>

<h3>Title: Q&C: When Quantization Meets Cache in Efficient Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Xin Ding, Xin Li, Haotong Qin, Zhibo Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02508">https://arxiv.org/abs/2503.02508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02508">https://arxiv.org/pdf/2503.02508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02508]] Q&C: When Quantization Meets Cache in Efficient Image Generation(https://arxiv.org/abs/2503.02508)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Quantization and cache mechanisms are typically applied individually for efficient Diffusion Transformers (DiTs), each demonstrating notable potential for acceleration. However, the promoting effect of combining the two mechanisms on efficient generation remains under-explored. Through empirical investigation, we find that the combination of quantization and cache mechanisms for DiT is not straightforward, and two key challenges lead to severe catastrophic performance degradation: (i) the sample efficacy of calibration datasets in post-training quantization (PTQ) is significantly eliminated by cache operation; (ii) the combination of the above mechanisms introduces more severe exposure bias within sampling distribution, resulting in amplified error accumulation in the image generation process. In this work, we take advantage of these two acceleration mechanisms and propose a hybrid acceleration method by tackling the above challenges, aiming to further improve the efficiency of DiTs while maintaining excellent generation capability. Concretely, a temporal-aware parallel clustering (TAP) is designed to dynamically improve the sample selection efficacy for the calibration within PTQ for different diffusion steps. A variance compensation (VC) strategy is derived to correct the sampling distribution. It mitigates exposure bias through an adaptive correction factor generation. Extensive experiments have shown that our method has accelerated DiTs by 12.7x while preserving competitive generation capability. The code will be available at this https URL.</li>
</ul>

<h3>Title: TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Oliver Grainge, Michael Milford, Indu Bodala, Sarvapali D. Ramchurn, Shoaib Ehsan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02511">https://arxiv.org/abs/2503.02511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02511">https://arxiv.org/pdf/2503.02511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02511]] TeTRA-VPR: A Ternary Transformer Approach for Compact Visual Place Recognition(https://arxiv.org/abs/2503.02511)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Visual Place Recognition (VPR) localizes a query image by matching it against a database of geo-tagged reference images, making it essential for navigation and mapping in robotics. Although Vision Transformer (ViT) solutions deliver high accuracy, their large models often exceed the memory and compute budgets of resource-constrained platforms such as drones and mobile robots. To address this issue, we propose TeTRA, a ternary transformer approach that progressively quantizes the ViT backbone to 2-bit precision and binarizes its final embedding layer, offering substantial reductions in model size and latency. A carefully designed progressive distillation strategy preserves the representational power of a full-precision teacher, allowing TeTRA to retain or even surpass the accuracy of uncompressed convolutional counterparts, despite using fewer resources. Experiments on standard VPR benchmarks demonstrate that TeTRA reduces memory consumption by up to 69% compared to efficient baselines, while lowering inference latency by 35%, with either no loss or a slight improvement in recall@1. These gains enable high-accuracy VPR on power-constrained, memory-limited robotic platforms, making TeTRA an appealing solution for real-world deployment.</li>
</ul>

<h3>Title: Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent</h3>
<ul>
<li><strong>Authors: </strong>Xingzuo Li, Kehai Chen, Yunfei Long, Xuefeng Bai, Yong Xu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02519">https://arxiv.org/abs/2503.02519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02519">https://arxiv.org/pdf/2503.02519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02519]] Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent(https://arxiv.org/abs/2503.02519)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods.</li>
</ul>

<h3>Title: SAGE-Amine: Generative Amine Design with Multi-Property Optimization for Efficient CO2 Capture</h3>
<ul>
<li><strong>Authors: </strong>Hocheol Lim, Hyein Cho, Jeonghoon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02534">https://arxiv.org/abs/2503.02534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02534">https://arxiv.org/pdf/2503.02534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02534]] SAGE-Amine: Generative Amine Design with Multi-Property Optimization for Efficient CO2 Capture(https://arxiv.org/abs/2503.02534)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Efficient CO2 capture is vital for mitigating climate change, with amine-based solvents being widely used due to their strong reactivity with CO2. However, optimizing key properties such as basicity, viscosity, and absorption capacity remains challenging, as traditional methods rely on labor-intensive experimentation and predefined chemical databases, limiting the exploration of novel solutions. Here, SAGE-Amine was introduced, a generative modeling approach that integrates Scoring-Assisted Generative Exploration (SAGE) with quantitative structure-property relationship models to design new amines tailored for CO2 capture. Unlike conventional virtual screening restricted to existing compounds, SAGE-Amine generates novel amines by leveraging autoregressive natural language processing models trained on amine datasets. SAGE-Amine identified known amines for CO2 capture from scratch and successfully performed single-property optimization, increasing basicity or reducing viscosity or vapor pressure. Furthermore, it facilitated multi-property optimization, simultaneously achieving high basicity with low viscosity and vapor pressure. The 10 top-ranked amines were suggested using SAGE-Amine and their thermodynamic properties were further assessed using COSMO-RS simulations, confirming their potential for CO2 capture. These results highlight the potential of generative modeling in accelerating the discovery of amine solvents and expanding the possibilities for industrial CO2 capture applications.</li>
</ul>

<h3>Title: RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification</h3>
<ul>
<li><strong>Authors: </strong>Zhen Yang, Guibao Shen, Liang Hou, Mushui Liu, Luozhou Wang, Xin Tao, Pengfei Wan, Di Zhang, Ying-Cong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02537">https://arxiv.org/abs/2503.02537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02537">https://arxiv.org/pdf/2503.02537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02537]] RectifiedHR: Enable Efficient High-Resolution Image Generation via Energy Rectification(https://arxiv.org/abs/2503.02537)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved remarkable advances in various image generation tasks. However, their performance notably declines when generating images at resolutions higher than those used during the training period. Despite the existence of numerous methods for producing high-resolution images, they either suffer from inefficiency or are hindered by complex operations. In this paper, we propose RectifiedHR, an efficient and straightforward solution for training-free high-resolution image generation. Specifically, we introduce the noise refresh strategy, which theoretically only requires a few lines of code to unlock the model's high-resolution generation ability and improve efficiency. Additionally, we first observe the phenomenon of energy decay that may cause image blurriness during the high-resolution image generation process. To address this issue, we propose an Energy Rectification strategy, where modifying the hyperparameters of the classifier-free guidance effectively improves the generation performance. Our method is entirely training-free and boasts a simple implementation logic. Through extensive comparisons with numerous baseline methods, our RectifiedHR demonstrates superior effectiveness and efficiency.</li>
</ul>

<h3>Title: Disentangled Knowledge Tracing for Alleviating Cognitive Bias</h3>
<ul>
<li><strong>Authors: </strong>Yiyun Zhou, Zheqi Lv, Shengyu Zhang, Jingyuan Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02539">https://arxiv.org/abs/2503.02539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02539">https://arxiv.org/pdf/2503.02539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02539]] Disentangled Knowledge Tracing for Alleviating Cognitive Bias(https://arxiv.org/abs/2503.02539)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In the realm of Intelligent Tutoring System (ITS), the accurate assessment of students' knowledge states through Knowledge Tracing (KT) is crucial for personalized learning. However, due to data bias, $\textit{i.e.}$, the unbalanced distribution of question groups ($\textit{e.g.}$, concepts), conventional KT models are plagued by cognitive bias, which tends to result in cognitive underload for overperformers and cognitive overload for underperformers. More seriously, this bias is amplified with the exercise recommendations by ITS. After delving into the causal relations in the KT models, we identify the main cause as the confounder effect of students' historical correct rate distribution over question groups on the student representation and prediction score. Towards this end, we propose a Disentangled Knowledge Tracing (DisKT) model, which separately models students' familiar and unfamiliar abilities based on causal effects and eliminates the impact of the confounder in student representation within the model. Additionally, to shield the contradictory psychology ($\textit{e.g.}$, guessing and mistaking) in the students' biased data, DisKT introduces a contradiction attention mechanism. Furthermore, DisKT enhances the interpretability of the model predictions by integrating a variant of Item Response Theory. Experimental results on 11 benchmarks and 3 synthesized datasets with different bias strengths demonstrate that DisKT significantly alleviates cognitive bias and outperforms 16 baselines in evaluation accuracy.</li>
</ul>

<h3>Title: PVTree: Realistic and Controllable Palm Vein Generation for Recognition Tasks</h3>
<ul>
<li><strong>Authors: </strong>Sheng Shang, Chenglong Zhao, Ruixin Zhang, Jianlong Jin, Jingyun Zhang, Rizen Guo, Shouhong Ding, Yunsheng Wu, Yang Zhao, Wei Jia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02547">https://arxiv.org/abs/2503.02547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02547">https://arxiv.org/pdf/2503.02547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02547]] PVTree: Realistic and Controllable Palm Vein Generation for Recognition Tasks(https://arxiv.org/abs/2503.02547)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect, biometric, generative</a></li>
<li><strong>Abstract: </strong>Palm vein recognition is an emerging biometric technology that offers enhanced security and privacy. However, acquiring sufficient palm vein data for training deep learning-based recognition models is challenging due to the high costs of data collection and privacy protection constraints. This has led to a growing interest in generating pseudo-palm vein data using generative models. Existing methods, however, often produce unrealistic palm vein patterns or struggle with controlling identity and style attributes. To address these issues, we propose a novel palm vein generation framework named PVTree. First, the palm vein identity is defined by a complex and authentic 3D palm vascular tree, created using an improved Constrained Constructive Optimization (CCO) algorithm. Second, palm vein patterns of the same identity are generated by projecting the same 3D vascular tree into 2D images from different views and converting them into realistic images using a generative model. As a result, PVTree satisfies the need for both identity consistency and intra-class diversity. Extensive experiments conducted on several publicly available datasets demonstrate that our proposed palm vein generation method surpasses existing methods and achieves a higher TAR@FAR=1e-4 under the 1:1 Open-set protocol. To the best of our knowledge, this is the first time that the performance of a recognition model trained on synthetic palm vein data exceeds that of the recognition model trained on real data, which indicates that palm vein image generation research has a promising future.</li>
</ul>

<h3>Title: Federated nnU-Net for Privacy-Preserving Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Grzegorz Skorupko, Fotios Avgoustidis, Carlos Martín-Isla, Lidia Garrucho, Dimitri A. Kessler, Esmeralda Ruiz Pujadas, Oliver Díaz, Maciej Bobowicz, Katarzyna Gwoździewicz, Xavier Bargalló, Paulius Jaruševičius, Kaisar Kushibar, Karim Lekadir</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02549">https://arxiv.org/abs/2503.02549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02549">https://arxiv.org/pdf/2503.02549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02549]] Federated nnU-Net for Privacy-Preserving Medical Image Segmentation(https://arxiv.org/abs/2503.02549)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, federate, segmentation</a></li>
<li><strong>Abstract: </strong>The nnU-Net framework has played a crucial role in medical image segmentation and has become the gold standard in multitudes of applications targeting different diseases, organs, and modalities. However, so far it has been used primarily in a centralized approach where the data collected from hospitals are stored in one center and used to train the nnU-Net. This centralized approach has various limitations, such as leakage of sensitive patient information and violation of patient privacy. Federated learning is one of the approaches to train a segmentation model in a decentralized manner that helps preserve patient privacy. In this paper, we propose FednnU-Net, a federated learning extension of nnU-Net. We introduce two novel federated learning methods to the nnU-Net framework - Federated Fingerprint Extraction (FFE) and Asymmetric Federated Averaging (AsymFedAvg) - and experimentally show their consistent performance for breast, cardiac and fetal segmentation using 6 datasets representing samples from 18 institutions. Additionally, to further promote research and deployment of decentralized training in privacy constrained institutions, we make our plug-n-play framework public. The source-code is available at this https URL .</li>
</ul>

<h3>Title: Tracking-Aware Deformation Field Estimation for Non-rigid 3D Reconstruction in Robotic Surgeries</h3>
<ul>
<li><strong>Authors: </strong>Zeqing Wang, Han Fang, Yihong Xu, Yutong Ban</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02558">https://arxiv.org/abs/2503.02558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02558">https://arxiv.org/pdf/2503.02558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02558]] Tracking-Aware Deformation Field Estimation for Non-rigid 3D Reconstruction in Robotic Surgeries(https://arxiv.org/abs/2503.02558)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Minimally invasive procedures have been advanced rapidly by the robotic laparoscopic surgery. The latter greatly assists surgeons in sophisticated and precise operations with reduced invasiveness. Nevertheless, it is still safety critical to be aware of even the least tissue deformation during instrument-tissue interactions, especially in 3D space. To address this, recent works rely on NeRF to render 2D videos from different perspectives and eliminate occlusions. However, most of the methods fail to predict the accurate 3D shapes and associated deformation estimates robustly. Differently, we propose Tracking-Aware Deformation Field (TADF), a novel framework which reconstructs the 3D mesh along with the 3D tissue deformation simultaneously. It first tracks the key points of soft tissue by a foundation vision model, providing an accurate 2D deformation field. Then, the 2D deformation field is smoothly incorporated with a neural implicit reconstruction network to obtain tissue deformation in the 3D space. Finally, we experimentally demonstrate that the proposed method provides more accurate deformation estimation compared with other 3D neural reconstruction methods in two public datasets.</li>
</ul>

<h3>Title: TFHE-SBC: Software Designs for Fully Homomorphic Encryption over the Torus on Single Board Computers</h3>
<ul>
<li><strong>Authors: </strong>Marin Matsumoto, Ai Nozaki, Hideki Takase, Masato Oguchi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02559">https://arxiv.org/abs/2503.02559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02559">https://arxiv.org/pdf/2503.02559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02559]] TFHE-SBC: Software Designs for Fully Homomorphic Encryption over the Torus on Single Board Computers(https://arxiv.org/abs/2503.02559)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Fully homomorphic encryption (FHE) is a technique that enables statistical processing and machine learning while protecting data including sensitive information collected by such single board computers (SBCs) on a cloud server. Among FHE schemes, the TFHE scheme is capable of homomorphic NAND operation, and unlike other FHE schemes, it can perform any operation, such as minimum, maximum, and comparison operations. However, TFHE requires Torus Learning With Error (TLWE) encryption, which encrypts one bit at a time, resulting in less efficient encryption and larger ciphertext size than the other schemes. In addition, SBCs have a limited number of hardware accelerators compared to servers, making it difficult to perform the same optimization as servers. In this study, we propose a novel SBC-specific design TFHE-SBC to accelerate the client-side TFHE operations and achieve communication and energy efficiency. Experimental results show that the TFHE-SBC encryption is up to 2486 times faster, communication efficiency improves 512 times higher, and 12 to 2004 times more energy efficiency than the state-of-the-art.</li>
</ul>

<h3>Title: LLM-Safety Evaluations Lack Robustness</h3>
<ul>
<li><strong>Authors: </strong>Tim Beyer, Sophie Xhonneux, Simon Geisler, Gauthier Gidel, Leo Schwinn, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02574">https://arxiv.org/abs/2503.02574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02574">https://arxiv.org/pdf/2503.02574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02574]] LLM-Safety Evaluations Lack Robustness(https://arxiv.org/abs/2503.02574)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we argue that current safety alignment research efforts for large language models are hindered by many intertwined sources of noise, such as small datasets, methodological inconsistencies, and unreliable evaluation setups. This can, at times, make it impossible to evaluate and compare attacks and defenses fairly, thereby slowing progress. We systematically analyze the LLM safety evaluation pipeline, covering dataset curation, optimization strategies for automated red-teaming, response generation, and response evaluation using LLM judges. At each stage, we identify key issues and highlight their practical impact. We also propose a set of guidelines for reducing noise and bias in evaluations of future attack and defense papers. Lastly, we offer an opposing perspective, highlighting practical reasons for existing limitations. We believe that addressing the outlined problems in future research will improve the field's ability to generate easily comparable results and make measurable progress.</li>
</ul>

<h3>Title: SPG: Improving Motion Diffusion by Smooth Perturbation Guidance</h3>
<ul>
<li><strong>Authors: </strong>Boseong Jeon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02577">https://arxiv.org/abs/2503.02577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02577">https://arxiv.org/pdf/2503.02577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02577]] SPG: Improving Motion Diffusion by Smooth Perturbation Guidance(https://arxiv.org/abs/2503.02577)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper presents a test-time guidance method to improve the output quality of the human motion diffusion models without requiring additional training. To have negative guidance, Smooth Perturbation Guidance (SPG) builds a weak model by temporally smoothing the motion in the denoising steps. Compared to model-agnostic methods originating from the image generation field, SPG effectively mitigates out-of-distribution issues when perturbing motion diffusion models. In SPG guidance, the nature of motion structure remains intact. This work conducts a comprehensive analysis across distinct model architectures and tasks. Despite its extremely simple implementation and no need for additional training requirements, SPG consistently enhances motion fidelity. Project page can be found at this https URL</li>
</ul>

<h3>Title: TS-CGNet: Temporal-Spatial Fusion Meets Centerline-Guided Diffusion for BEV Mapping</h3>
<ul>
<li><strong>Authors: </strong>Xinying Hong, Siyu Li, Kang Zeng, Hao Shi, Bomin Peng, Kailun Yang, Zhiyong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02578">https://arxiv.org/abs/2503.02578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02578">https://arxiv.org/pdf/2503.02578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02578]] TS-CGNet: Temporal-Spatial Fusion Meets Centerline-Guided Diffusion for BEV Mapping(https://arxiv.org/abs/2503.02578)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Bird's Eye View (BEV) perception technology is crucial for autonomous driving, as it generates top-down 2D maps for environment perception, navigation, and decision-making. Nevertheless, the majority of current BEV map generation studies focusing on visual map generation lack depth-aware reasoning capabilities. They exhibit limited efficacy in managing occlusions and handling complex environments, with a notable decline in perceptual performance under adverse weather conditions or low-light scenarios. Therefore, this paper proposes TS-CGNet, which leverages Temporal-Spatial fusion with Centerline-Guided diffusion. This visual framework, grounded in prior knowledge, is designed for integration into any existing network for building BEV maps. Specifically, this framework is decoupled into three parts: Local mapping system involves the initial generation of semantic maps using purely visual information; The Temporal-Spatial Aligner Module (TSAM) integrates historical information into mapping generation by applying transformation matrices; The Centerline-Guided Diffusion Model (CGDM) is a prediction module based on the diffusion model. CGDM incorporates centerline information through spatial-attention mechanisms to enhance semantic segmentation reconstruction. We construct BEV semantic segmentation maps by our methods on the public nuScenes and the robustness benchmarks under various corruptions. Our method improves 1.90%, 1.73%, and 2.87% for perceived ranges of 60x30m, 120x60m, and 240x60m in the task of BEV HD mapping. TS-CGNet attains an improvement of 1.92% for perceived ranges of 100x100m in the task of BEV semantic mapping. Moreover, TS-CGNet achieves an average improvement of 2.92% in detection accuracy under varying weather conditions and sensor interferences in the perception range of 240x60m. The source code will be publicly available at this https URL.</li>
</ul>

<h3>Title: MM-OR: A Large Multimodal Operating Room Dataset for Semantic Understanding of High-Intensity Surgical Environments</h3>
<ul>
<li><strong>Authors: </strong>Ege Özsoy, Chantal Pellegrini, Tobias Czempiel, Felix Tristram, Kun Yuan, David Bani-Harouni, Ulrich Eck, Benjamin Busam, Matthias Keicher, Nassir Navab</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02579">https://arxiv.org/abs/2503.02579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02579">https://arxiv.org/pdf/2503.02579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02579]] MM-OR: A Large Multimodal Operating Room Dataset for Semantic Understanding of High-Intensity Surgical Environments(https://arxiv.org/abs/2503.02579)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Operating rooms (ORs) are complex, high-stakes environments requiring precise understanding of interactions among medical staff, tools, and equipment for enhancing surgical assistance, situational awareness, and patient safety. Current datasets fall short in scale, realism and do not capture the multimodal nature of OR scenes, limiting progress in OR modeling. To this end, we introduce MM-OR, a realistic and large-scale multimodal spatiotemporal OR dataset, and the first dataset to enable multimodal scene graph generation. MM-OR captures comprehensive OR scenes containing RGB-D data, detail views, audio, speech transcripts, robotic logs, and tracking data and is annotated with panoptic segmentations, semantic scene graphs, and downstream task labels. Further, we propose MM2SG, the first multimodal large vision-language model for scene graph generation, and through extensive experiments, demonstrate its ability to effectively leverage multimodal inputs. Together, MM-OR and MM2SG establish a new benchmark for holistic OR understanding, and open the path towards multimodal scene analysis in complex, high-stakes environments. Our code, and data is available at this https URL.</li>
</ul>

<h3>Title: Unveiling the Potential of Segment Anything Model 2 for RGB-Thermal Semantic Segmentation with Language Guidance</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Zhao, Fei Teng, Kai Luo, Guoqiang Zhao, Zhiyong Li, Xu Zheng, Kailun Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02581">https://arxiv.org/abs/2503.02581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02581">https://arxiv.org/pdf/2503.02581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02581]] Unveiling the Potential of Segment Anything Model 2 for RGB-Thermal Semantic Segmentation with Language Guidance(https://arxiv.org/abs/2503.02581)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The perception capability of robotic systems relies on the richness of the dataset. Although Segment Anything Model 2 (SAM2), trained on large datasets, demonstrates strong perception potential in perception tasks, its inherent training paradigm prevents it from being suitable for RGB-T tasks. To address these challenges, we propose SHIFNet, a novel SAM2-driven Hybrid Interaction Paradigm that unlocks the potential of SAM2 with linguistic guidance for efficient RGB-Thermal perception. Our framework consists of two key components: (1) Semantic-Aware Cross-modal Fusion (SACF) module that dynamically balances modality contributions through text-guided affinity learning, overcoming SAM2's inherent RGB bias; (2) Heterogeneous Prompting Decoder (HPD) that enhances global semantic information through a semantic enhancement module and then combined with category embeddings to amplify cross-modal semantic consistency. With 32.27M trainable parameters, SHIFNet achieves state-of-the-art segmentation performance on public benchmarks, reaching 89.8% on PST900 and 67.8% on FMB, respectively. The framework facilitates the adaptation of pre-trained large models to RGB-T segmentation tasks, effectively mitigating the high costs associated with data collection while endowing robotic systems with comprehensive perception capabilities. The source code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: MciteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Caiyu Hu, Yikai Zhang, Tinghui Zhu, Yiwei Ye, Yanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02589">https://arxiv.org/abs/2503.02589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02589">https://arxiv.org/pdf/2503.02589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02589]] MciteBench: A Benchmark for Multimodal Citation Text Generation in MLLMs(https://arxiv.org/abs/2503.02589)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have advanced in integrating diverse modalities but frequently suffer from hallucination. A promising solution to mitigate this issue is to generate text with citations, providing a transparent chain for verification. However, existing work primarily focuses on generating citations for text-only content, overlooking the challenges and opportunities of multimodal contexts. To address this gap, we introduce MCiteBench, the first benchmark designed to evaluate and analyze the multimodal citation text generation ability of MLLMs. Our benchmark comprises data derived from academic papers and review-rebuttal interactions, featuring diverse information sources and multimodal content. We comprehensively evaluate models from multiple dimensions, including citation quality, source reliability, and answer accuracy. Through extensive experiments, we observe that MLLMs struggle with multimodal citation text generation. We also conduct deep analyses of models' performance, revealing that the bottleneck lies in attributing the correct sources rather than understanding the multimodal content.</li>
</ul>

<h3>Title: StageDesigner: Artistic Stage Generation for Scenography via Theater Scripts</h3>
<ul>
<li><strong>Authors: </strong>Zhaoxing Gan, Mengtian Li, Ruhua Chen, Zhongxia Ji, Sichen Guo, Huanling Hu, Guangnan Ye, Zuo Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02595">https://arxiv.org/abs/2503.02595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02595">https://arxiv.org/pdf/2503.02595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02595]] StageDesigner: Artistic Stage Generation for Scenography via Theater Scripts(https://arxiv.org/abs/2503.02595)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>In this work, we introduce StageDesigner, the first comprehensive framework for artistic stage generation using large language models combined with layout-controlled diffusion models. Given the professional requirements of stage scenography, StageDesigner simulates the workflows of seasoned artists to generate immersive 3D stage scenes. Specifically, our approach is divided into three primary modules: Script Analysis, which extracts thematic and spatial cues from input scripts; Foreground Generation, which constructs and arranges essential 3D objects; and Background Generation, which produces a harmonious background aligned with the narrative atmosphere and maintains spatial coherence by managing occlusions between foreground and background elements. Furthermore, we introduce the StagePro-V1 dataset, a dedicated dataset with 276 unique stage scenes spanning different historical styles and annotated with scripts, images, and detailed 3D layouts, specifically tailored for this task. Finally, evaluations using both standard and newly proposed metrics, along with extensive user studies, demonstrate the effectiveness of StageDesigner. Project can be found at: this https URL</li>
</ul>

<h3>Title: Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual Attention for Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wei-Yao Wang, Zhao Wang, Helen Suzuki, Yoshiyuki Kobayashi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02597">https://arxiv.org/abs/2503.02597</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02597">https://arxiv.org/pdf/2503.02597</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02597]] Seeing is Understanding: Unlocking Causal Attention into Modality-Mutual Attention for Multimodal LLMs(https://arxiv.org/abs/2503.02597)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent Multimodal Large Language Models (MLLMs) have demonstrated significant progress in perceiving and reasoning over multimodal inquiries, ushering in a new research era for foundation models. However, vision-language misalignment in MLLMs has emerged as a critical challenge, where the textual responses generated by these models are not factually aligned with the given text-image inputs. Existing efforts to address vision-language misalignment have focused on developing specialized vision-language connectors or leveraging visual instruction tuning from diverse domains. In this paper, we tackle this issue from a fundamental yet unexplored perspective by revisiting the core architecture of MLLMs. Most MLLMs are typically built on decoder-only LLMs consisting of a causal attention mechanism, which limits the ability of earlier modalities (e.g., images) to incorporate information from later modalities (e.g., text). To address this problem, we propose AKI, a novel MLLM that unlocks causal attention into modality-mutual attention (MMA) to enable image tokens to attend to text tokens. This simple yet effective design allows AKI to achieve superior performance in 12 multimodal understanding benchmarks (+7.2% on average) without introducing additional parameters and increasing training time. Our MMA design is intended to be generic, allowing for application across various modalities, and scalable to accommodate diverse multimodal scenarios. The code is publicly available at this https URL, and we will release our AKI-4B model to encourage further advancements in MLLMs across various directions.</li>
</ul>

<h3>Title: OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query Processing</h3>
<ul>
<li><strong>Authors: </strong>Yulong Hui, Yihao Liu, Yao Lu, Huanchen Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02603">https://arxiv.org/abs/2503.02603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02603">https://arxiv.org/pdf/2503.02603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02603]] OkraLong: A Flexible Retrieval-Augmented Framework for Long-Text Query Processing(https://arxiv.org/abs/2503.02603)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) encounter challenges in efficiently processing long-text queries, as seen in applications like enterprise document analysis and financial report comprehension. While conventional solutions employ long-context processing or Retrieval-Augmented Generation (RAG), they suffer from prohibitive input expenses or incomplete information. Recent advancements adopt context compression and dynamic retrieval loops, but still sacrifice critical details or incur iterative this http URL address these limitations, we propose OkraLong, a novel framework that flexibly optimizes the entire processing workflow. Unlike prior static or coarse-grained adaptive strategies, OkraLong adopts fine-grained orchestration through three synergistic components: analyzer, organizer and executor. The analyzer characterizes the task states, which guide the organizer in dynamically scheduling the workflow. The executor carries out the execution and generates the final answer. Experimental results demonstrate that OkraLong not only enhances answer accuracy but also achieves cost-effectiveness across a variety of datasets.</li>
</ul>

<h3>Title: XFMamba: Cross-Fusion Mamba for Multi-View Medical Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Zheng, Xu Chen, Shaogang Gong, Xavier Griffin, Greg Slabaugh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02619">https://arxiv.org/abs/2503.02619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02619">https://arxiv.org/pdf/2503.02619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02619]] XFMamba: Cross-Fusion Mamba for Multi-View Medical Image Classification(https://arxiv.org/abs/2503.02619)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Compared to single view medical image classification, using multiple views can significantly enhance predictive accuracy as it can account for the complementarity of each view while leveraging correlations between views. Existing multi-view approaches typically employ separate convolutional or transformer branches combined with simplistic feature fusion strategies. However, these approaches inadvertently disregard essential cross-view correlations, leading to suboptimal classification performance, and suffer from challenges with limited receptive field (CNNs) or quadratic computational complexity (transformers). Inspired by state space sequence models, we propose XFMamba, a pure Mamba-based cross-fusion architecture to address the challenge of multi-view medical image classification. XFMamba introduces a novel two-stage fusion strategy, facilitating the learning of single-view features and their cross-view disparity. This mechanism captures spatially long-range dependencies in each view while enhancing seamless information transfer between views. Results on three public datasets, MURA, CheXpert and DDSM, illustrate the effectiveness of our approach across diverse multi-view medical image classification tasks, showing that it outperforms existing convolution-based and transformer-based multi-view methods. Code is available at this https URL.</li>
</ul>

<h3>Title: Leveraging Self-Supervised Learning Methods for Remote Screening of Subjects with Paroxysmal Atrial Fibrillation</h3>
<ul>
<li><strong>Authors: </strong>Adrian Atienza, Gouthamaan Manimaran, Sadasivan Puthusserypady, Helena Dominguez, Peter K. Jacobsen, Jakob E. Bardram</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02621">https://arxiv.org/abs/2503.02621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02621">https://arxiv.org/pdf/2503.02621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02621]] Leveraging Self-Supervised Learning Methods for Remote Screening of Subjects with Paroxysmal Atrial Fibrillation(https://arxiv.org/abs/2503.02621)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The integration of Artificial Intelligence (AI) into clinical research has great potential to reveal patterns that are difficult for humans to detect, creating impactful connections between inputs and clinical outcomes. However, these methods often require large amounts of labeled data, which can be difficult to obtain in healthcare due to strict privacy laws and the need for experts to annotate data. This requirement creates a bottleneck when investigating unexplored clinical questions. This study explores the application of Self-Supervised Learning (SSL) as a way to obtain preliminary results from clinical studies with limited sized cohorts. To assess our approach, we focus on an underexplored clinical task: screening subjects for Paroxysmal Atrial Fibrillation (P-AF) using remote monitoring, single-lead ECG signals captured during normal sinus rhythm. We evaluate state-of-the-art SSL methods alongside supervised learning approaches, where SSL outperforms supervised learning in this task of interest. More importantly, it prevents misleading conclusions that may arise from poor performance in the latter paradigm when dealing with limited cohort settings.</li>
</ul>

<h3>Title: Rewarding Doubt: A Reinforcement Learning Approach to Confidence Calibration of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Paul Stangel, David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Kamilia Zaripova, Matthias Keicher, Nassir Navab</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02623">https://arxiv.org/abs/2503.02623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02623">https://arxiv.org/pdf/2503.02623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02623]] Rewarding Doubt: A Reinforcement Learning Approach to Confidence Calibration of Large Language Models(https://arxiv.org/abs/2503.02623)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A safe and trustworthy use of Large Language Models (LLMs) requires an accurate expression of confidence in their answers. We introduce a novel Reinforcement Learning (RL) approach for LLM calibration that fine-tunes LLMs to elicit calibrated confidence estimations in their answers to factual questions. We model the problem as a betting game where the model predicts a confidence score together with every answer, and design a reward function that penalizes both over and under-confidence. We prove that under our reward design an optimal policy would result in a perfectly calibrated confidence estimation. Our experiments demonstrate significantly improved confidence calibration and generalization to new tasks without re-training, indicating that our approach teaches a general confidence awareness. This approach enables the training of inherently calibrated LLMs.</li>
</ul>

<h3>Title: Towards Event Extraction with Massive Types: LLM-based Collaborative Annotation and Partitioning Extraction</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Liu, Zixuan Li, Long Bai, Yuxin Zuo, Daozhu Xu, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02628">https://arxiv.org/abs/2503.02628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02628">https://arxiv.org/pdf/2503.02628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02628]] Towards Event Extraction with Massive Types: LLM-based Collaborative Annotation and Partitioning Extraction(https://arxiv.org/abs/2503.02628)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Developing a general-purpose extraction system that can extract events with massive types is a long-standing target in Event Extraction (EE). In doing so, the challenge comes from two aspects: 1) The absence of an efficient and effective annotation method. 2) The absence of a powerful extraction method can handle massive types. For the first challenge, we propose a collaborative annotation method based on Large Language Models (LLMs). Through collaboration among multiple LLMs, it first refines annotations of trigger words from distant supervision and then carries out argument annotation. Next, a voting phase consolidates the annotation preferences across different LLMs. Finally, we create the EEMT dataset, the largest EE dataset to date, featuring over 200,000 samples, 3,465 event types, and 6,297 role types. For the second challenge, we propose an LLM-based Partitioning EE method called LLM-PEE. To overcome the limited context length of LLMs, LLM-PEE first recalls candidate event types and then splits them into multiple partitions for LLMs to extract events. The results in the supervised setting show that LLM-PEE outperforms the state-of-the-art methods by 5.4 in event detection and 6.1 in argument extraction. In the zero-shot setting, LLM-PEE achieves up to 12.9 improvement compared to mainstream LLMs, demonstrating its strong generalization capabilities.</li>
</ul>

<h3>Title: Quantum Geometry insights in Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Noémie C. Combe</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, math.DG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02655">https://arxiv.org/abs/2503.02655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02655">https://arxiv.org/pdf/2503.02655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02655]] Quantum Geometry insights in Deep Learning(https://arxiv.org/abs/2503.02655)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we explore the fundamental role of the Monge-Ampère equation in deep learning, particularly in the context of Boltzmann machines and energy-based models. We first review the structure of Boltzmann learning and its relation to free energy minimization. We then establish a connection between optimal transport theory and deep learning, demonstrating how the Monge-Ampère equation governs probability transformations in generative models. Additionally, we provide insights from quantum geometry, showing that the space of covariance matrices arising in the learning process coincides with the Connes-Araki-Haagerup (CAH) cone in von Neumann algebra theory. Furthermore, we introduce an alternative approach based on renormalization group (RG) flow, which, while distinct from the optimal transport perspective, reveals another manifestation of the Monge-Ampère domain in learning dynamics. This dual perspective offers a deeper mathematical understanding of hierarchical feature learning, bridging concepts from statistical mechanics, quantum geometry, and deep learning theory.</li>
</ul>

<h3>Title: Adapting Decoder-Based Language Models for Diverse Encoder Downstream Tasks</h3>
<ul>
<li><strong>Authors: </strong>Paul Suganthan, Fedor Moiseev, Le Yan, Junru Wu, Jianmo Ni, Jay Han, Imed Zitouni, Enrique Alfonseca, Xuanhui Wang, Zhe Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02656">https://arxiv.org/abs/2503.02656</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02656">https://arxiv.org/pdf/2503.02656</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02656]] Adapting Decoder-Based Language Models for Diverse Encoder Downstream Tasks(https://arxiv.org/abs/2503.02656)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Decoder-based transformers, while revolutionizing language modeling and scaling to immense sizes, have not completely overtaken encoder-heavy architectures in natural language processing. Specifically, encoder-only models remain dominant in tasks like classification, regression, and ranking. This is primarily due to the inherent structure of decoder-based models, which limits their direct applicability to these tasks. In this paper, we introduce Gemma Encoder, adapting the powerful Gemma decoder model to an encoder architecture, thereby unlocking its potential for a wider range of non-generative applications. To optimize the adaptation from decoder to encoder, we systematically analyze various pooling strategies, attention mechanisms, and hyperparameters (e.g., dropout rate). Furthermore, we benchmark Gemma Encoder against established approaches on the GLUE benchmarks, and MS MARCO ranking benchmark, demonstrating its effectiveness and versatility.</li>
</ul>

<h3>Title: LoRA-Null: Low-Rank Adaptation via Null Space for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pengwei Tang, Yong Liu, Dongjie Zhang, Xing Wu, Debing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02659">https://arxiv.org/abs/2503.02659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02659">https://arxiv.org/pdf/2503.02659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02659]] LoRA-Null: Low-Rank Adaptation via Null Space for Large Language Models(https://arxiv.org/abs/2503.02659)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) is the leading parameter-efficient fine-tuning method for Large Language Models (LLMs). However, the fine-tuned LLMs encounter the issue of catastrophic forgetting of the pre-trained world knowledge. To address this issue, inspired by theoretical insights of null space, we propose LoRA-Null, i.e., Low-Rank Adaptation via null space, which builds adapters initialized from the null space of the pre-trained knowledge activation. Concretely, we randomly collect a few data samples and capture their activations after passing through the LLM layer. We perform Singular Value Decomposition on the input activations to obtain their null space. We use the projection of the pre-trained weights onto the null space as the initialization for adapters. Experimental results demonstrate that this initialization approach can effectively preserve the original pre-trained world knowledge of the LLMs during fine-tuning. Additionally, if we freeze the values of the down-projection matrices during fine-tuning, it achieves even better preservation of the pre-trained world knowledge. LoRA-Null effectively preserves pre-trained world knowledge while maintaining strong fine-tuning performance, as validated by extensive experiments on LLaMA series (LLaMA2, LLaMA3, LLaMA3.1, and LLaMA3.2) across Code, Math, and Instruction Following tasks. We also provide a theoretical guarantee for the capacity of LoRA-Null to retain pre-trained knowledge. Code is in this https URL.</li>
</ul>

<h3>Title: Multidimensional Consistency Improves Reasoning in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Huiyuan Lai, Xiao Zhang, Malvina Nissim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02670">https://arxiv.org/abs/2503.02670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02670">https://arxiv.org/pdf/2503.02670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02670]] Multidimensional Consistency Improves Reasoning in Language Models(https://arxiv.org/abs/2503.02670)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large language models (LLMs) have proved able to address some complex reasoning tasks, we also know that they are highly sensitive to input variation, which can lead to different solution paths and final answers. Answer consistency across input variations can thus be taken as a sign of stronger confidence. Leveraging this insight, we introduce a framework, {\em Multidimensional Reasoning Consistency} where, focusing on math problems, models are systematically pushed to diversify solution paths towards a final answer, thereby testing them for answer consistency across multiple input variations. We induce variations in (i) order of shots in prompt, (ii) problem phrasing, and (iii) languages used. Extensive experiments on a large range of open-source state-of-the-art LLMs of various sizes show that reasoning consistency differs by variation dimension, and that by aggregating consistency across dimensions, our framework consistently enhances mathematical reasoning performance on both monolingual dataset GSM8K and multilingual dataset MGSM, especially for smaller models.</li>
</ul>

<h3>Title: State of play and future directions in industrial computer vision AI standards</h3>
<ul>
<li><strong>Authors: </strong>Artemis Stefanidou, Panagiotis Radoglou-Grammatikis, Vasileios Argyriou, Panagiotis Sarigiannidis, Iraklis Varlamis, Georgios Th. Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02675">https://arxiv.org/abs/2503.02675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02675">https://arxiv.org/pdf/2503.02675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02675]] State of play and future directions in industrial computer vision AI standards(https://arxiv.org/abs/2503.02675)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, interpretability</a></li>
<li><strong>Abstract: </strong>The recent tremendous advancements in the areas of Artificial Intelligence (AI) and Deep Learning (DL) have also resulted into corresponding remarkable progress in the field of Computer Vision (CV), showcasing robust technological solutions in a wide range of application sectors of high industrial interest (e.g., healthcare, autonomous driving, automation, etc.). Despite the outstanding performance of CV systems in specific domains, their development and exploitation at industrial-scale necessitates, among other, the addressing of requirements related to the reliability, transparency, trustworthiness, security, safety, and robustness of the developed AI models. The latter raises the imperative need for the development of efficient, comprehensive and widely-adopted industrial standards. In this context, this study investigates the current state of play regarding the development of industrial computer vision AI standards, emphasizing on critical aspects, like model interpretability, data quality, and regulatory compliance. In particular, a systematic analysis of launched and currently developing CV standards, proposed by the main international standardization bodies (e.g. ISO/IEC, IEEE, DIN, etc.) is performed. The latter is complemented by a comprehensive discussion on the current challenges and future directions observed in this regularization endeavor.</li>
</ul>

<h3>Title: MPO: Boosting LLM Agents with Meta Plan Optimization</h3>
<ul>
<li><strong>Authors: </strong>Weimin Xiong, Yifan Song, Qingxiu Dong, Bingchan Zhao, Feifan Song, Xun Wang, Sujian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02682">https://arxiv.org/abs/2503.02682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02682">https://arxiv.org/pdf/2503.02682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02682]] MPO: Boosting LLM Agents with Meta Plan Optimization(https://arxiv.org/abs/2503.02682)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios.</li>
</ul>

<h3>Title: Federated Learning for Privacy-Preserving Feedforward Control in Multi-Agent Systems</h3>
<ul>
<li><strong>Authors: </strong>Jakob Weber, Markus Gurtner, Benedikt Alt, Adrian Trachte, Andreas Kugi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02693">https://arxiv.org/abs/2503.02693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02693">https://arxiv.org/pdf/2503.02693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02693]] Federated Learning for Privacy-Preserving Feedforward Control in Multi-Agent Systems(https://arxiv.org/abs/2503.02693)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability. However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs. Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges. This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data. By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability. We demonstrate the effectiveness of our method in an autonomous driving use case. Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control. Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control. We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control. Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications.</li>
</ul>

<h3>Title: RedChronos: A Large Language Model-Based Log Analysis System for Insider Threat Detection in Enterprises</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Li, Zhengjia Zhu, Jiyan He, Xiu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02702">https://arxiv.org/abs/2503.02702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02702">https://arxiv.org/pdf/2503.02702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02702]] RedChronos: A Large Language Model-Based Log Analysis System for Insider Threat Detection in Enterprises(https://arxiv.org/abs/2503.02702)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Internal threat detection aims to address security threats within organizations or enterprises by identifying potential or already occurring malicious threats within vast amounts of logs. Although organizations or enterprises have dedicated personnel responsible for reviewing these logs, it is impossible to manually examine all logs entirely. In response to the vast number of logs, we propose a system called RedChronos, which is a Large Language Model-Based Log Analysis System. This system incorporates innovative improvements over previous research by employing Query-Aware Weighted Voting and a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations. On the public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches existing approaches in terms of accuracy, precision, and detection rate. Moreover, RedChronos reduces the need for manual intervention in security log reviews by 90\% in the Xiaohongshu SOC. Therefore, our RedChronos system demonstrates exceptional performance in handling Internal Threat Detection (IDT) tasks, providing innovative solutions for these challenges. We believe that future research can continue to enhance the system's performance in IDT tasks while also reducing the response time to internal risk events.</li>
</ul>

<h3>Title: Optimisation of cyber insurance coverage with selection of cost effective security controls</h3>
<ul>
<li><strong>Authors: </strong>Ganbayar Uuganbayar, Artsiom Yautsiukhin, Fabio Martinelli, Fabio Massacci</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02706">https://arxiv.org/abs/2503.02706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02706">https://arxiv.org/pdf/2503.02706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02706]] Optimisation of cyber insurance coverage with selection of cost effective security controls(https://arxiv.org/abs/2503.02706)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Nowadays, cyber threats are considered among the most dangerous risks by top management of enterprises. One way to deal with these risks is to insure them, but cyber insurance is still quite expensive. The insurance fee can be reduced if organisations improve their cyber security protection, i.e., reducing the insured risk. In other words, organisations need an investment strategy to decide the optimal amount of investments into cyber insurance and self-protection. In this work, we propose an approach to help a risk-averse organisation to distribute its cyber security investments in a cost-efficient way. What makes our approach unique is that next to defining the amount of investments in cyber insurance and self-protection, our proposal also explicitly defines how these investments should be spent by selecting the most cost-efficient security controls. Moreover, we provide an exact algorithm for the control selection problem considering several threats at the same time and compare this algorithm with other approximate algorithmic solutions.</li>
</ul>

<h3>Title: Catheter Detection and Segmentation in X-ray Images via Multi-task Learning</h3>
<ul>
<li><strong>Authors: </strong>Lin Xi, Yingliang Ma, Ethan Koland, Sandra Howell, Aldo Rinaldi, Kawal S. Rhode</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02717">https://arxiv.org/abs/2503.02717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02717">https://arxiv.org/pdf/2503.02717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02717]] Catheter Detection and Segmentation in X-ray Images via Multi-task Learning(https://arxiv.org/abs/2503.02717)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated detection and segmentation of surgical devices, such as catheters or wires, in X-ray fluoroscopic images have the potential to enhance image guidance in minimally invasive heart surgeries. In this paper, we present a convolutional neural network model that integrates a resnet architecture with multiple prediction heads to achieve real-time, accurate localization of electrodes on catheters and catheter segmentation in an end-to-end deep learning framework. We also propose a multi-task learning strategy in which our model is trained to perform both accurate electrode detection and catheter segmentation simultaneously. A key challenge with this approach is achieving optimal performance for both tasks. To address this, we introduce a novel multi-level dynamic resource prioritization method. This method dynamically adjusts sample and task weights during training to effectively prioritize more challenging tasks, where task difficulty is inversely proportional to performance and evolves throughout the training process. Experiments on both public and private datasets have demonstrated that the accuracy of our method surpasses the existing state-of-the-art methods in both single segmentation task and in the detection and segmentation multi-task. Our approach achieves a good trade-off between accuracy and efficiency, making it well-suited for real-time surgical guidance applications.</li>
</ul>

<h3>Title: Large Language Models for Multilingual Previously Fact-Checked Claim Detection</h3>
<ul>
<li><strong>Authors: </strong>Ivan Vykopal, Matúš Pikuliak, Simon Ostermann, Tatiana Anikina, Michal Gregor, Marián Šimko</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02737">https://arxiv.org/abs/2503.02737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02737">https://arxiv.org/pdf/2503.02737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02737]] Large Language Models for Multilingual Previously Fact-Checked Claim Detection(https://arxiv.org/abs/2503.02737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In our era of widespread false information, human fact-checkers often face the challenge of duplicating efforts when verifying claims that may have already been addressed in other countries or languages. As false information transcends linguistic boundaries, the ability to automatically detect previously fact-checked claims across languages has become an increasingly important task. This paper presents the first comprehensive evaluation of large language models (LLMs) for multilingual previously fact-checked claim detection. We assess seven LLMs across 20 languages in both monolingual and cross-lingual settings. Our results show that while LLMs perform well for high-resource languages, they struggle with low-resource languages. Moreover, translating original texts into English proved to be beneficial for low-resource languages. These findings highlight the potential of LLMs for multilingual previously fact-checked claim detection and provide a foundation for further research on this promising application of LLMs.</li>
</ul>

<h3>Title: BatchGEMBA: Token-Efficient Machine Translation Evaluation with Batched Prompting and Prompt Compression</h3>
<ul>
<li><strong>Authors: </strong>Daniil Larionov, Steffen Eger</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02756">https://arxiv.org/abs/2503.02756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02756">https://arxiv.org/pdf/2503.02756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02756]] BatchGEMBA: Token-Efficient Machine Translation Evaluation with Batched Prompting and Prompt Compression(https://arxiv.org/abs/2503.02756)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Model (LLM)-based Natural Language Generation evaluation have largely focused on single-example prompting, resulting in significant token overhead and computational inefficiencies. In this work, we introduce BatchGEMBA-MQM, a framework that integrates batched prompting with the GEMBA-MQM metric for machine translation evaluation. Our approach aggregates multiple translation examples into a single prompt, reducing token usage by 2-4 times (depending on the batch size) relative to single-example prompting. Furthermore, we propose a batching-aware prompt compression model that achieves an additional token reduction of 13-15% on average while also showing ability to help mitigate batching-induced quality degradation. Evaluations across several LLMs (GPT-4o, GPT-4o-mini, Mistral Small, Phi4, and CommandR7B) and varying batch sizes reveal that while batching generally negatively affects quality (but sometimes not substantially), prompt compression does not degrade further, and in some cases, recovers quality loss. For instance, GPT-4o retains over 90% of its baseline performance at a batch size of 4 when compression is applied, compared to a 44.6% drop without compression. We plan to release our code and trained models at this https URL to support future research in this domain.</li>
</ul>

<h3>Title: From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine Symbolic Language for Modern Clinical Relevance</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Tang, Nankai Wu, Fan Gao, Chengxiao Dai, Mengyao Zhao, Xinjie Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02760">https://arxiv.org/abs/2503.02760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02760">https://arxiv.org/pdf/2503.02760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02760]] From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine Symbolic Language for Modern Clinical Relevance(https://arxiv.org/abs/2503.02760)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Metaphorical expressions are abundant in Traditional Chinese Medicine (TCM), conveying complex disease mechanisms and holistic health concepts through culturally rich and often abstract terminology. Bridging these metaphors to anatomically driven Western medical (WM) concepts poses significant challenges for both automated language processing and real-world clinical practice. To address this gap, we propose a novel multi-agent and chain-of-thought (CoT) framework designed to interpret TCM metaphors accurately and map them to WM pathophysiology. Specifically, our approach combines domain-specialized agents (TCM Expert, WM Expert) with a Coordinator Agent, leveraging stepwise chain-of-thought prompts to ensure transparent reasoning and conflict resolution. We detail a methodology for building a metaphor-rich TCM dataset, discuss strategies for effectively integrating multi-agent collaboration and CoT reasoning, and articulate the theoretical underpinnings that guide metaphor interpretation across distinct medical paradigms. We present a comprehensive system design and highlight both the potential benefits and limitations of our approach, while leaving placeholders for future experimental validation. Our work aims to support clinical decision-making, cross-system educational initiatives, and integrated healthcare research, ultimately offering a robust scaffold for reconciling TCM's symbolic language with the mechanistic focus of Western medicine.</li>
</ul>

<h3>Title: Implicit Bias in LLMs: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Xinru Lin, Luyang Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02776">https://arxiv.org/abs/2503.02776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02776">https://arxiv.org/pdf/2503.02776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02776]] Implicit Bias in LLMs: A Survey(https://arxiv.org/abs/2503.02776)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Due to the implement of guardrails by developers, Large language models (LLMs) have demonstrated exceptional performance in explicit bias tests. However, bias in LLMs may occur not only explicitly, but also implicitly, much like humans who consciously strive for impartiality yet still harbor implicit bias. The unconscious and automatic nature of implicit bias makes it particularly challenging to study. This paper provides a comprehensive review of the existing literature on implicit bias in LLMs. We begin by introducing key concepts, theories and methods related to implicit bias in psychology, extending them from humans to LLMs. Drawing on the Implicit Association Test (IAT) and other psychological frameworks, we categorize detection methods into three primary approaches: word association, task-oriented text generation and decision-making. We divide our taxonomy of evaluation metrics for implicit bias into two categories: single-value-based metrics and comparison-value-based metrics. We classify datasets into two types: sentences with masked tokens and complete sentences, incorporating datasets from various domains to reflect the broad application of LLMs. Although research on mitigating implicit bias in LLMs is still limited, we summarize existing efforts and offer insights on future challenges. We aim for this work to serve as a clear guide for researchers and inspire innovative ideas to advance exploration in this task.</li>
</ul>

<h3>Title: Quantitative Resilience Modeling for Autonomous Cyber Defense</h3>
<ul>
<li><strong>Authors: </strong>Xavier Cadet, Simona Boboila, Edward Koh, Peter Chin, Alina Oprea</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02780">https://arxiv.org/abs/2503.02780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02780">https://arxiv.org/pdf/2503.02780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02780]] Quantitative Resilience Modeling for Autonomous Cyber Defense(https://arxiv.org/abs/2503.02780)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, interpretability</a></li>
<li><strong>Abstract: </strong>Cyber resilience is the ability of a system to recover from an attack with minimal impact on system operations. However, characterizing a network's resilience under a cyber attack is challenging, as there are no formal definitions of resilience applicable to diverse network topologies and attack patterns. In this work, we propose a quantifiable formulation of resilience that considers multiple defender operational goals, the criticality of various network resources for daily operations, and provides interpretability to security operators about their system's resilience under attack. We evaluate our approach within the CybORG environment, a reinforcement learning (RL) framework for autonomous cyber defense, analyzing trade-offs between resilience, costs, and prioritization of operational goals. Furthermore, we introduce methods to aggregate resilience metrics across time-variable attack patterns and multiple network topologies, comprehensively characterizing system resilience. Using insights gained from our resilience metrics, we design RL autonomous defensive agents and compare them against several heuristic baselines, showing that proactive network hardening techniques and prompt recovery of compromised machines are critical for effective cyber defenses.</li>
</ul>

<h3>Title: A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness</h3>
<ul>
<li><strong>Authors: </strong>Nathan Drenkow, Mathias Unberath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02797">https://arxiv.org/abs/2503.02797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02797">https://arxiv.org/pdf/2503.02797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02797]] A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness(https://arxiv.org/abs/2503.02797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image quality plays an important role in the performance of deep neural networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to changes in imaging conditions. Large-scale datasets often contain images under a wide range of conditions prompting a need to quantify and understand their underlying quality distribution in order to better characterize DNN performance and robustness. Aligning the sensitivities of image quality metrics and DNNs ensures that estimates of quality can act as proxies for image/dataset difficulty independent of the task models trained/evaluated on the data. Conventional image quality assessment (IQA) seeks to measure and align quality relative to human perceptual judgments, but here we seek a quality measure that is not only sensitive to imaging conditions but also well-aligned with DNN sensitivities. We first ask whether conventional IQA metrics are also informative of DNN performance. In order to answer this question, we reframe IQA from a causal perspective and examine conditions under which quality metrics are predictive of DNN performance. We show theoretically and empirically that current IQA metrics are weak predictors of DNN performance in the context of classification. We then use our causal framework to provide an alternative formulation and a new image quality metric that is more strongly correlated with DNN performance and can act as a prior on performance without training new task models. Our approach provides a means to directly estimate the quality distribution of large-scale image datasets towards characterizing the relationship between dataset composition and DNN performance.</li>
</ul>

<h3>Title: MX-Font++: Mixture of Heterogeneous Aggregation Experts for Few-shot Font Generation</h3>
<ul>
<li><strong>Authors: </strong>Weihang Wang, Duolin Sun, Jielei Zhang, Longwen Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02799">https://arxiv.org/abs/2503.02799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02799">https://arxiv.org/pdf/2503.02799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02799]] MX-Font++: Mixture of Heterogeneous Aggregation Experts for Few-shot Font Generation(https://arxiv.org/abs/2503.02799)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Few-shot Font Generation (FFG) aims to create new font libraries using limited reference glyphs, with crucial applications in digital accessibility and equity for low-resource languages, especially in multilingual artificial intelligence systems. Although existing methods have shown promising performance, transitioning to unseen characters in low-resource languages remains a significant challenge, especially when font glyphs vary considerably across training sets. MX-Font considers the content of a character from the perspective of a local component, employing a Mixture of Experts (MoE) approach to adaptively extract the component for better transition. However, the lack of a robust feature extractor prevents them from adequately decoupling content and style, leading to sub-optimal generation results. To alleviate these problems, we propose Heterogeneous Aggregation Experts (HAE), a powerful feature extraction expert that helps decouple content and style downstream from being able to aggregate information in channel and spatial dimensions. Additionally, we propose a novel content-style homogeneity loss to enhance the untangling. Extensive experiments on several datasets demonstrate that our MX-Font++ yields superior visual results in FFG and effectively outperforms state-of-the-art methods. Code and data are available at this https URL.</li>
</ul>

<h3>Title: RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration</h3>
<ul>
<li><strong>Authors: </strong>Alicia Russell-Gilbert, Sudip Mittal, Shahram Rahimi, Maria Seale, Joseph Jabour, Thomas Arnold, Joshua Church</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02800">https://arxiv.org/abs/2503.02800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02800">https://arxiv.org/pdf/2503.02800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02800]] RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration(https://arxiv.org/abs/2503.02800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions. Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge. In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach addresses the aforementioned PdM challenges. By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring fine-tuning on specific datasets. The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy. We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show significant improvements over our previous model with an accuracy increase from 70.7 to 89.1 on the real-world dataset. By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators. Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.</li>
</ul>

<h3>Title: Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts</h3>
<ul>
<li><strong>Authors: </strong>Marta Skreta, Tara Akhound-Sadegh, Viktor Ohanesian, Roberto Bondesan, Alán Aspuru-Guzik, Arnaud Doucet, Rob Brekelmans, Alexander Tong, Kirill Neklyudov</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02819">https://arxiv.org/abs/2503.02819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02819">https://arxiv.org/pdf/2503.02819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02819]] Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts(https://arxiv.org/abs/2503.02819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>While score-based generative models are the model of choice across diverse domains, there are limited tools available for controlling inference-time behavior in a principled manner, e.g. for composing multiple pretrained models. Existing classifier-free guidance methods use a simple heuristic to mix conditional and unconditional scores to approximately sample from conditional distributions. However, such methods do not approximate the intermediate distributions, necessitating additional 'corrector' steps. In this work, we provide an efficient and principled method for sampling from a sequence of annealed, geometric-averaged, or product distributions derived from pretrained score-based models. We derive a weighted simulation scheme which we call Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by carefully accounting for terms in the appropriate partial differential equations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo (SMC) resampling algorithms that leverage inference-time scaling to improve sampling quality. We empirically demonstrate the utility of our methods by proposing amortized sampling via inference-time temperature annealing, improving multi-objective molecule generation using pretrained models, and improving classifier-free guidance for text-to-image generation. Our code is available at this https URL.</li>
</ul>

<h3>Title: Developing a PET/CT Foundation Model for Cross-Modal Anatomical and Functional Imaging</h3>
<ul>
<li><strong>Authors: </strong>Yujin Oh, Robert Seifert, Yihan Cao, Christoph Clement, Justin Ferdinandus, Constantin Lapa, Alessandro Liebich, Michelle Amon, Johanna Enke, Sifan Song, Runqi Meng, Fang Zeng, Ning Guo, Xiang Li, Pedram Heidari, Axel Rominger, Kuangyu Shi, Quanzheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02824">https://arxiv.org/abs/2503.02824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02824">https://arxiv.org/pdf/2503.02824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02824]] Developing a PET/CT Foundation Model for Cross-Modal Anatomical and Functional Imaging(https://arxiv.org/abs/2503.02824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is widely used in cancer diagnosis, staging, and treatment monitoring, as it combines anatomical details from CT with functional metabolic activity and molecular marker expression information from PET. However, existing artificial intelligence-driven PET/CT analyses rely predominantly on task-specific models trained from scratch or on limited datasets, limiting their generalizability and robustness. To address this, we propose a foundation model approach specifically designed for multimodal PET/CT imaging. We introduce the Cross-Fraternal Twin Masked Autoencoder (FratMAE), a novel framework that effectively integrates whole-body anatomical and functional or molecular information. FratMAE employs separate Vision Transformer (ViT) encoders for PET and CT scans, along with cross-attention decoders that enable synergistic interactions between modalities during masked autoencoder training. Additionally, it incorporates textual metadata to enhance PET representation learning. By pre-training on PET/CT datasets, FratMAE captures intricate cross-modal relationships and global uptake patterns, achieving superior performance on downstream tasks and demonstrating its potential as a generalizable foundation model.</li>
</ul>

<h3>Title: AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation</h3>
<ul>
<li><strong>Authors: </strong>Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02832">https://arxiv.org/abs/2503.02832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02832">https://arxiv.org/pdf/2503.02832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02832]] AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation(https://arxiv.org/abs/2503.02832)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.</li>
</ul>

<h3>Title: In-Depth Analysis of Automated Acne Disease Recognition and Classification</h3>
<ul>
<li><strong>Authors: </strong>Afsana Ahsan Jeny, Masum Shah Junayed, Md Robel Mia, Md Baharul Islam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02835">https://arxiv.org/abs/2503.02835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02835">https://arxiv.org/pdf/2503.02835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02835]] In-Depth Analysis of Automated Acne Disease Recognition and Classification(https://arxiv.org/abs/2503.02835)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Facial acne is a common disease, especially among adolescents, negatively affecting both physically and psychologically. Classifying acne is vital to providing the appropriate treatment. Traditional visual inspection or expert scanning is time-consuming and difficult to differentiate acne types. This paper introduces an automated expert system for acne recognition and classification. The proposed method employs a machine learning-based technique to classify and evaluate six types of acne diseases to facilitate the diagnosis of dermatologists. The pre-processing phase includes contrast improvement, smoothing filter, and RGB to L*a*b color conversion to eliminate noise and improve the classification accuracy. Then, a clustering-based segmentation method, k-means clustering, is applied for segmenting the disease-affected regions that pass through the feature extraction step. Characteristics of these disease-affected regions are extracted based on a combination of gray-level co-occurrence matrix (GLCM) and Statistical features. Finally, five different machine learning classifiers are employed to classify acne diseases. Experimental results show that the Random Forest (RF) achieves the highest accuracy of 98.50%, which is promising compared to the state-of-the-art methods.</li>
</ul>

<h3>Title: SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ting-Ji Huang, Xu-Yang Chen, Han-Jia Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02836">https://arxiv.org/abs/2503.02836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02836">https://arxiv.org/pdf/2503.02836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02836]] SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting(https://arxiv.org/abs/2503.02836)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data. Current zero-shot approaches primarily rely on pre-trained generalized models, with their performance often depending on the variety and relevance of the pre-training data, which can raise privacy concerns. Instead of collecting diverse pre-training data, we introduce SeqFusion in this work, a novel framework that collects and fuses diverse pre-trained models (PTMs) sequentially for zero-shot forecasting. Based on the specific temporal characteristics of the target time series, SeqFusion selects the most suitable PTMs from a batch of pre-collected PTMs, performs sequential predictions, and fuses all the predictions while using minimal data to protect privacy. Each of these PTMs specializes in different temporal patterns and forecasting tasks, allowing SeqFusion to select by measuring distances in a shared representation space of the target time series with each PTM. Experiments demonstrate that SeqFusion achieves competitive accuracy in zero-shot forecasting compared to state-of-the-art methods.</li>
</ul>

<h3>Title: Boltzmann Attention Sampling for Image Analysis with Small Objects</h3>
<ul>
<li><strong>Authors: </strong>Theodore Zhao, Sid Kiblawi, Naoto Usuyama, Ho Hin Lee, Sam Preston, Hoifung Poon, Mu Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02841">https://arxiv.org/abs/2503.02841</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02841">https://arxiv.org/pdf/2503.02841</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02841]] Boltzmann Attention Sampling for Image Analysis with Small Objects(https://arxiv.org/abs/2503.02841)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Detecting and segmenting small objects, such as lung nodules and tumor lesions, remains a critical challenge in image analysis. These objects often occupy less than 0.1% of an image, making traditional transformer architectures inefficient and prone to performance degradation due to redundant attention computations on irrelevant regions. Existing sparse attention mechanisms rely on rigid hierarchical structures, which are poorly suited for detecting small, variable, and uncertain object locations. In this paper, we propose BoltzFormer, a novel transformer-based architecture designed to address these challenges through dynamic sparse attention. BoltzFormer identifies and focuses attention on relevant areas by modeling uncertainty using a Boltzmann distribution with an annealing schedule. Initially, a higher temperature allows broader area sampling in early layers, when object location uncertainty is greatest. As the temperature decreases in later layers, attention becomes more focused, enhancing efficiency and accuracy. BoltzFormer seamlessly integrates into existing transformer architectures via a modular Boltzmann attention sampling mechanism. Comprehensive evaluations on benchmark datasets demonstrate that BoltzFormer significantly improves segmentation performance for small objects while reducing attention computation by an order of magnitude compared to previous state-of-the-art methods.</li>
</ul>

<h3>Title: Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yuzhe Gu, Wenwei Zhang, Chengqi Lyu, Dahua Lin, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02846">https://arxiv.org/abs/2503.02846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02846">https://arxiv.org/pdf/2503.02846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02846]] Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs(https://arxiv.org/abs/2503.02846)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preference learning inevitably introduced noises during training. Therefore, this paper proposes a fine-grained factuality alignment method based on Direct Preference Optimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as mask signals, Mask-DPO only learns from factually correct sentences in the preferred samples and prevents the penalty on factual contents in the not preferred samples, which resolves the ambiguity in the preference learning. Extensive experimental results demonstrate that Mask-DPO can significantly improve the factuality of LLMs responses to questions from both in-domain and out-of-domain datasets, although these questions and their corresponding topics are unseen during training. Only trained on the ANAH train set, the score of Llama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%, even surpassing the score of Llama3.1-70B-Instruct (53.44%), while its FactScore on the out-of-domain Biography dataset is also improved from 30.29% to 39.39%. We further study the generalization property of Mask-DPO using different training sample scaling strategies and find that scaling the number of topics in the dataset is more effective than the number of questions. We provide a hypothesis of what factual alignment is doing with LLMs, on the implication of this phenomenon, and conduct proof-of-concept experiments to verify it. We hope the method and the findings pave the way for future research on scaling factuality alignment.</li>
</ul>

<h3>Title: Multimodal Deep Learning for Subtype Classification in Breast Cancer Using Histopathological Images and Gene Expression Data</h3>
<ul>
<li><strong>Authors: </strong>Amin Honarmandi Shandiz</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02849">https://arxiv.org/abs/2503.02849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02849">https://arxiv.org/pdf/2503.02849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02849]] Multimodal Deep Learning for Subtype Classification in Breast Cancer Using Histopathological Images and Gene Expression Data(https://arxiv.org/abs/2503.02849)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Molecular subtyping of breast cancer is crucial for personalized treatment and prognosis. Traditional classification approaches rely on either histopathological images or gene expression profiling, limiting their predictive power. In this study, we propose a deep multimodal learning framework that integrates histopathological images and gene expression data to classify breast cancer into this http URL and this http URL / Her2 subtypes. Our approach employs a ResNet-50 model for image feature extraction and fully connected layers for gene expression processing, with a cross-attention fusion mechanism to enhance modality interaction. We conduct extensive experiments using five-fold cross-validation, demonstrating that our multimodal integration outperforms unimodal approaches in terms of classification accuracy, precision-recall AUC, and F1-score. Our findings highlight the potential of deep learning for robust and interpretable breast cancer subtype classification, paving the way for improved clinical decision-making.</li>
</ul>

<h3>Title: Shakespearean Sparks: The Dance of Hallucination and Creativity in LLMs' Decoding Layers</h3>
<ul>
<li><strong>Authors: </strong>Zicong He, Boxuan Zhang, Lu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02851">https://arxiv.org/abs/2503.02851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02851">https://arxiv.org/pdf/2503.02851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02851]] Shakespearean Sparks: The Dance of Hallucination and Creativity in LLMs' Decoding Layers(https://arxiv.org/abs/2503.02851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are known to hallucinate, a phenomenon often linked to creativity. While previous research has primarily explored this connection through theoretical or qualitative lenses, our work takes a quantitative approach to systematically examine the relationship between hallucination and creativity in LLMs. Given the complex nature of creativity, we propose a narrow definition tailored to LLMs and introduce an evaluation framework, HCL, which quantifies Hallucination and Creativity across different Layers of LLMs during decoding. Our empirical analysis reveals a tradeoff between hallucination and creativity that is consistent across layer depth, model type, and model size. Notably, across different model architectures, we identify a specific layer at each model size that optimally balances this tradeoff. Additionally, the optimal layer tends to appear in the early layers of larger models, and the confidence of the model is also significantly higher at this layer. These findings provide a quantitative perspective that offers new insights into the interplay between LLM creativity and hallucination. The code and data for our experiments are available at this https URL.</li>
</ul>

<h3>Title: (How) Do Language Models Track State?</h3>
<ul>
<li><strong>Authors: </strong>Belinda Z. Li, Zifan Carl Guo, Jacob Andreas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02854">https://arxiv.org/abs/2503.02854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02854">https://arxiv.org/pdf/2503.02854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02854]] (How) Do Language Models Track State?(https://arxiv.org/abs/2503.02854)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformer language models (LMs) exhibit behaviors -- from storytelling to code generation -- that appear to require tracking the unobserved state of an evolving world. How do they do so? We study state tracking in LMs trained or fine-tuned to compose permutations (i.e., to compute the order of a set of objects after a sequence of swaps). Despite the simple algebraic structure of this problem, many other tasks (e.g., simulation of finite automata and evaluation of boolean expressions) can be reduced to permutation composition, making it a natural model for state tracking in general. We show that LMs consistently learn one of two state tracking mechanisms for this task. The first closely resembles the "associative scan" construction used in recent theoretical work by Liu et al. (2023) and Merrill et al. (2024). The second uses an easy-to-compute feature (permutation parity) to partially prune the space of outputs, then refines this with an associative scan. The two mechanisms exhibit markedly different robustness properties, and we show how to steer LMs toward one or the other with intermediate training tasks that encourage or suppress the heuristics. Our results demonstrate that transformer LMs, whether pretrained or fine-tuned, can learn to implement efficient and interpretable state tracking mechanisms, and the emergence of these mechanisms can be predicted and controlled.</li>
</ul>

<h3>Title: Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024</h3>
<ul>
<li><strong>Authors: </strong>Nuria Alina Chandra, Ryan Murtfeldt, Lin Qiu, Arnab Karmakar, Hannah Lee, Emmanuel Tanumihardja, Kevin Farhat, Ben Caffee, Sejin Paik, Changyeon Lee, Jongwook Choi, Aerin Kim, Oren Etzioni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02857">https://arxiv.org/abs/2503.02857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02857">https://arxiv.org/pdf/2503.02857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02857]] Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024(https://arxiv.org/abs/2503.02857)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>In the age of increasingly realistic generative AI, robust deepfake detection is essential for mitigating fraud and disinformation. While many deepfake detectors report high accuracy on academic datasets, we show that these academic benchmarks are out of date and not representative of recent deepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark consisting of in-the-wild deepfakes collected from social media and deepfake detection platform users in 2024. Deepfake-Eval-2024 consists of 44 hours of videos, 56.5 hours of audio, and 1,975 images, encompassing the latest manipulation technologies. The benchmark contains diverse media content from 88 different websites in 52 different languages. We find that the performance of open-source state-of-the-art deepfake detection models drops precipitously when evaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for audio, and 45% for image models compared to previous benchmarks. We also evaluate commercial deepfake detection models and models finetuned on Deepfake-Eval-2024, and find that they have superior performance to off-the-shelf open-source models, but they do not yet reach the accuracy of human deepfake forensic analysts. The dataset is available at this https URL.</li>
</ul>

<h3>Title: Privacy and Accuracy-Aware AI/ML Model Deduplication</h3>
<ul>
<li><strong>Authors: </strong>Hong Guan, Lei Yu, Lixi Zhou, Li Xiong, Kanchan Chowdhury, Lulu Xie, Xusheng Xiao, Jia Zou</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02862">https://arxiv.org/abs/2503.02862</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02862">https://arxiv.org/pdf/2503.02862</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02862]] Privacy and Accuracy-Aware AI/ML Model Deduplication(https://arxiv.org/abs/2503.02862)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer, large language model</a></li>
<li><strong>Abstract: </strong>With the growing adoption of privacy-preserving machine learning algorithms, such as Differentially Private Stochastic Gradient Descent (DP-SGD), training or fine-tuning models on private datasets has become increasingly prevalent. This shift has led to the need for models offering varying privacy guarantees and utility levels to satisfy diverse user requirements. However, managing numerous versions of large models introduces significant operational challenges, including increased inference latency, higher resource consumption, and elevated costs. Model deduplication is a technique widely used by many model serving and database systems to support high-performance and low-cost inference queries and model diagnosis queries. However, none of the existing model deduplication works has considered privacy, leading to unbounded aggregation of privacy costs for certain deduplicated models and inefficiencies when applied to deduplicate DP-trained models. We formalize the problems of deduplicating DP-trained models for the first time and propose a novel privacy- and accuracy-aware deduplication mechanism to address the problems. We developed a greedy strategy to select and assign base models to target models to minimize storage and privacy costs. When deduplicating a target model, we dynamically schedule accuracy validations and apply the Sparse Vector Technique to reduce the privacy costs associated with private validation data. Compared to baselines that do not provide privacy guarantees, our approach improved the compression ratio by up to $35\times$ for individual models (including large language models and vision transformers). We also observed up to $43\times$ inference speedup due to the reduction of I/O operations.</li>
</ul>

<h3>Title: Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework</h3>
<ul>
<li><strong>Authors: </strong>Ziang Zhou, Tianyuan Jin, Jieming Shi, Qing Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02863">https://arxiv.org/abs/2503.02863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02863">https://arxiv.org/pdf/2503.02863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02863]] Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework(https://arxiv.org/abs/2503.02863)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often exhibit misaligned confidence scores, usually overestimating the reliability of their predictions. While verbalized confidence in Large Language Models (LLMs) has gained attention, prior work remains divided on whether confidence scores can be systematically steered through prompting. Recent studies even argue that such prompt-induced confidence shifts are negligible, suggesting LLMs' confidence calibration is rigid to linguistic interventions. Contrary to these claims, we first rigorously confirm the existence of directional confidence shifts by probing three models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks, demonstrating that explicit instructions can inflate or deflate confidence scores in a regulated manner. Based on this observation, we propose a novel framework containing three components: confidence steering, steered confidence aggregation and steered answers selection, named SteeringConf. Our method, SteeringConf, leverages a confidence manipulation mechanism to steer the confidence scores of LLMs in several desired directions, followed by a summarization module that aggregates the steered confidence scores to produce a final prediction. We evaluate our method on 7 benchmarks and it consistently outperforms the baselines in terms of calibration metrics in task of confidence calibration and failure detection.</li>
</ul>

<h3>Title: FairSense-AI: Responsible AI Meets Sustainability</h3>
<ul>
<li><strong>Authors: </strong>Shaina Raza, Mukund Sayeeganesh Chettiar, Matin Yousefabadi, Tahniat Khan, Marcelo Lotif</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02865">https://arxiv.org/abs/2503.02865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02865">https://arxiv.org/pdf/2503.02865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02865]] FairSense-AI: Responsible AI Meets Sustainability(https://arxiv.org/abs/2503.02865)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce FairSense-AI: a multimodal framework designed to detect and mitigate bias in both text and images. By leveraging Large Language Models (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle forms of prejudice or stereotyping that can appear in content, providing users with bias scores, explanatory highlights, and automated recommendations for fairness enhancements. In addition, FairSense-AI integrates an AI risk assessment component that aligns with frameworks like the MIT AI Risk Repository and NIST AI Risk Management Framework, enabling structured identification of ethical and safety concerns. The platform is optimized for energy efficiency via techniques such as model pruning and mixed-precision computation, thereby reducing its environmental footprint. Through a series of case studies and applications, we demonstrate how FairSense-AI promotes responsible AI use by addressing both the social dimension of fairness and the pressing need for sustainability in large-scale AI deployments. this https URL, this https URL</li>
</ul>

<h3>Title: The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Ke Ji, Jiahao Xu, Tian Liang, Qiuzhi Liu, Zhiwei He, Xingyu Chen, Xiaoyuan Liu, Zhijie Wang, Junying Chen, Benyou Wang, Zhaopeng Tu, Haitao Mi, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02875">https://arxiv.org/abs/2503.02875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02875">https://arxiv.org/pdf/2503.02875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02875]] The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models(https://arxiv.org/abs/2503.02875)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Improving the reasoning capabilities of large language models (LLMs) typically requires supervised fine-tuning with labeled data or computationally expensive sampling. We introduce Unsupervised Prefix Fine-Tuning (UPFT), which leverages the observation of Prefix Self-Consistency -- the shared initial reasoning steps across diverse solution trajectories -- to enhance LLM reasoning efficiency. By training exclusively on the initial prefix substrings (as few as 8 tokens), UPFT removes the need for labeled data or exhaustive sampling. Experiments on reasoning benchmarks show that UPFT matches the performance of supervised methods such as Rejection Sampling Fine-Tuning, while reducing training time by 75% and sampling cost by 99%. Further analysis reveals that errors tend to appear in later stages of the reasoning process and that prefix-based training preserves the model's structural knowledge. This work demonstrates how minimal unsupervised fine-tuning can unlock substantial reasoning gains in LLMs, offering a scalable and resource-efficient alternative to conventional approaches.</li>
</ul>

<h3>Title: Wikipedia in the Era of LLMs: Evolution and Risks</h3>
<ul>
<li><strong>Authors: </strong>Siming Huang, Yuliang Xu, Mingmeng Geng, Yao Wan, Dongping Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02879">https://arxiv.org/abs/2503.02879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02879">https://arxiv.org/pdf/2503.02879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02879]] Wikipedia in the Era of LLMs: Evolution and Risks(https://arxiv.org/abs/2503.02879)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent changes and assess the impact of LLMs. Subsequently, we evaluate how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG). Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 1%-2% in certain categories. If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well. Moreover, the effectiveness of RAG might decrease if the knowledge base becomes polluted by LLM-generated content. While LLMs have not yet fully changed Wikipedia's language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks.</li>
</ul>

<h3>Title: ARINAR: Bi-Level Autoregressive Feature-by-Feature Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Qinyu Zhao, Stephen Gould, Liang Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2503.02883">https://arxiv.org/abs/2503.02883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2503.02883">https://arxiv.org/pdf/2503.02883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2503.02883]] ARINAR: Bi-Level Autoregressive Feature-by-Feature Generative Models(https://arxiv.org/abs/2503.02883)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Existing autoregressive (AR) image generative models use a token-by-token generation schema. That is, they predict a per-token probability distribution and sample the next token from that distribution. The main challenge is how to model the complex distribution of high-dimensional tokens. Previous methods either are too simplistic to fit the distribution or result in slow generation speed. Instead of fitting the distribution of the whole tokens, we explore using a AR model to generate each token in a feature-by-feature way, i.e., taking the generated features as input and generating the next feature. Based on that, we propose ARINAR (AR-in-AR), a bi-level AR model. The outer AR layer take previous tokens as input, predicts a condition vector z for the next token. The inner layer, conditional on z, generates features of the next token autoregressively. In this way, the inner layer only needs to model the distribution of a single feature, for example, using a simple Gaussian Mixture Model. On the ImageNet 256x256 image generation task, ARINAR-B with 213M parameters achieves an FID of 2.75, which is comparable to the state-of-the-art MAR-B model (FID=2.31), while five times faster than the latter.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
