<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Android Private Compute Core Architecture. (arXiv:2209.10317v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10317">http://arxiv.org/abs/2209.10317</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10317] Android Private Compute Core Architecture](http://arxiv.org/abs/2209.10317)</code></li>
<li>Summary: <p>Android's Private Compute Core (PCC) is a secure, isolated environment within
the operating system, that maintains separation from apps while enabling users
and developers to maintain control over their data. It is backed by open-source
code in the Android Framework introduced in Android 12. PCC allows features to
communicate with a server to receive model updates and contribute to global
model training through Private Compute Services (PCS), the core of which has
been open sourced. PCC is part of the OS, and by virtue of being isolated,
constrained, and trusted, it can host sophisticated ML features. The hosted
features themselves, running inside PCC, can be closed source and updatable. In
this way, PCC enables machine learning features to process ambient and OS-level
data and improve over time, while restricting the availability of information
about individual users to servers or apps.
</p></li>
</ul>

<h3>Title: Understanding Information Disclosure from Secure Computation Output: A Study of Average Salary Computation. (arXiv:2209.10457v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10457">http://arxiv.org/abs/2209.10457</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10457] Understanding Information Disclosure from Secure Computation Output: A Study of Average Salary Computation](http://arxiv.org/abs/2209.10457)</code></li>
<li>Summary: <p>Secure multi-party computation have seen substantial performance improvements
in recent years and are being increasingly used in commercial products. While a
great deal of work was dedicated to improving their efficiency under standard
security models, the threat models do not take into account information leakage
from the output of secure function evaluation. Quantification of information
disclosure about private inputs from observing the function outcome is the
subject of this work. Motivated by the City of Boston gender pay gap studies,
we focus on the computation of average salaries and determine information
disclosure about a target's private input to an adversary for a number of
distributions including log-normal, which is typically used for modeling
salaries. We consequently evaluate information disclosure after a repeated
evaluation of the function on overlapping inputs and provide recommendations
for using the sum and average functions in secure computation applications in
practice.
</p></li>
</ul>

<h3>Title: Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation. (arXiv:2209.10168v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10168">http://arxiv.org/abs/2209.10168</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10168] Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation](http://arxiv.org/abs/2209.10168)</code></li>
<li>Summary: <p>Graph anomaly detection (GAD) is a vital task since even a few anomalies can
pose huge threats to benign users. Recent semi-supervised GAD methods, which
can effectively leverage the available labels as prior knowledge, have achieved
superior performances than unsupervised methods. In practice, people usually
need to identify anomalies on new (sub)graphs to secure their business, but
they may lack labels to train an effective detection model. One natural idea is
to directly adopt a trained GAD model to the new (sub)graph for testing.
However, we find that existing semi-supervised GAD methods suffer from poor
generalization issue, i.e., well-trained models could not perform well on an
unseen area (i.e., not accessible in training) of the same graph. It may cause
great troubles. In this paper, we base on the phenomenon and propose a general
and novel research problem of generalized graph anomaly detection that aims to
effectively identify anomalies on both the training-domain graph and unseen
testing graph to eliminate potential dangers. Nevertheless, it is a challenging
task since only limited labels are available, and the normal background may
differ between training and testing data. Accordingly, we propose a data
augmentation method named \textit{AugAN} (\uline{Aug}mentation for
\uline{A}nomaly and \uline{N}ormal distributions) to enrich training data and
boost the generalizability of GAD models. Experiments verify the effectiveness
of our method in improving model generalizability.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Identifying Emerging Technologies and Leading Companies using Network Dynamics of Patent Clusters: a Cybersecurity Case Study. (arXiv:2209.10224v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10224">http://arxiv.org/abs/2209.10224</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10224] Identifying Emerging Technologies and Leading Companies using Network Dynamics of Patent Clusters: a Cybersecurity Case Study](http://arxiv.org/abs/2209.10224)</code></li>
<li>Summary: <p>Strategic decisions rely heavily on non-scientific instrumentation to
forecast emerging technologies and leading companies. Instead, we build a fast
quantitative system with a small computational footprint to discover the most
important technologies and companies in a given field, using generalisable
methods applicable to any industry. With the help of patent data from the US
Patent and Trademark Office, we first assign a value to each patent thanks to
automated machine learning tools. We then apply network science to track the
interaction and evolution of companies and clusters of patents (i.e.
technologies) to create rankings for both sets that highlight important or
emerging network nodes thanks to five network centrality indices. Finally, we
illustrate our system with a case study based on the cybersecurity industry.
Our results produce useful insights, for instance by highlighting (i) emerging
technologies with a growing mean patent value and cluster size, (ii) the most
influential companies in the field and (iii) attractive startups with few but
impactful patents. Complementary analysis also provides evidence of decreasing
marginal returns of research and development in larger companies in the
cybersecurity industry.
</p></li>
</ul>

<h3>Title: Adopting the Cybersecurity Concepts into Curriculum The Potential Effects on Students Cybersecurity Knowledge. (arXiv:2209.10407v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10407">http://arxiv.org/abs/2209.10407</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10407] Adopting the Cybersecurity Concepts into Curriculum The Potential Effects on Students Cybersecurity Knowledge](http://arxiv.org/abs/2209.10407)</code></li>
<li>Summary: <p>This study examines the effect of adopting cybersecurity concepts on the IT
curriculum and determines the potential effect on students' knowledge of
cybersecurity practices and level of awareness. To this end, a pilot study was
first conducted to measure the current level of cybersecurity awareness. The
results revealed that students do not have much knowledge of Cybersecurity.
Thus, a four-step approach was proposed to infuse the relevant cybersecurity
topics in five matched courses based on the latest Cybersecurity curricular
guidelines (CSEC2017). A sample of 42 students was selected purposively without
prior knowledge of Cybersecurity and divided identically into experimental and
control groups. Students in the experimental group were asked to take five
consecutive courses over five semesters. In each course, groups went through a
pre-test for the infused topics. Then, the experimental group taught the
corresponding infused topics. A post-test was administered to both groups at
the end of each course, and the t-test was conducted. The results found
significant differences between marks of prior and post-tests for 11 out of 14
infused topics. These satisfactory results would encourage universities to
infuse cybersecurity concepts into their curriculum
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Measuring and Controlling Split Layer Privacy Leakage Using Fisher Information. (arXiv:2209.10119v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10119">http://arxiv.org/abs/2209.10119</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10119] Measuring and Controlling Split Layer Privacy Leakage Using Fisher Information](http://arxiv.org/abs/2209.10119)</code></li>
<li>Summary: <p>Split learning and inference propose to run training/inference of a large
model that is split across client devices and the cloud. However, such a model
splitting imposes privacy concerns, because the activation flowing through the
split layer may leak information about the clients' private input data. There
is currently no good way to quantify how much private information is being
leaked through the split layer, nor a good way to improve privacy up to the
desired level.
</p></li>
</ul>

<p>In this work, we propose to use Fisher information as a privacy metric to
measure and control the information leakage. We show that Fisher information
can provide an intuitive understanding of how much private information is
leaking through the split layer, in the form of an error bound for an unbiased
reconstruction attacker. We then propose a privacy-enhancing technique, ReFIL,
that can enforce a user-desired level of Fisher information leakage at the
split layer to achieve high privacy, while maintaining reasonable utility.
</p>

<h3>Title: Fingerprinting Robot Movements via Acoustic Side Channel. (arXiv:2209.10240v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10240">http://arxiv.org/abs/2209.10240</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10240] Fingerprinting Robot Movements via Acoustic Side Channel](http://arxiv.org/abs/2209.10240)</code></li>
<li>Summary: <p>In this paper, we present an acoustic side channel attack which makes use of
smartphone microphones recording a robot in operation to exploit acoustic
properties of the sound to fingerprint a robot's movements. In this work we
consider the possibility of an insider adversary who is within physical
proximity of a robotic system (such as a technician or robot operator),
equipped with only their smartphone microphone. Through the acoustic
side-channel, we demonstrate that it is indeed possible to fingerprint not only
individual robot movements within 3D space, but also patterns of movements
which could lead to inferring the purpose of the movements (i.e. surgical
procedures which a surgical robot is undertaking) and hence, resulting in
potential privacy violations. Upon evaluation, we find that individual robot
movements can be fingerprinted with around 75% accuracy, decreasing slightly
with more fine-grained movement meta-data such as distance and speed.
Furthermore, workflows could be reconstructed with around 62% accuracy as a
whole, with more complex movements such as pick-and-place or packing
reconstructed with near perfect accuracy. As well as this, in some environments
such as surgical settings, audio may be recorded and transmitted over VoIP,
such as for education/teaching purposes or in remote telemedicine. The question
here is, can the same attack be successful even when VoIP communication is
employed, and how does packet loss impact the captured audio and the success of
the attack? Using the same characteristics of acoustic sound for plain audio
captured by the smartphone, the attack was 90% accurate in fingerprinting VoIP
samples on average, 15% higher than the baseline without the VoIP codec
employed. This opens up new research questions regarding anonymous
communications to protect robotic systems from acoustic side channel attacks
via VoIP communication networks.
</p></li>
</ul>

<h3>Title: Scalable Discovery and Continuous Inventory of Personal Data at Rest in Cloud Native Systems. (arXiv:2209.10412v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10412">http://arxiv.org/abs/2209.10412</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10412] Scalable Discovery and Continuous Inventory of Personal Data at Rest in Cloud Native Systems](http://arxiv.org/abs/2209.10412)</code></li>
<li>Summary: <p>Cloud native systems are processing large amounts of personal data through
numerous and possibly multi-paradigmatic data stores (e.g., relational and
non-relational databases). From a privacy engineering perspective, a core
challenge is to keep track of all exact locations, where personal data is being
stored, as required by regulatory frameworks such as the European General Data
Protection Regulation. In this paper, we present Teiresias, comprising i) a
workflow pattern for scalable discovery of personal data at rest, and ii) a
cloud native system architecture and open source prototype implementation of
said workflow pattern. To this end, we enable a continuous inventory of
personal data featuring transparency and accountability following
DevOps/DevPrivOps practices. In particular, we scope version-controlled
Infrastructure as Code definitions, cloud-based storages, and how to integrate
the process into CI/CD pipelines. Thereafter, we provide iii) a comparative
performance evaluation demonstrating both appropriate execution times for
real-world settings, and a promising personal data detection accuracy
outperforming existing proprietary tools in public clouds.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Text Revealer: Private Text Reconstruction via Model Inversion Attacks against Transformers. (arXiv:2209.10505v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10505">http://arxiv.org/abs/2209.10505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10505] Text Revealer: Private Text Reconstruction via Model Inversion Attacks against Transformers](http://arxiv.org/abs/2209.10505)</code></li>
<li>Summary: <p>Text classification has become widely used in various natural language
processing applications like sentiment analysis. Current applications often use
large transformer-based language models to classify input texts. However, there
is a lack of systematic study on how much private information can be inverted
when publishing models. In this paper, we formulate \emph{Text Revealer} -- the
first model inversion attack for text reconstruction against text
classification with transformers. Our attacks faithfully reconstruct private
texts included in training data with access to the target model. We leverage an
external dataset and GPT-2 to generate the target domain-like fluent text, and
then perturb its hidden state optimally with the feedback from the target
model. Our extensive experiments demonstrate that our attacks are effective for
datasets with different text lengths and can reconstruct private texts with
accuracy.
</p></li>
</ul>

<h3>Title: Learning the Propagation of Worms in Wireless Sensor Networks. (arXiv:2209.09984v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.09984">http://arxiv.org/abs/2209.09984</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.09984] Learning the Propagation of Worms in Wireless Sensor Networks](http://arxiv.org/abs/2209.09984)</code></li>
<li>Summary: <p>Wireless sensor networks (WSNs) are composed of spatially distributed sensors
and are considered vulnerable to attacks by worms and their variants. Due to
the distinct strategies of worms propagation, the dynamic behavior varies
depending on the different features of the sensors. Modeling the spread of
worms can help us understand the worm attack behaviors and analyze the
propagation procedure. In this paper, we design a communication model under
various worms. We aim to learn our proposed model to analytically derive the
dynamics of competitive worms propagation. We develop a new searching space
combined with complex neural network models. Furthermore, the experiment
results verified our analysis and demonstrated the performance of our proposed
learning algorithms.
</p></li>
</ul>

<h3>Title: Reconstructing Robot Operations via Radio-Frequency Side-Channel. (arXiv:2209.10179v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10179">http://arxiv.org/abs/2209.10179</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10179] Reconstructing Robot Operations via Radio-Frequency Side-Channel](http://arxiv.org/abs/2209.10179)</code></li>
<li>Summary: <p>Connected teleoperated robotic systems play a key role in ensuring
operational workflows are carried out with high levels of accuracy and low
margins of error. In recent years, a variety of attacks have been proposed that
actively target the robot itself from the cyber domain. However, little
attention has been paid to the capabilities of a passive attacker. In this
work, we investigate whether an insider adversary can accurately fingerprint
robot movements and operational warehousing workflows via the radio frequency
side channel in a stealthy manner. Using an SVM for classification, we found
that an adversary can fingerprint individual robot movements with at least 96%
accuracy, increasing to near perfect accuracy when reconstructing entire
warehousing workflows.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Learning Sparse Latent Representations for Generator Model. (arXiv:2209.09949v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.09949">http://arxiv.org/abs/2209.09949</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.09949] Learning Sparse Latent Representations for Generator Model](http://arxiv.org/abs/2209.09949)</code></li>
<li>Summary: <p>Sparsity is a desirable attribute. It can lead to more efficient and more
effective representations compared to the dense model. Meanwhile, learning
sparse latent representations has been a challenging problem in the field of
computer vision and machine learning due to its complexity. In this paper, we
present a new unsupervised learning method to enforce sparsity on the latent
space for the generator model with a gradually sparsified spike and slab
distribution as our prior. Our model consists of only one top-down generator
network that maps the latent variable to the observed data. Latent variables
can be inferred following generator posterior direction using non-persistent
gradient based method. Spike and Slab regularization in the inference step can
push non-informative latent dimensions towards zero to induce sparsity.
Extensive experiments show the model can preserve majority of the information
from original images with sparse representations while demonstrating improved
results compared to other existing methods. We observe that our model can learn
disentangled semantics and increase explainability of the latent codes while
boosting the robustness in the task of classification and denoising.
</p></li>
</ul>

<h3>Title: HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images. (arXiv:2209.10167v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10167">http://arxiv.org/abs/2209.10167</a></li>
<li>Code URL: <a href="https://github.com/dbseorms16/haze_net">https://github.com/dbseorms16/haze_net</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10167] HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images](http://arxiv.org/abs/2209.10167)</code></li>
<li>Summary: <p>Although gaze estimation methods have been developed with deep learning
techniques, there has been no such approach as aim to attain accurate
performance in low-resolution face images with a pixel width of 50 pixels or
less. To solve a limitation under the challenging low-resolution conditions, we
propose a high-frequency attentive super-resolved gaze estimation network,
i.e., HAZE-Net. Our network improves the resolution of the input image and
enhances the eye features and those boundaries via a proposed super-resolution
module based on a high-frequency attention block. In addition, our gaze
estimation module utilizes high-frequency components of the eye as well as the
global appearance map. We also utilize the structural location information of
faces to approximate head pose. The experimental results indicate that the
proposed method exhibits robust gaze estimation performance even in
low-resolution face images with 28x28 pixels. The source code of this work is
available at https://github.com/dbseorms16/HAZE_Net/.
</p></li>
</ul>

<h3>Title: D-InLoc++: Indoor Localization in Dynamic Environments. (arXiv:2209.10185v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10185">http://arxiv.org/abs/2209.10185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10185] D-InLoc++: Indoor Localization in Dynamic Environments](http://arxiv.org/abs/2209.10185)</code></li>
<li>Summary: <p>Most state-of-the-art localization algorithms rely on robust relative pose
estimation and geometry verification to obtain moving object agnostic camera
poses in complex indoor environments. However, this approach is prone to
mistakes if a scene contains repetitive structures, e.g., desks, tables, boxes,
or moving people. We show that the movable objects incorporate non-negligible
localization error and present a new straightforward method to predict the
six-degree-of-freedom (6DoF) pose more robustly. We equipped the localization
pipeline InLoc with real-time instance segmentation network YOLACT++. The masks
of dynamic objects are employed in the relative pose estimation step and in the
final sorting of camera pose proposal. At first, we filter out the matches
laying on masks of the dynamic objects. Second, we skip the comparison of query
and synthetic images on the area related to the moving object. This procedure
leads to a more robust localization. Lastly, we describe and improve the
mistakes caused by gradient-based comparison between synthetic and query images
and publish a new pipeline for simulation of environments with movable objects
from the Matterport scans. All the codes are available on
github.com/dubenma/D-InLocpp .
</p></li>
</ul>

<h3>Title: AirFi: Empowering WiFi-based Passive Human Gesture Recognition to Unseen Environment via Domain Generalization. (arXiv:2209.10285v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10285">http://arxiv.org/abs/2209.10285</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10285] AirFi: Empowering WiFi-based Passive Human Gesture Recognition to Unseen Environment via Domain Generalization](http://arxiv.org/abs/2209.10285)</code></li>
<li>Summary: <p>WiFi-based smart human sensing technology enabled by Channel State
Information (CSI) has received great attention in recent years. However,
CSI-based sensing systems suffer from performance degradation when deployed in
different environments. Existing works solve this problem by domain adaptation
using massive unlabeled high-quality data from the new environment, which is
usually unavailable in practice. In this paper, we propose a novel augmented
environment-invariant robust WiFi gesture recognition system named AirFi that
deals with the issue of environment dependency from a new perspective. The
AirFi is a novel domain generalization framework that learns the critical part
of CSI regardless of different environments and generalizes the model to unseen
scenarios, which does not require collecting any data for adaptation to the new
environment. AirFi extracts the common features from several training
environment settings and minimizes the distribution differences among them. The
feature is further augmented to be more robust to environments. Moreover, the
system can be further improved by few-shot learning techniques. Compared to
state-of-the-art methods, AirFi is able to work in different environment
settings without acquiring any CSI data from the new environment. The
experimental results demonstrate that our system remains robust in the new
environment and outperforms the compared systems.
</p></li>
</ul>

<h3>Title: DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions. (arXiv:2209.10381v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10381">http://arxiv.org/abs/2209.10381</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10381] DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions](http://arxiv.org/abs/2209.10381)</code></li>
<li>Summary: <p>Network architecture search (NAS), in particular the differentiable
architecture search (DARTS) method, has shown a great power to learn excellent
model architectures on the specific dataset of interest. In contrast to using a
fixed dataset, in this work, we focus on a different but important scenario for
NAS: how to refine a deployed network's model architecture to enhance its
robustness with the guidance of a few collected and misclassified examples that
are degraded by some real-world unknown corruptions having a specific pattern
(e.g., noise, blur, etc.). To this end, we first conduct an empirical study to
validate that the model architectures can be definitely related to the
corruption patterns. Surprisingly, by just adding a few corrupted and
misclassified examples (e.g., $10^3$ examples) to the clean training dataset
(e.g., $5.0 \times 10^4$ examples), we can refine the model architecture and
enhance the robustness significantly. To make it more practical, the key
problem, i.e., how to select the proper failure examples for the effective NAS
guidance, should be carefully investigated. Then, we propose a novel
core-failure-set guided DARTS that embeds a K-center-greedy algorithm for DARTS
to select suitable corrupted failure examples to refine the model architecture.
We use our method for DARTS-refined DNNs on the clean as well as 15 corruptions
with the guidance of four specific real-world corruptions. Compared with the
state-of-the-art NAS as well as data-augmentation-based enhancement methods,
our final method can achieve higher accuracy on both corrupted datasets and the
original clean dataset. On some of the corruption patterns, we can achieve as
high as over 45% absolute accuracy improvements.
</p></li>
</ul>

<h3>Title: Uncertainty-aware Label Distribution Learning for Facial Expression Recognition. (arXiv:2209.10448v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10448">http://arxiv.org/abs/2209.10448</a></li>
<li>Code URL: <a href="https://github.com/minhnhatvt/label-distribution-learning-fer-tf">https://github.com/minhnhatvt/label-distribution-learning-fer-tf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10448] Uncertainty-aware Label Distribution Learning for Facial Expression Recognition](http://arxiv.org/abs/2209.10448)</code></li>
<li>Summary: <p>Despite significant progress over the past few years, ambiguity is still a
key challenge in Facial Expression Recognition (FER). It can lead to noisy and
inconsistent annotation, which hinders the performance of deep learning models
in real-world scenarios. In this paper, we propose a new uncertainty-aware
label distribution learning method to improve the robustness of deep models
against uncertainty and ambiguity. We leverage neighborhood information in the
valence-arousal space to adaptively construct emotion distributions for
training samples. We also consider the uncertainty of provided labels when
incorporating them into the label distributions. Our method can be easily
integrated into a deep network to obtain more training supervision and improve
recognition accuracy. Intensive experiments on several datasets under various
noisy and ambiguous settings show that our method achieves competitive results
and outperforms recent state-of-the-art approaches. Our code and models are
available at https://github.com/minhnhatvt/label-distribution-learning-fer-tf.
</p></li>
</ul>

<h3>Title: Audit and Improve Robustness of Private Neural Networks on Encrypted Data. (arXiv:2209.09996v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.09996">http://arxiv.org/abs/2209.09996</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.09996] Audit and Improve Robustness of Private Neural Networks on Encrypted Data](http://arxiv.org/abs/2209.09996)</code></li>
<li>Summary: <p>Performing neural network inference on encrypted data without decryption is
one popular method to enable privacy-preserving neural networks (PNet) as a
service. Compared with regular neural networks deployed for
machine-learning-as-a-service, PNet requires additional encoding, e.g.,
quantized-precision numbers, and polynomial activation. Encrypted input also
introduces novel challenges such as adversarial robustness and security. To the
best of our knowledge, we are the first to study questions including (i)
Whether PNet is more robust against adversarial inputs than regular neural
networks? (ii) How to design a robust PNet given the encrypted input without
decryption? We propose PNet-Attack to generate black-box adversarial examples
that can successfully attack PNet in both target and untarget manners. The
attack results show that PNet robustness against adversarial inputs needs to be
improved. This is not a trivial task because the PNet model owner does not have
access to the plaintext of the input values, which prevents the application of
existing detection and defense methods such as input tuning, model
normalization, and adversarial training. To tackle this challenge, we propose a
new fast and accurate noise insertion method, called RPNet, to design Robust
and Private Neural Networks. Our comprehensive experiments show that
PNet-Attack reduces at least $2.5\times$ queries than prior works. We
theoretically analyze our RPNet methods and demonstrate that RPNet can decrease
$\sim 91.88\%$ attack success rate.
</p></li>
</ul>

<h3>Title: An Information-Theoretic and Contrastive Learning-based Approach for Identifying Code Statements Causing Software Vulnerability. (arXiv:2209.10414v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10414">http://arxiv.org/abs/2209.10414</a></li>
<li>Code URL: <a href="https://github.com/vannguyennd/livuitcl">https://github.com/vannguyennd/livuitcl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10414] An Information-Theoretic and Contrastive Learning-based Approach for Identifying Code Statements Causing Software Vulnerability](http://arxiv.org/abs/2209.10414)</code></li>
<li>Summary: <p>Software vulnerabilities existing in a program or function of computer
systems are a serious and crucial concern. Typically, in a program or function
consisting of hundreds or thousands of source code statements, there are only
few statements causing the corresponding vulnerabilities. Vulnerability
labeling is currently done on a function or program level by experts with the
assistance of machine learning tools. Extending this approach to the code
statement level is much more costly and time-consuming and remains an open
problem. In this paper we propose a novel end-to-end deep learning-based
approach to identify the vulnerability-relevant code statements of a specific
function. Inspired by the specific structures observed in real world vulnerable
code, we first leverage mutual information for learning a set of latent
variables representing the relevance of the source code statements to the
corresponding function's vulnerability. We then propose novel clustered spatial
contrastive learning in order to further improve the representation learning
and the robust selection process of vulnerability-relevant code statements.
Experimental results on real-world datasets of 200k+ C/C++ functions show the
superiority of our method over other state-of-the-art baselines. In general,
our method obtains a higher performance in VCP, VCA, and Top-10 ACC measures of
between 3\% to 14\% over the baselines when running on real-world datasets in
an unsupervised setting. Our released source code samples are publicly
available at
\href{https://github.com/vannguyennd/livuitcl}{https://github.com/vannguyennd/livuitcl.}
</p></li>
</ul>

<h3>Title: LCRL: Certified Policy Synthesis via Logically-Constrained Reinforcement Learning. (arXiv:2209.10341v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10341">http://arxiv.org/abs/2209.10341</a></li>
<li>Code URL: <a href="https://github.com/grockious/lcrl">https://github.com/grockious/lcrl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10341] LCRL: Certified Policy Synthesis via Logically-Constrained Reinforcement Learning](http://arxiv.org/abs/2209.10341)</code></li>
<li>Summary: <p>LCRL is a software tool that implements model-free Reinforcement Learning
(RL) algorithms over unknown Markov Decision Processes (MDPs), synthesising
policies that satisfy a given linear temporal specification with maximal
probability. LCRL leverages partially deterministic finite-state machines known
as Limit Deterministic Buchi Automata (LDBA) to express a given linear temporal
specification. A reward function for the RL algorithm is shaped on-the-fly,
based on the structure of the LDBA. Theoretical guarantees under proper
assumptions ensure the convergence of the RL algorithm to an optimal policy
that maximises the satisfaction probability. We present case studies to
demonstrate the applicability, ease of use, scalability, and performance of
LCRL. Owing to the LDBA-guided exploration and LCRL model-free architecture, we
observe robust performance, which also scales well when compared to standard RL
approaches (whenever applicable to LTL specifications). Full instructions on
how to execute all the case studies in this paper are provided on a GitHub page
that accompanies the LCRL distribution www.github.com/grockious/lcrl.
</p></li>
</ul>

<h3>Title: Off-Policy Risk Assessment in Markov Decision Processes. (arXiv:2209.10444v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10444">http://arxiv.org/abs/2209.10444</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10444] Off-Policy Risk Assessment in Markov Decision Processes](http://arxiv.org/abs/2209.10444)</code></li>
<li>Summary: <p>Addressing such diverse ends as safety alignment with human preferences, and
the efficiency of learning, a growing line of reinforcement learning research
focuses on risk functionals that depend on the entire distribution of returns.
Recent work on \emph{off-policy risk assessment} (OPRA) for contextual bandits
introduced consistent estimators for the target policy's CDF of returns along
with finite sample guarantees that extend to (and hold simultaneously over) all
risk. In this paper, we lift OPRA to Markov decision processes (MDPs), where
importance sampling (IS) CDF estimators suffer high variance on longer
trajectories due to small effective sample size. To mitigate these problems, we
incorporate model-based estimation to develop the first doubly robust (DR)
estimator for the CDF of returns in MDPs. This estimator enjoys significantly
less variance and, when the model is well specified, achieves the Cramer-Rao
variance lower bound. Moreover, for many risk functionals, the downstream
estimates enjoy both lower bias and lower variance. Additionally, we derive the
first minimax lower bounds for off-policy CDF and risk estimation, which match
our error bounds up to a constant factor. Finally, we demonstrate the precision
of our DR CDF estimates experimentally on several different environments.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Can Shadows Reveal Biometric Information?. (arXiv:2209.10077v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10077">http://arxiv.org/abs/2209.10077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10077] Can Shadows Reveal Biometric Information?](http://arxiv.org/abs/2209.10077)</code></li>
<li>Summary: <p>We study the problem of extracting biometric information of individuals by
looking at shadows of objects cast on diffuse surfaces. We show that the
biometric information leakage from shadows can be sufficient for reliable
identity inference under representative scenarios via a maximum likelihood
analysis. We then develop a learning-based method that demonstrates this
phenomenon in real settings, exploiting the subtle cues in the shadows that are
the source of the leakage without requiring any labeled real data. In
particular, our approach relies on building synthetic scenes composed of 3D
face models obtained from a single photograph of each identity. We transfer
what we learn from the synthetic data to the real data using domain adaptation
in a completely unsupervised way. Our model is able to generalize well to the
real domain and is robust to several variations in the scenes. We report high
classification accuracies in an identity classification task that takes place
in a scene with unknown geometry and occluding objects.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Progressive with Purpose: Guiding Progressive Inpainting DNNs through Context and Structure. (arXiv:2209.10071v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10071">http://arxiv.org/abs/2209.10071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10071] Progressive with Purpose: Guiding Progressive Inpainting DNNs through Context and Structure](http://arxiv.org/abs/2209.10071)</code></li>
<li>Summary: <p>The advent of deep learning in the past decade has significantly helped
advance image inpainting. Although achieving promising performance, deep
learning-based inpainting algorithms still struggle from the distortion caused
by the fusion of structural and contextual features, which are commonly
obtained from, respectively, deep and shallow layers of a convolutional
encoder. Motivated by this observation, we propose a novel progressive
inpainting network that maintains the structural and contextual integrity of a
processed image. More specifically, inspired by the Gaussian and Laplacian
pyramids, the core of the proposed network is a feature extraction module named
GLE. Stacking GLE modules enables the network to extract image features from
different image frequency components. This ability is important to maintain
structural and contextual integrity, for high frequency components correspond
to structural information while low frequency components correspond to
contextual information. The proposed network utilizes the GLE features to
progressively fill in missing regions in a corrupted image in an iterative
manner. Our benchmarking experiments demonstrate that the proposed method
achieves clear improvement in performance over many state-of-the-art inpainting
algorithms.
</p></li>
</ul>

<h3>Title: FV2ES: A Fully End2End Multimodal System for Fast Yet Effective Video Emotion Recognition Inference. (arXiv:2209.10170v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10170">http://arxiv.org/abs/2209.10170</a></li>
<li>Code URL: <a href="https://github.com/qlwei89/fv2es">https://github.com/qlwei89/fv2es</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10170] FV2ES: A Fully End2End Multimodal System for Fast Yet Effective Video Emotion Recognition Inference](http://arxiv.org/abs/2209.10170)</code></li>
<li>Summary: <p>In the latest social networks, more and more people prefer to express their
emotions in videos through text, speech, and rich facial expressions.
Multimodal video emotion analysis techniques can help understand users' inner
world automatically based on human expressions and gestures in images, tones in
voices, and recognized natural language. However, in the existing research, the
acoustic modality has long been in a marginal position as compared to visual
and textual modalities. That is, it tends to be more difficult to improve the
contribution of the acoustic modality for the whole multimodal emotion
recognition task. Besides, although better performance can be obtained by
introducing common deep learning methods, the complex structures of these
training models always result in low inference efficiency, especially when
exposed to high-resolution and long-length videos. Moreover, the lack of a
fully end-to-end multimodal video emotion recognition system hinders its
application. In this paper, we designed a fully multimodal video-to-emotion
system (named FV2ES) for fast yet effective recognition inference, whose
benefits are threefold: (1) The adoption of the hierarchical attention method
upon the sound spectra breaks through the limited contribution of the acoustic
modality and outperforms the existing models' performance on both IEMOCAP and
CMU-MOSEI datasets; (2) the introduction of the idea of multi-scale for visual
extraction while single-branch for inference brings higher efficiency and
maintains the prediction accuracy at the same time; (3) the further integration
of data pre-processing into the aligned multimodal learning model allows the
significant reduction of computational costs and storage space.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FedFOR: Stateless Heterogeneous Federated Learning with First-Order Regularization. (arXiv:2209.10537v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10537">http://arxiv.org/abs/2209.10537</a></li>
<li>Code URL: <a href="https://github.com/gt-ripl/fedfor">https://github.com/gt-ripl/fedfor</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10537] FedFOR: Stateless Heterogeneous Federated Learning with First-Order Regularization](http://arxiv.org/abs/2209.10537)</code></li>
<li>Summary: <p>Federated Learning (FL) seeks to distribute model training across local
clients without collecting data in a centralized data-center, hence removing
data-privacy concerns. A major challenge for FL is data heterogeneity (where
each client's data distribution can differ) as it can lead to weight divergence
among local clients and slow global convergence. The current SOTA FL methods
designed for data heterogeneity typically impose regularization to limit the
impact of non-IID data and are stateful algorithms, i.e., they maintain local
statistics over time. While effective, these approaches can only be used for a
special case of FL involving only a small number of reliable clients. For the
more typical applications of FL where the number of clients is large (e.g.,
edge-device and mobile applications), these methods cannot be applied,
motivating the need for a stateless approach to heterogeneous FL which can be
used for any number of clients. We derive a first-order gradient regularization
to penalize inconsistent local updates due to local data heterogeneity.
Specifically, to mitigate weight divergence, we introduce a first-order
approximation of the global data distribution into local objectives, which
intuitively penalizes updates in the opposite direction of the global update.
The end result is a stateless FL algorithm that achieves 1) significantly
faster convergence (i.e., fewer communication rounds) and 2) higher overall
converged performance than SOTA methods under non-IID data distribution.
Importantly, our approach does not impose unrealistic limits on the client
size, enabling learning from a large number of clients as is typical in most FL
applications.
</p></li>
</ul>

<h3>Title: Federated Learning from Pre-Trained Models: A Contrastive Learning Approach. (arXiv:2209.10083v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10083">http://arxiv.org/abs/2209.10083</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10083] Federated Learning from Pre-Trained Models: A Contrastive Learning Approach](http://arxiv.org/abs/2209.10083)</code></li>
<li>Summary: <p>Federated Learning (FL) is a machine learning paradigm that allows
decentralized clients to learn collaboratively without sharing their private
data. However, excessive computation and communication demands pose challenges
to current FL frameworks, especially when training large-scale models. To
prevent these issues from hindering the deployment of FL systems, we propose a
lightweight framework where clients jointly learn to fuse the representations
generated by multiple fixed pre-trained models rather than training a
large-scale model from scratch. This leads us to a more practical FL problem by
considering how to capture more client-specific and class-relevant information
from the pre-trained models and jointly improve each client's ability to
exploit those off-the-shelf models. In this work, we design a Federated
Prototype-wise Contrastive Learning (FedPCL) approach which shares knowledge
across clients through their class prototypes and builds client-specific
representations in a prototype-wise contrastive manner. Sharing prototypes
rather than learnable model parameters allows each client to fuse the
representations in a personalized way while keeping the shared knowledge in a
compact form for efficient communication. We perform a thorough evaluation of
the proposed FedPCL in the lightweight framework, measuring and visualizing its
ability to fuse various pre-trained models on popular FL datasets.
</p></li>
</ul>

<h3>Title: Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles Between Client Data Subspaces. (arXiv:2209.10526v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10526">http://arxiv.org/abs/2209.10526</a></li>
<li>Code URL: <a href="https://github.com/mmorafah/pacfl">https://github.com/mmorafah/pacfl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10526] Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles Between Client Data Subspaces](http://arxiv.org/abs/2209.10526)</code></li>
<li>Summary: <p>Clustered federated learning (FL) has been shown to produce promising results
by grouping clients into clusters. This is especially effective in scenarios
where separate groups of clients have significant differences in the
distributions of their local data. Existing clustered FL algorithms are
essentially trying to group together clients with similar distributions so that
clients in the same cluster can leverage each other's data to better perform
federated learning. However, prior clustered FL algorithms attempt to learn
these distribution similarities indirectly during training, which can be quite
time consuming as many rounds of federated learning may be required until the
formation of clusters is stabilized. In this paper, we propose a new approach
to federated learning that directly aims to efficiently identify distribution
similarities among clients by analyzing the principal angles between the client
data subspaces. Each client applies a truncated singular value decomposition
(SVD) step on its local data in a single-shot manner to derive a small set of
principal vectors, which provides a signature that succinctly captures the main
characteristics of the underlying distribution. This small set of principal
vectors is provided to the server so that the server can directly identify
distribution similarities among the clients to form clusters. This is achieved
by comparing the similarities of the principal angles between the client data
subspaces spanned by those principal vectors. The approach provides a simple,
yet effective clustered FL framework that addresses a broad range of data
heterogeneity issues beyond simpler forms of Non-IIDness like label skews. Our
clustered FL approach also enables convergence guarantees for non-convex
objectives. Our code is available at https://github.com/MMorafah/PACFL.
</p></li>
</ul>

<h3>Title: Performance Optimization for Variable Bitwidth Federated Learning in Wireless Networks. (arXiv:2209.10200v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10200">http://arxiv.org/abs/2209.10200</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10200] Performance Optimization for Variable Bitwidth Federated Learning in Wireless Networks](http://arxiv.org/abs/2209.10200)</code></li>
<li>Summary: <p>This paper considers improving wireless communication and computation
efficiency in federated learning (FL) via model quantization. In the proposed
bitwidth FL scheme, edge devices train and transmit quantized versions of their
local FL model parameters to a coordinating server, which, in turn, aggregates
them into a quantized global model and synchronizes the devices. The goal is to
jointly determine the bitwidths employed for local FL model quantization and
the set of devices participating in FL training at each iteration. This problem
is posed as an optimization problem whose goal is to minimize the training loss
of quantized FL under a per-iteration device sampling budget and delay
requirement. To derive the solution, an analytical characterization is
performed in order to show how the limited wireless resources and induced
quantization errors affect the performance of the proposed FL method. The
analytical results show that the improvement of FL training loss between two
consecutive iterations depends on the device selection and quantization scheme
as well as on several parameters inherent to the model being learned. Given
linear regression-based estimates of these model properties, it is shown that
the FL training process can be described as a Markov decision process (MDP),
and, then, a model-based reinforcement learning (RL) method is proposed to
optimize action selection over iterations. Compared to model-free RL, this
model-based RL approach leverages the derived mathematical characterization of
the FL training process to discover an effective device selection and
quantization scheme without imposing additional device communication overhead.
Simulation results show that the proposed FL algorithm can reduce 29% and 63%
convergence time compared to a model free RL method and the standard FL method,
respectively.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Deep Learning for Medical Image Segmentation: Tricks, Challenges and Future Directions. (arXiv:2209.10307v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10307">http://arxiv.org/abs/2209.10307</a></li>
<li>Code URL: <a href="https://github.com/hust-linyi/seg_trick">https://github.com/hust-linyi/seg_trick</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10307] Deep Learning for Medical Image Segmentation: Tricks, Challenges and Future Directions](http://arxiv.org/abs/2209.10307)</code></li>
<li>Summary: <p>Over the past few years, the rapid development of deep learning technologies
for computer vision has greatly promoted the performance of medical image
segmentation (MedISeg). However, the recent MedISeg publications usually focus
on presentations of the major contributions (e.g., network architectures,
training strategies, and loss functions) while unwittingly ignoring some
marginal implementation details (also known as "tricks"), leading to a
potential problem of the unfair experimental result comparisons. In this paper,
we collect a series of MedISeg tricks for different model implementation phases
(i.e., pre-training model, data pre-processing, data augmentation, model
implementation, model inference, and result post-processing), and
experimentally explore the effectiveness of these tricks on the consistent
baseline models. Compared to paper-driven surveys that only blandly focus on
the advantages and limitation analyses of segmentation models, our work
provides a large number of solid experiments and is more technically operable.
With the extensive experimental results on both the representative 2D and 3D
medical image datasets, we explicitly clarify the effect of these tricks.
Moreover, based on the surveyed tricks, we also open-sourced a strong MedISeg
repository, where each of its components has the advantage of plug-and-play. We
believe that this milestone work not only completes a comprehensive and
complementary survey of the state-of-the-art MedISeg approaches, but also
offers a practical guide for addressing the future medical image processing
challenges including but not limited to small dataset learning, class imbalance
learning, multi-modality learning, and domain adaptation. The code has been
released at: https://github.com/hust-linyi/MedISeg
</p></li>
</ul>

<h3>Title: Benchmarking and Analyzing 3D Human Pose and Shape Estimation Beyond Algorithms. (arXiv:2209.10529v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10529">http://arxiv.org/abs/2209.10529</a></li>
<li>Code URL: <a href="https://github.com/smplbody/hmr-benchmarks">https://github.com/smplbody/hmr-benchmarks</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10529] Benchmarking and Analyzing 3D Human Pose and Shape Estimation Beyond Algorithms](http://arxiv.org/abs/2209.10529)</code></li>
<li>Summary: <p>3D human pose and shape estimation (a.k.a. "human mesh recovery") has
achieved substantial progress. Researchers mainly focus on the development of
novel algorithms, while less attention has been paid to other critical factors
involved. This could lead to less optimal baselines, hindering the fair and
faithful evaluations of newly designed methodologies. To address this problem,
this work presents the first comprehensive benchmarking study from three
under-explored perspectives beyond algorithms. 1) Datasets. An analysis on 31
datasets reveals the distinct impacts of data samples: datasets featuring
critical attributes (i.e. diverse poses, shapes, camera characteristics,
backbone features) are more effective. Strategical selection and combination of
high-quality datasets can yield a significant boost to the model performance.
2) Backbones. Experiments with 10 backbones, ranging from CNNs to transformers,
show the knowledge learnt from a proximity task is readily transferable to
human mesh recovery. 3) Training strategies. Proper augmentation techniques and
loss designs are crucial. With the above findings, we achieve a PA-MPJPE of
47.3 mm on the 3DPW test set with a relatively simple model. More importantly,
we provide strong baselines for fair comparisons of algorithms, and
recommendations for building effective training configurations in the future.
Codebase is available at <a href="http://github.com/smplbody/hmr-benchmarks">this http URL</a>
</p></li>
</ul>

<h3>Title: Power of Explanations: Towards automatic debiasing in hate speech detection. (arXiv:2209.09975v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.09975">http://arxiv.org/abs/2209.09975</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.09975] Power of Explanations: Towards automatic debiasing in hate speech detection](http://arxiv.org/abs/2209.09975)</code></li>
<li>Summary: <p>Hate speech detection is a common downstream application of natural language
processing (NLP) in the real world. In spite of the increasing accuracy,
current data-driven approaches could easily learn biases from the imbalanced
data distributions originating from humans. The deployment of biased models
could further enhance the existing social biases. But unlike handling tabular
data, defining and mitigating biases in text classifiers, which deal with
unstructured data, are more challenging. A popular solution for improving
machine learning fairness in NLP is to conduct the debiasing process with a
list of potentially discriminated words given by human annotators. In addition
to suffering from the risks of overlooking the biased terms, exhaustively
identifying bias with human annotators are unsustainable since discrimination
is variable among different datasets and may evolve over time. To this end, we
propose an automatic misuse detector (MiD) relying on an explanation method for
detecting potential bias. And built upon that, an end-to-end debiasing
framework with the proposed staged correction is designed for text classifiers
without any external resources required.
</p></li>
</ul>

<h3>Title: Interlude: Balancing Chaos And Harmony For Fair and Fast Blockchains. (arXiv:2209.10125v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10125">http://arxiv.org/abs/2209.10125</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10125] Interlude: Balancing Chaos And Harmony For Fair and Fast Blockchains](http://arxiv.org/abs/2209.10125)</code></li>
<li>Summary: <p>Blockchains lie at the heart of Bitcoin and other cryptocurrencies that have
shown great promise to revolutionize finance and commerce. Although they are
gaining increasing popularity, they face technical challenges when it comes to
scaling to support greater demand while maintaining their desirable security
properties. In an exciting line of recent work, many researchers have proposed
various scalable blockchain protocols that demonstrate the potential to solve
these challenges. However, many of these protocols come with the assumptions of
honest majority and symmetric network access which may not accurately reflect
the real world where the participants may be self-interested or rational.
Secondly, these works show that their protocol works in an ideal environment
where each party has equal access to the network whereas different parties have
varying latencies and network speeds. These assumptions may render the
protocols susceptible to security threats in the real world, as highlighted by
the literature focused on exploring game-theoretic attacks on these protocols.
</p></li>
</ul>

<p>We propose a scalable blockchain protocol, Interlude, which comes with the
typical security guarantees while focusing on game-theoretic soundness and
network fairness. The novelty of Interlude is that it has a relatively simple
design consisting of a sequence of parallel blocks containing disjoint
transaction sets that can be mined quickly followed by a series block that is
slow to mine and gives the honest parties in the network time to synchronize.
Thus, between the chaos of parallel blocks, our blockchain protocol masquerades
an interlude moment of harmony in series blocks that synchronize the network.
</p>

<h3>Title: Generalized Gloves of Neural Additive Models: Pursuing transparent and accurate machine learning models in finance. (arXiv:2209.10082v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10082">http://arxiv.org/abs/2209.10082</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10082] Generalized Gloves of Neural Additive Models: Pursuing transparent and accurate machine learning models in finance](http://arxiv.org/abs/2209.10082)</code></li>
<li>Summary: <p>For many years, machine learning methods have been used in a wide range of
fields, including computer vision and natural language processing. While
machine learning methods have significantly improved model performance over
traditional methods, their black-box structure makes it difficult for
researchers to interpret results. For highly regulated financial industries,
transparency, explainability, and fairness are equally, if not more, important
than accuracy. Without meeting regulated requirements, even highly accurate
machine learning methods are unlikely to be accepted. We address this issue by
introducing a novel class of transparent and interpretable machine learning
algorithms known as generalized gloves of neural additive models. The
generalized gloves of neural additive models separate features into three
categories: linear features, individual nonlinear features, and interacted
nonlinear features. Additionally, interactions in the last category are only
local. The linear and nonlinear components are distinguished by a stepwise
selection algorithm, and interacted groups are carefully verified by applying
additive separation criteria. Empirical results demonstrate that generalized
gloves of neural additive models provide optimal accuracy with the simplest
architecture, allowing for a highly accurate, transparent, and explainable
approach to machine learning.
</p></li>
</ul>

<h3>Title: Fairness Reprogramming. (arXiv:2209.10222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10222">http://arxiv.org/abs/2209.10222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10222] Fairness Reprogramming](http://arxiv.org/abs/2209.10222)</code></li>
<li>Summary: <p>Despite a surge of recent advances in promoting machine Learning (ML)
fairness, the existing mainstream approaches mostly require training or
finetuning the entire weights of the neural network to meet the fairness
criteria. However, this is often infeasible in practice for those large-scale
trained models due to large computational and storage costs, low data
efficiency, and model privacy issues. In this paper, we propose a new generic
fairness learning paradigm, called FairReprogram, which incorporates the model
reprogramming technique. Specifically, FairReprogram considers the neural model
fixed, and instead appends to the input a set of perturbations, called the
fairness trigger, which is tuned towards the fairness criteria under a min-max
formulation. We further introduce an information-theoretic framework that
explains why and under what conditions fairness goals can be achieved using the
fairness trigger. We show both theoretically and empirically that the fairness
trigger can effectively obscure demographic biases in the output prediction of
fixed ML models by providing false demographic information that hinders the
model from utilizing the correct demographic information to make the
prediction. Extensive experiments on both NLP and CV datasets demonstrate that
our method can achieve better fairness improvements than retraining-based
methods with far less training cost and data dependency under two widely-used
fairness criteria.
</p></li>
</ul>

<h3>Title: Monotonic Neural Additive Models: Pursuing Regulated Machine Learning Models for Credit Scoring. (arXiv:2209.10070v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10070">http://arxiv.org/abs/2209.10070</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10070] Monotonic Neural Additive Models: Pursuing Regulated Machine Learning Models for Credit Scoring](http://arxiv.org/abs/2209.10070)</code></li>
<li>Summary: <p>The forecasting of credit default risk has been an active research field for
several decades. Historically, logistic regression has been used as a major
tool due to its compliance with regulatory requirements: transparency,
explainability, and fairness. In recent years, researchers have increasingly
used complex and advanced machine learning methods to improve prediction
accuracy. Even though a machine learning method could potentially improve the
model accuracy, it complicates simple logistic regression, deteriorates
explainability, and often violates fairness. In the absence of compliance with
regulatory requirements, even highly accurate machine learning methods are
unlikely to be accepted by companies for credit scoring. In this paper, we
introduce a novel class of monotonic neural additive models, which meet
regulatory requirements by simplifying neural network architecture and
enforcing monotonicity. By utilizing the special architectural features of the
neural additive model, the monotonic neural additive model penalizes
monotonicity violations effectively. Consequently, the computational cost of
training a monotonic neural additive model is similar to that of training a
neural additive model, as a free lunch. We demonstrate through empirical
results that our new model is as accurate as black-box fully-connected neural
networks, providing a highly accurate and regulated machine learning method.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Toward 3D Spatial Reasoning for Human-like Text-based Visual Question Answering. (arXiv:2209.10326v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10326">http://arxiv.org/abs/2209.10326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10326] Toward 3D Spatial Reasoning for Human-like Text-based Visual Question Answering](http://arxiv.org/abs/2209.10326)</code></li>
<li>Summary: <p>Text-based Visual Question Answering~(TextVQA) aims to produce correct
answers for given questions about the images with multiple scene texts. In most
cases, the texts naturally attach to the surface of the objects. Therefore,
spatial reasoning between texts and objects is crucial in TextVQA. However,
existing approaches are constrained within 2D spatial information learned from
the input images and rely on transformer-based architectures to reason
implicitly during the fusion process. Under this setting, these 2D spatial
reasoning approaches cannot distinguish the fine-grain spatial relations
between visual objects and scene texts on the same image plane, thereby
impairing the interpretability and performance of TextVQA models. In this
paper, we introduce 3D geometric information into a human-like spatial
reasoning process to capture the contextual knowledge of key objects
step-by-step. %we formulate a human-like spatial reasoning process by
introducing 3D geometric information for capturing key objects' contextual
knowledge. To enhance the model's understanding of 3D spatial relationships,
Specifically, (i)~we propose a relation prediction module for accurately
locating the region of interest of critical objects; (ii)~we design a
depth-aware attention calibration module for calibrating the OCR tokens'
attention according to critical objects. Extensive experiments show that our
method achieves state-of-the-art performance on TextVQA and ST-VQA datasets.
More encouragingly, our model surpasses others by clear margins of 5.7\% and
12.1\% on questions that involve spatial reasoning in TextVQA and ST-VQA valid
split. Besides, we also verify the generalizability of our model on the
text-based image captioning task.
</p></li>
</ul>

<h3>Title: Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees. (arXiv:2209.10492v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2209.10492">http://arxiv.org/abs/2209.10492</a></li>
<li>Code URL: <a href="https://github.com/swarnahub/summarizationprograms">https://github.com/swarnahub/summarizationprograms</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2209.10492] Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees](http://arxiv.org/abs/2209.10492)</code></li>
<li>Summary: <p>Current abstractive summarization models either suffer from a lack of clear
interpretability or provide incomplete rationales by only highlighting parts of
the source document. To this end, we propose the Summarization Program (SP), an
interpretable modular framework consisting of an (ordered) list of binary
trees, each encoding the step-by-step generative process of an abstractive
summary sentence from the source document. A Summarization Program contains one
root node per summary sentence, and a distinct tree connects each summary
sentence (root node) to the document sentences (leaf nodes) from which it is
derived, with the connecting nodes containing intermediate generated sentences.
Edges represent different modular operations involved in summarization such as
sentence fusion, compression, and paraphrasing. We first propose an efficient
best-first search method over neural modules, SP-Search that identifies SPs for
human summaries by directly optimizing for ROUGE scores. Next, using these
programs as automatic supervision, we propose seq2seq models that generate
Summarization Programs, which are then executed to obtain final summaries. We
demonstrate that SP-Search effectively represents the generative process behind
human summaries using modules that are typically faithful to their intended
behavior. We also conduct a simulation study to show that Summarization
Programs improve the interpretability of summarization models by allowing
humans to better simulate model reasoning. Summarization Programs constitute a
promising step toward interpretable and modular abstractive summarization, a
complex task previously addressed primarily through blackbox end-to-end neural
systems. Our code is available at
https://github.com/swarnaHub/SummarizationPrograms
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
