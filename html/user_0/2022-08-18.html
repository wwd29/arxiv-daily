<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Evaluating the Feasibility of a Provably Secure Privacy-Preserving Entity Resolution Adaptation of PPJoin using Homomorphic Encryption. (arXiv:2208.07999v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07999">http://arxiv.org/abs/2208.07999</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07999] Evaluating the Feasibility of a Provably Secure Privacy-Preserving Entity Resolution Adaptation of PPJoin using Homomorphic Encryption](http://arxiv.org/abs/2208.07999)</code></li>
<li>Summary: <p>Entity resolution is the task of disambiguating records that refer to the
same entity in the real world. In this work, we explore adapting one of the
most efficient and accurate Jaccard-based entity resolution algorithms -
PPJoin, to the private domain via homomorphic encryption. Towards this, we
present our precise adaptation of PPJoin (HE-PPJoin) that details certain
subtle data structure modifications and algorithmic additions needed for
correctness and privacy. We implement HE-PPJoin by extending the PALISADE
homomorphic encryption library and evaluate over it for accuracy and incurred
overhead. Furthermore, we directly compare HE-PPJoin against P4Join, an
existing privacy-preserving variant of PPJoin which uses fingerprinting for raw
content obfuscation, by demonstrating a rigorous analysis of the efficiency,
accuracy, and privacy properties achieved by our adaptation as well as a
characterization of those same attributes in P4Join.
</p></li>
</ul>

<h3>Title: Resource Allocation in Quantum Key Distribution (QKD) for Space-Air-Ground Integrated Networks. (arXiv:2208.08009v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08009">http://arxiv.org/abs/2208.08009</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08009] Resource Allocation in Quantum Key Distribution (QKD) for Space-Air-Ground Integrated Networks](http://arxiv.org/abs/2208.08009)</code></li>
<li>Summary: <p>Space-air-ground integrated networks (SAGIN) are one of the most promising
advanced paradigms in the sixth generation (6G) communication. SAGIN can
support high data rates, low latency, and seamless network coverage for
interconnected applications and services. However, communications in SAGIN are
facing tremendous security threats from the ever-increasing capacity of quantum
computers. Fortunately, quantum key distribution (QKD) for establishing secure
communications in SAGIN, i.e., QKD over SAGIN, can provide
information-theoretic security. To minimize the QKD deployment cost in SAGIN
with heterogeneous nodes, in this paper, we propose a resource allocation
scheme for QKD over SAGIN using stochastic programming. The proposed scheme is
formulated via two-stage stochastic programming (SP), while considering
uncertainties such as security requirements and weather conditions. Under
extensive experiments, the results clearly show that the proposed scheme can
achieve the optimal deployment cost under various security requirements and
unpredictable weather conditions.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Improving the Cybersecurity of Critical National Infrastructure using Modelling and Simulation. (arXiv:2208.07965v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07965">http://arxiv.org/abs/2208.07965</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07965] Improving the Cybersecurity of Critical National Infrastructure using Modelling and Simulation](http://arxiv.org/abs/2208.07965)</code></li>
<li>Summary: <p>The UK Critical National Infrastructure is critically dependent on digital
technologies that provide communications, monitoring, control, and
decision-support functionalities. Digital technologies are progressively
enhancing efficiency, reliability, and availability of infrastructure, and
enabling new benefits not previously available. These benefits can introduce
vulnerabilities through the connectivity enabled by the digital systems, thus,
making it easier for would-be attackers, who frequently use socio-technical
approaches, exploiting humans-in-the-loop to break in and sabotage an
organization. Therefore, policies and strategies that minimize and manage risks
must include an understanding of operator and corporate behaviors, as well as
technical elements and the interfaces between them and humans. Better security
via socio-technical security Modelling and Simulation can be achieved if backed
by government effort, including appropriate policy interventions. Government,
through its departments and agencies, can contribute by sign-posting and
shaping the decision-making environment concerning cybersecurity M&amp;S approaches
and tools, showing how they can contribute to enhancing security in Modern
Critical Infrastructure Systems.
</p></li>
</ul>

<h3>Title: A Tutorial Introduction to Lattice-based Cryptography and Homomorphic Encryption. (arXiv:2208.08125v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08125">http://arxiv.org/abs/2208.08125</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08125] A Tutorial Introduction to Lattice-based Cryptography and Homomorphic Encryption](http://arxiv.org/abs/2208.08125)</code></li>
<li>Summary: <p>Why study Lattice-based Cryptography? There are a few ways to answer this
question. 1. It is useful to have cryptosystems that are based on a variety of
hard computational problems so the different cryptosystems are not all
vulnerable in the same way. 2. The computational aspects of lattice-based
cryptosystem are usually simple to understand and fairly easy to implement in
practice. 3. Lattice-based cryptosystems have lower encryption/decryption
computational complexities compared to popular cryptosystems that are based on
the integer factorisation or the discrete logarithm problems. 4. Lattice-based
cryptosystems enjoy strong worst-case hardness security proofs based on
approximate versions of known NP-hard lattice problems. 5. Lattice-based
cryptosystems are believed to be good candidates for post-quantum cryptography,
since there are currently no known quantum algorithms for solving lattice
problems that perform significantly better than the best-known classical
(non-quantum) algorithms, unlike for integer factorisation and (elliptic curve)
discrete logarithm problems. 6. Last but not least, interesting structures in
lattice problems have led to significant advances in Homomorphic Encryption, a
new research area with wide-ranging applications.
</p></li>
</ul>

<h3>Title: An In-depth Study of Java Deserialization Remote-Code Execution Exploits and Vulnerabilities. (arXiv:2208.08173v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08173">http://arxiv.org/abs/2208.08173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08173] An In-depth Study of Java Deserialization Remote-Code Execution Exploits and Vulnerabilities](http://arxiv.org/abs/2208.08173)</code></li>
<li>Summary: <p>Nowadays, an increasing number of applications uses deserialization. This
technique, based on rebuilding the instance of objects from serialized byte
streams, can be dangerous since it can open the application to attacks such as
remote code execution (RCE) if the data to deserialize is originating from an
untrusted source. Deserialization vulnerabilities are so critical that they are
in OWASP's list of top 10 security risks for web applications. This is mainly
caused by faults in the development process of applications and by flaws in
their dependencies, i.e., flaws in the libraries used by these applications. No
previous work has studied deserialization attacks in-depth: How are they
performed? How are weaknesses introduced and patched? And for how long are
vulnerabilities present in the codebase? To yield a deeper understanding of
this important kind of vulnerability, we perform two main analyses: one on
attack gadgets, i.e., exploitable pieces of code, present in Java libraries,
and one on vulnerabilities present in Java applications. For the first
analysis, we conduct an exploratory large-scale study by running 256515
experiments in which we vary the versions of libraries for each of the 19
publicly available exploits. Such attacks rely on a combination of gadgets
present in one or multiple Java libraries. A gadget is a method which is using
objects or fields that can be attacker-controlled. Our goal is to precisely
identify library versions containing gadgets and to understand how gadgets have
been introduced and how they have been patched. We observe that the
modification of one innocent-looking detail in a class -- such as making it
public -- can already introduce a gadget. Furthermore, we noticed that among
the studied libraries, 37.5% are not patched, leaving gadgets available for
future attacks. For the second analysis, we manually analyze 104
deserialization vulnerabilities CVEs to understand how vulnerabilities are
introduced and patched in real-life Java applications. Results indicate that
the vulnerabilities are not always completely patched or that a workaround
solution is proposed. With a workaround solution, applications are still
vulnerable since the code itself is unchanged.
</p></li>
</ul>

<h3>Title: On the Elements of Datasets for Cyber Physical Systems Security. (arXiv:2208.08255v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08255">http://arxiv.org/abs/2208.08255</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08255] On the Elements of Datasets for Cyber Physical Systems Security](http://arxiv.org/abs/2208.08255)</code></li>
<li>Summary: <p>Datasets are essential to apply AI algorithms to Cyber Physical System (CPS)
Security. Due to scarcity of real CPS datasets, researchers elected to generate
their own datasets using either real or virtualized testbeds. However, unlike
other AI domains, a CPS is a complex system with many interfaces that determine
its behavior. A dataset that comprises merely a collection of sensor
measurements and network traffic may not be sufficient to develop resilient AI
defensive or offensive agents. In this paper, we study the \emph{elements} of
CPS security datasets required to capture the system behavior and interactions,
and propose a dataset architecture that has the potential to enhance the
performance of AI algorithms in securing cyber physical systems. The framework
includes dataset elements, attack representation, and required dataset
features. We compare existing datasets to the proposed architecture to identify
the current limitations and discuss the future of CPS dataset generation using
testbeds.
</p></li>
</ul>

<h3>Title: A Concept and Argumentation based Interpretable Model in High Risk Domains. (arXiv:2208.08149v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08149">http://arxiv.org/abs/2208.08149</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08149] A Concept and Argumentation based Interpretable Model in High Risk Domains](http://arxiv.org/abs/2208.08149)</code></li>
<li>Summary: <p>Interpretability has become an essential topic for artificial intelligence in
some high-risk domains such as healthcare, bank and security. For commonly-used
tabular data, traditional methods trained end-to-end machine learning models
with numerical and categorical data only, and did not leverage human
understandable knowledge such as data descriptions. Yet mining human-level
knowledge from tabular data and using it for prediction remain a challenge.
Therefore, we propose a concept and argumentation based model (CAM) that
includes the following two components: a novel concept mining method to obtain
human understandable concepts and their relations from both descriptions of
features and the underlying data, and a quantitative argumentation-based method
to do knowledge representation and reasoning. As a result of it, CAM provides
decisions that are based on human-level knowledge and the reasoning process is
intrinsically interpretable. Finally, to visualize the purposed interpretable
model, we provide a dialogical explanation that contain dominated reasoning
path within CAM. Experimental results on both open source benchmark dataset and
real-word business dataset show that (1) CAM is transparent and interpretable,
and the knowledge inside the CAM is coherent with human understanding; (2) Our
interpretable approach can reach competitive results comparing with other
state-of-art models.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data. (arXiv:2208.08207v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08207">http://arxiv.org/abs/2208.08207</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08207] Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data](http://arxiv.org/abs/2208.08207)</code></li>
<li>Summary: <p>The vast progress in synthetic image synthesis enables the generation of
facial images in high resolution and photorealism. In biometric applications,
the main motivation for using synthetic data is to solve the shortage of
publicly-available biometric data while reducing privacy risks when processing
such sensitive information. These advantages are exploited in this work by
simulating human face ageing with recent face age modification algorithms to
generate mated samples, thereby studying the impact of ageing on the
performance of an open-source biometric recognition system. Further, a real
dataset is used to evaluate the effects of short-term ageing, comparing the
biometric performance to the synthetic domain. The main findings indicate that
short-term ageing in the range of 1-5 years has only minor effects on the
general recognition performance. However, the correct verification of mated
faces with long-term age differences beyond 20 years poses still a significant
challenge and requires further investigation.
</p></li>
</ul>

<h3>Title: On the Privacy Effect of Data Enhancement via the Lens of Memorization. (arXiv:2208.08270v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08270">http://arxiv.org/abs/2208.08270</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08270] On the Privacy Effect of Data Enhancement via the Lens of Memorization](http://arxiv.org/abs/2208.08270)</code></li>
<li>Summary: <p>Machine learning poses severe privacy concerns as it is shown that the
learned models can reveal sensitive information about their training data. Many
works have investigated the effect of widely-adopted data augmentation (DA) and
adversarial training (AT) techniques, termed data enhancement in the paper, on
the privacy leakage of machine learning models. Such privacy effects are often
measured by membership inference attacks (MIAs), which aim to identify whether
a particular example belongs to the training set or not. We propose to
investigate privacy from a new perspective called memorization. Through the
lens of memorization, we find that previously deployed MIAs produce misleading
results as they are less likely to identify samples with higher privacy risks
as members compared to samples with low privacy risks. To solve this problem,
we deploy a recent attack that can capture the memorization degrees of
individual samples for evaluation. Through extensive experiments, we unveil
non-trivial findings about the connections between three important properties
of machine learning models, including privacy, generalization gap, and
adversarial robustness. We demonstrate that, unlike existing results, the
generalization gap is shown not highly correlated with privacy leakage.
Moreover, stronger adversarial robustness does not necessarily imply that the
model is more susceptible to privacy attacks.
</p></li>
</ul>

<h3>Title: Differential Privacy in Natural Language Processing: The Story So Far. (arXiv:2208.08140v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08140">http://arxiv.org/abs/2208.08140</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08140] Differential Privacy in Natural Language Processing: The Story So Far](http://arxiv.org/abs/2208.08140)</code></li>
<li>Summary: <p>As the tide of Big Data continues to influence the landscape of Natural
Language Processing (NLP), the utilization of modern NLP methods has grounded
itself in this data, in order to tackle a variety of text-based tasks. These
methods without a doubt can include private or otherwise personally
identifiable information. As such, the question of privacy in NLP has gained
fervor in recent years, coinciding with the development of new
Privacy-Enhancing Technologies (PETs). Among these PETs, Differential Privacy
boasts several desirable qualities in the conversation surrounding data
privacy. Naturally, the question becomes whether Differential Privacy is
applicable in the largely unstructured realm of NLP. This topic has sparked
novel research, which is unified in one basic goal: how can one adapt
Differential Privacy to NLP methods? This paper aims to summarize the
vulnerabilities addressed by Differential Privacy, the current thinking, and
above all, the crucial next steps that must be considered.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Efficient Detection and Filtering Systems for Distributed Training. (arXiv:2208.08085v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08085">http://arxiv.org/abs/2208.08085</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08085] Efficient Detection and Filtering Systems for Distributed Training](http://arxiv.org/abs/2208.08085)</code></li>
<li>Summary: <p>A plethora of modern machine learning tasks require the utilization of
large-scale distributed clusters as a critical component of the training
pipeline. However, abnormal Byzantine behavior of the worker nodes can derail
the training and compromise the quality of the inference. Such behavior can be
attributed to unintentional system malfunctions or orchestrated attacks; as a
result, some nodes may return arbitrary results to the parameter server (PS)
that coordinates the training. Recent work considers a wide range of attack
models and has explored robust aggregation and/or computational redundancy to
correct the distorted gradients. In this work, we consider attack models
ranging from strong ones: $q$ omniscient adversaries with full knowledge of the
defense protocol that can change from iteration to iteration to weak ones: $q$
randomly chosen adversaries with limited collusion abilities which only change
every few iterations at a time. Our algorithms rely on redundant task
assignments coupled with detection of adversarial behavior. For strong attacks,
we demonstrate a reduction in the fraction of distorted gradients ranging from
16\%-99\% as compared to the prior state-of-the-art. Our top-1 classification
accuracy results on the CIFAR-10 data set demonstrate 25\% advantage in
accuracy (averaged over strong and weak scenarios) under the most sophisticated
attacks compared to state-of-the-art methods.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Imperceptible and Robust Backdoor Attack in 3D Point Cloud. (arXiv:2208.08052v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08052">http://arxiv.org/abs/2208.08052</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08052] Imperceptible and Robust Backdoor Attack in 3D Point Cloud](http://arxiv.org/abs/2208.08052)</code></li>
<li>Summary: <p>With the thriving of deep learning in processing point cloud data, recent
works show that backdoor attacks pose a severe security threat to 3D vision
applications. The attacker injects the backdoor into the 3D model by poisoning
a few training samples with trigger, such that the backdoored model performs
well on clean samples but behaves maliciously when the trigger pattern appears.
Existing attacks often insert some additional points into the point cloud as
the trigger, or utilize a linear transformation (e.g., rotation) to construct
the poisoned point cloud. However, the effects of these poisoned samples are
likely to be weakened or even eliminated by some commonly used pre-processing
techniques for 3D point cloud, e.g., outlier removal or rotation augmentation.
In this paper, we propose a novel imperceptible and robust backdoor attack
(IRBA) to tackle this challenge. We utilize a nonlinear and local
transformation, called weighted local transformation (WLT), to construct
poisoned samples with unique transformations. As there are several
hyper-parameters and randomness in WLT, it is difficult to produce two similar
transformations. Consequently, poisoned samples with unique transformations are
likely to be resistant to aforementioned pre-processing techniques. Besides, as
the controllability and smoothness of the distortion caused by a fixed WLT, the
generated poisoned samples are also imperceptible to human inspection.
Extensive experiments on three benchmark datasets and four models show that
IRBA achieves 80%+ ASR in most cases even with pre-processing techniques, which
is significantly higher than previous state-of-the-art attacks.
</p></li>
</ul>

<h3>Title: Attackar: Attack of the Evolutionary Adversary. (arXiv:2208.08297v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08297">http://arxiv.org/abs/2208.08297</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08297] Attackar: Attack of the Evolutionary Adversary](http://arxiv.org/abs/2208.08297)</code></li>
<li>Summary: <p>Deep neural networks (DNNs) are sensitive to adversarial data in a variety of
scenarios, including the black-box scenario, where the attacker is only allowed
to query the trained model and receive an output. Existing black-box methods
for creating adversarial instances are costly, often using gradient estimation
or training a replacement network. This paper introduces \textit{Attackar}, an
evolutionary, score-based, black-box attack. Attackar is based on a novel
objective function that can be used in gradient-free optimization problems. The
attack only requires access to the output logits of the classifier and is thus
not affected by gradient masking. No additional information is needed,
rendering our method more suitable to real-life situations. We test its
performance with three different state-of-the-art models -- Inception-v3,
ResNet-50, and VGG-16-BN -- against three benchmark datasets: MNIST, CIFAR10
and ImageNet. Furthermore, we evaluate Attackar's performance on
non-differential transformation defenses and state-of-the-art robust models.
Our results demonstrate the superior performance of Attackar, both in terms of
accuracy score and query efficiency.
</p></li>
</ul>

<h3>Title: A Context-Aware Approach for Textual Adversarial Attack through Probability Difference Guided Beam Search. (arXiv:2208.08029v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08029">http://arxiv.org/abs/2208.08029</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08029] A Context-Aware Approach for Textual Adversarial Attack through Probability Difference Guided Beam Search](http://arxiv.org/abs/2208.08029)</code></li>
<li>Summary: <p>Textual adversarial attacks expose the vulnerabilities of text classifiers
and can be used to improve their robustness. Existing context-aware methods
solely consider the gold label probability and use the greedy search when
searching an attack path, often limiting the attack efficiency. To tackle these
issues, we propose PDBS, a context-aware textual adversarial attack model using
Probability Difference guided Beam Search. The probability difference is an
overall consideration of all class label probabilities, and PDBS uses it to
guide the selection of attack paths. In addition, PDBS uses the beam search to
find a successful attack path, thus avoiding suffering from limited search
space. Extensive experiments and human evaluation demonstrate that PDBS
outperforms previous best models in a series of evaluation metrics, especially
bringing up to a +19.5% attack success rate. Ablation studies and qualitative
analyses further confirm the efficiency of PDBS.
</p></li>
</ul>

<h3>Title: AutoCAT: Reinforcement Learning for Automated Exploration of Cache Timing-Channel Attacks. (arXiv:2208.08025v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08025">http://arxiv.org/abs/2208.08025</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08025] AutoCAT: Reinforcement Learning for Automated Exploration of Cache Timing-Channel Attacks](http://arxiv.org/abs/2208.08025)</code></li>
<li>Summary: <p>The aggressive performance optimizations in modern microprocessors can result
in security vulnerabilities. For example, the timing-based attacks in processor
caches are shown to be successful in stealing secret keys or causing privilege
escalation. So far, finding cache-timing vulnerabilities is mostly performed by
human experts, which is inefficient and laborious. There is a need for
automatic tools that can explore vulnerabilities because unreported
vulnerabilities leave the systems at risk. In this paper, we propose AutoCAT,
an automated exploration framework that finds cache timing-channel attacks
using reinforcement learning (RL). Specifically, AutoCAT formulates the cache
timing-channel attack as a guessing game between the attacker program and the
victim program holding a secret, which can thus be solved via modern deep RL
techniques. AutoCAT can explore attacks in various cache configurations without
knowing design details and under different attacker and victim configurations,
and also find attacks to bypass known detection and defense mechanisms. In
particular, AutoCAT discovered StealthyStreamline, a new attack that is able to
bypass detection based on performance counters and has up to a 71% higher
information leakage rate than the state-of-the-art LRU-based attacks on real
processors. AutoCAT is the first of its kind using RL for crafting
microarchitectural timing-channel attack sequences and can accelerate cache
timing-channel exploration for secure microprocessor designs.
</p></li>
</ul>

<h3>Title: An Efficient Multi-Step Framework for Malware Packing Identification. (arXiv:2208.08071v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08071">http://arxiv.org/abs/2208.08071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08071] An Efficient Multi-Step Framework for Malware Packing Identification](http://arxiv.org/abs/2208.08071)</code></li>
<li>Summary: <p>Malware developers use combinations of techniques such as compression,
encryption, and obfuscation to bypass anti-virus software. Malware with
anti-analysis technologies can bypass AI-based anti-virus software and malware
analysis tools. Therefore, classifying pack files is one of the big challenges.
Problems arise if the malware classifiers learn packers' features, not those of
malware. Training the models with unintended erroneous data turn into poisoning
attacks, adversarial attacks, and evasion attacks. Therefore, researchers
should consider packing to build appropriate malware classifier models. In this
paper, we propose a multi-step framework for classifying and identifying packed
samples which consists of pseudo-optimal feature selection, machine
learning-based classifiers, and packer identification steps. In the first step,
we use the CART algorithm and the permutation importance to preselect important
20 features. In the second step, each model learns 20 preselected features for
classifying the packed files with the highest performance. As a result, the
XGBoost, which learned the features preselected by XGBoost with the permutation
importance, showed the highest performance of any other experiment scenarios
with an accuracy of 99.67%, an F1-Score of 99.46%, and an area under the curve
(AUC) of 99.98%. In the third step, we propose a new approach that can identify
packers only for samples classified as Well-Known Packed.
</p></li>
</ul>

<h3>Title: An Empirical Study on the Membership Inference Attack against Tabular Data Synthesis Models. (arXiv:2208.08114v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08114">http://arxiv.org/abs/2208.08114</a></li>
<li>Code URL: <a href="https://github.com/jayoungkim408/mia">https://github.com/jayoungkim408/mia</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08114] An Empirical Study on the Membership Inference Attack against Tabular Data Synthesis Models](http://arxiv.org/abs/2208.08114)</code></li>
<li>Summary: <p>Tabular data typically contains private and important information; thus,
precautions must be taken before they are shared with others. Although several
methods (e.g., differential privacy and k-anonymity) have been proposed to
prevent information leakage, in recent years, tabular data synthesis models
have become popular because they can well trade-off between data utility and
privacy. However, recent research has shown that generative models for image
data are susceptible to the membership inference attack, which can determine
whether a given record was used to train a victim synthesis model. In this
paper, we investigate the membership inference attack in the context of tabular
data synthesis. We conduct experiments on 4 state-of-the-art tabular data
synthesis models under two attack scenarios (i.e., one black-box and one
white-box attack), and find that the membership inference attack can seriously
jeopardize these models. We next conduct experiments to evaluate how well two
popular differentially-private deep learning training algorithms, DP-SGD and
DP-GAN, can protect the models against the attack. Our key finding is that both
algorithms can largely alleviate this threat by sacrificing the generation
quality. Code and data available at: https://github.com/JayoungKim408/MIA
</p></li>
</ul>

<h3>Title: Label Flipping Data Poisoning Attack Against Wearable Human Activity Recognition System. (arXiv:2208.08433v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08433">http://arxiv.org/abs/2208.08433</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08433] Label Flipping Data Poisoning Attack Against Wearable Human Activity Recognition System](http://arxiv.org/abs/2208.08433)</code></li>
<li>Summary: <p>Human Activity Recognition (HAR) is a problem of interpreting sensor data to
human movement using an efficient machine learning (ML) approach. The HAR
systems rely on data from untrusted users, making them susceptible to data
poisoning attacks. In a poisoning attack, attackers manipulate the sensor
readings to contaminate the training set, misleading the HAR to produce
erroneous outcomes. This paper presents the design of a label flipping data
poisoning attack for a HAR system, where the label of a sensor reading is
maliciously changed in the data collection phase. Due to high noise and
uncertainty in the sensing environment, such an attack poses a severe threat to
the recognition system. Besides, vulnerability to label flipping attacks is
dangerous when activity recognition models are deployed in safety-critical
applications. This paper shades light on how to carry out the attack in
practice through smartphone-based sensor data collection applications. This is
an earlier research work, to our knowledge, that explores attacking the HAR
models via label flipping poisoning. We implement the proposed attack and test
it on activity recognition models based on the following machine learning
algorithms: multi-layer perceptron, decision tree, random forest, and XGBoost.
Finally, we evaluate the effectiveness of K-nearest neighbors (KNN)-based
defense mechanism against the proposed attack.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Deep Learning Enabled Time-Lapse 3D Cell Analysis. (arXiv:2208.07997v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07997">http://arxiv.org/abs/2208.07997</a></li>
<li>Code URL: <a href="https://github.com/ucsb-vrl/time-lapse3dcellanalysis">https://github.com/ucsb-vrl/time-lapse3dcellanalysis</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07997] Deep Learning Enabled Time-Lapse 3D Cell Analysis](http://arxiv.org/abs/2208.07997)</code></li>
<li>Summary: <p>This paper presents a method for time-lapse 3D cell analysis. Specifically,
we consider the problem of accurately localizing and quantitatively analyzing
sub-cellular features, and for tracking individual cells from time-lapse 3D
confocal cell image stacks. The heterogeneity of cells and the volume of
multi-dimensional images presents a major challenge for fully automated
analysis of morphogenesis and development of cells. This paper is motivated by
the pavement cell growth process, and building a quantitative morphogenesis
model. We propose a deep feature based segmentation method to accurately detect
and label each cell region. An adjacency graph based method is used to extract
sub-cellular features of the segmented cells. Finally, the robust graph based
tracking algorithm using multiple cell features is proposed for associating
cells at different time instances. Extensive experiment results are provided
and demonstrate the robustness of the proposed method. The code is available on
Github and the method is available as a service through the BisQue portal.
</p></li>
</ul>

<h3>Title: InterTrack: Interaction Transformer for 3D Multi-Object Tracking. (arXiv:2208.08041v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08041">http://arxiv.org/abs/2208.08041</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08041] InterTrack: Interaction Transformer for 3D Multi-Object Tracking](http://arxiv.org/abs/2208.08041)</code></li>
<li>Summary: <p>3D multi-object tracking (MOT) is a key problem for autonomous vehicles,
required to perform well-informed motion planning in dynamic environments.
Particularly for densely occupied scenes, associating existing tracks to new
detections remains challenging as existing systems tend to omit critical
contextual information. Our proposed solution, InterTrack, introduces the
Interaction Transformer for 3D MOT to generate discriminative object
representations for data association. We extract state and shape features for
each track and detection, and efficiently aggregate global information via
attention. We then perform a learned regression on each track/detection feature
pair to estimate affinities, and use a robust two-stage data association and
track management approach to produce the final tracks. We validate our approach
on the nuScenes 3D MOT benchmark, where we observe significant improvements,
particularly on classes with small physical sizes and clustered objects. As of
submission, InterTrack ranks 1st in overall AMOTA among methods using
CenterPoint detections.
</p></li>
</ul>

<h3>Title: Urban feature analysis from aerial remote sensing imagery using self-supervised and semi-supervised computer vision. (arXiv:2208.08047v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08047">http://arxiv.org/abs/2208.08047</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08047] Urban feature analysis from aerial remote sensing imagery using self-supervised and semi-supervised computer vision](http://arxiv.org/abs/2208.08047)</code></li>
<li>Summary: <p>Analysis of overhead imagery using computer vision is a problem that has
received considerable attention in academic literature. Most techniques that
operate in this space are both highly specialised and require expensive manual
annotation of large datasets. These problems are addressed here through the
development of a more generic framework, incorporating advances in
representation learning which allows for more flexibility in analysing new
categories of imagery with limited labeled data. First, a robust representation
of an unlabeled aerial imagery dataset was created based on the momentum
contrast mechanism. This was subsequently specialised for different tasks by
building accurate classifiers with as few as 200 labeled images. The successful
low-level detection of urban infrastructure evolution over a 10-year period
from 60 million unlabeled images, exemplifies the substantial potential of our
approach to advance quantitative urban research.
</p></li>
</ul>

<h3>Title: PDRF: Progressively Deblurring Radiance Field for Fast and Robust Scene Reconstruction from Blurry Images. (arXiv:2208.08049v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08049">http://arxiv.org/abs/2208.08049</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08049] PDRF: Progressively Deblurring Radiance Field for Fast and Robust Scene Reconstruction from Blurry Images](http://arxiv.org/abs/2208.08049)</code></li>
<li>Summary: <p>We present Progressively Deblurring Radiance Field (PDRF), a novel approach
to efficiently reconstruct high quality radiance fields from blurry images.
While current State-of-The-Art (SoTA) scene reconstruction methods achieve
photo-realistic rendering results from clean source views, their performances
suffer when the source views are affected by blur, which is commonly observed
for images in the wild. Previous deblurring methods either do not account for
3D geometry, or are computationally intense. To addresses these issues, PDRF, a
progressively deblurring scheme in radiance field modeling, accurately models
blur by incorporating 3D scene context. PDRF further uses an efficient
importance sampling scheme, which results in fast scene optimization.
Specifically, PDRF proposes a Coarse Ray Renderer to quickly estimate voxel
density and feature; a Fine Voxel Renderer is then used to achieve high quality
ray tracing. We perform extensive experiments and show that PDRF is 15X faster
than previous SoTA while achieving better performance on both synthetic and
real scenes.
</p></li>
</ul>

<h3>Title: Significance of Skeleton-based Features in Virtual Try-On. (arXiv:2208.08076v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08076">http://arxiv.org/abs/2208.08076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08076] Significance of Skeleton-based Features in Virtual Try-On](http://arxiv.org/abs/2208.08076)</code></li>
<li>Summary: <p>The idea of \textit{Virtual Try-ON} (VTON) benefits e-retailing by giving an
user the convenience of trying a clothing at the comfort of their home. In
general, most of the existing VTON methods produce inconsistent results when a
person posing with his arms folded i.e., bent or crossed, wants to try an
outfit. The problem becomes severe in the case of long-sleeved outfits. As
then, for crossed arm postures, overlap among different clothing parts might
happen. The existing approaches, especially the warping-based methods employing
\textit{Thin Plate Spline (TPS)} transform can not tackle such cases. To this
end, we attempt a solution approach where the clothing from the source person
is segmented into semantically meaningful parts and each part is warped
independently to the shape of the person. To address the bending issue, we
employ hand-crafted geometric features consistent with human body geometry for
warping the source outfit. In addition, we propose two learning-based modules:
a synthesizer network and a mask prediction network. All these together attempt
to produce a photo-realistic, pose-robust VTON solution without requiring any
paired training data. Comparison with some of the benchmark methods clearly
establishes the effectiveness of the approach.
</p></li>
</ul>

<h3>Title: Two Heads are Better than One: Robust Learning Meets Multi-branch Models. (arXiv:2208.08083v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08083">http://arxiv.org/abs/2208.08083</a></li>
<li>Code URL: <a href="https://github.com/huangd1999/bort">https://github.com/huangd1999/bort</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08083] Two Heads are Better than One: Robust Learning Meets Multi-branch Models](http://arxiv.org/abs/2208.08083)</code></li>
<li>Summary: <p>Deep neural networks (DNNs) are vulnerable to adversarial examples, in which
DNNs are misled to false outputs due to inputs containing imperceptible
perturbations. Adversarial training, a reliable and effective method of
defense, may significantly reduce the vulnerability of neural networks and
becomes the de facto standard for robust learning. While many recent works
practice the data-centric philosophy, such as how to generate better
adversarial examples or use generative models to produce additional training
data, we look back to the models themselves and revisit the adversarial
robustness from the perspective of deep feature distribution as an insightful
complementarity. In this paper, we propose Branch Orthogonality adveRsarial
Training (BORT) to obtain state-of-the-art performance with solely the original
dataset for adversarial training. To practice our design idea of integrating
multiple orthogonal solution spaces, we leverage a simple and straightforward
multi-branch neural network that eclipses adversarial attacks with no increase
in inference time. We heuristically propose a corresponding loss function,
branch-orthogonal loss, to make each solution space of the multi-branch model
orthogonal. We evaluate our approach on CIFAR-10, CIFAR-100, and SVHN against
\ell_{\infty} norm-bounded perturbations of size \epsilon = 8/255,
respectively. Exhaustive experiments are conducted to show that our method goes
beyond all state-of-the-art methods without any tricks. Compared to all methods
that do not use additional data for training, our models achieve 67.3% and
41.5% robust accuracy on CIFAR-10 and CIFAR-100 (improving upon the
state-of-the-art by +7.23% and +9.07%). We also outperform methods using a
training set with a far larger scale than ours. All our models and codes are
available online at https://github.com/huangd1999/BORT.
</p></li>
</ul>

<h3>Title: Road detection via a dual-task network based on cross-layer graph fusion modules. (arXiv:2208.08116v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08116">http://arxiv.org/abs/2208.08116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08116] Road detection via a dual-task network based on cross-layer graph fusion modules](http://arxiv.org/abs/2208.08116)</code></li>
<li>Summary: <p>Road detection based on remote sensing images is of great significance to
intelligent traffic management. The performances of the mainstream road
detection methods are mainly determined by their extracted features, whose
richness and robustness can be enhanced by fusing features of different types
and cross-layer connections. However, the features in the existing mainstream
model frameworks are often similar in the same layer by the single-task
training, and the traditional cross-layer fusion ways are too simple to obtain
an efficient effect, so more complex fusion ways besides concatenation and
addition deserve to be explored. Aiming at the above defects, we propose a
dual-task network (DTnet) for road detection and cross-layer graph fusion
module (CGM): the DTnet consists of two parallel branches for road area and
edge detection, respectively, while enhancing the feature diversity by fusing
features between two branches through our designed feature bridge modules
(FBM). The CGM improves the cross-layer fusion effect by a complex feature
stream graph, and four graph patterns are evaluated. Experimental results on
three public datasets demonstrate that our method effectively improves the
final detection result.
</p></li>
</ul>

<h3>Title: Multi-View Correlation Consistency for Semi-Supervised Semantic Segmentation. (arXiv:2208.08437v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08437">http://arxiv.org/abs/2208.08437</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08437] Multi-View Correlation Consistency for Semi-Supervised Semantic Segmentation](http://arxiv.org/abs/2208.08437)</code></li>
<li>Summary: <p>Semi-supervised semantic segmentation needs rich and robust supervision on
unlabeled data. Consistency learning enforces the same pixel to have similar
features in different augmented views, which is a robust signal but neglects
relationships with other pixels. In comparison, contrastive learning considers
rich pairwise relationships, but it can be a conundrum to assign binary
positive-negative supervision signals for pixel pairs. In this paper, we take
the best of both worlds and propose multi-view correlation consistency (MVCC)
learning: it considers rich pairwise relationships in self-correlation matrices
and matches them across views to provide robust supervision. Together with this
correlation consistency loss, we propose a view-coherent data augmentation
strategy that guarantees pixel-pixel correspondence between different views. In
a series of semi-supervised settings on two datasets, we report competitive
accuracy compared with the state-of-the-art methods. Notably, on Cityscapes, we
achieve 76.8% mIoU with 1/8 labeled data, just 0.6% shy from the fully
supervised oracle.
</p></li>
</ul>

<h3>Title: Ask Question First for Enhancing Lifelong Language Learning. (arXiv:2208.08367v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08367">http://arxiv.org/abs/2208.08367</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08367] Ask Question First for Enhancing Lifelong Language Learning](http://arxiv.org/abs/2208.08367)</code></li>
<li>Summary: <p>Lifelong language learning aims to stream learning NLP tasks while retaining
knowledge of previous tasks. Previous works based on the language model and
following data-free constraint approaches have explored formatting all data as
"begin token (\textit{B}) + context (\textit{C}) + question (\textit{Q}) +
answer (\textit{A})" for different tasks. However, they still suffer from
catastrophic forgetting and are exacerbated when the previous task's pseudo
data is insufficient for the following reasons: (1) The model has difficulty
generating task-corresponding pseudo data, and (2) \textit{A} is prone to error
when \textit{A} and \textit{C} are separated by \textit{Q} because the
information of the \textit{C} is diminished before generating \textit{A}.
Therefore, we propose the Ask Question First and Replay Question (AQF-RQ),
including a novel data format "\textit{BQCA}" and a new training task to train
pseudo questions of previous tasks. Experimental results demonstrate that
AQF-RQ makes it easier for the model to generate more pseudo data that match
corresponding tasks, and is more robust to both sufficient and insufficient
pseudo-data when the task boundary is both clear and unclear. AQF-RQ can
achieve only 0.36\% lower performance than multi-task learning.
</p></li>
</ul>

<h3>Title: FedPerm: Private and Robust Federated Learning by Parameter Permutation. (arXiv:2208.07922v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07922">http://arxiv.org/abs/2208.07922</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07922] FedPerm: Private and Robust Federated Learning by Parameter Permutation](http://arxiv.org/abs/2208.07922)</code></li>
<li>Summary: <p>Federated Learning (FL) is a distributed learning paradigm that enables
mutually untrusting clients to collaboratively train a common machine learning
model. Client data privacy is paramount in FL. At the same time, the model must
be protected from poisoning attacks from adversarial clients. Existing
solutions address these two problems in isolation. We present FedPerm, a new FL
algorithm that addresses both these problems by combining a novel intra-model
parameter shuffling technique that amplifies data privacy, with Private
Information Retrieval (PIR) based techniques that permit cryptographic
aggregation of clients' model updates. The combination of these techniques
further helps the federation server constrain parameter updates from clients so
as to curtail effects of model poisoning attacks by adversarial clients. We
further present FedPerm's unique hyperparameters that can be used effectively
to trade off computation overheads with model utility. Our empirical evaluation
on the MNIST dataset demonstrates FedPerm's effectiveness over existing
Differential Privacy (DP) enforcement solutions in FL.
</p></li>
</ul>

<h3>Title: Towards Generating Robust, Fair, and Emotion-Aware Explanations for Recommender Systems. (arXiv:2208.08017v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08017">http://arxiv.org/abs/2208.08017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08017] Towards Generating Robust, Fair, and Emotion-Aware Explanations for Recommender Systems](http://arxiv.org/abs/2208.08017)</code></li>
<li>Summary: <p>As recommender systems become increasingly sophisticated and complex, they
often suffer from lack of fairness and transparency. Providing robust and
unbiased explanations for recommendations has been drawing more and more
attention as it can help address these issues and improve trustworthiness and
informativeness of recommender systems. However, despite the fact that such
explanations are generated for humans who respond more strongly to messages
with appropriate emotions, there is a lack of consideration for emotions when
generating explanations for recommendations. Current explanation generation
models are found to exaggerate certain emotions without accurately capturing
the underlying tone or the meaning. In this paper, we propose a novel method
based on a multi-head transformer, called Emotion-aware Transformer for
Explainable Recommendation (EmoTER), to generate more robust, fair, and
emotion-enhanced explanations. To measure the linguistic quality and emotion
fairness of the generated explanations, we adopt both automatic text metrics
and human perceptions for evaluation. Experiments on three widely-used
benchmark datasets with multiple evaluation metrics demonstrate that EmoTER
consistently outperforms the existing state-of-the-art explanation generation
models in terms of text quality, explainability, and consideration for fairness
to emotion distribution. Implementation of EmoTER will be released as an
open-source toolkit to support further research.
</p></li>
</ul>

<h3>Title: On Establishing Robust Consistency in Answer Set Programs. (arXiv:2208.08157v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08157">http://arxiv.org/abs/2208.08157</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08157] On Establishing Robust Consistency in Answer Set Programs](http://arxiv.org/abs/2208.08157)</code></li>
<li>Summary: <p>Answer set programs used in real-world applications often require that the
program is usable with different input data. This, however, can often lead to
contradictory statements and consequently to an inconsistent program. Causes
for potential contradictions in a program are conflicting rules. In this paper,
we show how to ensure that a program $\mathcal{P}$ remains non-contradictory
given any allowed set of such input data. For that, we introduce the notion of
conflict-resolving $\lambda$- extensions. A conflict-resolving
$\lambda$-extension for a conflicting rule $r$ is a set $\lambda$ of (default)
literals such that extending the body of $r$ by $\lambda$ resolves all
conflicts of $r$ at once. We investigate the properties that suitable
$\lambda$-extensions should possess and building on that, we develop a strategy
to compute all such conflict-resolving $\lambda$-extensions for each
conflicting rule in $\mathcal{P}$. We show that by implementing a conflict
resolution process that successively resolves conflicts using
$\lambda$-extensions eventually yields a program that remains non-contradictory
given any allowed set of input data.
</p></li>
</ul>

<h3>Title: Superior generalization of smaller models in the presence of significant label noise. (arXiv:2208.08003v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08003">http://arxiv.org/abs/2208.08003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08003] Superior generalization of smaller models in the presence of significant label noise](http://arxiv.org/abs/2208.08003)</code></li>
<li>Summary: <p>The benefits of over-parameterization in achieving superior generalization
performance have been shown in several recent studies, justifying the trend of
using larger models in practice. In the context of robust learning however, the
effect of neural network size has not been well studied. In this work, we find
that in the presence of a substantial fraction of mislabeled examples,
increasing the network size beyond some point can be harmful. In particular,
the originally monotonic or `double descent' test loss curve (w.r.t. network
width) turns into a U-shaped or a double U-shaped curve when label noise
increases, suggesting that the best generalization is achieved by some model
with intermediate size. We observe that when network size is controlled by
density through random pruning, similar test loss behaviour is observed. We
also take a closer look into both phenomenon through bias-variance
decomposition and theoretically characterize how label noise shapes the
variance term. Similar behavior of the test loss can be observed even when
state-of-the-art robust methods are applied, indicating that limiting the
network size could further boost existing methods. Finally, we empirically
examine the effect of network size on the smoothness of learned functions, and
find that the originally negative correlation between size and smoothness is
flipped by label noise.
</p></li>
</ul>

<h3>Title: Gradient-Based Meta-Learning Using Uncertainty to Weigh Loss for Few-Shot Learning. (arXiv:2208.08135v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08135">http://arxiv.org/abs/2208.08135</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08135] Gradient-Based Meta-Learning Using Uncertainty to Weigh Loss for Few-Shot Learning](http://arxiv.org/abs/2208.08135)</code></li>
<li>Summary: <p>Model-Agnostic Meta-Learning (MAML) is one of the most successful
meta-learning techniques for few-shot learning. It uses gradient descent to
learn commonalities between various tasks, enabling the model to learn the
meta-initialization of its own parameters to quickly adapt to new tasks using a
small amount of labeled training data. A key challenge to few-shot learning is
task uncertainty. Although a strong prior can be obtained from meta-learning
with a large number of tasks, a precision model of the new task cannot be
guaranteed because the volume of the training dataset is normally too small. In
this study, first,in the process of choosing initialization parameters, the new
method is proposed for task-specific learner adaptively learn to select
initialization parameters that minimize the loss of new tasks. Then, we propose
two improved methods for the meta-loss part: Method 1 generates weights by
comparing meta-loss differences to improve the accuracy when there are few
classes, and Method 2 introduces the homoscedastic uncertainty of each task to
weigh multiple losses based on the original gradient descent,as a way to
enhance the generalization ability to novel classes while ensuring accuracy
improvement. Compared with previous gradient-based meta-learning methods, our
model achieves better performance in regression tasks and few-shot
classification and improves the robustness of the model to the learning rate
and query sets in the meta-test set.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h3>Title: BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency. (arXiv:2208.08320v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08320">http://arxiv.org/abs/2208.08320</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08320] BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency](http://arxiv.org/abs/2208.08320)</code></li>
<li>Summary: <p>Twitter bot detection is an important and meaningful task. Existing
text-based methods can deeply analyze user tweet content, achieving high
performance. However, novel Twitter bots evade these detections by stealing
genuine users' tweets and diluting malicious content with benign tweets. These
novel bots are proposed to be characterized by semantic inconsistency. In
addition, methods leveraging Twitter graph structure are recently emerging,
showing great competitiveness. However, hardly a method has made text and graph
modality deeply fused and interacted to leverage both advantages and learn the
relative importance of the two modalities. In this paper, we propose a novel
model named BIC that makes the text and graph modalities deeply interactive and
detects tweet semantic inconsistency. Specifically, BIC contains a text
propagation module, a graph propagation module to conduct bot detection
respectively on text and graph structure, and a proven effective text-graph
interactive module to make the two interact. Besides, BIC contains a semantic
consistency detection module to learn semantic consistency information from
tweets. Extensive experiments demonstrate that our framework outperforms
competitive baselines on a comprehensive Twitter bot benchmark. We also prove
the effectiveness of the proposed interaction and semantic consistency
detection.
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human Activity Recognition in Videos. (arXiv:2208.07929v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07929">http://arxiv.org/abs/2208.07929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07929] ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human Activity Recognition in Videos](http://arxiv.org/abs/2208.07929)</code></li>
<li>Summary: <p>Human activity recognition is an emerging and important area in computer
vision which seeks to determine the activity an individual or group of
individuals are performing. The applications of this field ranges from
generating highlight videos in sports, to intelligent surveillance and gesture
recognition. Most activity recognition systems rely on a combination of
convolutional neural networks (CNNs) to perform feature extraction from the
data and recurrent neural networks (RNNs) to determine the time dependent
nature of the data. This paper proposes and designs two transformer neural
networks for human activity recognition: a recurrent transformer (ReT), a
specialized neural network used to make predictions on sequences of data, as
well as a vision transformer (ViT), a transformer optimized for extracting
salient features from images, to improve speed and scalability of activity
recognition. We have provided an extensive comparison of the proposed
transformer neural networks with the contemporary CNN and RNN-based human
activity recognition models in terms of speed and accuracy.
</p></li>
</ul>

<h3>Title: Boosting Modern and Historical Handwritten Text Recognition with Deformable Convolutions. (arXiv:2208.08109v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08109">http://arxiv.org/abs/2208.08109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08109] Boosting Modern and Historical Handwritten Text Recognition with Deformable Convolutions](http://arxiv.org/abs/2208.08109)</code></li>
<li>Summary: <p>Handwritten Text Recognition (HTR) in free-layout pages is a challenging
image understanding task that can provide a relevant boost to the digitization
of handwritten documents and reuse of their content. The task becomes even more
challenging when dealing with historical documents due to the variability of
the writing style and degradation of the page quality. State-of-the-art HTR
approaches typically couple recurrent structures for sequence modeling with
Convolutional Neural Networks for visual feature extraction. Since
convolutional kernels are defined on fixed grids and focus on all input pixels
independently while moving over the input image, this strategy disregards the
fact that handwritten characters can vary in shape, scale, and orientation even
within the same document and that the ink pixels are more relevant than the
background ones. To cope with these specific HTR difficulties, we propose to
adopt deformable convolutions, which can deform depending on the input at hand
and better adapt to the geometric variations of the text. We design two
deformable architectures and conduct extensive experiments on both modern and
historical datasets. Experimental results confirm the suitability of deformable
convolutions for the HTR task.
</p></li>
</ul>

<h3>Title: DICE: Data-Efficient Clinical Event Extraction with Generative Models. (arXiv:2208.07989v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07989">http://arxiv.org/abs/2208.07989</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07989] DICE: Data-Efficient Clinical Event Extraction with Generative Models](http://arxiv.org/abs/2208.07989)</code></li>
<li>Summary: <p>Event extraction in the clinical domain is an under-explored research area.
The lack of training data in addition to the high volume of domain-specific
jargon that includes long entities with vague boundaries make the task
especially challenging. In this paper, we introduce DICE, a robust and
data-efficient generative model for clinical event extraction. DICE frames
event extraction as a conditional generation problem and utilizes descriptions
provided by domain experts to boost the performance under low-resource
settings. Furthermore, DICE learns to locate and bound biomedical mentions with
an auxiliary mention identification task trained jointly with event extraction
tasks to leverage inter-task dependencies and further incorporates the
identified mentions as trigger and argument candidates for their respective
tasks. We also introduce MACCROBAT-EE, the first clinical event extraction
dataset with event argument annotation. Our experiments demonstrate the
robustness of DICE under low data settings for the clinical domain and the
benefits of incorporating flexible joint training and mention markers into
generative approaches.
</p></li>
</ul>

<h3>Title: A Sequence Tagging based Framework for Few-Shot Relation Extraction. (arXiv:2208.08053v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08053">http://arxiv.org/abs/2208.08053</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08053] A Sequence Tagging based Framework for Few-Shot Relation Extraction](http://arxiv.org/abs/2208.08053)</code></li>
<li>Summary: <p>Relation Extraction (RE) refers to extracting the relation triples in the
input text. Existing neural work based systems for RE rely heavily on manually
labeled training data, but there are still a lot of domains where sufficient
labeled data does not exist. Inspired by the distance-based few-shot named
entity recognition methods, we put forward the definition of the few-shot RE
task based on the sequence tagging joint extraction approaches, and propose a
few-shot RE framework for the task. Besides, we apply two actual sequence
tagging models to our framework (called Few-shot TPLinker and Few-shot BiTT),
and achieves solid results on two few-shot RE tasks constructed from a public
dataset.
</p></li>
</ul>

<h3>Title: NECE: Narrative Event Chain Extraction Toolkit. (arXiv:2208.08063v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08063">http://arxiv.org/abs/2208.08063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08063] NECE: Narrative Event Chain Extraction Toolkit](http://arxiv.org/abs/2208.08063)</code></li>
<li>Summary: <p>NECE is an event-based text analysis toolkit built for narrative documents.
NECE aims to provide users open and easy accesses to an event-based summary and
abstraction of long narrative documents through both a graphic interface and a
python package, which can be readily used in narrative analysis, understanding,
or other advanced purposes. Our work addresses the challenge of long passage
events extraction and temporal ordering of key events; at the same time, it
offers options to select and view events related to narrative entities, such as
main characters and gender groups. We conduct human evaluation to demonstrate
the quality of the event chain extraction system and character features mining
algorithms. Lastly, we shed light on the toolkit's potential downstream
applications by demonstrating its usage in gender bias analysis and
Question-Answering tasks.
</p></li>
</ul>

<h3>Title: Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction. (arXiv:2208.08280v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08280">http://arxiv.org/abs/2208.08280</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08280] Exploiting Unlabeled Data for Target-Oriented Opinion Words Extraction](http://arxiv.org/abs/2208.08280)</code></li>
<li>Summary: <p>Target-oriented Opinion Words Extraction (TOWE) is a fine-grained sentiment
analysis task that aims to extract the corresponding opinion words of a given
opinion target from the sentence. Recently, deep learning approaches have made
remarkable progress on this task. Nevertheless, the TOWE task still suffers
from the scarcity of training data due to the expensive data annotation
process. Limited labeled data increase the risk of distribution shift between
test data and training data. In this paper, we propose exploiting massive
unlabeled data to reduce the risk by increasing the exposure of the model to
varying distribution shifts. Specifically, we propose a novel Multi-Grained
Consistency Regularization (MGCR) method to make use of unlabeled data and
design two filters specifically for TOWE to filter noisy data at different
granularity. Extensive experimental results on four TOWE benchmark datasets
indicate the superiority of MGCR compared with current state-of-the-art
methods. The in-depth analysis also demonstrates the effectiveness of the
different-granularity filters. Our codes are available at
https://github.com/TOWESSL/TOWESSL.
</p></li>
</ul>

<h3>Title: Extracting Medication Changes in Clinical Narratives using Pre-trained Language Models. (arXiv:2208.08417v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08417">http://arxiv.org/abs/2208.08417</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08417] Extracting Medication Changes in Clinical Narratives using Pre-trained Language Models](http://arxiv.org/abs/2208.08417)</code></li>
<li>Summary: <p>An accurate and detailed account of patient medications, including medication
changes within the patient timeline, is essential for healthcare providers to
provide appropriate patient care. Healthcare providers or the patients
themselves may initiate changes to patient medication. Medication changes take
many forms, including prescribed medication and associated dosage modification.
These changes provide information about the overall health of the patient and
the rationale that led to the current care. Future care can then build on the
resulting state of the patient. This work explores the automatic extraction of
medication change information from free-text clinical notes. The Contextual
Medication Event Dataset (CMED) is a corpus of clinical notes with annotations
that characterize medication changes through multiple change-related
attributes, including the type of change (start, stop, increase, etc.),
initiator of the change, temporality, change likelihood, and negation. Using
CMED, we identify medication mentions in clinical text and propose three novel
high-performing BERT-based systems that resolve the annotated medication change
characteristics. We demonstrate that our proposed architectures improve
medication change classification performance over the initial work exploring
CMED. We identify medication mentions with high performance at 0.959 F1, and
our proposed systems classify medication changes and their attributes at an
overall average of 0.827 F1.
</p></li>
</ul>

<h3>Title: Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions. (arXiv:2208.07934v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07934">http://arxiv.org/abs/2208.07934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07934] Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions](http://arxiv.org/abs/2208.07934)</code></li>
<li>Summary: <p>In this paper, we focus on the problem of statistical dependence estimation
using characteristic functions. We propose a statistical dependence measure,
based on the maximum-norm of the difference between joint and product-marginal
characteristic functions. The proposed measure can detect arbitrary statistical
dependence between two random vectors of possibly different dimensions, is
differentiable, and easily integrable into modern machine learning and deep
learning pipelines. We also conduct experiments both with simulated and real
data. Our simulations show, that the proposed method can measure statistical
dependencies in high-dimensional, non-linear data, and is less affected by the
curse of dimensionality, compared to the previous work in this line of
research. The experiments with real data demonstrate the potential
applicability of our statistical measure for two different empirical inference
scenarios, showing statistically significant improvement in the performance
characteristics when applied for supervised feature extraction and deep neural
network regularization. In addition, we provide a link to the accompanying
open-source repository https://bit.ly/3d4ch5I.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h2>fair</h2>
<h3>Title: Open Long-Tailed Recognition in a Dynamic World. (arXiv:2208.08349v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08349">http://arxiv.org/abs/2208.08349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08349] Open Long-Tailed Recognition in a Dynamic World](http://arxiv.org/abs/2208.08349)</code></li>
<li>Summary: <p>Real world data often exhibits a long-tailed and open-ended (with unseen
classes) distribution. A practical recognition system must balance between
majority (head) and minority (tail) classes, generalize across the
distribution, and acknowledge novelty upon the instances of unseen classes
(open classes). We define Open Long-Tailed Recognition++ (OLTR++) as learning
from such naturally distributed data and optimizing for the classification
accuracy over a balanced test set which includes both known and open classes.
OLTR++ handles imbalanced classification, few-shot learning, open-set
recognition, and active learning in one integrated algorithm, whereas existing
classification approaches often focus only on one or two aspects and deliver
poorly over the entire spectrum. The key challenges are: 1) how to share visual
knowledge between head and tail classes, 2) how to reduce confusion between
tail and open classes, and 3) how to actively explore open classes with learned
knowledge. Our algorithm, OLTR++, maps images to a feature space such that
visual concepts can relate to each other through a memory association mechanism
and a learned metric (dynamic meta-embedding) that both respects the closed
world classification of seen classes and acknowledges the novelty of open
classes. Additionally, we propose an active learning scheme based on visual
memory, which learns to recognize open classes in a data-efficient manner for
future expansions. On three large-scale open long-tailed datasets we curated
from ImageNet (object-centric), Places (scene-centric), and MS1M (face-centric)
data, as well as three standard benchmarks (CIFAR-10-LT, CIFAR-100-LT, and
iNaturalist-18), our approach, as a unified framework, consistently
demonstrates competitive performance. Notably, our approach also shows strong
potential for the active exploration of open classes and the fairness analysis
of minority groups.
</p></li>
</ul>

<h3>Title: What Artificial Neural Networks Can Tell Us About Human Language Acquisition. (arXiv:2208.07998v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.07998">http://arxiv.org/abs/2208.07998</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.07998] What Artificial Neural Networks Can Tell Us About Human Language Acquisition](http://arxiv.org/abs/2208.07998)</code></li>
<li>Summary: <p>Rapid progress in machine learning for natural language processing has the
potential to transform debates about how humans learn language. However, the
learning environments and biases of current artificial learners and humans
diverge in ways that weaken the impact of the evidence obtained from learning
simulations. For example, today's most effective neural language models are
trained on roughly one thousand times the amount of linguistic data available
to a typical child. To increase the relevance of learnability results from
computational models, we need to train model learners without significant
advantages over humans. If an appropriate model successfully acquires some
target linguistic knowledge, it can provide a proof of concept that the target
is learnable in a hypothesized human learning scenario. Plausible model
learners will enable us to carry out experimental manipulations to make causal
inferences about variables in the learning environment, and to rigorously test
poverty-of-the-stimulus-style claims arguing for innate linguistic knowledge in
humans on the basis of speculations about learnability. Comparable experiments
will never be possible with human subjects due to practical and ethical
considerations, making model learners an indispensable resource. So far,
attempts to deprive current models of unfair advantages obtain sub-human
results for key grammatical behaviors such as acceptability judgments. But
before we can justifiably conclude that language learning requires more prior
domain-specific knowledge than current models possess, we must first explore
non-linguistic inputs in the form of multimodal stimuli and multi-agent
interaction as ways to make our learners more efficient at learning from
limited linguistic input.
</p></li>
</ul>

<h3>Title: Error Parity Fairness: Testing for Group Fairness in Regression Tasks. (arXiv:2208.08279v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08279">http://arxiv.org/abs/2208.08279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08279] Error Parity Fairness: Testing for Group Fairness in Regression Tasks](http://arxiv.org/abs/2208.08279)</code></li>
<li>Summary: <p>The applications of Artificial Intelligence (AI) surround decisions on
increasingly many aspects of human lives. Society responds by imposing legal
and social expectations for the accountability of such automated decision
systems (ADSs). Fairness, a fundamental constituent of AI accountability, is
concerned with just treatment of individuals and sensitive groups (e.g., based
on sex, race). While many studies focus on fair learning and fairness testing
for the classification tasks, the literature is rather limited on how to
examine fairness in regression tasks. This work presents error parity as a
regression fairness notion and introduces a testing methodology to assess group
fairness based on a statistical hypothesis testing procedure. The error parity
test checks whether prediction errors are distributed similarly across
sensitive groups to determine if an ADS is fair. It is followed by a suitable
permutation test to compare groups on several statistics to explore disparities
and identify impacted groups. The usefulness and applicability of the proposed
methodology are demonstrated via a case study on COVID-19 projections in the US
at the county level, which revealed race-based differences in forecast errors.
Overall, the proposed regression fairness testing methodology fills a gap in
the fair machine learning literature and may serve as a part of larger
accountability assessments and algorithm audits.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: KAM -- a Kernel Attention Module for Emotion Classification with EEG Data. (arXiv:2208.08161v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2208.08161">http://arxiv.org/abs/2208.08161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2208.08161] KAM -- a Kernel Attention Module for Emotion Classification with EEG Data](http://arxiv.org/abs/2208.08161)</code></li>
<li>Summary: <p>In this work, a kernel attention module is presented for the task of
EEG-based emotion classification with neural networks. The proposed module
utilizes a self-attention mechanism by performing a kernel trick, demanding
significantly fewer trainable parameters and computations than standard
attention modules. The design also provides a scalar for quantitatively
examining the amount of attention assigned during deep feature refinement,
hence help better interpret a trained model. Using EEGNet as the backbone
model, extensive experiments are conducted on the SEED dataset to assess the
module's performance on within-subject classification tasks compared to other
SOTA attention modules. Requiring only one extra parameter, the inserted module
is shown to boost the base model's mean prediction accuracy up to more than 1\%
across 15 subjects. A key component of the method is the interpretability of
solutions, which is addressed using several different techniques, and is
included throughout as part of the dependency analysis.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
