<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-10-15</h1>
<h3>Title: Think as a Doctor: An Interpretable AI Approach for ICU Mortality Prediction</h3>
<ul>
<li><strong>Authors: </strong>Qingwen Li, Xiaohang Zhao, Xiao Han, Hailiang Huang, Lanjuan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11745">https://arxiv.org/abs/2510.11745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11745">https://arxiv.org/pdf/2510.11745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11745]] Think as a Doctor: An Interpretable AI Approach for ICU Mortality Prediction(https://arxiv.org/abs/2510.11745)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Intensive Care Unit (ICU) mortality prediction, which estimates a patient's mortality status at discharge using EHRs collected early in an ICU admission, is vital in critical care. For this task, predictive accuracy alone is insufficient; interpretability is equally essential for building clinical trust and meeting regulatory standards, a topic that has attracted significant attention in information system research. Accordingly, an ideal solution should enable intrinsic interpretability and align its reasoning with three key elements of the ICU decision-making practices: clinical course identification, demographic heterogeneity, and prognostication awareness. However, conventional approaches largely focus on demographic heterogeneity, overlooking clinical course identification and prognostication awareness. Recent prototype learning methods address clinical course identification, yet the integration of the other elements into such frameworks remains underexplored. To address these gaps, we propose ProtoDoctor, a novel ICU mortality prediction framework that delivers intrinsic interpretability while integrating all three elements of the ICU decision-making practices into its reasoning process. Methodologically, ProtoDoctor features two key innovations: the Prognostic Clinical Course Identification module and the Demographic Heterogeneity Recognition module. The former enables the identification of clinical courses via prototype learning and achieves prognostication awareness using a novel regularization mechanism. The latter models demographic heterogeneity through cohort-specific prototypes and risk adjustments. Extensive empirical evaluations demonstrate that ProtoDoctor outperforms state-of-the-art baselines in predictive accuracy. Human evaluations further confirm that its interpretations are more clinically meaningful, trustworthy, and applicable in ICU practice.</li>
</ul>

<h3>Title: GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving</h3>
<ul>
<li><strong>Authors: </strong>Ruida Wang, Jiarui Yao, Rui Pan, Shizhe Diao, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11769">https://arxiv.org/abs/2510.11769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11769">https://arxiv.org/pdf/2510.11769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11769]] GAR: Generative Adversarial Reinforcement Learning for Formal Theorem Proving(https://arxiv.org/abs/2510.11769)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Solving math problems through verifiable languages such as Lean has significantly impacted both the mathematics and computer science communities. Current state-of-the-art models are often trained with expensive online Reinforcement Learning (RL) or expert iteration. However, these approaches rely on fixed problem sets, which causes inefficient training and limits the model to tackle complex problems. To overcome these limitations, we propose GAR: Generative Adversarial Reinforcement learning, a comprehensive RL training framework that jointly trains the problem composer and solver in an adversarial loop. GAR introduces an implicit curriculum learning mechanism, which aligns task difficulty with the prover's evolving capability. It thereby improves the training efficiency and enables stronger performance of proving advanced theorems. Experiments show that with GAR training, Goedel-Prover-V2-8B and DeepSeek-Prover-V2-7B achieve an average relative improvement in pass@32 of 4.20% on MiniF2F-Test benchmark, while DeepSeek-Prover-V2's pass@32 on ProofNet-Test increases from 22.58% to 25.81%. Beyond formal proving, GAR establishes a general RL paradigm for co-evolution of problem generation and solving under verifiable environments.</li>
</ul>

<h3>Title: A Comprehensive Survey of Website Fingerprinting Attacks and Defenses in Tor: Advances and Open Challenges</h3>
<ul>
<li><strong>Authors: </strong>Yuwen Cui, Guangjing Wang, Khanh Vu, Kai Wei, Kehan Shen, Zhengyuan Jiang, Xiao Han, Ning Wang, Zhuo Lu, Yao Liu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11804">https://arxiv.org/abs/2510.11804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11804">https://arxiv.org/pdf/2510.11804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11804]] A Comprehensive Survey of Website Fingerprinting Attacks and Defenses in Tor: Advances and Open Challenges(https://arxiv.org/abs/2510.11804)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>The Tor network provides users with strong anonymity by routing their internet traffic through multiple relays. While Tor encrypts traffic and hides IP addresses, it remains vulnerable to traffic analysis attacks such as the website fingerprinting (WF) attack, achieving increasingly high fingerprinting accuracy even under open-world conditions. In response, researchers have proposed a variety of defenses, ranging from adaptive padding, traffic regularization, and traffic morphing to adversarial perturbation, that seek to obfuscate or reshape traffic traces. However, these defenses often entail trade-offs between privacy, usability, and system performance. Despite extensive research, a comprehensive survey unifying WF datasets, attack methodologies, and defense strategies remains absent. This paper fills that gap by systematically categorizing existing WF research into three key domains: datasets, attack models, and defense mechanisms. We provide an in-depth comparative analysis of techniques, highlight their strengths and limitations under diverse threat models, and discuss emerging challenges such as multi-tab browsing and coarse-grained traffic features. By consolidating prior work and identifying open research directions, this survey serves as a foundation for advancing stronger privacy protection in Tor.</li>
</ul>

<h3>Title: PHANTOM RECALL: When Familiar Puzzles Fool Smart Models</h3>
<ul>
<li><strong>Authors: </strong>Souradeep Mukhopadhyay, Rishabh Baral, Nimeesh Mahajan, Samhitha Harish, Aswin RRV, Mihir Parmar, Mutsumi Nakamura, Chitta Baral</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11812">https://arxiv.org/abs/2510.11812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11812">https://arxiv.org/pdf/2510.11812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11812]] PHANTOM RECALL: When Familiar Puzzles Fool Smart Models(https://arxiv.org/abs/2510.11812)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) such as GPT, Gemini, and Claude often appear adept at solving classic logic puzzles--but how much genuine reasoning underlies their answers? Recent evidence suggests that these models frequently rely on memorized templates rather than reasoning from first principles. When puzzles are slightly modified, their performance collapses, revealing a striking fragility. In particular, we asked: Have LLMs addressed these issues? To what extent? How about perturbations to other puzzles? Is there a general way of reformulating the prompt so that the models do better? To examine these things systematically, we introduce PHANTOM RECALL, a benchmark comprising 25 well-known logic puzzles and 149 carefully designed perturbations that preserve reasoning structure but alter superficial details and solutions. We evaluate eleven leading LLMs and identify a recurring failure mode--phantom recall--where models confidently reproduce memorized solutions or spurious rationales that no longer fit the altered scenario. To probe and mitigate this issue, we contribute three tools: (i) an automated logical-equivalence judge to detect reasoning mismatches, (ii) a taxonomy of fine-grained reasoning error categories, and (iii) a prompting-based mitigation framework guided by these categories. Despite near-perfect accuracy on unmodified puzzles, models significantly underperform humans on perturbed ones, exhibiting both phantom recall and over-elaboration. Our findings reveal a crucial limitation: LLMs often fail to re-reason when contextual cues shift--highlighting the gap between linguistic fluency and logical understanding.</li>
</ul>

<h3>Title: BlackIce: A Containerized Red Teaming Toolkit for AI Security Testing</h3>
<ul>
<li><strong>Authors: </strong>Caelin Kaplan, Alexander Warnecke, Neil Archibald</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11823">https://arxiv.org/abs/2510.11823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11823">https://arxiv.org/pdf/2510.11823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11823]] BlackIce: A Containerized Red Teaming Toolkit for AI Security Testing(https://arxiv.org/abs/2510.11823)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>AI models are being increasingly integrated into real-world systems, raising significant concerns about their safety and security. Consequently, AI red teaming has become essential for organizations to proactively identify and address vulnerabilities before they can be exploited by adversaries. While numerous AI red teaming tools currently exist, practitioners face challenges in selecting the most appropriate tools from a rapidly expanding landscape, as well as managing complex and frequently conflicting software dependencies across isolated projects. Given these challenges and the relatively small number of organizations with dedicated AI red teams, there is a strong need to lower barriers to entry and establish a standardized environment that simplifies the setup and execution of comprehensive AI model assessments. Inspired by Kali Linux's role in traditional penetration testing, we introduce BlackIce, an open-source containerized toolkit designed for red teaming Large Language Models (LLMs) and classical machine learning (ML) models. BlackIce provides a reproducible, version-pinned Docker image that bundles 14 carefully selected open-source tools for Responsible AI and Security testing, all accessible via a unified command-line interface. With this setup, initiating red team assessments is as straightforward as launching a container, either locally or using a cloud platform. Additionally, the image's modular architecture facilitates community-driven extensions, allowing users to easily adapt or expand the toolkit as new threats emerge. In this paper, we describe the architecture of the container image, the process used for selecting tools, and the types of evaluations they support.</li>
</ul>

<h3>Title: Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Simone Mungari, Ettore Ritacco, Pietro Sabatino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11827">https://arxiv.org/abs/2510.11827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11827">https://arxiv.org/pdf/2510.11827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11827]] Combining Euclidean and Hyperbolic Representations for Node-level Anomaly Detection(https://arxiv.org/abs/2510.11827)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Node-level anomaly detection (NAD) is challenging due to diverse structural patterns and feature distributions. As such, NAD is a critical task with several applications which range from fraud detection, cybersecurity, to recommendation systems. We introduce Janus, a framework that jointly leverages Euclidean and Hyperbolic Graph Neural Networks to capture complementary aspects of node representations. Each node is described by two views, composed by the original features and structural features derived from random walks and degrees, then embedded into Euclidean and Hyperbolic spaces. A multi Graph-Autoencoder framework, equipped with a contrastive learning objective as regularization term, aligns the embeddings across the Euclidean and Hyperbolic spaces, highlighting nodes whose views are difficult to reconcile and are thus likely anomalous. Experiments on four real-world datasets show that Janus consistently outperforms shallow and deep baselines, empirically demonstrating that combining multiple geometric representations provides a robust and effective approach for identifying subtle and complex anomalies in graphs.</li>
</ul>

<h3>Title: Schrödinger bridge for generative AI: Soft-constrained formulation and convergence analysis</h3>
<ul>
<li><strong>Authors: </strong>Jin Ma, Ying Tan, Renyuan Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, math.OC, q-fin.MF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11829">https://arxiv.org/abs/2510.11829</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11829">https://arxiv.org/pdf/2510.11829</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11829]] Schrödinger bridge for generative AI: Soft-constrained formulation and convergence analysis(https://arxiv.org/abs/2510.11829)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative AI can be framed as the problem of learning a model that maps simple reference measures into complex data distributions, and it has recently found a strong connection to the classical theory of the Schrödinger bridge problems (SBPs) due partly to their common nature of interpolating between prescribed marginals via entropy-regularized stochastic dynamics. However, the classical SBP enforces hard terminal constraints, which often leads to instability in practical implementations, especially in high-dimensional or data-scarce regimes. To address this challenge, we follow the idea of the so-called soft-constrained Schrödinger bridge problem (SCSBP), in which the terminal constraint is replaced by a general penalty function. This relaxation leads to a more flexible stochastic control formulation of McKean-Vlasov type. We establish the existence of optimal solutions for all penalty levels and prove that, as the penalty grows, both the controls and value functions converge to those of the classical SBP at a linear rate. Our analysis builds on Doob's h-transform representations, the stability results of Schrödinger potentials, Gamma-convergence, and a novel fixed-point argument that couples an optimization problem over the space of measures with an auxiliary entropic optimal transport problem. These results not only provide the first quantitative convergence guarantees for soft-constrained bridges but also shed light on how penalty regularization enables robust generative modeling, fine-tuning, and transfer learning.</li>
</ul>

<h3>Title: Z0-Inf: Zeroth Order Approximation for Data Influence</h3>
<ul>
<li><strong>Authors: </strong>Narine Kokhlikyan, Kamalika Chaudhuri, Saeed Mahloujifar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11832">https://arxiv.org/abs/2510.11832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11832">https://arxiv.org/pdf/2510.11832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11832]] Z0-Inf: Zeroth Order Approximation for Data Influence(https://arxiv.org/abs/2510.11832)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A critical aspect of analyzing and improving modern machine learning systems lies in understanding how individual training examples influence a model's predictive behavior. Estimating this influence enables critical applications, including data selection and model debugging; in particular, self-influence, which quantifies the influence of a training point on itself, has found many uses in data quality assessment and outlier detection. Existing methods for measuring data influence, however, are often impractical for large models due to low accuracy or prohibitive computational costs: most approaches either provide poor approximations or rely on gradients and inverse-Hessian computations that remain challenging to scale. In this work, we introduce a highly efficient zeroth-order approximation for estimating the influence of training data that requires only a fraction of the time and memory footprint of prior methods. Notably, our method relies solely on loss values of intermediate checkpoints on the training and test data, along with the checkpoints themselves, making it broadly applicable even when the loss function of interest is non-differentiable. Beyond its computational efficiency, our approach achieves superior accuracy in estimating self-influence and comparable or improved accuracy in estimating train-test influence for fine-tuned large language models, enabling scalable and practical analysis of how training data shapes model behavior.</li>
</ul>

<h3>Title: Don't Walk the Line: Boundary Guidance for Filtered Generation</h3>
<ul>
<li><strong>Authors: </strong>Sarah Ball, Andreas Haupt</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11834">https://arxiv.org/abs/2510.11834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11834">https://arxiv.org/pdf/2510.11834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11834]] Don't Walk the Line: Boundary Guidance for Filtered Generation(https://arxiv.org/abs/2510.11834)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative models are increasingly paired with safety classifiers that filter harmful or undesirable outputs. A common strategy is to fine-tune the generator to reduce the probability of being filtered, but this can be suboptimal: it often pushes the model toward producing samples near the classifier's decision boundary, increasing both false positives and false negatives. We propose Boundary Guidance, a reinforcement learning fine-tuning method that explicitly steers generation away from the classifier's margin. On a benchmark of jailbreak and ambiguous prompts, Boundary Guidance improves both the safety and the utility of outputs, as judged by LLM-as-a-Judge evaluations. Comprehensive ablations across model scales and reward designs demonstrate the robustness of our approach.</li>
</ul>

<h3>Title: Countermind: A Multi-Layered Security Architecture for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dominik Schwarz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11837">https://arxiv.org/abs/2510.11837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11837">https://arxiv.org/pdf/2510.11837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11837]] Countermind: A Multi-Layered Security Architecture for Large Language Models(https://arxiv.org/abs/2510.11837)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>The security of Large Language Model (LLM) applications is fundamentally challenged by "form-first" attacks like prompt injection and jailbreaking, where malicious instructions are embedded within user inputs. Conventional defenses, which rely on post hoc output filtering, are often brittle and fail to address the root cause: the model's inability to distinguish trusted instructions from untrusted data. This paper proposes Countermind, a multi-layered security architecture intended to shift defenses from a reactive, post hoc posture to a proactive, pre-inference, and intra-inference enforcement model. The architecture proposes a fortified perimeter designed to structurally validate and transform all inputs, and an internal governance mechanism intended to constrain the model's semantic processing pathways before an output is generated. The primary contributions of this work are conceptual designs for: (1) A Semantic Boundary Logic (SBL) with a mandatory, time-coupled Text Crypter intended to reduce the plaintext prompt injection attack surface, provided all ingestion paths are enforced. (2) A Parameter-Space Restriction (PSR) mechanism, leveraging principles from representation engineering, to dynamically control the LLM's access to internal semantic clusters, with the goal of mitigating semantic drift and dangerous emergent behaviors. (3) A Secure, Self-Regulating Core that uses an OODA loop and a learning security module to adapt its defenses based on an immutable audit log. (4) A Multimodal Input Sandbox and Context-Defense mechanisms to address threats from non-textual data and long-term semantic poisoning. This paper outlines an evaluation plan designed to quantify the proposed architecture's effectiveness in reducing the Attack Success Rate (ASR) for form-first attacks and to measure its potential latency overhead.</li>
</ul>

<h3>Title: WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation</h3>
<ul>
<li><strong>Authors: </strong>Yu-Hsiang Wang, Olgica Milenkovic</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11839">https://arxiv.org/abs/2510.11839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11839">https://arxiv.org/pdf/2510.11839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11839]] WaveletDiff: Multilevel Wavelet Diffusion For Time Series Generation(https://arxiv.org/abs/2510.11839)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Time series are ubiquitous in many applications that involve forecasting, classification and causal inference tasks, such as healthcare, finance, audio signal processing and climate sciences. Still, large, high-quality time series datasets remain scarce. Synthetic generation can address this limitation; however, current models confined either to the time or frequency domains struggle to reproduce the inherently multi-scaled structure of real-world time series. We introduce WaveletDiff, a novel framework that trains diffusion models directly on wavelet coefficients to exploit the inherent multi-resolution structure of time series data. The model combines dedicated transformers for each decomposition level with cross-level attention mechanisms that enable selective information exchange between temporal and frequency scales through adaptive gating. It also incorporates energy preservation constraints for individual levels based on Parseval's theorem to preserve spectral fidelity throughout the diffusion process. Comprehensive tests across six real-world datasets from energy, finance, and neuroscience domains demonstrate that WaveletDiff consistently outperforms state-of-the-art time-domain and frequency-domain generative methods on both short and long time series across five diverse performance metrics. For example, WaveletDiff achieves discriminative scores and Context-FID scores that are $3\times$ smaller on average than the second-best baseline across all datasets.</li>
</ul>

<h3>Title: Deep Research Brings Deeper Harm</h3>
<ul>
<li><strong>Authors: </strong>Shuo Chen, Zonggen Li, Zhen Han, Bailan He, Tong Liu, Haokun Chen, Georg Groh, Philip Torr, Volker Tresp, Jindong Gu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11851">https://arxiv.org/abs/2510.11851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11851">https://arxiv.org/pdf/2510.11851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11851]] Deep Research Brings Deeper Harm(https://arxiv.org/abs/2510.11851)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Deep Research (DR) agents built on Large Language Models (LLMs) can perform complex, multi-step research by decomposing tasks, retrieving online information, and synthesizing detailed reports. However, the misuse of LLMs with such powerful capabilities can lead to even greater risks. This is especially concerning in high-stakes and knowledge-intensive domains such as biosecurity, where DR can generate a professional report containing detailed forbidden knowledge. Unfortunately, we have found such risks in practice: simply submitting a harmful query, which a standalone LLM directly rejects, can elicit a detailed and dangerous report from DR agents. This highlights the elevated risks and underscores the need for a deeper safety analysis. Yet, jailbreak methods designed for LLMs fall short in exposing such unique risks, as they do not target the research ability of DR agents. To address this gap, we propose two novel jailbreak strategies: Plan Injection, which injects malicious sub-goals into the agent's plan; and Intent Hijack, which reframes harmful queries as academic research questions. We conducted extensive experiments across different LLMs and various safety benchmarks, including general and biosecurity forbidden prompts. These experiments reveal 3 key findings: (1) Alignment of the LLMs often fail in DR agents, where harmful prompts framed in academic terms can hijack agent intent; (2) Multi-step planning and execution weaken the alignment, revealing systemic vulnerabilities that prompt-level safeguards cannot address; (3) DR agents not only bypass refusals but also produce more coherent, professional, and dangerous content, compared with standalone LLMs. These results demonstrate a fundamental misalignment in DR agents and call for better alignment techniques tailored to DR agents. Code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Robust Adversarial Reinforcement Learning in Stochastic Games via Sequence Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xiaohang Tang, Zhuowen Cheng, Satyabrat Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11877">https://arxiv.org/abs/2510.11877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11877">https://arxiv.org/pdf/2510.11877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11877]] Robust Adversarial Reinforcement Learning in Stochastic Games via Sequence Modeling(https://arxiv.org/abs/2510.11877)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The Transformer, a highly expressive architecture for sequence modeling, has recently been adapted to solve sequential decision-making, most notably through the Decision Transformer (DT), which learns policies by conditioning on desired returns. Yet, the adversarial robustness of reinforcement learning methods based on sequence modeling remains largely unexplored. Here we introduce the Conservative Adversarially Robust Decision Transformer (CART), to our knowledge the first framework designed to enhance the robustness of DT in adversarial stochastic games. We formulate the interaction between the protagonist and the adversary at each stage as a stage game, where the payoff is defined as the expected maximum value over subsequent states, thereby explicitly incorporating stochastic state transitions. By conditioning Transformer policies on the NashQ value derived from these stage games, CART generates policy that are simultaneously less exploitable (adversarially robust) and conservative to transition uncertainty. Empirically, CART achieves more accurate minimax value estimation and consistently attains superior worst-case returns across a range of adversarial stochastic games.</li>
</ul>

<h3>Title: R-WoM: Retrieval-augmented World Model For Computer-use Agents</h3>
<ul>
<li><strong>Authors: </strong>Kai Mei, Jiang Guo, Shuaichen Chang, Mingwen Dong, Dongkyu Lee, Xing Niu, Jiarong Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11892">https://arxiv.org/abs/2510.11892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11892">https://arxiv.org/pdf/2510.11892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11892]] R-WoM: Retrieval-augmented World Model For Computer-use Agents(https://arxiv.org/abs/2510.11892)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can serve as world models to enhance agent decision-making in digital environments by simulating future states and predicting action outcomes, potentially eliminating costly trial-and-error exploration. However, this capability is fundamentally limited by LLMs' tendency toward hallucination and their reliance on static training knowledge, which can lead to compounding errors that inhibit long-horizon simulations. To systematically investigate whether LLMs are appropriate for world modeling, we probe two core capabilities of world models--future state prediction and reward estimation--through three tasks: next-state identification, full-procedure planning alignment, and milestone transition recognition. Our analysis shows that while LLMs effectively capture immediate next states and identify meaningful state transitions, their performance rapidly degrades in full-procedure planning. This highlights LLMs' limitations in reliably modeling environment dynamics over long horizons. To address these limitations, we propose the Retrieval-augmented World Model (R-WoM), which grounds LLM simulations by incorporating factual, up-to-date knowledge retrieved from external tutorials. Experiments show that R-WoM achieves substantial improvements of up to 25.3% (OSWorld) and 18.1% (WebArena) compared to baselines, with particular advantages in longer-horizon simulations.</li>
</ul>

<h3>Title: ADARL: Adaptive Low-Rank Structures for Robust Policy Learning under Uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Chenliang Li, Junyu Leng, Jiaxiang Li, Youbang Sun, Shixiang Chen, Shahin Shahrampour, Alfredo Garcia</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11899">https://arxiv.org/abs/2510.11899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11899">https://arxiv.org/pdf/2510.11899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11899]] ADARL: Adaptive Low-Rank Structures for Robust Policy Learning under Uncertainty(https://arxiv.org/abs/2510.11899)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robust reinforcement learning (Robust RL) seeks to handle epistemic uncertainty in environment dynamics, but existing approaches often rely on nested min--max optimization, which is computationally expensive and yields overly conservative policies. We propose \textbf{Adaptive Rank Representation (AdaRL)}, a bi-level optimization framework that improves robustness by aligning policy complexity with the intrinsic dimension of the task. At the lower level, AdaRL performs policy optimization under fixed-rank constraints with dynamics sampled from a Wasserstein ball around a centroid model. At the upper level, it adaptively adjusts the rank to balance the bias--variance trade-off, projecting policy parameters onto a low-rank manifold. This design avoids solving adversarial worst-case dynamics while ensuring robustness without over-parameterization. Empirical results on MuJoCo continuous control benchmarks demonstrate that AdaRL not only consistently outperforms fixed-rank baselines (e.g., SAC) and state-of-the-art robust RL methods (e.g., RNAC, Parseval), but also converges toward the intrinsic rank of the underlying tasks. These results highlight that adaptive low-rank policy representations provide an efficient and principled alternative for robust RL under model uncertainty.</li>
</ul>

<h3>Title: Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks</h3>
<ul>
<li><strong>Authors: </strong>Rizal Fathony, Igor Melnyk, Owen Reinert, Nam H. Nguyen, Daniele Rosa, C. Bayan Bruss</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11903">https://arxiv.org/abs/2510.11903</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11903">https://arxiv.org/pdf/2510.11903</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11903]] Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks(https://arxiv.org/abs/2510.11903)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>User event modeling plays a central role in many machine learning applications, with use cases spanning e-commerce, social media, finance, cybersecurity, and other domains. User events can be broadly categorized into personal events, which involve individual actions, and relational events, which involve interactions between two users. These two types of events are typically modeled separately, using sequence-based methods for personal events and graph-based methods for relational events. Despite the need to capture both event types in real-world systems, prior work has rarely considered them together. This is often due to the convenient simplification that user behavior can be adequately represented by a single formalization, either as a sequence or a graph. To address this gap, there is a need for public datasets and prediction tasks that explicitly incorporate both personal and relational events. In this work, we introduce a collection of such datasets, propose a unified formalization, and empirically show that models benefit from incorporating both event types. Our results also indicate that current methods leave a notable room for improvements. We release these resources to support further research in unified user event modeling and encourage progress in this direction.</li>
</ul>

<h3>Title: LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance</h3>
<ul>
<li><strong>Authors: </strong>Patrick Haller, Mark Ibrahim, Polina Kirichenko, Levent Sagun, Samuel J. Bell</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11905">https://arxiv.org/abs/2510.11905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11905">https://arxiv.org/pdf/2510.11905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11905]] LLM Knowledge is Brittle: Truthfulness Representations Rely on Superficial Resemblance(https://arxiv.org/abs/2510.11905)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>For Large Language Models (LLMs) to be reliable, they must learn robust knowledge that can be generally applied in diverse settings -- often unlike those seen during training. Yet, extensive research has shown that LLM performance can be brittle, with models exhibiting excessive sensitivity to trivial input variations. In this work, we explore whether this brittleness is a direct result of unstable internal knowledge representations. To explore this question, we build on previous work showing that LLM representations encode statement truthfulness -- i.e., true, factual statements can be easily separated from false, inaccurate ones. Specifically, we test the robustness of learned knowledge by evaluating representation separability on samples that have undergone superficial transformations to drive them out-of-distribution (OOD), such as typos or reformulations. By applying semantically-preserving perturbations, we study how separability degrades as statements become more OOD, across four LLM families, five evaluation datasets, and three knowledge probing methods. Our results reveal that internal representations of statement truthfulness collapse as the samples' presentations become less similar to those seen during pre-training. While LLMs can often distinguish between true and false statements when they closely resemble the pre-training data, this ability is highly dependent on the statement's exact surface form. These findings offer a possible explanation for brittle benchmark performance: LLMs may learn shallow, non-robust knowledge representations that allow for only limited generalizability. Our work presents a fundamental challenge for the utility of truthfulness probes, and more broadly, calls for further research on improving the robustness of learned knowledge representations.</li>
</ul>

<h3>Title: Robust ML-based Detection of Conventional, LLM-Generated, and Adversarial Phishing Emails Using Advanced Text Preprocessing</h3>
<ul>
<li><strong>Authors: </strong>Deeksha Hareesha Kulal, Chidozie Princewill Arannonu, Afsah Anwar, Nidhi Rastogi, Quamar Niyaz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11915">https://arxiv.org/abs/2510.11915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11915">https://arxiv.org/pdf/2510.11915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11915]] Robust ML-based Detection of Conventional, LLM-Generated, and Adversarial Phishing Emails Using Advanced Text Preprocessing(https://arxiv.org/abs/2510.11915)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Phishing remains a critical cybersecurity threat, especially with the advent of large language models (LLMs) capable of generating highly convincing malicious content. Unlike earlier phishing attempts which are identifiable by grammatical errors, misspellings, incorrect phrasing, and inconsistent formatting, LLM generated emails are grammatically sound, contextually relevant, and linguistically natural. These advancements make phishing emails increasingly difficult to distinguish from legitimate ones, challenging traditional detection mechanisms. Conventional phishing detection systems often fail when faced with emails crafted by LLMs or manipulated using adversarial perturbation techniques. To address this challenge, we propose a robust phishing email detection system featuring an enhanced text preprocessing pipeline. This pipeline includes spelling correction and word splitting to counteract adversarial modifications and improve detection accuracy. Our approach integrates widely adopted natural language processing (NLP) feature extraction techniques and machine learning algorithms. We evaluate our models on publicly available datasets comprising both phishing and legitimate emails, achieving a detection accuracy of 94.26% and F1-score of 84.39% in model deployment setting. To assess robustness, we further evaluate our models using adversarial phishing samples generated by four attack methods in Python TextAttack framework. Additionally, we evaluate models' performance against phishing emails generated by LLMs including ChatGPT and Llama. Results highlight the resilience of models against evolving AI-powered phishing threats.</li>
</ul>

<h3>Title: Variational Mixture of Graph Neural Experts for Alzheimer's Disease Biomarker Recognition in EEG Brain Networks</h3>
<ul>
<li><strong>Authors: </strong>Jun-En Ding, Anna Zilverstand, Shihao Yang, Albert Chih-Chieh Yang, Feng Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11917">https://arxiv.org/abs/2510.11917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11917">https://arxiv.org/pdf/2510.11917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11917]] Variational Mixture of Graph Neural Experts for Alzheimer's Disease Biomarker Recognition in EEG Brain Networks(https://arxiv.org/abs/2510.11917)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Dementia disorders such as Alzheimer's disease (AD) and frontotemporal dementia (FTD) exhibit overlapping electrophysiological signatures in EEG that challenge accurate diagnosis. Existing EEG-based methods are limited by full-band frequency analysis that hinders precise differentiation of dementia subtypes and severity stages. We propose a variational mixture of graph neural experts (VMoGE) that integrates frequency-specific biomarker identification with structured variational inference for enhanced dementia diagnosis and staging. VMoGE employs a multi-granularity transformer to extract multi-scale temporal patterns across four frequency bands, followed by a variational graph convolutional encoder using Gaussian Markov Random Field priors. Through structured variational inference and adaptive gating, VMoGE links neural specialization to physiologically meaningful EEG frequency bands. Evaluated on two diverse datasets for both subtype classification and severity staging, VMoGE achieves superior performance with AUC improvements of +4% to +10% over state-of-the-art methods. Moreover, VMoGE provides interpretable insights through expert weights that correlate with clinical indicators and spatial patterns aligned with neuropathological signatures, facilitating EEG biomarker discovery for comprehensive dementia diagnosis and monitoring.</li>
</ul>

<h3>Title: Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning Enabled Decoder-Only Transformer</h3>
<ul>
<li><strong>Authors: </strong>Nayan Sanjay Bhatia, Pranay Kocheta, Russell Elliott, Harikrishna S. Kuttivelil, Katia Obraczka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11926">https://arxiv.org/abs/2510.11926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11926">https://arxiv.org/pdf/2510.11926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11926]] Indoor Localization using Compact, Telemetry-Agnostic, Transfer-Learning Enabled Decoder-Only Transformer(https://arxiv.org/abs/2510.11926)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Indoor Wi-Fi positioning remains a challenging problem due to the high sensitivity of radio signals to environmental dynamics, channel propagation characteristics, and hardware heterogeneity. Conventional fingerprinting and model-based approaches typically require labor-intensive calibration and suffer rapid performance degradation when devices, channel or deployment conditions change. In this paper, we introduce Locaris, a decoder-only large language model (LLM) for indoor localization. Locaris treats each access point (AP) measurement as a token, enabling the ingestion of raw Wi-Fi telemetry without pre-processing. By fine-tuning its LLM on different Wi-Fi datasets, Locaris learns a lightweight and generalizable mapping from raw signals directly to device location. Our experimental study comparing Locaris with state-of-the-art methods consistently shows that Locaris matches or surpasses existing techniques for various types of telemetry. Our results demonstrate that compact LLMs can serve as calibration-free regression models for indoor localization, offering scalable and robust cross-environment performance in heterogeneous Wi-Fi deployments. Few-shot adaptation experiments, using only a handful of calibration points per device, further show that Locaris maintains high accuracy when applied to previously unseen devices and deployment scenarios. This yields sub-meter accuracy with just a few hundred samples, robust performance under missing APs and supports any and all available telemetry. Our findings highlight the practical viability of Locaris for indoor positioning in the real-world scenarios, particularly in large-scale deployments where extensive calibration is infeasible.</li>
</ul>

<h3>Title: TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Yupei Li, Philipp Borchert, Gerasimos Lampouras</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11944">https://arxiv.org/abs/2510.11944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11944">https://arxiv.org/pdf/2510.11944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11944]] TopoAlign: A Framework for Aligning Code to Math via Topological Decomposition(https://arxiv.org/abs/2510.11944)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at both informal and formal (e.g. Lean 4) mathematical reasoning but still struggle with autoformalisation, the task of transforming informal into formal mathematical statements. Autoformalisation helps pair the informal reasoning of LLMs with formal proof assistants which enable machine-verifiable generation and mitigate hallucinations. Yet, the performance of current Math LLMs is constrained by the scarcity of large-scale corpora, particularly those containing pairs of informal and formal statements. Although current models are trained to generate code from natural language instructions, structural and syntactic differences between these and formal mathematics limit effective transfer learning. We propose TopoAlign, a framework that unlocks widely available code repositories as training resources for Math LLMs. TopoAlign decomposes code into docstrings, main functions, and dependency functions, and reassembles these components into analogues that structurally mirror formal statements. This produces structurally aligned code data that can be used for training Math LLMs without requiring additional human annotation. We train two state-of-the-art models, DeepSeek-Math and Herald, and evaluate them on the minif2f, Putnam, and ProofNet benchmarks. TopoAlign provides substantial gains for DeepSeek-Math, improving performance by 17.77% on BEq@10 and 68.82% on typecheck@10. Despite introducing no new mathematical knowledge, our framework achieves gains of 0.12% and 1.09% for Herald on BEq@10 and typecheck@10, respectively, demonstrating that training on aligned code data is beneficial even for specialized models.</li>
</ul>

<h3>Title: GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences</h3>
<ul>
<li><strong>Authors: </strong>Priyanka Dey, Daniele Rosa, Wenqing Zheng, Daniel Barcklow, Jieyu Zhao, Emilio Ferrara</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11952">https://arxiv.org/abs/2510.11952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11952">https://arxiv.org/pdf/2510.11952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11952]] GRAVITY: A Framework for Personalized Text Generation via Profile-Grounded Synthetic Preferences(https://arxiv.org/abs/2510.11952)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Personalization in LLMs often relies on costly human feedback or interaction logs, limiting scalability and neglecting deeper user attributes. To reduce the reliance on human annotations, we introduce GRAVITY (Generative Response with Aligned Values, Interests, and Traits of You), a framework for generating synthetic, profile-grounded preference data that captures users' interests, values, beliefs, and personality traits. By integrating demographic, cultural, and psychological frameworks -- including Hofstede's cultural dimensions, Schwartz's basic values, the World Values Survey, and Big Five OCEAN traits -- GRAVITY synthesizes preference pairs to guide personalized content generation. We evaluate GRAVITY on book descriptions for 400 Amazon users, comparing it to prompt-based conditioning, standard fine-tuning, and naive synthetic pair generation. Profile-grounded synthetic data consistently improves generation, especially across multiple cultures (USA, Brazil, Japan, India), achieving over 4% higher preference gains across baselines, with user studies showing that GRAVITY outputs are preferred over 86% of the time. Our results show that scenario-grounded synthetic data can capture richer user variation, reduce reliance on costly annotation, and produce more engaging, user-centered content, offering a scalable path for LLM personalization.</li>
</ul>

<h3>Title: Y-shaped Generative Flows</h3>
<ul>
<li><strong>Authors: </strong>Arip Asadulaev, Semyon Semenov, Abduragim Shtanchaev, Eric Moulines, Fakhri Karray, Martin Takac</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11955">https://arxiv.org/abs/2510.11955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11955">https://arxiv.org/pdf/2510.11955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11955]] Y-shaped Generative Flows(https://arxiv.org/abs/2510.11955)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern continuous-time generative models often induce V-shaped transport: each sample travels independently along nearly straight trajectories from prior to data, overlooking shared structure. We introduce Y-shaped generative flows, which move probability mass together along shared pathways before branching to target-specific endpoints. Our formulation is based on novel velocity-powered transport cost with a sublinear exponent (between zero and one). this concave dependence rewards joint and fast mass movement. Practically, we instantiate the idea in a scalable neural ODE training objective. On synthetic, image, and biology datasets, Y-flows recover hierarchy-aware structure, improve distributional metrics over strong flow-based baselines, and reach targets with fewer integration steps.</li>
</ul>

<h3>Title: Direct Multi-Token Decoding</h3>
<ul>
<li><strong>Authors: </strong>Xuan Luo, Weizhi Wang, Xifeng Yan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11958">https://arxiv.org/abs/2510.11958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11958">https://arxiv.org/pdf/2510.11958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11958]] Direct Multi-Token Decoding(https://arxiv.org/abs/2510.11958)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Decoder-only transformers have become the standard architecture for large language models (LLMs) due to their strong performance. Recent studies suggest that, in pre-trained LLMs, early, middle, and late layers may serve distinct roles: Early layers focus on understanding the input context, middle layers handle task-specific processing, and late layers convert abstract representations into output tokens. We hypothesize that once representations have been processed by the early and middle layers, the resulting hidden states may encapsulate sufficient information to support the generation of multiple tokens using only the late layers, eliminating the need to repeatedly traverse the early and middle layers. We refer to this inference paradigm as Direct Multi-Token Decoding (DMTD). Unlike speculative decoding, our method introduces no additional parameters, auxiliary routines, or post-generation verification. Despite being trained on a limited dataset, a fine-tuned DMTD Qwen3-4B model has already demonstrated promising results, achieving up to a 2x speedup with only minor performance loss. Moreover, as shown in our scaling analysis, its performance is expected to further improve with larger training datasets.</li>
</ul>

<h3>Title: MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Bowei Guo, Shengkun Tang, Cong Zeng, Zhiqiang Shen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11962">https://arxiv.org/abs/2510.11962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11962">https://arxiv.org/pdf/2510.11962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11962]] MosaicDiff: Training-free Structural Pruning for Diffusion Model Acceleration Reflecting Pretraining Dynamics(https://arxiv.org/abs/2510.11962)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are renowned for their generative capabilities, yet their pretraining processes exhibit distinct phases of learning speed that have been entirely overlooked in prior post-training acceleration efforts in the community. In this study, we introduce a novel framework called MosaicDiff that aligns diffusion pretraining dynamics with post-training sampling acceleration via trajectory-aware structural pruning. Our approach leverages the observation that the middle, fast-learning stage of diffusion pretraining requires more conservative pruning to preserve critical model features, while the early and later, slow-learning stages benefit from a more aggressive pruning strategy. This adaptive pruning mechanism is the first to explicitly mirror the inherent learning speed variations of diffusion pretraining, thereby harmonizing the model's inner training dynamics with its accelerated sampling process. Extensive experiments on DiT and SDXL demonstrate that our method achieves significant speed-ups in sampling without compromising output quality, outperforming previous state-of-the-art methods by large margins, also providing a new viewpoint for more efficient and robust training-free diffusion acceleration.</li>
</ul>

<h3>Title: QLENS: Towards A Quantum Perspective of Language Transformers</h3>
<ul>
<li><strong>Authors: </strong>Aditya Gupta, Kirandeep Kaur, Vinayak Gupta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11963">https://arxiv.org/abs/2510.11963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11963">https://arxiv.org/pdf/2510.11963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11963]] QLENS: Towards A Quantum Perspective of Language Transformers(https://arxiv.org/abs/2510.11963)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>In natural language processing, current methods for understanding Transformers are successful at identifying intermediate predictions during a model's inference. However, these approaches function as limited diagnostic checkpoints, lacking a mathematical framework for mechanistically modeling how each layer facilitates transitions between these evolving states. This interpretability gap and past successes of interdisciplinary outlooks inspire us to turn to physics in search of a descriptive mathematical framework for Transformers. We observe that language models are intrinsically probabilistic, an attribute that is echoed in the core postulates of quantum mechanics. This parallel inspires us to translate insights from this discipline to that of natural language processing. Towards this objective, we propose QLENS a novel attempt to develop a physics-based perspective on the Transformer generation process. Under QLENS, a Transformer is studied by converting its latent activations into a state vector in a Hilbert space derived from the model's output units. This state subsequently evolves through hidden layers - reformulated as unitary operators and analogously defined Hamiltonians - during inference. The model's final probability distribution is obtained by applying the Born rule to the end state using a specific measurement operator. To demonstrate QLENS's potential, we conduct a proof-of-concept by probing a toy Transformer to investigate the influence of individual layers in a model's prediction trajectory. We present our work as a foundation for cross-domain insights to be leveraged towards a broader understanding of Transformers.</li>
</ul>

<h3>Title: Scaling Long-Horizon LLM Agent via Context-Folding</h3>
<ul>
<li><strong>Authors: </strong>Weiwei Sun, Miao Lu, Zhan Ling, Kang Liu, Xuesong Yao, Yiming Yang, Jiecao Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11967">https://arxiv.org/abs/2510.11967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11967">https://arxiv.org/pdf/2510.11967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11967]] Scaling Long-Horizon LLM Agent via Context-Folding(https://arxiv.org/abs/2510.11967)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) agents are fundamentally constrained by context length on long-horizon tasks. We introduce Context-Folding, a framework that empowers agents to actively manage their working context. An agent can procedurally branch into a sub-trajectory to handle a subtask and then fold it upon completion, collapsing the intermediate steps while retaining a concise summary of the outcome. To make this behavior learnable, we develop an end-to-end reinforcement learning framework FoldGRPO with specific process rewards to encourage effective task decomposition and context management. On complex long-horizon tasks (Deep Research and SWE), our folding agent matches or outperforms the ReAct baselines while using an active context 10$\times$ smaller and significantly outperforms models that rely on summarization-based context management.</li>
</ul>

<h3>Title: CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Yutong Cheng, Yang Liu, Changze Li, Dawn Song, Peng Gao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11974">https://arxiv.org/abs/2510.11974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11974">https://arxiv.org/pdf/2510.11974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11974]] CTIArena: Benchmarking LLM Knowledge and Reasoning Across Heterogeneous Cyber Threat Intelligence(https://arxiv.org/abs/2510.11974)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>Cyber threat intelligence (CTI) is central to modern cybersecurity, providing critical insights for detecting and mitigating evolving threats. With the natural language understanding and reasoning capabilities of large language models (LLMs), there is increasing interest in applying them to CTI, which calls for benchmarks that can rigorously evaluate their performance. Several early efforts have studied LLMs on some CTI tasks but remain limited: (i) they adopt only closed-book settings, relying on parametric knowledge without leveraging CTI knowledge bases; (ii) they cover only a narrow set of tasks, lacking a systematic view of the CTI landscape; and (iii) they restrict evaluation to single-source analysis, unlike realistic scenarios that require reasoning across multiple sources. To fill these gaps, we present CTIArena, the first benchmark for evaluating LLM performance on heterogeneous, multi-source CTI under knowledge-augmented settings. CTIArena spans three categories, structured, unstructured, and hybrid, further divided into nine tasks that capture the breadth of CTI analysis in modern security operations. We evaluate ten widely used LLMs and find that most struggle in closed-book setups but show noticeable gains when augmented with security-specific knowledge through our designed retrieval-augmented techniques. These findings highlight the limitations of general-purpose LLMs and the need for domain-tailored techniques to fully unlock their potential for CTI.</li>
</ul>

<h3>Title: Learning Dynamics of VLM Finetuning</h3>
<ul>
<li><strong>Authors: </strong>Jusheng Zhang, Kaitong Cai, Jing Yang, Keze Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11978">https://arxiv.org/abs/2510.11978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11978">https://arxiv.org/pdf/2510.11978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11978]] Learning Dynamics of VLM Finetuning(https://arxiv.org/abs/2510.11978)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Preference-based finetuning of vision--language models (VLMs) is brittle: trivially wrong negatives inject uninformative gradients that destabilize training. We recast alignment as \textbf{learning-dynamics--aware optimization} and introduce \textbf{Cooling-Weighted DPO (CW-DPO)}, a two-stage recipe that explicitly models and exploits the training trajectory. \textbf{Stage 1} performs supervised finetuning with \textbf{gentle negatives}: \textbf{low-weight smoothed supervision} that regularizes the base policy and curbs overconfidence without explicit penalties. \textbf{Stage 2} applies a DPO objective in which the \textbf{negative term is scaled by a cooling weight} computed from the model's \textbf{average token log-probability} on each negative, suppressing uninformative gradients from easy or off-distribution samples while preserving signal from hard negatives. In practice, we emphasize \textbf{on-policy negatives} and allow \textbf{mixed negatives} by blending a controllable fraction of dataset negatives to maintain contrast freshness. Throughout, we instrument training with $\Delta\!\log p$ probes on positives and negatives as first-class signals for early stopping, curriculum design, and failure diagnosis. Across diverse VLM tasks, CW-DPO yields \textbf{more stable optimization}, \textbf{better calibration}, and \textbf{higher pairwise win-rates} than SFT-only and vanilla DPO, while \textbf{converging in fewer steps}. Ablations isolate the \textbf{cooling-weight mechanism} as the primary driver of these gains and show complementary benefits from mixing on-policy and dataset negatives. Taken together, our results show that \textbf{smoothing learning dynamics before cooling preferences} is a simple, general principle for robust VLM alignment.</li>
</ul>

<h3>Title: Learning by Steering the Neural Dynamics: A Statistical Mechanics Perspective</h3>
<ul>
<li><strong>Authors: </strong>Mattia Scardecchia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11984">https://arxiv.org/abs/2510.11984</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11984">https://arxiv.org/pdf/2510.11984</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11984]] Learning by Steering the Neural Dynamics: A Statistical Mechanics Perspective(https://arxiv.org/abs/2510.11984)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Despite the striking successes of deep neural networks trained with gradient-based optimization, these methods differ fundamentally from their biological counterparts. This gap raises key questions about how nature achieves robust, sample-efficient learning at minimal energy costs and solves the credit-assignment problem without backpropagation. We take a step toward bridging contemporary AI and computational neuroscience by studying how neural dynamics can support fully local, distributed learning that scales to simple machine-learning benchmarks. Using tools from statistical mechanics, we identify conditions for the emergence of robust dynamical attractors in random asymmetric recurrent networks. We derive a closed-form expression for the number of fixed points as a function of self-coupling strength, and we reveal a phase transition in their structure: below a critical self-coupling, isolated fixed points coexist with exponentially many narrow clusters showing the overlap-gap property; above it, subdominant yet dense and extensive clusters appear. These fixed points become accessible, including to a simple asynchronous dynamical rule, after an algorithm-dependent self-coupling threshold. Building on this analysis, we propose a biologically plausible algorithm for supervised learning with any binary recurrent network. Inputs are mapped to fixed points of the dynamics, by relaxing under transient external stimuli and stabilizing the resulting configurations via local plasticity. We show that our algorithm can learn an entangled version of MNIST, leverages depth to develop hierarchical representations and increase hetero-association capacity, and is applicable to several architectures. Finally, we highlight the strong connection between algorithm performance and the unveiled phase transition, and we suggest a cortex-inspired alternative to self-couplings for its emergence.</li>
</ul>

<h3>Title: Conjecturing: An Overlooked Step in Formal Mathematical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jasivan Alex Sivakumar, Philipp Borchert, Ronald Cardenas, Gerasimos Lampouras</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11986">https://arxiv.org/abs/2510.11986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11986">https://arxiv.org/pdf/2510.11986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11986]] Conjecturing: An Overlooked Step in Formal Mathematical Reasoning(https://arxiv.org/abs/2510.11986)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoformalisation, the task of expressing informal mathematical statements in formal language, is often viewed as a direct translation process. This, however, disregards a critical preceding step: conjecturing. Many mathematical problems cannot be formalised directly without first conjecturing a conclusion such as an explicit answer, or a specific bound. Since Large Language Models (LLMs) already struggle with autoformalisation, and the evaluation of their conjecturing ability is limited and often entangled within autoformalisation or proof, it is particularly challenging to understand its effect. To address this gap, we augment existing datasets to create ConjectureBench, and redesign the evaluation framework and metric specifically to measure the conjecturing capabilities of LLMs both as a distinct task and within the autoformalisation pipeline. Our evaluation of foundational models, including GPT-4.1 and DeepSeek-V3.1, reveals that their autoformalisation performance is substantially overestimated when the conjecture is accounted for during evaluation. However, the conjecture should not be assumed to be provided. We design an inference-time method, Lean-FIRe to improve conjecturing and autoformalisation, which, to the best of our knowledge, achieves the first successful end-to-end autoformalisation of 13 PutnamBench problems with GPT-4.1 and 7 with DeepSeek-V3.1. We demonstrate that while LLMs possess the requisite knowledge to generate accurate conjectures, improving autoformalisation performance requires treating conjecturing as an independent task, and investigating further how to correctly integrate it within autoformalisation. Finally, we provide forward-looking guidance to steer future research toward improving conjecturing, an overlooked step of formal mathematical reasoning.</li>
</ul>

<h3>Title: PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation</h3>
<ul>
<li><strong>Authors: </strong>Hatem Ibrahem, Ahmed Salem, Qinmin Vivian Hu, Guanghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11992">https://arxiv.org/abs/2510.11992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11992">https://arxiv.org/pdf/2510.11992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11992]] PanoTPS-Net: Panoramic Room Layout Estimation via Thin Plate Spline Transformation(https://arxiv.org/abs/2510.11992)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurately estimating the 3D layout of rooms is a crucial task in computer vision, with potential applications in robotics, augmented reality, and interior design. This paper proposes a novel model, PanoTPS-Net, to estimate room layout from a single panorama image. Leveraging a Convolutional Neural Network (CNN) and incorporating a Thin Plate Spline (TPS) spatial transformation, the architecture of PanoTPS-Net is divided into two stages: First, a convolutional neural network extracts the high-level features from the input images, allowing the network to learn the spatial parameters of the TPS transformation. Second, the TPS spatial transformation layer is generated to warp a reference layout to the required layout based on the predicted parameters. This unique combination empowers the model to properly predict room layouts while also generalizing effectively to both cuboid and non-cuboid layouts. Extensive experiments on publicly available datasets and comparisons with state-of-the-art methods demonstrate the effectiveness of the proposed method. The results underscore the model's accuracy in room layout estimation and emphasize the compatibility between the TPS transformation and panorama images. The robustness of the model in handling both cuboid and non-cuboid room layout estimation is evident with a 3DIoU value of 85.49, 86.16, 81.76, and 91.98 on PanoContext, Stanford-2D3D, Matterport3DLayout, and ZInD datasets, respectively. The source code is available at: this https URL.</li>
</ul>

<h3>Title: Prompt-Guided Spatial Understanding with RGB-D Transformers for Fine-Grained Object Relation Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Tanner Muturi, Blessing Agyei Kyem, Joshua Kofi Asamoah, Neema Jakisa Owor, Richard Dyzinela, Andrews Danyo, Yaw Adu-Gyamfi, Armstrong Aboah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.11996">https://arxiv.org/abs/2510.11996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.11996">https://arxiv.org/pdf/2510.11996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.11996]] Prompt-Guided Spatial Understanding with RGB-D Transformers for Fine-Grained Object Relation Reasoning(https://arxiv.org/abs/2510.11996)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Spatial reasoning in large-scale 3D environments such as warehouses remains a significant challenge for vision-language systems due to scene clutter, occlusions, and the need for precise spatial understanding. Existing models often struggle with generalization in such settings, as they rely heavily on local appearance and lack explicit spatial grounding. In this work, we introduce a dedicated spatial reasoning framework for the Physical AI Spatial Intelligence Warehouse dataset introduced in the Track 3 2025 AI City Challenge. Our approach enhances spatial comprehension by embedding mask dimensions in the form of bounding box coordinates directly into the input prompts, enabling the model to reason over object geometry and layout. We fine-tune the framework across four question categories namely: Distance Estimation, Object Counting, Multi-choice Grounding, and Spatial Relation Inference using task-specific supervision. To further improve consistency with the evaluation system, normalized answers are appended to the GPT response within the training set. Our comprehensive pipeline achieves a final score of 73.0606, placing 4th overall on the public leaderboard. These results demonstrate the effectiveness of structured prompt enrichment and targeted optimization in advancing spatial reasoning for real-world industrial environments.</li>
</ul>

<h3>Title: Generate Logical Equivalence Questions</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Wang, Haoming Yu, Yicheng Yang, Zhiyuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12001">https://arxiv.org/abs/2510.12001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12001">https://arxiv.org/pdf/2510.12001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12001]] Generate Logical Equivalence Questions(https://arxiv.org/abs/2510.12001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Academic dishonesty is met with zero tolerance in higher education, yet plagiarism has become increasingly prevalent in the era of online teaching and learning. Automatic Question Generation (AQG) presents a potential solution to mitigate copying by creating unique questions for each student. Additionally, AQG can provide a vast array of practice questions. Our AQG focuses on generating logical equivalence questions for Discrete Mathematics, a foundational course for first-year computer science students. A literature review reveals that existing AQGs for this type of question generate all propositions that meet user-defined constraints, resulting in inefficiencies and a lack of uniform question difficulty. To address this, we propose a new approach that defines logical equivalence questions using a formal language, translates this language into two sets of generation rules, and develops a linear-time algorithm for question generation. We evaluated our AQG through two experiments. The first involved a group of students completing questions generated by our system. Statistical analysis shows that the accuracy of these questions is comparable to that of textbook questions. The second experiment assessed the number of steps required to solve our generated questions, textbook questions, and those generated by multiple large language models. The results indicated that the difficulty of our questions was similar to that of textbook questions, confirming the quality of our AQG.</li>
</ul>

<h3>Title: Evaluating the Explainability of Vision Transformers in Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Leili Barekatain, Ben Glocker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12021">https://arxiv.org/abs/2510.12021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12021">https://arxiv.org/pdf/2510.12021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12021]] Evaluating the Explainability of Vision Transformers in Medical Imaging(https://arxiv.org/abs/2510.12021)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Understanding model decisions is crucial in medical imaging, where interpretability directly impacts clinical trust and adoption. Vision Transformers (ViTs) have demonstrated state-of-the-art performance in diagnostic imaging; however, their complex attention mechanisms pose challenges to explainability. This study evaluates the explainability of different Vision Transformer architectures and pre-training strategies - ViT, DeiT, DINO, and Swin Transformer - using Gradient Attention Rollout and Grad-CAM. We conduct both quantitative and qualitative analyses on two medical imaging tasks: peripheral blood cell classification and breast ultrasound image classification. Our findings indicate that DINO combined with Grad-CAM offers the most faithful and localized explanations across datasets. Grad-CAM consistently produces class-discriminative and spatially precise heatmaps, while Gradient Attention Rollout yields more scattered activations. Even in misclassification cases, DINO with Grad-CAM highlights clinically relevant morphological features that appear to have misled the model. By improving model transparency, this research supports the reliable and explainable integration of ViTs into critical medical diagnostic workflows.</li>
</ul>

<h3>Title: Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM</h3>
<ul>
<li><strong>Authors: </strong>Alice Saebom Kwak, Maria Alexeeva, Gus Hahn-Powell, Keith Alcock, Kevin McLaughlin, Doug McCorkle, Gabe McNunn, Mihai Surdeanu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12023">https://arxiv.org/abs/2510.12023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12023">https://arxiv.org/pdf/2510.12023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12023]] Information Extraction from Conversation Transcripts: Neuro-Symbolic vs. LLM(https://arxiv.org/abs/2510.12023)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>The current trend in information extraction (IE) is to rely extensively on large language models, effectively discarding decades of experience in building symbolic or statistical IE systems. This paper compares a neuro-symbolic (NS) and an LLM-based IE system in the agricultural domain, evaluating them on nine interviews across pork, dairy, and crop subdomains. The LLM-based system outperforms the NS one (F1 total: 69.4 vs. 52.7; core: 63.0 vs. 47.2), where total includes all extracted information and core focuses on essential details. However, each system has trade-offs: the NS approach offers faster runtime, greater control, and high accuracy in context-free tasks but lacks generalizability, struggles with contextual nuances, and requires significant resources to develop and maintain. The LLM-based system achieves higher performance, faster deployment, and easier maintenance but has slower runtime, limited control, model dependency and hallucination risks. Our findings highlight the "hidden cost" of deploying NLP systems in real-world applications, emphasizing the need to balance performance, efficiency, and control.</li>
</ul>

<h3>Title: Mamaba Can Learn Low-Dimensional Targets In-Context via Test-Time Feature Learning</h3>
<ul>
<li><strong>Authors: </strong>Junsoo Oh, Wei Huang, Taiji Suzuki</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12026">https://arxiv.org/abs/2510.12026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12026">https://arxiv.org/pdf/2510.12026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12026]] Mamaba Can Learn Low-Dimensional Targets In-Context via Test-Time Feature Learning(https://arxiv.org/abs/2510.12026)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Mamba, a recently proposed linear-time sequence model, has attracted significant attention for its computational efficiency and strong empirical performance. However, a rigorous theoretical understanding of its underlying mechanisms remains limited. In this work, we provide a theoretical analysis of Mamba's in-context learning (ICL) capability by focusing on tasks defined by low-dimensional nonlinear target functions. Specifically, we study in-context learning of a single-index model $y \approx g_*(\langle \boldsymbol{\beta}, \boldsymbol{x} \rangle)$, which depends on only a single relevant direction $\boldsymbol{\beta}$, referred to as feature. We prove that Mamba, pretrained by gradient-based methods, can achieve efficient ICL via test-time feature learning, extracting the relevant direction directly from context examples. Consequently, we establish a test-time sample complexity that improves upon linear Transformers -- analyzed to behave like kernel methods -- and is comparable to nonlinear Transformers, which have been shown to surpass the Correlational Statistical Query (CSQ) lower bound and achieve near information-theoretically optimal rate in previous works. Our analysis reveals the crucial role of the nonlinear gating mechanism in Mamba for feature extraction, highlighting it as the fundamental driver behind Mamba's ability to achieve both computational efficiency and high performance.</li>
</ul>

<h3>Title: CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement</h3>
<ul>
<li><strong>Authors: </strong>Jung-Woo Shim, Yeong-Joon Ju, Ji-Hoon Park, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12029">https://arxiv.org/abs/2510.12029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12029">https://arxiv.org/pdf/2510.12029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12029]] CPR: Mitigating Large Language Model Hallucinations with Curative Prompt Refinement(https://arxiv.org/abs/2510.12029)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) highlight their fluency in generating responses to diverse prompts. However, these models sometimes generate plausible yet incorrect ``hallucinated" facts, undermining trust. A frequent but often overlooked cause of such errors is the use of poorly structured or vague prompts by users, leading LLMs to base responses on assumed rather than actual intentions. To mitigate hallucinations induced by these ill-formed prompts, we introduce Curative Prompt Refinement (CPR), a plug-and-play framework for curative prompt refinement that 1) cleans ill-formed prompts, and 2) generates additional informative task descriptions to align the intention of the user and the prompt using a fine-tuned small language model. When applied to language models, we discover that CPR significantly increases the quality of generation while also mitigating hallucination. Empirical studies show that prompts with CPR applied achieves over a 90\% win rate over the original prompts without any external knowledge.</li>
</ul>

<h3>Title: Security and Privacy Assessment of U.S. and Non-U.S. Android E-Commerce Applications</h3>
<ul>
<li><strong>Authors: </strong>Urvashi Kishnani, Sanchari Das</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12031">https://arxiv.org/abs/2510.12031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12031">https://arxiv.org/pdf/2510.12031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12031]] Security and Privacy Assessment of U.S. and Non-U.S. Android E-Commerce Applications(https://arxiv.org/abs/2510.12031)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>E-commerce mobile applications are central to global financial transactions, making their security and privacy crucial. In this study, we analyze 92 top-grossing Android e-commerce apps (58 U.S.-based and 34 international) using MobSF, AndroBugs, and RiskInDroid. Our analysis shows widespread SSL and certificate weaknesses, with approximately 92% using unsecured HTTP connections and an average MobSF security score of 40.92/100. Over-privileged permissions were identified in 77 apps. While U.S. apps exhibited fewer manifest, code, and certificate vulnerabilities, both groups showed similar network-related issues. We advocate for the adoption of stronger, standardized, and user-focused security practices across regions.</li>
</ul>

<h3>Title: Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jung-Woo Shim, Yeong-Joon Ju, Ji-Hoon Park, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12032">https://arxiv.org/abs/2510.12032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12032">https://arxiv.org/pdf/2510.12032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12032]] Multi-stage Prompt Refinement for Mitigating Hallucinations in Large Language Models(https://arxiv.org/abs/2510.12032)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have shown strong performance in natural language understanding and generation tasks. However, LLMs continue to encounter challenges with hallucinations, where models generate plausible but incorrect information. While several factors contribute to hallucinations, the impact of ill-formed prompts, prompts with ambiguous wording, incorrect grammar, or incomplete information, was relatively under explored. To address this, we introduce Multi-stage Prompt Refinement (MPR), a framework designed to systematically improve these ill-formed prompts across multiple stages. Each stage addresses specific errors such as punctuation, typographical mistakes, and misuse of key terms, using small language models (SLMs) fine-tuned for these tasks. MPR iteratively enhances the clarity of prompts with additional context and employs a self-reflection mechanism with ranking to prioritize the most relevant input. Experimental results on hallucination benchmarks show that prompts refined by MPR achieve over an 85~\% win rate compared to their original forms, demonstrating its effectiveness in reducing hallucinations and improving LLM output accuracy. Interestingly, we reveal that MPR can be combined with existing post-hoc hallucination mitigation frameworks, further enhancing its versatility. MPR provides a lightweight and adaptable solution for enhancing LLM reliability across various domains.</li>
</ul>

<h3>Title: On the Interplay between Human Label Variation and Model Fairness</h3>
<ul>
<li><strong>Authors: </strong>Kemal Kurniawan, Meladel Mistica, Timothy Baldwin, Jey Han Lau</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12036">https://arxiv.org/abs/2510.12036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12036">https://arxiv.org/pdf/2510.12036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12036]] On the Interplay between Human Label Variation and Model Fairness(https://arxiv.org/abs/2510.12036)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The impact of human label variation (HLV) on model fairness is an unexplored topic. This paper examines the interplay by comparing training on majority-vote labels with a range of HLV methods. Our experiments show that without explicit debiasing, HLV training methods have a positive impact on fairness.</li>
</ul>

<h3>Title: Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions</h3>
<ul>
<li><strong>Authors: </strong>Sungmin Kang, Yavuz Faruk Bakman, Duygu Nur Yaldiz, Baturalp Buyukates, Salman Avestimehr</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12040">https://arxiv.org/abs/2510.12040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12040">https://arxiv.org/pdf/2510.12040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12040]] Uncertainty Quantification for Hallucination Detection in Large Language Models: Foundations, Methodology, and Future Directions(https://arxiv.org/abs/2510.12040)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has transformed the landscape of natural language processing, enabling breakthroughs across a wide range of areas including question answering, machine translation, and text summarization. Yet, their deployment in real-world applications has raised concerns over reliability and trustworthiness, as LLMs remain prone to hallucinations that produce plausible but factually incorrect outputs. Uncertainty quantification (UQ) has emerged as a central research direction to address this issue, offering principled measures for assessing the trustworthiness of model generations. We begin by introducing the foundations of UQ, from its formal definition to the traditional distinction between epistemic and aleatoric uncertainty, and then highlight how these concepts have been adapted to the context of LLMs. Building on this, we examine the role of UQ in hallucination detection, where quantifying uncertainty provides a mechanism for identifying unreliable generations and improving reliability. We systematically categorize a wide spectrum of existing methods along multiple dimensions and present empirical results for several representative approaches. Finally, we discuss current limitations and outline promising future research directions, providing a clearer picture of the current landscape of LLM UQ for hallucination detection.</li>
</ul>

<h3>Title: Improving Text-to-Image Generation with Input-Side Inference-Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Ruibo Chen, Jiacheng Pan, Heng Huang, Zhenheng Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12041">https://arxiv.org/abs/2510.12041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12041">https://arxiv.org/pdf/2510.12041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12041]] Improving Text-to-Image Generation with Input-Side Inference-Time Scaling(https://arxiv.org/abs/2510.12041)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in text-to-image (T2I) generation have achieved impressive results, yet existing models often struggle with simple or underspecified prompts, leading to suboptimal image-text alignment, aesthetics, and quality. We propose a prompt rewriting framework that leverages large language models (LLMs) to refine user inputs before feeding them into T2I backbones. Our approach introduces a carefully designed reward system and an iterative direct preference optimization (DPO) training pipeline, enabling the rewriter to enhance prompts without requiring supervised fine-tuning data. We evaluate our method across diverse T2I models and benchmarks. Results show that our prompt rewriter consistently improves image-text alignment, visual quality, and aesthetics, outperforming strong baselines. Furthermore, we demonstrate strong transferability by showing that a prompt rewriter trained on one T2I backbone generalizes effectively to others without needing to be retrained. We also systematically study scalability, evaluating how performance gains scale with the capacity of the large LLM used as the rewriter. These findings highlight that prompt rewriting is an effective, scalable, and practical model-agnostic strategy for improving T2I systems. We plan to release the code and trained prompt rewriters soon.</li>
</ul>

<h3>Title: Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yukun Zhang, Qi Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12044">https://arxiv.org/abs/2510.12044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12044">https://arxiv.org/pdf/2510.12044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12044]] Hierarchical Alignment: Surgical Fine-Tuning via Functional Layer Specialization in Large Language Models(https://arxiv.org/abs/2510.12044)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Existing alignment techniques for Large Language Models (LLMs), such as Direct Preference Optimization (DPO), typically treat the model as a monolithic entity, applying uniform optimization pressure across all layers. This approach overlooks the functional specialization within the Transformer architecture, where different layers are known to handle distinct tasks from syntax to abstract reasoning. In this paper, we challenge this one-size-fits-all paradigm by introducing Hierarchical Alignment, a novel method that applies targeted DPO to distinct functional blocks of a model's layers: local (syntax), intermediate (logic), and global (factuality). Through a series of controlled experiments on state-of-the-art models like Llama-3.1-8B and Qwen1.5-7B using LoRA for surgical fine-tuning, our results, evaluated by a powerful LLM-as-Judge, demonstrate significant and predictable improvements. Specifically, aligning the local layers (Local-Align) enhances grammatical fluency. More importantly, aligning the global layers (Global-Align) not only improves factual consistency as hypothesized but also proves to be the most effective strategy for enhancing logical coherence, outperforming all baselines. Critically, all hierarchical strategies successfully avoid the "alignment tax" observed in standard DPO, where gains in fluency come at the cost of degraded logical reasoning. These findings establish a more resource-efficient, controllable, and interpretable path for model alignment, highlighting the immense potential of shifting from monolithic optimization to structure-aware surgical fine-tuning to build more advanced and reliable LLMs.</li>
</ul>

<h3>Title: Over-Threshold Multiparty Private Set Intersection for Collaborative Network Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Onur Eren Arpaci (1), Raouf Boutaba (1), Florian Kerschbaum (1) ((1) University of Waterloo)</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12045">https://arxiv.org/abs/2510.12045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12045">https://arxiv.org/pdf/2510.12045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12045]] Over-Threshold Multiparty Private Set Intersection for Collaborative Network Intrusion Detection(https://arxiv.org/abs/2510.12045)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>An important function of collaborative network intrusion detection is to analyze the network logs of the collaborators for joint IP addresses. However, sharing IP addresses in plain is sensitive and may be even subject to privacy legislation as it is personally identifiable information. In this paper, we present the privacy-preserving collection of IP addresses. We propose a single collector, over-threshold private set intersection protocol. In this protocol $N$ participants identify the IP addresses that appear in at least $t$ participant's sets without revealing any information about other IP addresses. Using a novel hashing scheme, we reduce the computational complexity of the previous state-of-the-art solution from $O(M(N \log{M}/t)^{2t})$ to $O(t^2M\binom{N}{t})$, where $M$ denotes the dataset size. This reduction makes it practically feasible to apply our protocol to real network logs. We test our protocol using joint networks logs of multiple institutions. Additionally, we present two deployment options: a collusion-safe deployment, which provides stronger security guarantees at the cost of increased communication overhead, and a non-interactive deployment, which assumes a non-colluding collector but offers significantly lower communication costs and applicable to many use cases of collaborative network intrusion detection similar to ours.</li>
</ul>

<h3>Title: APCE: Adaptive Progressive Context Expansion for Long Context Processing</h3>
<ul>
<li><strong>Authors: </strong>Baisub Lee, Sanghyun Byun, Mohanad Odema, Jung Guack, Jacob Song, Woo Seong Chung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12051">https://arxiv.org/abs/2510.12051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12051">https://arxiv.org/pdf/2510.12051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12051]] APCE: Adaptive Progressive Context Expansion for Long Context Processing(https://arxiv.org/abs/2510.12051)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deploying useful Long-Context Transformer Models (LCTMs) requires addressing two key challenges: (1) A growing memory footprint due to quadratic self-attention and linear KV-cache scaling in memory as sequence length increases; (2) the ContextRot phenomena where empirical evidence suggests that transformer architecture's performance degrades with increasing context length. Given the shared dependency on the input, a natural question arises: Can we surgically select the most important input chunks for processing to synergistically (a) reduce the memory footprint, and (b) mitigate the ContextRot effects? In this paper, we answer this question in the affirmative for long-context summarization tasks. We propose APCE as a context-aware solution to select the most important input chunks through low-dimensional semantic similarity matching with the current query. By directly operating on the input, APCE decouples from strict dependency on underlying hardware or CUDA environments, promising a compatible solution scalable to different deployment systems. Our empirical evaluations have demonstrated superior or on-par summarization performance for APCE compared to the full dense baseline using a fraction (50%-70%) of the input sequence resulting in KV-cache and self-attention memory efficiency improvements. We hope our findings inspire further research on context-aware efficiency solutions for LCTMs geared towards other relevant long-context tasks.</li>
</ul>

<h3>Title: APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Xinxin Huang, Han Sun, Junmin Cai, Ningzhong Liu, Huiyu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12056">https://arxiv.org/abs/2510.12056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12056">https://arxiv.org/pdf/2510.12056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12056]] APGNet: Adaptive Prior-Guided for Underwater Camouflaged Object Detection(https://arxiv.org/abs/2510.12056)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting camouflaged objects in underwater environments is crucial for marine ecological research and resource exploration. However, existing methods face two key challenges: underwater image degradation, including low contrast and color distortion, and the natural camouflage of marine organisms. Traditional image enhancement techniques struggle to restore critical features in degraded images, while camouflaged object detection (COD) methods developed for terrestrial scenes often fail to adapt to underwater environments due to the lack of consideration for underwater optical characteristics. To address these issues, we propose APGNet, an Adaptive Prior-Guided Network, which integrates a Siamese architecture with a novel prior-guided mechanism to enhance robustness and detection accuracy. First, we employ the Multi-Scale Retinex with Color Restoration (MSRCR) algorithm for data augmentation, generating illumination-invariant images to mitigate degradation effects. Second, we design an Extended Receptive Field (ERF) module combined with a Multi-Scale Progressive Decoder (MPD) to capture multi-scale contextual information and refine feature representations. Furthermore, we propose an adaptive prior-guided mechanism that hierarchically fuses position and boundary priors by embedding spatial attention in high-level features for coarse localization and using deformable convolution to refine contours in low-level features. Extensive experimental results on two public MAS datasets demonstrate that our proposed method APGNet outperforms 15 state-of-art methods under widely used evaluation metrics.</li>
</ul>

<h3>Title: Your VAR Model is Secretly an Efficient and Explainable Generative Classifier</h3>
<ul>
<li><strong>Authors: </strong>Yi-Chung Chen, David I. Inouye, Jing Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12060">https://arxiv.org/abs/2510.12060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12060">https://arxiv.org/pdf/2510.12060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12060]] Your VAR Model is Secretly an Efficient and Explainable Generative Classifier(https://arxiv.org/abs/2510.12060)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative classifiers, which leverage conditional generative models for classification, have recently demonstrated desirable properties such as robustness to distribution shifts. However, recent progress in this area has been largely driven by diffusion-based models, whose substantial computational cost severely limits scalability. This exclusive focus on diffusion-based methods has also constrained our understanding of generative classifiers. In this work, we propose a novel generative classifier built on recent advances in visual autoregressive (VAR) modeling, which offers a new perspective for studying generative classifiers. To further enhance its performance, we introduce the Adaptive VAR Classifier$^+$ (A-VARC$^+$), which achieves a superior trade-off between accuracy and inference speed, thereby significantly improving practical applicability. Moreover, we show that the VAR-based method exhibits fundamentally different properties from diffusion-based methods. In particular, due to its tractable likelihood, the VAR-based classifier enables visual explainability via token-wise mutual information and demonstrates inherent resistance to catastrophic forgetting in class-incremental learning tasks.</li>
</ul>

<h3>Title: Adding All Flavors: A Hybrid Random Number Generator for dApps and Web3</h3>
<ul>
<li><strong>Authors: </strong>Ranjith Chodavarapu, Rabimba Karanjai, Xinxin Fan, Weidong Shi, Lei Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12062">https://arxiv.org/abs/2510.12062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12062">https://arxiv.org/pdf/2510.12062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12062]] Adding All Flavors: A Hybrid Random Number Generator for dApps and Web3(https://arxiv.org/abs/2510.12062)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Random numbers play a vital role in many decentralized applications (dApps), such as gaming and decentralized finance (DeFi) applications. Existing random number provision mechanisms can be roughly divided into two categories, on-chain, and off-chain. On-chain approaches usually rely on the blockchain as the major input and all computations are done by blockchain nodes. The major risk for this type of method is that the input itself is susceptible to the adversary's influence. Off-chain approaches, as the name suggested, complete the generation without the involvement of blockchain nodes and share the result directly with a dApp. These mechanisms usually have a strong security assumption and high complexity. To mitigate these limitations and provide a framework that allows a dApp to balance different factors involved in random number generation, we propose a hybrid random number generation solution that leverages IoT devices equipped with trusted execution environment (TEE) as the randomness sources, and then utilizes a set of cryptographic tools to aggregate the multiple sources and obtain the final random number that can be consumed by the dApp. The new approach only needs one honest random source to guarantee the unbiasedness of the final random number and a user can configure the system to tolerate malicious participants who can refuse to respond to avoid unfavored results. We also provide a concrete construction that can further reduce the on-chain computation complexity to lower the cost of the solution in practice. We evaluate the computation and gas costs to demonstrate the effectiveness of the improvement.</li>
</ul>

<h3>Title: VIDMP3: Video Editing by Representing Motion with Pose and Position Priors</h3>
<ul>
<li><strong>Authors: </strong>Sandeep Mishra, Oindrila Saha, Alan C. Bovik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12069">https://arxiv.org/abs/2510.12069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12069">https://arxiv.org/pdf/2510.12069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12069]] VIDMP3: Video Editing by Representing Motion with Pose and Position Priors(https://arxiv.org/abs/2510.12069)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Motion-preserved video editing is crucial for creators, particularly in scenarios that demand flexibility in both the structure and semantics of swapped objects. Despite its potential, this area remains underexplored. Existing diffusion-based editing methods excel in structure-preserving tasks, using dense guidance signals to ensure content integrity. While some recent methods attempt to address structure-variable editing, they often suffer from issues such as temporal inconsistency, subject identity drift, and the need for human intervention. To address these challenges, we introduce VidMP3, a novel approach that leverages pose and position priors to learn a generalized motion representation from source videos. Our method enables the generation of new videos that maintain the original motion while allowing for structural and semantic flexibility. Both qualitative and quantitative evaluations demonstrate the superiority of our approach over existing methods. The code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: A Review on Domain Adaption and Generative Adversarial Networks(GANs)</h3>
<ul>
<li><strong>Authors: </strong>Aashish Dhawan, Divyanshu Mudgal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12075">https://arxiv.org/abs/2510.12075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12075">https://arxiv.org/pdf/2510.12075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12075]] A Review on Domain Adaption and Generative Adversarial Networks(GANs)(https://arxiv.org/abs/2510.12075)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The major challenge in today's computer vision scenario is the availability of good quality labeled data. In a field of study like image classification, where data is of utmost importance, we need to find more reliable methods which can overcome the scarcity of data to produce results comparable to previous benchmark results. In most cases, obtaining labeled data is very difficult because of the high cost of human labor and in some cases impossible. The purpose of this paper is to discuss Domain Adaptation and various methods to implement it. The main idea is to use a model trained on a particular dataset to predict on data from a different domain of the same kind, for example - a model trained on paintings of airplanes predicting on real images of airplanes</li>
</ul>

<h3>Title: An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations</h3>
<ul>
<li><strong>Authors: </strong>Benjamin W. Nelson, Celeste Wong, Matthew T. Silvestrini, Sooyoon Shin, Alanna Robinson, Jessica Lee, Eric Yang, John Torous, Andrew Trister</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12083">https://arxiv.org/abs/2510.12083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12083">https://arxiv.org/pdf/2510.12083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12083]] An AI-Based Behavioral Health Safety Filter and Dataset for Identifying Mental Health Crises in Text-Based Conversations(https://arxiv.org/abs/2510.12083)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models often mishandle psychiatric emergencies, offering harmful or inappropriate advice and enabling destructive behaviors. This study evaluated the Verily behavioral health safety filter (VBHSF) on two datasets: the Verily Mental Health Crisis Dataset containing 1,800 simulated messages and the NVIDIA Aegis AI Content Safety Dataset subsetted to 794 mental health-related messages. The two datasets were clinician-labelled and we evaluated performance using the clinician labels. Additionally, we carried out comparative performance analyses against two open source, content moderation guardrails: OpenAI Omni Moderation Latest and NVIDIA NeMo Guardrails. The VBHSF demonstrated, well-balanced performance on the Verily Mental Health Crisis Dataset v1.0, achieving high sensitivity (0.990) and specificity (0.992) in detecting any mental health crises. It achieved an F1-score of 0.939, sensitivity ranged from 0.917-0.992, and specificity was >= 0.978 in identifying specific crisis categories. When evaluated against the NVIDIA Aegis AI Content Safety Dataset 2.0, VBHSF performance remained highly sensitive (0.982) and accuracy (0.921) with reduced specificity (0.859). When compared with the NVIDIA NeMo and OpenAI Omni Moderation Latest guardrails, the VBHSF demonstrated superior performance metrics across both datasets, achieving significantly higher sensitivity in all cases (all p < 0.001) and higher specificity relative to NVIDIA NeMo (p < 0.001), but not to OpenAI Omni Moderation Latest (p = 0.094). NVIDIA NeMo and OpenAI Omni Moderation Latest exhibited inconsistent performance across specific crisis types, with sensitivity for some categories falling below 0.10. Overall, the VBHSF demonstrated robust, generalizable performance that prioritizes sensitivity to minimize missed crises, a crucial feature for healthcare applications.</li>
</ul>

<h3>Title: Elevating Medical Image Security: A Cryptographic Framework Integrating Hyperchaotic Map and GRU</h3>
<ul>
<li><strong>Authors: </strong>Weixuan Li, Guang Yu, Quanjun Li, Junhua Zhou, Jiajun Chen, Yihang Dong, Mengqian Wang, Zimeng Li, Changwei Gong, Lin Tang, Xuhang Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12084">https://arxiv.org/abs/2510.12084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12084">https://arxiv.org/pdf/2510.12084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12084]] Elevating Medical Image Security: A Cryptographic Framework Integrating Hyperchaotic Map and GRU(https://arxiv.org/abs/2510.12084)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Chaotic systems play a key role in modern image encryption due to their sensitivity to initial conditions, ergodicity, and complex dynamics. However, many existing chaos-based encryption methods suffer from vulnerabilities, such as inadequate permutation and diffusion, and suboptimal pseudorandom properties. This paper presents Kun-IE, a novel encryption framework designed to address these issues. The framework features two key contributions: the development of the 2D Sin-Cos Pi Hyperchaotic Map (2D-SCPHM), which offers a broader chaotic range and superior pseudorandom sequence generation, and the introduction of Kun-SCAN, a novel permutation strategy that significantly reduces pixel correlations, enhancing resistance to statistical attacks. Kun-IE is flexible and supports encryption for images of any size. Experimental results and security analyses demonstrate its robustness against various cryptanalytic attacks, making it a strong solution for secure image communication. The code is available at this \href{this https URL}{link}.</li>
</ul>

<h3>Title: GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs</h3>
<ul>
<li><strong>Authors: </strong>Heng Zhang, Tianyi Zhang, Yuling Shi, Xiaodong Gu, Yaomin Shen, Haochen You, Zijian Zhang, Yilei Yuan, Jin Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12085">https://arxiv.org/abs/2510.12085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12085">https://arxiv.org/pdf/2510.12085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12085]] GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs(https://arxiv.org/abs/2510.12085)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph foundation models represent a transformative paradigm for learning transferable representations across diverse graph domains. Recent methods leverage large language models to unify graph and text modalities into a shared representation space using contrastive learning. However, systematic evaluations reveal significant performance degradation at structural boundaries where distinct topological patterns converge, with accuracy losses exceeding 20 percentage points. This issue arises from a key limitation: current methods assume all graph structures can be encoded within a single Euclidean space. In reality, tree structures require hyperbolic geometry to preserve hierarchical branching, while cyclic patterns depend on spherical geometry for closure properties. At structural boundaries, nodes experience conflicting geometric constraints that uniform encoding spaces cannot resolve. This raises a crucial challenge: \textbf{Can alignment frameworks be designed to respect the intrinsic geometric diversity of graph structures?} We introduce \textbf{GraphShaper}, a geometry-aware framework that enhances graph encoding through multi-geometric specialization. Our approach employs expert networks tailored to different geometric spaces, dynamically computing fusion weights to adaptively integrate geometric properties based on local structural characteristics. This adaptive fusion preserves structural integrity before alignment with text embeddings. Extensive experiments demonstrate that GraphShaper achieves 9.47\% accuracy improvements on citation networks and 7.63\% on social networks in zero-shot settings.</li>
</ul>

<h3>Title: Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback</h3>
<ul>
<li><strong>Authors: </strong>Xingpei Ma, Shenneng Huang, Jiaran Cai, Yuansheng Guan, Shen Zheng, Hanfeng Zhao, Qiang Zhang, Shunsi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12089">https://arxiv.org/abs/2510.12089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12089">https://arxiv.org/pdf/2510.12089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12089]] Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback(https://arxiv.org/abs/2510.12089)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models have significantly improved audio-driven human video generation, surpassing traditional methods in both quality and controllability. However, existing approaches still face challenges in lip-sync accuracy, temporal coherence for long video generation, and multi-character animation. In this work, we propose a diffusion transformer (DiT)-based framework for generating lifelike talking videos of arbitrary length, and introduce a training-free method for multi-character audio-driven animation. First, we employ a LoRA-based training strategy combined with a position shift inference approach, which enables efficient long video generation while preserving the capabilities of the foundation model. Moreover, we combine partial parameter updates with reward feedback to enhance both lip synchronization and natural body motion. Finally, we propose a training-free approach, Mask Classifier-Free Guidance (Mask-CFG), for multi-character animation, which requires no specialized datasets or model modifications and supports audio-driven animation for three or more characters. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches, achieving high-quality, temporally coherent, and multi-character audio-driven video generation in a simple, efficient, and cost-effective manner.</li>
</ul>

<h3>Title: IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Wenxu Zhou, Kaixuan Nie, Hang Du, Dong Yin, Wei Huang, Siqiang Guo, Xiaobo Zhang, Pengbo Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12095">https://arxiv.org/abs/2510.12095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12095">https://arxiv.org/pdf/2510.12095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12095]] IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation(https://arxiv.org/abs/2510.12095)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this study, we present IL3D, a large-scale dataset meticulously designed for large language model (LLM)-driven 3D scene generation, addressing the pressing demand for diverse, high-quality training data in indoor layout design. Comprising 27,816 indoor layouts across 18 prevalent room types and a library of 29,215 high-fidelity 3D object assets, IL3D is enriched with instance-level natural language annotations to support robust multimodal learning for vision-language tasks. We establish rigorous benchmarks to evaluate LLM-driven scene generation. Experimental results show that supervised fine-tuning (SFT) of LLMs on IL3D significantly improves generalization and surpasses the performance of SFT on other datasets. IL3D offers flexible multimodal data export capabilities, including point clouds, 3D bounding boxes, multiview images, depth maps, normal maps, and semantic masks, enabling seamless adaptation to various visual tasks. As a versatile and robust resource, IL3D significantly advances research in 3D scene generation and embodied intelligence, by providing high-fidelity scene data to support environment perception tasks of embodied agents.</li>
</ul>

<h3>Title: An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring</h3>
<ul>
<li><strong>Authors: </strong>Jianping Li, Dongyang Guo, Wenjie Li, Wei Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12098">https://arxiv.org/abs/2510.12098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12098">https://arxiv.org/pdf/2510.12098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12098]] An Adaptive Edge-Guided Dual-Network Framework for Fast QR Code Motion Deblurring(https://arxiv.org/abs/2510.12098)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Unlike general image deblurring that prioritizes perceptual quality, QR code deblurring focuses on ensuring successful decoding. QR codes are characterized by highly structured patterns with sharp edges, a robust prior for restoration. Yet existing deep learning methods rarely exploit these priors explicitly. To address this gap, we propose the Edge-Guided Attention Block (EGAB), which embeds explicit edge priors into a Transformer architecture. Based on EGAB, we develop Edge-Guided Restormer (EG-Restormer), an effective network that significantly boosts the decoding rate of severely blurred QR codes. For mildly blurred inputs, we design the Lightweight and Efficient Network (LENet) for fast deblurring. We further integrate these two networks into an Adaptive Dual-network (ADNet), which dynamically selects the suitable network based on input blur severity, making it ideal for resource-constrained mobile devices. Extensive experiments show that our EG-Restormer and ADNet achieve state-of-the-art performance with a competitive speed. Project page: this https URL</li>
</ul>

<h3>Title: G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior</h3>
<ul>
<li><strong>Authors: </strong>Junfeng Ni, Yixin Chen, Zhifei Yang, Yu Liu, Ruijie Lu, Song-Chun Zhu, Siyuan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12099">https://arxiv.org/abs/2510.12099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12099">https://arxiv.org/pdf/2510.12099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12099]] G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior(https://arxiv.org/abs/2510.12099)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Despite recent advances in leveraging generative prior from pre-trained diffusion models for 3D scene reconstruction, existing methods still face two critical limitations. First, due to the lack of reliable geometric supervision, they struggle to produce high-quality reconstructions even in observed regions, let alone in unobserved areas. Second, they lack effective mechanisms to mitigate multi-view inconsistencies in the generated images, leading to severe shape-appearance ambiguities and degraded scene geometry. In this paper, we identify accurate geometry as the fundamental prerequisite for effectively exploiting generative models to enhance 3D scene reconstruction. We first propose to leverage the prevalence of planar structures to derive accurate metric-scale depth maps, providing reliable supervision in both observed and unobserved regions. Furthermore, we incorporate this geometry guidance throughout the generative pipeline to improve visibility mask estimation, guide novel view selection, and enhance multi-view consistency when inpainting with video diffusion models, resulting in accurate and consistent scene completion. Extensive experiments on Replica, ScanNet++, and DeepBlending show that our method consistently outperforms existing baselines in both geometry and appearance reconstruction, particularly for unobserved regions. Moreover, our method naturally supports single-view inputs and unposed videos, with strong generalizability in both indoor and outdoor scenarios with practical real-world applicability. The project page is available at this https URL.</li>
</ul>

<h3>Title: Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ziliang Qiu, Renfen Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12110">https://arxiv.org/abs/2510.12110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12110">https://arxiv.org/pdf/2510.12110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12110]] Deep Associations, High Creativity: A Simple yet Effective Metric for Evaluating Large Language Models(https://arxiv.org/abs/2510.12110)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The evaluation of LLMs' creativity represents a crucial research domain, though challenges such as data contamination and costly human assessments often impede progress. Drawing inspiration from human creativity assessment, we propose PACE, asking LLMs to generate Parallel Association Chains to Evaluate their creativity. PACE minimizes the risk of data contamination and offers a straightforward, highly efficient evaluation, as evidenced by its strong correlation with Chatbot Arena Creative Writing rankings (Spearman's $\rho = 0.739$, $p < 0.001$) across various proprietary and open-source models. A comparative analysis of associative creativity between LLMs and humans reveals that while high-performing LLMs achieve scores comparable to average human performance, professional humans consistently outperform LLMs. Furthermore, linguistic analysis reveals that both humans and LLMs exhibit a trend of decreasing concreteness in their associations, and humans demonstrating a greater diversity of associative patterns.</li>
</ul>

<h3>Title: Chimera: State Space Models Beyond Sequences</h3>
<ul>
<li><strong>Authors: </strong>Aakash Lahoti, Tanya Marwah, Ratish Puduppully, Albert Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12111">https://arxiv.org/abs/2510.12111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12111">https://arxiv.org/pdf/2510.12111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12111]] Chimera: State Space Models Beyond Sequences(https://arxiv.org/abs/2510.12111)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based deep learning methods have become the standard approach for modeling diverse data such as sequences, images, and graphs. These methods rely on self-attention, which treats data as an unordered set of elements. This ignores the neighborhood structure or graph topology of the data and requires inductive biases--such as position embeddings in sequences and images, or random walks in graphs--to incorporate topology. However, designing such task-specific biases requires significant effort and can introduce side effects that hinder generalization. We introduce Chimera, a unified model that directly incorporates data topology in a principled way, removing the need for domain-specific biases. The key idea is that state space models--which naturally do not require position embeddings--can be generalized to capture any graph topology. Our experiments show that Chimera achieves strong performance across language, vision, and graph domains, outperforming BERT on GLUE by 0.7 points, ViT on ImageNet-1k by 2.6%, and all baselines on the Long Range Graph Benchmark. We further propose algorithmic optimizations to improve Chimera's efficiency: (1) for Directed Acyclic Graphs, Chimera can be implemented as a linear-time recurrence; (2) for general graphs, a simple mathematical relaxation achieves Transformer's quadratic complexity without domain-specific heuristics. These results validate Chimera's core contribution and support the idea that data topology is a powerful inductive bias across modalities.</li>
</ul>

<h3>Title: Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Li, Xiangyi Wang, Heng Guo, Guangwei Gao, Zhanyu Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12114">https://arxiv.org/abs/2510.12114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12114">https://arxiv.org/pdf/2510.12114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12114]] Self-Supervised Selective-Guided Diffusion Model for Old-Photo Face Restoration(https://arxiv.org/abs/2510.12114)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Old-photo face restoration poses significant challenges due to compounded degradations such as breakage, fading, and severe blur. Existing pre-trained diffusion-guided methods either rely on explicit degradation priors or global statistical guidance, which struggle with localized artifacts or face color. We propose Self-Supervised Selective-Guided Diffusion (SSDiff), which leverages pseudo-reference faces generated by a pre-trained diffusion model under weak guidance. These pseudo-labels exhibit structurally aligned contours and natural colors, enabling region-specific restoration via staged supervision: structural guidance applied throughout the denoising process and color refinement in later steps, aligned with the coarse-to-fine nature of diffusion. By incorporating face parsing maps and scratch masks, our method selectively restores breakage regions while avoiding identity mismatch. We further construct VintageFace, a 300-image benchmark of real old face photos with varying degradation levels. SSDiff outperforms existing GAN-based and diffusion-based methods in perceptual quality, fidelity, and regional controllability. Code link: this https URL.</li>
</ul>

<h3>Title: Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhao, Naoki Yoshinaga, Yuma Tsuta, Akiko Aizawa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12115">https://arxiv.org/abs/2510.12115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12115">https://arxiv.org/pdf/2510.12115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12115]] Tracing Multilingual Knowledge Acquisition Dynamics in Domain Adaptation: A Case Study of English-Japanese Biomedical Adaptation(https://arxiv.org/abs/2510.12115)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multilingual domain adaptation (ML-DA) is widely used to learn new domain knowledge across languages into large language models (LLMs). Although many methods have been proposed to improve domain adaptation, the mechanisms of multilingual knowledge acquisition, how domain knowledge is learned within a language and transferred across languages, remain underexplored. This gap leads to suboptimal performance, particularly in low-resource settings. This work examines the learning dynamics of LLMs during ML-DA. Because prior ML-DA studies often train and evaluate on datasets with mismatched knowledge coverage, we propose AdaXEval, an adaptive evaluation method that builds multiple-choice QA datasets from the same bilingual domain corpus used for training, thereby directly studying multilingual knowledge acquisition. Through continual training of LLMs with diverse data recipes, we track how LLMs acquire domain facts and pinpoint the mechanism behind the transformation process from domain training data to knowledge. Our experiments on a 13B English-Japanese bilingual LLM reveal that cross-lingual transfer remains challenging despite a high-quality bilingual corpus. The code has been released.</li>
</ul>

<h3>Title: Locket: Robust Feature-Locking Technique for Language Models</h3>
<ul>
<li><strong>Authors: </strong>Lipeng He, Vasisht Duddu, N. Asokan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12117">https://arxiv.org/abs/2510.12117</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12117">https://arxiv.org/pdf/2510.12117</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12117]] Locket: Robust Feature-Locking Technique for Language Models(https://arxiv.org/abs/2510.12117)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Chatbot providers (e.g., OpenAI) rely on tiered subscription schemes to generate revenue, offering basic models for free users, and advanced models for paying subscribers. However, a finer-grained pay-to-unlock scheme for premium features (e.g., math, coding) is thought to be more economically viable for the providers. Such a scheme requires a feature-locking technique (FLoTE) which is (i) effective in refusing locked features, (ii) utility-preserving for unlocked features, (iii) robust against evasion or unauthorized credential sharing, and (iv) scalable to multiple features and users. However, existing FLoTEs (e.g., password-locked models) are not robust or scalable. We present Locket, the first robust and scalable FLoTE to enable pay-to-unlock schemes. Locket uses a novel merging approach to attach adapters to an LLM for refusing unauthorized features. Our comprehensive evaluation shows that Locket is effective ($100$% refusal on locked features), utility-preserving ($\leq 7$% utility degradation in unlocked features), robust ($\leq 5$% attack success rate), and scales to multiple features and clients.</li>
</ul>

<h3>Title: ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Luo, Yangyi Zhao, Ka Chun Cheung, Simon See, Renjie Wan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12119">https://arxiv.org/abs/2510.12119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12119">https://arxiv.org/pdf/2510.12119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12119]] ImageSentinel: Protecting Visual Datasets from Unauthorized Retrieval-Augmented Image Generation(https://arxiv.org/abs/2510.12119)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, extraction, watermark</a></li>
<li><strong>Abstract: </strong>The widespread adoption of Retrieval-Augmented Image Generation (RAIG) has raised significant concerns about the unauthorized use of private image datasets. While these systems have shown remarkable capabilities in enhancing generation quality through reference images, protecting visual datasets from unauthorized use in such systems remains a challenging problem. Traditional digital watermarking approaches face limitations in RAIG systems, as the complex feature extraction and recombination processes fail to preserve watermark signals during generation. To address these challenges, we propose ImageSentinel, a novel framework for protecting visual datasets in RAIG. Our framework synthesizes sentinel images that maintain visual consistency with the original dataset. These sentinels enable protection verification through randomly generated character sequences that serve as retrieval keys. To ensure seamless integration, we leverage vision-language models to generate the sentinel images. Experimental results demonstrate that ImageSentinel effectively detects unauthorized dataset usage while preserving generation quality for authorized applications. Code is available at this https URL.</li>
</ul>

<h3>Title: FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements</h3>
<ul>
<li><strong>Authors: </strong>Xiao Yang, Jiyao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12132">https://arxiv.org/abs/2510.12132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12132">https://arxiv.org/pdf/2510.12132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12132]] FedHUG: Federated Heterogeneous Unsupervised Generalization for Remote Physiological Measurements(https://arxiv.org/abs/2510.12132)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Remote physiological measurement gained wide attention, while it requires collecting users' privacy-sensitive information, and existing contactless measurements still rely on labeled client data. This presents challenges when we want to further update real-world deployed models with numerous user data lacking labels. To resolve these challenges, we instantiate a new protocol called Federated Unsupervised Domain Generalization (FUDG) in this work. Subsequently, the \textbf{Fed}erated \textbf{H}eterogeneous \textbf{U}nsupervised \textbf{G}eneralization (\textbf{FedHUG}) framework is proposed and consists of: (1) Minimal Bias Aggregation module dynamically adjusts aggregation weights based on prior-driven bias evaluation to cope with heterogeneous non-IID features from multiple domains. (2) The Global Distribution-aware Learning Controller parameterizes the label distribution and dynamically manipulates client-specific training strategies, thereby mitigating the server-client label distribution skew and long-tail issue. The proposal shows superior performance across state-of-the-art techniques in estimation with either RGB video or mmWave radar. The code will be released.</li>
</ul>

<h3>Title: SafeMT: Multi-turn Safety for Multimodal Language Models</h3>
<ul>
<li><strong>Authors: </strong>Han Zhu, Juntao Dai, Jiaming Ji, Haoran Li, Chengkun Cai, Pengcheng Wen, Chi-Min Chan, Boyuan Chen, Yaodong Yang, Sirui Han, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12133">https://arxiv.org/abs/2510.12133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12133">https://arxiv.org/pdf/2510.12133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12133]] SafeMT: Multi-turn Safety for Multimodal Language Models(https://arxiv.org/abs/2510.12133)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread use of multi-modal Large Language models (MLLMs), safety issues have become a growing concern. Multi-turn dialogues, which are more common in everyday interactions, pose a greater risk than single prompts; however, existing benchmarks do not adequately consider this situation. To encourage the community to focus on the safety issues of these models in multi-turn dialogues, we introduce SafeMT, a benchmark that features dialogues of varying lengths generated from harmful queries accompanied by images. This benchmark consists of 10,000 samples in total, encompassing 17 different scenarios and four jailbreak methods. Additionally, we propose Safety Index (SI) to evaluate the general safety of MLLMs during conversations. We assess the safety of 17 models using this benchmark and discover that the risk of successful attacks on these models increases as the number of turns in harmful dialogues rises. This observation indicates that the safety mechanisms of these models are inadequate for recognizing the hazard in dialogue interactions. We propose a dialogue safety moderator capable of detecting malicious intent concealed within conversations and providing MLLMs with relevant safety policies. Experimental results from several open-source models indicate that this moderator is more effective in reducing multi-turn ASR compared to existed guard models.</li>
</ul>

<h3>Title: Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shihao Ji, Zihui Song, Jiajie Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12137">https://arxiv.org/abs/2510.12137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12137">https://arxiv.org/pdf/2510.12137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12137]] Credal Transformer: A Principled Approach for Quantifying and Mitigating Hallucinations in Large Language Models(https://arxiv.org/abs/2510.12137)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) hallucinate, generating factually incorrect yet confident assertions. We argue this stems from the Transformer's Softmax function, which creates "Artificial Certainty" by collapsing ambiguous attention scores into a single probability distribution, discarding uncertainty information at each layer. To fix this, we introduce the Credal Transformer, which replaces standard attention with a Credal Attention Mechanism (CAM) based on evidential theory. CAM produces a "credal set" (a set of distributions) instead of a single attention vector, with the set's size directly measuring model uncertainty. We implement this by re-conceptualizing attention scores as evidence masses for a Dirichlet distribution: sufficient evidence recovers standard attention, while insufficient evidence yields a diffuse distribution, representing ambiguity. Empirically, the Credal Transformer identifies out-of-distribution inputs, quantifies ambiguity, and significantly reduces confident errors on unanswerable questions by abstaining. Our contribution is a new architecture to mitigate hallucinations and a design paradigm that integrates uncertainty quantification directly into the model, providing a foundation for more reliable AI.</li>
</ul>

<h3>Title: Fairness-Constrained Optimization Attack in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Harsh Kasyap, Minghong Fang, Zhuqing Liu, Carsten Maple, Somanath Tripathy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12143">https://arxiv.org/abs/2510.12143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12143">https://arxiv.org/pdf/2510.12143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12143]] Fairness-Constrained Optimization Attack in Federated Learning(https://arxiv.org/abs/2510.12143)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a privacy-preserving machine learning technique that facilitates collaboration among participants across demographics. FL enables model sharing, while restricting the movement of data. Since FL provides participants with independence over their training data, it becomes susceptible to poisoning attacks. Such collaboration also propagates bias among the participants, even unintentionally, due to different data distribution or historical bias present in the data. This paper proposes an intentional fairness attack, where a client maliciously sends a biased model, by increasing the fairness loss while training, even considering homogeneous data distribution. The fairness loss is calculated by solving an optimization problem for fairness metrics such as demographic parity and equalized odds. The attack is insidious and hard to detect, as it maintains global accuracy even after increasing the bias. We evaluate our attack against the state-of-the-art Byzantine-robust and fairness-aware aggregation schemes over different datasets, in various settings. The empirical results demonstrate the attack efficacy by increasing the bias up to 90\%, even in the presence of a single malicious client in the FL system.</li>
</ul>

<h3>Title: VeilAudit: Breaking the Deadlock Between Privacy and Accountability Across Blockchains</h3>
<ul>
<li><strong>Authors: </strong>Minhao Qiao, Iqbal Gondal, Hai Dong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12153">https://arxiv.org/abs/2510.12153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12153">https://arxiv.org/pdf/2510.12153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12153]] VeilAudit: Breaking the Deadlock Between Privacy and Accountability Across Blockchains(https://arxiv.org/abs/2510.12153)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Cross chain interoperability in blockchain systems exposes a fundamental tension between user privacy and regulatory accountability. Existing solutions enforce an all or nothing choice between full anonymity and mandatory identity disclosure, which limits adoption in regulated financial settings. We present VeilAudit, a cross chain auditing framework that introduces Auditor Only Linkability, which allows auditors to link transaction behaviors that originate from the same anonymous entity without learning its identity. VeilAudit achieves this with a user generated Linkable Audit Tag that embeds a zero knowledge proof to attest to its validity without exposing the user master wallet address, and with a special ciphertext that only designated auditors can test for linkage. To balance privacy and compliance, VeilAudit also supports threshold gated identity revelation under due process. VeilAudit further provides a mechanism for building reputation in pseudonymous environments, which enables applications such as cross chain credit scoring based on verifiable behavioral history. We formalize the security guarantees and develop a prototype that spans multiple EVM chains. Our evaluation shows that the framework is practical for today multichain environments.</li>
</ul>

<h3>Title: Self-Verifying Reflection Helps Transformers with CoT Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhongwei Yu, Wannian Xia, Xue Yan, Bo Xu, Haifeng Zhang, Yali Du, Jun Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12157">https://arxiv.org/abs/2510.12157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12157">https://arxiv.org/pdf/2510.12157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12157]] Self-Verifying Reflection Helps Transformers with CoT Reasoning(https://arxiv.org/abs/2510.12157)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Advanced large language models (LLMs) frequently reflect in reasoning chain-of-thoughts (CoTs), where they self-verify the correctness of current solutions and explore alternatives. However, given recent findings that LLMs detect limited errors in CoTs, how reflection contributes to empirical improvements remains unclear. To analyze this issue, in this paper, we present a minimalistic reasoning framework to support basic self-verifying reflection for small transformers without natural language, which ensures analytic clarity and reduces the cost of comprehensive experiments. Theoretically, we prove that self-verifying reflection guarantees improvements if verification errors are properly bounded. Experimentally, we show that tiny transformers, with only a few million parameters, benefit from self-verification in both training and reflective execution, reaching remarkable LLM-level performance in integer multiplication and Sudoku. Similar to LLM results, we find that reinforcement learning (RL) improves in-distribution performance and incentivizes frequent reflection for tiny transformers, yet RL mainly optimizes shallow statistical patterns without faithfully reducing verification errors. In conclusion, integrating generative transformers with discriminative verification inherently facilitates CoT reasoning, regardless of scaling and natural language.</li>
</ul>

<h3>Title: DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ziyuan Gao, Philippe Morel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12159">https://arxiv.org/abs/2510.12159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12159">https://arxiv.org/pdf/2510.12159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12159]] DPL: Spatial-Conditioned Diffusion Prototype Enhancement for One-Shot Medical Segmentation(https://arxiv.org/abs/2510.12159)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>One-shot medical image segmentation faces fundamental challenges in prototype representation due to limited annotated data and significant anatomical variability across patients. Traditional prototype-based methods rely on deterministic averaging of support features, creating brittle representations that fail to capture intra-class diversity essential for robust generalization. This work introduces Diffusion Prototype Learning (DPL), a novel framework that reformulates prototype construction through diffusion-based feature space exploration. DPL models one-shot prototypes as learnable probability distributions, enabling controlled generation of diverse yet semantically coherent prototype variants from minimal labeled data. The framework operates through three core innovations: (1) a diffusion-based prototype enhancement module that transforms single support prototypes into diverse variant sets via forward-reverse diffusion processes, (2) a spatial-aware conditioning mechanism that leverages geometric properties derived from prototype feature statistics, and (3) a conservative fusion strategy that preserves prototype fidelity while maximizing representational diversity. DPL ensures training-inference consistency by using the same diffusion enhancement and fusion pipeline in both phases. This process generates enhanced prototypes that serve as the final representations for similarity calculations, while the diffusion process itself acts as a regularizer. Extensive experiments on abdominal MRI and CT datasets demonstrate significant improvements respectively, establishing new state-of-the-art performance in one-shot medical image segmentation.</li>
</ul>

<h3>Title: State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jiahuan Zhou, Kai Zhu, Zhenyu Cui, Zichen Liu, Xu Zou, Gang Hua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12160">https://arxiv.org/abs/2510.12160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12160">https://arxiv.org/pdf/2510.12160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12160]] State Space Prompting via Gathering and Spreading Spatio-Temporal Information for Video Understanding(https://arxiv.org/abs/2510.12160)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recently, pre-trained state space models have shown great potential for video classification, which sequentially compresses visual tokens in videos with linear complexity, thereby improving the processing efficiency of video data while maintaining high performance. To apply powerful pre-trained models to downstream tasks, prompt learning is proposed to achieve efficient downstream task adaptation with only a small number of fine-tuned parameters. However, the sequentially compressed visual prompt tokens fail to capture the spatial and temporal contextual information in the video, thus limiting the effective propagation of spatial information within a video frame and temporal information between frames in the state compression model and the extraction of discriminative information. To tackle the above issue, we proposed a State Space Prompting (SSP) method for video understanding, which combines intra-frame and inter-frame prompts to aggregate and propagate key spatiotemporal information in the video. Specifically, an Intra-Frame Gathering (IFG) module is designed to aggregate spatial key information within each frame. Besides, an Inter-Frame Spreading (IFS) module is designed to spread discriminative spatio-temporal information across different frames. By adaptively balancing and compressing key spatio-temporal information within and between frames, our SSP effectively propagates discriminative information in videos in a complementary manner. Extensive experiments on four video benchmark datasets verify that our SSP significantly outperforms existing SOTA methods by 2.76% on average while reducing the overhead of fine-tuning parameters.</li>
</ul>

<h3>Title: A Survey on Parallel Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Wang, Boye Niu, Zipeng Gao, Zhi Zheng, Tong Xu, Linghui Meng, Zhongli Li, Jing Liu, Yilong Chen, Chen Zhu, Hua Wu, Haifeng Wang, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12164">https://arxiv.org/abs/2510.12164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12164">https://arxiv.org/pdf/2510.12164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12164]] A Survey on Parallel Reasoning(https://arxiv.org/abs/2510.12164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>With the increasing capabilities of Large Language Models (LLMs), parallel reasoning has emerged as a new inference paradigm that enhances reasoning robustness by concurrently exploring multiple lines of thought before converging on a final answer. It has become a significant trend to explore parallel reasoning to overcome the fragility of standard sequential methods and improve practical performance. In this paper, we aim to survey and summarize the progress and challenges of parallel reasoning. We first present a formal definition of parallel reasoning and clarify its distinction from related concepts like Chain-of-Thought. Then, we organize and discuss advanced techniques based on a novel taxonomy, including non-interactive reasoning, interactive reasoning, and efficiency-focused decoding strategies. Additionally, we explore various application scenarios, such as solving complex problems and enhancing the reliability of LLM this http URL, we highlight the core challenges of parallel reasoning and suggest potential directions for future research. We hope that our work can provide a useful roadmap for beginners and encourage more research on improving parallel reasoning methods. Related source can be avaliable in this https URL.</li>
</ul>

<h3>Title: Towards Inference-time Scaling for Continuous Space Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Minghan Wang, Thuy-Trang Vu, Ehsan Shareghi, Gholamreza Haffari</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12167">https://arxiv.org/abs/2510.12167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12167">https://arxiv.org/pdf/2510.12167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12167]] Towards Inference-time Scaling for Continuous Space Reasoning(https://arxiv.org/abs/2510.12167)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference-time scaling through multiple sample generation in combination with Process- or Outcome-Reward Model (PRM or ORM) re-ranking has proven effective for text-based reasoning in large language models. This paper investigates whether such established techniques can be successfully adapted to reasoning in the continuous space, using COCONUT (Hao et al. 2024) continuous space reasoning LM as the backbone. We demonstrate the feasibility of generating diverse reasoning paths through dropout-based sampling. Our Pass@N analysis on the generated samples reveals the potential that could enable a significant gain in performance akin to observed gain in the discrete space. However, we highlight unique challenges faced for materializing this gain in the continuous thought space. In particular, working recipes for data generation and training PRM and ORM models in the discrete space unlocks only marginal improvements in the continuous space. Through probing various aspects including geometric properties and trajectory dynamics we identify the underlying reasons that prevent effective discrimination between correct and incorrect reasoning (essential for the functioning of PRM and ORM). Our findings reveal that current limitations stem from the absence of key inductive biases in continuous thought representations. We argue that the training frameworks for continuous reasoning LMs require not only to optimize for accuracy but also to explicitly incorporate inductive biases that could be utilized during inference-time for discrimination of correct and incorrect thoughts.\footnote{Our code and data will be publicly available.}</li>
</ul>

<h3>Title: Leaking Queries On Secure Stream Processing Systems</h3>
<ul>
<li><strong>Authors: </strong>Hung Pham, Viet Vo, Tien Tuan Anh Dinh, Duc Tran, Shuhao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12172">https://arxiv.org/abs/2510.12172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12172">https://arxiv.org/pdf/2510.12172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12172]] Leaking Queries On Secure Stream Processing Systems(https://arxiv.org/abs/2510.12172)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack</a></li>
<li><strong>Abstract: </strong>Stream processing systems are important in modern applications in which data arrive continuously and need to be processed in real time. Because of their resource and scalability requirements, many of these systems run on the cloud, which is considered untrusted. Existing works on securing databases on the cloud focus on protecting the data, and most systems leverage trusted hardware for high performance. However, in stream processing systems, queries are as sensitive as the data because they contain the application logics. We demonstrate that it is practical to extract the queries from stream processing systems that use Intel SGX for securing the execution engine. The attack performed by a malicious cloud provider is based on timing side channels, and it works in two phases. In the offline phase, the attacker profiles the execution time of individual stream operators, based on synthetic data. This phase outputs a model that identifies individual stream operators. In the online phase, the attacker isolates the operators that make up the query, monitors its execution, and recovers the operators using the model in the previous phase. We implement the attack based on popular data stream benchmarks using SecureStream and NEXMark, and demonstrate attack success rates of up to 92%. We further discuss approaches that can harden streaming processing systems against our attacks without incurring high overhead.</li>
</ul>

<h3>Title: From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing</h3>
<ul>
<li><strong>Authors: </strong>Chengrui Xiang, Tengfei Ma, Xiangzheng Fu, Yiping Liu, Bosheng Song, Xiangxiang Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12181">https://arxiv.org/abs/2510.12181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12181">https://arxiv.org/pdf/2510.12181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12181]] From Knowledge to Treatment: Large Language Model Assisted Biomedical Concept Representation for Drug Repurposing(https://arxiv.org/abs/2510.12181)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Drug repurposing plays a critical role in accelerating treatment discovery, especially for complex and rare diseases. Biomedical knowledge graphs (KGs), which encode rich clinical associations, have been widely adopted to support this task. However, existing methods largely overlook common-sense biomedical concept knowledge in real-world labs, such as mechanistic priors indicating that certain drugs are fundamentally incompatible with specific treatments. To address this gap, we propose LLaDR, a Large Language Model-assisted framework for Drug Repurposing, which improves the representation of biomedical concepts within KGs. Specifically, we extract semantically enriched treatment-related textual representations of biomedical entities from large language models (LLMs) and use them to fine-tune knowledge graph embedding (KGE) models. By injecting treatment-relevant knowledge into KGE, LLaDR largely improves the representation of biomedical concepts, enhancing semantic understanding of under-studied or complex indications. Experiments based on benchmarks demonstrate that LLaDR achieves state-of-the-art performance across different scenarios, with case studies on Alzheimer's disease further confirming its robustness and effectiveness. Code is available at this https URL.</li>
</ul>

<h3>Title: BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Youngju Yoo, Seho Kim, Changick Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12182">https://arxiv.org/abs/2510.12182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12182">https://arxiv.org/pdf/2510.12182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12182]] BEEP3D: Box-Supervised End-to-End Pseudo-Mask Generation for 3D Instance Segmentation(https://arxiv.org/abs/2510.12182)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D instance segmentation is crucial for understanding complex 3D environments, yet fully supervised methods require dense point-level annotations, resulting in substantial annotation costs and labor overhead. To mitigate this, box-level annotations have been explored as a weaker but more scalable form of supervision. However, box annotations inherently introduce ambiguity in overlapping regions, making accurate point-to-instance assignment challenging. Recent methods address this ambiguity by generating pseudo-masks through training a dedicated pseudo-labeler in an additional training stage. However, such two-stage pipelines often increase overall training time and complexity, hinder end-to-end optimization. To overcome these challenges, we propose BEEP3D-Box-supervised End-to-End Pseudo-mask generation for 3D instance segmentation. BEEP3D adopts a student-teacher framework, where the teacher model serves as a pseudo-labeler and is updated by the student model via an Exponential Moving Average. To better guide the teacher model to generate precise pseudo-masks, we introduce an instance center-based query refinement that enhances position query localization and leverages features near instance centers. Additionally, we design two novel losses-query consistency loss and masked feature consistency loss-to align semantic and geometric signals between predictions and pseudo-masks. Extensive experiments on ScanNetV2 and S3DIS datasets demonstrate that BEEP3D achieves competitive or superior performance compared to state-of-the-art weakly supervised methods while remaining computationally efficient.</li>
</ul>

<h3>Title: CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jiwan Kim, Kibum Kim, Sangwoo Seo, Chanyoung Park</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12184">https://arxiv.org/abs/2510.12184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12184">https://arxiv.org/pdf/2510.12184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12184]] CompoDistill: Attention Distillation for Compositional Reasoning in Multimodal LLMs(https://arxiv.org/abs/2510.12184)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, efficient Multimodal Large Language Models (MLLMs) have gained significant attention as a solution to their high computational complexity, making them more practical for real-world applications. In this regard, the knowledge distillation (KD) approach has emerged as a promising alternative, which transfers the rich visual and linguistic knowledge from a larger model (teacher) to a smaller model (student). However, we observe that existing KD methods struggle to effectively distill the teacher MLLM's rich visual perception abilities to the student, a challenge that has been largely overlooked in previous studies. Through a systematic analysis, we identify visual attention misalignment between student and teacher as the main cause of this issue. Based on this insight, we propose CompoDistill, a novel KD framework that explicitly aligns the student's visual attention with that of the teacher to enhance the student's visual perception abilities. Our extensive experiments show that CompoDistill significantly improves performance on compositional reasoning tasks that require visual perception abilities while maintaining strong performance on visual question answering tasks, as done in existing studies. Furthermore, CompoDistill demonstrates effectiveness with a more advanced backbone, highlighting its generalizability.</li>
</ul>

<h3>Title: Not in Sync: Unveiling Temporal Bias in Audio Chat Models</h3>
<ul>
<li><strong>Authors: </strong>Jiayu Yao, Shenghua Liu, Yiwei Wang, Rundong Cheng, Lingrui Mei, Baolong Bi, Zhen Xiong, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12185">https://arxiv.org/abs/2510.12185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12185">https://arxiv.org/pdf/2510.12185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12185]] Not in Sync: Unveiling Temporal Bias in Audio Chat Models(https://arxiv.org/abs/2510.12185)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Audio Language Models (LALMs) are increasingly applied to audio understanding and multimodal reasoning, yet their ability to locate when events occur remains underexplored. We present the first systematic study of temporal bias in LALMs, revealing a key limitation in their timestamp prediction. For example, when asked "At which second does the lecturer introduce the key formula?", models often predict timestamps that are consistently earlier or later than the ground truth. Through controlled experiments on timestamped datasets, we find that temporal bias (i) is prevalent across datasets and models, (ii) increases with audio length - even accumulating to tens of seconds in extended recordings, and (iii) varies across event types and positions. We quantify this effect with the Temporal Bias Index (TBI), measuring systematic misalignment in predicted event timings, and complement it with a visualization framework. Our findings highlight a fundamental limitation in current LALMs and call for the development of temporally robust architectures.</li>
</ul>

<h3>Title: DPO-Tuned Large Language Models for Segmentation in Simultaneous Speech Translation</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Yang, Satoshi Nakamura</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12195">https://arxiv.org/abs/2510.12195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12195">https://arxiv.org/pdf/2510.12195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12195]] DPO-Tuned Large Language Models for Segmentation in Simultaneous Speech Translation(https://arxiv.org/abs/2510.12195)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Simultaneous speech translation requires accurate segmentation to balance translation quality and latency. Recent studies such as SHAS have introduced pretrained segmentation models, achieving stronger performance than heuristic rules. However, segmentation models such as SHAS, though pretrained and more robust than heuristic methods, are still constrained by supervised learning objectives and do not incorporate human preference alignment, which is crucial for natural real-time interpretation. In this work, we propose a segmentation framework based on large language models (LLMs) trained with Direct Preference Optimization (DPO). By leveraging preference alignment, our method enables LLMs to predict natural segmentation points that better meet the demands of real-time translation. We evaluate the system on the ACL 60/60 corpus across three language pairs (English-Japanese, Chinese, German), using SeamlessM4T v2 as the translation backbone. Experimental results show that our DPO-tuned LLM achieves higher segmentation accuracy than SHAS and yields consistent improvements in translation quality (BLEU, COMET) as well as latency (Average Lagging). Furthermore, our system benefits from IWSLT baselines for direct comparison. These findings highlight the potential of preference-tuned LLMs to surpass existing pretrained segmentation models and advance adaptive, human-aligned simultaneous interpretation.</li>
</ul>

<h3>Title: HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application Vulnerabilities</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxue Ren, Penghao Jiang, Kaixin Li, Zhiyong Huang, Xiaoning Du, Jiaojiao Jiang, Zhenchang Xing, Jiamou Sun, Terry Yue Zhuo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12200">https://arxiv.org/abs/2510.12200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12200">https://arxiv.org/pdf/2510.12200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12200]] HackWorld: Evaluating Computer-Use Agents on Exploiting Web Application Vulnerabilities(https://arxiv.org/abs/2510.12200)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Web applications are prime targets for cyberattacks as gateways to critical services and sensitive data. Traditional penetration testing is costly and expertise-intensive, making it difficult to scale with the growing web ecosystem. While language model agents show promise in cybersecurity, modern web applications demand visual understanding, dynamic content handling, and multi-step interactions that only computer-use agents (CUAs) can perform. Yet, their ability to discover and exploit vulnerabilities through graphical interfaces remains largely unexplored. We present HackWorld, the first framework for systematically evaluating CUAs' capabilities to exploit web application vulnerabilities via visual interaction. Unlike sanitized benchmarks, HackWorld includes 36 real-world applications across 11 frameworks and 7 languages, featuring realistic flaws such as injection vulnerabilities, authentication bypasses, and unsafe input handling. Using a Capture-the-Flag (CTF) setup, it tests CUAs' capacity to identify and exploit these weaknesses while navigating complex web interfaces. Evaluation of state-of-the-art CUAs reveals concerning trends: exploitation rates below 12% and low cybersecurity awareness. CUAs often fail at multi-step attack planning and misuse security tools. These results expose the current limitations of CUAs in web security contexts and highlight opportunities for developing more security-aware agents capable of effective vulnerability detection and exploitation.</li>
</ul>

<h3>Title: The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data</h3>
<ul>
<li><strong>Authors: </strong>Muammer Bay, Timo von Marcard, Dren Fazlija</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12208">https://arxiv.org/abs/2510.12208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12208">https://arxiv.org/pdf/2510.12208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12208]] The Impact of Synthetic Data on Object Detection Model Performance: A Comparative Analysis with Real-World Data(https://arxiv.org/abs/2510.12208)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative AI, particularly in computer vision (CV), offer new opportunities to optimize workflows across industries, including logistics and manufacturing. However, many AI applications are limited by a lack of expertise and resources, which forces a reliance on general-purpose models. Success with these models often requires domain-specific data for fine-tuning, which can be costly and inefficient. Thus, using synthetic data for fine-tuning is a popular, cost-effective alternative to gathering real-world data. This work investigates the impact of synthetic data on the performance of object detection models, compared to models trained on real-world data only, specifically within the domain of warehouse logistics. To this end, we examined the impact of synthetic data generated using the NVIDIA Omniverse Replicator tool on the effectiveness of object detection models in real-world scenarios. It comprises experiments focused on pallet detection in a warehouse setting, utilizing both real and various synthetic dataset generation strategies. Our findings provide valuable insights into the practical applications of synthetic image data in computer vision, suggesting that a balanced integration of synthetic and real data can lead to robust and efficient object detection models.</li>
</ul>

<h3>Title: DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification</h3>
<ul>
<li><strong>Authors: </strong>Tao Xie, Zexi Tan, Haoyi Xiao, Binbin Sun, Yiqun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12214">https://arxiv.org/abs/2510.12214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12214">https://arxiv.org/pdf/2510.12214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12214]] DE3S: Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification(https://arxiv.org/abs/2510.12214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Early time-series classification (ETSC) in medical applications is crucial for time-sensitive scenarios such as sepsis prediction in intensive care units (ICUs), where a large number of deaths are caused by delayed prediction. ETSC can significantly improve ICU resource utilization efficiency and healthcare precision. However, it faces conflicting goals of accuracy and earliness, with existing methods often trading one for the other, struggling to capture subtle early-stage patterns due to weak initial signals and class imbalance. The key to solve these challenges is to find shapelets, which are discriminative subsequences (or shapes) with high interpretability in time-series classification. This paper proposes Dual-Enhanced Soft-Sparse-Shape Learning for Medical Early Time-Series Classification (DE3S), which introduces a novel Dual-Enhanced Soft-Shape Learning framework to figure out shapelets precisely through three innovations: (1) a comprehensive dual-enhancement strategy combines traditional temporal augmentation with attention-based global temporal enhancement for robust representation learning, (2) an attention-score-based soft shapelet sparsification mechanism dynamically preserves discriminative patterns while aggregating less important shapelets into representative tokens, and (3) a dual-path Mixture of Experts Network (MoE) and Inception modules fusion architecture where MoE performs local learning within shapelets and multi-scale Inception modules capture global patterns across shapelets. The framework employs weighted cross-entropy loss for class imbalance handling and demonstrates robustness on subject-consistency datasets. Extensive experiments on six real-world medical datasets show state-of-the-art performance, with ablation studies confirming component efficacy.</li>
</ul>

<h3>Title: HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment</h3>
<ul>
<li><strong>Authors: </strong>Ali Mekky, Omar El Herraoui, Preslav Nakov, Yuxia Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12217">https://arxiv.org/abs/2510.12217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12217">https://arxiv.org/pdf/2510.12217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12217]] HALF: Harm-Aware LLM Fairness Evaluation Aligned with Deployment(https://arxiv.org/abs/2510.12217)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed across high-impact domains, from clinical decision support and legal analysis to hiring and education, making fairness and bias evaluation before deployment critical. However, existing evaluations lack grounding in real-world scenarios and do not account for differences in harm severity, e.g., a biased decision in surgery should not be weighed the same as a stylistic bias in text summarization. To address this gap, we introduce HALF (Harm-Aware LLM Fairness), a deployment-aligned framework that assesses model bias in realistic applications and weighs the outcomes by harm severity. HALF organizes nine application domains into three tiers (Severe, Moderate, Mild) using a five-stage pipeline. Our evaluation results across eight LLMs show that (1) LLMs are not consistently fair across domains, (2) model size or performance do not guarantee fairness, and (3) reasoning models perform better in medical decision support but worse in education. We conclude that HALF exposes a clear gap between previous benchmarking success and deployment readiness.</li>
</ul>

<h3>Title: DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images</h3>
<ul>
<li><strong>Authors: </strong>Vu Tram Anh Khuong, Luu Tu Nguyen, Thi Bich Phuong Man, Thanh Ha Le, Thi Duyen Ngo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12219">https://arxiv.org/abs/2510.12219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12219">https://arxiv.org/pdf/2510.12219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12219]] DIANet: A Phase-Aware Dual-Stream Network for Micro-Expression Recognition via Dynamic Images(https://arxiv.org/abs/2510.12219)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Micro-expressions are brief, involuntary facial movements that typically last less than half a second and often reveal genuine emotions. Accurately recognizing these subtle expressions is critical for applications in psychology, security, and behavioral analysis. However, micro-expression recognition (MER) remains a challenging task due to the subtle and transient nature of facial cues and the limited availability of annotated data. While dynamic image (DI) representations have been introduced to summarize temporal motion into a single frame, conventional DI-based methods often overlook the distinct characteristics of different temporal phases within a micro-expression. To address this issue, this paper proposes a novel dual-stream framework, DIANet, which leverages phase-aware dynamic images - one encoding the onset-to-apex phase and the other capturing the apex-to-offset phase. Each stream is processed by a dedicated convolutional neural network, and a cross-attention fusion module is employed to adaptively integrate features from both streams based on their contextual relevance. Extensive experiments conducted on three benchmark MER datasets (CASME-II, SAMM, and MMEW) demonstrate that the proposed method consistently outperforms conventional single-phase DI-based approaches. The results highlight the importance of modeling temporal phase information explicitly and suggest a promising direction for advancing MER.</li>
</ul>

<h3>Title: Hierarchical Koopman Diffusion: Fast Generation with Interpretable Diffusion Trajectory</h3>
<ul>
<li><strong>Authors: </strong>Hanru Bai, Weiyang Ding, Difan Zou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12220">https://arxiv.org/abs/2510.12220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12220">https://arxiv.org/pdf/2510.12220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12220]] Hierarchical Koopman Diffusion: Fast Generation with Interpretable Diffusion Trajectory(https://arxiv.org/abs/2510.12220)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved impressive success in high-fidelity image generation but suffer from slow sampling due to their inherently iterative denoising process. While recent one-step methods accelerate inference by learning direct noise-to-image mappings, they sacrifice the interpretability and fine-grained control intrinsic to diffusion dynamics, key advantages that enable applications like editable generation. To resolve this dichotomy, we introduce \textbf{Hierarchical Koopman Diffusion}, a novel framework that achieves both one-step sampling and interpretable generative trajectories. Grounded in Koopman operator theory, our method lifts the nonlinear diffusion dynamics into a latent space where evolution is governed by globally linear operators, enabling closed-form trajectory solutions. This formulation not only eliminates iterative sampling but also provides full access to intermediate states, allowing manual intervention during generation. To model the multi-scale nature of images, we design a hierarchical architecture that disentangles generative dynamics across spatial resolutions via scale-specific Koopman subspaces, capturing coarse-to-fine details systematically. We empirically show that the Hierarchical Koopman Diffusion not only achieves competitive one-step generation performance but also provides a principled mechanism for interpreting and manipulating the generative process through spectral analysis. Our framework bridges the gap between fast sampling and interpretability in diffusion models, paving the way for explainable image synthesis in generative modeling.</li>
</ul>

<h3>Title: Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Bianca Raimondi, Daniela Dalbagno, Maurizio Gabbrielli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12229">https://arxiv.org/abs/2510.12229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12229">https://arxiv.org/pdf/2510.12229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12229]] Analysing Moral Bias in Finetuned LLMs through Mechanistic Interpretability(https://arxiv.org/abs/2510.12229)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been shown to internalize human-like biases during finetuning, yet the mechanisms by which these biases manifest remain unclear. In this work, we investigated whether the well-known Knobe effect, a moral bias in intentionality judgements, emerges in finetuned LLMs and whether it can be traced back to specific components of the model. We conducted a Layer-Patching analysis across 3 open-weights LLMs and demonstrated that the bias is not only learned during finetuning but also localized in a specific set of layers. Surprisingly, we found that patching activations from the corresponding pretrained model into just a few critical layers is sufficient to eliminate the effect. Our findings offer new evidence that social biases in LLMs can be interpreted, localized, and mitigated through targeted interventions, without the need for model retraining.</li>
</ul>

<h3>Title: BIGFix: Bidirectional Image Generation with Token Fixing</h3>
<ul>
<li><strong>Authors: </strong>Victor Besnier, David Hurych, Andrei Bursuc, Eduardo Valle</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12231">https://arxiv.org/abs/2510.12231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12231">https://arxiv.org/pdf/2510.12231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12231]] BIGFix: Bidirectional Image Generation with Token Fixing(https://arxiv.org/abs/2510.12231)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in image and video generation have raised significant interest from both academia and industry. A key challenge in this field is improving inference efficiency, as model size and the number of inference steps directly impact the commercial viability of generative models while also posing fundamental scientific challenges. A promising direction involves combining auto-regressive sequential token modeling with multi-token prediction per step, reducing inference time by up to an order of magnitude. However, predicting multiple tokens in parallel can introduce structural inconsistencies due to token incompatibilities, as capturing complex joint dependencies during training remains challenging. Traditionally, once tokens are sampled, there is no mechanism to backtrack and refine erroneous predictions. We propose a method for self-correcting image generation by iteratively refining sampled tokens. We achieve this with a novel training scheme that injects random tokens in the context, improving robustness and enabling token fixing during sampling. Our method preserves the efficiency benefits of parallel token prediction while significantly enhancing generation quality. We evaluate our approach on image generation using the ImageNet-256 and CIFAR-10 datasets, as well as on video generation with UCF-101 and NuScenes, demonstrating substantial improvements across both modalities.</li>
</ul>

<h3>Title: Unveiling the Vulnerability of Graph-LLMs: An Interpretable Multi-Dimensional Adversarial Attack on TAGs</h3>
<ul>
<li><strong>Authors: </strong>Bowen Fan, Zhilin Guo, Xunkai Li, Yihan Zhou, Bing Zhou, Zhenjun Li, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12233">https://arxiv.org/abs/2510.12233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12233">https://arxiv.org/pdf/2510.12233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12233]] Unveiling the Vulnerability of Graph-LLMs: An Interpretable Multi-Dimensional Adversarial Attack on TAGs(https://arxiv.org/abs/2510.12233)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have become a pivotal framework for modeling graph-structured data, enabling a wide range of applications from social network analysis to molecular chemistry. By integrating large language models (LLMs), text-attributed graphs (TAGs) enhance node representations with rich textual semantics, significantly boosting the expressive power of graph-based learning. However, this sophisticated synergy introduces critical vulnerabilities, as Graph-LLMs are susceptible to adversarial attacks on both their structural topology and textual attributes. Although specialized attack methods have been designed for each of these aspects, no work has yet unified them into a comprehensive approach. In this work, we propose the Interpretable Multi-Dimensional Graph Attack (IMDGA), a novel human-centric adversarial attack framework designed to orchestrate multi-level perturbations across both graph structure and textual features. IMDGA utilizes three tightly integrated modules to craft attacks that balance interpretability and impact, enabling a deeper understanding of Graph-LLM vulnerabilities. Through rigorous theoretical analysis and comprehensive empirical evaluations on diverse datasets and architectures, IMDGA demonstrates superior interpretability, attack effectiveness, stealthiness, and robustness compared to existing methods. By exposing critical weaknesses in TAG representation learning, this work uncovers a previously underexplored semantic dimension of vulnerability in Graph-LLMs, offering valuable insights for improving their resilience. Our code and resources are publicly available at this https URL.</li>
</ul>

<h3>Title: Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuehui Li, Yahao Lu, Haoyuan Wu, Sen Zhang, Liang Lin, Yukai Shi</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12241">https://arxiv.org/abs/2510.12241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12241">https://arxiv.org/pdf/2510.12241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12241]] Ivan-ISTD: Rethinking Cross-domain Heteroscedastic Noise Perturbations in Infrared Small Target Detection(https://arxiv.org/abs/2510.12241)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the multimedia domain, Infrared Small Target Detection (ISTD) plays a important role in drone-based multi-modality sensing. To address the dual challenges of cross-domain shift and heteroscedastic noise perturbations in ISTD, we propose a doubly wavelet-guided Invariance learning framework(Ivan-ISTD). In the first stage, we generate training samples aligned with the target domain using Wavelet-guided Cross-domain Synthesis. This wavelet-guided alignment machine accurately separates the target background through multi-frequency wavelet filtering. In the second stage, we introduce Real-domain Noise Invariance Learning, which extracts real noise characteristics from the target domain to build a dynamic noise library. The model learns noise invariance through self-supervised loss, thereby overcoming the limitations of distribution bias in traditional artificial noise modeling. Finally, we create the Dynamic-ISTD Benchmark, a cross-domain dynamic degradation dataset that simulates the distribution shifts encountered in real-world applications. Additionally, we validate the versatility of our method using other real-world datasets. Experimental results demonstrate that our approach outperforms existing state-of-the-art methods in terms of many quantitative metrics. In particular, Ivan-ISTD demonstrates excellent robustness in cross-domain scenarios. The code for this work can be found at: this https URL.</li>
</ul>

<h3>Title: MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant</h3>
<ul>
<li><strong>Authors: </strong>Tao Yin, Xiaohong Zhang, Jiacheng Zhang, Li Huang, Zhibin Zhang, Yuansong Zeng, Jin Xie, Meng Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12245">https://arxiv.org/abs/2510.12245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12245">https://arxiv.org/pdf/2510.12245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12245]] MoRA: On-the-fly Molecule-aware Low-Rank Adaptation Framework for LLM-based Multi-Modal Molecular Assistant(https://arxiv.org/abs/2510.12245)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effectively integrating molecular graph structures with Large Language Models (LLMs) is a key challenge in drug discovery. Most existing multi-modal alignment methods typically process these structures by fine-tuning the LLM or adding a static adapter simultaneously. However, these approaches have two main limitations: (1) it optimizes a shared parameter space across all molecular inputs, limiting the model's ability to capture instance-specific structural features; and (2) fine-tuning the LLM for molecular tasks can lead to catastrophic forgetting, undermining its general reasoning capabilities. In this paper, instead of static task-oriented adaptation, we propose an instance-specific parameter space alignment approach for each molecule on-the-fly. To this end, we introduce Molecule-aware Low-Rank Adaptation (MoRA) that produces a unique set of low-rank adaptation weights for each input molecular graph. These weights are then dynamically injected into a frozen LLM, allowing the model to adapt its reasoning to the structure of each molecular input, while preserving the LLM's core knowledge. Extensive experiments demonstrate that on key molecular tasks, such as chemical reaction prediction and molecular captioning, MoRA's instance-specific dynamic adaptation outperforms statically adapted baselines, including a 14.1% relative improvement in reaction prediction exact match and a 22% reduction in error for quantum property prediction. The code is available at this https URL.</li>
</ul>

<h3>Title: DSAS: A Universal Plug-and-Play Framework for Attention Optimization in Multi-Document Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Jiakai Li, Rongzheng Wang, Yizhuo Ma, Shuang Liang, Guangchun Luo, Ke Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12251">https://arxiv.org/abs/2510.12251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12251">https://arxiv.org/pdf/2510.12251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12251]] DSAS: A Universal Plug-and-Play Framework for Attention Optimization in Multi-Document Question Answering(https://arxiv.org/abs/2510.12251)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) show considerable promise across various fields, they have notable limitations in handling multi-document question answering (Multi-doc QA) tasks. The first challenge is long-range dependency modeling, where LLMs struggle to focus on key information in long texts, which weakens important semantic connections. Second, most LLMs suffer from the ''lost-in-the-middle'' issue, where they have difficulty processing information in the middle of long inputs. Current solutions either truncate global dependencies or demand costly finetuning, ultimately lacking a universal and simple solution for these challenges. To resolve these limitations, we propose Dual-Stage Adaptive Sharpening (DSAS) containing two modules. (i) The Contextual Gate Weighting (CGW) module alleviates ''lost-in-the-middle'' by assessing paragraph relevance through layer-wise attention tracking and position-aware weighting. (ii) The Reciprocal Attention Suppression (RAS) module enhances focus on critical paragraphs by suppressing information exchange between key and irrelevant texts, thus mitigating the limitations in long-range dependency modeling. Notably, DSAS functions as a plug-and-play solution requiring no architectural modifications or extra training parameters. Extensive experiments on four benchmarks demonstrate DSAS's efficacy across mainstream LLMs (Llama, Qwen, Mistral, and Deepseek), with an average F1-score improvement of 4.2% in Multi-doc QA tasks on Llama-3.1-8B-Instruct and Qwen2.5-14B-Instruct. Ablation studies confirm the essential contributions of both the CGW and RAS modules. In addition, detailed discussions in the Appendix further validate the robustness and scalability of DSAS.</li>
</ul>

<h3>Title: PromptLocate: Localizing Prompt Injection Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Jia, Yupei Liu, Zedian Shao, Jinyuan Jia, Neil Gong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12252">https://arxiv.org/abs/2510.12252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12252">https://arxiv.org/pdf/2510.12252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12252]] PromptLocate: Localizing Prompt Injection Attacks(https://arxiv.org/abs/2510.12252)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Prompt injection attacks deceive a large language model into completing an attacker-specified task instead of its intended task by contaminating its input data with an injected prompt, which consists of injected instruction(s) and data. Localizing the injected prompt within contaminated data is crucial for post-attack forensic analysis and data recovery. Despite its growing importance, prompt injection localization remains largely unexplored. In this work, we bridge this gap by proposing PromptLocate, the first method for localizing injected prompts. PromptLocate comprises three steps: (1) splitting the contaminated data into semantically coherent segments, (2) identifying segments contaminated by injected instructions, and (3) pinpointing segments contaminated by injected data. We show PromptLocate accurately localizes injected prompts across eight existing and eight adaptive attacks.</li>
</ul>

<h3>Title: Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development</h3>
<ul>
<li><strong>Authors: </strong>Changfu Xu, Jianxiong Guo, Yuzhu Liang, Haiyang Huang, Haodong Zou, Xi Zheng, Shui Yu, Xiaowen Chu, Jiannong Cao, Tian Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12253">https://arxiv.org/abs/2510.12253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12253">https://arxiv.org/pdf/2510.12253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12253]] Diffusion Models for Reinforcement Learning: Foundations, Taxonomy, and Development(https://arxiv.org/abs/2510.12253)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion Models (DMs), as a leading class of generative models, offer key advantages for reinforcement learning (RL), including multi-modal expressiveness, stable training, and trajectory-level planning. This survey delivers a comprehensive and up-to-date synthesis of diffusion-based RL. We first provide an overview of RL, highlighting its challenges, and then introduce the fundamental concepts of DMs, investigating how they are integrated into RL frameworks to address key challenges in this research field. We establish a dual-axis taxonomy that organizes the field along two orthogonal dimensions: a function-oriented taxonomy that clarifies the roles DMs play within the RL pipeline, and a technique-oriented taxonomy that situates implementations across online versus offline learning regimes. We also provide a comprehensive examination of this progression from single-agent to multi-agent domains, thereby forming several frameworks for DM-RL integration and highlighting their practical utility. Furthermore, we outline several categories of successful applications of diffusion-based RL across diverse domains, discuss open research issues of current methodologies, and highlight key directions for future research to advance the field. Finally, we summarize the survey to identify promising future development directions. We are actively maintaining a GitHub repository (this https URL) for papers and other related resources to apply DMs for RL.</li>
</ul>

<h3>Title: FedMMKT:Co-Enhancing a Server Text-to-Image Model and Client Task Models in Multi-Modal Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Ningxin He, Yang Liu, Wei Sun, Xiaozhou Ye, Ye Ouyang, Tiegang Gao, Zehui Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12254">https://arxiv.org/abs/2510.12254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12254">https://arxiv.org/pdf/2510.12254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12254]] FedMMKT:Co-Enhancing a Server Text-to-Image Model and Client Task Models in Multi-Modal Federated Learning(https://arxiv.org/abs/2510.12254)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Text-to-Image (T2I) models have demonstrated their versatility in a wide range of applications. However, adaptation of T2I models to specialized tasks is often limited by the availability of task-specific data due to privacy concerns. On the other hand, harnessing the power of rich multimodal data from modern mobile systems and IoT infrastructures presents a great opportunity. This paper introduces Federated Multi-modal Knowledge Transfer (FedMMKT), a novel framework that enables co-enhancement of a server T2I model and client task-specific models using decentralized multimodal data without compromising data privacy.</li>
</ul>

<h3>Title: Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs</h3>
<ul>
<li><strong>Authors: </strong>Blazej Manczak, Eric Lin, Francisco Eiras, James O' Neill, Vaikkunth Mugunthan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12255">https://arxiv.org/abs/2510.12255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12255">https://arxiv.org/pdf/2510.12255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12255]] Shallow Robustness, Deep Vulnerabilities: Multi-Turn Evaluation of Medical LLMs(https://arxiv.org/abs/2510.12255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are rapidly transitioning into medical clinical use, yet their reliability under realistic, multi-turn interactions remains poorly understood. Existing evaluation frameworks typically assess single-turn question answering under idealized conditions, overlooking the complexities of medical consultations where conflicting input, misleading context, and authority influence are common. We introduce MedQA-Followup, a framework for systematically evaluating multi-turn robustness in medical question answering. Our approach distinguishes between shallow robustness (resisting misleading initial context) and deep robustness (maintaining accuracy when answers are challenged across turns), while also introducing an indirect-direct axis that separates contextual framing (indirect) from explicit suggestion (direct). Using controlled interventions on the MedQA dataset, we evaluate five state-of-the-art LLMs and find that while models perform reasonably well under shallow perturbations, they exhibit severe vulnerabilities in multi-turn settings, with accuracy dropping from 91.2% to as low as 13.5% for Claude Sonnet 4. Counterintuitively, indirect, context-based interventions are often more harmful than direct suggestions, yielding larger accuracy drops across models and exposing a significant vulnerability for clinical deployment. Further compounding analyses reveal model differences, with some showing additional performance drops under repeated interventions while others partially recovering or even improving. These findings highlight multi-turn robustness as a critical but underexplored dimension for safe and reliable deployment of medical LLMs.</li>
</ul>

<h3>Title: Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images</h3>
<ul>
<li><strong>Authors: </strong>Yuto Yokoi, Kazuhiro Hotta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12258">https://arxiv.org/abs/2510.12258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12258">https://arxiv.org/pdf/2510.12258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12258]] Multiplicative Loss for Enhancing Semantic Segmentation in Medical and Cellular Images(https://arxiv.org/abs/2510.12258)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, segmentation</a></li>
<li><strong>Abstract: </strong>We propose two novel loss functions, Multiplicative Loss and Confidence-Adaptive Multiplicative Loss, for semantic segmentation in medical and cellular images. Although Cross Entropy and Dice Loss are widely used, their additive combination is sensitive to hyperparameters and often performs suboptimally, especially with limited data. Medical images suffer from data scarcity due to privacy, ethics, and costly annotations, requiring robust and efficient training objectives. Our Multiplicative Loss combines Cross Entropy and Dice losses multiplicatively, dynamically modulating gradients based on prediction confidence. This reduces penalties for confident correct predictions and amplifies gradients for incorrect overconfident ones, stabilizing optimization. Building on this, Confidence-Adaptive Multiplicative Loss applies a confidence-driven exponential scaling inspired by Focal Loss, integrating predicted probabilities and Dice coefficients to emphasize difficult samples. This enhances learning under extreme data scarcity by strengthening gradients when confidence is low. Experiments on cellular and medical segmentation benchmarks show our framework consistently outperforms tuned additive and existing loss functions, offering a simple, effective, and hyperparameter-free mechanism for robust segmentation under challenging data limitations.</li>
</ul>

<h3>Title: HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Han, Huanyu Wang, Zeyu Zhang, Xiangxiang Dai, Xutong Liu, John C.S. Lui</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12266">https://arxiv.org/abs/2510.12266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12266">https://arxiv.org/pdf/2510.12266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12266]] HiLoRA: Adaptive Hierarchical LoRA Routing for Training-Free Domain Generalization(https://arxiv.org/abs/2510.12266)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) has emerged as a widely used technique for adapting large language models (LLMs) to new domains, due to its modular design and broad availability on platforms such as HuggingFace. This availability has motivated efforts to reuse existing LoRAs for domain generalization. However, existing methods often rely on explicit task labels or additional training, which are impractical for deployment. Moreover, they typically activate a fixed number of entire LoRA modules, leading to parameter redundancy or insufficiency that degrade performance. In this paper, we propose \texttt{HiLoRA}, a training-free framework that performs adaptive hierarchical routing over LoRA pools. Drawing on structural properties of LoRA, we define rank-one components (ROCs), in which each rank parameter is regarded as an independent unit. For a given input sequence, \texttt{HiLoRA} first adaptively selects a subset of LoRAs and determines their ROC allocation based on Gaussian likelihoods at the sequence level. At the token level, it further refines routing by activating only the most informative ROCs. We further provide theoretical guarantees that \texttt{HiLoRA} selects the most relevant LoRAs with high probability. Extensive experiments show that \texttt{HiLoRA} achieves substantial improvements in domain generalization, with accuracy gains of up to {\small $55\%$} over state-of-the-art baselines, while maintaining comparable inference throughput.</li>
</ul>

<h3>Title: SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis</h3>
<ul>
<li><strong>Authors: </strong>Chenghanyu Zhang, Zekun Li, Peipei Li, Xing Cui, Shuhan Xia, Weixiang Yan, Yiqiao Zhang, Qianyu Zhuang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12267">https://arxiv.org/abs/2510.12267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12267">https://arxiv.org/pdf/2510.12267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12267]] SpineBench: Benchmarking Multimodal LLMs for Spinal Pathology Analysis(https://arxiv.org/abs/2510.12267)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the increasing integration of Multimodal Large Language Models (MLLMs) into the medical field, comprehensive evaluation of their performance in various medical domains becomes critical. However, existing benchmarks primarily assess general medical tasks, inadequately capturing performance in nuanced areas like the spine, which relies heavily on visual input. To address this, we introduce SpineBench, a comprehensive Visual Question Answering (VQA) benchmark designed for fine-grained analysis and evaluation of MLLMs in the spinal domain. SpineBench comprises 64,878 QA pairs from 40,263 spine images, covering 11 spinal diseases through two critical clinical tasks: spinal disease diagnosis and spinal lesion localization, both in multiple-choice format. SpineBench is built by integrating and standardizing image-label pairs from open-source spinal disease datasets, and samples challenging hard negative options for each VQA pair based on visual similarity (similar but not the same disease), simulating real-world challenging scenarios. We evaluate 12 leading MLLMs on SpineBench. The results reveal that these models exhibit poor performance in spinal tasks, highlighting limitations of current MLLM in the spine domain and guiding future improvements in spinal medicine applications. SpineBench is publicly available at this https URL.</li>
</ul>

<h3>Title: Chinese ModernBERT with Whole-Word Masking</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Zhao, Ningtao Wang, Xing Fu, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12285">https://arxiv.org/abs/2510.12285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12285">https://arxiv.org/pdf/2510.12285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12285]] Chinese ModernBERT with Whole-Word Masking(https://arxiv.org/abs/2510.12285)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Encoder-only Transformers have advanced along three axes -- architecture, data, and systems -- yielding Pareto gains in accuracy, speed, and memory efficiency. Yet these improvements have not fully transferred to Chinese, where tokenization and morphology differ markedly from English. We introduce Chinese ModernBERT, a from-scratch Chinese encoder that couples: (i) a hardware-aware 32k BPE vocabulary tailored to frequent Chinese affixes/compounds, lowering the embedding budget; (ii) whole-word masking (WWM) with a dynamic masking curriculum (30% -> 15%) to align task difficulty with training progress; (iii) a two-stage pre-training pipeline that extends the native context from 1,024 to 8,192 tokens using RoPE and alternating local/global attention; and (iv) a damped-cosine learning-rate schedule for stable long-horizon optimization. We pre-train on ~1.2T Chinese tokens from CCI3-HQ, CCI4 (Chinese), and Cosmopedia-Chinese. On CLUE, Chinese ModernBERT is competitive with strong Chinese encoders under a unified fine-tuning protocol. Under bf16 it achieves high long-sequence throughput while maintaining strong short-sequence speed, reflecting benefits from budget allocation and attention design. To probe retrieval-oriented quality, we add a small amount of open contrastive data: fine-tuning on SimCLUE (~3M pairs) improves further when adding T2Ranking (~2M), reaching 0.505 (Pearson) / 0.537 (Spearman) on the SimCLUE test set. Under this open-data setting, Chinese ModernBERT surpasses Qwen-0.6B-embedding on SimCLUE, suggesting a clear scaling path for STS with additional curated pairs. We will release tokenizer and weights to facilitate reproducible research.</li>
</ul>

<h3>Title: Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector</h3>
<ul>
<li><strong>Authors: </strong>Sifan Li, Hongkai Chen, Yujun Cai, Qingwen Ye, Liyang Chen, Junsong Yuan, Yiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12287">https://arxiv.org/abs/2510.12287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12287">https://arxiv.org/pdf/2510.12287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12287]] Vision Language Models Map Logos to Text via Semantic Entanglement in the Visual Projector(https://arxiv.org/abs/2510.12287)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision Language Models (VLMs) have achieved impressive progress in multimodal reasoning; yet, they remain vulnerable to hallucinations, where outputs are not grounded in visual evidence. In this paper, we investigate a previously overlooked setting: logo hallucination, where models generate brand names or textual content despite logos containing no visible words. Using curated splits of pure symbols, hybrids, and text-bearing logos, as well as the challenging Hard-60 subset, we systematically measure hallucination across leading VLMs. We further probe robustness through nine structured perturbations and show that hallucinations persist even under strong distortions, with occlusion exposing the sharpest weaknesses. Embedding-level analysis with open-weight LLaVA demonstrates that hallucination is tied to a small subset of projector dimensions, and targeted ablation substantially reduces errors while preserving OCR accuracy. Together, these findings reveal that VLMs often rely on symbolic priors rather than genuine glyph perception, particularly for iconic circular logos, and that projector subspaces play a decisive role in this failure mode. Our work contributes both a novel diagnostic lens and actionable mitigation insights, highlighting projector disentanglement and OCR-guided decoding as promising directions for building more trustworthy multimodal systems.</li>
</ul>

<h3>Title: A large-scale, unsupervised pipeline for automatic corpus annotation using LLMs: variation and change in the English consider construction</h3>
<ul>
<li><strong>Authors: </strong>Cameron Morin, Matti Marttinen Larsson</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12306">https://arxiv.org/abs/2510.12306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12306">https://arxiv.org/pdf/2510.12306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12306]] A large-scale, unsupervised pipeline for automatic corpus annotation using LLMs: variation and change in the English consider construction(https://arxiv.org/abs/2510.12306)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As natural language corpora expand at an unprecedented rate, manual annotation remains a significant methodological bottleneck in corpus linguistic work. We address this challenge by presenting a scalable, unsupervised pipeline for automating grammatical annotation in voluminous corpora using large language models (LLMs). Unlike previous supervised and iterative approaches, our method employs a four-phase workflow: prompt engineering, pre-hoc evaluation, automated batch processing, and post-hoc validation. We demonstrate the pipeline's accessibility and effectiveness through a diachronic case study of variation in the English consider construction. Using GPT-5 through the OpenAI API, we annotate 143,933 sentences from the Corpus of Historical American English (COHA) in under 60 hours, achieving 98%+ accuracy on two sophisticated annotation procedures. Our results suggest that LLMs can perform a range of data preparation tasks at scale with minimal human intervention, opening new possibilities for corpus-based research, though implementation requires attention to costs, licensing, and other ethical considerations.</li>
</ul>

<h3>Title: Hybrid Gaussian Splatting for Novel Urban View Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Omran, Farhad Zanjani, Davide Abati, Jens Petersen, Amirhossein Habibian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12308">https://arxiv.org/abs/2510.12308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12308">https://arxiv.org/pdf/2510.12308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12308]] Hybrid Gaussian Splatting for Novel Urban View Synthesis(https://arxiv.org/abs/2510.12308)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper describes the Qualcomm AI Research solution to the RealADSim-NVS challenge, hosted at the RealADSim Workshop at ICCV 2025. The challenge concerns novel view synthesis in street scenes, and participants are required to generate, starting from car-centric frames captured during some training traversals, renders of the same urban environment as viewed from a different traversal (e.g. different street lane or car direction). Our solution is inspired by hybrid methods in scene generation and generative simulators merging gaussian splatting and diffusion models, and it is composed of two stages: First, we fit a 3D reconstruction of the scene and render novel views as seen from the target cameras. Then, we enhance the resulting frames with a dedicated single-step diffusion model. We discuss specific choices made in the initialization of gaussian primitives as well as the finetuning of the enhancer model and its training data curation. We report the performance of our model design and we ablate its components in terms of novel view quality as measured by PSNR, SSIM and LPIPS. On the public leaderboard reporting test results, our proposal reaches an aggregated score of 0.432, achieving the second place overall.</li>
</ul>

<h3>Title: DeepTrust: Multi-Step Classification through Dissimilar Adversarial Representations for Robust Android Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Daniel Pulido-Cortázar, Daniel Gibert, Felip Manyà</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12310">https://arxiv.org/abs/2510.12310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12310">https://arxiv.org/pdf/2510.12310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12310]] DeepTrust: Multi-Step Classification through Dissimilar Adversarial Representations for Robust Android Malware Detection(https://arxiv.org/abs/2510.12310)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust</a></li>
<li><strong>Abstract: </strong>Over the last decade, machine learning has been extensively applied to identify malicious Android applications. However, such approaches remain vulnerable against adversarial examples, i.e., examples that are subtly manipulated to fool a machine learning model into making incorrect predictions. This research presents DeepTrust, a novel metaheuristic that arranges flexible classifiers, like deep neural networks, into an ordered sequence where the final decision is made by a single internal model based on conditions activated in cascade. In the Robust Android Malware Detection competition at the 2025 IEEE Conference SaTML, DeepTrust secured the first place and achieved state-of-the-art results, outperforming the next-best competitor by up to 266% under feature-space evasion attacks. This is accomplished while maintaining the highest detection rate on non-adversarial malware and a false positive rate below 1%. The method's efficacy stems from maximizing the divergence of the learned representations among the internal models. By using classifiers inducing fundamentally dissimilar embeddings of the data, the decision space becomes unpredictable for an attacker. This frustrates the iterative perturbation process inherent to evasion attacks, enhancing system robustness without compromising accuracy on clean examples.</li>
</ul>

<h3>Title: Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation</h3>
<ul>
<li><strong>Authors: </strong>Greta Damo, Elena Cabrio, Serena Villata</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12316">https://arxiv.org/abs/2510.12316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12316">https://arxiv.org/pdf/2510.12316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12316]] Beating Harmful Stereotypes Through Facts: RAG-based Counter-speech Generation(https://arxiv.org/abs/2510.12316)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Counter-speech generation is at the core of many expert activities, such as fact-checking and hate speech, to counter harmful content. Yet, existing work treats counter-speech generation as pure text generation task, mainly based on Large Language Models or NGO experts. These approaches show severe drawbacks due to the limited reliability and coherence in the generated countering text, and in scalability, respectively. To close this gap, we introduce a novel framework to model counter-speech generation as knowledge-wise text generation process. Our framework integrates advanced Retrieval-Augmented Generation (RAG) pipelines to ensure the generation of trustworthy counter-speech for 8 main target groups identified in the hate speech literature, including women, people of colour, persons with disabilities, migrants, Muslims, Jews, LGBT persons, and other. We built a knowledge base over the United Nations Digital Library, EUR-Lex and the EU Agency for Fundamental Rights, comprising a total of 32,792 texts. We use the MultiTarget-CONAN dataset to empirically assess the quality of the generated counter-speech, both through standard metrics (i.e., JudgeLM) and a human evaluation. Results show that our framework outperforms standard LLM baselines and competitive approach, on both assessments. The resulting framework and the knowledge base pave the way for studying trustworthy and sound counter-speech generation, in hate speech and beyond.</li>
</ul>

<h3>Title: Leveraging Teleconnections with Physics-Informed Graph Attention Networks for Long-Range Extreme Rainfall Forecasting in Thailand</h3>
<ul>
<li><strong>Authors: </strong>Kiattikun Chobtham, Kanoksri Sarinnapakorn, Kritanai Torsri, Prattana Deeprasertkul, Jirawan Kamma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12328">https://arxiv.org/abs/2510.12328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12328">https://arxiv.org/pdf/2510.12328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12328]] Leveraging Teleconnections with Physics-Informed Graph Attention Networks for Long-Range Extreme Rainfall Forecasting in Thailand(https://arxiv.org/abs/2510.12328)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Accurate rainfall forecasting, particularly for extreme events, remains a significant challenge in climatology and the Earth system. This paper presents novel physics-informed Graph Neural Networks (GNNs) combined with extreme-value analysis techniques to improve gauge-station rainfall predictions across Thailand. The model leverages a graph-structured representation of gauge stations to capture complex spatiotemporal patterns, and it offers explainability through teleconnections. We preprocess relevant climate indices that potentially influence regional rainfall. The proposed Graph Attention Network with Long Short-Term Memory (Attention-LSTM) applies the attention mechanism using initial edge features derived from simple orographic-precipitation physics formulation. The embeddings are subsequently processed by LSTM layers. To address extremes, we perform Peak-Over-Threshold (POT) mapping using the novel Spatial Season-aware Generalized Pareto Distribution (GPD) method, which overcomes limitations of traditional machine-learning models. Experiments demonstrate that our method outperforms well-established baselines across most regions, including areas prone to extremes, and remains strongly competitive with the state of the art. Compared with the operational forecasting system SEAS5, our real-world application improves extreme-event prediction and offers a practical enhancement to produce fine-resolution maps that support decision-making in long-term water management.</li>
</ul>

<h3>Title: Traveling Salesman-Based Token Ordering Improves Stability in Homomorphically Encrypted Language Models</h3>
<ul>
<li><strong>Authors: </strong>Donghwan Rho, Sieun Seo, Hyewon Sung, Chohong Min, Ernest K. Ryu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12343">https://arxiv.org/abs/2510.12343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12343">https://arxiv.org/pdf/2510.12343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12343]] Traveling Salesman-Based Token Ordering Improves Stability in Homomorphically Encrypted Language Models(https://arxiv.org/abs/2510.12343)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, large language model</a></li>
<li><strong>Abstract: </strong>As users increasingly interact with large language models (LLMs) using private information, secure and encrypted communication becomes essential. Homomorphic encryption (HE) provides a principled solution by enabling computation directly on encrypted data. Although prior work has explored aspects of running LLMs under HE, the challenge of text generation, particularly next-token prediction, has received limited attention and remains a key obstacle to practical encrypted interaction. In this work, we propose a TSP-based token reordering strategy to address the difficulties of encrypted text generation, together with a post-processing step that further reduces approximation error. Theoretical analysis and experimental results demonstrate that our method prevents collapse, improves coherence in generated text, and preserves data privacy throughout. Overall, our contributions advance the feasibility of practical and privacy-preserving LLM inference.</li>
</ul>

<h3>Title: Fine-grained Analysis of Brain-LLM Alignment through Input Attribution</h3>
<ul>
<li><strong>Authors: </strong>Michela Proietti, Roberto Capobianco, Mariya Toneva</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12355">https://arxiv.org/abs/2510.12355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12355">https://arxiv.org/pdf/2510.12355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12355]] Fine-grained Analysis of Brain-LLM Alignment through Input Attribution(https://arxiv.org/abs/2510.12355)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding the alignment between large language models (LLMs) and human brain activity can reveal computational principles underlying language processing. We introduce a fine-grained input attribution method to identify the specific words most important for brain-LLM alignment, and leverage it to study a contentious research question about brain-LLM alignment: the relationship between brain alignment (BA) and next-word prediction (NWP). Our findings reveal that BA and NWP rely on largely distinct word subsets: NWP exhibits recency and primacy biases with a focus on syntax, while BA prioritizes semantic and discourse-level information with a more targeted recency effect. This work advances our understanding of how LLMs relate to human language processing and highlights differences in feature reliance between BA and NWP. Beyond this study, our attribution method can be broadly applied to explore the cognitive relevance of model predictions in diverse language processing tasks.</li>
</ul>

<h3>Title: MoBiLE: Efficient Mixture-of-Experts Inference on Consumer GPU with Mixture of Big Little Experts</h3>
<ul>
<li><strong>Authors: </strong>Yushu Zhao, Yubin Qin, Yang Wang, Xiaolong Yang, Huiming Han, Shaojun Wei, Yang Hu, Shouyi Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12357">https://arxiv.org/abs/2510.12357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12357">https://arxiv.org/pdf/2510.12357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12357]] MoBiLE: Efficient Mixture-of-Experts Inference on Consumer GPU with Mixture of Big Little Experts(https://arxiv.org/abs/2510.12357)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) models have recently demonstrated exceptional performance across a diverse range of applications. The principle of sparse activation in MoE models facilitates an offloading strategy, wherein active experts are maintained in GPU HBM, while inactive experts are stored in CPU DRAM. The efficacy of this approach, however, is fundamentally constrained by the limited bandwidth of the CPU-GPU interconnect. To mitigate this bottleneck, existing approaches have employed prefetching to accelerate MoE inference. These methods attempt to predict and prefetch the required experts using specially trained modules. Nevertheless, such techniques are often encumbered by significant training overhead and have shown diminished effectiveness on recent MoE models with fine-grained expert segmentation. In this paper, we propose MoBiLE, a plug-and-play offloading-based MoE inference framework with \textit{mixture of big-little experts}. It reduces the number of experts for unimportant tokens to half for acceleration while maintaining full experts for important tokens to guarantee model quality. Further, a dedicated fallback and prefetching mechanism is designed for switching between little and big experts to improve memory efficiency. We evaluate MoBiLE on four typical modern MoE architectures and challenging generative tasks. Our results show that MoBiLE achieves a speedup of 1.60x to 1.72x compared to the baseline on a consumer GPU system, with negligible degradation in accuracy.</li>
</ul>

<h3>Title: CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Jinzhou Lin, Jie Zhou, Wenhao Xu, Rongtao Xu, Changwei Wang, Shunpeng Chen, Kexue Fu, Yihua Shao, Li Guo, Shibiao Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12362">https://arxiv.org/abs/2510.12362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12362">https://arxiv.org/pdf/2510.12362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12362]] CurriFlow: Curriculum-Guided Depth Fusion with Optical Flow-Based Temporal Alignment for 3D Semantic Scene Completion(https://arxiv.org/abs/2510.12362)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic Scene Completion (SSC) aims to infer complete 3D geometry and semantics from monocular images, serving as a crucial capability for camera-based perception in autonomous driving. However, existing SSC methods relying on temporal stacking or depth projection often lack explicit motion reasoning and struggle with occlusions and noisy depth supervision. We propose CurriFlow, a novel semantic occupancy prediction framework that integrates optical flow-based temporal alignment with curriculum-guided depth fusion. CurriFlow employs a multi-level fusion strategy to align segmentation, visual, and depth features across frames using pre-trained optical flow, thereby improving temporal consistency and dynamic object understanding. To enhance geometric robustness, a curriculum learning mechanism progressively transitions from sparse yet accurate LiDAR depth to dense but noisy stereo depth during training, ensuring stable optimization and seamless adaptation to real-world deployment. Furthermore, semantic priors from the Segment Anything Model (SAM) provide category-agnostic supervision, strengthening voxel-level semantic learning and spatial consistency. Experiments on the SemanticKITTI benchmark demonstrate that CurriFlow achieves state-of-the-art performance with a mean IoU of 16.9, validating the effectiveness of our motion-guided and curriculum-aware design for camera-based 3D semantic scene completion.</li>
</ul>

<h3>Title: LLM-REVal: Can We Trust LLM Reviewers Yet?</h3>
<ul>
<li><strong>Authors: </strong>Rui Li, Jia-Chen Gu, Po-Nien Kung, Heming Xia, Junfeng liu, Xiangwen Kong, Zhifang Sui, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12367">https://arxiv.org/abs/2510.12367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12367">https://arxiv.org/pdf/2510.12367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12367]] LLM-REVal: Can We Trust LLM Reviewers Yet?(https://arxiv.org/abs/2510.12367)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has inspired researchers to integrate them extensively into the academic workflow, potentially reshaping how research is practiced and reviewed. While previous studies highlight the potential of LLMs in supporting research and peer review, their dual roles in the academic workflow and the complex interplay between research and review bring new risks that remain largely underexplored. In this study, we focus on how the deep integration of LLMs into both peer-review and research processes may influence scholarly fairness, examining the potential risks of using LLMs as reviewers by simulation. This simulation incorporates a research agent, which generates papers and revises, alongside a review agent, which assesses the submissions. Based on the simulation results, we conduct human annotations and identify pronounced misalignment between LLM-based reviews and human judgments: (1) LLM reviewers systematically inflate scores for LLM-authored papers, assigning them markedly higher scores than human-authored ones; (2) LLM reviewers persistently underrate human-authored papers with critical statements (e.g., risk, fairness), even after multiple revisions. Our analysis reveals that these stem from two primary biases in LLM reviewers: a linguistic feature bias favoring LLM-generated writing styles, and an aversion toward critical statements. These results highlight the risks and equity concerns posed to human authors and academic research if LLMs are deployed in the peer review cycle without adequate caution. On the other hand, revisions guided by LLM reviews yield quality gains in both LLM-based and human evaluations, illustrating the potential of the LLMs-as-reviewers for early-stage researchers and enhancing low-quality papers.</li>
</ul>

<h3>Title: Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling</h3>
<ul>
<li><strong>Authors: </strong>Tim J. Schoonbeek, Shao-Hsuan Hung, Dan Lehman, Hans Onvlee, Jacek Kustra, Peter H.N. de With, Fons van der Sommen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12385">https://arxiv.org/abs/2510.12385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12385">https://arxiv.org/pdf/2510.12385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12385]] Learning to Recognize Correctly Completed Procedure Steps in Egocentric Assembly Videos through Spatio-Temporal Modeling(https://arxiv.org/abs/2510.12385)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Procedure step recognition (PSR) aims to identify all correctly completed steps and their sequential order in videos of procedural tasks. The existing state-of-the-art models rely solely on detecting assembly object states in individual video frames. By neglecting temporal features, model robustness and accuracy are limited, especially when objects are partially occluded. To overcome these limitations, we propose Spatio-Temporal Occlusion-Resilient Modeling for Procedure Step Recognition (STORM-PSR), a dual-stream framework for PSR that leverages both spatial and temporal features. The assembly state detection stream operates effectively with unobstructed views of the object, while the spatio-temporal stream captures both spatial and temporal features to recognize step completions even under partial occlusion. This stream includes a spatial encoder, pre-trained using a novel weakly supervised approach to capture meaningful spatial representations, and a transformer-based temporal encoder that learns how these spatial features relate over time. STORM-PSR is evaluated on the MECCANO and IndustReal datasets, reducing the average delay between actual and predicted assembly step completions by 11.2% and 26.1%, respectively, compared to prior methods. We demonstrate that this reduction in delay is driven by the spatio-temporal stream, which does not rely on unobstructed views of the object to infer completed steps. The code for STORM-PSR, along with the newly annotated MECCANO labels, is made publicly available at this https URL .</li>
</ul>

<h3>Title: Scene Coordinate Reconstruction Priors</h3>
<ul>
<li><strong>Authors: </strong>Wenjing Bian, Axel Barroso-Laguna, Tommaso Cavallari, Victor Adrian Prisacariu, Eric Brachmann</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12387">https://arxiv.org/abs/2510.12387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12387">https://arxiv.org/pdf/2510.12387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12387]] Scene Coordinate Reconstruction Priors(https://arxiv.org/abs/2510.12387)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Scene coordinate regression (SCR) models have proven to be powerful implicit scene representations for 3D vision, enabling visual relocalization and structure-from-motion. SCR models are trained specifically for one scene. If training images imply insufficient multi-view constraints SCR models degenerate. We present a probabilistic reinterpretation of training SCR models, which allows us to infuse high-level reconstruction priors. We investigate multiple such priors, ranging from simple priors over the distribution of reconstructed depth values to learned priors over plausible scene coordinate configurations. For the latter, we train a 3D point cloud diffusion model on a large corpus of indoor scans. Our priors push predicted 3D scene points towards plausible geometry at each training step to increase their likelihood. On three indoor datasets our priors help learning better scene representations, resulting in more coherent scene point clouds, higher registration rates and better camera poses, with a positive effect on down-stream tasks such as novel view synthesis and camera relocalization.</li>
</ul>

<h3>Title: Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Hailay Kidu Teklehaymanot, Wolfgang Nejdl</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12389">https://arxiv.org/abs/2510.12389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12389">https://arxiv.org/pdf/2510.12389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12389]] Tokenization Disparities as Infrastructure Bias: How Subword Systems Create Inequities in LLM Access and Efficiency(https://arxiv.org/abs/2510.12389)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Tokenization disparities pose a significant barrier to achieving equitable access to artificial intelligence across linguistically diverse populations. This study conducts a large-scale cross-linguistic evaluation of tokenization efficiency in over 200 languages to systematically quantify computational inequities in large language models (LLMs). Using a standardized experimental framework, we applied consistent preprocessing and normalization protocols, followed by uniform tokenization through the tiktoken library across all language samples. Comprehensive tokenization statistics were collected using established evaluation metrics, including Tokens Per Sentence (TPS) and Relative Tokenization Cost (RTC), benchmarked against English baselines. Our cross-linguistic analysis reveals substantial and systematic disparities: Latin-script languages consistently exhibit higher tokenization efficiency, while non-Latin and morphologically complex languages incur significantly greater token inflation, often 3-5 times higher RTC ratios. These inefficiencies translate into increased computational costs and reduced effective context utilization for underrepresented languages. Overall, the findings highlight structural inequities in current AI systems, where speakers of low-resource and non-Latin languages face disproportionate computational disadvantages. Future research should prioritize the development of linguistically informed tokenization strategies and adaptive vocabulary construction methods that incorporate typological diversity, ensuring more inclusive and computationally equitable multilingual AI systems.</li>
</ul>

<h3>Title: IP-Augmented Multi-Modal Malicious URL Detection Via Token-Contrastive Representation Enhancement and Multi-Granularity Fusion</h3>
<ul>
<li><strong>Authors: </strong>Ye Tian, Yanqiu Yu, Liangliang Song, Zhiquan Liu, Yanbin Wang, Jianguo Sun</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12395">https://arxiv.org/abs/2510.12395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12395">https://arxiv.org/pdf/2510.12395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12395]] IP-Augmented Multi-Modal Malicious URL Detection Via Token-Contrastive Representation Enhancement and Multi-Granularity Fusion(https://arxiv.org/abs/2510.12395)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Malicious URL detection remains a critical cybersecurity challenge as adversaries increasingly employ sophisticated evasion techniques including obfuscation, character-level perturbations, and adversarial attacks. Although pre-trained language models (PLMs) like BERT have shown potential for URL analysis tasks, three limitations persist in current implementations: (1) inability to effectively model the non-natural hierarchical structure of URLs, (2) insufficient sensitivity to character-level obfuscation, and (3) lack of mechanisms to incorporate auxiliary network-level signals such as IP addresses-all essential for robust detection. To address these challenges, we propose CURL-IP, an advanced multi-modal detection framework incorporating three key innovations: (1) Token-Contrastive Representation Enhancer, which enhances subword token representations through token-aware contrastive learning to produce more discriminative and isotropic embeddings; (2) Cross-Layer Multi-Scale Aggregator, employing hierarchical aggregation of Transformer outputs via convolutional operations and gated MLPs to capture both local and global semantic patterns across layers; and (3) Blockwise Multi-Modal Coupler that decomposes URL-IP features into localized block units and computes cross-modal attention weights at the block level, enabling fine-grained inter-modal interaction. This architecture enables simultaneous preservation of fine-grained lexical cues, contextual semantics, and integration of network-level signals. Our evaluation on large-scale real-world datasets shows the framework significantly outperforms state-of-the-art baselines across binary and multi-class classification tasks.</li>
</ul>

<h3>Title: Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals</h3>
<ul>
<li><strong>Authors: </strong>Masahiro Negishi, Hyunsoo Park, Kinga O. Mastej, Aron Walsh</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12405">https://arxiv.org/abs/2510.12405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12405">https://arxiv.org/pdf/2510.12405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12405]] Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals(https://arxiv.org/abs/2510.12405)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>To address pressing scientific challenges such as climate change, increasingly sophisticated generative artificial intelligence models are being developed that can efficiently sample the large chemical space of possible functional materials. These models can quickly sample new chemical compositions paired with crystal structures. They are typically evaluated using uniqueness and novelty metrics, which depend on a chosen crystal distance function. However, the most prevalent distance function has four limitations: it fails to quantify the degree of similarity between compounds, cannot distinguish compositional difference and structural difference, lacks Lipschitz continuity against shifts in atomic coordinates, and results in a uniqueness metric that is not invariant against the permutation of generated samples. In this work, we propose using two continuous distance functions to evaluate uniqueness and novelty, which theoretically overcome these limitations. Our experiments show that these distances reveal insights missed by traditional distance functions, providing a more reliable basis for evaluating and comparing generative models for inorganic crystals.</li>
</ul>

<h3>Title: Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model</h3>
<ul>
<li><strong>Authors: </strong>Huu Tien Nguyen, Ahmed Karam Eldaly</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12408">https://arxiv.org/abs/2510.12408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12408">https://arxiv.org/pdf/2510.12408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12408]] Low-Field Magnetic Resonance Image Quality Enhancement using a Conditional Flow Matching Model(https://arxiv.org/abs/2510.12408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel framework for image quality transfer based on conditional flow matching (CFM). Unlike conventional generative models that rely on iterative sampling or adversarial objectives, CFM learns a continuous flow between a noise distribution and target data distributions through the direct regression of an optimal velocity field. We evaluate this approach in the context of low-field magnetic resonance imaging (LF-MRI), a rapidly emerging modality that offers affordable and portable scanning but suffers from inherently low signal-to-noise ratio and reduced diagnostic quality. Our framework is designed to reconstruct high-field-like MR images from their corresponding low-field inputs, thereby bridging the quality gap without requiring expensive infrastructure. Experiments demonstrate that CFM not only achieves state-of-the-art performance, but also generalizes robustly to both in-distribution and out-of-distribution data. Importantly, it does so while utilizing significantly fewer parameters than competing deep learning methods. These results underline the potential of CFM as a powerful and scalable tool for MRI reconstruction, particularly in resource-limited clinical environments.</li>
</ul>

<h3>Title: Targeted Pooled Latent-Space Steganalysis Applied to Generative Steganography, with a Fix</h3>
<ul>
<li><strong>Authors: </strong>Etienne Levecque (LIST3N), Aurélien Noirault (CRIStAL), Tomáš Pevný (CTU), Jan Butora (CRIStAL), Patrick Bas (CRIStAL), Rémi Cogranne (LIST3N)</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12414">https://arxiv.org/abs/2510.12414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12414">https://arxiv.org/pdf/2510.12414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12414]] Targeted Pooled Latent-Space Steganalysis Applied to Generative Steganography, with a Fix(https://arxiv.org/abs/2510.12414)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Steganographic schemes dedicated to generated images modify the seed vector in the latent space to embed a message, whereas most steganalysis methods attempt to detect the embedding in the image space. This paper proposes to perform steganalysis in the latent space by modeling the statistical distribution of the norm of the latent vector. Specifically, we analyze the practical security of a scheme proposed by Hu et. al. for latent diffusion models, which is both robust and practically undetectable when steganalysis is performed on generated images. We show that after embedding, the Stego (latent) vector is distributed on a hypersphere while the Cover vector is i.i.d. Gaussian. By going from the image space to the latent space, we show that it is possible to model the norm of the vector in the latent space under the Cover or Stego hypothesis as Gaussian distributions with different variances. A Likelihood Ratio Test is then derived to perform pooled steganalysis. The impact of the potential knowledge of the prompt and the number of diffusion steps, is also studied. Additionally, we also show how, by randomly sampling the norm of the latent vector before generation, the initial Stego scheme becomes undetectable in the latent space.</li>
</ul>

<h3>Title: VideoLucy: Deep Memory Backtracking for Long Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jialong Zuo, Yongtai Deng, Lingdong Kong, Jingkang Yang, Rui Jin, Yiwei Zhang, Nong Sang, Liang Pan, Ziwei Liu, Changxin Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12422">https://arxiv.org/abs/2510.12422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12422">https://arxiv.org/pdf/2510.12422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12422]] VideoLucy: Deep Memory Backtracking for Long Video Understanding(https://arxiv.org/abs/2510.12422)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that agent-based systems leveraging large language models (LLMs) for key information retrieval and integration have emerged as a promising approach for long video understanding. However, these systems face two major challenges. First, they typically perform modeling and reasoning on individual frames, struggling to capture the temporal context of consecutive frames. Second, to reduce the cost of dense frame-level captioning, they adopt sparse frame sampling, which risks discarding crucial information. To overcome these limitations, we propose VideoLucy, a deep memory backtracking framework for long video understanding. Inspired by the human recollection process from coarse to fine, VideoLucy employs a hierarchical memory structure with progressive granularity. This structure explicitly defines the detail level and temporal scope of memory at different hierarchical depths. Through an agent-based iterative backtracking mechanism, VideoLucy systematically mines video-wide, question-relevant deep memories until sufficient information is gathered to provide a confident answer. This design enables effective temporal understanding of consecutive frames while preserving critical details. In addition, we introduce EgoMem, a new benchmark for long video understanding. EgoMem is designed to comprehensively evaluate a model's ability to understand complex events that unfold over time and capture fine-grained details in extremely long videos. Extensive experiments demonstrate the superiority of VideoLucy. Built on open-source models, VideoLucy significantly outperforms state-of-the-art methods on multiple long video understanding benchmarks, achieving performance even surpassing the latest proprietary models such as GPT-4o. Our code and dataset will be made publicly at this https URL</li>
</ul>

<h3>Title: PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangjun Zai, Xingyu Tan, Xiaoyang Wang, Qing Liu, Xiwei Xu, Wenjie Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12434">https://arxiv.org/abs/2510.12434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12434">https://arxiv.org/pdf/2510.12434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12434]] PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation(https://arxiv.org/abs/2510.12434)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Knowledge Hypergraphs (KHs) have recently emerged as a knowledge representation for retrieval-augmented generation (RAG), offering a paradigm to model multi-entity relations into a structured form. However, existing KH-based RAG methods suffer from three major limitations: static retrieval planning, non-adaptive retrieval execution, and superficial use of KH structure and semantics, which constrain their ability to perform effective multi-hop question answering. To overcome these limitations, we propose PRoH, a dynamic Planning and Reasoning over Knowledge Hypergraphs framework. PRoH incorporates three core innovations: (i) a context-aware planning module that sketches the local KH neighborhood to guide structurally grounded reasoning plan generation; (ii) a structured question decomposition process that organizes subquestions as a dynamically evolving Directed Acyclic Graph (DAG) to enable adaptive, multi-trajectory exploration; and (iii) an Entity-Weighted Overlap (EWO)-guided reasoning path retrieval algorithm that prioritizes semantically coherent hyperedge traversals. Experiments across multiple domains demonstrate that PRoH achieves state-of-the-art performance, surpassing the prior SOTA model HyperGraphRAG by an average of 19.73% in F1 and 8.41% in Generation Evaluation (G-E) score, while maintaining strong robustness in long-range multi-hop reasoning tasks.</li>
</ul>

<h3>Title: Formal Models and Convergence Analysis for Context-Aware Security Verification</h3>
<ul>
<li><strong>Authors: </strong>Ayush Chaudhary</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12440">https://arxiv.org/abs/2510.12440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12440">https://arxiv.org/pdf/2510.12440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12440]] Formal Models and Convergence Analysis for Context-Aware Security Verification(https://arxiv.org/abs/2510.12440)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We present a formal framework for context-aware security verification that establishes provable guarantees for ML-enhanced adaptive systems. We introduce context-completeness - a new security property - and prove: (1) sample complexity bounds showing when adaptive verification succeeds, (2) information-theoretic limits relating context richness to detection capability, (3) convergence guarantees for ML-based payload generators, and (4) compositional soundness bounds. We further provide a formal separation between static context-blind verifiers and context-aware adaptive verifiers: for a natural family of targets, any static verifier with finite payload budget achieves completeness at most alpha, while a context-aware verifier with sufficient information achieves completeness greater than alpha. We validate our theoretical predictions through controlled experiments on 97,224 exploit samples, demonstrating: detection accuracy improving from 58% to 69.93% with dataset growth, success probability increasing from 51% to 82% with context enrichment, training loss converging at O(1/sqrt(T)) rate, and false positive rate (10.19%) within theoretical bounds (12%). Our results show that theoretically-grounded adaptive verification achieves provable improvements over static approaches under stated assumptions while maintaining soundness guarantees.</li>
</ul>

<h3>Title: Bayesian Optimization for Dynamic Pricing and Learning</h3>
<ul>
<li><strong>Authors: </strong>Anush Anand, Pranav Agrawal, Tejas Bodas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12447">https://arxiv.org/abs/2510.12447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12447">https://arxiv.org/pdf/2510.12447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12447]] Bayesian Optimization for Dynamic Pricing and Learning(https://arxiv.org/abs/2510.12447)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dynamic pricing is the practice of adjusting the selling price of a product to maximize a firm's revenue by responding to market demand. The literature typically distinguishes between two settings: infinite inventory, where the firm has unlimited stock and time to sell, and finite inventory, where both inventory and selling horizon are limited. In both cases, the central challenge lies in the fact that the demand function -- how sales respond to price -- is unknown and must be learned from data. Traditional approaches often assume a specific parametric form for the demand function, enabling the use of reinforcement learning (RL) to identify near-optimal pricing strategies. However, such assumptions may not hold in real-world scenarios, limiting the applicability of these methods. In this work, we propose a Gaussian Process (GP) based nonparametric approach to dynamic pricing that avoids restrictive modeling assumptions. We treat the demand function as a black-box function of the price and develop pricing algorithms based on Bayesian Optimization (BO) -- a sample-efficient method for optimizing unknown functions. We present BO-based algorithms tailored for both infinite and finite inventory settings and provide regret guarantees for both regimes, thereby quantifying the learning efficiency of our methods. Through extensive experiments, we demonstrate that our BO-based methods outperform several state-of-the-art RL algorithms in terms of revenue, while requiring fewer assumptions and offering greater robustness. This highlights Bayesian Optimization as a powerful and practical tool for dynamic pricing in complex, uncertain environments.</li>
</ul>

<h3>Title: A Function Centric Perspective On Flat and Sharp Minima</h3>
<ul>
<li><strong>Authors: </strong>Israel Mason-Williams, Gabryel Mason-Williams, Helen Yannakoudakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12451">https://arxiv.org/abs/2510.12451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12451">https://arxiv.org/pdf/2510.12451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12451]] A Function Centric Perspective On Flat and Sharp Minima(https://arxiv.org/abs/2510.12451)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Flat minima are widely believed to correlate with improved generalisation in deep neural networks. However, this connection has proven more nuanced in recent studies, with both theoretical counterexamples and empirical exceptions emerging in the literature. In this paper, we revisit the role of sharpness in model performance, proposing that sharpness is better understood as a function-dependent property rather than a reliable indicator of poor generalisation. We conduct extensive empirical studies, from single-objective optimisation to modern image classification tasks, showing that sharper minima often emerge when models are regularised (e.g., via SAM, weight decay, or data augmentation), and that these sharp minima can coincide with better generalisation, calibration, robustness, and functional consistency. Across a range of models and datasets, we find that baselines without regularisation tend to converge to flatter minima yet often perform worse across all safety metrics. Our findings demonstrate that function complexity, rather than flatness alone, governs the geometry of solutions, and that sharper minima can reflect more appropriate inductive biases (especially under regularisation), calling for a function-centric reappraisal of loss landscape geometry.</li>
</ul>

<h3>Title: Time-Correlated Video Bridge Matching</h3>
<ul>
<li><strong>Authors: </strong>Viacheslav Vasilev, Arseny Ivanov, Nikita Gushchin, Maria Kovaleva, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12453">https://arxiv.org/abs/2510.12453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12453">https://arxiv.org/pdf/2510.12453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12453]] Time-Correlated Video Bridge Matching(https://arxiv.org/abs/2510.12453)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models excel in noise-to-data generation tasks, providing a mapping from a Gaussian distribution to a more complex data distribution. However they struggle to model translations between complex distributions, limiting their effectiveness in data-to-data tasks. While Bridge Matching (BM) models address this by finding the translation between data distributions, their application to time-correlated data sequences remains unexplored. This is a critical limitation for video generation and manipulation tasks, where maintaining temporal coherence is particularly important. To address this gap, we propose Time-Correlated Video Bridge Matching (TCVBM), a framework that extends BM to time-correlated data sequences in the video domain. TCVBM explicitly models inter-sequence dependencies within the diffusion bridge, directly incorporating temporal correlations into the sampling process. We compare our approach to classical methods based on bridge matching and diffusion models for three video-related tasks: frame interpolation, image-to-video generation, and video super-resolution. TCVBM achieves superior performance across multiple quantitative metrics, demonstrating enhanced generation quality and reconstruction fidelity.</li>
</ul>

<h3>Title: Attack-Specialized Deep Learning with Ensemble Fusion for Network Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Nisith Dissanayake (1), Uthayasanker Thayasivam (1) ((1) University of Moratuwa)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12455">https://arxiv.org/abs/2510.12455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12455">https://arxiv.org/pdf/2510.12455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12455]] Attack-Specialized Deep Learning with Ensemble Fusion for Network Anomaly Detection(https://arxiv.org/abs/2510.12455)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>The growing scale and sophistication of cyberattacks pose critical challenges to network security, particularly in detecting diverse intrusion types within imbalanced datasets. Traditional intrusion detection systems (IDS) often struggle to maintain high accuracy across both frequent and rare attacks, leading to increased false negatives for minority classes. To address this, we propose a hybrid anomaly detection framework that integrates specialized deep learning models with an ensemble meta-classifier. Each model is trained to detect a specific attack category, enabling tailored learning of class-specific patterns, while their collective outputs are fused by a Random Forest meta-classifier to improve overall decision reliability. The framework is evaluated on the NSL-KDD benchmark, demonstrating superior performance in handling class imbalance compared to conventional monolithic models. Results show significant improvements in precision, recall, and F1-score across all attack categories, including rare classes such as User to Root (U2R). The proposed system achieves near-perfect detection rates with minimal false alarms, highlighting its robustness and generalizability. This work advances the design of intrusion detection systems by combining specialization with ensemble learning, providing an effective and scalable solution for safeguarding modern networks.</li>
</ul>

<h3>Title: Probing Latent Knowledge Conflict for Faithful Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Linfeng Gao, Baolong Bi, Zheng Yuan, Le Wang, Zerui Chen, Zhimin Wei, Shenghua Liu, Qinggang Zhang, Jinsong Su</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12460">https://arxiv.org/abs/2510.12460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12460">https://arxiv.org/pdf/2510.12460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12460]] Probing Latent Knowledge Conflict for Faithful Retrieval-Augmented Generation(https://arxiv.org/abs/2510.12460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to enhance the factuality of Large Language Models (LLMs). However, existing RAG systems often suffer from an unfaithfulness issue, where the model's response contradicts evidence from the retrieved context. Existing approaches to improving contextual faithfulness largely rely on external interventions, such as prompt engineering, decoding constraints, or reward-based fine-tuning. These works treat the LLM as a black box and overlook a crucial question: how does the LLM internally integrate retrieved evidence with its parametric memory, particularly under knowledge conflicts? To address this gap, we conduct a probing-based analysis of hidden-state representations in LLMs and observe three findings: knowledge integration occurs hierarchically, conflicts manifest as latent signals at the sentence level, and irrelevant context is often amplified when aligned with parametric knowledge. Building on these findings, we propose CLEAR (Conflict-Localized and Enhanced Attention for RAG), a framework that (i) decomposes context into fine-grained sentence-level knowledge, (ii) employs hidden-state probing to localize conflicting knowledge, and (iii) introduces conflict-aware fine-tuning to guide the model to accurately integrate retrieved evidence. Extensive experiments across three benchmarks demonstrate that CLEAR substantially improves both accuracy and contextual faithfulness, consistently outperforming strong baselines under diverse conflict conditions. The related resources are available at this https URL.</li>
</ul>

<h3>Title: Resource-sensitive but language-blind: Community size and not grammatical complexity better predicts the accuracy of Large Language Models in a novel Wug Test</h3>
<ul>
<li><strong>Authors: </strong>Nikoleta Pantelidou, Evelina Leivada, Paolo Morosi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12463">https://arxiv.org/abs/2510.12463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12463">https://arxiv.org/pdf/2510.12463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12463]] Resource-sensitive but language-blind: Community size and not grammatical complexity better predicts the accuracy of Large Language Models in a novel Wug Test(https://arxiv.org/abs/2510.12463)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The linguistic abilities of Large Language Models are a matter of ongoing debate. This study contributes to this discussion by investigating model performance in a morphological generalization task that involves novel words. Using a multilingual adaptation of the Wug Test, six models were tested across four partially unrelated languages (Catalan, English, Greek, and Spanish) and compared with human speakers. The aim is to determine whether model accuracy approximates human competence and whether it is shaped primarily by linguistic complexity or by the quantity of available training data. Consistent with previous research, the results show that the models are able to generalize morphological processes to unseen words with human-like accuracy. However, accuracy patterns align more closely with community size and data availability than with structural complexity, refining earlier claims in the literature. In particular, languages with larger speaker communities and stronger digital representation, such as Spanish and English, revealed higher accuracy than less-resourced ones like Catalan and Greek. Overall, our findings suggest that model behavior is mainly driven by the richness of linguistic resources rather than by sensitivity to grammatical complexity, reflecting a form of performance that resembles human linguistic competence only superficially.</li>
</ul>

<h3>Title: MS-GAGA: Metric-Selective Guided Adversarial Generation Attack</h3>
<ul>
<li><strong>Authors: </strong>Dion J. X. Ho, Gabriel Lee Jun Rong, Niharika Shrivastava, Harshavardhan Abichandani, Pai Chet Ng, Xiaoxiao Miao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12468">https://arxiv.org/abs/2510.12468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12468">https://arxiv.org/pdf/2510.12468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12468]] MS-GAGA: Metric-Selective Guided Adversarial Generation Attack(https://arxiv.org/abs/2510.12468)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We present MS-GAGA (Metric-Selective Guided Adversarial Generation Attack), a two-stage framework for crafting transferable and visually imperceptible adversarial examples against deepfake detectors in black-box settings. In Stage 1, a dual-stream attack module generates adversarial candidates: MNTD-PGD applies enhanced gradient calculations optimized for small perturbation budgets, while SG-PGD focuses perturbations on visually salient regions. This complementary design expands the adversarial search space and improves transferability across unseen models. In Stage 2, a metric-aware selection module evaluates candidates based on both their success against black-box models and their structural similarity (SSIM) to the original image. By jointly optimizing transferability and imperceptibility, MS-GAGA achieves up to 27% higher misclassification rates on unseen detectors compared to state-of-the-art attacks.</li>
</ul>

<h3>Title: Proof of Cloud: Data Center Execution Assurance for Confidential VMs</h3>
<ul>
<li><strong>Authors: </strong>Filip Rezabek, Moe Mahhouk, Andrew Miller, Stefan Genchev, Quintus Kilbourn, Georg Carle, Jonathan Passerat-Palmbach</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12469">https://arxiv.org/abs/2510.12469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12469">https://arxiv.org/pdf/2510.12469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12469]] Proof of Cloud: Data Center Execution Assurance for Confidential VMs(https://arxiv.org/abs/2510.12469)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Confidential Virtual Machines (CVMs) protect data in use by running workloads inside hardware-isolated environments. In doing so, they also inherit the limitations of the underlying hardware. Trusted Execution Environments (TEEs), which enforce this isolation, explicitly exclude adversaries with physical access from their threat model. Commercial TEEs, e.g., Intel TDX, thus assume infrastructure providers do not physically exploit hardware and serve as safeguards instead. This creates a tension: tenants must trust provider integrity at the hardware layer, yet existing remote attestation offers no way to verify that CVMs actually run on physically trusted platforms, leaving today's CVM deployments unable to demonstrate that their guarantees align with the TEE vendor's threat model. We bridge this confidence gap with Data Center Execution Assurance (DCEA), a design generating "Proofs of Cloud". DCEA binds a CVM to its underlying platform using vTPM-anchored measurements, ensuring CVM launch evidence and TPM quotes refer to the same physical chassis. This takes advantage of the fact that data centers are often identifiable via TPMs. Our approach applies to CVMs accessing vTPMs and running on top of software stacks fully controlled by the cloud provider, as well as single-tenant bare-metal deployments with discrete TPMs. We trust providers for integrity (certificate issuance), but not for the confidentiality of CVM-visible state. DCEA enables remote verification of a CVM's platform origin and integrity, mitigating attacks like replay and attestation proxying. We include a candidate implementation on Google Cloud and Intel TDX that leverages Intel TXT for trusted launch. Our design refines CVMs' threat model and provides a practical path for deploying high-assurance, confidential workloads in minimally trusted environments.</li>
</ul>

<h3>Title: SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression</h3>
<ul>
<li><strong>Authors: </strong>Biao Zhang, Lixin Chen, Tong Liu, Bo Zheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12474">https://arxiv.org/abs/2510.12474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12474">https://arxiv.org/pdf/2510.12474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12474]] SMEC: Rethinking Matryoshka Representation Learning for Retrieval Embedding Compression(https://arxiv.org/abs/2510.12474)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) generate high-dimensional embeddings that capture rich semantic and syntactic information. However, high-dimensional embeddings exacerbate computational complexity and storage requirements, thereby hindering practical deployment. To address these challenges, we propose a novel training framework named Sequential Matryoshka Embedding Compression (SMEC). This framework introduces the Sequential Matryoshka Representation Learning(SMRL) method to mitigate gradient variance during training, the Adaptive Dimension Selection (ADS) module to reduce information degradation during dimension pruning, and the Selectable Cross-batch Memory (S-XBM) module to enhance unsupervised learning between high- and low-dimensional embeddings. Experiments on image, text, and multimodal datasets demonstrate that SMEC achieves significant dimensionality reduction while maintaining performance. For instance, on the BEIR dataset, our approach improves the performance of compressed LLM2Vec embeddings (256 dimensions) by 1.1 points and 2.7 points compared to the Matryoshka-Adaptor and Search-Adaptor models, respectively.</li>
</ul>

<h3>Title: When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection</h3>
<ul>
<li><strong>Authors: </strong>Lang Gao, Xuhui Li, Chenxi Wang, Mingzhe Li, Wei Liu, Zirui Song, Jinghui Zhang, Rui Yan, Preslav Nakov, Xiuying Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12476">https://arxiv.org/abs/2510.12476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12476">https://arxiv.org/pdf/2510.12476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12476]] When Personalization Tricks Detectors: The Feature-Inversion Trap in Machine-Generated Text Detection(https://arxiv.org/abs/2510.12476)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have grown more powerful in language generation, producing fluent text and even imitating personal style. Yet, this ability also heightens the risk of identity impersonation. To the best of our knowledge, no prior work has examined personalized machine-generated text (MGT) detection. In this paper, we introduce \dataset, the first benchmark for evaluating detector robustness in personalized settings, built from literary and blog texts paired with their LLM-generated imitations. Our experimental results demonstrate large performance gaps across detectors in personalized settings: some state-of-the-art models suffer significant drops. We attribute this limitation to the \textit{feature-inversion trap}, where features that are discriminative in general domains become inverted and misleading when applied to personalized text. Based on this finding, we propose \method, a simple and reliable way to predict detector performance changes in personalized settings. \method identifies latent directions corresponding to inverted features and constructs probe datasets that differ primarily along these features to evaluate detector dependence. Our experiments show that \method can accurately predict both the direction and the magnitude of post-transfer changes, showing 85\% correlation with the actual performance gaps. We hope that this work will encourage further research on personalized text detection.</li>
</ul>

<h3>Title: A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shurong Chai, Rahul Kumar JAIN, Rui Xu, Shaocong Mo, Ruibo Hou, Shiyu Teng, Jiaqing Liu, Lanfen Lin, Yen-Wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12482">https://arxiv.org/abs/2510.12482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12482">https://arxiv.org/pdf/2510.12482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12482]] A Text-Image Fusion Method with Data Augmentation Capabilities for Referring Medical Image Segmentation(https://arxiv.org/abs/2510.12482)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning relies heavily on data augmentation to mitigate limited data, especially in medical imaging. Recent multimodal learning integrates text and images for segmentation, known as referring or text-guided image segmentation. However, common augmentations like rotation and flipping disrupt spatial alignment between image and text, weakening performance. To address this, we propose an early fusion framework that combines text and visual features before augmentation, preserving spatial consistency. We also design a lightweight generator that projects text embeddings into visual space, bridging semantic gaps. Visualization of generated pseudo-images shows accurate region localization. Our method is evaluated on three medical imaging tasks and four segmentation frameworks, achieving state-of-the-art results. Code is publicly available on GitHub: this https URL.</li>
</ul>

<h3>Title: PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture</h3>
<ul>
<li><strong>Authors: </strong>Yi Liu, Yang Liu, Leqian Zheng, Jue Hong, Junjie Shi, Qingyou Yang, Ye Wu, Cong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12494">https://arxiv.org/abs/2510.12494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12494">https://arxiv.org/pdf/2510.12494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12494]] PubSub-VFL: Towards Efficient Two-Party Split Learning in Heterogeneous Environments via Publisher/Subscriber Architecture(https://arxiv.org/abs/2510.12494)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of the digital economy, data collaboration between organizations has become a well-established business model, driving the growth of various industries. However, privacy concerns make direct data sharing impractical. To address this, Two-Party Split Learning (a.k.a. Vertical Federated Learning (VFL)) has emerged as a promising solution for secure collaborative learning. Despite its advantages, this architecture still suffers from low computational resource utilization and training efficiency. Specifically, its synchronous dependency design increases training latency, while resource and data heterogeneity among participants further hinder efficient computation. To overcome these challenges, we propose PubSub-VFL, a novel VFL paradigm with a Publisher/Subscriber architecture optimized for two-party collaborative learning with high computational efficiency. PubSub-VFL leverages the decoupling capabilities of the Pub/Sub architecture and the data parallelism of the parameter server architecture to design a hierarchical asynchronous mechanism, reducing training latency and improving system efficiency. Additionally, to mitigate the training imbalance caused by resource and data heterogeneity, we formalize an optimization problem based on participants' system profiles, enabling the selection of optimal hyperparameters while preserving privacy. We conduct a theoretical analysis to demonstrate that PubSub-VFL achieves stable convergence and is compatible with security protocols such as differential privacy. Extensive case studies on five benchmark datasets further validate its effectiveness, showing that, compared to state-of-the-art baselines, PubSub-VFL not only accelerates training by $2 \sim 7\times$ without compromising accuracy, but also achieves a computational resource utilization rate of up to 91.07%.</li>
</ul>

<h3>Title: Mitigating the Noise Shift for Denoising Generative Models via Noise Awareness Guidance</h3>
<ul>
<li><strong>Authors: </strong>Jincheng Zhong, Boyuan Jiang, Xin Tao, Pengfei Wan, Kun Gai, Mingsheng Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12497">https://arxiv.org/abs/2510.12497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12497">https://arxiv.org/pdf/2510.12497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12497]] Mitigating the Noise Shift for Denoising Generative Models via Noise Awareness Guidance(https://arxiv.org/abs/2510.12497)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Existing denoising generative models rely on solving discretized reverse-time SDEs or ODEs. In this paper, we identify a long-overlooked yet pervasive issue in this family of models: a misalignment between the pre-defined noise level and the actual noise level encoded in intermediate states during sampling. We refer to this misalignment as noise shift. Through empirical analysis, we demonstrate that noise shift is widespread in modern diffusion models and exhibits a systematic bias, leading to sub-optimal generation due to both out-of-distribution generalization and inaccurate denoising updates. To address this problem, we propose Noise Awareness Guidance (NAG), a simple yet effective correction method that explicitly steers sampling trajectories to remain consistent with the pre-defined noise schedule. We further introduce a classifier-free variant of NAG, which jointly trains a noise-conditional and a noise-unconditional model via noise-condition dropout, thereby eliminating the need for external classifiers. Extensive experiments, including ImageNet generation and various supervised fine-tuning tasks, show that NAG consistently mitigates noise shift and substantially improves the generation quality of mainstream diffusion models.</li>
</ul>

<h3>Title: The Robustness of Differentiable Causal Discovery in Misspecified Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Huiyang Yi, Yanyan He, Duxin Chen, Mingyu Kang, He Wang, Wenwu Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12503">https://arxiv.org/abs/2510.12503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12503">https://arxiv.org/pdf/2510.12503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12503]] The Robustness of Differentiable Causal Discovery in Misspecified Scenarios(https://arxiv.org/abs/2510.12503)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal discovery aims to learn causal relationships between variables from targeted data, making it a fundamental task in machine learning. However, causal discovery algorithms often rely on unverifiable causal assumptions, which are usually difficult to satisfy in real-world data, thereby limiting the broad application of causal discovery in practical scenarios. Inspired by these considerations, this work extensively benchmarks the empirical performance of various mainstream causal discovery algorithms, which assume i.i.d. data, under eight model assumption violations. Our experimental results show that differentiable causal discovery methods exhibit robustness under the metrics of Structural Hamming Distance and Structural Intervention Distance of the inferred graphs in commonly used challenging scenarios, except for scale variation. We also provide the theoretical explanations for the performance of differentiable causal discovery methods. Finally, our work aims to comprehensively benchmark the performance of recent differentiable causal discovery methods under model assumption violations, and provide the standard for reasonable evaluation of causal discovery, as well as to further promote its application in real-world scenarios.</li>
</ul>

<h3>Title: Multi-Armed Bandits with Minimum Aggregated Revenue Constraints</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Ben Yahmed, Hafedh El Ferchichi, Marc Abeille, Vianney Perchet</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12523">https://arxiv.org/abs/2510.12523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12523">https://arxiv.org/pdf/2510.12523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12523]] Multi-Armed Bandits with Minimum Aggregated Revenue Constraints(https://arxiv.org/abs/2510.12523)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We examine a multi-armed bandit problem with contextual information, where the objective is to ensure that each arm receives a minimum aggregated reward across contexts while simultaneously maximizing the total cumulative reward. This framework captures a broad class of real-world applications where fair revenue allocation is critical and contextual variation is inherent. The cross-context aggregation of minimum reward constraints, while enabling better performance and easier feasibility, introduces significant technical challenges -- particularly the absence of closed-form optimal allocations typically available in standard MAB settings. We design and analyze algorithms that either optimistically prioritize performance or pessimistically enforce constraint satisfaction. For each algorithm, we derive problem-dependent upper bounds on both regret and constraint violations. Furthermore, we establish a lower bound demonstrating that the dependence on the time horizon in our results is optimal in general and revealing fundamental limitations of the free exploration principle leveraged in prior work.</li>
</ul>

<h3>Title: Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Kong, Chen Zong, Junkai Deng, Xuhui Chen, Fei Hou, Shiqing Xin, Junhui Hou, Chen Qian, Ying He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12524">https://arxiv.org/abs/2510.12524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12524">https://arxiv.org/pdf/2510.12524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12524]] Voronoi-Assisted Diffusion for Computing Unsigned Distance Fields from Unoriented Points(https://arxiv.org/abs/2510.12524)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Unsigned Distance Fields (UDFs) provide a flexible representation for 3D shapes with arbitrary topology, including open and closed surfaces, orientable and non-orientable geometries, and non-manifold structures. While recent neural approaches have shown promise in learning UDFs, they often suffer from numerical instability, high computational cost, and limited controllability. We present a lightweight, network-free method, Voronoi-Assisted Diffusion (VAD), for computing UDFs directly from unoriented point clouds. Our approach begins by assigning bi-directional normals to input points, guided by two Voronoi-based geometric criteria encoded in an energy function for optimal alignment. The aligned normals are then diffused to form an approximate UDF gradient field, which is subsequently integrated to recover the final UDF. Experiments demonstrate that VAD robustly handles watertight and open surfaces, as well as complex non-manifold and non-orientable geometries, while remaining computationally efficient and stable.</li>
</ul>

<h3>Title: Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion</h3>
<ul>
<li><strong>Authors: </strong>David Björkstrand, Tiesheng Wang, Lars Bretzner, Josephine Sullivan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12537">https://arxiv.org/abs/2510.12537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12537">https://arxiv.org/pdf/2510.12537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12537]] Unconditional Human Motion and Shape Generation via Balanced Score-Based Diffusion(https://arxiv.org/abs/2510.12537)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent work has explored a range of model families for human motion generation, including Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and diffusion-based models. Despite their differences, many methods rely on over-parameterized input features and auxiliary losses to improve empirical results. These strategies should not be strictly necessary for diffusion models to match the human motion distribution. We show that on par with state-of-the-art results in unconditional human motion generation are achievable with a score-based diffusion model using only careful feature-space normalization and analytically derived weightings for the standard L2 score-matching loss, while generating both motion and shape directly, thereby avoiding slow post hoc shape recovery from joints. We build the method step by step, with a clear theoretical motivation for each component, and provide targeted ablations demonstrating the effectiveness of each proposed addition in isolation.</li>
</ul>

<h3>Title: Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jasmin Freudenberg, Kai Hahn, Christian Weber, Madjid Fathi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12541">https://arxiv.org/abs/2510.12541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12541">https://arxiv.org/pdf/2510.12541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12541]] Evaluation of Real-Time Preprocessing Methods in AI-Based ECG Signal Analysis(https://arxiv.org/abs/2510.12541)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>The increasing popularity of portable ECG systems and the growing demand for privacy-compliant, energy-efficient real-time analysis require new approaches to signal processing at the point of data acquisition. In this context, the edge domain is acquiring increasing importance, as it not only reduces latency times, but also enables an increased level of data security. The FACE project aims to develop an innovative machine learning solution for analysing long-term electrocardiograms that synergistically combines the strengths of edge and cloud computing. In this thesis, various pre-processing steps of ECG signals are analysed with regard to their applicability in the project. The selection of suitable methods in the edge area is based in particular on criteria such as energy efficiency, processing capability and real-time capability.</li>
</ul>

<h3>Title: MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Tianhao Li, Tingfa Xu, Ying Wang, Haolin Qin, Xu Lin, Jianan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12565">https://arxiv.org/abs/2510.12565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12565">https://arxiv.org/pdf/2510.12565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12565]] MMOT: The First Challenging Benchmark for Drone-based Multispectral Multi-Object Tracking(https://arxiv.org/abs/2510.12565)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Drone-based multi-object tracking is essential yet highly challenging due to small targets, severe occlusions, and cluttered backgrounds. Existing RGB-based tracking algorithms heavily depend on spatial appearance cues such as color and texture, which often degrade in aerial views, compromising reliability. Multispectral imagery, capturing pixel-level spectral reflectance, provides crucial cues that enhance object discriminability under degraded spatial conditions. However, the lack of dedicated multispectral UAV datasets has hindered progress in this domain. To bridge this gap, we introduce MMOT, the first challenging benchmark for drone-based multispectral multi-object tracking. It features three key characteristics: (i) Large Scale - 125 video sequences with over 488.8K annotations across eight categories; (ii) Comprehensive Challenges - covering diverse conditions such as extreme small targets, high-density scenarios, severe occlusions, and complex motion; and (iii) Precise Oriented Annotations - enabling accurate localization and reduced ambiguity under aerial perspectives. To better extract spectral features and leverage oriented annotations, we further present a multispectral and orientation-aware MOT scheme adapting existing methods, featuring: (i) a lightweight Spectral 3D-Stem integrating spectral features while preserving compatibility with RGB pretraining; (ii) an orientation-aware Kalman filter for precise state estimation; and (iii) an end-to-end orientation-adaptive transformer. Extensive experiments across representative trackers consistently show that multispectral input markedly improves tracking performance over RGB baselines, particularly for small and densely packed objects. We believe our work will advance drone-based multispectral multi-object tracking research. Our MMOT, code, and benchmarks are publicly available at this https URL.</li>
</ul>

<h3>Title: Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Simon Ravé, Jean-Christophe Lombardo, Pejman Rasti, Alexis Joly, David Rousseau</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12579">https://arxiv.org/abs/2510.12579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12579">https://arxiv.org/pdf/2510.12579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12579]] Unlocking Zero-Shot Plant Segmentation with Pl@ntNet Intelligence(https://arxiv.org/abs/2510.12579)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present a zero-shot segmentation approach for agricultural imagery that leverages Plantnet, a large-scale plant classification model, in conjunction with its DinoV2 backbone and the Segment Anything Model (SAM). Rather than collecting and annotating new datasets, our method exploits Plantnet's specialized plant representations to identify plant regions and produce coarse segmentation masks. These masks are then refined by SAM to yield detailed segmentations. We evaluate on four publicly available datasets of various complexity in terms of contrast including some where the limited size of the training data and complex field conditions often hinder purely supervised methods. Our results show consistent performance gains when using Plantnet-fine-tuned DinoV2 over the base DinoV2 model, as measured by the Jaccard Index (IoU). These findings highlight the potential of combining foundation models with specialized plant-centric models to alleviate the annotation bottleneck and enable effective segmentation in diverse agricultural scenarios.</li>
</ul>

<h3>Title: LayerSync: Self-aligning Intermediate Layers</h3>
<ul>
<li><strong>Authors: </strong>Yasaman Haghighi, Bastien van Delft, Mariam Hassan, Alexandre Alahi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12581">https://arxiv.org/abs/2510.12581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12581">https://arxiv.org/pdf/2510.12581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12581]] LayerSync: Self-aligning Intermediate Layers(https://arxiv.org/abs/2510.12581)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose LayerSync, a domain-agnostic approach for improving the generation quality and the training efficiency of diffusion models. Prior studies have highlighted the connection between the quality of generation and the representations learned by diffusion models, showing that external guidance on model intermediate representations accelerates training. We reconceptualize this paradigm by regularizing diffusion models with their own intermediate representations. Building on the observation that representation quality varies across diffusion model layers, we show that the most semantically rich representations can act as an intrinsic guidance for weaker ones, reducing the need for external supervision. Our approach, LayerSync, is a self-sufficient, plug-and-play regularizer term with no overhead on diffusion model training and generalizes beyond the visual domain to other modalities. LayerSync requires no pretrained models nor additional data. We extensively evaluate the method on image generation and demonstrate its applicability to other domains such as audio, video, and motion generation. We show that it consistently improves the generation quality and the training efficiency. For example, we speed up the training of flow-based transformer by over 8.75x on ImageNet dataset and improved the generation quality by 23.6%. The code is available at this https URL.</li>
</ul>

<h3>Title: Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Jiachen Lei, Keli Liu, Julius Berner, Haiming Yu, Hongkai Zheng, Jiahong Wu, Xiangxiang Chu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12586">https://arxiv.org/abs/2510.12586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12586">https://arxiv.org/pdf/2510.12586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12586]] Advancing End-to-End Pixel Space Generative Modeling via Self-supervised Pre-training(https://arxiv.org/abs/2510.12586)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Pixel-space generative models are often more difficult to train and generally underperform compared to their latent-space counterparts, leaving a persistent performance and efficiency gap. In this paper, we introduce a novel two-stage training framework that closes this gap for pixel-space diffusion and consistency models. In the first stage, we pre-train encoders to capture meaningful semantics from clean images while aligning them with points along the same deterministic sampling trajectory, which evolves points from the prior to the data distribution. In the second stage, we integrate the encoder with a randomly initialized decoder and fine-tune the complete model end-to-end for both diffusion and consistency models. Our training framework demonstrates strong empirical performance on ImageNet dataset. Specifically, our diffusion model reaches an FID of 2.04 on ImageNet-256 and 2.35 on ImageNet-512 with 75 number of function evaluations (NFE), surpassing prior pixel-space methods by a large margin in both generation quality and efficiency while rivaling leading VAE-based models at comparable training cost. Furthermore, on ImageNet-256, our consistency model achieves an impressive FID of 8.82 in a single sampling step, significantly surpassing its latent-space counterpart. To the best of our knowledge, this marks the first successful training of a consistency model directly on high-resolution images without relying on pre-trained VAEs or diffusion models.</li>
</ul>

<h3>Title: Teaching Language Models to Faithfully Express their Uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Bryan Eikema, Evgenia Ilia, José G. C. de Souza, Chrysoula Zerva, Wilker Aziz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12587">https://arxiv.org/abs/2510.12587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12587">https://arxiv.org/pdf/2510.12587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12587]] Teaching Language Models to Faithfully Express their Uncertainty(https://arxiv.org/abs/2510.12587)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often miscommunicate their uncertainty: repeated queries can produce divergent answers, yet generated responses are typically unhedged or hedged in ways that do not reflect this variability. This conveys unfaithful information about the uncertain state of the LLMs' knowledge, creating a faithfulness gap that affects even strong LLMs. We introduce Faithful Uncertainty Tuning (FUT): a fine-tuning approach that teaches instruction-tuned LLMs to express uncertainty faithfully without altering their underlying answer distribution. We construct training data by augmenting model samples with uncertainty hedges (i.e. verbal cues such as 'possibly' or 'likely') aligned with sample consistency, requiring no supervision beyond the model and a set of prompts. We evaluate FUT on open-domain question answering (QA) across multiple models and datasets. Our results show that FUT substantially reduces the faithfulness gap, while preserving QA accuracy and introducing minimal semantic distribution shift. Further analyses demonstrate robustness across decoding strategies, choice of hedgers, and other forms of uncertainty expression (i.e. numerical). These findings establish FUT as a simple and effective way to teach LLMs to communicate uncertainty faithfully.</li>
</ul>

<h3>Title: Research in Collaborative Learning Does Not Serve Cross-Silo Federated Learning in Practice</h3>
<ul>
<li><strong>Authors: </strong>Kevin Kuo, Chhavi Yadav, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12595">https://arxiv.org/abs/2510.12595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12595">https://arxiv.org/pdf/2510.12595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12595]] Research in Collaborative Learning Does Not Serve Cross-Silo Federated Learning in Practice(https://arxiv.org/abs/2510.12595)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, federate</a></li>
<li><strong>Abstract: </strong>Cross-silo federated learning (FL) is a promising approach to enable cross-organization collaboration in machine learning model development without directly sharing private data. Despite growing organizational interest driven by data protection regulations such as GDPR and HIPAA, the adoption of cross-silo FL remains limited in practice. In this paper, we conduct an interview study to understand the practical challenges associated with cross-silo FL adoption. With interviews spanning a diverse set of stakeholders such as user organizations, software providers, and academic researchers, we uncover various barriers, from concerns about model performance to questions of incentives and trust between participating organizations. Our study shows that cross-silo FL faces a set of challenges that have yet to be well-captured by existing research in the area and are quite distinct from other forms of federated learning such as cross-device FL. We end with a discussion on future research directions that can help overcome these challenges.</li>
</ul>

<h3>Title: StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis</h3>
<ul>
<li><strong>Authors: </strong>Siyuan Li, Aodu Wulianghai, Xi Lin, Guangyan Li, Xiang Chen, Jun Wu, Jianhua Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12608">https://arxiv.org/abs/2510.12608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12608">https://arxiv.org/pdf/2510.12608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12608]] StyleDecipher: Robust and Explainable Detection of LLM-Generated Texts with Stylistic Analysis(https://arxiv.org/abs/2510.12608)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, large language model</a></li>
<li><strong>Abstract: </strong>With the increasing integration of large language models (LLMs) into open-domain writing, detecting machine-generated text has become a critical task for ensuring content authenticity and trust. Existing approaches rely on statistical discrepancies or model-specific heuristics to distinguish between LLM-generated and human-written text. However, these methods struggle in real-world scenarios due to limited generalization, vulnerability to paraphrasing, and lack of explainability, particularly when facing stylistic diversity or hybrid human-AI authorship. In this work, we propose StyleDecipher, a robust and explainable detection framework that revisits LLM-generated text detection using combined feature extractors to quantify stylistic differences. By jointly modeling discrete stylistic indicators and continuous stylistic representations derived from semantic embeddings, StyleDecipher captures distinctive style-level divergences between human and LLM outputs within a unified representation space. This framework enables accurate, explainable, and domain-agnostic detection without requiring access to model internals or labeled segments. Extensive experiments across five diverse domains, including news, code, essays, reviews, and academic abstracts, demonstrate that StyleDecipher consistently achieves state-of-the-art in-domain accuracy. Moreover, in cross-domain evaluations, it surpasses existing baselines by up to 36.30%, while maintaining robustness against adversarial perturbations and mixed human-AI content. Further qualitative and quantitative analysis confirms that stylistic signals provide explainable evidence for distinguishing machine-generated text. Our source code can be accessed at this https URL.</li>
</ul>

<h3>Title: Towards Fast Coarse-graining and Equation Discovery with Foundation Inference Models</h3>
<ul>
<li><strong>Authors: </strong>Manuel Hinz, Maximilian Mauel, Patrick Seifner, David Berghaus, Kostadin Cvejoski, Ramses J. Sanchez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12618">https://arxiv.org/abs/2510.12618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12618">https://arxiv.org/pdf/2510.12618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12618]] Towards Fast Coarse-graining and Equation Discovery with Foundation Inference Models(https://arxiv.org/abs/2510.12618)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>High-dimensional recordings of dynamical processes are often characterized by a much smaller set of effective variables, evolving on low-dimensional manifolds. Identifying these latent dynamics requires solving two intertwined problems: discovering appropriate coarse-grained variables and simultaneously fitting the governing equations. Most machine learning approaches tackle these tasks jointly by training autoencoders together with models that enforce dynamical consistency. We propose to decouple the two problems by leveraging the recently introduced Foundation Inference Models (FIMs). FIMs are pretrained models that estimate the infinitesimal generators of dynamical systems (e.g., the drift and diffusion of a stochastic differential equation) in zero-shot mode. By amortizing the inference of the dynamics through a FIM with frozen weights, and training only the encoder-decoder map, we define a simple, simulation-consistent loss that stabilizes representation learning. A proof of concept on a stochastic double-well system with semicircle diffusion, embedded into synthetic video data, illustrates the potential of this approach for fast and reusable coarse-graining pipelines.</li>
</ul>

<h3>Title: ACADATA: Parallel Dataset of Academic Data for Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Iñaki Lacunza, Javier Garcia Gilabert, Francesca De Luca Fornaciari, Javier Aula-Blasco, Aitor Gonzalez-Agirre, Maite Melero, Marta Villegas</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12621">https://arxiv.org/abs/2510.12621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12621">https://arxiv.org/pdf/2510.12621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12621]] ACADATA: Parallel Dataset of Academic Data for Machine Translation(https://arxiv.org/abs/2510.12621)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present ACADATA, a high-quality parallel dataset for academic translation, that consists of two subsets: ACAD-TRAIN, which contains approximately 1.5 million author-generated paragraph pairs across 96 language directions and ACAD-BENCH, a curated evaluation set of almost 6,000 translations covering 12 directions. To validate its utility, we fine-tune two Large Language Models (LLMs) on ACAD-TRAIN and benchmark them on ACAD-BENCH against specialized machine-translation systems, general-purpose, open-weight LLMs, and several large-scale proprietary models. Experimental results demonstrate that fine-tuning on ACAD-TRAIN leads to improvements in academic translation quality by +6.1 and +12.4 d-BLEU points on average for 7B and 2B models respectively, while also improving long-context translation in a general domain by up to 24.9% when translating out of English. The fine-tuned top-performing model surpasses the best propietary and open-weight models on academic translation domain. By releasing ACAD-TRAIN, ACAD-BENCH and the fine-tuned models, we provide the community with a valuable resource to advance research in academic domain and long-context translation.</li>
</ul>

<h3>Title: Noisy Neighbor: Exploiting RDMA for Resource Exhaustion Attacks in Containerized Clouds</h3>
<ul>
<li><strong>Authors: </strong>Gunwoo Kim, Taejune Park, Jinwoo Kim</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12629">https://arxiv.org/abs/2510.12629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12629">https://arxiv.org/pdf/2510.12629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12629]] Noisy Neighbor: Exploiting RDMA for Resource Exhaustion Attacks in Containerized Clouds(https://arxiv.org/abs/2510.12629)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>In modern containerized cloud environments, the adoption of RDMA (Remote Direct Memory Access) has expanded to reduce CPU overhead and enable high-performance data exchange. Achieving this requires strong performance isolation to ensure that one container's RDMA workload does not degrade the performance of others, thereby maintaining critical security assurances. However, existing isolation techniques are difficult to apply effectively due to the complexity of microarchitectural resource management within RDMA NICs (RNICs). This paper experimentally analyzes two types of resource exhaustion attacks on NVIDIA BlueField-3: (i) state saturation attacks and (ii) pipeline saturation attacks. Our results show that state saturation attacks can cause up to a 93.9% loss in bandwidth, a 1,117x increase in latency, and a 115% rise in cache misses for victim containers, while pipeline saturation attacks lead to severe link-level congestion and significant amplification, where small verb requests result in disproportionately high resource consumption. To mitigate these threats and restore predictable security assurances, we propose HT-Verbs, a threshold-driven framework based on real-time per-container RDMA verb telemetry and adaptive resource classification that partitions RNIC resources into hot, warm, and cold tiers and throttles abusive workloads without requiring hardware modifications.</li>
</ul>

<h3>Title: Laminar: A Scalable Asynchronous RL Post-Training Framework</h3>
<ul>
<li><strong>Authors: </strong>Guangming Sheng, Yuxuan Tong, Borui Wan, Wang Zhang, Chaobo Jia, Xibin Wu, Yuqi Wu, Xiang Li, Chi Zhang, Yanghua Peng, Haibin Lin, Xin Liu, Chuan Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12633">https://arxiv.org/abs/2510.12633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12633">https://arxiv.org/pdf/2510.12633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12633]] Laminar: A Scalable Asynchronous RL Post-Training Framework(https://arxiv.org/abs/2510.12633)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) post-training for Large Language Models (LLMs) is now scaling to large clusters and running for extended durations to enhance model reasoning performance. However, the scalability of existing RL frameworks is limited, as extreme long-tail skewness in RL trajectory generation causes severe GPU underutilization. Current asynchronous RL systems attempt to mitigate this, but they rely on global weight synchronization between the actor and all rollouts, which creates a rigid model update schedule. This global synchronization is ill-suited for the highly skewed and evolving distribution of trajectory generation latency in RL training, crippling training efficiency. Our key insight is that efficient scaling requires breaking this lockstep through trajectory-level asynchrony, which generates and consumes each trajectory independently. We propose Laminar, a scalable and robust RL post-training system built on a fully decoupled architecture. First, we replace global updates with a tier of relay workers acting as a distributed parameter service. This enables asynchronous and fine-grained weight synchronization, allowing rollouts to pull the latest weight anytime without stalling the actor's training loop. Second, a dynamic repack mechanism consolidates long-tail trajectories onto a few dedicated rollouts, maximizing generation throughput. The fully decoupled design also isolates failures, ensuring robustness for long-running jobs. Our evaluation on a 1024-GPU cluster shows that Laminar achieves up to 5.48$\times$ training throughput speedup over state-of-the-art systems, while reducing model convergence time.</li>
</ul>

<h3>Title: COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point-of-View questions</h3>
<ul>
<li><strong>Authors: </strong>Nzubechukwu C. Ohalete (1), Kevin B. Gittner (1), Lauren M. Matheny (1) ((1) School of Data Science and Analytics, Kennesaw State University, GA, USA)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12637">https://arxiv.org/abs/2510.12637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12637">https://arxiv.org/pdf/2510.12637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12637]] COSTAR-A: A prompting framework for enhancing Large Language Model performance on Point-of-View questions(https://arxiv.org/abs/2510.12637)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are highly sensitive to prompt design, and making optimized prompting techniques is crucial for generating consistent, high-quality outputs. In this study, we introduce COSTAR-A, a novel prompt engineering framework that enhances the existing COSTAR method, which stands for Context, Objective, Style, Tone, Audience, and Response, by adding the 'Answer' component at the end. We demonstrate that while the original COSTAR framework improves prompt clarity and aligns outputs for larger LLMs, its performance is less consistent with smaller, locally optimized models, particularly in tasks that require more directive or constrained outputs. Through a series of controlled prompt-output assessments with smaller (at most 8 billion parameters), fine-tuned models, we found that COSTAR-A can enhance the output structure and decisiveness of localized LLMs for certain tasks, although its effectiveness varies across models and use cases. Notably, the Llama 3.1-8B model exhibited performance improvements when prompted with COSTAR-A compared to COSTAR alone. These findings emphasize the adaptability and scalability of COSTAR-A as a prompting framework, particularly in computationally efficient AI deployments on resource-constrained hardware.</li>
</ul>

<h3>Title: Reasoning Pattern Matters: Learning to Reason without Human Rationales</h3>
<ul>
<li><strong>Authors: </strong>Chaoxu Pang, Yixuan Cao, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12643">https://arxiv.org/abs/2510.12643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12643">https://arxiv.org/pdf/2510.12643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12643]] Reasoning Pattern Matters: Learning to Reason without Human Rationales(https://arxiv.org/abs/2510.12643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable reasoning capabilities under the widely adopted SFT+RLVR paradigm, which first performs Supervised Fine-Tuning (SFT) on human-annotated reasoning trajectories (rationales) to establish initial reasoning behaviors, then applies Reinforcement Learning with Verifiable Rewards (RLVR) to optimize the model using verifiable signals without golden rationales. However, annotating high-quality rationales for the SFT stage remains prohibitively expensive. This paper investigates when and how rationale annotation costs can be substantially reduced without compromising reasoning performance. We identify a broad class of problems, termed patterned reasoning tasks, where reasoning follows a fixed, procedural strategy consistent across instances. Although instances vary in content such as domain knowledge, factual information, or numeric values, the solution derives from applying a shared reasoning pattern. We argue that the success of SFT+RLVR on such tasks primarily stems from its ability to enable models to internalize these reasoning patterns. Using numerical semantic matching as a representative task, we provide both causal and behavioral evidence showing that reasoning patterns rather than the quantity or quality of rationales are the key determinant of performance. Building on these insights, we propose Pattern-Aware LLMs as Rationale AnnOtators (PARO), a simple yet effective framework that enables LLMs to generate rationales aligned with task-specific reasoning patterns without requiring human rationale annotations. Experiments show that PARO-generated rationales achieve comparable SFT+RLVR performance to human rationales that are 10 times larger. These results suggest that large-scale human rationale annotations can be replaced with LLM-based automatic annotations requiring only limited human supervision over reasoning patterns.</li>
</ul>

<h3>Title: Towards Foundation Inference Models that Learn ODEs In-Context</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Mauel, Manuel Hinz, Patrick Seifner, David Berghaus, Ramses J. Sanchez</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12650">https://arxiv.org/abs/2510.12650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12650">https://arxiv.org/pdf/2510.12650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12650]] Towards Foundation Inference Models that Learn ODEs In-Context(https://arxiv.org/abs/2510.12650)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ordinary differential equations (ODEs) describe dynamical systems evolving deterministically in continuous time. Accurate data-driven modeling of systems as ODEs, a central problem across the natural sciences, remains challenging, especially if the data is sparse or noisy. We introduce FIM-ODE (Foundation Inference Model for ODEs), a pretrained neural model designed to estimate ODEs zero-shot (i.e., in context) from sparse and noisy observations. Trained on synthetic data, the model utilizes a flexible neural operator for robust ODE inference, even from corrupted data. We empirically verify that FIM-ODE provides accurate estimates, on par with a neural state-of-the-art method, and qualitatively compare the structure of their estimated vector fields.</li>
</ul>

<h3>Title: PromoGuardian: Detecting Promotion Abuse Fraud with Multi-Relation Fused Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Shaofei Li, Xiao Han, Ziqi Zhang, Minyao Hua, Shuli Gao, Zhenkai Liang, Yao Guo, Xiangqun Chen, Ding Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12652">https://arxiv.org/abs/2510.12652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12652">https://arxiv.org/pdf/2510.12652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12652]] PromoGuardian: Detecting Promotion Abuse Fraud with Multi-Relation Fused Graph Neural Networks(https://arxiv.org/abs/2510.12652)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As e-commerce platforms develop, fraudulent activities are increasingly emerging, posing significant threats to the security and stability of these platforms. Promotion abuse is one of the fastest-growing types of fraud in recent years and is characterized by users exploiting promotional activities to gain financial benefits from the platform. To investigate this issue, we conduct the first study on promotion abuse fraud in e-commerce platforms MEITUAN. We find that promotion abuse fraud is a group-based fraudulent activity with two types of fraudulent activities: Stocking Up and Cashback Abuse. Unlike traditional fraudulent activities such as fake reviews, promotion abuse fraud typically involves ordinary customers conducting legitimate transactions and these two types of fraudulent activities are often intertwined. To address this issue, we propose leveraging additional information from the spatial and temporal perspectives to detect promotion abuse fraud. In this paper, we introduce PROMOGUARDIAN, a novel multi-relation fused graph neural network that integrates the spatial and temporal information of transaction data into a homogeneous graph to detect promotion abuse fraud. We conduct extensive experiments on real-world data from MEITUAN, and the results demonstrate that our proposed model outperforms state-of-the-art methods in promotion abuse fraud detection, achieving 93.15% precision, detecting 2.1 to 5.0 times more fraudsters, and preventing 1.5 to 8.8 times more financial losses in production environments.</li>
</ul>

<h3>Title: SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning</h3>
<ul>
<li><strong>Authors: </strong>Chih-Chuan Cheng, Yi-Ju Tseng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12659">https://arxiv.org/abs/2510.12659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12659">https://arxiv.org/pdf/2510.12659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12659]] SG-XDEAT: Sparsity-Guided Cross-Dimensional and Cross-Encoding Attention with Target-Aware Conditioning in Tabular Learning(https://arxiv.org/abs/2510.12659)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose SG-XDEAT (Sparsity-Guided Cross Dimensional and Cross-Encoding Attention with Target Aware Conditioning), a novel framework designed for supervised learning on tabular data. At its core, SG-XDEAT employs a dual-stream encoder that decomposes each input feature into two parallel representations: a raw value stream and a target-conditioned (label-aware) stream. These dual representations are then propagated through a hierarchical stack of attention-based modules. SG-XDEAT integrates three key components: (i) Cross-Dimensional self-attention, which captures intra-view dependencies among features within each stream; (ii) Cross-Encoding self-attention, which enables bidirectional interaction between raw and target-aware representations; and (iii) an Adaptive Sparse Self-Attention (ASSA) mechanism, which dynamically suppresses low-utility tokens by driving their attention weights toward zero--thereby mitigating the impact of noise. Empirical results on multiple public benchmarks show consistent gains over strong baselines, confirming that jointly modeling raw and target-aware views--while adaptively filtering noise--yields a more robust deep tabular learner.</li>
</ul>

<h3>Title: On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Shuhei Tarashima, Yushan Wang, Norio Tagawa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12660">https://arxiv.org/abs/2510.12660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12660">https://arxiv.org/pdf/2510.12660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12660]] On the Use of Hierarchical Vision Foundation Models for Low-Cost Human Mesh Recovery and Pose Estimation(https://arxiv.org/abs/2510.12660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this work, we aim to develop simple and efficient models for human mesh recovery (HMR) and its predecessor task, human pose estimation (HPE). State-of-the-art HMR methods, such as HMR2.0 and its successors, rely on large, non-hierarchical vision transformers as encoders, which are inherited from the corresponding HPE models like ViTPose. To establish baselines across varying computational budgets, we first construct three lightweight HMR2.0 variants by adapting the corresponding ViTPose models. In addition, we propose leveraging the early stages of hierarchical vision foundation models (VFMs), including Swin Transformer, GroupMixFormer, and VMamba, as encoders. This design is motivated by the observation that intermediate stages of hierarchical VFMs produce feature maps with resolutions comparable to or higher than those of non-hierarchical counterparts. We conduct a comprehensive evaluation of 27 hierarchical-VFM-based HMR and HPE models, demonstrating that using only the first two or three stages achieves performance on par with full-stage models. Moreover, we show that the resulting truncated models exhibit better trade-offs between accuracy and computational efficiency compared to existing lightweight alternatives.</li>
</ul>

<h3>Title: Hash chaining degrades security at Facebook</h3>
<ul>
<li><strong>Authors: </strong>Thomas Rivasseau</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12665">https://arxiv.org/abs/2510.12665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12665">https://arxiv.org/pdf/2510.12665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12665]] Hash chaining degrades security at Facebook(https://arxiv.org/abs/2510.12665)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Modern web and digital application password storage relies on password hashing for storage and security. Ad-hoc upgrade of password storage to keep up with hash algorithm norms may be used to save costs but can introduce unforeseen vulnerabilities. This is the case in the password storage scheme used by Meta Platforms which services several billion monthly users worldwide. In this paper we present the first example of an exploit which demonstrates the security weakness of Facebook's password storage scheme, and discuss its implications. Proper ethical disclosure guidelines and vendor notification were followed.</li>
</ul>

<h3>Title: TerraCodec: Compressing Earth Observations</h3>
<ul>
<li><strong>Authors: </strong>Julen Costa-Watanabe, Isabelle Wittmann, Benedikt Blumenstiel, Konrad Schindler</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12670">https://arxiv.org/abs/2510.12670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12670">https://arxiv.org/pdf/2510.12670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12670]] TerraCodec: Compressing Earth Observations(https://arxiv.org/abs/2510.12670)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Earth observation (EO) satellites produce massive streams of multispectral image time series, posing pressing challenges for storage and transmission. Yet, learned EO compression remains fragmented, lacking publicly available pretrained models and misaligned with advances in compression for natural imagery. Image codecs overlook temporal redundancy, while video codecs rely on motion priors that fail to capture the radiometric evolution of largely static scenes. We introduce TerraCodec (TEC), a family of learned codecs tailored to EO. TEC includes efficient image-based variants adapted to multispectral inputs, as well as a Temporal Transformer model (TEC-TT) that leverages dependencies across time. To overcome the fixed-rate setting of today's neural codecs, we present Latent Repacking, a novel method for training flexible-rate transformer models that operate on varying rate-distortion settings. Trained on Sentinel-2 data, TerraCodec outperforms classical codecs, achieving 3-10x stronger compression at equivalent image quality. Beyond compression, TEC-TT enables zero-shot cloud inpainting, surpassing state-of-the-art methods on the AllClear benchmark. Our results establish bespoke, learned compression algorithms as a promising direction for Earth observation. Code and model weights will be released under a permissive license.</li>
</ul>

<h3>Title: Keep Calm and Avoid Harmful Content: Concept Alignment and Latent Manipulation Towards Safer Answers</h3>
<ul>
<li><strong>Authors: </strong>Ruben Belo, Claudia Soares, Marta Guimaraes</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12672">https://arxiv.org/abs/2510.12672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12672">https://arxiv.org/pdf/2510.12672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12672]] Keep Calm and Avoid Harmful Content: Concept Alignment and Latent Manipulation Towards Safer Answers(https://arxiv.org/abs/2510.12672)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are susceptible to jailbreak attacks that bypass built-in safety guardrails (e.g., by tricking the model with adversarial prompts). We propose Concept Alignment and Concept Manipulation \textbf{CALM}, an inference-time method that suppresses harmful concepts by modifying latent representations of the last layer of the model, without retraining. Leveraging \gls*{cw} technique from Computer Vision combined with orthogonal projection, CALM removes unwanted latent directions associated with harmful content while preserving model performance. Experiments show that CALM reduces harmful outputs and outperforms baseline methods in most metrics, offering a lightweight approach to AI safety with no additional training data or model fine-tuning, while incurring only a small computational overhead at inference.</li>
</ul>

<h3>Title: Few Shot Semi-Supervised Learning for Abnormal Stop Detection from Sparse GPS Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ayub Sabir, Junbiao Pang, Jiaqi Wu, Fatima Ashraf</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12686">https://arxiv.org/abs/2510.12686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12686">https://arxiv.org/pdf/2510.12686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12686]] Few Shot Semi-Supervised Learning for Abnormal Stop Detection from Sparse GPS Trajectories(https://arxiv.org/abs/2510.12686)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Abnormal stop detection (ASD) in intercity coach transportation is critical for ensuring passenger safety, operational reliability, and regulatory compliance. However, two key challenges hinder ASD effectiveness: sparse GPS trajectories, which obscure short or unauthorized stops, and limited labeled data, which restricts supervised learning. Existing methods often assume dense sampling or regular movement patterns, limiting their applicability. To address data sparsity, we propose a Sparsity-Aware Segmentation (SAS) method that adaptively defines segment boundaries based on local spatial-temporal density. Building upon these segments, we introduce three domain-specific indicators to capture abnormal stop behaviors. To further mitigate the impact of sparsity, we develop Locally Temporal-Indicator Guided Adjustment (LTIGA), which smooths these indicators via local similarity graphs. To overcome label scarcity, we construct a spatial-temporal graph where each segment is a node with LTIGA-refined features. We apply label propagation to expand weak supervision across the graph, followed by a GCN to learn relational patterns. A final self-training module incorporates high-confidence pseudo-labels to iteratively improve predictions. Experiments on real-world coach data show an AUC of 0.854 and AP of 0.866 using only 10 labeled instances, outperforming prior methods. The code and dataset are publicly available at \href{this https URL}</li>
</ul>

<h3>Title: DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization</h3>
<ul>
<li><strong>Authors: </strong>Danial Hosseintabar, Fan Chen, Giannis Daras, Antonio Torralba, Constantinos Daskalakis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12691">https://arxiv.org/abs/2510.12691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12691">https://arxiv.org/pdf/2510.12691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12691]] DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization(https://arxiv.org/abs/2510.12691)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as powerful generative priors for high-dimensional inverse problems, yet learning them when only corrupted or noisy observations are available remains challenging. In this work, we propose a new method for training diffusion models with Expectation-Maximization (EM) from corrupted data. Our proposed method, DiffEM, utilizes conditional diffusion models to reconstruct clean data from observations in the E-step, and then uses the reconstructed data to refine the conditional diffusion model in the M-step. Theoretically, we provide monotonic convergence guarantees for the DiffEM iteration, assuming appropriate statistical conditions. We demonstrate the effectiveness of our approach through experiments on various image reconstruction tasks.</li>
</ul>

<h3>Title: Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Shelley Zixin Shu, Haozhe Luo, Alexander Poellinger, Mauricio Reyes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12704">https://arxiv.org/abs/2510.12704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12704">https://arxiv.org/pdf/2510.12704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12704]] Hybrid Explanation-Guided Learning for Transformer-Based Chest X-Ray Diagnosis(https://arxiv.org/abs/2510.12704)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based deep learning models have demonstrated exceptional performance in medical imaging by leveraging attention mechanisms for feature representation and interpretability. However, these models are prone to learning spurious correlations, leading to biases and limited generalization. While human-AI attention alignment can mitigate these issues, it often depends on costly manual supervision. In this work, we propose a Hybrid Explanation-Guided Learning (H-EGL) framework that combines self-supervised and human-guided constraints to enhance attention alignment and improve generalization. The self-supervised component of H-EGL leverages class-distinctive attention without relying on restrictive priors, promoting robustness and flexibility. We validate our approach on chest X-ray classification using the Vision Transformer (ViT), where H-EGL outperforms two state-of-the-art Explanation-Guided Learning (EGL) methods, demonstrating superior classification accuracy and generalization capability. Additionally, it produces attention maps that are better aligned with human expertise.</li>
</ul>

<h3>Title: Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xingang Guo, Utkarsh Tyagi, Advait Gosai, Paula Vergara, Ernesto Gabriel Hernández Montoya, Chen Bo Calvin Zhang, Bin Hu, Yunzhong He, Bing Liu, Rakshith Sharma Srinivasa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12712">https://arxiv.org/abs/2510.12712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12712">https://arxiv.org/pdf/2510.12712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12712]] Beyond Seeing: Evaluating Multimodal LLMs on Tool-Enabled Image Perception, Transformation, and Reasoning(https://arxiv.org/abs/2510.12712)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) are increasingly applied in real-world scenarios where user-provided images are often imperfect, requiring active image manipulations such as cropping, editing, or enhancement to uncover salient visual cues. Beyond static visual perception, MLLMs must also think with images: dynamically transforming visual content and integrating it with other tools to solve complex tasks. However, this shift from treating vision as passive context to a manipulable cognitive workspace remains underexplored. Most existing benchmarks still follow a think about images paradigm, where images are regarded as static inputs. To address this gap, we introduce IRIS, an Interactive Reasoning with Images and Systems that evaluates MLLMs' ability to perceive, transform, and reason across complex visual-textual tasks under the think with images paradigm. IRIS comprises 1,204 challenging, open-ended vision tasks (603 single-turn, 601 multi-turn) spanning across five diverse domains, each paired with detailed rubrics to enable systematic evaluation. Our evaluation shows that current MLLMs struggle with tasks requiring effective integration of vision and general-purpose tools. Even the strongest model (GPT-5-think) reaches only 18.68% pass rate. We further observe divergent tool-use behaviors, with OpenAI models benefiting from diverse image manipulations while Gemini-2.5-pro shows no improvement. By introducing the first benchmark centered on think with images, IRIS offers critical insights for advancing visual intelligence in MLLMs.</li>
</ul>

<h3>Title: Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction</h3>
<ul>
<li><strong>Authors: </strong>Matthew Adrian, Yunsie Chung, Kevin Boyd, Saee Paliwal, Srimukh Prasad Veccham, Alan C. Cheng</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12719">https://arxiv.org/abs/2510.12719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12719">https://arxiv.org/pdf/2510.12719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12719]] Multitask finetuning and acceleration of chemical pretrained models for small molecule drug property prediction(https://arxiv.org/abs/2510.12719)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Chemical pretrained models, sometimes referred to as foundation models, are receiving considerable interest for drug discovery applications. The general chemical knowledge extracted from self-supervised training has the potential to improve predictions for critical drug discovery endpoints, including on-target potency and ADMET properties. Multi-task learning has previously been successfully leveraged to improve predictive models. Here, we show that enabling multitasking in finetuning of chemical pretrained graph neural network models such as Kinetic GROVER Multi-Task (KERMT), an enhanced version of the GROVER model, and Knowledge-guided Pre-training of Graph Transformer (KGPT) significantly improves performance over non-pretrained graph neural network models. Surprisingly, we find that the performance improvement from finetuning KERMT in a multitask manner is most significant at larger data sizes. Additionally, we publish two multitask ADMET data splits to enable more accurate benchmarking of multitask deep learning methods for drug property prediction. Finally, we provide an accelerated implementation of the KERMT model on GitHub, unlocking large-scale pretraining, finetuning, and inference in industrial drug discovery workflows.</li>
</ul>

<h3>Title: CARVQ: Corrective Adaptor with Group Residual Vector Quantization for LLM Embedding Compression</h3>
<ul>
<li><strong>Authors: </strong>Dayin Gou, Sanghyun Byun, Nilesh Malpeddi, Gabrielle De Micheli, Prathamesh Vaste, Jacob Song, Woo Seong Chung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12721">https://arxiv.org/abs/2510.12721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12721">https://arxiv.org/pdf/2510.12721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12721]] CARVQ: Corrective Adaptor with Group Residual Vector Quantization for LLM Embedding Compression(https://arxiv.org/abs/2510.12721)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) typically rely on a large number of parameters for token embedding, leading to substantial storage requirements and memory footprints. In particular, LLMs deployed on edge devices are memory-bound, and reducing the memory footprint by compressing the embedding layer not only frees up the memory bandwidth but also speeds up inference. To address this, we introduce CARVQ, a post-training novel Corrective Adaptor combined with group Residual Vector Quantization. CARVQ relies on the composition of both linear and non-linear maps and mimics the original model embedding to compress to approximately 1.6 bits without requiring specialized hardware to support lower-bit storage. We test our method on pre-trained LLMs such as LLaMA-3.2-1B, LLaMA-3.2-3B, LLaMA-3.2-3B-Instruct, LLaMA-3.1-8B, Qwen2.5-7B, Qwen2.5-Math-7B and Phi-4, evaluating on common generative, discriminative, math and reasoning tasks. We show that in most cases, CARVQ can achieve lower average bitwidth-per-parameter while maintaining reasonable perplexity and accuracy compared to scalar quantization. Our contributions include a novel compression technique that is compatible with state-of-the-art transformer quantization methods and can be seamlessly integrated into any hardware supporting 4-bit memory to reduce the model's memory footprint in memory-constrained devices. This work demonstrates a crucial step toward the efficient deployment of LLMs on edge devices.</li>
</ul>

<h3>Title: Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems</h3>
<ul>
<li><strong>Authors: </strong>Anas Abouaomar, Mohammed El hanjri, Abdellatif Kobbane, Anis Laouiti, Khalid Nafil</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12727">https://arxiv.org/abs/2510.12727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12727">https://arxiv.org/pdf/2510.12727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12727]] Hierarchical Federated Learning for Crop Yield Prediction in Smart Agricultural Production Systems(https://arxiv.org/abs/2510.12727)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In this paper, we presents a novel hierarchical federated learning architecture specifically designed for smart agricultural production systems and crop yield prediction. Our approach introduces a seasonal subscription mechanism where farms join crop-specific clusters at the beginning of each agricultural season. The proposed three-layer architecture consists of individual smart farms at the client level, crop-specific aggregators at the middle layer, and a global model aggregator at the top level. Within each crop cluster, clients collaboratively train specialized models tailored to specific crop types, which are then aggregated to produce a higher-level global model that integrates knowledge across multiple crops. This hierarchical design enables both local specialization for individual crop types and global generalization across diverse agricultural contexts while preserving data privacy and reducing communication overhead. Experiments demonstrate the effectiveness of the proposed system, showing that local and crop-layer models closely follow actual yield patterns with consistent alignment, significantly outperforming standard machine learning models. The results validate the advantages of hierarchical federated learning in the agricultural context, particularly for scenarios involving heterogeneous farming environments and privacy-sensitive agricultural data.</li>
</ul>

<h3>Title: Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect</h3>
<ul>
<li><strong>Authors: </strong>Jon Donnelly, Srikar Katta, Emanuele Borgonovo, Cynthia Rudin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12734">https://arxiv.org/abs/2510.12734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12734">https://arxiv.org/pdf/2510.12734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12734]] Doctor Rashomon and the UNIVERSE of Madness: Variable Importance with Unobserved Confounding and the Rashomon Effect(https://arxiv.org/abs/2510.12734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Variable importance (VI) methods are often used for hypothesis generation, feature selection, and scientific validation. In the standard VI pipeline, an analyst estimates VI for a single predictive model with only the observed features. However, the importance of a feature depends heavily on which other variables are included in the model, and essential variables are often omitted from observational datasets. Moreover, the VI estimated for one model is often not the same as the VI estimated for another equally-good model - a phenomenon known as the Rashomon Effect. We address these gaps by introducing UNobservables and Inference for Variable importancE using Rashomon SEts (UNIVERSE). Our approach adapts Rashomon sets - the sets of near-optimal models in a dataset - to produce bounds on the true VI even with missing features. We theoretically guarantee the robustness of our approach, show strong performance on semi-synthetic simulations, and demonstrate its utility in a credit risk task.</li>
</ul>

<h3>Title: Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Adam Tupper, Christian Gagné</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12741">https://arxiv.org/abs/2510.12741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12741">https://arxiv.org/pdf/2510.12741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12741]] Personalized Federated Fine-Tuning of Vision Foundation Models for Healthcare(https://arxiv.org/abs/2510.12741)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Foundation models open up new possibilities for the use of AI in healthcare. However, even when pre-trained on health data, they still need to be fine-tuned for specific downstream tasks. Furthermore, although foundation models reduce the amount of training data required to achieve good performance, obtaining sufficient data is still a challenge. This is due, in part, to restrictions on sharing and aggregating data from different sources to protect patients' privacy. One possible solution to this is to fine-tune foundation models via federated learning across multiple participating clients (i.e., hospitals, clinics, etc.). In this work, we propose a new personalized federated fine-tuning method that learns orthogonal LoRA adapters to disentangle general and client-specific knowledge, enabling each client to fully exploit both their own data and the data of others. Our preliminary results on real-world federated medical imaging tasks demonstrate that our approach is competitive against current federated fine-tuning methods.</li>
</ul>

<h3>Title: FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Junhao Zhuang, Shi Guo, Xin Cai, Xiaohui Li, Yihao Liu, Chun Yuan, Tianfan Xue</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12747">https://arxiv.org/abs/2510.12747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12747">https://arxiv.org/pdf/2510.12747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12747]] FlashVSR: Towards Real-Time Diffusion-Based Streaming Video Super-Resolution(https://arxiv.org/abs/2510.12747)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have recently advanced video restoration, but applying them to real-world video super-resolution (VSR) remains challenging due to high latency, prohibitive computation, and poor generalization to ultra-high resolutions. Our goal in this work is to make diffusion-based VSR practical by achieving efficiency, scalability, and real-time performance. To this end, we propose FlashVSR, the first diffusion-based one-step streaming framework towards real-time VSR. FlashVSR runs at approximately 17 FPS for 768x1408 videos on a single A100 GPU by combining three complementary innovations: (i) a train-friendly three-stage distillation pipeline that enables streaming super-resolution, (ii) locality-constrained sparse attention that cuts redundant computation while bridging the train-test resolution gap, and (iii) a tiny conditional decoder that accelerates reconstruction without sacrificing quality. To support large-scale training, we also construct VSR-120K, a new dataset with 120k videos and 180k images. Extensive experiments show that FlashVSR scales reliably to ultra-high resolutions and achieves state-of-the-art performance with up to 12x speedup over prior one-step diffusion VSR models. We will release the code, pretrained models, and dataset to foster future research in efficient diffusion-based VSR.</li>
</ul>

<h3>Title: SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding</h3>
<ul>
<li><strong>Authors: </strong>Zhiliu Yang, Jinyu Dai, Jianyuan Zhang, Zhu Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12749">https://arxiv.org/abs/2510.12749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12749">https://arxiv.org/pdf/2510.12749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12749]] SPORTS: Simultaneous Panoptic Odometry, Rendering, Tracking and Segmentation for Urban Scenes Understanding(https://arxiv.org/abs/2510.12749)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The scene perception, understanding, and simulation are fundamental techniques for embodied-AI agents, while existing solutions are still prone to segmentation deficiency, dynamic objects' interference, sensor data sparsity, and view-limitation problems. This paper proposes a novel framework, named SPORTS, for holistic scene understanding via tightly integrating Video Panoptic Segmentation (VPS), Visual Odometry (VO), and Scene Rendering (SR) tasks into an iterative and unified perspective. Firstly, VPS designs an adaptive attention-based geometric fusion mechanism to align cross-frame features via enrolling the pose, depth, and optical flow modality, which automatically adjust feature maps for different decoding stages. And a post-matching strategy is integrated to improve identities tracking. In VO, panoptic segmentation results from VPS are combined with the optical flow map to improve the confidence estimation of dynamic objects, which enhances the accuracy of the camera pose estimation and completeness of the depth map generation via the learning-based paradigm. Furthermore, the point-based rendering of SR is beneficial from VO, transforming sparse point clouds into neural fields to synthesize high-fidelity RGB views and twin panoptic views. Extensive experiments on three public datasets demonstrate that our attention-based feature fusion outperforms most existing state-of-the-art methods on the odometry, tracking, segmentation, and novel view synthesis tasks.</li>
</ul>

<h3>Title: VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage</h3>
<ul>
<li><strong>Authors: </strong>A. Alfarano, L. Venturoli, D. Negueruela del Castillo (University of Zurich, Max Planck Society)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12750">https://arxiv.org/abs/2510.12750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12750">https://arxiv.org/pdf/2510.12750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12750]] VQArt-Bench: A semantically rich VQA Benchmark for Art and Cultural Heritage(https://arxiv.org/abs/2510.12750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated significant capabilities in joint visual and linguistic tasks. However, existing Visual Question Answering (VQA) benchmarks often fail to evaluate deep semantic understanding, particularly in complex domains like visual art analysis. Confined to simple syntactic structures and surface-level attributes, these questions fail to capture the diversity and depth of human visual inquiry. This limitation incentivizes models to exploit statistical shortcuts rather than engage in visual reasoning. To address this gap, we introduce VQArt-Bench, a new, large-scale VQA benchmark for the cultural heritage domain. This benchmark is constructed using a novel multi-agent pipeline where specialized agents collaborate to generate nuanced, validated, and linguistically diverse questions. The resulting benchmark is structured along relevant visual understanding dimensions that probe a model's ability to interpret symbolic meaning, narratives, and complex visual relationships. Our evaluation of 14 state-of-the-art MLLMs on this benchmark reveals significant limitations in current models, including a surprising weakness in simple counting tasks and a clear performance gap between proprietary and open-source models.</li>
</ul>

<h3>Title: KoALA: KL-L0 Adversarial Detector via Label Agreement</h3>
<ul>
<li><strong>Authors: </strong>Siqi Li, Yasser Shoukry</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12752">https://arxiv.org/abs/2510.12752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12752">https://arxiv.org/pdf/2510.12752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12752]] KoALA: KL-L0 Adversarial Detector via Label Agreement(https://arxiv.org/abs/2510.12752)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Deep neural networks are highly susceptible to adversarial attacks, which pose significant risks to security- and safety-critical applications. We present KoALA (KL-L0 Adversarial detection via Label Agreement), a novel, semantics-free adversarial detector that requires no architectural changes or adversarial retraining. KoALA operates on a simple principle: it detects an adversarial attack when class predictions from two complementary similarity metrics disagree. These metrics-KL divergence and an L0-based similarity-are specifically chosen to detect different types of perturbations. The KL divergence metric is sensitive to dense, low-amplitude shifts, while the L0-based similarity is designed for sparse, high-impact changes. We provide a formal proof of correctness for our approach. The only training required is a simple fine-tuning step on a pre-trained image encoder using clean images to ensure the embeddings align well with both metrics. This makes KOALA a lightweight, plug-and-play solution for existing models and various data modalities. Our extensive experiments on ResNet/CIFAR-10 and CLIP/Tiny-ImageNet confirm our theoretical claims. When the theorem's conditions are met, KoALA consistently and effectively detects adversarial examples. On the full test sets, KoALA achieves a precision of 0.94 and a recall of 0.81 on ResNet/CIFAR-10, and a precision of 0.66 and a recall of 0.85 on CLIP/Tiny-ImageNet.</li>
</ul>

<h3>Title: E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization</h3>
<ul>
<li><strong>Authors: </strong>Wenpu Li, Bangyan Liao, Yi Zhou, Qi Xu, Pian Wan, Peidong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12753">https://arxiv.org/abs/2510.12753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12753">https://arxiv.org/pdf/2510.12753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12753]] E-MoFlow: Learning Egomotion and Optical Flow from Event Data via Implicit Regularization(https://arxiv.org/abs/2510.12753)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The estimation of optical flow and 6-DoF ego-motion, two fundamental tasks in 3D vision, has typically been addressed independently. For neuromorphic vision (e.g., event cameras), however, the lack of robust data association makes solving the two problems separately an ill-posed challenge, especially in the absence of supervision via ground truth. Existing works mitigate this ill-posedness by either enforcing the smoothness of the flow field via an explicit variational regularizer or leveraging explicit structure-and-motion priors in the parametrization to improve event alignment. The former notably introduces bias in results and computational overhead, while the latter, which parametrizes the optical flow in terms of the scene depth and the camera motion, often converges to suboptimal local minima. To address these issues, we propose an unsupervised framework that jointly optimizes egomotion and optical flow via implicit spatial-temporal and geometric regularization. First, by modeling camera's egomotion as a continuous spline and optical flow as an implicit neural representation, our method inherently embeds spatial-temporal coherence through inductive biases. Second, we incorporate structure-and-motion priors through differential geometric constraints, bypassing explicit depth estimation while maintaining rigorous geometric consistency. As a result, our framework (called E-MoFlow) unifies egomotion and optical flow estimation via implicit regularization under a fully unsupervised paradigm. Experiments demonstrate its versatility to general 6-DoF motion scenarios, achieving state-of-the-art performance among unsupervised methods and competitive even with supervised approaches.</li>
</ul>

<h3>Title: Dr.LLM: Dynamic Layer Routing in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Heakl, Martin Gubri, Salman Khan, Sangdoo Yun, Seong Joon Oh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12773">https://arxiv.org/abs/2510.12773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12773">https://arxiv.org/pdf/2510.12773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12773]] Dr.LLM: Dynamic Layer Routing in LLMs(https://arxiv.org/abs/2510.12773)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) process every token through all layers of a transformer stack, causing wasted computation on simple queries and insufficient flexibility for harder ones that need deeper reasoning. Adaptive-depth methods can improve efficiency, but prior approaches rely on costly inference-time search, architectural changes, or large-scale retraining, and in practice often degrade accuracy despite efficiency gains. We introduce this http URL, Dynamic routing of Layers for LLMs, a retrofittable framework that equips pretrained models with lightweight per-layer routers deciding to skip, execute, or repeat a block. Routers are trained with explicit supervision: using Monte Carlo Tree Search (MCTS), we derive high-quality layer configurations that preserve or improve accuracy under a compute budget. Our design, windowed pooling for stable routing, focal loss with class balancing, and bottleneck MLP routers, ensures robustness under class imbalance and long sequences. On ARC (logic) and DART (math), this http URL improves accuracy by up to +3.4%p while saving 5 layers per example on average. Routers generalize to out-of-domain tasks (MMLU, GSM8k, AIME, TruthfulQA, SQuADv2, GPQA, PIQA, AGIEval) with only 0.85% accuracy drop while retaining efficiency, and outperform prior routing methods by up to +7.7%p. Overall, this http URL shows that explicitly supervised routers retrofit frozen LLMs for budget-aware, accuracy-driven inference without altering base weights.</li>
</ul>

<h3>Title: What If : Understanding Motion Through Sparse Interactions</h3>
<ul>
<li><strong>Authors: </strong>Stefan Andreas Baumann, Nick Stracke, Timy Phan, Björn Ommer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12777">https://arxiv.org/abs/2510.12777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12777">https://arxiv.org/pdf/2510.12777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12777]] What If : Understanding Motion Through Sparse Interactions(https://arxiv.org/abs/2510.12777)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Understanding the dynamics of a physical scene involves reasoning about the diverse ways it can potentially change, especially as a result of local interactions. We present the Flow Poke Transformer (FPT), a novel framework for directly predicting the distribution of local motion, conditioned on sparse interactions termed "pokes". Unlike traditional methods that typically only enable dense sampling of a single realization of scene dynamics, FPT provides an interpretable directly accessible representation of multi-modal scene motion, its dependency on physical interactions and the inherent uncertainties of scene dynamics. We also evaluate our model on several downstream tasks to enable comparisons with prior methods and highlight the flexibility of our approach. On dense face motion generation, our generic pre-trained model surpasses specialized baselines. FPT can be fine-tuned in strongly out-of-distribution tasks such as synthetic datasets to enable significant improvements over in-domain methods in articulated object motion estimation. Additionally, predicting explicit motion distributions directly enables our method to achieve competitive performance on tasks like moving part segmentation from pokes which further demonstrates the versatility of our FPT. Code and models are publicly available at this https URL.</li>
</ul>

<h3>Title: MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars</h3>
<ul>
<li><strong>Authors: </strong>Felix Taubner, Ruihang Zhang, Mathieu Tuli, Sherwin Bahmani, David B. Lindell</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12785">https://arxiv.org/abs/2510.12785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12785">https://arxiv.org/pdf/2510.12785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12785]] MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars(https://arxiv.org/abs/2510.12785)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Digital human avatars aim to simulate the dynamic appearance of humans in virtual environments, enabling immersive experiences across gaming, film, virtual reality, and more. However, the conventional process for creating and animating photorealistic human avatars is expensive and time-consuming, requiring large camera capture rigs and significant manual effort from professional 3D artists. With the advent of capable image and video generation models, recent methods enable automatic rendering of realistic animated avatars from a single casually captured reference image of a target subject. While these techniques significantly lower barriers to avatar creation and offer compelling realism, they lack constraints provided by multi-view information or an explicit 3D representation. So, image quality and realism degrade when rendered from viewpoints that deviate strongly from the reference image. Here, we build a video model that generates animatable multi-view videos of digital humans based on a single reference image and target expressions. Our model, MVP4D, is based on a state-of-the-art pre-trained video diffusion model and generates hundreds of frames simultaneously from viewpoints varying by up to 360 degrees around a target subject. We show how to distill the outputs of this model into a 4D avatar that can be rendered in real-time. Our approach significantly improves the realism, temporal consistency, and 3D consistency of generated avatars compared to previous methods.</li>
</ul>

<h3>Title: UniFusion: Vision-Language Model as Unified Encoder in Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Kevin Li, Manuel Brack, Sudeep Katakol, Hareesh Ravi, Ajinkya Kale</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12789">https://arxiv.org/abs/2510.12789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12789">https://arxiv.org/pdf/2510.12789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12789]] UniFusion: Vision-Language Model as Unified Encoder in Image Generation(https://arxiv.org/abs/2510.12789)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Although recent advances in visual generation have been remarkable, most existing architectures still depend on distinct encoders for images and text. This separation constrains diffusion models' ability to perform cross-modal reasoning and knowledge transfer. Prior attempts to bridge this gap often use the last layer information from VLM, employ multiple visual encoders, or train large unified models jointly for text and image generation, which demands substantial computational resources and large-scale data, limiting its this http URL present UniFusion, a diffusion-based generative model conditioned on a frozen large vision-language model (VLM) that serves as a unified multimodal encoder. At the core of UniFusion is the Layerwise Attention Pooling (LAP) mechanism that extracts both high level semantics and low level details from text and visual tokens of a frozen VLM to condition a diffusion generative model. We demonstrate that LAP outperforms other shallow fusion architectures on text-image alignment for generation and faithful transfer of visual information from VLM to the diffusion model which is key for editing. We propose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI), which conditions a diffusion transformer (DiT) only on the text tokens generated by the VLM during in-model prompt rewriting. VERIFI combines the alignment of the conditioning distribution with the VLM's reasoning capabilities for increased capabilities and flexibility at inference. In addition, finetuning on editing task not only improves text-image alignment for generation, indicative of cross-modality knowledge transfer, but also exhibits tremendous generalization capabilities. Our model when trained on single image editing, zero-shot generalizes to multiple image references further motivating the unified encoder design of UniFusion.</li>
</ul>

<h3>Title: ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Long Cui, Weiyun Wang, Jie Shao, Zichen Wen, Gen Luo, Linfeng Zhang, Yanting Zhang, Yu Qiao, Wenhai Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12793">https://arxiv.org/abs/2510.12793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12793">https://arxiv.org/pdf/2510.12793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12793]] ViCO: A Training Strategy towards Semantic Aware Dynamic High-Resolution(https://arxiv.org/abs/2510.12793)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing Multimodal Large Language Models (MLLMs) suffer from increased inference costs due to the additional vision tokens introduced by image inputs. In this work, we propose Visual Consistency Learning (ViCO), a novel training algorithm that enables the model to represent images of varying semantic complexities using different numbers of vision tokens. The key idea behind our method is to employ multiple MLP connectors, each with a different image compression ratio, to downsample the vision tokens based on the semantic complexity of the image. During training, we minimize the KL divergence between the responses conditioned on different MLP connectors. At inference time, we introduce an image router, termed Visual Resolution Router (ViR), that automatically selects the appropriate compression rate for each image patch. Compared with existing dynamic high-resolution strategies, which adjust the number of visual tokens based on image resolutions, our method dynamically adapts the number of visual tokens according to semantic complexity. Experimental results demonstrate that our method can reduce the number of vision tokens by up to 50% while maintaining the model's perception, reasoning, and OCR capabilities. We hope this work will contribute to the development of more efficient MLLMs. The code and models will be released to facilitate future research.</li>
</ul>

<h3>Title: CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations</h3>
<ul>
<li><strong>Authors: </strong>Caner Korkmaz, Brighton Nuwagira, Barış Coşkunuzer, Tolga Birdal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, math.AT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12795">https://arxiv.org/abs/2510.12795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12795">https://arxiv.org/pdf/2510.12795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12795]] CuMPerLay: Learning Cubical Multiparameter Persistence Vectorizations(https://arxiv.org/abs/2510.12795)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>We present CuMPerLay, a novel differentiable vectorization layer that enables the integration of Cubical Multiparameter Persistence (CMP) into deep learning pipelines. While CMP presents a natural and powerful way to topologically work with images, its use is hindered by the complexity of multifiltration structures as well as the vectorization of CMP. In face of these challenges, we introduce a new algorithm for vectorizing MP homologies of cubical complexes. Our CuMPerLay decomposes the CMP into a combination of individual, learnable single-parameter persistence, where the bifiltration functions are jointly learned. Thanks to the differentiability, its robust topological feature vectors can be seamlessly used within state-of-the-art architectures such as Swin Transformers. We establish theoretical guarantees for the stability of our vectorization under generalized Wasserstein metrics. Our experiments on benchmark medical imaging and computer vision datasets show the benefit CuMPerLay on classification and segmentation performance, particularly in limited-data scenarios. Overall, CuMPerLay offers a promising direction for integrating global structural information into deep networks for structured image analysis.</li>
</ul>

<h3>Title: DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Yingyan Li, Shuyao Shang, Weisong Liu, Bing Zhan, Haochen Wang, Yuqi Wang, Yuntao Chen, Xiaoman Wang, Yasong An, Chufeng Tang, Lu Hou, Lue Fan, Zhaoxiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12796">https://arxiv.org/abs/2510.12796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12796">https://arxiv.org/pdf/2510.12796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12796]] DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving(https://arxiv.org/abs/2510.12796)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Scaling Vision-Language-Action (VLA) models on large-scale data offers a promising path to achieving a more generalized driving intelligence. However, VLA models are limited by a ``supervision deficit'': the vast model capacity is supervised by sparse, low-dimensional actions, leaving much of their representational power underutilized. To remedy this, we propose \textbf{DriveVLA-W0}, a training paradigm that employs world modeling to predict future images. This task generates a dense, self-supervised signal that compels the model to learn the underlying dynamics of the driving environment. We showcase the paradigm's versatility by instantiating it for two dominant VLA archetypes: an autoregressive world model for VLAs that use discrete visual tokens, and a diffusion world model for those operating on continuous visual features. Building on the rich representations learned from world modeling, we introduce a lightweight action expert to address the inference latency for real-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a 680x larger in-house dataset demonstrate that DriveVLA-W0 significantly outperforms BEV and VLA baselines. Crucially, it amplifies the data scaling law, showing that performance gains accelerate as the training dataset size increases.</li>
</ul>

<h3>Title: DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search</h3>
<ul>
<li><strong>Authors: </strong>Kartik Narayan, Yang Xu, Tian Cao, Kavya Nerella, Vishal M. Patel, Navid Shiee, Peter Grasch, Chao Jia, Yinfei Yang, Zhe Gan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.12801">https://arxiv.org/abs/2510.12801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.12801">https://arxiv.org/pdf/2510.12801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.12801]] DeepMMSearch-R1: Empowering Multimodal LLMs in Multimodal Web Search(https://arxiv.org/abs/2510.12801)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) in real-world applications require access to external knowledge sources and must remain responsive to the dynamic and ever-changing real-world information in order to address information-seeking and knowledge-intensive user queries. Existing approaches, such as retrieval augmented generation (RAG) methods, search agents, and search equipped MLLMs, often suffer from rigid pipelines, excessive search calls, and poorly constructed search queries, which result in inefficiencies and suboptimal outcomes. To address these limitations, we present DeepMMSearch-R1, the first multimodal LLM capable of performing on-demand, multi-turn web searches and dynamically crafting queries for both image and text search tools. Specifically, DeepMMSearch-R1 can initiate web searches based on relevant crops of the input image making the image search more effective, and can iteratively adapt text search queries based on retrieved information, thereby enabling self-reflection and self-correction. Our approach relies on a two-stage training pipeline: a cold start supervised finetuning phase followed by an online reinforcement learning optimization. For training, we introduce DeepMMSearchVQA, a novel multimodal VQA dataset created through an automated pipeline intermixed with real-world information from web search tools. This dataset contains diverse, multi-hop queries that integrate textual and visual information, teaching the model when to search, what to search for, which search tool to use and how to reason over the retrieved information. We conduct extensive experiments across a range of knowledge-intensive benchmarks to demonstrate the superiority of our approach. Finally, we analyze the results and provide insights that are valuable for advancing multimodal web-search.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
