<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Recovering Sign Bits of DCT Coefficients in Digital Images as an Optimization Problem. (arXiv:2211.01096v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01096">http://arxiv.org/abs/2211.01096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01096] Recovering Sign Bits of DCT Coefficients in Digital Images as an Optimization Problem](http://arxiv.org/abs/2211.01096)</code></li>
<li>Summary: <p>Recovering unknown, missing, damaged, distorted or lost information in DCT
coefficients is a common task in multiple applications of digital image
processing, including image compression, selective image encryption, and image
communications. This paper investigates recovery of a special type of
information in DCT coefficients of digital images: sign bits. This problem can
be modelled as a mixed integer linear programming (MILP) problem, which is
NP-hard in general. To efficiently solve the problem, we propose two
approximation methods: 1) a relaxation-based method that convert the MILP
problem to a linear programming (LP) problem; 2) a divide-and-conquer method
which splits the target image into sufficiently small regions, each of which
can be more efficiently solved as an MILP problem, and then conducts a global
optimization phase as a smaller MILP problem or an LP problem to maximize
smoothness across different regions. To the best of our knowledge, we are the
first who considered how to use global optimization to recover sign bits of DCT
coefficients. We considered how the proposed methods can be applied to
JPEG-encoded images and conducted extensive experiments to validate the
performances of our proposed methods. The experimental results showed that the
proposed methods worked well, especially when the number of unknown sign bits
per DCT block is not too large. Compared with other existing methods, which are
all based on simple error-concealment strategies, our proposed methods
outperformed them with a substantial margin, both according to objective
quality metrics (PSNR and SSIM) and also our subjective evaluation. Our work
has a number of profound implications, e.g., more sign bits can be discarded to
develop more efficient image compression methods, and image encryption methods
based on sign bit encryption can be less secure than we previously understood.
</p></li>
</ul>

<h3>Title: Secure and Efficient Privacy-preserving Authentication Scheme using Cuckoo Filter in Remote Patient Monitoring Network. (arXiv:2211.01270v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01270">http://arxiv.org/abs/2211.01270</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01270] Secure and Efficient Privacy-preserving Authentication Scheme using Cuckoo Filter in Remote Patient Monitoring Network](http://arxiv.org/abs/2211.01270)</code></li>
<li>Summary: <p>With the ubiquitous advancement in smart medical devices and systems, the
potential of Remote Patient Monitoring (RPM) network is evolving in modern
healthcare systems. The medical professionals (doctors, nurses, or medical
experts) can access vitals and sensitive physiological information about the
patients and provide proper treatment to improve the quality of life through
the RPM network. However, the wireless nature of communication in the RPM
network makes it challenging to design an efficient mechanism for secure
communication. Many authentication schemes have been proposed in recent years
to ensure the security of the RPM network. Pseudonym, digital signature, and
Authenticated Key Exchange (AKE) protocols are used for the Internet of Medical
Things (IoMT) to develop secure authorization and privacy-preserving
communication. However, traditional authentication protocols face overhead
challenges due to maintaining a large set of key-pairs or pseudonyms results on
the hospital cloud server. In this research work, we identify this research gap
and propose a novel secure and efficient privacy-preserving authentication
scheme using cuckoo filters for the RPM network. The use of cuckoo filters in
our proposed scheme provides an efficient way for mutual anonymous
authentication and a secret shared key establishment process between medical
professionals and patients. Moreover, we identify the misbehaving sensor nodes
using a correlation-based anomaly detection model to establish secure
communication. The security analysis and formal security validation using SPAN
and AVISPA tools show the robustness of our proposed scheme against message
modification attacks, replay attacks, and man-in-the-middle attacks.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Deep Multimodal Fusion for Generalizable Person Re-identification. (arXiv:2211.00933v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00933">http://arxiv.org/abs/2211.00933</a></li>
<li>Code URL: <a href="https://github.com/jeremyxsc/dmf">https://github.com/jeremyxsc/dmf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00933] Deep Multimodal Fusion for Generalizable Person Re-identification](http://arxiv.org/abs/2211.00933)</code></li>
<li>Summary: <p>Person re-identification plays a significant role in realistic scenarios due
to its various applications in public security and video surveillance.
Recently, leveraging the supervised or semi-unsupervised learning paradigms,
which benefits from the large-scale datasets and strong computing performance,
has achieved a competitive performance on a specific target domain. However,
when Re-ID models are directly deployed in a new domain without target samples,
they always suffer from considerable performance degradation and poor domain
generalization. To address this challenge, in this paper, we propose DMF, a
Deep Multimodal Fusion network for the general scenarios on person
re-identification task, where rich semantic knowledge is introduced to assist
in feature representation learning during the pre-training stage. On top of it,
a multimodal fusion strategy is introduced to translate the data of different
modalities into the same feature space, which can significantly boost
generalization capability of Re-ID model. In the fine-tuning stage, a realistic
dataset is adopted to fine-tine the pre-trained model for distribution
alignment with real-world. Comprehensive experiments on benchmarks demonstrate
that our proposed method can significantly outperform previous domain
generalization or meta-learning methods. Our source code will also be publicly
available at https://github.com/JeremyXSC/DMF.
</p></li>
</ul>

<h3>Title: SoK: Play-to-Earn Projects. (arXiv:2211.01000v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01000">http://arxiv.org/abs/2211.01000</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01000] SoK: Play-to-Earn Projects](http://arxiv.org/abs/2211.01000)</code></li>
<li>Summary: <p>Play-to-earn is one of the prospective categories of decentralized
applications. The play-to-earn projects combine blockchain technology with
entertaining games and finance, attracting various participants. While huge
amounts of capital have been poured into these projects, the new crypto niche
is considered controversial, and the traditional gaming industry is hesitant to
embrace blockchain technology. In addition, there is little systematic research
on these projects. In this paper, we delineate play-to-earn projects in terms
of economic &amp; governance models and implementation and analyze how blockchain
technology can benefit these projects by providing system robustness,
transparency, composability, and decentralized governance. We begin by
identifying the participants and characterizing the tokens, which are products
of composability. We then summarize the roadmap and governance model to exposit
there is a transition from centralized governance to decentralized governance.
We also classify the implementation of the play-to-earn projects with different
extents of robustness and transparency. Finally, we discuss the security &amp;
societal challenges for future research in terms of possible attacks, the
economics of tokens, and governance.
</p></li>
</ul>

<h3>Title: SoK: A Stratified Approach to Blockchain Decentralization. (arXiv:2211.01291v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01291">http://arxiv.org/abs/2211.01291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01291] SoK: A Stratified Approach to Blockchain Decentralization](http://arxiv.org/abs/2211.01291)</code></li>
<li>Summary: <p>Decentralization has been touted as the principal security advantage which
propelled blockchain systems at the forefront of developments in the financial
technology space. Its exact semantics nevertheless remain highly contested and
ambiguous, with proponents and critics disagreeing widely on the level of
decentralization offered. To address this, we put forth a systematization of
the current landscape with respect to decentralization and we derive a
methodology that can help direct future research towards defining and measuring
decentralization. Our approach dissects blockchain systems into multiple
layers, or strata, each possibly encapsulating multiple categories, and enables
a unified method for measuring decentralization in each one. Our layers are (1)
hardware, (2) software, (3) network, (4) consensus, (5) economics
("tokenomics"), (6) API, (7) governance, and (8) geography. Armed with this
stratification, we examine for each layer which pertinent properties of
distributed ledgers (safety, liveness, privacy, stability) can be at risk due
to centralization and in what way. Our work highlights the challenges in
measuring and achieving decentralization, points to the degree of
(de)centralization of various existing systems, where such assessment can be
made from presently available public information, and suggests potential
metrics and directions where future research is needed. We also introduce the
"Minimum Decentralization Test", as a way to assess the decentralization state
of a blockchain system and, as an exemplary case, we showcase how it can be
applied to Bitcoin.
</p></li>
</ul>

<h3>Title: Explainable AI over the Internet of Things: Overview, State-of-the-Art and Future Directions. (arXiv:2211.01036v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01036">http://arxiv.org/abs/2211.01036</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01036] Explainable AI over the Internet of Things: Overview, State-of-the-Art and Future Directions](http://arxiv.org/abs/2211.01036)</code></li>
<li>Summary: <p>Explainable Artificial Intelligence (XAI) is transforming the field of
Artificial Intelligence (AI) by enhancing the trust of end-users in machines.
As the number of connected devices keeps on growing, the Internet of Things
(IoT) market needs to be trustworthy for the end-users. However, existing
literature still lacks a systematic and comprehensive survey work on the use of
XAI for IoT. To bridge this lacking, in this paper, we address the XAI
frameworks with a focus on their characteristics and support for IoT. We
illustrate the widely-used XAI services for IoT applications, such as security
enhancement, Internet of Medical Things (IoMT), Industrial IoT (IIoT), and
Internet of City Things (IoCT). We also suggest the implementation choice of
XAI models over IoT systems in these applications with appropriate examples and
summarize the key inferences for future works. Moreover, we present the
cutting-edge development in edge XAI structures and the support of
sixth-generation (6G) communication services for IoT applications, along with
key inferences. In a nutshell, this paper constitutes the first holistic
compilation on the development of XAI-based frameworks tailored for the demands
of future IoT use cases.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Unsupervised Model Adaptation for Source-free Segmentation of Medical Images. (arXiv:2211.00807v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00807">http://arxiv.org/abs/2211.00807</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00807] Unsupervised Model Adaptation for Source-free Segmentation of Medical Images](http://arxiv.org/abs/2211.00807)</code></li>
<li>Summary: <p>The recent prevalence of deep neural networks has lead semantic segmentation
networks to achieve human-level performance in the medical field when
sufficient training data is provided. Such networks however fail to generalize
when tasked with predicting semantic maps for out-of-distribution images,
requiring model re-training on the new distributions. This expensive process
necessitates expert knowledge in order to generate training labels.
Distribution shifts can arise naturally in the medical field via the choice of
imaging device, i.e. MRI or CT scanners. To combat the need for labeling images
in a target domain after a model is successfully trained in a fully annotated
\textit{source domain} with a different data distribution, unsupervised domain
adaptation (UDA) can be used. Most UDA approaches ensure target generalization
by creating a shared source/target latent feature space. This allows a source
trained classifier to maintain performance on the target domain. However most
UDA approaches require joint source and target data access, which may create
privacy leaks with respect to patient information. We propose an UDA algorithm
for medical image segmentation that does not require access to source data
during adaptation, and is thus capable in maintaining patient data privacy. We
rely on an approximation of the source latent features at adaptation time, and
create a joint source/target embedding space by minimizing a distributional
distance metric based on optimal transport. We demonstrate our approach is
competitive to recent UDA medical segmentation works even with the added
privacy requisite.
</p></li>
</ul>

<h3>Title: My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization. (arXiv:2211.01361v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01361">http://arxiv.org/abs/2211.01361</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01361] My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization](http://arxiv.org/abs/2211.01361)</code></li>
<li>Summary: <p>Recently, productization of face recognition and identification algorithms
have become the most controversial topic about ethical AI. As new policies
around digital identities are formed, we introduce three face access models in
a hypothetical social network, where the user has the power to only appear in
photos they approve. Our approach eclipses current tagging systems and replaces
unapproved faces with quantitatively dissimilar deepfakes. In addition, we
propose new metrics specific for this task, where the deepfake is generated at
random with a guaranteed dissimilarity. We explain access models based on
strictness of the data flow, and discuss impact of each model on privacy,
usability, and performance. We evaluate our system on Facial Descriptor Dataset
as the real dataset, and two synthetic datasets with random and equal class
distributions. Running seven SOTA face recognizers on our results, MFMC reduces
the average accuracy by 61%. Lastly, we extensively analyze similarity metrics,
deepfake generators, and datasets in structural, visual, and generative spaces;
supporting the design choices and verifying the quality.
</p></li>
</ul>

<h3>Title: User-Entity Differential Privacy in Learning Natural Language Models. (arXiv:2211.01141v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01141">http://arxiv.org/abs/2211.01141</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01141] User-Entity Differential Privacy in Learning Natural Language Models](http://arxiv.org/abs/2211.01141)</code></li>
<li>Summary: <p>In this paper, we introduce a novel concept of user-entity differential
privacy (UeDP) to provide formal privacy protection simultaneously to both
sensitive entities in textual data and data owners in learning natural language
models (NLMs). To preserve UeDP, we developed a novel algorithm, called
UeDP-Alg, optimizing the trade-off between privacy loss and model utility with
a tight sensitivity bound derived from seamlessly combining user and sensitive
entity sampling processes. An extensive theoretical analysis and evaluation
show that our UeDP-Alg outperforms baseline approaches in model utility under
the same privacy budget consumption on several NLM tasks, using benchmark
datasets.
</p></li>
</ul>

<h3>Title: On the Interaction Between Differential Privacy and Gradient Compression in Deep Learning. (arXiv:2211.00734v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00734">http://arxiv.org/abs/2211.00734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00734] On the Interaction Between Differential Privacy and Gradient Compression in Deep Learning](http://arxiv.org/abs/2211.00734)</code></li>
<li>Summary: <p>While differential privacy and gradient compression are separately
well-researched topics in machine learning, the study of interaction between
these two topics is still relatively new. We perform a detailed empirical study
on how the Gaussian mechanism for differential privacy and gradient compression
jointly impact test accuracy in deep learning. The existing literature in
gradient compression mostly evaluates compression in the absence of
differential privacy guarantees, and demonstrate that sufficiently high
compression rates reduce accuracy. Similarly, existing literature in
differential privacy evaluates privacy mechanisms in the absence of
compression, and demonstrates that sufficiently strong privacy guarantees
reduce accuracy. In this work, we observe while gradient compression generally
has a negative impact on test accuracy in non-private training, it can
sometimes improve test accuracy in differentially private training.
Specifically, we observe that when employing aggressive sparsification or rank
reduction to the gradients, test accuracy is less affected by the Gaussian
noise added for differential privacy. These observations are explained through
an analysis how differential privacy and compression effects the bias and
variance in estimating the average gradient. We follow this study with a
recommendation on how to improve test accuracy under the context of
differentially private deep learning and gradient compression. We evaluate this
proposal and find that it can reduce the negative impact of noise added by
differential privacy mechanisms on test accuracy by up to 24.6%, and reduce the
negative impact of gradient sparsification on test accuracy by up to 15.1%.
</p></li>
</ul>

<h3>Title: Local Differentially Private Frequency Estimation based on Learned Sketches. (arXiv:2211.01138v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01138">http://arxiv.org/abs/2211.01138</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01138] Local Differentially Private Frequency Estimation based on Learned Sketches](http://arxiv.org/abs/2211.01138)</code></li>
<li>Summary: <p>Sketches are widely used for frequency estimation of data with a large
domain. However, sketches-based frequency estimation faces more challenges when
considering privacy. Local differential privacy (LDP) is a solution to
frequency estimation on sensitive data while preserving the privacy. LDP
enables each user to perturb its data on the client-side to protect the
privacy, but it also introduces errors to the frequency estimations. The hash
collisions in the sketches make the estimations for low-frequent items even
worse. In this paper, we propose a two-phase frequency estimation framework for
data with a large domain based on an LDP learned sketch, which separates the
high-frequent and low-frequent items to avoid the errors caused by hash
collisions. We theoretically proved that the proposed method satisfies LDP and
it is more accurate than the state-of-the-art frequency estimation methods
including Apple-CMS, Apple-HCMS and FLH. The experimental results verify the
performance of our method.
</p></li>
</ul>

<h3>Title: Proof of User Similarity: the Spatial Measurer of Blockchain. (arXiv:2211.01143v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01143">http://arxiv.org/abs/2211.01143</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01143] Proof of User Similarity: the Spatial Measurer of Blockchain](http://arxiv.org/abs/2211.01143)</code></li>
<li>Summary: <p>Although proof of work (PoW) consensus dominates the current blockchain-based
systems mostly, it has always been criticized for the uneconomic brute-force
calculation. As alternatives, energy-conservation and energy-recycling
mechanisms heaved in sight. In this paper, we propose proof of user similarity
(PoUS), a distinct energy-recycling consensus mechanism, harnessing the
valuable computing power to calculate the similarities of users, and enact the
calculation results into the packing rule. However, the expensive calculation
required in PoUS challenges miners in participating, and may induce plagiarism
and lying risks. To resolve these issues, PoUS embraces the best-effort schema
by allowing miners to compute partially. Besides, a voting mechanism based on
the two-parties computation and Bayesian truth serum is proposed to guarantee
privacy-preserved voting and truthful reports. Noticeably, PoUS distinguishes
itself in recycling the computing power back to blockchain since it turns the
resource wastage to facilitate refined cohort analysis of users, serving as the
spatial measurer and enabling a searchable blockchain. We build a prototype of
PoUS and compare its performance with PoW. The results show that PoUS
outperforms PoW in achieving an average TPS improvement of 24.01% and an
average confirmation latency reduction of 43.64%. Besides, PoUS functions well
in mirroring the spatial information of users, with negligible computation time
and communication cost.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: On the detection of synthetic images generated by diffusion models. (arXiv:2211.00680v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00680">http://arxiv.org/abs/2211.00680</a></li>
<li>Code URL: <a href="https://github.com/grip-unina/dmimagedetection">https://github.com/grip-unina/dmimagedetection</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00680] On the detection of synthetic images generated by diffusion models](http://arxiv.org/abs/2211.00680)</code></li>
<li>Summary: <p>Over the past decade, there has been tremendous progress in creating
synthetic media, mainly thanks to the development of powerful methods based on
generative adversarial networks (GAN). Very recently, methods based on
diffusion models (DM) have been gaining the spotlight. In addition to providing
an impressive level of photorealism, they enable the creation of text-based
visual content, opening up new and exciting opportunities in many different
application fields, from arts to video games. On the other hand, this property
is an additional asset in the hands of malicious users, who can generate and
distribute fake media perfectly adapted to their attacks, posing new challenges
to the media forensic community. With this work, we seek to understand how
difficult it is to distinguish synthetic images generated by diffusion models
from pristine ones and whether current state-of-the-art detectors are suitable
for the task. To this end, first we expose the forensics traces left by
diffusion models, then study how current detectors, developed for GAN-generated
images, perform on these new synthetic images, especially in challenging
social-networks scenarios involving image compression and resizing. Datasets
and code are available at github.com/grip-unina/DMimageDetection.
</p></li>
</ul>

<h3>Title: Generative Poisoning Using Random Discriminators. (arXiv:2211.01086v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01086">http://arxiv.org/abs/2211.01086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01086] Generative Poisoning Using Random Discriminators](http://arxiv.org/abs/2211.01086)</code></li>
<li>Summary: <p>We introduce ShortcutGen, a new data poisoning attack that generates
sample-dependent, error-minimizing perturbations by learning a generator. The
key novelty of ShortcutGen is the use of a randomly-initialized discriminator,
which provides spurious shortcuts needed for generating poisons. Different from
recent, iterative methods, our ShortcutGen can generate perturbations with only
one forward pass in a label-free manner, and compared to the only existing
generative method, DeepConfuse, our ShortcutGen is faster and simpler to train
while remaining competitive. We also demonstrate that integrating a simple
augmentation strategy can further boost the robustness of ShortcutGen against
early stopping, and combining augmentation and non-augmentation leads to new
state-of-the-art results in terms of final validation accuracy, especially in
the challenging, transfer scenario. Lastly, we speculate, through uncovering
its working mechanism, that learning a more general representation space could
allow ShortcutGen to work for unseen data.
</p></li>
</ul>

<h3>Title: Improving transferability of 3D adversarial attacks with scale and shear transformations. (arXiv:2211.01093v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01093">http://arxiv.org/abs/2211.01093</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01093] Improving transferability of 3D adversarial attacks with scale and shear transformations](http://arxiv.org/abs/2211.01093)</code></li>
<li>Summary: <p>Previous work has shown that 3D point cloud classifiers can be vulnerable to
adversarial examples. However, most of the existing methods are aimed at
white-box attacks, where the parameters and other information of the
classifiers are known in the attack, which is unrealistic for real-world
applications. In order to improve the attack performance of the black-box
classifiers, the research community generally uses the transfer-based black-box
attack. However, the transferability of current 3D attacks is still relatively
low. To this end, this paper proposes Scale and Shear (SS) Attack to generate
3D adversarial examples with strong transferability. Specifically, we randomly
scale or shear the input point cloud, so that the attack will not overfit the
white-box model, thereby improving the transferability of the attack. Extensive
experiments show that the SS attack proposed in this paper can be seamlessly
combined with the existing state-of-the-art (SOTA) 3D point cloud attack
methods to form more powerful attack methods, and the SS attack improves the
transferability over 3.6 times compare to the baseline. Moreover, while
substantially outperforming the baseline methods, the SS attack achieves SOTA
transferability under various defenses. Our code will be available online at
https://github.com/cuge1995/SS-attack
</p></li>
</ul>

<h3>Title: The Impostor Among US(B): Off-Path Injection Attacks on USB Communications. (arXiv:2211.01109v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01109">http://arxiv.org/abs/2211.01109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01109] The Impostor Among US(B): Off-Path Injection Attacks on USB Communications](http://arxiv.org/abs/2211.01109)</code></li>
<li>Summary: <p>USB is the most prevalent peripheral interface in modern computer systems and
its inherent insecurities make it an appealing attack vector. A well-known
limitation of USB is that traffic is not encrypted. This allows on-path
adversaries to trivially perform man-in-the-middle attacks. Off-path attacks
that compromise the confidentiality of communications have also been shown to
be possible. However, so far no off-path attacks that breach USB communications
integrity have been demonstrated.
</p></li>
</ul>

<p>In this work we show that the integrity of USB communications is not
guaranteed even against off-path attackers.Specifically, we design and build
malicious devices that, even when placed outside of the path between a victim
device and the host, can inject data to that path. Using our developed
injectors we can falsify the provenance of data input as interpreted by a host
computer system. By injecting on behalf of trusted victim devices we can
circumvent any software-based authorisation policy defences that computer
systems employ against common USB attacks. We demonstrate two concrete attacks.
The first injects keystrokes allowing an attacker to execute commands. The
second demonstrates file-contents replacement including during system install
from a USB disk. We test the attacks on 29 USB 2.0 and USB 3.x hubs and find 14
of them to be vulnerable.
</p>

<h3>Title: a-RNA: Adversarial Radio Noise Attack to Fool Radar-based Environment Perception Systems. (arXiv:2211.01112v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01112">http://arxiv.org/abs/2211.01112</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01112] a-RNA: Adversarial Radio Noise Attack to Fool Radar-based Environment Perception Systems](http://arxiv.org/abs/2211.01112)</code></li>
<li>Summary: <p>Due to their robustness to degraded capturing conditions, radars are widely
used for environment perception, which is a critical task in applications like
autonomous vehicles. More specifically, Ultra-Wide Band (UWB) radars are
particularly efficient for short range settings as they carry rich information
on the environment. Recent UWB-based systems rely on Machine Learning (ML) to
exploit the rich signature of these sensors. However, ML classifiers are
susceptible to adversarial examples, which are created from raw data to fool
the classifier such that it assigns the input to the wrong class. These attacks
represent a serious threat to systems integrity, especially for safety-critical
applications. In this work, we present a new adversarial attack on UWB radars
in which an adversary injects adversarial radio noise in the wireless channel
to cause an obstacle recognition failure. First, based on signals collected in
real-life environment, we show that conventional attacks fail to generate
robust noise under realistic conditions. We propose a-RNA, i.e., Adversarial
Radio Noise Attack to overcome these issues. Specifically, a-RNA generates an
adversarial noise that is efficient without synchronization between the input
signal and the noise. Moreover, a-RNA generated noise is, by-design, robust
against pre-processing countermeasures such as filtering-based defenses.
Moreover, in addition to the undetectability objective by limiting the noise
magnitude budget, a-RNA is also efficient in the presence of sophisticated
defenses in the spectral domain by introducing a frequency budget. We believe
this work should alert about potentially critical implementations of
adversarial attacks on radar systems that should be taken seriously.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Rethinking the Metric in Few-shot Learning: From an Adaptive Multi-Distance Perspective. (arXiv:2211.00890v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00890">http://arxiv.org/abs/2211.00890</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00890] Rethinking the Metric in Few-shot Learning: From an Adaptive Multi-Distance Perspective](http://arxiv.org/abs/2211.00890)</code></li>
<li>Summary: <p>Few-shot learning problem focuses on recognizing unseen classes given a few
labeled images. In recent effort, more attention is paid to fine-grained
feature embedding, ignoring the relationship among different distance metrics.
In this paper, for the first time, we investigate the contributions of
different distance metrics, and propose an adaptive fusion scheme, bringing
significant improvements in few-shot classification. We start from a naive
baseline of confidence summation and demonstrate the necessity of exploiting
the complementary property of different distance metrics. By finding the
competition problem among them, built upon the baseline, we propose an Adaptive
Metrics Module (AMM) to decouple metrics fusion into metric-prediction fusion
and metric-losses fusion. The former encourages mutual complementary, while the
latter alleviates metric competition via multi-task collaborative learning.
Based on AMM, we design a few-shot classification framework AMTNet, including
the AMM and the Global Adaptive Loss (GAL), to jointly optimize the few-shot
task and auxiliary self-supervised task, making the embedding features more
robust. In the experiment, the proposed AMM achieves 2% higher performance than
the naive metrics fusion module, and our AMTNet outperforms the
state-of-the-arts on multiple benchmark datasets.
</p></li>
</ul>

<h3>Title: Semantic SuperPoint: A Deep Semantic Descriptor. (arXiv:2211.01098v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01098">http://arxiv.org/abs/2211.01098</a></li>
<li>Code URL: <a href="https://github.com/gabriel-sgama/semantic-superpoint">https://github.com/gabriel-sgama/semantic-superpoint</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01098] Semantic SuperPoint: A Deep Semantic Descriptor](http://arxiv.org/abs/2211.01098)</code></li>
<li>Summary: <p>Several SLAM methods benefit from the use of semantic information. Most
integrate photometric methods with high-level semantics such as object
detection and semantic segmentation. We propose that adding a semantic
segmentation decoder in a shared encoder architecture would help the descriptor
decoder learn semantic information, improving the feature extractor. This would
be a more robust approach than only using high-level semantic information since
it would be intrinsically learned in the descriptor and would not depend on the
final quality of the semantic prediction. To add this information, we take
advantage of multi-task learning methods to improve accuracy and balance the
performance of each task. The proposed models are evaluated according to
detection and matching metrics on the HPatches dataset. The results show that
the Semantic SuperPoint model performs better than the baseline one.
</p></li>
</ul>

<h3>Title: OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object Detection. (arXiv:2211.01142v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01142">http://arxiv.org/abs/2211.01142</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01142] OPA-3D: Occlusion-Aware Pixel-Wise Aggregation for Monocular 3D Object Detection](http://arxiv.org/abs/2211.01142)</code></li>
<li>Summary: <p>Despite monocular 3D object detection having recently made a significant leap
forward thanks to the use of pre-trained depth estimators for pseudo-LiDAR
recovery, such two-stage methods typically suffer from overfitting and are
incapable of explicitly encapsulating the geometric relation between depth and
object bounding box. To overcome this limitation, we instead propose OPA-3D, a
single-stage, end-to-end, Occlusion-Aware Pixel-Wise Aggregation network that
to jointly estimate dense scene depth with depth-bounding box residuals and
object bounding boxes, allowing a two-stream detection of 3D objects, leading
to significantly more robust detections. Thereby, the geometry stream denoted
as the Geometry Stream, combines visible depth and depth-bounding box residuals
to recover the object bounding box via explicit occlusion-aware optimization.
In addition, a bounding box based geometry projection scheme is employed in an
effort to enhance distance perception. The second stream, named as the Context
Stream, directly regresses 3D object location and size. This novel two-stream
representation further enables us to enforce cross-stream consistency terms
which aligns the outputs of both streams, improving the overall performance.
Extensive experiments on the public benchmark demonstrate that OPA-3D
outperforms state-of-the-art methods on the main Car category, whilst keeping a
real-time inference speed. We plan to release all codes and trained models
soon.
</p></li>
</ul>

<h3>Title: Web-based Elicitation of Human Perception on mixup Data. (arXiv:2211.01202v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01202">http://arxiv.org/abs/2211.01202</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01202] Web-based Elicitation of Human Perception on mixup Data](http://arxiv.org/abs/2211.01202)</code></li>
<li>Summary: <p>Synthetic data is proliferating on the web and powering many advances in
machine learning. However, it is not always clear if synthetic labels are
perceptually sensible to humans. The web provides us with a platform to take a
step towards addressing this question through online elicitation. We design a
series of elicitation interfaces, which we release as \texttt{HILL MixE Suite},
and recruit 159 participants, to provide perceptual judgments over the kinds of
synthetic data constructed during \textit{mixup} training: a powerful
regularizer shown to improve model robustness, generalization, and calibration.
We find that human perception does not consistently align with the labels
traditionally used for synthetic points and begin to demonstrate the
applicability of these findings to potentially increase the reliability of
downstream models. We release all elicited judgments in a new data hub we call
\texttt{H-Mix}.
</p></li>
</ul>

<h3>Title: CircleSnake: Instance Segmentation with Circle Representation. (arXiv:2211.01254v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01254">http://arxiv.org/abs/2211.01254</a></li>
<li>Code URL: <a href="https://github.com/hrlblab/circlesnake">https://github.com/hrlblab/circlesnake</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01254] CircleSnake: Instance Segmentation with Circle Representation](http://arxiv.org/abs/2211.01254)</code></li>
<li>Summary: <p>Circle representation has recently been introduced as a medical imaging
optimized representation for more effective instance object detection on
ball-shaped medical objects. With its superior performance on instance
detection, it is appealing to extend the circle representation to instance
medical object segmentation. In this work, we propose CircleSnake, a simple
end-to-end circle contour deformation-based segmentation method for ball-shaped
medical objects. Compared to the prevalent DeepSnake method, our contribution
is three-fold: (1) We replace the complicated bounding box to octagon contour
transformation with a computation-free and consistent bounding circle to circle
contour adaption for segmenting ball-shaped medical objects; (2) Circle
representation has fewer degrees of freedom (DoF=2) as compared with the
octagon representation (DoF=8), thus yielding a more robust segmentation
performance and better rotation consistency; (3) To the best of our knowledge,
the proposed CircleSnake method is the first end-to-end circle representation
deep segmentation pipeline method with consistent circle detection, circle
contour proposal, and circular convolution. The key innovation is to integrate
the circular graph convolution with circle detection into an end-to-end
instance segmentation framework, enabled by the proposed simple and consistent
circle contour representation. Glomeruli are used to evaluate the performance
of the benchmarks. From the results, CircleSnake increases the average
precision of glomerular detection from 0.559 to 0.614. The Dice score increased
from 0.804 to 0.849. The code has been released:
https://github.com/hrlblab/CircleSnake
</p></li>
</ul>

<h3>Title: Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations. (arXiv:2211.00881v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00881">http://arxiv.org/abs/2211.00881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00881] Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations](http://arxiv.org/abs/2211.00881)</code></li>
<li>Summary: <p>Syntactically controlled paraphrase generation has become an emerging
research direction in recent years. Most existing approaches require annotated
paraphrase pairs for training and are thus costly to extend to new domains.
Unsupervised approaches, on the other hand, do not need paraphrase pairs but
suffer from relatively poor performance in terms of syntactic control and
quality of generated paraphrases. In this paper, we demonstrate that leveraging
Abstract Meaning Representations (AMR) can greatly improve the performance of
unsupervised syntactically controlled paraphrase generation. Our proposed
model, AMR-enhanced Paraphrase Generator (AMRPG), separately encodes the AMR
graph and the constituency parse of the input sentence into two disentangled
semantic and syntactic embeddings. A decoder is then learned to reconstruct the
input sentence from the semantic and syntactic embeddings. Our experiments show
that AMRPG generates more accurate syntactically controlled paraphrases, both
quantitatively and qualitatively, compared to the existing unsupervised
approaches. We also demonstrate that the paraphrases generated by AMRPG can be
used for data augmentation to improve the robustness of NLP models.
</p></li>
</ul>

<h3>Title: Dialect-robust Evaluation of Generated Text. (arXiv:2211.00922v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00922">http://arxiv.org/abs/2211.00922</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00922] Dialect-robust Evaluation of Generated Text](http://arxiv.org/abs/2211.00922)</code></li>
<li>Summary: <p>Evaluation metrics that are not robust to dialect variation make it
impossible to tell how well systems perform for many groups of users, and can
even penalize systems for producing text in lower-resource dialects. However,
currently, there exists no way to quantify how metrics respond to change in the
dialect of a generated utterance. We thus formalize dialect robustness and
dialect awareness as goals for NLG evaluation metrics. We introduce a suite of
methods and corresponding statistical tests one can use to assess metrics in
light of the two goals. Applying the suite to current state-of-the-art metrics,
we demonstrate that they are not dialect-robust and that semantic perturbations
frequently lead to smaller decreases in a metric than the introduction of
dialect features. As a first step to overcome this limitation, we propose a
training schema, NANO, which introduces regional and language information to
the pretraining process of a metric. We demonstrate that NANO provides a
size-efficient way for models to improve the dialect robustness while
simultaneously improving their performance on the standard metric benchmark.
</p></li>
</ul>

<h3>Title: Learning an Artificial Language for Knowledge-Sharing in Multilingual Translation. (arXiv:2211.01292v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01292">http://arxiv.org/abs/2211.01292</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01292] Learning an Artificial Language for Knowledge-Sharing in Multilingual Translation](http://arxiv.org/abs/2211.01292)</code></li>
<li>Summary: <p>The cornerstone of multilingual neural translation is shared representations
across languages. Given the theoretically infinite representation power of
neural networks, semantically identical sentences are likely represented
differently. While representing sentences in the continuous latent space
ensures expressiveness, it introduces the risk of capturing of irrelevant
features which hinders the learning of a common representation. In this work,
we discretize the encoder output latent space of multilingual models by
assigning encoder states to entries in a codebook, which in effect represents
source sentences in a new artificial language. This discretization process not
only offers a new way to interpret the otherwise black-box model
representations, but, more importantly, gives potential for increasing
robustness in unseen testing conditions. We validate our approach on
large-scale experiments with realistic data volumes and domains. When tested in
zero-shot conditions, our approach is competitive with two strong alternatives
from the literature. We also use the learned artificial language to analyze
model behavior, and discover that using a similar bridge language increases
knowledge-sharing among the remaining languages.
</p></li>
</ul>

<h3>Title: An Easy-to-use and Robust Approach for the Differentially Private De-Identification of Clinical Textual Documents. (arXiv:2211.01147v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01147">http://arxiv.org/abs/2211.01147</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01147] An Easy-to-use and Robust Approach for the Differentially Private De-Identification of Clinical Textual Documents](http://arxiv.org/abs/2211.01147)</code></li>
<li>Summary: <p>Unstructured textual data is at the heart of healthcare systems. For obvious
privacy reasons, these documents are not accessible to researchers as long as
they contain personally identifiable information. One way to share this data
while respecting the legislative framework (notably GDPR or HIPAA) is, within
the medical structures, to de-identify it, i.e. to detect the personal
information of a person through a Named Entity Recognition (NER) system and
then replacing it to make it very difficult to associate the document with the
person. The challenge is having reliable NER and substitution tools without
compromising confidentiality and consistency in the document. Most of the
conducted research focuses on English medical documents with coarse
substitutions by not benefiting from advances in privacy. This paper shows how
an efficient and differentially private de-identification approach can be
achieved by strengthening the less robust de-identification method and by
adapting state-of-the-art differentially private mechanisms for substitution
purposes. The result is an approach for de-identifying clinical documents in
French language, but also generalizable to other languages and whose robustness
is mathematically proven.
</p></li>
</ul>

<h3>Title: Defending with Errors: Approximate Computing for Robustness of Deep Neural Networks. (arXiv:2211.01182v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01182">http://arxiv.org/abs/2211.01182</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01182] Defending with Errors: Approximate Computing for Robustness of Deep Neural Networks](http://arxiv.org/abs/2211.01182)</code></li>
<li>Summary: <p>Machine-learning architectures, such as Convolutional Neural Networks (CNNs)
are vulnerable to adversarial attacks: inputs crafted carefully to force the
system output to a wrong label. Since machine-learning is being deployed in
safety-critical and security-sensitive domains, such attacks may have
catastrophic security and safety consequences. In this paper, we propose for
the first time to use hardware-supported approximate computing to improve the
robustness of machine-learning classifiers. We show that successful adversarial
attacks against the exact classifier have poor transferability to the
approximate implementation. Surprisingly, the robustness advantages also apply
to white-box attacks where the attacker has unrestricted access to the
approximate classifier implementation: in this case, we show that substantially
higher levels of adversarial noise are needed to produce adversarial examples.
Furthermore, our approximate computing model maintains the same level in terms
of classification accuracy, does not require retraining, and reduces resource
utilization and energy consumption of the CNN. We conducted extensive
experiments on a set of strong adversarial attacks; We empirically show that
the proposed implementation increases the robustness of a LeNet-5, Alexnet and
VGG-11 CNNs considerably with up to 50% by-product saving in energy consumption
due to the simpler nature of the approximate logic.
</p></li>
</ul>

<h3>Title: Isometric Representations in Neural Networks Improve Robustness. (arXiv:2211.01236v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01236">http://arxiv.org/abs/2211.01236</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01236] Isometric Representations in Neural Networks Improve Robustness](http://arxiv.org/abs/2211.01236)</code></li>
<li>Summary: <p>Artificial and biological agents cannon learn given completely random and
unstructured data. The structure of data is encoded in the metric relationships
between data points. In the context of neural networks, neuronal activity
within a layer forms a representation reflecting the transformation that the
layer implements on its inputs. In order to utilize the structure in the data
in a truthful manner, such representations should reflect the input distances
and thus be continuous and isometric. Supporting this statement, recent
findings in neuroscience propose that generalization and robustness are tied to
neural representations being continuously differentiable. In machine learning,
most algorithms lack robustness and are generally thought to rely on aspects of
the data that differ from those that humans use, as is commonly seen in
adversarial attacks. During cross-entropy classification, the metric and
structural properties of network representations are usually broken both
between and within classes. This side effect from training can lead to
instabilities under perturbations near locations where such structure is not
preserved. One of the standard solutions to obtain robustness is to add ad hoc
regularization terms, but to our knowledge, forcing representations to preserve
the metric structure of the input data as a stabilising mechanism has not yet
been studied. In this work, we train neural networks to perform classification
while simultaneously maintaining within-class metric structure, leading to
isometric within-class representations. Such network representations turn out
to be beneficial for accurate and robust inference. By stacking layers with
this property we create a network architecture that facilitates hierarchical
manipulation of internal neural representations. Finally, we verify that
isometric regularization improves the robustness to adversarial attacks on
MNIST.
</p></li>
</ul>

<h3>Title: A survey on the development status and application prospects of knowledge graph in smart grids. (arXiv:2211.00901v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00901">http://arxiv.org/abs/2211.00901</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00901] A survey on the development status and application prospects of knowledge graph in smart grids](http://arxiv.org/abs/2211.00901)</code></li>
<li>Summary: <p>With the advent of the electric power big data era, semantic interoperability
and interconnection of power data have received extensive attention. Knowledge
graph technology is a new method describing the complex relationships between
concepts and entities in the objective world, which is widely concerned because
of its robust knowledge inference ability. Especially with the proliferation of
measurement devices and exponential growth of electric power data empowers,
electric power knowledge graph provides new opportunities to solve the
contradictions between the massive power resources and the continuously
increasing demands for intelligent applications. In an attempt to fulfil the
potential of knowledge graph and deal with the various challenges faced, as
well as to obtain insights to achieve business applications of smart grids,
this work first presents a holistic study of knowledge-driven intelligent
application integration. Specifically, a detailed overview of electric power
knowledge mining is provided. Then, the overview of the knowledge graph in
smart grids is introduced. Moreover, the architecture of the big knowledge
graph platform for smart grids and critical technologies are described.
Furthermore, this paper comprehensively elaborates on the application prospects
leveraged by knowledge graph oriented to smart grids, power consumer service,
decision-making in dispatching, and operation and maintenance of power
equipment. Finally, issues and challenges are summarised.
</p></li>
</ul>

<h3>Title: MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations. (arXiv:2211.00713v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00713">http://arxiv.org/abs/2211.00713</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00713] MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations](http://arxiv.org/abs/2211.00713)</code></li>
<li>Summary: <p>Mesh-based approaches are fundamental to solving physics-based simulations,
however, they require significant computational efforts, especially for highly
non-linear problems. Deep learning techniques accelerate physics-based
simulations, however, they fail to perform efficiently as the size and
complexity of the problem increases. Hence in this work, we propose MAgNET:
Multi-channel Aggregation Network, a novel geometric deep learning framework
for performing supervised learning on mesh-based graph data. MAgNET is based on
the proposed MAg (Multichannel Aggregation) operation which generalises the
concept of multi-channel local operations in convolutional neural networks to
arbitrary non-grid inputs. MAg can efficiently perform non-linear regression
mapping for graph-structured data. MAg layers are interleaved with the proposed
novel graph pooling operations to constitute a graph U-Net architecture that is
robust, handles arbitrary complex meshes and scales efficiently with the size
of the problem. Although not limited to the type of discretisation, we showcase
the predictive capabilities of MAgNET for several non-linear finite element
simulations.
</p></li>
</ul>

<h3>Title: Maximum Likelihood Distillation for Robust Modulation Classification. (arXiv:2211.00748v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00748">http://arxiv.org/abs/2211.00748</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00748] Maximum Likelihood Distillation for Robust Modulation Classification](http://arxiv.org/abs/2211.00748)</code></li>
<li>Summary: <p>Deep Neural Networks are being extensively used in communication systems and
Automatic Modulation Classification (AMC) in particular. However, they are very
susceptible to small adversarial perturbations that are carefully crafted to
change the network decision. In this work, we build on knowledge distillation
ideas and adversarial training in order to build more robust AMC systems. We
first outline the importance of the quality of the training data in terms of
accuracy and robustness of the model. We then propose to use the Maximum
Likelihood function, which could solve the AMC problem in offline settings, to
generate better training labels. Those labels teach the model to be uncertain
in challenging conditions, which permits to increase the accuracy, as well as
the robustness of the model when combined with adversarial training.
Interestingly, we observe that this increase in performance transfers to online
settings, where the Maximum Likelihood function cannot be used in practice.
Overall, this work highlights the potential of learning to be uncertain in
difficult scenarios, compared to directly removing label noise.
</p></li>
</ul>

<h3>Title: Model-based Reinforcement Learning with a Hamiltonian Canonical ODE Network. (arXiv:2211.00942v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00942">http://arxiv.org/abs/2211.00942</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00942] Model-based Reinforcement Learning with a Hamiltonian Canonical ODE Network](http://arxiv.org/abs/2211.00942)</code></li>
<li>Summary: <p>Model-based reinforcement learning usually suffers from a high sample
complexity in training the world model, especially for the environments with
complex dynamics. To make the training for general physical environments more
efficient, we introduce Hamiltonian canonical ordinary differential equations
into the learning process, which inspires a novel model of neural ordinary
differential auto-encoder (NODA). NODA can model the physical world by nature
and is flexible to impose Hamiltonian mechanics (e.g., the dimension of the
physical equations) which can further accelerate training of the environment
models. It can consequentially empower an RL agent with the robust
extrapolation using a small amount of samples as well as the guarantee on the
physical plausibility. Theoretically, we prove that NODA has uniform bounds for
multi-step transition errors and value errors under certain conditions.
Extensive experiments show that NODA can learn the environment dynamics
effectively with a high sample efficiency, making it possible to facilitate
reinforcement learning agents at the early stage.
</p></li>
</ul>

<h3>Title: Spatial-temporal recurrent reinforcement learning for autonomous ships. (arXiv:2211.01004v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01004">http://arxiv.org/abs/2211.01004</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01004] Spatial-temporal recurrent reinforcement learning for autonomous ships](http://arxiv.org/abs/2211.01004)</code></li>
<li>Summary: <p>The paper proposes a spatial-temporal recurrent neural network architecture
for Deep $Q$-Networks to steer an autonomous ship. The network design allows
handling an arbitrary number of surrounding target ships while offering
robustness to partial observability. Further, a state-of-the-art collision risk
metric is proposed to enable an easier assessment of different situations by
the agent. The COLREG rules of maritime traffic are explicitly considered in
the design of the reward function. The final policy is validated on a custom
set of newly created single-ship encounters called "Around the Clock" problems
and the commonly chosen Imazu (1987) problems, which include 18 multi-ship
scenarios. Additionally, the framework shows robustness when deployed
simultaneously in multi-agent scenarios. The proposed network architecture is
compatible with other deep reinforcement learning algorithms, including
actor-critic frameworks.
</p></li>
</ul>

<h3>Title: Continual Conscious Active Fine-Tuning to Robustify Online Machine Learning Models Against Data Distribution Shifts. (arXiv:2211.01315v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01315">http://arxiv.org/abs/2211.01315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01315] Continual Conscious Active Fine-Tuning to Robustify Online Machine Learning Models Against Data Distribution Shifts](http://arxiv.org/abs/2211.01315)</code></li>
<li>Summary: <p>Unlike their offline traditional counterpart, online machine learning models
are capable of handling data distribution shifts while serving at the test
time. However, they have limitations in addressing this phenomenon. They are
either expensive or unreliable. We propose augmenting an online learning
approach called test-time adaptation with a continual conscious active
fine-tuning layer to develop an enhanced variation that can handle drastic data
distribution shifts reliably and cost-effectively. The proposed augmentation
incorporates the following aspects: a continual aspect to confront the
ever-ending data distribution shifts, a conscious aspect to imply that
fine-tuning is a distribution-shift-aware process that occurs at the
appropriate time to address the recently detected data distribution shifts, and
an active aspect to indicate employing human-machine collaboration for the
relabeling to be cost-effective and practical for diverse applications. Our
empirical results show that the enhanced test-time adaptation variation
outperforms the traditional variation by a factor of two.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: SufrinNet: Toward Sufficient Cross-View Interaction for Stereo Image Enhancement in The Dark. (arXiv:2211.00859v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00859">http://arxiv.org/abs/2211.00859</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00859] SufrinNet: Toward Sufficient Cross-View Interaction for Stereo Image Enhancement in The Dark](http://arxiv.org/abs/2211.00859)</code></li>
<li>Summary: <p>Low-light stereo image enhancement (LLSIE) is a relatively new task to
enhance the quality of visually unpleasant stereo images captured in dark
conditions. So far, very few studies on deep LLSIE have been explored due to
certain challenging issues, i.e., the task has not been well addressed, and
current methods clearly suffer from two shortages: 1) insufficient cross-view
interaction; 2) lacking long-range dependency for intra-view learning. In this
paper, we therefore propose a novel LLSIE model, termed \underline{Suf}ficient
C\underline{r}oss-View \underline{In}teraction Network (SufrinNet). To be
specific, we present sufficient inter-view interaction module (SIIM) to enhance
the information exchange across views. SIIM not only discovers the cross-view
correlations at different scales, but also explores the cross-scale information
interaction. Besides, we present a spatial-channel information mining block
(SIMB) for intra-view feature extraction, and the benefits are twofold. One is
the long-range dependency capture to build spatial long-range relationship, and
the other is expanded channel information refinement that enhances information
flow in channel dimension. Extensive experiments on Flickr1024, KITTI 2012,
KITTI 2015 and Middlebury datasets show that our method obtains better
illumination adjustment and detail recovery, and achieves SOTA performance
compared to other related methods. Our codes, datasets and models will be
publicly available.
</p></li>
</ul>

<h3>Title: TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding Tag/Word Relations and More Fine-Grained Tags. (arXiv:2211.00684v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00684">http://arxiv.org/abs/2211.00684</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00684] TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding Tag/Word Relations and More Fine-Grained Tags](http://arxiv.org/abs/2211.00684)</code></li>
<li>Summary: <p>So far, discontinuous named entity recognition (NER) has received increasing
research attention and many related methods have surged such as
hypergraph-based methods, span-based methods, and sequence-to-sequence
(Seq2Seq) methods, etc. However, these methods more or less suffer from some
problems such as decoding ambiguity and efficiency, which limit their
performance. Recently, grid-tagging methods, which benefit from the flexible
design of tagging systems and model architectures, have shown superiority to
adapt for various information extraction tasks. In this paper, we follow the
line of such methods and propose a competitive grid-tagging model for
discontinuous NER. We call our model TOE because we incorporate two kinds of
Tag-Oriented Enhancement mechanisms into a state-of-the-art (SOTA) grid-tagging
model that casts the NER problem into word-word relationship prediction. First,
we design a Tag Representation Embedding Module (TREM) to force our model to
consider not only word-word relationships but also word-tag and tag-tag
relationships. Concretely, we construct tag representations and embed them into
TREM, so that TREM can treat tag and word representations as
queries/keys/values and utilize self-attention to model their relationships. On
the other hand, motivated by the Next-Neighboring-Word (NNW) and Tail-Head-Word
(THW) tags in the SOTA model, we add two new symmetric tags, namely
Previous-Neighboring-Word (PNW) and Head-Tail-Word (HTW), to model more
fine-grained word-word relationships and alleviate error propagation from tag
prediction. In the experiments of three benchmark datasets, namely CADEC,
ShARe13 and ShARe14, our TOE model pushes the SOTA results by about 0.83%,
0.05% and 0.66% in F1, demonstrating its effectiveness.
</p></li>
</ul>

<h3>Title: Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset. (arXiv:2211.00869v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00869">http://arxiv.org/abs/2211.00869</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00869] Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset](http://arxiv.org/abs/2211.00869)</code></li>
<li>Summary: <p>Event extraction (EE) is crucial to downstream tasks such as new aggregation
and event knowledge graph construction. Most existing EE datasets manually
define fixed event types and design specific schema for each of them, failing
to cover diverse events emerging from the online text. Moreover, news titles,
an important source of event mentions, have not gained enough attention in
current EE research. In this paper, We present Title2Event, a large-scale
sentence-level dataset benchmarking Open Event Extraction without restricting
event types. Title2Event contains more than 42,000 news titles in 34 topics
collected from Chinese web pages. To the best of our knowledge, it is currently
the largest manually-annotated Chinese dataset for open event extraction. We
further conduct experiments on Title2Event with different models and show that
the characteristics of titles make it challenging for event extraction,
addressing the significance of advanced study on this problem. The dataset and
baseline codes are available at https://open-event-hub.github.io/title2event.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments. (arXiv:2211.00735v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00735">http://arxiv.org/abs/2211.00735</a></li>
<li>Code URL: <a href="https://github.com/vivekkhimani/torchfl">https://github.com/vivekkhimani/torchfl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00735] TorchFL: A Performant Library for Bootstrapping Federated Learning Experiments](http://arxiv.org/abs/2211.00735)</code></li>
<li>Summary: <p>With the increased legislation around data privacy, federated learning (FL)
has emerged as a promising technique that allows the clients (end-user) to
collaboratively train deep learning (DL) models without transferring and
storing the data in a centralized, third-party server. Despite the theoretical
success, FL is yet to be adopted in real-world systems due to the hardware,
computing, and various infrastructure constraints presented by the edge and
mobile devices of the clients. As a result, simulated datasets, models, and
experiments are heavily used by the FL research community to validate their
theories and findings. We introduce TorchFL, a performant library for (i)
bootstrapping the FL experiments, (ii) executing them using various hardware
accelerators, (iii) profiling the performance, and (iv) logging the overall and
agent-specific results on the go. Being built on a bottom-up design using
PyTorch and Lightning, TorchFL provides ready-to-use abstractions for models,
datasets, and FL algorithms, while allowing the developers to customize them as
and when required.
</p></li>
</ul>

<h3>Title: Fast Adaptive Federated Bilevel Optimization. (arXiv:2211.01122v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01122">http://arxiv.org/abs/2211.01122</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01122] Fast Adaptive Federated Bilevel Optimization](http://arxiv.org/abs/2211.01122)</code></li>
<li>Summary: <p>Bilevel optimization has been widely applied to many machine learning tasks
such as meta learning, hyperparameter learning and policy optimization.
Although many optimization algorithms recently have been developed, few
adaptive algorithm focuses on the bilevel problems under the distributed
setting. It is well known that the adaptive gradient methods show superior
performances on both distributed and non-distributed optimization. In the
paper, thus, we propose an efficient adaptive federated bilevel optimization
algorithm (i.e.,AdaFBiO) to solve the distributed bilevel optimization
problems, where the objective function of Upper-Level (UL) problem is possibly
nonconvex, and that of Lower-Level (LL) problem is strongly convex.
Specifically, our AdaFBiO algorithm builds on the momentum-based variance
reduced technique and local-SGD to obtain the best known sample and
communication complexities simultaneously. In particular, our AdaFBiO algorithm
uses the unified adaptive matrices to flexibly incorporate various adaptive
learning rates to update variables in both UL and LL problems. Moreover, we
provide a convergence analysis framework for our AdaFBiO algorithm, and prove
that it reaches the sample complexity of $\tilde{O}(\epsilon^{-3})$ with
communication complexity of $\tilde{O}(\epsilon^{-2})$ to find
$\epsilon$-stationary point. Experimental results on federated
hyper-representation learning and federated data hyper-cleaning tasks verify
efficiency of our algorithm.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Fair Visual Recognition via Intervention with Proxy Features. (arXiv:2211.01253v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01253">http://arxiv.org/abs/2211.01253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01253] Fair Visual Recognition via Intervention with Proxy Features](http://arxiv.org/abs/2211.01253)</code></li>
<li>Summary: <p>Deep learning models often learn to make predictions that rely on sensitive
social attributes like gender and race, which poses significant fairness risks,
especially in societal applications, e.g., hiring, banking, and criminal
justice. Existing work tackles this issue by minimizing information about
social attributes in models for debiasing. However, the high correlation
between target task and social attributes makes bias mitigation incompatible
with target task accuracy. Recalling that model bias arises because the
learning of features in regard to bias attributes (i.e., bias features) helps
target task optimization, we explore the following research question: \emph{Can
we leverage proxy features to replace the role of bias feature in target task
optimization for debiasing?} To this end, we propose \emph{Proxy Debiasing}, to
first transfer the target task's learning of bias information from bias
features to artificial proxy features, and then employ causal intervention to
eliminate proxy features in inference. The key idea of \emph{Proxy Debiasing}
is to design controllable proxy features to on one hand replace bias features
in contributing to target task during the training stage, and on the other hand
easily to be removed by intervention during the inference stage. This
guarantees the elimination of bias features without affecting the target
information, thus addressing the fairness-accuracy paradox in previous
debiasing solutions. We apply \emph{Proxy Debiasing} to several benchmark
datasets, and achieve significant improvements over the state-of-the-art
debiasing methods in both of accuracy and fairness.
</p></li>
</ul>

<h3>Title: An Aggregation of Aggregation Methods in Computational Pathology. (arXiv:2211.01256v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01256">http://arxiv.org/abs/2211.01256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01256] An Aggregation of Aggregation Methods in Computational Pathology](http://arxiv.org/abs/2211.01256)</code></li>
<li>Summary: <p>Image analysis and machine learning algorithms operating on multi-gigapixel
whole-slide images (WSIs) often process a large number of tiles (sub-images)
and require aggregating predictions from the tiles in order to predict
WSI-level labels. In this paper, we present a review of existing literature on
various types of aggregation methods with a view to help guide future research
in the area of computational pathology (CPath). We propose a general CPath
workflow with three pathways that consider multiple levels and types of data
and the nature of computation to analyse WSIs for predictive modelling. We
categorize aggregation methods according to the context and representation of
the data, features of computational modules and CPath use cases. We compare and
contrast different methods based on the principle of multiple instance
learning, perhaps the most commonly used aggregation method, covering a wide
range of CPath literature. To provide a fair comparison, we consider a specific
WSI-level prediction task and compare various aggregation methods for that
task. Finally, we conclude with a list of objectives and desirable attributes
of aggregation methods in general, pros and cons of the various approaches,
some recommendations and possible future directions.
</p></li>
</ul>

<h3>Title: Impact Of Missing Data Imputation On The Fairness And Accuracy Of Graph Node Classifiers. (arXiv:2211.00783v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00783">http://arxiv.org/abs/2211.00783</a></li>
<li>Code URL: <a href="https://github.com/harisalimansoor/fairnessgraphdataimputation">https://github.com/harisalimansoor/fairnessgraphdataimputation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00783] Impact Of Missing Data Imputation On The Fairness And Accuracy Of Graph Node Classifiers](http://arxiv.org/abs/2211.00783)</code></li>
<li>Summary: <p>Analysis of the fairness of machine learning (ML) algorithms recently
attracted many researchers' interest. Most ML methods show bias toward
protected groups, which limits the applicability of ML models in many
applications like crime rate prediction etc. Since the data may have missing
values which, if not appropriately handled, are known to further harmfully
affect fairness. Many imputation methods are proposed to deal with missing
data. However, the effect of missing data imputation on fairness is not studied
well. In this paper, we analyze the effect on fairness in the context of graph
data (node attributes) imputation using different embedding and neural network
methods. Extensive experiments on six datasets demonstrate severe fairness
issues in missing data imputation under graph node classification. We also find
that the choice of the imputation method affects both fairness and accuracy.
Our results provide valuable insights into graph data fairness and how to
handle missingness in graphs efficiently. This work also provides directions
regarding theoretical studies on fairness in graph data.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Towards Inter-character Relationship-driven Story Generation. (arXiv:2211.00676v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00676">http://arxiv.org/abs/2211.00676</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00676] Towards Inter-character Relationship-driven Story Generation](http://arxiv.org/abs/2211.00676)</code></li>
<li>Summary: <p>In this paper, we introduce the task of modeling interpersonal relationships
for story generation. For addressing this task, we propose Relationships as
Latent Variables for Story Generation, (ReLiSt). ReLiSt generates stories
sentence by sentence and has two major components - a relationship selector and
a story continuer. The relationship selector specifies a latent variable to
pick the relationship to exhibit in the next sentence and the story continuer
generates the next sentence while expressing the selected relationship in a
coherent way. Our automatic and human evaluations demonstrate that ReLiSt is
able to generate stories with relationships that are more faithful to desired
relationships while maintaining the content quality. The relationship
assignments to sentences during inference bring interpretability to ReLiSt.
</p></li>
</ul>

<h3>Title: Gradient Knowledge Distillation for Pre-trained Language Models. (arXiv:2211.01071v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.01071">http://arxiv.org/abs/2211.01071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.01071] Gradient Knowledge Distillation for Pre-trained Language Models](http://arxiv.org/abs/2211.01071)</code></li>
<li>Summary: <p>Knowledge distillation (KD) is an effective framework to transfer knowledge
from a large-scale teacher to a compact yet well-performing student. Previous
KD practices for pre-trained language models mainly transfer knowledge by
aligning instance-wise outputs between the teacher and student, while
neglecting an important knowledge source, i.e., the gradient of the teacher.
The gradient characterizes how the teacher responds to changes in inputs, which
we assume is beneficial for the student to better approximate the underlying
mapping function of the teacher. Therefore, we propose Gradient Knowledge
Distillation (GKD) to incorporate the gradient alignment objective into the
distillation process. Experimental results show that GKD outperforms previous
KD methods regarding student performance. Further analysis shows that
incorporating gradient knowledge makes the student behave more consistently
with the teacher, improving the interpretability greatly.
</p></li>
</ul>

<h3>Title: Discover Important Paths in the Knowledge Graph Based on Dynamic Relation Confidence. (arXiv:2211.00914v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.00914">http://arxiv.org/abs/2211.00914</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.00914] Discover Important Paths in the Knowledge Graph Based on Dynamic Relation Confidence](http://arxiv.org/abs/2211.00914)</code></li>
<li>Summary: <p>Most of the existing knowledge graphs are not usually complete and can be
complemented by some reasoning algorithms. The reasoning method based on path
features is widely used in the field of knowledge graph reasoning and
completion on account of that its have strong interpretability. However,
reasoning methods based on path features still have several problems in the
following aspects: Path search isinefficient, insufficient paths for sparse
tasks and some paths are not helpful for reasoning tasks. In order to solve the
above problems, this paper proposes a method called DC-Path that combines
dynamic relation confidence and other indicators to evaluate path features, and
then guide path search, finally conduct relation reasoning. Experimental result
show that compared with the existing relation reasoning algorithm, this method
can select the most representative features in the current reasoning task from
the knowledge graph and achieve better performance on the current relation
reasoning task.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
