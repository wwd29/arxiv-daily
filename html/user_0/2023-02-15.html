<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: That Escalated Quickly: An ML Framework for Alert Prioritization. (arXiv:2302.06648v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06648">http://arxiv.org/abs/2302.06648</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06648] That Escalated Quickly: An ML Framework for Alert Prioritization](http://arxiv.org/abs/2302.06648) #security</code></li>
<li>Summary: <p>In place of in-house solutions, organizations are increasingly moving towards
managed services for cyber defense. Security Operations Centers are specialized
cybersecurity units responsible for the defense of an organization, but the
large-scale centralization of threat detection is causing SOCs to endure an
overwhelming amount of false positive alerts -- a phenomenon known as alert
fatigue. Large collections of imprecise sensors, an inability to adapt to known
false positives, evolution of the threat landscape, and inefficient use of
analyst time all contribute to the alert fatigue problem. To combat these
issues, we present That Escalated Quickly (TEQ), a machine learning framework
that reduces alert fatigue with minimal changes to SOC workflows by predicting
alert-level and incident-level actionability. On real-world data, the system is
able to reduce the time it takes to respond to actionable incidents by
$22.9\%$, suppress $54\%$ of false positives with a $95.1\%$ detection rate,
and reduce the number of alerts an analyst needs to investigate within singular
incidents by $14\%$.
</p></li>
</ul>

<h3>Title: Proof of Reputation. (arXiv:2302.06966v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06966">http://arxiv.org/abs/2302.06966</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06966] Proof of Reputation](http://arxiv.org/abs/2302.06966) #security</code></li>
<li>Summary: <p>We present the new mining protocol Proof-of-Reputation (PoR) for
decentralized Proof-of-Work (PoW) blockchains, in particular for Bitcoin. PoR
combines the classical PoW with the new ingredient of cryptographic reputation.
The same level of security compared to pure PoW can be achieved with a
significant energy consumption reduction (of the order of 30\%) for the same
security level. The proper implementation of a decentralized reputation
protocol is suitable with an extra layer of mining security: Certified Mining.
</p></li>
</ul>

<h3>Title: RISE: RISC-V SoC for En/decryption Acceleration on the Edge for Homomorphic Encryption. (arXiv:2302.07104v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07104">http://arxiv.org/abs/2302.07104</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07104] RISE: RISC-V SoC for En/decryption Acceleration on the Edge for Homomorphic Encryption](http://arxiv.org/abs/2302.07104) #security</code></li>
<li>Summary: <p>Today edge devices commonly connect to the cloud to use its storage and
compute capabilities. This leads to security and privacy concerns about user
data. Homomorphic Encryption (HE) is a promising solution to address the data
privacy problem as it allows arbitrarily complex computations on encrypted data
without ever needing to decrypt it. While there has been a lot of work on
accelerating HE computations in the cloud, little attention has been paid to
the message-to-ciphertext and ciphertext-to-message conversion operations on
the edge. In this work, we profile the edge-side conversion operations, and our
analysis shows that during conversion error sampling, encryption, and
decryption operations are the bottlenecks. To overcome these bottlenecks, we
present RISE, an area and energy-efficient RISC-V SoC. RISE leverages an
efficient and lightweight pseudo-random number generator core and combines it
with fast sampling techniques to accelerate the error sampling operations. To
accelerate the encryption and decryption operations, RISE uses scalable,
data-level parallelism to implement the number theoretic transform operation,
the main bottleneck within the encryption and decryption operations. In
addition, RISE saves area by implementing a unified en/decryption datapath, and
efficiently exploits techniques like memory reuse and data reordering to
utilize a minimal amount of on-chip memory. We evaluate RISE using a complete
RTL design containing a RISC-V processor interfaced with our accelerator. Our
analysis reveals that for message-to-ciphertext conversion and
ciphertext-to-message conversion, using RISE leads up to 6191.19X and 2481.44X
more energy-efficient solution, respectively, than when using just the RISC-V
processor.
</p></li>
</ul>

<h3>Title: Security Reputation Metrics. (arXiv:2302.07172v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07172">http://arxiv.org/abs/2302.07172</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07172] Security Reputation Metrics](http://arxiv.org/abs/2302.07172) #security</code></li>
<li>Summary: <p>Security reputation metrics (aka. security metrics) quantify the security
levels of organization (e.g., hosting or Internet access providers) relative to
comparable entities. They enable benchmarking and are essential tools for
decision and policy-making in security, and may be used to govern and steer
responsible parties towards investing in security when economic or other
decision-making factors may drive them to do otherwise.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Bounding Training Data Reconstruction in DP-SGD. (arXiv:2302.07225v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07225">http://arxiv.org/abs/2302.07225</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07225] Bounding Training Data Reconstruction in DP-SGD](http://arxiv.org/abs/2302.07225) #privacy</code></li>
<li>Summary: <p>Differentially private training offers a protection which is usually
interpreted as a guarantee against membership inference attacks. By proxy, this
guarantee extends to other threats like reconstruction attacks attempting to
extract complete training examples. Recent works provide evidence that if one
does not need to protect against membership attacks but instead only wants to
protect against training data reconstruction, then utility of private models
can be improved because less noise is required to protect against these more
ambitious attacks. We investigate this further in the context of DP-SGD, a
standard algorithm for private deep learning, and provide an upper bound on the
success of any reconstruction attack against DP-SGD together with an attack
that empirically matches the predictions of our bound. Together, these two
results open the door to fine-grained investigations on how to set the privacy
parameters of DP-SGD in practice to protect against reconstruction attacks.
Finally, we use our methods to demonstrate that different settings of the
DP-SGD parameters leading to the same DP guarantees can result in significantly
different success rates for reconstruction, indicating that the DP guarantee
alone might not be a good proxy for controlling the protection against
reconstruction attacks.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Oops..! I Glitched It Again! How to Multi-Glitch the Glitching-Protections on ARM TrustZone-M. (arXiv:2302.06932v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06932">http://arxiv.org/abs/2302.06932</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06932] Oops](http://arxiv.org/abs/2302.06932) #protect</code></li>
<li>Summary: <p>Voltage Fault Injection (VFI), also known as power glitching, has proven to
be a severe threat to real-world systems. In VFI attacks, the adversary
disturbs the power-supply of the target-device forcing the device to
illegitimate behavior. Various countermeasures have been proposed to address
different types of fault injection attacks at different abstraction layers,
either requiring to modify the underlying hardware or software/firmware at the
machine instruction level. Moreover, only recently, individual chip
manufacturers have started to respond to this threat by integrating
countermeasures in their products. Generally, these countermeasures aim at
protecting against single fault injection (SFI) attacks, since Multiple Fault
Injection (MFI) is believed to be challenging and sometimes even impractical.
In this paper, we present {\mu}-Glitch, the first Voltage Fault Injection (VFI)
platform which is capable of injecting multiple, coordinated voltage faults
into a target device, requiring only a single trigger signal. We provide a
novel flow for Multiple Voltage Fault Injection (MVFI) attacks to significantly
reduce the search complexity for fault parameters, as the search space
increases exponentially with each additional fault injection. We evaluate and
showcase the effectiveness and practicality of our attack platform on four
real-world chips, featuring TrustZone-M: The first two have interdependent
backchecking mechanisms, while the second two have additionally integrated
countermeasures against fault injection. Our evaluation revealed that
{\mu}-Glitch can successfully inject four consecutive faults within an average
time of one day. Finally, we discuss potential countermeasures to mitigate VFI
attacks and additionally propose two novel attack scenarios for MVFI.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions. (arXiv:2302.06801v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06801">http://arxiv.org/abs/2302.06801</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06801] Backdoor Learning for NLP: Recent Advances, Challenges, and Future Research Directions](http://arxiv.org/abs/2302.06801) #defense</code></li>
<li>Summary: <p>Although backdoor learning is an active research topic in the NLP domain, the
literature lacks studies that systematically categorize and summarize backdoor
attacks and defenses. To bridge the gap, we present a comprehensive and
unifying study of backdoor learning for NLP by summarizing the literature in a
systematic manner. We first present and motivate the importance of backdoor
learning for building robust NLP systems. Next, we provide a thorough account
of backdoor attack techniques, their applications, defenses against backdoor
attacks, and various mitigation techniques to remove backdoor attacks. We then
provide a detailed review and analysis of evaluation metrics, benchmark
datasets, threat models, and challenges related to backdoor learning in NLP.
Ultimately, our work aims to crystallize and contextualize the landscape of
existing literature in backdoor learning for the text domain and motivate
further research in the field. To this end, we identify troubling gaps in the
literature and offer insights and ideas into open challenges and future
research directions. Finally, we provide a GitHub repository with a list of
backdoor learning papers that will be continuously updated at
https://github.com/marwanomar1/Backdoor-Learning-for-NLP.
</p></li>
</ul>

<h2>attack</h2>
<h2>robust</h2>
<h3>Title: Deep Learning Predicts Prevalent and Incident Parkinson's Disease From UK Biobank Fundus Imaging. (arXiv:2302.06727v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06727">http://arxiv.org/abs/2302.06727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06727] Deep Learning Predicts Prevalent and Incident Parkinson's Disease From UK Biobank Fundus Imaging](http://arxiv.org/abs/2302.06727) #robust</code></li>
<li>Summary: <p>Parkinson's disease is the world's fastest growing neurological disorder.
Research to elucidate the mechanisms of Parkinson's disease and automate
diagnostics would greatly improve the treatment of patients with Parkinson's
disease. Current diagnostic methods are expensive with limited availability.
Considering the long progression time of Parkinson's disease, a desirable
screening should be diagnostically accurate even before the onset of symptoms
to allow medical intervention. We promote attention for retinal fundus imaging,
often termed a window to the brain, as a diagnostic screening modality for
Parkinson's disease. We conduct a systematic evaluation of conventional machine
learning and deep learning techniques to classify Parkinson's disease from UK
Biobank fundus imaging. Our results suggest Parkinson's disease individuals can
be differentiated from age and gender matched healthy subjects with 71%
accuracy. This accuracy is maintained when predicting either prevalent or
incident Parkinson's disease. Explainability and trustworthiness is enhanced by
visual attribution maps of localized biomarkers and quantified metrics of model
robustness to data perturbations.
</p></li>
</ul>

<h3>Title: Robust Unsupervised StyleGAN Image Restoration. (arXiv:2302.06733v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06733">http://arxiv.org/abs/2302.06733</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06733] Robust Unsupervised StyleGAN Image Restoration](http://arxiv.org/abs/2302.06733) #robust</code></li>
<li>Summary: <p>GAN-based image restoration inverts the generative process to repair images
corrupted by known degradations. Existing unsupervised methods must be
carefully tuned for each task and degradation level. In this work, we make
StyleGAN image restoration robust: a single set of hyperparameters works across
a wide range of degradation levels. This makes it possible to handle
combinations of several degradations, without the need to retune. Our proposed
approach relies on a 3-phase progressive latent space extension and a
conservative optimizer, which avoids the need for any additional regularization
terms. Extensive experiments demonstrate robustness on inpainting, upsampling,
denoising, and deartifacting at varying degradations levels, outperforming
other StyleGAN-based inversion techniques. Our approach also favorably compares
to diffusion-based restoration by yielding much more realistic inversion
results. Code will be released upon publication.
</p></li>
</ul>

<h3>Title: Learning with Noisy labels via Self-supervised Adversarial Noisy Masking. (arXiv:2302.06805v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06805">http://arxiv.org/abs/2302.06805</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06805] Learning with Noisy labels via Self-supervised Adversarial Noisy Masking](http://arxiv.org/abs/2302.06805) #robust</code></li>
<li>Summary: <p>Collecting large-scale datasets is crucial for training deep models,
annotating the data, however, inevitably yields noisy labels, which poses
challenges to deep learning algorithms. Previous efforts tend to mitigate this
problem via identifying and removing noisy samples or correcting their labels
according to the statistical properties (e.g., loss values) among training
samples. In this paper, we aim to tackle this problem from a new perspective,
delving into the deep feature maps, we empirically find that models trained
with clean and mislabeled samples manifest distinguishable activation feature
distributions. From this observation, a novel robust training approach termed
adversarial noisy masking is proposed. The idea is to regularize deep features
with a label quality guided masking scheme, which adaptively modulates the
input data and label simultaneously, preventing the model to overfit noisy
samples. Further, an auxiliary task is designed to reconstruct input data, it
naturally provides noise-free self-supervised signals to reinforce the
generalization ability of deep models. The proposed method is simple and
flexible, it is tested on both synthetic and real-world noisy datasets, where
significant improvements are achieved over previous state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Learning from Noisy Labels with Decoupled Meta Label Purifier. (arXiv:2302.06810v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06810">http://arxiv.org/abs/2302.06810</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06810] Learning from Noisy Labels with Decoupled Meta Label Purifier](http://arxiv.org/abs/2302.06810) #robust</code></li>
<li>Summary: <p>Training deep neural networks(DNN) with noisy labels is challenging since DNN
can easily memorize inaccurate labels, leading to poor generalization ability.
Recently, the meta-learning based label correction strategy is widely adopted
to tackle this problem via identifying and correcting potential noisy labels
with the help of a small set of clean validation data. Although training with
purified labels can effectively improve performance, solving the meta-learning
problem inevitably involves a nested loop of bi-level optimization between
model weights and hyper-parameters (i.e., label distribution). As compromise,
previous methods resort to a coupled learning process with alternating update.
In this paper, we empirically find such simultaneous optimization over both
model weights and label distribution can not achieve an optimal routine,
consequently limiting the representation ability of backbone and accuracy of
corrected labels. From this observation, a novel multi-stage label purifier
named DMLP is proposed. DMLP decouples the label correction process into
label-free representation learning and a simple meta label purifier. In this
way, DMLP can focus on extracting discriminative feature and label correction
in two distinctive stages. DMLP is a plug-and-play label purifier, the purified
labels can be directly reused in naive end-to-end network retraining or other
robust learning methods, where state-of-the-art results are obtained on several
synthetic and real-world noisy datasets, especially under high noise levels.
</p></li>
</ul>

<h3>Title: Self-supervised Likelihood Estimation with Energy Guidance for Anomaly Segmentation in Urban Scenes. (arXiv:2302.06815v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06815">http://arxiv.org/abs/2302.06815</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06815] Self-supervised Likelihood Estimation with Energy Guidance for Anomaly Segmentation in Urban Scenes](http://arxiv.org/abs/2302.06815) #robust</code></li>
<li>Summary: <p>Robust autonomous driving requires agents to accurately identify unexpected
areas in urban scenes. To this end, some critical issues remain open: how to
design advisable metric to measure anomalies, and how to properly generate
training samples of anomaly data? Previous effort usually resorts to
uncertainty estimation and sample synthesis from classification tasks, which
ignore the context information and sometimes requires auxiliary datasets with
fine-grained annotations. On the contrary, in this paper, we exploit the strong
context-dependent nature of segmentation task and design an energy-guided
self-supervised frameworks for anomaly segmentation, which optimizes an anomaly
head by maximizing the likelihood of self-generated anomaly pixels. To this
end, we design two estimators for anomaly likelihood estimation, one is a
simple task-agnostic binary estimator and the other depicts anomaly likelihood
as residual of task-oriented energy model. Based on proposed estimators, we
further incorporate our framework with likelihood-guided mask refinement
process to extract informative anomaly pixels for model training. We conduct
extensive experiments on challenging Fishyscapes and Road Anomaly benchmarks,
demonstrating that without any auxiliary data or synthetic models, our method
can still achieves competitive performance to other SOTA schemes.
</p></li>
</ul>

<h3>Title: Searching Transferable Mixed-Precision Quantization Policy through Large Margin Regularization. (arXiv:2302.06845v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06845">http://arxiv.org/abs/2302.06845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06845] Searching Transferable Mixed-Precision Quantization Policy through Large Margin Regularization](http://arxiv.org/abs/2302.06845) #robust</code></li>
<li>Summary: <p>Mixed-precision quantization (MPQ) suffers from time-consuming policy search
process (i.e., the bit-width assignment for each layer) on large-scale datasets
(e.g., ISLVRC-2012), which heavily limits its practicability in real-world
deployment scenarios. In this paper, we propose to search the effective MPQ
policy by using a small proxy dataset for the model trained on a large-scale
one. It breaks the routine that requires a consistent dataset at model training
and MPQ policy search time, which can improve the MPQ searching efficiency
significantly. However, the discrepant data distributions bring difficulties in
searching for such a transferable MPQ policy. Motivated by the observation that
quantization narrows the class margin and blurs the decision boundary, we
search the policy that guarantees a general and dataset-independent property:
discriminability of feature representations. Namely, we seek the policy that
can robustly keep the intra-class compactness and inter-class separation. Our
method offers several advantages, i.e., high proxy data utilization, no extra
hyper-parameter tuning for approximating the relationship between
full-precision and quantized model and high searching efficiency. We search
high-quality MPQ policies with the proxy dataset that has only 4% of the data
scale compared to the large-scale target dataset, achieving the same accuracy
as searching directly on the latter, and improving the MPQ searching efficiency
by up to 300 times.
</p></li>
</ul>

<h3>Title: Robust Representation Learning with Self-Distillation for Domain Generalization. (arXiv:2302.06874v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06874">http://arxiv.org/abs/2302.06874</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06874] Robust Representation Learning with Self-Distillation for Domain Generalization](http://arxiv.org/abs/2302.06874) #robust</code></li>
<li>Summary: <p>Domain generalization is a challenging problem in machine learning, where the
goal is to train a model that can generalize well to unseen target domains
without prior knowledge of these domains. Despite the recent success of deep
neural networks, there remains a lack of effective methods for domain
generalization using vision transformers. In this paper, we propose a novel
domain generalization technique called Robust Representation Learning with
Self-Distillation (RRLD) that utilizes a combination of i) intermediate-block
self-distillation and ii) augmentation-guided self-distillation to improve the
generalization capabilities of transformer-based models on unseen domains. This
approach enables the network to learn robust and general features that are
invariant to different augmentations and domain shifts while effectively
mitigating overfitting to source domains. To evaluate the effectiveness of our
proposed method, we perform extensive experiments on PACS [1] and OfficeHome
[2] benchmark datasets, as well as a real-world wafer semiconductor defect
dataset [3]. Our results demonstrate that RRLD achieves robust and accurate
generalization performance. We observe an improvement in the range of 0.3% to
2.3% over the state-of-the-art on the three datasets.
</p></li>
</ul>

<h3>Title: An Image Processing Pipeline for Autonomous Deep-Space Optical Navigation. (arXiv:2302.06918v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06918">http://arxiv.org/abs/2302.06918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06918] An Image Processing Pipeline for Autonomous Deep-Space Optical Navigation](http://arxiv.org/abs/2302.06918) #robust</code></li>
<li>Summary: <p>A new era of space exploration and exploitation is fast approaching. A
multitude of spacecraft will flow in the future decades under the propulsive
momentum of the new space economy. Yet, the flourishing proliferation of
deep-space assets will make it unsustainable to pilot them from ground with
standard radiometric tracking. The adoption of autonomous navigation
alternatives is crucial to overcoming these limitations. Among these, optical
navigation is an affordable and fully ground-independent approach. Probes can
triangulate their position by observing visible beacons, e.g., planets or
asteroids, by acquiring their line-of-sight in deep space. To do so, developing
efficient and robust image processing algorithms providing information to
navigation filters is a necessary action. This paper proposes an innovative
pipeline for unresolved beacon recognition and line-of-sight extraction from
images for autonomous interplanetary navigation. The developed algorithm
exploits the k-vector method for the non-stellar object identification and
statistical likelihood to detect whether any beacon projection is visible in
the image. Statistical results show that the accuracy in detecting the planet
position projection is independent of the spacecraft position uncertainty.
Whereas, the planet detection success rate is higher than 95% when the
spacecraft position is known with a 3sigma accuracy up to 10^5 km.
</p></li>
</ul>

<h3>Title: Underwater target detection based on improved YOLOv7. (arXiv:2302.06939v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06939">http://arxiv.org/abs/2302.06939</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06939] Underwater target detection based on improved YOLOv7](http://arxiv.org/abs/2302.06939) #robust</code></li>
<li>Summary: <p>Underwater target detection is a crucial aspect of ocean exploration.
However, conventional underwater target detection methods face several
challenges such as inaccurate feature extraction, slow detection speed and lack
of robustness in complex underwater environments. To address these limitations,
this study proposes an improved YOLOv7 network (YOLOv7-AC) for underwater
target detection. The proposed network utilizes an ACmixBlock module to replace
the 3x3 convolution block in the E-ELAN structure, and incorporates jump
connections and 1x1 convolution architecture between ACmixBlock modules to
improve feature extraction and network reasoning speed. Additionally, a
ResNet-ACmix module is designed to avoid feature information loss and reduce
computation, while a Global Attention Mechanism (GAM) is inserted in the
backbone and head parts of the model to improve feature extraction.
Furthermore, the K-means++ algorithm is used instead of K-means to obtain
anchor boxes and enhance model accuracy. Experimental results show that the
improved YOLOv7 network outperforms the original YOLOv7 model and other popular
underwater target detection methods. The proposed network achieved a mean
average precision (mAP) value of 89.6% and 97.4% on the URPC dataset and
Brackish dataset, respectively, and demonstrated a higher frame per second
(FPS) compared to the original YOLOv7 model. The source code for this study is
publicly available at https://github.com/NZWANG/YOLOV7-AC. In conclusion, the
improved YOLOv7 network proposed in this study represents a promising solution
for underwater target detection and holds great potential for practical
applications in various underwater tasks.
</p></li>
</ul>

<h3>Title: Camera Calibration without Camera Access -- A Robust Validation Technique for Extended PnP Methods. (arXiv:2302.06949v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06949">http://arxiv.org/abs/2302.06949</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06949] Camera Calibration without Camera Access -- A Robust Validation Technique for Extended PnP Methods](http://arxiv.org/abs/2302.06949) #robust</code></li>
<li>Summary: <p>A challenge in image based metrology and forensics is intrinsic camera
calibration when the used camera is unavailable. The unavailability raises two
questions. The first question is how to find the projection model that
describes the camera, and the second is to detect incorrect models. In this
work, we use off-the-shelf extended PnP-methods to find the model from 2D-3D
correspondences, and propose a method for model validation. The most common
strategy for evaluating a projection model is comparing different models'
residual variances - however, this naive strategy cannot distinguish whether
the projection model is potentially underfitted or overfitted. To this end, we
model the residual errors for each correspondence, individually scale all
residuals using a predicted variance and test if the new residuals are drawn
from a standard normal distribution. We demonstrate the effectiveness of our
proposed validation in experiments on synthetic data, simulating 2D detection
and Lidar measurements. Additionally, we provide experiments using data from an
actual scene and compare non-camera access and camera access calibrations.
Last, we use our method to validate annotations in MegaDepth.
</p></li>
</ul>

<h3>Title: Bilateral-Fuser: A Novel Multi-cue Fusion Architecture with Anatomical-aware Tokens for Fovea Localization. (arXiv:2302.06961v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06961">http://arxiv.org/abs/2302.06961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06961] Bilateral-Fuser: A Novel Multi-cue Fusion Architecture with Anatomical-aware Tokens for Fovea Localization](http://arxiv.org/abs/2302.06961) #robust</code></li>
<li>Summary: <p>Accurate localization of fovea is one of the primary steps in analyzing
retinal diseases since it helps prevent irreversible vision loss. Although
current deep learning-based methods achieve better performance than traditional
methods, there still remain challenges such as utilizing anatomical landmarks
insufficiently, sensitivity to diseased retinal images and various image
conditions. In this paper, we propose a novel transformer-based architecture
(Bilateral-Fuser) for multi-cue fusion. This architecture explicitly
incorporates long-range connections and global features using retina and vessel
distributions for robust fovea localization. We introduce a spatial attention
mechanism in the dual-stream encoder for extracting and fusing self-learned
anatomical information. This design focuses more on features distributed along
blood vessels and significantly decreases computational costs by reducing token
numbers. Our comprehensive experiments show that the proposed architecture
achieves state-of-the-art performance on two public and one large-scale private
datasets. We also present that the Bilateral-Fuser is more robust on both
normal and diseased retina images and has better generalization capacity in
cross-dataset experiments.
</p></li>
</ul>

<h3>Title: Point Cloud Registration for LiDAR and Photogrammetric Data: a Critical Synthesis and Performance Analysis on Classic and Deep Learning Algorithms. (arXiv:2302.07184v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07184">http://arxiv.org/abs/2302.07184</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07184] Point Cloud Registration for LiDAR and Photogrammetric Data: a Critical Synthesis and Performance Analysis on Classic and Deep Learning Algorithms](http://arxiv.org/abs/2302.07184) #robust</code></li>
<li>Summary: <p>Recent advances in computer vision and deep learning have shown promising
performance in estimating rigid/similarity transformation between unregistered
point clouds of complex objects and scenes. However, their performances are
mostly evaluated using a limited number of datasets from a single sensor (e.g.
Kinect or RealSense cameras), lacking a comprehensive overview of their
applicability in photogrammetric 3D mapping scenarios. In this work, we provide
a comprehensive review of the state-of-the-art (SOTA) point cloud registration
methods, where we analyze and evaluate these methods using a diverse set of
point cloud data from indoor to satellite sources. The quantitative analysis
allows for exploring the strengths, applicability, challenges, and future
trends of these methods. In contrast to existing analysis works that introduce
point cloud registration as a holistic process, our experimental analysis is
based on its inherent two-step process to better comprehend these approaches
including feature/keypoint-based initial coarse registration and dense fine
registration through cloud-to-cloud (C2C) optimization. More than ten methods,
including classic hand-crafted, deep-learning-based feature correspondence, and
robust C2C methods were tested. We observed that the success rate of most of
the algorithms are fewer than 40% over the datasets we tested and there are
still are large margin of improvement upon existing algorithms concerning 3D
sparse corresopondence search, and the ability to register point clouds with
complex geometry and occlusions. With the evaluated statistics on three
datasets, we conclude the best-performing methods for each step and provide our
recommendations, and outlook future efforts.
</p></li>
</ul>

<h3>Title: The Stable Entropy Hypothesis and Entropy-Aware Decoding: An Analysis and Algorithm for Robust Natural Language Generation. (arXiv:2302.06784v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06784">http://arxiv.org/abs/2302.06784</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06784] The Stable Entropy Hypothesis and Entropy-Aware Decoding: An Analysis and Algorithm for Robust Natural Language Generation](http://arxiv.org/abs/2302.06784) #robust</code></li>
<li>Summary: <p>State-of-the-art language generation models can degenerate when applied to
open-ended generation problems such as text completion, story generation, or
dialog modeling. This degeneration usually shows up in the form of incoherence,
lack of vocabulary diversity, and self-repetition or copying from the context.
In this paper, we postulate that ``human-like'' generations usually lie in a
narrow and nearly flat entropy band, and violation of these entropy bounds
correlates with degenerate behavior. Our experiments show that this stable
narrow entropy zone exists across models, tasks, and domains and confirm the
hypothesis that violations of this zone correlate with degeneration. We then
use this insight to propose an entropy-aware decoding algorithm that respects
these entropy bounds resulting in less degenerate, more contextual, and
"human-like" language generation in open-ended text generation settings.
</p></li>
</ul>

<h3>Title: In Search for a Generalizable Method for Source Free Domain Adaptation. (arXiv:2302.06658v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06658">http://arxiv.org/abs/2302.06658</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06658] In Search for a Generalizable Method for Source Free Domain Adaptation](http://arxiv.org/abs/2302.06658) #robust</code></li>
<li>Summary: <p>Source-free domain adaptation (SFDA) is compelling because it allows adapting
an off-the-shelf model to a new domain using only unlabelled data. In this
work, we apply existing SFDA techniques to a challenging set of
naturally-occurring distribution shifts in bioacoustics, which are very
different from the ones commonly studied in computer vision. We find existing
methods perform differently relative to each other than observed in vision
benchmarks, and sometimes perform worse than no adaptation at all. We propose a
new simple method which outperforms the existing methods on our new shifts
while exhibiting strong performance on a range of vision datasets. Our findings
suggest that existing SFDA methods are not as generalizable as previously
thought and that considering diverse modalities can be a useful avenue for
designing more robust models.
</p></li>
</ul>

<h3>Title: SpeckleNN: A unified embedding for real-time speckle pattern classification in X-ray single-particle imaging with limited labeled examples. (arXiv:2302.06895v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06895">http://arxiv.org/abs/2302.06895</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06895] SpeckleNN: A unified embedding for real-time speckle pattern classification in X-ray single-particle imaging with limited labeled examples](http://arxiv.org/abs/2302.06895) #robust</code></li>
<li>Summary: <p>With X-ray free-electron lasers (XFELs), it is possible to determine the
three-dimensional structure of noncrystalline nanoscale particles using X-ray
single-particle imaging (SPI) techniques at room temperature. Classifying SPI
scattering patterns, or "speckles", to extract single hits that are needed for
real-time vetoing and three-dimensional reconstruction poses a challenge for
high data rate facilities like European XFEL and LCLS-II-HE. Here, we introduce
SpeckleNN, a unified embedding model for real-time speckle pattern
classification with limited labeled examples that can scale linearly with
dataset size. Trained with twin neural networks, SpeckleNN maps speckle
patterns to a unified embedding vector space, where similarity is measured by
Euclidean distance. We highlight its few-shot classification capability on new
never-seen samples and its robust performance despite only tens of labels per
classification category even in the presence of substantial missing detector
areas. Without the need for excessive manual labeling or even a full detector
image, our classification method offers a great solution for real-time
high-throughput SPI experiments.
</p></li>
</ul>

<h3>Title: Robust Deep Reinforcement Learning through Regret Neighborhoods. (arXiv:2302.06912v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06912">http://arxiv.org/abs/2302.06912</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06912] Robust Deep Reinforcement Learning through Regret Neighborhoods](http://arxiv.org/abs/2302.06912) #robust</code></li>
<li>Summary: <p>Deep Reinforcement Learning (DRL) policies have been shown to be vulnerable
to small adversarial noise in observations. Such adversarial noise can have
disastrous consequences in safety-critical environments. For instance, a
self-driving car receiving adversarially perturbed sensory observations about
nearby signs (e.g., a stop sign physically altered to be perceived as a speed
limit sign) or objects (e.g., cars altered to be recognized as trees) can be
fatal. Existing approaches for making RL algorithms robust to an
observation-perturbing adversary have focused on reactive approaches that
iteratively improve against adversarial examples generated at each iteration.
While such approaches have been shown to provide improvements over regular RL
methods, they are reactive and can fare significantly worse if certain
categories of adversarial examples are not generated during training. To that
end, we pursue a more proactive approach that relies on directly optimizing a
well-studied robustness measure, regret instead of expected value. We provide a
principled approach that minimizes maximum regret over a "neighborhood" of
observations to the received "observation". Our regret criterion can be used to
modify existing value- and policy-based Deep RL methods. We demonstrate that
our approaches provide a significant improvement in performance across a wide
variety of benchmarks against leading approaches for robust Deep RL.
</p></li>
</ul>

<h3>Title: An Experimental Study of Byzantine-Robust Aggregation Schemes in Federated Learning. (arXiv:2302.07173v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07173">http://arxiv.org/abs/2302.07173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07173] An Experimental Study of Byzantine-Robust Aggregation Schemes in Federated Learning](http://arxiv.org/abs/2302.07173) #robust</code></li>
<li>Summary: <p>Byzantine-robust federated learning aims at mitigating Byzantine failures
during the federated training process, where malicious participants may upload
arbitrary local updates to the central server to degrade the performance of the
global model. In recent years, several robust aggregation schemes have been
proposed to defend against malicious updates from Byzantine clients and improve
the robustness of federated learning. These solutions were claimed to be
Byzantine-robust, under certain assumptions. Other than that, new attack
strategies are emerging, striving to circumvent the defense schemes. However,
there is a lack of systematic comparison and empirical study thereof. In this
paper, we conduct an experimental study of Byzantine-robust aggregation schemes
under different attacks using two popular algorithms in federated learning,
FedSGD and FedAvg . We first survey existing Byzantine attack strategies and
Byzantine-robust aggregation schemes that aim to defend against Byzantine
attacks. We also propose a new scheme, ClippedClustering , to enhance the
robustness of a clustering-based scheme by automatically clipping the updates.
Then we provide an experimental evaluation of eight aggregation schemes in the
scenario of five different Byzantine attacks. Our results show that these
aggregation schemes sustain relatively high accuracy in some cases but are
ineffective in others. In particular, our proposed ClippedClustering
successfully defends against most attacks under independent and IID local
datasets. However, when the local datasets are Non-IID, the performance of all
the aggregation schemes significantly decreases. With Non-IID data, some of
these aggregation schemes fail even in the complete absence of Byzantine
clients. We conclude that the robustness of all the aggregation schemes is
limited, highlighting the need for new defense strategies, in particular for
Non-IID datasets.
</p></li>
</ul>

<h3>Title: Randomization for adversarial robustness: the Good, the Bad and the Ugly. (arXiv:2302.07221v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07221">http://arxiv.org/abs/2302.07221</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07221] Randomization for adversarial robustness: the Good, the Bad and the Ugly](http://arxiv.org/abs/2302.07221) #robust</code></li>
<li>Summary: <p>Deep neural networks are known to be vulnerable to adversarial attacks: A
small perturbation that is imperceptible to a human can easily make a
well-trained deep neural network misclassify. To defend against adversarial
attacks, randomized classifiers have been proposed as a robust alternative to
deterministic ones. In this work we show that in the binary classification
setting, for any randomized classifier, there is always a deterministic
classifier with better adversarial risk. In other words, randomization is not
necessary for robustness. In many common randomization schemes, the
deterministic classifiers with better risk are explicitly described: For
example, we show that ensembles of classifiers are more robust than mixtures of
classifiers, and randomized smoothing is more robust than input noise
injection. Finally, experiments confirm our theoretical results with the two
families of randomized classifiers we analyze.
</p></li>
</ul>

<h3>Title: Cauchy Loss Function: Robustness Under Gaussian and Cauchy Noise. (arXiv:2302.07238v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07238">http://arxiv.org/abs/2302.07238</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07238] Cauchy Loss Function: Robustness Under Gaussian and Cauchy Noise](http://arxiv.org/abs/2302.07238) #robust</code></li>
<li>Summary: <p>In supervised machine learning, the choice of loss function implicitly
assumes a particular noise distribution over the data. For example, the
frequently used mean squared error (MSE) loss assumes a Gaussian noise
distribution. The choice of loss function during training and testing affects
the performance of artificial neural networks (ANNs). It is known that MSE may
yield substandard performance in the presence of outliers. The Cauchy loss
function (CLF) assumes a Cauchy noise distribution, and is therefore
potentially better suited for data with outliers. This papers aims to determine
the extent of robustness and generalisability of the CLF as compared to MSE.
CLF and MSE are assessed on a few handcrafted regression problems, and a
real-world regression problem with artificially simulated outliers, in the
context of ANN training. CLF yielded results that were either comparable to or
better than the results yielded by MSE, with a few notable exceptions.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: PerAda: Parameter-Efficient and Generalizable Federated Learning Personalization with Guarantees. (arXiv:2302.06637v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06637">http://arxiv.org/abs/2302.06637</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06637] PerAda: Parameter-Efficient and Generalizable Federated Learning Personalization with Guarantees](http://arxiv.org/abs/2302.06637) #federate</code></li>
<li>Summary: <p>Personalized Federated Learning (pFL) has emerged as a promising solution to
tackle data heterogeneity across clients in FL. However, existing pFL methods
either (1) introduce high communication and computation costs or (2) overfit to
local data, which can be limited in scope, and are vulnerable to evolved test
samples with natural shifts. In this paper, we propose PerAda, a
parameter-efficient pFL framework that reduces communication and computational
costs and exhibits superior generalization performance, especially under
test-time distribution shifts. PerAda reduces the costs by leveraging the power
of pretrained models and only updates and communicates a small number of
additional parameters from adapters. PerAda has good generalization since it
regularizes each client's personalized adapter with a global adapter, while the
global adapter uses knowledge distillation to aggregate generalized information
from all clients. Theoretically, we provide generalization bounds to explain
why PerAda improves generalization, and we prove its convergence to stationary
points under non-convex settings. Empirically, PerAda demonstrates competitive
personalized performance (+4.85% on CheXpert) and enables better
out-of-distribution generalization (+5.23% on CIFAR-10-C) on different datasets
across natural and medical domains compared with baselines, while only updating
12.6% of parameters per model based on the adapter.
</p></li>
</ul>

<h3>Title: Communication-Efficient Federated Bilevel Optimization with Local and Global Lower Level Problems. (arXiv:2302.06701v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06701">http://arxiv.org/abs/2302.06701</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06701] Communication-Efficient Federated Bilevel Optimization with Local and Global Lower Level Problems](http://arxiv.org/abs/2302.06701) #federate</code></li>
<li>Summary: <p>Bilevel Optimization has witnessed notable progress recently with new
emerging efficient algorithms, yet it is underexplored in the Federated
Learning setting. It is unclear how the challenges of Federated Learning affect
the convergence of bilevel algorithms. In this work, we study Federated Bilevel
Optimization problems. We first propose the FedBiO algorithm that solves the
hyper-gradient estimation problem efficiently, then we propose FedBiOAcc to
accelerate FedBiO. FedBiO has communication complexity $O(\epsilon^{-1.5})$
with linear speed up, while FedBiOAcc achieves communication complexity
$O(\epsilon^{-1})$, sample complexity $O(\epsilon^{-1.5})$ and also the linear
speed up. We also study Federated Bilevel Optimization problems with local
lower level problems, and prove that FedBiO and FedBiOAcc converges at the same
rate with some modification.
</p></li>
</ul>

<h3>Title: EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data. (arXiv:2302.07155v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07155">http://arxiv.org/abs/2302.07155</a></li>
<li>Code URL: <a href="https://github.com/mingruiliu-ml-lab/episode">https://github.com/mingruiliu-ml-lab/episode</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07155] EPISODE: Episodic Gradient Clipping with Periodic Resampled Corrections for Federated Learning with Heterogeneous Data](http://arxiv.org/abs/2302.07155) #federate</code></li>
<li>Summary: <p>Gradient clipping is an important technique for deep neural networks with
exploding gradients, such as recurrent neural networks. Recent studies have
shown that the loss functions of these networks do not satisfy the conventional
smoothness condition, but instead satisfy a relaxed smoothness condition, i.e.,
the Lipschitz constant of the gradient scales linearly in terms of the gradient
norm. Due to this observation, several gradient clipping algorithms have been
developed for nonconvex and relaxed-smooth functions. However, the existing
algorithms only apply to the single-machine or multiple-machine setting with
homogeneous data across machines. It remains unclear how to design provably
efficient gradient clipping algorithms in the general Federated Learning (FL)
setting with heterogeneous data and limited communication rounds. In this
paper, we design EPISODE, the very first algorithm to solve FL problems with
heterogeneous data in the nonconvex and relaxed smoothness setting. The key
ingredients of the algorithm are two new techniques called \textit{episodic
gradient clipping} and \textit{periodic resampled corrections}. At the
beginning of each round, EPISODE resamples stochastic gradients from each
client and obtains the global averaged gradient, which is used to (1) determine
whether to apply gradient clipping for the entire round and (2) construct local
gradient corrections for each client. Notably, our algorithm and analysis
provide a unified framework for both homogeneous and heterogeneous data under
any noise level of the stochastic gradient, and it achieves state-of-the-art
complexity results. In particular, we prove that EPISODE can achieve linear
speedup in the number of machines, and it requires significantly fewer
communication rounds. Experiments on several heterogeneous datasets show the
superior performance of EPISODE over several strong baselines in FL.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Characterizing notions of omniprediction via multicalibration. (arXiv:2302.06726v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06726">http://arxiv.org/abs/2302.06726</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06726] Characterizing notions of omniprediction via multicalibration](http://arxiv.org/abs/2302.06726) #fair</code></li>
<li>Summary: <p>A recent line of work shows that notions of multigroup fairness imply
surprisingly strong notions of omniprediction: loss minimization guarantees
that apply not just for a specific loss function, but for any loss belonging to
a large family of losses. While prior work has derived various notions of
omniprediction from multigroup fairness guarantees of varying strength, it was
unknown whether the connection goes in both directions.
</p></li>
</ul>

<p>In this work, we answer this question in the affirmative, establishing
equivalences between notions of multicalibration and omniprediction. The new
definitions that hold the key to this equivalence are new notions of swap
omniprediction, which are inspired by swap regret in online learning. We show
that these can be characterized exactly by a strengthening of multicalibration
that we refer to as swap multicalibration. One can go from standard to swap
multicalibration by a simple discretization; moreover all known algorithms for
standard multicalibration in fact give swap multicalibration. In the context of
omniprediction though, introducing the notion of swapping results in provably
stronger notions, which require a predictor to minimize expected loss at least
as well as an adaptive adversary who can choose both the loss function and
hypothesis based on the value predicted by the predictor.
</p>
<p>Building on these characterizations, we paint a complete picture of the
relationship between the various omniprediction notions in the literature by
establishing implications and separations between them. Our work deepens our
understanding of the connections between multigroup fairness, loss minimization
and outcome indistinguishability and establishes new connections to classic
notions in online learning.
</p>

<h3>Title: Provable Detection of Propagating Sampling Bias in Prediction Models. (arXiv:2302.06752v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06752">http://arxiv.org/abs/2302.06752</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06752] Provable Detection of Propagating Sampling Bias in Prediction Models](http://arxiv.org/abs/2302.06752) #fair</code></li>
<li>Summary: <p>With an increased focus on incorporating fairness in machine learning models,
it becomes imperative not only to assess and mitigate bias at each stage of the
machine learning pipeline but also to understand the downstream impacts of bias
across stages. Here we consider a general, but realistic, scenario in which a
predictive model is learned from (potentially biased) training data, and model
predictions are assessed post-hoc for fairness by some auditing method. We
provide a theoretical analysis of how a specific form of data bias,
differential sampling bias, propagates from the data stage to the prediction
stage. Unlike prior work, we evaluate the downstream impacts of data biases
quantitatively rather than qualitatively and prove theoretical guarantees for
detection. Under reasonable assumptions, we quantify how the amount of bias in
the model predictions varies as a function of the amount of differential
sampling bias in the data, and at what point this bias becomes provably
detectable by the auditor. Through experiments on two criminal justice datasets
-- the well-known COMPAS dataset and historical data from NYPD's stop and frisk
policy -- we demonstrate that the theoretical results hold in practice even
when our assumptions are relaxed.
</p></li>
</ul>

<h3>Title: When Mitigating Bias is Unfair: A Comprehensive Study on the Impact of Bias Mitigation Algorithms. (arXiv:2302.07185v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07185">http://arxiv.org/abs/2302.07185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07185] When Mitigating Bias is Unfair: A Comprehensive Study on the Impact of Bias Mitigation Algorithms](http://arxiv.org/abs/2302.07185) #fair</code></li>
<li>Summary: <p>Most works on the fairness of machine learning systems focus on the blind
optimization of common fairness metrics, such as Demographic Parity and
Equalized Odds. In this paper, we conduct a comparative study of several bias
mitigation approaches to investigate their behaviors at a fine grain, the
prediction level. Our objective is to characterize the differences between fair
models obtained with different approaches. With comparable performances in
fairness and accuracy, are the different bias mitigation approaches impacting a
similar number of individuals? Do they mitigate bias in a similar way? Do they
affect the same individuals when debiasing a model? Our findings show that bias
mitigation approaches differ a lot in their strategies, both in the number of
impacted individuals and the populations targeted. More surprisingly, we show
these results even apply for several runs of the same mitigation approach.
These findings raise questions about the limitations of the current group
fairness metrics, as well as the arbitrariness, hence unfairness, of the whole
debiasing process.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations. (arXiv:2302.06885v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06885">http://arxiv.org/abs/2302.06885</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06885] Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations](http://arxiv.org/abs/2302.06885) #interpretability</code></li>
<li>Summary: <p>Knowledge tracing (KT) is a crucial technique to predict students' future
performance by observing their historical learning processes. Due to the
powerful representation ability of deep neural networks, remarkable progress
has been made by using deep learning techniques to solve the KT problem. The
majority of existing approaches rely on the \emph{homogeneous question}
assumption that questions have equivalent contributions if they share the same
set of knowledge components. Unfortunately, this assumption is inaccurate in
real-world educational scenarios. Furthermore, it is very challenging to
interpret the prediction results from the existing deep learning based KT
models. Therefore, in this paper, we present QIKT, a question-centric
interpretable KT model to address the above challenges. The proposed QIKT
approach explicitly models students' knowledge state variations at a
fine-grained level with question-sensitive cognitive representations that are
jointly learned from a question-centric knowledge acquisition module and a
question-centric problem solving module. Meanwhile, the QIKT utilizes an item
response theory based prediction layer to generate interpretable prediction
results. The proposed QIKT model is evaluated on three public real-world
educational datasets. The results demonstrate that our approach is superior on
the KT prediction task, and it outperforms a wide range of deep learning based
KT models in terms of prediction accuracy with better model interpretability.
To encourage reproducible results, we have provided all the datasets and code
at \url{https://pykt.org/}.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Towards Explainable Visual Anomaly Detection. (arXiv:2302.06670v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06670">http://arxiv.org/abs/2302.06670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06670] Towards Explainable Visual Anomaly Detection](http://arxiv.org/abs/2302.06670) #explainability</code></li>
<li>Summary: <p>Anomaly detection and localization of visual data, including images and
videos, are of great significance in both machine learning academia and applied
real-world scenarios. Despite the rapid development of visual anomaly detection
techniques in recent years, the interpretations of these black-box models and
reasonable explanations of why anomalies can be distinguished out are scarce.
This paper provides the first survey concentrated on explainable visual anomaly
detection methods. We first introduce the basic background of image-level
anomaly detection and video-level anomaly detection, followed by the current
explainable approaches for visual anomaly detection. Then, as the main content
of this survey, a comprehensive and exhaustive literature review of explainable
anomaly detection methods for both images and videos is presented. Finally, we
discuss several promising future directions and open problems to explore on the
explainability of visual anomaly detection.
</p></li>
</ul>

<h3>Title: The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus. (arXiv:2302.07265v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07265">http://arxiv.org/abs/2302.07265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07265] The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus](http://arxiv.org/abs/2302.07265) #explainability</code></li>
<li>Summary: <p>Explainable AI (XAI) is a rapidly evolving field that aims to improve
transparency and trustworthiness of AI systems to humans. One of the unsolved
challenges in XAI is estimating the performance of these explanation methods
for neural networks, which has resulted in numerous competing metrics with
little to no indication of which one is to be preferred. In this paper, to
identify the most reliable evaluation method in a given explainability context,
we propose MetaQuantus -- a simple yet powerful framework that meta-evaluates
two complementary performance characteristics of an evaluation method: its
resilience to noise and reactivity to randomness. We demonstrate the
effectiveness of our framework through a series of experiments, targeting
various open questions in XAI, such as the selection of explanation methods and
optimisation of hyperparameters of a given metric. We release our work under an
open-source license to serve as a development tool for XAI researchers and
Machine Learning (ML) practitioners to verify and benchmark newly constructed
metrics (i.e., ``estimators'' of explanation quality). With this work, we
provide clear and theoretically-grounded guidance for building reliable
evaluation methods, thus facilitating standardisation and reproducibility in
the field of XAI.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Symbolic Discovery of Optimization Algorithms. (arXiv:2302.06675v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06675">http://arxiv.org/abs/2302.06675</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06675] Symbolic Discovery of Optimization Algorithms](http://arxiv.org/abs/2302.06675) #diffusion</code></li>
<li>Summary: <p>We present a method to formulate algorithm discovery as program search, and
apply it to discover optimization algorithms for deep neural network training.
We leverage efficient search techniques to explore an infinite and sparse
program space. To bridge the large generalization gap between proxy and target
tasks, we also introduce program selection and simplification strategies. Our
method discovers a simple and effective optimization algorithm, $\textbf{Lion}$
($\textit{Evo$\textbf{L}$ved S$\textbf{i}$gn M$\textbf{o}$me$\textbf{n}$tum}$).
It is more memory-efficient than Adam as it only keeps track of the momentum.
Different from adaptive optimizers, its update has the same magnitude for each
parameter calculated through the sign operation. We compare Lion with widely
used optimizers, such as Adam and Adafactor, for training a variety of models
on different tasks. On image classification, Lion boosts the accuracy of ViT by
up to 2% on ImageNet and saves up to 5x the pre-training compute on JFT. On
vision-language contrastive learning, we achieve 88.3% $\textit{zero-shot}$ and
91.1% $\textit{fine-tuning}$ accuracy on ImageNet, surpassing the previous best
results by 2% and 0.1%, respectively. On diffusion models, Lion outperforms
Adam by achieving a better FID score and reducing the training compute by up to
2.3x. For autoregressive, masked language modeling, and fine-tuning, Lion
exhibits a similar or better performance compared to Adam. Our analysis of Lion
reveals that its performance gain grows with the training batch size. It also
requires a smaller learning rate than Adam due to the larger norm of the update
produced by the sign function. Additionally, we examine the limitations of Lion
and identify scenarios where its improvements are small or not statistically
significant. The implementation of Lion is publicly available.
</p></li>
</ul>

<h3>Title: DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models. (arXiv:2302.06826v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06826">http://arxiv.org/abs/2302.06826</a></li>
<li>Code URL: <a href="https://github.com/rem105-210/difffashion">https://github.com/rem105-210/difffashion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06826] DiffFashion: Reference-based Fashion Design with Structure-aware Transfer by Diffusion Models](http://arxiv.org/abs/2302.06826) #diffusion</code></li>
<li>Summary: <p>Image-based fashion design with AI techniques has attracted increasing
attention in recent years. We focus on a new fashion design task, where we aim
to transfer a reference appearance image onto a clothing image while preserving
the structure of the clothing image. It is a challenging task since there are
no reference images available for the newly designed output fashion images.
Although diffusion-based image translation or neural style transfer (NST) has
enabled flexible style transfer, it is often difficult to maintain the original
structure of the image realistically during the reverse diffusion, especially
when the referenced appearance image greatly differs from the common clothing
appearance. To tackle this issue, we present a novel diffusion model-based
unsupervised structure-aware transfer method to semantically generate new
clothes from a given clothing image and a reference appearance image. In
specific, we decouple the foreground clothing with automatically generated
semantic masks by conditioned labels. And the mask is further used as guidance
in the denoising process to preserve the structure information. Moreover, we
use the pre-trained vision Transformer (ViT) for both appearance and structure
guidance. Our experimental results show that the proposed method outperforms
state-of-the-art baseline models, generating more realistic images in the
fashion design task. Code and demo can be found at
https://github.com/Rem105-210/DiffFashion.
</p></li>
</ul>

<h3>Title: Text-Guided Scene Sketch-to-Photo Synthesis. (arXiv:2302.06883v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06883">http://arxiv.org/abs/2302.06883</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06883] Text-Guided Scene Sketch-to-Photo Synthesis](http://arxiv.org/abs/2302.06883) #diffusion</code></li>
<li>Summary: <p>We propose a method for scene-level sketch-to-photo synthesis with text
guidance. Although object-level sketch-to-photo synthesis has been widely
studied, whole-scene synthesis is still challenging without reference photos
that adequately reflect the target style. To this end, we leverage knowledge
from recent large-scale pre-trained generative models, resulting in text-guided
sketch-to-photo synthesis without the need for reference images. To train our
model, we use self-supervised learning from a set of photographs. Specifically,
we use a pre-trained edge detector that maps both color and sketch images into
a standardized edge domain, which reduces the gap between photograph-based edge
images (during training) and hand-drawn sketch images (during inference). We
implement our method by fine-tuning a latent diffusion model (i.e., Stable
Diffusion) with sketch and text conditions. Experiments show that the proposed
method translates original sketch images that are not extracted from color
images into photos with compelling visual quality.
</p></li>
</ul>

<h3>Title: DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided Latent Diffusion Model. (arXiv:2302.06908v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.06908">http://arxiv.org/abs/2302.06908</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.06908] DiffFaceSketch: High-Fidelity Face Image Synthesis with Sketch-Guided Latent Diffusion Model](http://arxiv.org/abs/2302.06908) #diffusion</code></li>
<li>Summary: <p>Synthesizing face images from monochrome sketches is one of the most
fundamental tasks in the field of image-to-image translation. However, it is
still challenging to (1)~make models learn the high-dimensional face features
such as geometry and color, and (2)~take into account the characteristics of
input sketches. Existing methods often use sketches as indirect inputs (or as
auxiliary inputs) to guide the models, resulting in the loss of sketch features
or the alteration of geometry information. In this paper, we introduce a
Sketch-Guided Latent Diffusion Model (SGLDM), an LDM-based network architect
trained on the paired sketch-face dataset. We apply a Multi-Auto-Encoder (AE)
to encode the different input sketches from different regions of a face from
pixel space to a feature map in latent space, which enables us to reduce the
dimension of the sketch input while preserving the geometry-related information
of local face details. We build a sketch-face paired dataset based on the
existing method that extracts the edge map from an image. We then introduce a
Stochastic Region Abstraction (SRA), an approach to augment our dataset to
improve the robustness of SGLDM to handle sketch input with arbitrary
abstraction. The evaluation study shows that SGLDM can synthesize high-quality
face images with different expressions, facial accessories, and hairstyles from
various sketches with different abstraction levels.
</p></li>
</ul>

<h3>Title: Universal Guidance for Diffusion Models. (arXiv:2302.07121v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07121">http://arxiv.org/abs/2302.07121</a></li>
<li>Code URL: <a href="https://github.com/arpitbansal297/universal-guided-diffusion">https://github.com/arpitbansal297/universal-guided-diffusion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07121] Universal Guidance for Diffusion Models](http://arxiv.org/abs/2302.07121) #diffusion</code></li>
<li>Summary: <p>Typical diffusion models are trained to accept a particular form of
conditioning, most commonly text, and cannot be conditioned on other modalities
without retraining. In this work, we propose a universal guidance algorithm
that enables diffusion models to be controlled by arbitrary guidance modalities
without the need to retrain any use-specific components. We show that our
algorithm successfully generates quality images with guidance functions
including segmentation, face recognition, object detection, and classifier
signals. Code is available at
https://github.com/arpitbansal297/Universal-Guided-Diffusion.
</p></li>
</ul>

<h3>Title: Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data. (arXiv:2302.07194v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07194">http://arxiv.org/abs/2302.07194</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07194] Score Approximation, Estimation and Distribution Recovery of Diffusion Models on Low-Dimensional Data](http://arxiv.org/abs/2302.07194) #diffusion</code></li>
<li>Summary: <p>Diffusion models achieve state-of-the-art performance in various generation
tasks. However, their theoretical foundations fall far behind. This paper
studies score approximation, estimation, and distribution recovery of diffusion
models, when data are supported on an unknown low-dimensional linear subspace.
Our result provides sample complexity bounds for distribution estimation using
diffusion models. We show that with a properly chosen neural network
architecture, the score function can be both accurately approximated and
efficiently estimated. Furthermore, the generated distribution based on the
estimated score function captures the data geometric structures and converges
to a close vicinity of the data distribution. The convergence rate depends on
the subspace dimension, indicating that diffusion models can circumvent the
curse of data ambient dimensionality.
</p></li>
</ul>

<h3>Title: Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions. (arXiv:2302.07261v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2302.07261">http://arxiv.org/abs/2302.07261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2302.07261] Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions](http://arxiv.org/abs/2302.07261) #diffusion</code></li>
<li>Summary: <p>Diffusion-based generative models (DBGMs) perturb data to a target noise
distribution and reverse this inference diffusion process to generate samples.
The choice of inference diffusion affects both likelihoods and sample quality.
For example, extending the inference process with auxiliary variables leads to
improved sample quality. While there are many such multivariate diffusions to
explore, each new one requires significant model-specific analysis, hindering
rapid prototyping and evaluation. In this work, we study Multivariate Diffusion
Models (MDMs). For any number of auxiliary variables, we provide a recipe for
maximizing a lower-bound on the MDMs likelihood without requiring any
model-specific analysis. We then demonstrate how to parameterize the diffusion
for a specified target noise distribution; these two points together enable
optimizing the inference diffusion process. Optimizing the diffusion expands
easy experimentation from just a few well-known processes to an automatic
search over all linear diffusions. To demonstrate these ideas, we introduce two
new specific diffusions as well as learn a diffusion process on the MNIST,
CIFAR10, and ImageNet32 datasets. We show learned MDMs match or surpass
bits-per-dims (BPDs) relative to fixed choices of diffusions for a given
dataset and model architecture.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
