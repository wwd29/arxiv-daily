<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Another Round of Breaking and Making Quantum Money: How to Not Build It from Lattices, and More. (arXiv:2211.11994v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11994">http://arxiv.org/abs/2211.11994</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11994] Another Round of Breaking and Making Quantum Money: How to Not Build It from Lattices, and More](http://arxiv.org/abs/2211.11994)</code></li>
<li>Summary: <p>Public verification of quantum money has been one of the central objects in
quantum cryptography ever since Wiesner's pioneering idea of using quantum
mechanics to construct banknotes against counterfeiting. So far, we do not know
any publicly-verifiable quantum money scheme that is provably secure from
standard assumptions.
</p></li>
</ul>

<p>In this work, we provide both negative and positive results for publicly
verifiable quantum money.
</p>
<p>**In the first part, we give a general theorem, showing that a certain
natural class of quantum money schemes from lattices cannot be secure. We use
this theorem to break the recent quantum money scheme of Khesin, Lu, and Shor.
</p>
<p>**In the second part, we propose a framework for building quantum money and
quantum lightning we call invariant money which abstracts some of the ideas of
quantum money from knots by Farhi et al.(ITCS'12). In addition to formalizing
this framework, we provide concrete hard computational problems loosely
inspired by classical knowledge-of-exponent assumptions, whose hardness would
imply the security of quantum lightning, a strengthening of quantum money where
not even the bank can duplicate banknotes.
</p>
<p>**We discuss potential instantiations of our framework, including an oracle
construction using cryptographic group actions and instantiations from
rerandomizable functional encryption, isogenies over elliptic curves, and
knots.
</p>

<h3>Title: Modeling Resources in Permissionless Longest-chain Total-order Broadcast. (arXiv:2211.12050v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12050">http://arxiv.org/abs/2211.12050</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12050] Modeling Resources in Permissionless Longest-chain Total-order Broadcast](http://arxiv.org/abs/2211.12050)</code></li>
<li>Summary: <p>Blockchain protocols implement total-order broadcast in a permissionless
setting, where processes can freely join and leave. In such a setting, to
safeguard against Sybil attacks, correct processes rely on cryptographic proofs
tied to a particular type of resource to make them eligible to order
transactions. For example, in the case of Proof-of-Work (PoW), this resource is
computation, and the proof is a solution to a computationally hard puzzle.
Conversely, in Proof-of-Stake (PoS), the resource corresponds to the number of
coins that every process in the system owns, and a secure lottery selects a
process for participation proportionally to its coin holdings.
</p></li>
</ul>

<p>Although many resource-based blockchain protocols are formally proven secure
in the literature, the existing security proofs fail to demonstrate why
particular types of resources cause the blockchain protocols to be vulnerable
to distinct classes of attacks. For instance, PoS systems are more vulnerable
to long-range attacks, where an adversary corrupts past processes to re-write
the history, than Proof-of-Work and Proof-of-Storage systems.
Proof-of-Storage-based and Proof-of-Stake-based protocols are both more
susceptible to private double-spending attacks than Proof-of-Work-based
protocols; in this case, an adversary mines its chain in secret without sharing
its blocks with the rest of the processes until the end of the attack.
</p>
<p>In this paper, we formally characterize the properties of resources through
an abstraction called resource allocator and give a framework for understanding
longest-chain consensus protocols based on different underlying resources. In
addition, we use this resource allocator to demonstrate security trade-offs
between various resources focusing on well-known attacks (e.g., the long-range
attack and nothing-at-stake attacks).
</p>

<h2>security</h2>
<h3>Title: Analysis of the DoIP Protocol for Security Vulnerabilities. (arXiv:2211.12177v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12177">http://arxiv.org/abs/2211.12177</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12177] Analysis of the DoIP Protocol for Security Vulnerabilities](http://arxiv.org/abs/2211.12177)</code></li>
<li>Summary: <p>DoIP, which is defined in ISO 13400, is a transport protocol stack for
diagnostic data. Diagnostic data is a potential attack vector at vehicles, so
secure transmission must be guaranteed to protect sensitive data and the
vehicle. Previous work analyzed a draft version and earlier versions of the
DoIP protocol without Transport Layer Security (TLS). No formal analysis exists
for the DoIP protocol. The goal of this work is to investigate the DoIP
protocol for design flaws that may lead to security vulnerabilities and
possible attacks to exploit them. For this purpose, we deductively analyze the
DoIP protocol in a first step and subsequently confirm our conclusions
formally. For the formal analysis, we use the prover Tamarin. Based on the
results, we propose countermeasures to improve the DoIP's security.We showthat
the DoIP protocol cannot be considered secure mainly because the security
mechanisms TLS and client authentication in the DoIP protocol are not
mandatory. We propose measures to mitigate the vulnerabilities thatwe confirm
to remain after activating TLS. These require only a minor redesign of the
protocol.
</p></li>
</ul>

<h3>Title: The Security Protocol Verifier ProVerif and its Horn Clause Resolution Algorithm. (arXiv:2211.12227v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12227">http://arxiv.org/abs/2211.12227</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12227] The Security Protocol Verifier ProVerif and its Horn Clause Resolution Algorithm](http://arxiv.org/abs/2211.12227)</code></li>
<li>Summary: <p>ProVerif is a widely used security protocol verifier. Internally, ProVerif
uses an abstract representation of the protocol by Horn clauses and a
resolution algorithm on these clauses, in order to prove security properties of
the protocol or to find attacks. In this paper, we present an overview of
ProVerif and discuss some specificities of its resolution algorithm, related to
the particular application domain and the particular clauses that ProVerif
generates. This paper is a short summary that gives pointers to publications on
ProVerif in which the reader will find more details.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level Unlabeled Scenes. (arXiv:2211.11950v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11950">http://arxiv.org/abs/2211.11950</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11950] UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level Unlabeled Scenes](http://arxiv.org/abs/2211.11950)</code></li>
<li>Summary: <p>Semi-supervised Learning (SSL) has received increasing attention in
autonomous driving to relieve enormous burden for 3D annotation. In this paper,
we propose UpCycling, a novel SSL framework for 3D object detection with zero
additional raw-level point cloud: learning from unlabeled de-identified
intermediate features (i.e., smashed data) for privacy preservation. The
intermediate features do not require additional computation on autonomous
vehicles since they are naturally produced by the inference pipeline. However,
augmenting 3D scenes at a feature level turns out to be a critical issue:
applying the augmentation methods in the latest semi-supervised 3D object
detectors distorts intermediate features, which causes the pseudo-labels to
suffer from significant noise. To solve the distortion problem while achieving
highly effective SSL, we introduce hybrid pseudo labels, feature-level Ground
Truth sampling (F-GT) and Rotation (F-RoT), which safely augment unlabeled
multi-type 3D scene features and provide high-quality supervision. We implement
UpCycling on two representative 3D object detection models, SECOND-IoU and
PV-RCNN, and perform experiments on widely-used datasets (Waymo, KITTI, and
Lyft). While preserving privacy with zero raw-point scene, UpCycling
significantly outperforms the state-of-the-art SSL methods that utilize
raw-point scenes, in both domain adaptation and partial-label scenarios.
</p></li>
</ul>

<h3>Title: GDPR Compliant Collection of Therapist-Patient-Dialogues. (arXiv:2211.12360v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12360">http://arxiv.org/abs/2211.12360</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12360] GDPR Compliant Collection of Therapist-Patient-Dialogues](http://arxiv.org/abs/2211.12360)</code></li>
<li>Summary: <p>According to the Global Burden of Disease list provided by the World Health
Organization (WHO), mental disorders are among the most debilitating
disorders.To improve the diagnosis and the therapy effectiveness in recent
years, researchers have tried to identify individual biomarkers. Gathering
neurobiological data however, is costly and time-consuming. Another potential
source of information, which is already part of the clinical routine, are
therapist-patient dialogues. While there are some pioneering works
investigating the role of language as predictors for various therapeutic
parameters, for example patient-therapist alliance, there are no large-scale
studies. A major obstacle to conduct these studies is the availability of
sizeable datasets, which are needed to train machine learning models. While
these conversations are part of the daily routine of clinicians, gathering them
is usually hindered by various ethical (purpose of data usage), legal (data
privacy) and technical (data formatting) limitations. Some of these limitations
are particular to the domain of therapy dialogues, like the increased
difficulty in anonymisation, or the transcription of the recordings. In this
paper, we elaborate on the challenges we faced in starting our collection of
therapist-patient dialogues in a psychiatry clinic under the General Data
Privacy Regulation of the European Union with the goal to use the data for
Natural Language Processing (NLP) research. We give an overview of each step in
our procedure and point out the potential pitfalls to motivate further research
in this field.
</p></li>
</ul>

<h3>Title: Private Ad Modeling with DP-SGD. (arXiv:2211.11896v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11896">http://arxiv.org/abs/2211.11896</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11896] Private Ad Modeling with DP-SGD](http://arxiv.org/abs/2211.11896)</code></li>
<li>Summary: <p>A well-known algorithm in privacy-preserving ML is differentially private
stochastic gradient descent (DP-SGD). While this algorithm has been evaluated
on text and image data, it has not been previously applied to ads data, which
are notorious for their high class imbalance and sparse gradient updates. In
this work we apply DP-SGD to several ad modeling tasks including predicting
click-through rates, conversion rates, and number of conversion events, and
evaluate their privacy-utility trade-off on real-world datasets. Our work is
the first to empirically demonstrate that DP-SGD can provide both privacy and
utility for ad modeling tasks.
</p></li>
</ul>

<h3>Title: Generalized Private Selection and Testing with High Confidence. (arXiv:2211.12063v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12063">http://arxiv.org/abs/2211.12063</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12063] Generalized Private Selection and Testing with High Confidence](http://arxiv.org/abs/2211.12063)</code></li>
<li>Summary: <p>Composition theorems are general and powerful tools that facilitate privacy
accounting across multiple data accesses from per-access privacy bounds.
However they often result in weaker bounds compared with end-to-end analysis.
Two popular tools that mitigate that are the exponential mechanism (or report
noisy max) and the sparse vector technique, generalized in a recent private
selection framework by Liu and Talwar (STOC 2019). In this work, we propose a
flexible framework of private selection and testing that generalizes the one
proposed by Liu and Talwar, supporting a wide range of applications. We apply
our framework to solve several fundamental tasks, including query releasing,
top-$k$ selection, and stable selection, with improved confidence-accuracy
tradeoffs. Additionally, for online settings, we apply our private testing to
design a mechanism for adaptive query releasing, which improves the sample
complexity dependence on the confidence parameter for the celebrated private
multiplicative weights algorithm of Hardt and Rothblum (FOCS 2010).
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors. (arXiv:2211.12005v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12005">http://arxiv.org/abs/2211.12005</a></li>
<li>Code URL: <a href="https://github.com/sizhe-chen/sep">https://github.com/sizhe-chen/sep</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12005] Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors](http://arxiv.org/abs/2211.12005)</code></li>
<li>Summary: <p>As data become increasingly vital for deep learning, a company would be very
cautious about releasing data, because the competitors could use the released
data to train high-performance models, thereby posing a tremendous threat to
the company's commercial competence. To prevent training good models on the
data, imperceptible perturbations could be added to it. Since such
perturbations aim at hurting the entire training process, they should reflect
the vulnerability of DNN training, rather than that of a single model. Based on
this new idea, we seek adversarial examples that are always unrecognized (never
correctly classified) in training. In this paper, we uncover them by modeling
checkpoints' gradients, forming the proposed self-ensemble protection (SEP),
which is very effective because (1) learning on examples ignored during normal
training tends to yield DNNs ignoring normal examples; (2) checkpoints'
cross-model gradients are close to orthogonal, meaning that they are as diverse
as DNNs with different architectures in conventional ensemble. That is, our
amazing performance of ensemble only requires the computation of training one
model. By extensive experiments with 9 baselines on 3 datasets and 5
architectures, SEP is verified to be a new state-of-the-art, e.g., our small
$\ell_\infty=2/255$ perturbations reduce the accuracy of a CIFAR-10 ResNet18
from 94.56\% to 14.68\%, compared to 41.35\% by the best-known method.Code is
available at https://github.com/Sizhe-Chen/SEP.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: A Survey on Backdoor Attack and Defense in Natural Language Processing. (arXiv:2211.11958v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11958">http://arxiv.org/abs/2211.11958</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11958] A Survey on Backdoor Attack and Defense in Natural Language Processing](http://arxiv.org/abs/2211.11958)</code></li>
<li>Summary: <p>Deep learning is becoming increasingly popular in real-life applications,
especially in natural language processing (NLP). Users often choose training
outsourcing or adopt third-party data and models due to data and computation
resources being limited. In such a situation, training data and models are
exposed to the public. As a result, attackers can manipulate the training
process to inject some triggers into the model, which is called backdoor
attack. Backdoor attack is quite stealthy and difficult to be detected because
it has little inferior influence on the model's performance for the clean
samples. To get a precise grasp and understanding of this problem, in this
paper, we conduct a comprehensive review of backdoor attacks and defenses in
the field of NLP. Besides, we summarize benchmark datasets and point out the
open issues to design credible systems to defend against backdoor attacks.
</p></li>
</ul>

<h3>Title: Backdoor Cleansing with Unlabeled Data. (arXiv:2211.12044v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12044">http://arxiv.org/abs/2211.12044</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12044] Backdoor Cleansing with Unlabeled Data](http://arxiv.org/abs/2211.12044)</code></li>
<li>Summary: <p>Due to the increasing computational demand of Deep Neural Networks (DNNs),
companies and organizations have begun to outsource the training process.
However, the externally trained DNNs can potentially be backdoor attacked. It
is crucial to defend against such attacks, i.e., to postprocess a suspicious
model so that its backdoor behavior is mitigated while its normal prediction
power on clean inputs remain uncompromised. To remove the abnormal backdoor
behavior, existing methods mostly rely on additional labeled clean samples.
However, such requirement may be unrealistic as the training data are often
unavailable to end users. In this paper, we investigate the possibility of
circumventing such barrier. We propose a novel defense method that does not
require training labels. Through a carefully designed layer-wise weight
re-initialization and knowledge distillation, our method can effectively
cleanse backdoor behaviors of a suspicious network {with negligible compromise
in} its normal behavior. In experiments, we show that our method, trained
without labels, is on-par with state-of-the-art defense methods trained using
labels. We also observe promising defense results even on out-of-distribution
data. This makes our method very practical.
</p></li>
</ul>

<h3>Title: SoK: Inference Attacks and Defenses in Human-Centered Wireless Sensing. (arXiv:2211.12087v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12087">http://arxiv.org/abs/2211.12087</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12087] SoK: Inference Attacks and Defenses in Human-Centered Wireless Sensing](http://arxiv.org/abs/2211.12087)</code></li>
<li>Summary: <p>Human-centered wireless sensing aims to understand the fine-grained
environment and activities of a human using the diverse wireless signals around
her. The wireless sensing community has demonstrated the superiority of such
techniques in many applications such as smart homes, human-computer
interactions, and smart cities. Like many other technologies, wireless sensing
is also a double-edged sword. While the sensed information about a human can be
used for many good purposes such as enhancing life quality, an adversary can
also abuse it to steal private information about the human (e.g., location,
living habits, and behavioral biometric characteristics). However, the
literature lacks a systematic understanding of the privacy vulnerabilities of
wireless sensing and the defenses against them.
</p></li>
</ul>

<p>In this work, we aim to bridge this gap. First, we propose a framework to
systematize wireless sensing-based inference attacks. Our framework consists of
three key steps: deploying a sniffing device, sniffing wireless signals, and
inferring private information. Our framework can be used to guide the design of
new inference attacks since different attacks can instantiate these three steps
differently. Second, we propose a defense-in-depth framework to systematize
defenses against such inference attacks. The prevention component of our
framework aims to prevent inference attacks via obfuscating the wireless
signals around a human, while the detection component aims to detect and
respond to attacks. Third, based on our attack and defense frameworks, we
identify gaps in the existing literature and discuss future research
directions.
</p>

<h2>attack</h2>
<h3>Title: Addressing Mistake Severity in Neural Networks with Semantic Knowledge. (arXiv:2211.11880v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11880">http://arxiv.org/abs/2211.11880</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11880] Addressing Mistake Severity in Neural Networks with Semantic Knowledge](http://arxiv.org/abs/2211.11880)</code></li>
<li>Summary: <p>Robustness in deep neural networks and machine learning algorithms in general
is an open research challenge. In particular, it is difficult to ensure
algorithmic performance is maintained on out-of-distribution inputs or
anomalous instances that cannot be anticipated at training time. Embodied
agents will be deployed in these conditions, and are likely to make incorrect
predictions. An agent will be viewed as untrustworthy unless it can maintain
its performance in dynamic environments. Most robust training techniques aim to
improve model accuracy on perturbed inputs; as an alternate form of robustness,
we aim to reduce the severity of mistakes made by neural networks in
challenging conditions. We leverage current adversarial training methods to
generate targeted adversarial attacks during the training process in order to
increase the semantic similarity between a model's predictions and true labels
of misclassified instances. Results demonstrate that our approach performs
better with respect to mistake severity compared to standard and adversarially
trained models. We also find an intriguing role that non-robust features play
with regards to semantic similarity.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: NEVIS'22: A Stream of 100 Tasks Sampled from 30 Years of Computer Vision Research. (arXiv:2211.11747v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11747">http://arxiv.org/abs/2211.11747</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11747] NEVIS'22: A Stream of 100 Tasks Sampled from 30 Years of Computer Vision Research](http://arxiv.org/abs/2211.11747)</code></li>
<li>Summary: <p>We introduce the Never Ending VIsual-classification Stream (NEVIS'22), a
benchmark consisting of a stream of over 100 visual classification tasks,
sorted chronologically and extracted from papers sampled uniformly from
computer vision proceedings spanning the last three decades. The resulting
stream reflects what the research community thought was meaningful at any point
in time. Despite being limited to classification, the resulting stream has a
rich diversity of tasks from OCR, to texture analysis, crowd counting, scene
recognition, and so forth. The diversity is also reflected in the wide range of
dataset sizes, spanning over four orders of magnitude. Overall, NEVIS'22 poses
an unprecedented challenge for current sequential learning approaches due to
the scale and diversity of tasks, yet with a low entry barrier as it is limited
to a single modality and each task is a classical supervised learning problem.
Moreover, we provide a reference implementation including strong baselines and
a simple evaluation protocol to compare methods in terms of their trade-off
between accuracy and compute. We hope that NEVIS'22 can be useful to
researchers working on continual learning, meta-learning, AutoML and more
generally sequential learning, and help these communities join forces towards
more robust and efficient models that efficiently adapt to a never ending
stream of data. Implementations have been made available at
https://github.com/deepmind/dm_nevis.
</p></li>
</ul>

<h3>Title: Teach-DETR: Better Training DETR with Teachers. (arXiv:2211.11953v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11953">http://arxiv.org/abs/2211.11953</a></li>
<li>Code URL: <a href="https://github.com/leonhlj/teach-detr">https://github.com/leonhlj/teach-detr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11953] Teach-DETR: Better Training DETR with Teachers](http://arxiv.org/abs/2211.11953)</code></li>
<li>Summary: <p>In this paper, we present a novel training scheme, namely Teach-DETR, to
learn better DETR-based detectors from versatile teacher detectors. We show
that the predicted boxes from teacher detectors are effective medium to
transfer knowledge of teacher detectors, which could be either RCNN-based or
DETR-based detectors, to train a more accurate and robust DETR model. This new
training scheme can easily incorporate the predicted boxes from multiple
teacher detectors, each of which provides parallel supervisions to the student
DETR. Our strategy introduces no additional parameters and adds negligible
computational cost to the original detector during training. During inference,
Teach-DETR brings zero additional overhead and maintains the merit of requiring
no non-maximum suppression. Extensive experiments show that our method leads to
consistent improvement for various DETR-based detectors. Specifically, we
improve the state-of-the-art detector DINO with Swin-Large backbone and
36-epoch training schedule, from 57.8% to 58.9% in terms of mean average
precision on MSCOCO 2017 validation set. Code will be available at
https://github.com/LeonHLJ/Teach-DETR.
</p></li>
</ul>

<h3>Title: Transformation-Equivariant 3D Object Detection for Autonomous Driving. (arXiv:2211.11962v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11962">http://arxiv.org/abs/2211.11962</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11962] Transformation-Equivariant 3D Object Detection for Autonomous Driving](http://arxiv.org/abs/2211.11962)</code></li>
<li>Summary: <p>3D object detection received increasing attention in autonomous driving
recently. Objects in 3D scenes are distributed with diverse orientations.
Ordinary detectors do not explicitly model the variations of rotation and
reflection transformations. Consequently, large networks and extensive data
augmentation are required for robust detection. Recent equivariant networks
explicitly model the transformation variations by applying shared networks on
multiple transformed point clouds, showing great potential in object geometry
modeling. However, it is difficult to apply such networks to 3D object
detection in autonomous driving due to its large computation cost and slow
reasoning speed. In this work, we present TED, an efficient
Transformation-Equivariant 3D Detector to overcome the computation cost and
speed issues. TED first applies a sparse convolution backbone to extract
multi-channel transformation-equivariant voxel features; and then aligns and
aggregates these equivariant features into lightweight and compact
representations for high-performance 3D object detection. On the highly
competitive KITTI 3D car detection leaderboard, TED ranked 1st among all
submissions with competitive efficiency.
</p></li>
</ul>

<h3>Title: Multimorbidity Content-Based Medical Image Retrieval Using Proxies. (arXiv:2211.12185v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12185">http://arxiv.org/abs/2211.12185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12185] Multimorbidity Content-Based Medical Image Retrieval Using Proxies](http://arxiv.org/abs/2211.12185)</code></li>
<li>Summary: <p>Content-based medical image retrieval is an important diagnostic tool that
improves the explainability of computer-aided diagnosis systems and provides
decision making support to healthcare professionals. Medical imaging data, such
as radiology images, are often multimorbidity; a single sample may have more
than one pathology present. As such, image retrieval systems for the medical
domain must be designed for the multi-label scenario. In this paper, we propose
a novel multi-label metric learning method that can be used for both
classification and content-based image retrieval. In this way, our model is
able to support diagnosis by predicting the presence of diseases and provide
evidence for these predictions by returning samples with similar pathological
content to the user. In practice, the retrieved images may also be accompanied
by pathology reports, further assisting in the diagnostic process. Our method
leverages proxy feature vectors, enabling the efficient learning of a robust
feature space in which the distance between feature vectors can be used as a
measure of the similarity of those samples. Unlike existing proxy-based
methods, training samples are able to assign to multiple proxies that span
multiple class labels. This multi-label proxy assignment results in a feature
space that encodes the complex relationships between diseases present in
medical imaging data. Our method outperforms state-of-the-art image retrieval
systems and a set of baseline approaches. We demonstrate the efficacy of our
approach to both classification and content-based image retrieval on two
multimorbidity radiology datasets.
</p></li>
</ul>

<h3>Title: Event Transformer+. A multi-purpose solution for efficient event data processing. (arXiv:2211.12222v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12222">http://arxiv.org/abs/2211.12222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12222] Event Transformer+](http://arxiv.org/abs/2211.12222)</code></li>
<li>Summary: <p>Event cameras record sparse illumination changes with high temporal
resolution and high dynamic range. Thanks to their sparse recording and low
consumption, they are increasingly used in applications such as AR/VR and
autonomous driving. Current top-performing methods often ignore specific
event-data properties, leading to the development of generic but
computationally expensive algorithms, while event-aware methods do not perform
as well. We propose Event Transformer+, that improves our seminal work evtprev
EvT with a refined patch-based event representation and a more robust backbone
to achieve more accurate results, while still benefiting from event-data
sparsity to increase its efficiency. Additionally, we show how our system can
work with different data modalities and propose specific output heads, for
event-stream predictions (i.e. action recognition) and per-pixel predictions
(dense depth estimation). Evaluation results show better performance to the
state-of-the-art while requiring minimal computation resources, both on GPU and
CPU.
</p></li>
</ul>

<h3>Title: PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models Against Adversarial Examples. (arXiv:2211.12294v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12294">http://arxiv.org/abs/2211.12294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12294] PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models Against Adversarial Examples](http://arxiv.org/abs/2211.12294)</code></li>
<li>Summary: <p>Point cloud completion, as the upstream procedure of 3D recognition and
segmentation, has become an essential part of many tasks such as navigation and
scene understanding. While various point cloud completion models have
demonstrated their powerful capabilities, their robustness against adversarial
attacks, which have been proven to be fatally malicious towards deep neural
networks, remains unknown. In addition, existing attack approaches towards
point cloud classifiers cannot be applied to the completion models due to
different output forms and attack purposes. In order to evaluate the robustness
of the completion models, we propose PointCA, the first adversarial attack
against 3D point cloud completion models. PointCA can generate adversarial
point clouds that maintain high similarity with the original ones, while being
completed as another object with totally different semantic information.
Specifically, we minimize the representation discrepancy between the
adversarial example and the target point set to jointly explore the adversarial
point clouds in the geometry space and the feature space. Furthermore, to
launch a stealthier attack, we innovatively employ the neighbourhood density
information to tailor the perturbation constraint, leading to geometry-aware
and distribution-adaptive modifications for each point. Extensive experiments
against different premier point cloud completion networks show that PointCA can
cause a performance degradation from 77.9% to 16.7%, with the structure chamfer
distance kept below 0.01. We conclude that existing completion models are
severely vulnerable to adversarial examples, and state-of-the-art defenses for
point cloud classification will be partially invalid when applied to incomplete
and uneven point cloud data.
</p></li>
</ul>

<h3>Title: Neural Dependencies Emerging from Learning Massive Categories. (arXiv:2211.12339v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12339">http://arxiv.org/abs/2211.12339</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12339] Neural Dependencies Emerging from Learning Massive Categories](http://arxiv.org/abs/2211.12339)</code></li>
<li>Summary: <p>This work presents two astonishing findings on neural networks learned for
large-scale image classification. 1) Given a well-trained model, the logits
predicted for some category can be directly obtained by linearly combining the
predictions of a few other categories, which we call \textbf{neural
dependency}. 2) Neural dependencies exist not only within a single model, but
even between two independently learned models, regardless of their
architectures. Towards a theoretical analysis of such phenomena, we demonstrate
that identifying neural dependencies is equivalent to solving the Covariance
Lasso (CovLasso) regression problem proposed in this paper. Through
investigating the properties of the problem solution, we confirm that neural
dependency is guaranteed by a redundant logit covariance matrix, which
condition is easily met given massive categories, and that neural dependency is
highly sparse, implying that one category correlates to only a few others. We
further empirically show the potential of neural dependencies in understanding
internal data correlations, generalizing models to unseen categories, and
improving model robustness with a dependency-derived regularizer. Code for this
work will be made publicly available.
</p></li>
</ul>

<h3>Title: U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with Unsupervised Threshold. (arXiv:2211.12353v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12353">http://arxiv.org/abs/2211.12353</a></li>
<li>Code URL: <a href="https://github.com/mtailanian/uflow">https://github.com/mtailanian/uflow</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12353] U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with Unsupervised Threshold](http://arxiv.org/abs/2211.12353)</code></li>
<li>Summary: <p>In this work we propose a non-contrastive method for anomaly detection and
segmentation in images, that benefits both from a modern machine learning
approach and a more classic statistical detection theory. The method consists
of three phases. First, features are extracted by making use of a multi-scale
image Transformer architecture. Then, these features are fed into a U-shaped
Normalizing Flow that lays the theoretical foundations for the last phase,
which computes a pixel-level anomaly map, and performs a segmentation based on
the a contrario framework. This multiple hypothesis testing strategy permits to
derive a robust automatic detection threshold, which is key in many real-world
applications, where an operational point is needed. The segmentation results
are evaluated using the Intersection over Union (IoU) metric, and for assessing
the generated anomaly maps we report the area under the Receiver Operating
Characteristic curve (ROC-AUC) at both image and pixel level. For both metrics,
the proposed approach produces state-of-the-art results, ranking first in most
MvTec-AD categories, with a mean pixel-level ROC- AUC of 98.74%. Code and
trained models are available at https://github.com/mtailanian/uflow.
</p></li>
</ul>

<h3>Title: LiCamGait: Gait Recognition in the Wild by Using LiDAR and Camera Multi-modal Visual Sensors. (arXiv:2211.12371v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12371">http://arxiv.org/abs/2211.12371</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12371] LiCamGait: Gait Recognition in the Wild by Using LiDAR and Camera Multi-modal Visual Sensors](http://arxiv.org/abs/2211.12371)</code></li>
<li>Summary: <p>LiDAR can capture accurate depth information in large-scale scenarios without
the effect of light conditions, and the captured point cloud contains
gait-related 3D geometric properties and dynamic motion characteristics. We
make the first attempt to leverage LiDAR to remedy the limitation of
view-dependent and light-sensitive camera for more robust and accurate gait
recognition. In this paper, we propose a LiDAR-camera-based gait recognition
method with an effective multi-modal feature fusion strategy, which fully
exploits advantages of both point clouds and images. In particular, we propose
a new in-the-wild gait dataset, LiCamGait, involving multi-modal visual data
and diverse 2D/3D representations. Our method achieves state-of-the-art
performance on the new dataset. Code and dataset will be released when this
paper is published.
</p></li>
</ul>

<h3>Title: Robust AUC Optimization under the Supervision of Clean Data. (arXiv:2211.11751v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11751">http://arxiv.org/abs/2211.11751</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11751] Robust AUC Optimization under the Supervision of Clean Data](http://arxiv.org/abs/2211.11751)</code></li>
<li>Summary: <p>AUC (area under the ROC curve) optimization algorithms have drawn much
attention due to the incredible adaptability for seriously imbalanced data.
Real-world datasets usually contain extensive noisy samples that seriously
hinder the model performance, but a limited number of clean samples can be
obtained easily. Although some AUC optimization studies make an effort to
dispose of noisy samples, they do not utilize such clean samples well. In this
paper, we propose a robust AUC optimization algorithm (RAUCO) with good use of
available clean samples. Expressly, our RAUCO algorithm can exclude noisy
samples from the training by employing the technology of self-paced learning
(SPL) under the supervision of clean samples. Moreover, considering the impact
of the data enhancement technology on SPL, we innovatively introduce the
consistency regularization term to SPL. Theoretical results on the convergence
of our RAUCO algorithm are provided under mild assumptions. Comprehensive
experiments demonstrate that our RAUCO algorithm holds better robustness than
existing algorithms.
</p></li>
</ul>

<h3>Title: Learnable Graph Convolutional Attention Networks. (arXiv:2211.11853v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11853">http://arxiv.org/abs/2211.11853</a></li>
<li>Code URL: <a href="https://github.com/psanch21/l-cat">https://github.com/psanch21/l-cat</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11853] Learnable Graph Convolutional Attention Networks](http://arxiv.org/abs/2211.11853)</code></li>
<li>Summary: <p>Existing Graph Neural Networks (GNNs) compute the message exchange between
nodes by either aggregating uniformly (convolving) the features of all the
neighboring nodes, or by applying a non-uniform score (attending) to the
features. Recent works have shown the strengths and weaknesses of the resulting
GNN architectures, respectively, GCNs and GATs. In this work, we aim at
exploiting the strengths of both approaches to their full extent. To this end,
we first introduce the graph convolutional attention layer (CAT), which relies
on convolutions to compute the attention scores. Unfortunately, as in the case
of GCNs and GATs, we show that there exists no clear winner between the three
(neither theoretically nor in practice) as their performance directly depends
on the nature of the data (i.e., of the graph and features). This result brings
us to the main contribution of our work, the learnable graph convolutional
attention network (L-CAT): a GNN architecture that automatically interpolates
between GCN, GAT and CAT in each layer, by adding only two scalar parameters.
Our results demonstrate that L-CAT is able to efficiently combine different GNN
layers along the network, outperforming competing methods in a wide range of
datasets, and resulting in a more robust model that reduces the need of
cross-validating.
</p></li>
</ul>

<h3>Title: COVID-Net Assistant: A Deep Learning-Driven Virtual Assistant for COVID-19 Symptom Prediction and Recommendation. (arXiv:2211.11944v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11944">http://arxiv.org/abs/2211.11944</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11944] COVID-Net Assistant: A Deep Learning-Driven Virtual Assistant for COVID-19 Symptom Prediction and Recommendation](http://arxiv.org/abs/2211.11944)</code></li>
<li>Summary: <p>As the COVID-19 pandemic continues to put a significant burden on healthcare
systems worldwide, there has been growing interest in finding inexpensive
symptom pre-screening and recommendation methods to assist in efficiently using
available medical resources such as PCR tests. In this study, we introduce the
design of COVID-Net Assistant, an efficient virtual assistant designed to
provide symptom prediction and recommendations for COVID-19 by analyzing users'
cough recordings through deep convolutional neural networks. We explore a
variety of highly customized, lightweight convolutional neural network
architectures generated via machine-driven design exploration (which we refer
to as COVID-Net Assistant neural networks) on the Covid19-Cough benchmark
dataset. The Covid19-Cough dataset comprises 682 cough recordings from a
COVID-19 positive cohort and 642 from a COVID-19 negative cohort. Among the 682
cough recordings labeled positive, 382 recordings were verified by PCR test.
Our experimental results show promising, with the COVID-Net Assistant neural
networks demonstrating robust predictive performance, achieving AUC scores of
over 0.93, with the best score over 0.95 while being fast and efficient in
inference. The COVID-Net Assistant models are made available in an open source
manner through the COVID-Net open initiative and, while not a production-ready
solution, we hope their availability acts as a good resource for clinical
scientists, machine learning researchers, as well as citizen scientists to
develop innovative solutions.
</p></li>
</ul>

<h3>Title: Robustness of Physics-Informed Neural Networks to Noise in Sensor Data. (arXiv:2211.12042v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12042">http://arxiv.org/abs/2211.12042</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12042] Robustness of Physics-Informed Neural Networks to Noise in Sensor Data](http://arxiv.org/abs/2211.12042)</code></li>
<li>Summary: <p>Physics-Informed Neural Networks (PINNs) have been shown to be an effective
way of incorporating physics-based domain knowledge into neural network models
for many important real-world systems. They have been particularly effective as
a means of inferring system information based on data, even in cases where data
is scarce. Most of the current work however assumes the availability of
high-quality data. In this work, we further conduct a preliminary investigation
of the robustness of physics-informed neural networks to the magnitude of noise
in the data. Interestingly, our experiments reveal that the inclusion of
physics in the neural network is sufficient to negate the impact of noise in
data originating from hypothetical low quality sensors with high
signal-to-noise ratios of up to 1. The resultant predictions for this test case
are seen to still match the predictive value obtained for equivalent data
obtained from high-quality sensors with potentially 10x less noise. This
further implies the utility of physics-informed neural network modeling for
making sense of data from sensor networks in the future, especially with the
advent of Industry 4.0 and the increasing trend towards ubiquitous deployment
of low-cost sensors which are typically noisier.
</p></li>
</ul>

<h3>Title: GRATIS: Deep Learning Graph Representation with Task-specific Topology and Multi-dimensional Edge Features. (arXiv:2211.12482v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12482">http://arxiv.org/abs/2211.12482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12482] GRATIS: Deep Learning Graph Representation with Task-specific Topology and Multi-dimensional Edge Features](http://arxiv.org/abs/2211.12482)</code></li>
<li>Summary: <p>Graph is powerful for representing various types of real-world data. The
topology (edges' presence) and edges' features of a graph decides the message
passing mechanism among vertices within the graph. While most existing
approaches only manually define a single-value edge to describe the
connectivity or strength of association between a pair of vertices,
task-specific and crucial relationship cues may be disregarded by such manually
defined topology and single-value edge features. In this paper, we propose the
first general graph representation learning framework (called GRATIS) which can
generate a strong graph representation with a task-specific topology and
task-specific multi-dimensional edge features from any arbitrary input. To
learn each edge's presence and multi-dimensional feature, our framework takes
both of the corresponding vertices pair and their global contextual information
into consideration, enabling the generated graph representation to have a
globally optimal message passing mechanism for different down-stream tasks. The
principled investigation results achieved for various graph analysis tasks on
11 graph and non-graph datasets show that our GRATIS can not only largely
enhance pre-defined graphs but also learns a strong graph representation for
non-graph data, with clear performance improvements on all tasks. In
particular, the learned topology and multi-dimensional edge features provide
complementary task-related cues for graph analysis tasks. Our framework is
effective, robust and flexible, and is a plug-and-play module that can be
combined with different backbones and Graph Neural Networks (GNNs) to generate
a task-specific graph representation from various graph and non-graph data. Our
code is made publicly available at
https://github.com/SSYSteve/Learning-Graph-Representation-with-Task-specific-Topology-and-Multi-dimensional-Edge-Features.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: PIC-Score: Probabilistic Interpretable Comparison Score for Optimal Matching Confidence in Single- and Multi-Biometric (Face) Recognition. (arXiv:2211.12483v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12483">http://arxiv.org/abs/2211.12483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12483] PIC-Score: Probabilistic Interpretable Comparison Score for Optimal Matching Confidence in Single- and Multi-Biometric (Face) Recognition](http://arxiv.org/abs/2211.12483)</code></li>
<li>Summary: <p>In the context of biometrics, matching confidence refers to the confidence
that a given matching decision is correct. Since many biometric systems operate
in critical decision-making processes, such as in forensics investigations,
accurately and reliably stating the matching confidence becomes of high
importance. Previous works on biometric confidence estimation can well
differentiate between high and low confidence, but lack interpretability.
Therefore, they do not provide accurate probabilistic estimates of the
correctness of a decision. In this work, we propose a probabilistic
interpretable comparison (PIC) score that accurately reflects the probability
that the score originates from samples of the same identity. We prove that the
proposed approach provides optimal matching confidence. Contrary to other
approaches, it can also optimally combine multiple samples in a joint PIC score
which further increases the recognition and confidence estimation performance.
In the experiments, the proposed PIC approach is compared against all biometric
confidence estimation methods available on four publicly available databases
and five state-of-the-art face recognition systems. The results demonstrate
that PIC has a significantly more accurate probabilistic interpretation than
similar approaches and is highly effective for multi-biometric recognition. The
code is publicly-available.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Vision-based localization methods under GPS-denied conditions. (arXiv:2211.11988v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11988">http://arxiv.org/abs/2211.11988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11988] Vision-based localization methods under GPS-denied conditions](http://arxiv.org/abs/2211.11988)</code></li>
<li>Summary: <p>This paper reviews vision-based localization methods in GPS-denied
environments and classifies the mainstream methods into Relative Vision
Localization (RVL) and Absolute Vision Localization (AVL). For RVL, we discuss
the broad application of optical flow in feature extraction-based Visual
Odometry (VO) solutions and introduce advanced optical flow estimation methods.
For AVL, we review recent advances in Visual Simultaneous Localization and
Mapping (VSLAM) techniques, from optimization-based methods to Extended Kalman
Filter (EKF) based methods. We also introduce the application of offline map
registration and lane vision detection schemes to achieve Absolute Visual
Localization. This paper compares the performance and applications of
mainstream methods for visual localization and provides suggestions for future
studies.
</p></li>
</ul>

<h3>Title: Deep-Learning-Based Computer Vision Approach For The Segmentation Of Ball Deliveries And Tracking In Cricket. (arXiv:2211.12009v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12009">http://arxiv.org/abs/2211.12009</a></li>
<li>Code URL: <a href="https://github.com/theimad/cricket-image-segmentation">https://github.com/theimad/cricket-image-segmentation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12009] Deep-Learning-Based Computer Vision Approach For The Segmentation Of Ball Deliveries And Tracking In Cricket](http://arxiv.org/abs/2211.12009)</code></li>
<li>Summary: <p>There has been a significant increase in the adoption of technology in
cricket recently. This trend has created the problem of duplicate work being
done in similar computer vision-based research works. Our research tries to
solve one of these problems by segmenting ball deliveries in a cricket
broadcast using deep learning models, MobileNet and YOLO, thus enabling
researchers to use our work as a dataset for their research. The output from
our research can be used by cricket coaches and players to analyze ball
deliveries which are played during the match. This paper presents an approach
to segment and extract video shots in which only the ball is being delivered.
The video shots are a series of continuous frames that make up the whole scene
of the video. Object detection models are applied to reach a high level of
accuracy in terms of correctly extracting video shots. The proof of concept for
building large datasets of video shots for ball deliveries is proposed which
paves the way for further processing on those shots for the extraction of
semantics. Ball tracking in these video shots is also done using a separate
RetinaNet model as a sample of the usefulness of the proposed dataset. The
position on the cricket pitch where the ball lands is also extracted by
tracking the ball along the y-axis. The video shot is then classified as a
full-pitched, good-length or short-pitched delivery.
</p></li>
</ul>

<h3>Title: Adaptive Dynamic Filtering Network for Image Denoising. (arXiv:2211.12051v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12051">http://arxiv.org/abs/2211.12051</a></li>
<li>Code URL: <a href="https://github.com/it-hao/ADFNet">https://github.com/it-hao/ADFNet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12051] Adaptive Dynamic Filtering Network for Image Denoising](http://arxiv.org/abs/2211.12051)</code></li>
<li>Summary: <p>In image denoising networks, feature scaling is widely used to enlarge the
receptive field size and reduce computational costs. This practice, however,
also leads to the loss of high-frequency information and fails to consider
within-scale characteristics. Recently, dynamic convolution has exhibited
powerful capabilities in processing high-frequency information (e.g., edges,
corners, textures), but previous works lack sufficient spatial contextual
information in filter generation. To alleviate these issues, we propose to
employ dynamic convolution to improve the learning of high-frequency and
multi-scale features. Specifically, we design a spatially enhanced kernel
generation (SEKG) module to improve dynamic convolution, enabling the learning
of spatial context information with a very low computational complexity. Based
on the SEKG module, we propose a dynamic convolution block (DCB) and a
multi-scale dynamic convolution block (MDCB). The former enhances the
high-frequency information via dynamic convolution and preserves low-frequency
information via skip connections. The latter utilizes shared adaptive dynamic
kernels and the idea of dilated convolution to achieve efficient multi-scale
feature extraction. The proposed multi-dimension feature integration (MFI)
mechanism further fuses the multi-scale features, providing precise and
contextually enriched feature representations. Finally, we build an efficient
denoising network with the proposed DCB and MDCB, named ADFNet. It achieves
better performance with low computational complexity on real-world and
synthetic Gaussian noisy datasets. The source code is available at
https://github.com/it-hao/ADFNet.
</p></li>
</ul>

<h3>Title: Visually Grounded Commonsense Knowledge Acquisition. (arXiv:2211.12054v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12054">http://arxiv.org/abs/2211.12054</a></li>
<li>Code URL: <a href="https://github.com/thunlp/clever">https://github.com/thunlp/clever</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12054] Visually Grounded Commonsense Knowledge Acquisition](http://arxiv.org/abs/2211.12054)</code></li>
<li>Summary: <p>Large-scale commonsense knowledge bases empower a broad range of AI
applications, where the automatic extraction of commonsense knowledge (CKE) is
a fundamental and challenging problem. CKE from text is known for suffering
from the inherent sparsity and reporting bias of commonsense in text. Visual
perception, on the other hand, contains rich commonsense knowledge about
real-world entities, e.g., (person, can_hold, bottle), which can serve as
promising sources for acquiring grounded commonsense knowledge. In this work,
we present CLEVER, which formulates CKE as a distantly supervised
multi-instance learning problem, where models learn to summarize commonsense
relations from a bag of images about an entity pair without any human
annotation on image instances. To address the problem, CLEVER leverages
vision-language pre-training models for deep understanding of each image in the
bag, and selects informative instances from the bag to summarize commonsense
entity relations via a novel contrastive attention mechanism. Comprehensive
experimental results in held-out and human evaluation show that CLEVER can
extract commonsense knowledge in promising quality, outperforming pre-trained
language model-based methods by 3.9 AUC and 6.4 mAUC points. The predicted
commonsense scores show strong correlation with human judgment with a 0.78
Spearman coefficient. Moreover, the extracted commonsense can also be grounded
into images with reasonable interpretability. The data and codes can be
obtained at https://github.com/thunlp/CLEVER.
</p></li>
</ul>

<h3>Title: FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for Visual Place Recognition by Fusing Frames and Events. (arXiv:2211.12244v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12244">http://arxiv.org/abs/2211.12244</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12244] FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for Visual Place Recognition by Fusing Frames and Events](http://arxiv.org/abs/2211.12244)</code></li>
<li>Summary: <p>Traditional visual place recognition (VPR), usually using standard cameras,
is easy to fail due to glare or high-speed motion. By contrast, event cameras
have the advantages of low latency, high temporal resolution, and high dynamic
range, which can deal with the above issues. Nevertheless, event cameras are
prone to failure in weakly textured or motionless scenes, while standard
cameras can still provide appearance information in this case. Thus, exploiting
the complementarity of standard cameras and event cameras can effectively
improve the performance of VPR algorithms. In the paper, we propose
FE-Fusion-VPR, an attention-based multi-scale network architecture for VPR by
fusing frames and events. First, the intensity frame and event volume are fed
into the two-stream feature extraction network for shallow feature fusion.
Next, the three-scale features are obtained through the multi-scale fusion
network and aggregated into three sub-descriptors using the VLAD layer.
Finally, the weight of each sub-descriptor is learned through the descriptor
re-weighting network to obtain the final refined descriptor. Experimental
results show that on the Brisbane-Event-VPR and DDD20 datasets, the Recall@1 of
our FE-Fusion-VPR is 25.20% and 37.21% higher than Event-VPR and
Ensemble-EventVPR, and is 2.55% and 15.89% higher than MultiRes-NetVLAD and
NetVLAD. To our knowledge, this is the first end-to-end network that goes
beyond the existing event-based and frame-based SOTA methods to fuse frame and
events directly for VPR.
</p></li>
</ul>

<h3>Title: Unsupervised extraction, labelling and clustering of segments from clinical notes. (arXiv:2211.11799v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11799">http://arxiv.org/abs/2211.11799</a></li>
<li>Code URL: <a href="https://github.com/zepzep/clinical-notes-extraction">https://github.com/zepzep/clinical-notes-extraction</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11799] Unsupervised extraction, labelling and clustering of segments from clinical notes](http://arxiv.org/abs/2211.11799)</code></li>
<li>Summary: <p>This work is motivated by the scarcity of tools for accurate, unsupervised
information extraction from unstructured clinical notes in computationally
underrepresented languages, such as Czech. We introduce a stepping stone to a
broad array of downstream tasks such as summarisation or integration of
individual patient records, extraction of structured information for national
cancer registry reporting or building of semi-structured semantic patient
representations for computing patient embeddings. More specifically, we present
a method for unsupervised extraction of semantically-labelled textual segments
from clinical notes and test it out on a dataset of Czech breast cancer
patients, provided by Masaryk Memorial Cancer Institute (the largest Czech
hospital specialising in oncology). Our goal was to extract, classify (i.e.
label) and cluster segments of the free-text notes that correspond to specific
clinical features (e.g., family background, comorbidities or toxicities). The
presented results demonstrate the practical relevance of the proposed approach
for building more sophisticated extraction and analytical pipelines deployed on
Czech clinical notes.
</p></li>
</ul>

<h3>Title: PESE: Event Structure Extraction using Pointer Network based Encoder-Decoder Architecture. (arXiv:2211.12157v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12157">http://arxiv.org/abs/2211.12157</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12157] PESE: Event Structure Extraction using Pointer Network based Encoder-Decoder Architecture](http://arxiv.org/abs/2211.12157)</code></li>
<li>Summary: <p>The task of event extraction (EE) aims to find the events and event-related
argument information from the text and represent them in a structured format.
Most previous works try to solve the problem by separately identifying multiple
substructures and aggregating them to get the complete event structure. The
problem with the methods is that it fails to identify all the interdependencies
among the event participants (event-triggers, arguments, and roles). In this
paper, we represent each event record in a unique tuple format that contains
trigger phrase, trigger type, argument phrase, and corresponding role
information. Our proposed pointer network-based encoder-decoder model generates
an event tuple in each time step by exploiting the interactions among event
participants and presenting a truly end-to-end solution to the EE task. We
evaluate our model on the ACE2005 dataset, and experimental results demonstrate
the effectiveness of our model by achieving competitive performance compared to
the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: An Emotion-Aware Multi-Task Approach to Fake News and Rumour Detection using Transfer Learning. (arXiv:2211.12374v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12374">http://arxiv.org/abs/2211.12374</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12374] An Emotion-Aware Multi-Task Approach to Fake News and Rumour Detection using Transfer Learning](http://arxiv.org/abs/2211.12374)</code></li>
<li>Summary: <p>Social networking sites, blogs, and online articles are instant sources of
news for internet users globally. However, in the absence of strict regulations
mandating the genuineness of every text on social media, it is probable that
some of these texts are fake news or rumours. Their deceptive nature and
ability to propagate instantly can have an adverse effect on society. This
necessitates the need for more effective detection of fake news and rumours on
the web. In this work, we annotate four fake news detection and rumour
detection datasets with their emotion class labels using transfer learning. We
show the correlation between the legitimacy of a text with its intrinsic
emotion for fake news and rumour detection, and prove that even within the same
emotion class, fake and real news are often represented differently, which can
be used for improved feature extraction. Based on this, we propose a multi-task
framework for fake news and rumour detection, predicting both the emotion and
legitimacy of the text. We train a variety of deep learning models in
single-task and multi-task settings for a more comprehensive comparison. We
further analyze the performance of our multi-task approach for fake news
detection in cross-domain settings to verify its efficacy for better
generalization across datasets, and to verify that emotions act as a
domain-independent feature. Experimental results verify that our multi-task
models consistently outperform their single-task counterparts in terms of
accuracy, precision, recall, and F1 score, both for in-domain and cross-domain
settings. We also qualitatively analyze the difference in performance in
single-task and multi-task learning models.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: GitFL: Adaptive Asynchronous Federated Learning using Version Control. (arXiv:2211.12049v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12049">http://arxiv.org/abs/2211.12049</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12049] GitFL: Adaptive Asynchronous Federated Learning using Version Control](http://arxiv.org/abs/2211.12049)</code></li>
<li>Summary: <p>As a promising distributed machine learning paradigm that enables
collaborative training without compromising data privacy, Federated Learning
(FL) has been increasingly used in AIoT (Artificial Intelligence of Things)
design. However, due to the lack of efficient management of straggling devices,
existing FL methods greatly suffer from the problems of low inference accuracy
and long training time. Things become even worse when taking various uncertain
factors (e.g., network delays, performance variances caused by process
variation) existing in AIoT scenarios into account. To address this issue, this
paper proposes a novel asynchronous FL framework named GitFL, whose
implementation is inspired by the famous version control system Git. Unlike
traditional FL, the cloud server of GitFL maintains a master model (i.e., the
global model) together with a set of branch models indicating the trained local
models committed by selected devices, where the master model is updated based
on both all the pushed branch models and their version information, and only
the branch models after the pull operation are dispatched to devices. By using
our proposed Reinforcement Learning (RL)-based device selection mechanism, a
pulled branch model with an older version will be more likely to be dispatched
to a faster and less frequently selected device for the next round of local
training. In this way, GitFL enables both effective control of model staleness
and adaptive load balance of versioned models among straggling devices, thus
avoiding the performance deterioration. Comprehensive experimental results on
well-known models and datasets show that, compared with state-of-the-art
asynchronous FL methods, GitFL can achieve up to 2.64X training acceleration
and 7.88% inference accuracy improvements in various uncertain scenarios.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Fairness Increases Adversarial Vulnerability. (arXiv:2211.11835v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11835">http://arxiv.org/abs/2211.11835</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11835] Fairness Increases Adversarial Vulnerability](http://arxiv.org/abs/2211.11835)</code></li>
<li>Summary: <p>The remarkable performance of deep learning models and their applications in
consequential domains (e.g., facial recognition) introduces important
challenges at the intersection of equity and security. Fairness and robustness
are two desired notions often required in learning models. Fairness ensures
that models do not disproportionately harm (or benefit) some groups over
others, while robustness measures the models' resilience against small input
perturbations.
</p></li>
</ul>

<p>This paper shows the existence of a dichotomy between fairness and
robustness, and analyzes when achieving fairness decreases the model robustness
to adversarial samples. The reported analysis sheds light on the factors
causing such contrasting behavior, suggesting that distance to the decision
boundary across groups as a key explainer for this behavior. Extensive
experiments on non-linear models and different architectures validate the
theoretical findings in multiple vision domains. Finally, the paper proposes a
simple, yet effective, solution to construct models achieving good tradeoffs
between fairness and robustness.
</p>

<h3>Title: A survey on knowledge-enhanced multimodal learning. (arXiv:2211.12328v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12328">http://arxiv.org/abs/2211.12328</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12328] A survey on knowledge-enhanced multimodal learning](http://arxiv.org/abs/2211.12328)</code></li>
<li>Summary: <p>Multimodal learning has been a field of increasing interest, aiming to
combine various modalities in a single joint representation. Especially in the
area of visiolinguistic (VL) learning multiple models and techniques have been
developed, targeting a variety of tasks that involve images and text. VL models
have reached unprecedented performances by extending the idea of Transformers,
so that both modalities can learn from each other. Massive pre-training
procedures enable VL models to acquire a certain level of real-world
understanding, although many gaps can be identified: the limited comprehension
of commonsense, factual, temporal and other everyday knowledge aspects
questions the extendability of VL tasks. Knowledge graphs and other knowledge
sources can fill those gaps by explicitly providing missing information,
unlocking novel capabilities of VL models. In the same time, knowledge graphs
enhance explainability, fairness and validity of decision making, issues of
outermost importance for such complex implementations. The current survey aims
to unify the fields of VL representation learning and knowledge graphs, and
provides a taxonomy and analysis of knowledge-enhanced VL models.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: A Graph Regularized Point Process Model For Event Propagation Sequence. (arXiv:2211.11758v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.11758">http://arxiv.org/abs/2211.11758</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.11758] A Graph Regularized Point Process Model For Event Propagation Sequence](http://arxiv.org/abs/2211.11758)</code></li>
<li>Summary: <p>Point process is the dominant paradigm for modeling event sequences occurring
at irregular intervals. In this paper we aim at modeling latent dynamics of
event propagation in graph, where the event sequence propagates in a directed
weighted graph whose nodes represent event marks (e.g., event types). Most
existing works have only considered encoding sequential event history into
event representation and ignored the information from the latent graph
structure. Besides they also suffer from poor model explainability, i.e.,
failing to uncover causal influence across a wide variety of nodes. To address
these problems, we propose a Graph Regularized Point Process (GRPP) that can be
decomposed into: 1) a graph propagation model that characterizes the event
interactions across nodes with neighbors and inductively learns node
representations; 2) a temporal attentive intensity model, whose excitation and
time decay factors of past events on the current event are constructed via the
contextualization of the node embedding. Moreover, by applying a graph
regularization method, GRPP provides model interpretability by uncovering
influence strengths between nodes. Numerical experiments on various datasets
show that GRPP outperforms existing models on both the propagation time and
node prediction by notable margins.
</p></li>
</ul>

<h3>Title: Interpreting Neural Networks through the Polytope Lens. (arXiv:2211.12312v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12312">http://arxiv.org/abs/2211.12312</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12312] Interpreting Neural Networks through the Polytope Lens](http://arxiv.org/abs/2211.12312)</code></li>
<li>Summary: <p>Mechanistic interpretability aims to explain what a neural network has
learned at a nuts-and-bolts level. What are the fundamental primitives of
neural network representations? Previous mechanistic descriptions have used
individual neurons or their linear combinations to understand the
representations a network has learned. But there are clues that neurons and
their linear combinations are not the correct fundamental units of description:
directions cannot describe how neural networks use nonlinearities to structure
their representations. Moreover, many instances of individual neurons and their
combinations are polysemantic (i.e. they have multiple unrelated meanings).
Polysemanticity makes interpreting the network in terms of neurons or
directions challenging since we can no longer assign a specific feature to a
neural unit. In order to find a basic unit of description that does not suffer
from these problems, we zoom in beyond just directions to study the way that
piecewise linear activation functions (such as ReLU) partition the activation
space into numerous discrete polytopes. We call this perspective the polytope
lens. The polytope lens makes concrete predictions about the behavior of neural
networks, which we evaluate through experiments on both convolutional image
classifiers and language models. Specifically, we show that polytopes can be
used to identify monosemantic regions of activation space (while directions are
not in general monosemantic) and that the density of polytope boundaries
reflect semantic boundaries. We also outline a vision for what mechanistic
interpretability might look like through the polytope lens.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Accelerating Diffusion Sampling with Classifier-based Feature Distillation. (arXiv:2211.12039v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12039">http://arxiv.org/abs/2211.12039</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12039] Accelerating Diffusion Sampling with Classifier-based Feature Distillation](http://arxiv.org/abs/2211.12039)</code></li>
<li>Summary: <p>Although diffusion model has shown great potential for generating higher
quality images than GANs, slow sampling speed hinders its wide application in
practice. Progressive distillation is thus proposed for fast sampling by
progressively aligning output images of $N$-step teacher sampler with
$N/2$-step student sampler. In this paper, we argue that this
distillation-based accelerating method can be further improved, especially for
few-step samplers, with our proposed \textbf{C}lassifier-based \textbf{F}eature
\textbf{D}istillation (CFD). Instead of aligning output images, we distill
teacher's sharpened feature distribution into the student with a
dataset-independent classifier, making the student focus on those important
features to improve performance. We also introduce a dataset-oriented loss to
further optimize the model. Experiments on CIFAR-10 show the superiority of our
method in achieving high quality and fast sampling. Code will be released soon.
</p></li>
</ul>

<h3>Title: Human Evaluation of Text-to-Image Models on a Multi-Task Benchmark. (arXiv:2211.12112v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12112">http://arxiv.org/abs/2211.12112</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12112] Human Evaluation of Text-to-Image Models on a Multi-Task Benchmark](http://arxiv.org/abs/2211.12112)</code></li>
<li>Summary: <p>We provide a new multi-task benchmark for evaluating text-to-image models. We
perform a human evaluation comparing the most common open-source (Stable
Diffusion) and commercial (DALL-E 2) models. Twenty computer science AI
graduate students evaluated the two models, on three tasks, at three difficulty
levels, across ten prompts each, providing 3,600 ratings. Text-to-image
generation has seen rapid progress to the point that many recent models have
demonstrated their ability to create realistic high-resolution images for
various prompts. However, current text-to-image methods and the broader body of
research in vision-language understanding still struggle with intricate text
prompts that contain many objects with multiple attributes and relationships.
We introduce a new text-to-image benchmark that contains a suite of thirty-two
tasks over multiple applications that capture a model's ability to handle
different features of a text prompt. For example, asking a model to generate a
varying number of the same object to measure its ability to count or providing
a text prompt with several objects that each have a different attribute to
identify its ability to match objects and attributes correctly. Rather than
subjectively evaluating text-to-image results on a set of prompts, our new
multi-task benchmark consists of challenge tasks at three difficulty levels
(easy, medium, and hard) and human ratings for each generated image.
</p></li>
</ul>

<h3>Title: DiffDreamer: Consistent Single-view Perpetual View Generation with Conditional Diffusion Models. (arXiv:2211.12131v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12131">http://arxiv.org/abs/2211.12131</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12131] DiffDreamer: Consistent Single-view Perpetual View Generation with Conditional Diffusion Models](http://arxiv.org/abs/2211.12131)</code></li>
<li>Summary: <p>Perpetual view generation -- the task of generating long-range novel views by
flying into a given image -- has been a novel yet promising task. We introduce
DiffDreamer, an unsupervised framework capable of synthesizing novel views
depicting a long camera trajectory while training solely on internet-collected
images of nature scenes. We demonstrate that image-conditioned diffusion models
can effectively perform long-range scene extrapolation while preserving both
local and global consistency significantly better than prior GAN-based methods.
Project page: https://primecai.github.io/diffdreamer .
</p></li>
</ul>

<h3>Title: Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems. (arXiv:2211.12343v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12343">http://arxiv.org/abs/2211.12343</a></li>
<li>Code URL: <a href="https://github.com/mengxiangming/dmps">https://github.com/mengxiangming/dmps</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12343] Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems](http://arxiv.org/abs/2211.12343)</code></li>
<li>Summary: <p>We consider the ubiquitous linear inverse problems with additive Gaussian
noise and propose an unsupervised general-purpose sampling approach called
diffusion model based posterior sampling (DMPS) to reconstruct the unknown
signal from noisy linear measurements. Specifically, the prior of the unknown
signal is implicitly modeled by one pre-trained diffusion model (DM). In
posterior sampling, to address the intractability of exact noise-perturbed
likelihood score, a simple yet effective noise-perturbed pseudo-likelihood
score is introduced under the uninformative prior assumption. While DMPS
applies to any kind of DM with proper modifications, we focus on the ablated
diffusion model (ADM) as one specific example and evaluate its efficacy on a
variety of linear inverse problems such as image super-resolution, denoising,
deblurring, colorization. Experimental results demonstrate that, for both
in-distribution and out-of-distribution samples, DMPS achieves highly
competitive or even better performances on various tasks while being 3 times
faster than the leading competitor. The code to reproduce the results is
available at https://github.com/mengxiangming/dmps.
</p></li>
</ul>

<h3>Title: SinDiffusion: Learning a Diffusion Model from a Single Natural Image. (arXiv:2211.12445v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12445">http://arxiv.org/abs/2211.12445</a></li>
<li>Code URL: <a href="https://github.com/weilunwang/sindiffusion">https://github.com/weilunwang/sindiffusion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12445] SinDiffusion: Learning a Diffusion Model from a Single Natural Image](http://arxiv.org/abs/2211.12445)</code></li>
<li>Summary: <p>We present SinDiffusion, leveraging denoising diffusion models to capture
internal distribution of patches from a single natural image. SinDiffusion
significantly improves the quality and diversity of generated samples compared
with existing GAN-based approaches. It is based on two core designs. First,
SinDiffusion is trained with a single model at a single scale instead of
multiple models with progressive growing of scales which serves as the default
setting in prior work. This avoids the accumulation of errors, which cause
characteristic artifacts in generated results. Second, we identify that a
patch-level receptive field of the diffusion network is crucial and effective
for capturing the image's patch statistics, therefore we redesign the network
structure of the diffusion model. Coupling these two designs enables us to
generate photorealistic and diverse images from a single image. Furthermore,
SinDiffusion can be applied to various applications, i.e., text-guided image
generation, and image outpainting, due to the inherent capability of diffusion
models. Extensive experiments on a wide range of images demonstrate the
superiority of our proposed method for modeling the patch distribution.
</p></li>
</ul>

<h3>Title: EDICT: Exact Diffusion Inversion via Coupled Transformations. (arXiv:2211.12446v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12446">http://arxiv.org/abs/2211.12446</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12446] EDICT: Exact Diffusion Inversion via Coupled Transformations](http://arxiv.org/abs/2211.12446)</code></li>
<li>Summary: <p>Finding an initial noise vector that produces an input image when fed into
the diffusion process (known as inversion) is an important problem in denoising
diffusion models (DDMs), with applications for real image editing. The
state-of-the-art approach for real image editing with inversion uses denoising
diffusion implicit models (DDIMs) to deterministically noise the image to the
intermediate state along the path that the denoising would follow given the
original conditioning. However, DDIM inversion for real images is unstable as
it relies on local linearization assumptions, which result in the propagation
of errors, leading to incorrect image reconstruction and loss of content. To
alleviate these problems, we propose Exact Diffusion Inversion via Coupled
Transformations (EDICT), an inversion method that draws inspiration from affine
coupling layers. EDICT enables mathematically exact inversion of real and
model-generated images by maintaining two coupled noise vectors which are used
to invert each other in an alternating fashion. Using Stable Diffusion, a
state-of-the-art latent diffusion model, we demonstrate that EDICT successfully
reconstructs real images with high fidelity. On complex image datasets like
MS-COCO, EDICT reconstruction significantly outperforms DDIM, improving the
mean square error of reconstruction by a factor of two. Using noise vectors
inverted from real images, EDICT enables a wide range of image edits--from
local and global semantic edits to image stylization--while maintaining
fidelity to the original image structure. EDICT requires no model
training/finetuning, prompt tuning, or extra data and can be combined with any
pretrained DDM. Code will be made available shortly.
</p></li>
</ul>

<h3>Title: Person Image Synthesis via Denoising Diffusion Model. (arXiv:2211.12500v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2211.12500">http://arxiv.org/abs/2211.12500</a></li>
<li>Code URL: <a href="https://github.com/ankanbhunia/PIDM">https://github.com/ankanbhunia/PIDM</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2211.12500] Person Image Synthesis via Denoising Diffusion Model](http://arxiv.org/abs/2211.12500)</code></li>
<li>Summary: <p>The pose-guided person image generation task requires synthesizing
photorealistic images of humans in arbitrary poses. The existing approaches use
generative adversarial networks that do not necessarily maintain realistic
textures or need dense correspondences that struggle to handle complex
deformations and severe occlusions. In this work, we show how denoising
diffusion models can be applied for high-fidelity person image synthesis with
strong sample diversity and enhanced mode coverage of the learnt data
distribution. Our proposed Person Image Diffusion Model (PIDM) disintegrates
the complex transfer problem into a series of simpler forward-backward
denoising steps. This helps in learning plausible source-to-target
transformation trajectories that result in faithful textures and undistorted
appearance details. We introduce a 'texture diffusion module' based on
cross-attention to accurately model the correspondences between appearance and
pose information available in source and target images. Further, we propose
'disentangled classifier-free guidance' to ensure close resemblance between the
conditional inputs and the synthesized output in terms of both pose and
appearance information. Our extensive results on two large-scale benchmarks and
a user study demonstrate the photorealism of our proposed approach under
challenging scenarios. We also show how our generated images can help in
downstream tasks. Our code and models will be publicly released.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
