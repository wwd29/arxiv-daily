<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-11-01</h1>
<h3>Title: Advanced Cyberattack Detection in Internet of Medical Things (IoMT) Using Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Alireza Mohammadi, Hosna Ghahramani, Seyyed Amir Asghari, Mehdi Aminian</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23306">https://arxiv.org/abs/2410.23306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23306">https://arxiv.org/pdf/2410.23306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23306]] Advanced Cyberattack Detection in Internet of Medical Things (IoMT) Using Convolutional Neural Networks(https://arxiv.org/abs/2410.23306)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>The increasing integration of the Internet of Medical Things (IoMT) into healthcare systems has significantly enhanced patient care but has also introduced critical cybersecurity challenges. This paper presents a novel approach based on Convolutional Neural Networks (CNNs) for detecting cyberattacks within IoMT environments. Unlike previous studies that predominantly utilized traditional machine learning (ML) models or simpler Deep Neural Networks (DNNs), the proposed model leverages the capabilities of CNNs to effectively analyze the temporal characteristics of network traffic data. Trained and evaluated on the CICIoMT2024 dataset, which comprises 18 distinct types of cyberattacks across a range of IoMT devices, the proposed CNN model demonstrates superior performance compared to previous state-of-the-art methods, achieving a perfect accuracy of 99% in binary, categorical, and multiclass classification tasks. This performance surpasses that of conventional ML models such as Logistic Regression, AdaBoost, DNNs, and Random Forests. These findings highlight the potential of CNNs to substantially improve IoMT cybersecurity, thereby ensuring the protection and integrity of connected healthcare systems.</li>
</ul>

<h3>Title: Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures</h3>
<ul>
<li><strong>Authors: </strong>Victoria Benjamin, Emily Braca, Israel Carter, Hafsa Kanchwala, Nava Khojasteh, Charly Landow, Yi Luo, Caroline Ma, Anna Magarelli, Rachel Mirin, Avery Moyer, Kayla Simpson, Amelia Skawinski, Thomas Heverin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23308">https://arxiv.org/abs/2410.23308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23308">https://arxiv.org/pdf/2410.23308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23308]] Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures(https://arxiv.org/abs/2410.23308)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>This study systematically analyzes the vulnerability of 36 large language models (LLMs) to various prompt injection attacks, a technique that leverages carefully crafted prompts to elicit malicious LLM behavior. Across 144 prompt injection tests, we observed a strong correlation between model parameters and vulnerability, with statistical analyses, such as logistic regression and random forest feature analysis, indicating that parameter size and architecture significantly influence susceptibility. Results revealed that 56 percent of tests led to successful prompt injections, emphasizing widespread vulnerability across various parameter sizes, with clustering analysis identifying distinct vulnerability profiles associated with specific model configurations. Additionally, our analysis uncovered correlations between certain prompt injection techniques, suggesting potential overlaps in vulnerabilities. These findings underscore the urgent need for robust, multi-layered defenses in LLMs deployed across critical infrastructure and sensitive industries. Successful prompt injection attacks could result in severe consequences, including data breaches, unauthorized access, or misinformation. Future research should explore multilingual and multi-step defenses alongside adaptive mitigation strategies to strengthen LLM security in diverse, real-world environments.</li>
</ul>

<h3>Title: VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration</h3>
<ul>
<li><strong>Authors: </strong>Dezhan Tu, Danylo Vashchilenko, Yuzhe Lu, Panpan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.DC, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23317">https://arxiv.org/abs/2410.23317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23317">https://arxiv.org/pdf/2410.23317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23317]] VL-Cache: Sparsity and Modality-Aware KV Cache Compression for Vision-Language Model Inference Acceleration(https://arxiv.org/abs/2410.23317)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) have demonstrated impressive performance across a versatile set of tasks. A key challenge in accelerating VLMs is storing and accessing the large Key-Value (KV) cache that encodes long visual contexts, such as images or videos. While existing KV cache compression methods are effective for Large Language Models (LLMs), directly migrating them to VLMs yields suboptimal accuracy and speedup. To bridge the gap, we propose VL-Cache, a novel KV cache compression recipe tailored for accelerating VLM inference. In this paper, we first investigate the unique sparsity pattern of VLM attention by distinguishing visual and text tokens in prefill and decoding phases. Based on these observations, we introduce a layer-adaptive sparsity-aware cache budget allocation method that effectively distributes the limited cache budget across different layers, further reducing KV cache size without compromising accuracy. Additionally, we develop a modality-aware token scoring policy to better evaluate the token importance. Empirical results on multiple benchmark datasets demonstrate that retaining only 10% of KV cache achieves accuracy comparable to that with full cache. In a speed benchmark, our method accelerates end-to-end latency of generating 100 tokens by up to 2.33x and speeds up decoding by up to 7.08x, while reducing the memory footprint of KV cache in GPU by 90%.</li>
</ul>

<h3>Title: Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists</h3>
<ul>
<li><strong>Authors: </strong>Michał Pietruszka, Łukasz Borchmann, Aleksander Jędrosz, Paweł Morawiecki</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23331">https://arxiv.org/abs/2410.23331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23331">https://arxiv.org/pdf/2410.23331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23331]] Can Models Help Us Create Better Models? Evaluating LLMs as Data Scientists(https://arxiv.org/abs/2410.23331)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a benchmark for large language models designed to tackle one of the most knowledge-intensive tasks in data science: writing feature engineering code, which requires domain knowledge in addition to a deep understanding of the underlying problem and data structure. The model is provided with a dataset description in a prompt and asked to generate code transforming it. The evaluation score is derived from the improvement achieved by an XGBoost model fit on the modified dataset compared to the original data. By an extensive evaluation of state-of-the-art models and comparison to well-established benchmarks, we demonstrate that the FeatEng of our proposal can cheaply and efficiently assess the broad capabilities of LLMs, in contrast to the existing methods.</li>
</ul>

<h3>Title: MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhu, Yixiong Chen, Mingyu Ding, Ping Luo, Leye Wang, Jingdong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23332">https://arxiv.org/abs/2410.23332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23332">https://arxiv.org/pdf/2410.23332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23332]] MoLE: Enhancing Human-centric Text-to-image Diffusion via Mixture of Low-rank Experts(https://arxiv.org/abs/2410.23332)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion has attracted vast attention due to its impressive image-generation capabilities. However, when it comes to human-centric text-to-image generation, particularly in the context of faces and hands, the results often fall short of naturalness due to insufficient training priors. We alleviate the issue in this work from two perspectives. 1) From the data aspect, we carefully collect a human-centric dataset comprising over one million high-quality human-in-the-scene images and two specific sets of close-up images of faces and hands. These datasets collectively provide a rich prior knowledge base to enhance the human-centric image generation capabilities of the diffusion model. 2) On the methodological front, we propose a simple yet effective method called Mixture of Low-rank Experts (MoLE) by considering low-rank modules trained on close-up hand and face images respectively as experts. This concept draws inspiration from our observation of low-rank refinement, where a low-rank module trained by a customized close-up dataset has the potential to enhance the corresponding image part when applied at an appropriate scale. To validate the superiority of MoLE in the context of human-centric image generation compared to state-of-the-art, we construct two benchmarks and perform evaluations with diverse metrics and human studies. Datasets, model, and code are released at this https URL.</li>
</ul>

<h3>Title: Sequential Order-Robust Mamba for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Seunghan Lee, Juri Hong, Kibok Lee, Taeyoung Park</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23356">https://arxiv.org/abs/2410.23356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23356">https://arxiv.org/pdf/2410.23356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23356]] Sequential Order-Robust Mamba for Time Series Forecasting(https://arxiv.org/abs/2410.23356)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Mamba has recently emerged as a promising alternative to Transformers, offering near-linear complexity in processing sequential data. However, while channels in time series (TS) data have no specific order in general, recent studies have adopted Mamba to capture channel dependencies (CD) in TS, introducing a sequential order bias. To address this issue, we propose SOR-Mamba, a TS forecasting method that 1) incorporates a regularization strategy to minimize the discrepancy between two embedding vectors generated from data with reversed channel orders, thereby enhancing robustness to channel order, and 2) eliminates the 1D-convolution originally designed to capture local information in sequential data. Furthermore, we introduce channel correlation modeling (CCM), a pretraining task aimed at preserving correlations between channels from the data space to the latent space in order to enhance the ability to capture CD. Extensive experiments demonstrate the efficacy of the proposed method across standard and transfer learning scenarios. Code is available at this https URL.</li>
</ul>

<h3>Title: Leveraging Language Models and Bandit Algorithms to Drive Adoption of Battery-Electric Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Keiichi Namikoshi, David A. Shamma, Rumen Iliev, Jingchao Fang, Alexandre Filipowicz, Candice L Hogan, Charlene Wu, Nikos Arechiga</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23371">https://arxiv.org/abs/2410.23371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23371">https://arxiv.org/pdf/2410.23371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23371]] Leveraging Language Models and Bandit Algorithms to Drive Adoption of Battery-Electric Vehicles(https://arxiv.org/abs/2410.23371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Behavior change interventions are important to coordinate societal action across a wide array of important applications, including the adoption of electrified vehicles to reduce emissions. Prior work has demonstrated that interventions for behavior must be personalized, and that the intervention that is most effective on average across a large group can result in a backlash effect that strengthens opposition among some subgroups. Thus, it is important to target interventions to different audiences, and to present them in a natural, conversational style. In this context, an important emerging application domain for large language models (LLMs) is conversational interventions for behavior change. In this work, we leverage prior work on understanding values motivating the adoption of battery electric vehicles. We leverage new advances in LLMs, combined with a contextual bandit, to develop conversational interventions that are personalized to the values of each study participant. We use a contextual bandit algorithm to learn to target values based on the demographics of each participant. To train our bandit algorithm in an offline manner, we leverage LLMs to play the role of study participants. We benchmark the persuasive effectiveness of our bandit-enhanced LLM against an unaided LLM generating conversational interventions without demographic-targeted values.</li>
</ul>

<h3>Title: Estimating Neural Network Robustness via Lipschitz Constant and Architecture Sensitivity</h3>
<ul>
<li><strong>Authors: </strong>Abulikemu Abuduweili, Changliu Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23382">https://arxiv.org/abs/2410.23382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23382">https://arxiv.org/pdf/2410.23382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23382]] Estimating Neural Network Robustness via Lipschitz Constant and Architecture Sensitivity(https://arxiv.org/abs/2410.23382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Ensuring neural network robustness is essential for the safe and reliable operation of robotic learning systems, especially in perception and decision-making tasks within real-world environments. This paper investigates the robustness of neural networks in perception systems, specifically examining their sensitivity to targeted, small-scale perturbations. We identify the Lipschitz constant as a key metric for quantifying and enhancing network robustness. We derive an analytical expression to compute the Lipschitz constant based on neural network architecture, providing a theoretical basis for estimating and improving robustness. Several experiments reveal the relationship between network design, the Lipschitz constant, and robustness, offering practical insights for developing safer, more robust robot learning systems.</li>
</ul>

<h3>Title: Adaptive Network Intervention for Complex Systems: A Hierarchical Graph Reinforcement Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Qiliang Chen, Babak Heydari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23396">https://arxiv.org/abs/2410.23396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23396">https://arxiv.org/pdf/2410.23396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23396]] Adaptive Network Intervention for Complex Systems: A Hierarchical Graph Reinforcement Learning Approach(https://arxiv.org/abs/2410.23396)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Effective governance and steering of behavior in complex multi-agent systems (MAS) are essential for managing system-wide outcomes, particularly in environments where interactions are structured by dynamic networks. In many applications, the goal is to promote pro-social behavior among agents, where network structure plays a pivotal role in shaping these interactions. This paper introduces a Hierarchical Graph Reinforcement Learning (HGRL) framework that governs such systems through targeted interventions in the network structure. Operating within the constraints of limited managerial authority, the HGRL framework demonstrates superior performance across a range of environmental conditions, outperforming established baseline methods. Our findings highlight the critical influence of agent-to-agent learning (social learning) on system behavior: under low social learning, the HGRL manager preserves cooperation, forming robust core-periphery networks dominated by cooperators. In contrast, high social learning accelerates defection, leading to sparser, chain-like networks. Additionally, the study underscores the importance of the system manager's authority level in preventing system-wide failures, such as agent rebellion or collapse, positioning HGRL as a powerful tool for dynamic network-based governance.</li>
</ul>

<h3>Title: FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions</h3>
<ul>
<li><strong>Authors: </strong>Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, Brandon M. Wood</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23405">https://arxiv.org/abs/2410.23405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23405">https://arxiv.org/pdf/2410.23405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23405]] FlowLLM: Flow Matching for Material Generation with Large Language Models as Base Distributions(https://arxiv.org/abs/2410.23405)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Material discovery is a critical area of research with the potential to revolutionize various fields, including carbon capture, renewable energy, and electronics. However, the immense scale of the chemical space makes it challenging to explore all possible materials experimentally. In this paper, we introduce FlowLLM, a novel generative model that combines large language models (LLMs) and Riemannian flow matching (RFM) to design novel crystalline materials. FlowLLM first fine-tunes an LLM to learn an effective base distribution of meta-stable crystals in a text representation. After converting to a graph representation, the RFM model takes samples from the LLM and iteratively refines the coordinates and lattice parameters. Our approach significantly outperforms state-of-the-art methods, increasing the generation rate of stable materials by over three times and increasing the rate for stable, unique, and novel crystals by $\sim50\%$ - a huge improvement on a difficult problem. Additionally, the crystals generated by FlowLLM are much closer to their relaxed state when compared with another leading model, significantly reducing post-hoc computational cost.</li>
</ul>

<h3>Title: EchoFM: Foundation Model for Generalizable Echocardiogram Analysis</h3>
<ul>
<li><strong>Authors: </strong>Sekeun Kim, Pengfei Jin, Sifan Song, Cheng Chen, Yiwei Li, Hui Ren, Xiang Li, Tianming Liu, Quanzheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23413">https://arxiv.org/abs/2410.23413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23413">https://arxiv.org/pdf/2410.23413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23413]] EchoFM: Foundation Model for Generalizable Echocardiogram Analysis(https://arxiv.org/abs/2410.23413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models have recently gained significant attention because of their generalizability and adaptability across multiple tasks and data distributions. Although medical foundation models have emerged, solutions for cardiac imaging, especially echocardiography videos, are still unexplored. In this paper, we introduce EchoFM, a foundation model specifically designed to represent and analyze echocardiography videos. In EchoFM, we propose a self-supervised learning framework that captures both spatial and temporal variability patterns through a spatio-temporal consistent masking strategy and periodic-driven contrastive learning. This framework can effectively capture the spatio-temporal dynamics of echocardiography and learn the representative video features without any labels. We pre-train our model on an extensive dataset comprising over 290,000 echocardiography videos covering 26 scan views across different imaging modes, with up to 20 million frames of images. The pre-trained EchoFM can then be easily adapted and fine-tuned for a variety of downstream tasks, serving as a robust backbone model. Our evaluation was systemically designed for four downstream tasks after the echocardiography examination routine. Experiment results show that EchoFM surpasses state-of-the-art methods, including specialized echocardiography methods, self-supervised pre-training models, and general-purposed pre-trained foundation models, across all downstream tasks.</li>
</ul>

<h3>Title: Mitigating Challenges in Ethereum's Proof-of-Stake Consensus: Evaluating the Impact of EigenLayer and Lido</h3>
<ul>
<li><strong>Authors: </strong>Li Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23422">https://arxiv.org/abs/2410.23422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23422">https://arxiv.org/pdf/2410.23422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23422]] Mitigating Challenges in Ethereum's Proof-of-Stake Consensus: Evaluating the Impact of EigenLayer and Lido(https://arxiv.org/abs/2410.23422)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The transition of Ethereum from a Proof-of-Work (PoW) to a Proof-of-Stake (PoS) consensus mechanism introduces a transformative approach to blockchain validation, offering enhanced scalability, energy efficiency, and security. However, this shift also presents significant challenges, including high barriers to becoming a validator, restrictions on the liquidity of staked Ether (ETH), and the risk of centralization due to staking pool dynamics. This paper addresses these challenges by exploring two innovative solutions: EigenLayer and Lido. EigenLayer is a middleware solution enabling restaking, allowing validators to secure multiple protocols and thereby increasing decentralization and profitability. Lido, a liquid staking protocol, simplifies participation by issuing stETH tokens that retain liquidity, allowing users to earn rewards without long-term lock-up constraints. This paper provides a detailed analysis of how these technologies mitigate key PoS challenges, reduce validator entry barriers, unlock staked capital, and improve decentralization. We conclude with an evaluation of the combined potential of EigenLayer and Lido to foster a more resilient and inclusive Ethereum ecosystem, setting the stage for further advancements in decentralized finance.</li>
</ul>

<h3>Title: Dynamic Information Sub-Selection for Decision Support</h3>
<ul>
<li><strong>Authors: </strong>Hung-Tien Huang, Maxwell Lennon, Shreyas Bhat Brahmavar, Sean Sylvia, Junier B. Oliva</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23423">https://arxiv.org/abs/2410.23423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23423">https://arxiv.org/pdf/2410.23423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23423]] Dynamic Information Sub-Selection for Decision Support(https://arxiv.org/abs/2410.23423)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>We introduce Dynamic Information Sub-Selection (DISS), a novel framework of AI assistance designed to enhance the performance of black-box decision-makers by tailoring their information processing on a per-instance basis. Blackbox decision-makers (e.g., humans or real-time systems) often face challenges in processing all possible information at hand (e.g., due to cognitive biases or resource constraints), which can degrade decision efficacy. DISS addresses these challenges through policies that dynamically select the most effective features and options to forward to the black-box decision-maker for prediction. We develop a scalable frequentist data acquisition strategy and a decision-maker mimicking technique for enhanced budget efficiency. We explore several impactful applications of DISS, including biased decision-maker support, expert assignment optimization, large language model decision support, and interpretability. Empirical validation of our proposed DISS methodology shows superior performance to state-of-the-art methods across various applications.</li>
</ul>

<h3>Title: Communication-Efficient Federated Learning over Wireless Channels via Gradient Sketching</h3>
<ul>
<li><strong>Authors: </strong>Vineet Sunil Gattani, Junshan Zhang, Gautam Dasarathy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23424">https://arxiv.org/abs/2410.23424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23424">https://arxiv.org/pdf/2410.23424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23424]] Communication-Efficient Federated Learning over Wireless Channels via Gradient Sketching(https://arxiv.org/abs/2410.23424)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Large-scale federated learning (FL) over wireless multiple access channels (MACs) has emerged as a crucial learning paradigm with a wide range of applications. However, its widespread adoption is hindered by several major challenges, including limited bandwidth shared by many edge devices, noisy and erroneous wireless communications, and heterogeneous datasets with different distributions across edge devices. To overcome these fundamental challenges, we propose Federated Proximal Sketching (FPS), tailored towards band-limited wireless channels and handling data heterogeneity across edge devices. FPS uses a count sketch data structure to address the bandwidth bottleneck and enable efficient compression while maintaining accurate estimation of significant coordinates. Additionally, we modify the loss function in FPS such that it is equipped to deal with varying degrees of data heterogeneity. We establish the convergence of the FPS algorithm under mild technical conditions and characterize how the bias induced due to factors like data heterogeneity and noisy wireless channels play a role in the overall result. We complement the proposed theoretical framework with numerical experiments that demonstrate the stability, accuracy, and efficiency of FPS in comparison to state-of-the-art methods on both synthetic and real-world datasets. Overall, our results show that FPS is a promising solution to tackling the above challenges of FL over wireless MACs.</li>
</ul>

<h3>Title: Social Science Meets LLMs: How Reliable Are Large Language Models in Social Simulations?</h3>
<ul>
<li><strong>Authors: </strong>Yue Huang, Zhengqing Yuan, Yujun Zhou, Kehan Guo, Xiangqi Wang, Haomin Zhuang, Weixiang Sun, Lichao Sun, Jindong Wang, Yanfang Ye, Xiangliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23426">https://arxiv.org/abs/2410.23426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23426">https://arxiv.org/pdf/2410.23426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23426]] Social Science Meets LLMs: How Reliable Are Large Language Models in Social Simulations?(https://arxiv.org/abs/2410.23426)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly employed for simulations, enabling applications in role-playing agents and Computational Social Science (CSS). However, the reliability of these simulations is under-explored, which raises concerns about the trustworthiness of LLMs in these applications. In this paper, we aim to answer ``How reliable is LLM-based simulation?'' To address this, we introduce TrustSim, an evaluation dataset covering 10 CSS-related topics, to systematically investigate the reliability of the LLM simulation. We conducted experiments on 14 LLMs and found that inconsistencies persist in the LLM-based simulated roles. In addition, the consistency level of LLMs does not strongly correlate with their general performance. To enhance the reliability of LLMs in simulation, we proposed Adaptive Learning Rate Based ORPO (AdaORPO), a reinforcement learning-based algorithm to improve the reliability in simulation across 7 LLMs. Our research provides a foundation for future studies to explore more robust and trustworthy LLM-based simulations.</li>
</ul>

<h3>Title: Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment</h3>
<ul>
<li><strong>Authors: </strong>Arihan Yadav, Alan McMillan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23437">https://arxiv.org/abs/2410.23437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23437">https://arxiv.org/pdf/2410.23437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23437]] Mind the Gap: A Generalized Approach for Cross-Modal Embedding Alignment(https://arxiv.org/abs/2410.23437)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) systems enhance text generation by incorporating external knowledge but often struggle when retrieving context across different text modalities due to semantic gaps. We introduce a generalized projection-based method, inspired by adapter modules in transfer learning, that efficiently bridges these gaps between various text types, such as programming code and pseudocode, or English and French sentences. Our approach emphasizes speed, accuracy, and data efficiency, requiring minimal resources for training and inference. By aligning embeddings from heterogeneous text modalities into a unified space through a lightweight projection network, our model significantly outperforms traditional retrieval methods like the Okapi BM25 algorithm and models like Dense Passage Retrieval (DPR), while approaching the accuracy of Sentence Transformers. Extensive evaluations demonstrate the effectiveness and generalizability of our method across different tasks, highlighting its potential for real-time, resource-constrained applications.</li>
</ul>

<h3>Title: Learning and Transferring Sparse Contextual Bigrams with Linear Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yunwei Ren, Zixuan Wang, Jason D. Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23438">https://arxiv.org/abs/2410.23438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23438">https://arxiv.org/pdf/2410.23438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23438]] Learning and Transferring Sparse Contextual Bigrams with Linear Transformers(https://arxiv.org/abs/2410.23438)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have excelled in natural language modeling and one reason behind this success is their exceptional ability to combine contextual informal and global knowledge. However, the theoretical basis remains unclear. In this paper, first we introduce the Sparse Contextual Bigram (SCB), a natural extension of the classical bigram model, where the next token's generation depends on a sparse set of earlier positions determined by the last token. We then analyze the training dynamics and sample complexity of learning SCB using a one-layer linear transformer with a gradient-based algorithm. We show that when trained from scratch, the training process can be split into an initial sample-intensive stage where the correlation is boosted from zero to a nontrivial value, followed by a more sample-efficient stage of further improvement. Additionally, we prove that, provided a nontrivial correlation between the downstream and pretraining tasks, finetuning from a pretrained model allows us to bypass the initial sample-intensive stage. We also empirically demonstrate that our algorithm can outperform SGD in this setting and discuss its relationship with the usual softmax-based transformers.</li>
</ul>

<h3>Title: Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruhan Wang, Yu Yang, Zhishuai Liu, Dongruo Zhou, Pan Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23450">https://arxiv.org/abs/2410.23450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23450">https://arxiv.org/pdf/2410.23450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23450]] Return Augmented Decision Transformer for Off-Dynamics Reinforcement Learning(https://arxiv.org/abs/2410.23450)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study offline off-dynamics reinforcement learning (RL) to utilize data from an easily accessible source domain to enhance policy learning in a target domain with limited data. Our approach centers on return-conditioned supervised learning (RCSL), particularly focusing on the decision transformer (DT), which can predict actions conditioned on desired return guidance and complete trajectory history. Previous works tackle the dynamics shift problem by augmenting the reward in the trajectory from the source domain to match the optimal trajectory in the target domain. However, this strategy can not be directly applicable in RCSL owing to (1) the unique form of the RCSL policy class, which explicitly depends on the return, and (2) the absence of a straightforward representation of the optimal trajectory distribution. We propose the Return Augmented Decision Transformer (RADT) method, where we augment the return in the source domain by aligning its distribution with that in the target domain. We provide the theoretical analysis demonstrating that the RCSL policy learned from RADT achieves the same level of suboptimality as would be obtained without a dynamics shift. We introduce two practical implementations RADT-DARA and RADT-MV respectively. Extensive experiments conducted on D4RL datasets reveal that our methods generally outperform dynamic programming based methods in off-dynamics RL scenarios.</li>
</ul>

<h3>Title: Rethinking Deep Thinking: Stable Learning of Algorithms using Lipschitz Constraints</h3>
<ul>
<li><strong>Authors: </strong>Jay Bear, Adam Prügel-Bennett, Jonathon Hare</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23451">https://arxiv.org/abs/2410.23451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23451">https://arxiv.org/pdf/2410.23451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23451]] Rethinking Deep Thinking: Stable Learning of Algorithms using Lipschitz Constraints(https://arxiv.org/abs/2410.23451)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Iterative algorithms solve problems by taking steps until a solution is reached. Models in the form of Deep Thinking (DT) networks have been demonstrated to learn iterative algorithms in a way that can scale to different sized problems at inference time using recurrent computation and convolutions. However, they are often unstable during training, and have no guarantees of convergence/termination at the solution. This paper addresses the problem of instability by analyzing the growth in intermediate representations, allowing us to build models (referred to as Deep Thinking with Lipschitz Constraints (DT-L)) with many fewer parameters and providing more reliable solutions. Additionally our DT-L formulation provides guarantees of convergence of the learned iterative procedure to a unique solution at inference time. We demonstrate DT-L is capable of robustly learning algorithms which extrapolate to harder problems than in the training set. We benchmark on the traveling salesperson problem to evaluate the capabilities of the modified system in an NP-hard problem where DT fails to learn.</li>
</ul>

<h3>Title: Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document</h3>
<ul>
<li><strong>Authors: </strong>Vicky Dong, Hao Yu, Yao Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23452">https://arxiv.org/abs/2410.23452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23452">https://arxiv.org/pdf/2410.23452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23452]] Graph-Augmented Relation Extraction Model with LLMs-Generated Support Document(https://arxiv.org/abs/2410.23452)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This study introduces a novel approach to sentence-level relation extraction (RE) that integrates Graph Neural Networks (GNNs) with Large Language Models (LLMs) to generate contextually enriched support documents. By harnessing the power of LLMs to generate auxiliary information, our approach crafts an intricate graph representation of textual data. This graph is subsequently processed through a Graph Neural Network (GNN) to refine and enrich the embeddings associated with each entity ensuring a more nuanced and interconnected understanding of the data. This methodology addresses the limitations of traditional sentence-level RE models by incorporating broader contexts and leveraging inter-entity interactions, thereby improving the model's ability to capture complex relationships across sentences. Our experiments, conducted on the CrossRE dataset, demonstrate the effectiveness of our approach, with notable improvements in performance across various domains. The results underscore the potential of combining GNNs with LLM-generated context to advance the field of relation extraction.</li>
</ul>

<h3>Title: Collage: Decomposable Rapid Prototyping for Information Extraction on Scientific PDFs</h3>
<ul>
<li><strong>Authors: </strong>Sireesh Gururaja, Yueheng Zhang, Guannan Tang, Tianhao Zhang, Kevin Murphy, Yu-Tsen Yi, Junwon Seo, Anthony Rollett, Emma Strubell</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23478">https://arxiv.org/abs/2410.23478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23478">https://arxiv.org/pdf/2410.23478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23478]] Collage: Decomposable Rapid Prototyping for Information Extraction on Scientific PDFs(https://arxiv.org/abs/2410.23478)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Recent years in NLP have seen the continued development of domain-specific information extraction tools for scientific documents, alongside the release of increasingly multimodal pretrained transformer models. While the opportunity for scientists outside of NLP to evaluate and apply such systems to their own domains has never been clearer, these models are difficult to compare: they accept different input formats, are often black-box and give little insight into processing failures, and rarely handle PDF documents, the most common format of scientific publication. In this work, we present Collage, a tool designed for rapid prototyping, visualization, and evaluation of different information extraction models on scientific PDFs. Collage allows the use and evaluation of any HuggingFace token classifier, several LLMs, and multiple other task-specific models out of the box, and provides extensible software interfaces to accelerate experimentation with new models. Further, we enable both developers and users of NLP-based tools to inspect, debug, and better understand modeling pipelines by providing granular views of intermediate states of processing. We demonstrate our system in the context of information extraction to assist with literature review in materials science.</li>
</ul>

<h3>Title: Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System</h3>
<ul>
<li><strong>Authors: </strong>Julian Collado, Kevin Stangl</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR, cs.CV, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23483">https://arxiv.org/abs/2410.23483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23483">https://arxiv.org/pdf/2410.23483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23483]] Keep on Swimming: Real Attackers Only Need Partial Knowledge of a Multi-Model System(https://arxiv.org/abs/2410.23483)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Recent approaches in machine learning often solve a task using a composition of multiple models or agentic architectures. When targeting a composed system with adversarial attacks, it might not be computationally or informationally feasible to train an end-to-end proxy model or a proxy model for every component of the system. We introduce a method to craft an adversarial attack against the overall multi-model system when we only have a proxy model for the final black-box model, and when the transformation applied by the initial models can make the adversarial perturbations ineffective. Current methods handle this by applying many copies of the first model/transformation to an input and then re-use a standard adversarial attack by averaging gradients, or learning a proxy model for both stages. To our knowledge, this is the first attack specifically designed for this threat model and our method has a substantially higher attack success rate (80% vs 25%) and contains 9.4% smaller perturbations (MSE) compared to prior state-of-the-art methods. Our experiments focus on a supervised image pipeline, but we are confident the attack will generalize to other multi-model settings [e.g. a mix of open/closed source foundation models], or agentic systems</li>
</ul>

<h3>Title: Causality-Driven Audits of Model Robustness</h3>
<ul>
<li><strong>Authors: </strong>Nathan Drenkow, Chris Ribaudo, Mathias Unberath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23494">https://arxiv.org/abs/2410.23494</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23494">https://arxiv.org/pdf/2410.23494</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23494]] Causality-Driven Audits of Model Robustness(https://arxiv.org/abs/2410.23494)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robustness audits of deep neural networks (DNN) provide a means to uncover model sensitivities to the challenging real-world imaging conditions that significantly degrade DNN performance in-the-wild. Such conditions are often the result of the compounding of multiple factors inherent to the environment, sensor, or processing pipeline and may lead to complex image distortions that are not easily categorized. When robustness audits are limited to a set of pre-determined imaging effects or distortions, the results cannot be (easily) transferred to real-world conditions where image corruptions may be more complex or nuanced. To address this challenge, we present a new alternative robustness auditing method that uses causal inference to measure DNN sensitivities to the factors of the imaging process that cause complex distortions. Our approach uses causal models to explicitly encode assumptions about the domain-relevant factors and their interactions. Then, through extensive experiments on natural and rendered images across multiple vision tasks, we show that our approach reliably estimates causal effects of each factor on DNN performance using observational domain data. These causal effects directly tie DNN sensitivities to observable properties of the imaging pipeline in the domain of interest towards reducing the risk of unexpected DNN failures when deployed in that domain.</li>
</ul>

<h3>Title: Smaller Large Language Models Can Do Moral Self-Correction</h3>
<ul>
<li><strong>Authors: </strong>Guangliang Liu, Zhiyu Xue, Rongrong Wang, Kristen Marie Johnson</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23496">https://arxiv.org/abs/2410.23496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23496">https://arxiv.org/pdf/2410.23496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23496]] Smaller Large Language Models Can Do Moral Self-Correction(https://arxiv.org/abs/2410.23496)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-correction is one of the most amazing emerging capabilities of Large Language Models (LLMs), enabling LLMs to self-modify an inappropriate output given a natural language feedback which describes the problems of that output. Moral self-correction is a post-hoc approach correcting unethical generations without requiring a gradient update, making it both computationally lightweight and capable of preserving the language modeling ability. Previous works have shown that LLMs can self-debias, and it has been reported that small models, i.e., those with less than 22B parameters, are not capable of moral self-correction. However, there is no direct proof as to why such smaller models fall short of moral self-correction, though previous research hypothesizes that larger models are skilled in following instructions and understanding abstract social norms. In this paper, we empirically validate this hypothesis in the context of social stereotyping, through meticulous prompting. Our experimental results indicate that (i) surprisingly, 3.8B LLMs with proper safety alignment fine-tuning can achieve very good moral self-correction performance, highlighting the significant effects of safety alignment; and (ii) small LLMs are indeed weaker than larger-scale models in terms of comprehending social norms and self-explanation through CoT, but all scales of LLMs show bad self-correction performance given unethical instructions.</li>
</ul>

<h3>Title: Development and Comparative Analysis of Machine Learning Models for Hypoxemia Severity Triage in CBRNE Emergency Scenarios Using Physiological and Demographic Data from Medical-Grade Devices</h3>
<ul>
<li><strong>Authors: </strong>Santino Nanini, Mariem Abid, Yassir Mamouni, Arnaud Wiedemann, Philippe Jouvet, Stephane Bourassa</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23503">https://arxiv.org/abs/2410.23503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23503">https://arxiv.org/pdf/2410.23503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23503]] Development and Comparative Analysis of Machine Learning Models for Hypoxemia Severity Triage in CBRNE Emergency Scenarios Using Physiological and Demographic Data from Medical-Grade Devices(https://arxiv.org/abs/2410.23503)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>This paper presents the development of machine learning (ML) models to predict hypoxemia severity during emergency triage, especially in Chemical, Biological, Radiological, Nuclear, and Explosive (CBRNE) events, using physiological data from medical-grade sensors. Gradient Boosting Models (XGBoost, LightGBM, CatBoost) and sequential models (LSTM, GRU) were trained on physiological and demographic data from the MIMIC-III and IV datasets. A robust preprocessing pipeline addressed missing data, class imbalances, and incorporated synthetic data flagged with masks. Gradient Boosting Models (GBMs) outperformed sequential models in terms of training speed, interpretability, and reliability, making them well-suited for real-time decision-making. While their performance was comparable to that of sequential models, the GBMs used score features from six physiological variables derived from the enhanced National Early Warning Score (NEWS) 2, which we termed NEWS2+. This approach significantly improved prediction accuracy. While sequential models handled temporal data well, their performance gains did not justify the higher computational cost. A 5-minute prediction window was chosen for timely intervention, with minute-level interpolations standardizing the data. Feature importance analysis highlighted the significant role of mask and score features in enhancing both transparency and performance. Temporal dependencies proved to be less critical, as Gradient Boosting Models were able to capture key patterns effectively without relying on them. This study highlights ML's potential to improve triage and reduce alarm fatigue. Future work will integrate data from multiple hospitals to enhance model generalizability across clinical settings.</li>
</ul>

<h3>Title: Learning to Achieve Goals with Belief State Transformers</h3>
<ul>
<li><strong>Authors: </strong>Edward S. Hu, Kwangjun Ahn, Qinghua Liu, Haoran Xu, Manan Tomar, Ada Langford, Dinesh Jayaraman, Alex Lamb, John Langford</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23506">https://arxiv.org/abs/2410.23506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23506">https://arxiv.org/pdf/2410.23506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23506]] Learning to Achieve Goals with Belief State Transformers(https://arxiv.org/abs/2410.23506)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We introduce the "Belief State Transformer", a next-token predictor that takes both a prefix and suffix as inputs, with a novel objective of predicting both the next token for the prefix and the previous token for the suffix. The Belief State Transformer effectively learns to solve challenging problems that conventional forward-only transformers struggle with, in a domain-independent fashion. Key to this success is learning a compact belief state that captures all relevant information necessary for accurate predictions. Empirical ablations show that each component of the model is essential in difficult scenarios where standard Transformers fall short. For the task of story writing with known prefixes and suffixes, our approach outperforms the Fill-in-the-Middle method for reaching known goals and demonstrates improved performance even when the goals are unknown. Altogether, the Belief State Transformer enables more efficient goal-conditioned decoding, better test-time inference, and high-quality text representations on small scale problems.</li>
</ul>

<h3>Title: Tiny Transformers Excel at Sentence Compression</h3>
<ul>
<li><strong>Authors: </strong>Peter Belcak, Roger Wattenhofer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23510">https://arxiv.org/abs/2410.23510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23510">https://arxiv.org/pdf/2410.23510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23510]] Tiny Transformers Excel at Sentence Compression(https://arxiv.org/abs/2410.23510)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>It is staggering that words of the English language, which are on average represented by 5--6 bytes of ASCII, require as much as 24 kilobytes when served to large language models. We show that there is room for more information in every token embedding. We demonstrate that 1--3-layer transformers are capable of encoding and subsequently decoding standard English sentences into as little as a single 3-kilobyte token. Our work implies that even small networks can learn to construct valid English sentences and suggests the possibility of optimising large language models by moving from sub-word token embeddings towards larger fragments of text.</li>
</ul>

<h3>Title: Dynamic Strategy Planning for Efficient Question Answering with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tanmay Parekh, Pradyot Prakash, Alexander Radovic, Akshay Shekher, Denis Savenkov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23511">https://arxiv.org/abs/2410.23511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23511">https://arxiv.org/pdf/2410.23511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23511]] Dynamic Strategy Planning for Efficient Question Answering with Large Language Models(https://arxiv.org/abs/2410.23511)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Research has shown the effectiveness of reasoning (e.g., Chain-of-Thought), planning (e.g., SelfAsk), and retrieval augmented generation strategies to improve the performance of Large Language Models (LLMs) on various tasks, such as question answering. However, using a single fixed strategy to answer different kinds of questions is suboptimal in performance and inefficient in terms of generated output tokens and performed retrievals. In our work, we propose a novel technique DyPlan, to induce a dynamic strategy selection process in LLMs, to improve performance and reduce costs in question-answering. DyPlan incorporates an initial decision step to select the most suitable strategy conditioned on the input question and guides the LLM's response generation accordingly. We extend DyPlan to DyPlan-verify, adding an internal verification and correction process to further enrich the generated answer. Experiments on three prominent multi-hop question answering (MHQA) datasets reveal how DyPlan can improve model performance by 7-13% while reducing the cost by 11-32% relative to the best baseline model.</li>
</ul>

<h3>Title: Neural spell-checker: Beyond words with synthetic data generation</h3>
<ul>
<li><strong>Authors: </strong>Matej Klemen, Martin Božič, Špela Arhar Holdt, Marko Robnik-Šikonja</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23514">https://arxiv.org/abs/2410.23514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23514">https://arxiv.org/pdf/2410.23514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23514]] Neural spell-checker: Beyond words with synthetic data generation(https://arxiv.org/abs/2410.23514)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Spell-checkers are valuable tools that enhance communication by identifying misspelled words in written texts. Recent improvements in deep learning, and in particular in large language models, have opened new opportunities to improve traditional spell-checkers with new functionalities that not only assess spelling correctness but also the suitability of a word for a given context. In our work, we present and compare two new spell-checkers and evaluate them on synthetic, learner, and more general-domain Slovene datasets. The first spell-checker is a traditional, fast, word-based approach, based on a morphological lexicon with a significantly larger word list compared to existing spell-checkers. The second approach uses a language model trained on a large corpus with synthetically inserted errors. We present the training data construction strategies, which turn out to be a crucial component of neural spell-checkers. Further, the proposed neural model significantly outperforms all existing spell-checkers for Slovene in both precision and recall.</li>
</ul>

<h3>Title: Generative forecasting of brain activity enhances Alzheimer's classification and interpretation</h3>
<ul>
<li><strong>Authors: </strong>Yutong Gao, Vince D. Calhoun, Robyn L. Miller</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23515">https://arxiv.org/abs/2410.23515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23515">https://arxiv.org/pdf/2410.23515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23515]] Generative forecasting of brain activity enhances Alzheimer's classification and interpretation(https://arxiv.org/abs/2410.23515)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Understanding the relationship between cognition and intrinsic brain activity through purely data-driven approaches remains a significant challenge in neuroscience. Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive method to monitor regional neural activity, providing a rich and complex spatiotemporal data structure. Deep learning has shown promise in capturing these intricate representations. However, the limited availability of large datasets, especially for disease-specific groups such as Alzheimer's Disease (AD), constrains the generalizability of deep learning models. In this study, we focus on multivariate time series forecasting of independent component networks derived from rs-fMRI as a form of data augmentation, using both a conventional LSTM-based model and the novel Transformer-based BrainLM model. We assess their utility in AD classification, demonstrating how generative forecasting enhances classification performance. Post-hoc interpretation of BrainLM reveals class-specific brain network sensitivities associated with AD.</li>
</ul>

<h3>Title: LBurst: Learning-Based Robotic Burst Feature Extraction for 3D Reconstruction in Low Light</h3>
<ul>
<li><strong>Authors: </strong>Ahalya Ravendran, Mitch Bryson, Donald G. Dansereau</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23522">https://arxiv.org/abs/2410.23522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23522">https://arxiv.org/pdf/2410.23522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23522]] LBurst: Learning-Based Robotic Burst Feature Extraction for 3D Reconstruction in Low Light(https://arxiv.org/abs/2410.23522)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Drones have revolutionized the fields of aerial imaging, mapping, and disaster recovery. However, the deployment of drones in low-light conditions is constrained by the image quality produced by their on-board cameras. In this paper, we present a learning architecture for improving 3D reconstructions in low-light conditions by finding features in a burst. Our approach enhances visual reconstruction by detecting and describing high quality true features and less spurious features in low signal-to-noise ratio images. We demonstrate that our method is capable of handling challenging scenes in millilux illumination, making it a significant step towards drones operating at night and in extremely low-light applications such as underground mining and search and rescue operations.</li>
</ul>

<h3>Title: LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hieu Tran, Junda Wang, Yujan Ting, Weijing Huang, Terrence Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23526">https://arxiv.org/abs/2410.23526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23526">https://arxiv.org/pdf/2410.23526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23526]] LEAF: Learning and Evaluation Augmented by Fact-Checking to Improve Factualness in Large Language Models(https://arxiv.org/abs/2410.23526)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable capabilities in various natural language processing tasks, yet they often struggle with maintaining factual accuracy, particularly in knowledge-intensive domains like healthcare. This study introduces LEAF: Learning and Evaluation Augmented by Fact-Checking, a novel approach designed to enhance the factual reliability of LLMs, with a focus on medical question answering (QA). LEAF utilizes a dual strategy to enhance the factual accuracy of responses from models such as Llama 3 70B Instruct and Llama 3 8B Instruct. The first strategy, Fact-Check-Then-RAG, improves Retrieval-Augmented Generation (RAG) by incorporating fact-checking results to guide the retrieval process without updating model parameters. The second strategy, Learning from Fact-Checks via Self-Training, involves supervised fine-tuning (SFT) on fact-checked responses or applying Simple Preference Optimization (SimPO) with fact-checking as a ranking mechanism, both updating LLM parameters from supervision. These findings suggest that integrating fact-checked responses whether through RAG enhancement or self-training enhances the reliability and factual correctness of LLM outputs, offering a promising solution for applications where information accuracy is crucial.</li>
</ul>

<h3>Title: Large Language Models for Patient Comments Multi-Label Classification</h3>
<ul>
<li><strong>Authors: </strong>Hajar Sakai, Sarah S. Lam, Mohammadsadegh Mikaeili, Joshua Bosire, Franziska Jovin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23528">https://arxiv.org/abs/2410.23528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23528">https://arxiv.org/pdf/2410.23528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23528]] Large Language Models for Patient Comments Multi-Label Classification(https://arxiv.org/abs/2410.23528)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, large language model</a></li>
<li><strong>Abstract: </strong>Patient experience and care quality are crucial for a hospital's sustainability and reputation. The analysis of patient feedback offers valuable insight into patient satisfaction and outcomes. However, the unstructured nature of these comments poses challenges for traditional machine learning methods following a supervised learning paradigm. This is due to the unavailability of labeled data and the nuances these texts encompass. This research explores leveraging Large Language Models (LLMs) in conducting Multi-label Text Classification (MLTC) of inpatient comments shared after a stay in the hospital. GPT-4o-Turbo was leveraged to conduct the classification. However, given the sensitive nature of patients' comments, a security layer is introduced before feeding the data to the LLM through a Protected Health Information (PHI) detection framework, which ensures patients' de-identification. Additionally, using the prompt engineering framework, zero-shot learning, in-context learning, and chain-of-thought prompting were experimented with. Results demonstrate that GPT-4o-Turbo, whether following a zero-shot or few-shot setting, outperforms traditional methods and Pre-trained Language Models (PLMs) and achieves the highest overall performance with an F1-score of 76.12% and a weighted F1-score of 73.61% followed closely by the few-shot learning results. Subsequently, the results' association with other patient experience structured variables (e.g., rating) was conducted. The study enhances MLTC through the application of LLMs, offering healthcare practitioners an efficient method to gain deeper insights into patient feedback and deliver prompt, appropriate responses.</li>
</ul>

<h3>Title: There and Back Again: On the relation between noises, images, and their inversions in diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Łukasz Staniszewski, Łukasz Kuciński, Kamil Deja</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23530">https://arxiv.org/abs/2410.23530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23530">https://arxiv.org/pdf/2410.23530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23530]] There and Back Again: On the relation between noises, images, and their inversions in diffusion models(https://arxiv.org/abs/2410.23530)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Denoising Diffusion Probabilistic Models (DDPMs) achieve state-of-the-art performance in synthesizing new images from random noise, but they lack meaningful latent space that encodes data into features. Recent DDPM-based editing techniques try to mitigate this issue by inverting images back to their approximated staring noise. In this work, we study the relation between the initial Gaussian noise, the samples generated from it, and their corresponding latent encodings obtained through the inversion procedure. First, we interpret their spatial distance relations to show the inaccuracy of the DDIM inversion technique by localizing latent representations manifold between the initial noise and generated samples. Then, we demonstrate the peculiar relation between initial Gaussian noise and its corresponding generations during diffusion training, showing that the high-level features of generated images stabilize rapidly, keeping the spatial distance relationship between noises and generations consistent throughout the training.</li>
</ul>

<h3>Title: Simulating User Agents for Embodied Conversational-AI</h3>
<ul>
<li><strong>Authors: </strong>Daniel Philipov, Vardhan Dongre, Gokhan Tur, Dilek Hakkani-Tür</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23535">https://arxiv.org/abs/2410.23535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23535">https://arxiv.org/pdf/2410.23535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23535]] Simulating User Agents for Embodied Conversational-AI(https://arxiv.org/abs/2410.23535)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Embodied agents designed to assist users with tasks must engage in natural language interactions, interpret instructions, execute actions, and communicate effectively to resolve issues. However, collecting large-scale, diverse datasets of situated human-robot dialogues to train and evaluate such agents is expensive, labor-intensive, and time-consuming. To address this challenge, we propose building a large language model (LLM)-based user agent that can simulate user behavior during interactions with an embodied agent in a virtual environment. Given a user goal (e.g., make breakfast), at each time step, the user agent may observe" the robot actions or speak" to either intervene with the robot or answer questions. Such a user agent assists in improving the scalability and efficiency of embodied dialogues dataset generation and is critical for enhancing and evaluating the robot's interaction and task completion ability, as well as for research in reinforcement learning using AI feedback. We evaluate our user agent's ability to generate human-like behaviors by comparing its simulated dialogues with the TEACh dataset. We perform three experiments: zero-shot prompting to predict dialogue acts, few-shot prompting, and fine-tuning on the TEACh training subset. Results show the LLM-based user agent achieves an F-measure of 42% with zero-shot prompting and 43.4% with few-shot prompting in mimicking human speaking behavior. Through fine-tuning, performance in deciding when to speak remained stable, while deciding what to say improved from 51.1% to 62.5%. These findings showcase the feasibility of the proposed approach for assessing and enhancing the effectiveness of robot task completion through natural language communication.</li>
</ul>

<h3>Title: EVeCA: Efficient and Verifiable On-Chain Data Query Framework Using Challenge-Based Authentication</h3>
<ul>
<li><strong>Authors: </strong>Meng Shen, Yuzhi Liu, Qinglin Zhao, Wei Wang, Wei Ou, Wenbao Han, Liehuang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23546">https://arxiv.org/abs/2410.23546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23546">https://arxiv.org/pdf/2410.23546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23546]] EVeCA: Efficient and Verifiable On-Chain Data Query Framework Using Challenge-Based Authentication(https://arxiv.org/abs/2410.23546)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>As blockchain applications become increasingly widespread, there is a rising demand for on-chain data queries. However, existing schemes for on-chain data queries face a challenge between verifiability and efficiency. Queries on blockchain databases can compromise the authenticity of the query results, while schemes that utilize on-chain Authenticated Data Structure (ADS) have lower efficiency. To overcome this limitation, we propose an efficient and verifiable on-chain data query framework EVeCA. In our approach, we free the full nodes from the task of ADS maintenance by delegating it to a limited number of nodes, and full nodes verify the correctness of ADS by using challenge-based authentication scheme instead of reconstructing them, which prevents the service providers from maintaining incorrect ADS with overwhelming probability. By carefully designing the ADS verification scheme, EVeCA achieves higher efficiency while remaining resilient against adaptive attacks. Our framework effectively eliminates the need for on-chain ADS maintenance, and allows full nodes to participate in ADS maintenance in a cost-effective way. We demonstrate the effectiveness of the proposed scheme through security analysis and experimental evaluation. Compared to existing schemes, our approach improves ADS maintenance efficiency by about 20*.</li>
</ul>

<h3>Title: From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents</h3>
<ul>
<li><strong>Authors: </strong>Nalin Tiwary, Vardhan Dongre, Sanil Arun Chawla, Ashwin Lamani, Dilek Hakkani-Tür</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23555">https://arxiv.org/abs/2410.23555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23555">https://arxiv.org/pdf/2410.23555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23555]] From Context to Action: Analysis of the Impact of State Representation and Context on the Generalization of Multi-Turn Web Navigation Agents(https://arxiv.org/abs/2410.23555)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Model (LLM)-based frameworks have extended their capabilities to complex real-world applications, such as interactive web navigation. These systems, driven by user commands, navigate web browsers to complete tasks through multi-turn dialogues, offering both innovative opportunities and significant challenges. Despite the introduction of benchmarks for conversational web navigation, a detailed understanding of the key contextual components that influence the performance of these agents remains elusive. This study aims to fill this gap by analyzing the various contextual elements crucial to the functioning of web navigation agents. We investigate the optimization of context management, focusing on the influence of interaction history and web page representation. Our work highlights improved agent performance across out-of-distribution scenarios, including unseen websites, categories, and geographic locations through effective context management. These findings provide insights into the design and optimization of LLM-based agents, enabling more accurate and effective web navigation in real-world applications.</li>
</ul>

<h3>Title: Transferable Ensemble Black-box Jailbreak Attacks on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yiqi Yang, Hongye Fu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23558">https://arxiv.org/abs/2410.23558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23558">https://arxiv.org/pdf/2410.23558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23558]] Transferable Ensemble Black-box Jailbreak Attacks on Large Language Models(https://arxiv.org/abs/2410.23558)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>In this report, we propose a novel black-box jailbreak attacking framework that incorporates various LLM-as-Attacker methods to deliver transferable and powerful jailbreak attacks. Our method is designed based on three key observations from existing jailbreaking studies and practices. First, we consider an ensemble approach should be more effective in exposing the vulnerabilities of an aligned LLM compared to individual attacks. Second, different malicious instructions inherently vary in their jailbreaking difficulty, necessitating differentiated treatment to ensure more efficient attacks. Finally, the semantic coherence of a malicious instruction is crucial for triggering the defenses of an aligned LLM; therefore, it must be carefully disrupted to manipulate its embedding representation, thereby increasing the jailbreak success rate. We validated our approach by participating in the Competition for LLM and Agent Safety 2024, where our team achieved top performance in the Jailbreaking Attack Track.</li>
</ul>

<h3>Title: Across-Platform Detection of Malicious Cryptocurrency Transactions via Account Interaction Learning</h3>
<ul>
<li><strong>Authors: </strong>Zheng Che, Meng Shen, Zhehui Tan, Hanbiao Du, Liehuang Zhu, Wei Wang, Ting Chen, Qinglin Zhao, Yong Xie</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23563">https://arxiv.org/abs/2410.23563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23563">https://arxiv.org/pdf/2410.23563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23563]] Across-Platform Detection of Malicious Cryptocurrency Transactions via Account Interaction Learning(https://arxiv.org/abs/2410.23563)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the rapid evolution of Web3.0, cryptocurrency has become a cornerstone of decentralized finance. While these digital assets enable efficient and borderless financial transactions, their pseudonymous nature has also attracted malicious activities such as money laundering, fraud, and other financial crimes. Effective detection of malicious transactions is crucial to maintaining the security and integrity of the Web 3.0 ecosystem. Existing malicious transaction detection methods rely on large amounts of labeled data and suffer from low generalization. Label-efficient and generalizable malicious transaction detection remains a challenging task. In this paper, we propose ShadowEyes, a novel malicious transaction detection method. Specifically, we first propose a generalized graph structure named TxGraph as a representation of malicious transaction, which captures the interaction features of each malicious account and its neighbors. Then we carefully design a data augmentation method tailored to simulate the evolution of malicious transactions to generate positive pairs. To alleviate account label scarcity, we further design a graph contrastive mechanism, which enables ShadowEyes to learn discriminative features effectively from unlabeled data, thereby enhancing its detection capabilities in real-world scenarios. We conduct extensive experiments using public datasets to evaluate the performance of ShadowEyes. The results demonstrate that it outperforms state-of-the-art (SOTA) methods in four typical scenarios. Specifically, in the zero-shot learning scenario, it can achieve an F1 score of 76.98% for identifying gambling transactions, surpassing the SOTA method by12.05%. In the scenario of across-platform malicious transaction detection, ShadowEyes maintains an F1 score of around 90%, which is 10% higher than the SOTA method.</li>
</ul>

<h3>Title: BioNCERE: Non-Contrastive Enhancement For Relation Extraction In Biomedical Texts</h3>
<ul>
<li><strong>Authors: </strong>Farshad Noravesh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23583">https://arxiv.org/abs/2410.23583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23583">https://arxiv.org/pdf/2410.23583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23583]] BioNCERE: Non-Contrastive Enhancement For Relation Extraction In Biomedical Texts(https://arxiv.org/abs/2410.23583)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>State-of-the-art models for relation extraction (RE) in the biomedical domain consider finetuning BioBERT using classification, but they may suffer from the anisotropy problem. Contrastive learning methods can reduce this anisotropy phenomena, and also help to avoid class collapse in any classification problem. In the present paper, a new training method called biological non-contrastive relation extraction (BioNCERE) is introduced for relation extraction without using any named entity labels for training to reduce annotation costs. BioNCERE uses transfer learning and non-contrastive learning to avoid full or dimensional collapse as well as bypass overfitting. It resolves RE in three stages by leveraging transfer learning two times. By freezing the weights learned in previous stages in the proposed pipeline and by leveraging non-contrastive learning in the second stage, the model predicts relations without any knowledge of named entities. Experiments have been done on SemMedDB that are almost similar to State-of-the-art performance on RE without using the information of named entities.</li>
</ul>

<h3>Title: End-to-End Ontology Learning with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Andy Lo, Albert Q. Jiang, Wenda Li, Mateja Jamnik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23584">https://arxiv.org/abs/2410.23584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23584">https://arxiv.org/pdf/2410.23584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23584]] End-to-End Ontology Learning with Large Language Models(https://arxiv.org/abs/2410.23584)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Ontologies are useful for automatic machine processing of domain knowledge as they represent it in a structured format. Yet, constructing ontologies requires substantial manual effort. To automate part of this process, large language models (LLMs) have been applied to solve various subtasks of ontology learning. However, this partial ontology learning does not capture the interactions between subtasks. We address this gap by introducing OLLM, a general and scalable method for building the taxonomic backbone of an ontology from scratch. Rather than focusing on subtasks, like individual relations between entities, we model entire subcomponents of the target ontology by finetuning an LLM with a custom regulariser that reduces overfitting on high-frequency concepts. We introduce a novel suite of metrics for evaluating the quality of the generated ontology by measuring its semantic and structural similarity to the ground truth. In contrast to standard metrics, our metrics use deep learning techniques to define more robust distance measures between graphs. Both our quantitative and qualitative results on Wikipedia show that OLLM outperforms subtask composition methods, producing more semantically accurate ontologies while maintaining structural integrity. We further demonstrate that our model can be effectively adapted to new domains, like arXiv, needing only a small number of training examples. Our source code and datasets are available at this https URL.</li>
</ul>

<h3>Title: How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?</h3>
<ul>
<li><strong>Authors: </strong>Weiguo Gao, Ming Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23594">https://arxiv.org/abs/2410.23594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23594">https://arxiv.org/pdf/2410.23594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23594]] How Do Flow Matching Models Memorize and Generalize in Sample Data Subspaces?(https://arxiv.org/abs/2410.23594)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Real-world data is often assumed to lie within a low-dimensional structure embedded in high-dimensional space. In practical settings, we observe only a finite set of samples, forming what we refer to as the sample data subspace. It serves an essential approximation supporting tasks such as dimensionality reduction and generation. A major challenge lies in whether generative models can reliably synthesize samples that stay within this subspace rather than drifting away from the underlying structure. In this work, we provide theoretical insights into this challenge by leveraging Flow Matching models, which transform a simple prior into a complex target distribution via a learned velocity field. By treating the real data distribution as discrete, we derive analytical expressions for the optimal velocity field under a Gaussian prior, showing that generated samples memorize real data points and represent the sample data subspace exactly. To generalize to suboptimal scenarios, we introduce the Orthogonal Subspace Decomposition Network (OSDNet), which systematically decomposes the velocity field into subspace and off-subspace components. Our analysis shows that the off-subspace component decays, while the subspace component generalizes within the sample data subspace, ensuring generated samples preserve both proximity and diversity.</li>
</ul>

<h3>Title: Using Structural Similarity and Kolmogorov-Arnold Networks for Anatomical Embedding of 3-hinge Gyrus</h3>
<ul>
<li><strong>Authors: </strong>Minheng Chen, Chao Cao, Tong Chen, Yan Zhuang, Jing Zhang, Yanjun Lyu, Xiaowei Yu, Lu Zhang, Tianming Liu, Dajiang Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23598">https://arxiv.org/abs/2410.23598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23598">https://arxiv.org/pdf/2410.23598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23598]] Using Structural Similarity and Kolmogorov-Arnold Networks for Anatomical Embedding of 3-hinge Gyrus(https://arxiv.org/abs/2410.23598)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The 3-hinge gyrus (3HG) is a newly defined folding pattern, which is the conjunction of gyri coming from three directions in cortical folding. Many studies demonstrated that 3HGs can be reliable nodes when constructing brain networks or connectome since they simultaneously possess commonality and individuality across different individual brains and populations. However, 3HGs are identified and validated within individual spaces, making it difficult to directly serve as the brain network nodes due to the absence of cross-subject correspondence. The 3HG correspondences represent the intrinsic regulation of brain organizational architecture, traditional image-based registration methods tend to fail because individual anatomical properties need to be fully respected. To address this challenge, we propose a novel self-supervised framework for anatomical feature embedding of the 3HGs to build the correspondences among different brains. The core component of this framework is to construct a structural similarity-enhanced multi-hop feature encoding strategy based on the recently developed Kolmogorov-Arnold network (KAN) for anatomical feature embedding. Extensive experiments suggest that our approach can effectively establish robust cross-subject correspondences when no one-to-one mapping exists.</li>
</ul>

<h3>Title: Dynamic Uncertainty Ranking: Enhancing In-Context Learning for Long-Tail Knowledge in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shuyang Yu, Runxue Bao, Parminder Bhatia, Taha Kass-Hout, Jiayu Zhou, Cao Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23605">https://arxiv.org/abs/2410.23605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23605">https://arxiv.org/pdf/2410.23605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23605]] Dynamic Uncertainty Ranking: Enhancing In-Context Learning for Long-Tail Knowledge in LLMs(https://arxiv.org/abs/2410.23605)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can learn vast amounts of knowledge from diverse domains during pre-training. However, long-tail knowledge from specialized domains is often scarce and underrepresented, rarely appearing in the models' memorization. Prior work has shown that in-context learning (ICL) with retriever augmentation can help LLMs better capture long-tail knowledge, reducing their reliance on pre-trained data. Despite these advances, we observe that LLM predictions for long-tail questions remain uncertain to variations in retrieved samples. To take advantage of the uncertainty in ICL for guiding LLM predictions toward correct answers on long-tail samples, we propose a reinforcement learning-based dynamic uncertainty ranking method for ICL that accounts for the varying impact of each retrieved sample on LLM predictions. Our approach prioritizes more informative and stable samples while demoting misleading ones, updating rankings based on the feedback from the LLM w.r.t. each retrieved sample. To enhance training efficiency and reduce query costs, we introduce a learnable dynamic ranking threshold, adjusted when the model encounters negative prediction shifts. Experimental results on various question-answering datasets from different domains show that our method outperforms the best baseline by $2.76\%$, with a notable $5.96\%$ boost in accuracy on long-tail questions that elude zero-shot inference.</li>
</ul>

<h3>Title: Context-Aware Token Selection and Packing for Enhanced Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Zhang, Baoxin Li, Jae-sun Seo, Yu Cap</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23608">https://arxiv.org/abs/2410.23608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23608">https://arxiv.org/pdf/2410.23608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23608]] Context-Aware Token Selection and Packing for Enhanced Vision Transformer(https://arxiv.org/abs/2410.23608)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In recent years, the long-range attention mechanism of vision transformers has driven significant performance breakthroughs across various computer vision tasks. However, the traditional self-attention mechanism, which processes both informative and non-informative tokens, suffers from inefficiency and inaccuracies. While sparse attention mechanisms have been introduced to mitigate these issues by pruning tokens involved in attention, they often lack context-awareness and intelligence. These mechanisms frequently apply a uniform token selection strategy across different inputs for batch training or optimize efficiency only for the inference stage. To overcome these challenges, we propose a novel algorithm: Select and Pack Attention (SPA). SPA dynamically selects informative tokens using a low-cost gating layer supervised by selection labels and packs these tokens into new batches, enabling a variable number of tokens to be used in parallelized GPU batch training and inference. Extensive experiments across diverse datasets and computer vision tasks demonstrate that SPA delivers superior performance and efficiency, including a 0.6 mAP improvement in object detection and a 16.4% reduction in computational costs.</li>
</ul>

<h3>Title: On Positional Bias of Faithfulness for Long-form Summarization</h3>
<ul>
<li><strong>Authors: </strong>David Wan, Jesse Vig, Mohit Bansal, Shafiq Joty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23609">https://arxiv.org/abs/2410.23609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23609">https://arxiv.org/pdf/2410.23609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23609]] On Positional Bias of Faithfulness for Long-form Summarization(https://arxiv.org/abs/2410.23609)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often exhibit positional bias in long-context settings, under-attending to information in the middle of inputs. We investigate the presence of this bias in long-form summarization, its impact on faithfulness, and various techniques to mitigate this bias. To consistently evaluate faithfulness, we first compile a benchmark of eight human-annotated long-form summarization datasets and perform a meta-evaluation of faithfulness metrics. We show that LLM-based faithfulness metrics, though effective with full-context inputs, remain sensitive to document order, indicating positional bias. Analyzing LLM-generated summaries across six datasets, we find a "U-shaped" trend in faithfulness, where LLMs faithfully summarize the beginning and end of documents but neglect middle content. Perturbing document order similarly reveals models are less faithful when important documents are placed in the middle of the input. We find that this behavior is partly due to shifting focus with context length: as context increases, summaries become less faithful, but beyond a certain length, faithfulness improves as the model focuses on the end. Finally, we experiment with different generation techniques to reduce positional bias and find that prompting techniques effectively direct model attention to specific positions, whereas more sophisticated approaches offer limited improvements. Our data and code are available in this https URL.</li>
</ul>

<h3>Title: Identifiability Guarantees for Causal Disentanglement from Purely Observational Data</h3>
<ul>
<li><strong>Authors: </strong>Ryan Welch, Jiaqi Zhang, Caroline Uhler</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23620">https://arxiv.org/abs/2410.23620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23620">https://arxiv.org/pdf/2410.23620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23620]] Identifiability Guarantees for Causal Disentanglement from Purely Observational Data(https://arxiv.org/abs/2410.23620)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Causal disentanglement aims to learn about latent causal factors behind data, holding the promise to augment existing representation learning methods in terms of interpretability and extrapolation. Recent advances establish identifiability results assuming that interventions on (single) latent factors are available; however, it remains debatable whether such assumptions are reasonable due to the inherent nature of intervening on latent variables. Accordingly, we reconsider the fundamentals and ask what can be learned using just observational data. We provide a precise characterization of latent factors that can be identified in nonlinear causal models with additive Gaussian noise and linear mixing, without any interventions or graphical restrictions. In particular, we show that the causal variables can be identified up to a layer-wise transformation and that further disentanglement is not possible. We transform these theoretical results into a practical algorithm consisting of solving a quadratic program over the score estimation of the observed data. We provide simulation results to support our theoretical guarantees and demonstrate that our algorithm can derive meaningful causal representations from purely observational data.</li>
</ul>

<h3>Title: On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiufeng Song, Xiao Guo, Jiache Zhang, Qirui Li, Lei Bai, Xiaoming Liu, Guangtao Zhai, Xiaohong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23623">https://arxiv.org/abs/2410.23623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23623">https://arxiv.org/pdf/2410.23623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23623]] On Learning Multi-Modal Forgery Representation for Diffusion Generated Video Detection(https://arxiv.org/abs/2410.23623)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, diffusion</a></li>
<li><strong>Abstract: </strong>Large numbers of synthesized videos from diffusion models pose threats to information security and authenticity, leading to an increasing demand for generated content detection. However, existing video-level detection algorithms primarily focus on detecting facial forgeries and often fail to identify diffusion-generated content with a diverse range of semantics. To advance the field of video forensics, we propose an innovative algorithm named Multi-Modal Detection(MM-Det) for detecting diffusion-generated videos. MM-Det utilizes the profound perceptual and comprehensive abilities of Large Multi-modal Models (LMMs) by generating a Multi-Modal Forgery Representation (MMFR) from LMM's multi-modal space, enhancing its ability to detect unseen forgery content. Besides, MM-Det leverages an In-and-Across Frame Attention (IAFA) mechanism for feature augmentation in the spatio-temporal domain. A dynamic fusion strategy helps refine forgery representations for the fusion. Moreover, we construct a comprehensive diffusion video dataset, called Diffusion Video Forensics (DVF), across a wide range of forgery videos. MM-Det achieves state-of-the-art performance in DVF, demonstrating the effectiveness of our algorithm. Both source code and DVF are available at this https URL.</li>
</ul>

<h3>Title: EMGBench: Benchmarking Out-of-Distribution Generalization and Adaptation for Electromyography</h3>
<ul>
<li><strong>Authors: </strong>Jehan Yang, Maxwell Soh, Vivianna Lieu, Douglas J Weber, Zackory Erickson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23625">https://arxiv.org/abs/2410.23625</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23625">https://arxiv.org/pdf/2410.23625</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23625]] EMGBench: Benchmarking Out-of-Distribution Generalization and Adaptation for Electromyography(https://arxiv.org/abs/2410.23625)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces the first generalization and adaptation benchmark using machine learning for evaluating out-of-distribution performance of electromyography (EMG) classification algorithms. The ability of an EMG classifier to handle inputs drawn from a different distribution than the training distribution is critical for real-world deployment as a control interface. By predicting the user's intended gesture using EMG signals, we can create a wearable solution to control assistive technologies, such as computers, prosthetics, and mobile manipulator robots. This new out-of-distribution benchmark consists of two major tasks that have utility for building robust and adaptable control interfaces: 1) intersubject classification and 2) adaptation using train-test splits for time-series. This benchmark spans nine datasets--the largest collection of EMG datasets in a benchmark. Among these, a new dataset is introduced, featuring a novel, easy-to-wear high-density EMG wearable for data collection. The lack of open-source benchmarks has made comparing accuracy results between papers challenging for the EMG research community. This new benchmark provides researchers with a valuable resource for analyzing practical measures of out-of-distribution performance for EMG datasets. Our code and data from our new dataset can be found at this http URL.</li>
</ul>

<h3>Title: Posture-Informed Muscular Force Learning for Robust Hand Pressure Estimation</h3>
<ul>
<li><strong>Authors: </strong>Kyungjin Seo, Junghoon Seo, Hanseok Jeong, Sangpil Kim, Sang Ho Yoon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23629">https://arxiv.org/abs/2410.23629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23629">https://arxiv.org/pdf/2410.23629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23629]] Posture-Informed Muscular Force Learning for Robust Hand Pressure Estimation(https://arxiv.org/abs/2410.23629)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present PiMForce, a novel framework that enhances hand pressure estimation by leveraging 3D hand posture information to augment forearm surface electromyography (sEMG) signals. Our approach utilizes detailed spatial information from 3D hand poses in conjunction with dynamic muscle activity from sEMG to enable accurate and robust whole-hand pressure measurements under diverse hand-object interactions. We also developed a multimodal data collection system that combines a pressure glove, an sEMG armband, and a markerless finger-tracking module. We created a comprehensive dataset from 21 participants, capturing synchronized data of hand posture, sEMG signals, and exerted hand pressure across various hand postures and hand-object interaction scenarios using our collection system. Our framework enables precise hand pressure estimation in complex and natural interaction scenarios. Our approach substantially mitigates the limitations of traditional sEMG-based or vision-based methods by integrating 3D hand posture information with sEMG signals. Video demos, data, and code are available online.</li>
</ul>

<h3>Title: Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction</h3>
<ul>
<li><strong>Authors: </strong>Guan-Hua Huang, Wan-Chen Lai, Tai-Been Chen, Chien-Chin Hsu, Huei-Yung Chen, Yi-Chen Wu, Li-Ren Yeh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23649">https://arxiv.org/abs/2410.23649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23649">https://arxiv.org/pdf/2410.23649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23649]] Deep Convolutional Neural Networks on Multiclass Classification of Three-Dimensional Brain Images for Parkinson's Disease Stage Prediction(https://arxiv.org/abs/2410.23649)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease (PD), a degenerative disorder of the central nervous system, is commonly diagnosed using functional medical imaging techniques such as single-photon emission computed tomography (SPECT). In this study, we utilized two SPECT data sets (n = 634 and n = 202) from different hospitals to develop a model capable of accurately predicting PD stages, a multiclass classification task. We used the entire three-dimensional (3D) brain images as input and experimented with various model architectures. Initially, we treated the 3D images as sequences of two-dimensional (2D) slices and fed them sequentially into 2D convolutional neural network (CNN) models pretrained on ImageNet, averaging the outputs to obtain the final predicted stage. We also applied 3D CNN models pretrained on Kinetics-400. Additionally, we incorporated an attention mechanism to account for the varying importance of different slices in the prediction process. To further enhance model efficacy and robustness, we simultaneously trained the two data sets using weight sharing, a technique known as cotraining. Our results demonstrated that 2D models pretrained on ImageNet outperformed 3D models pretrained on Kinetics-400, and models utilizing the attention mechanism outperformed both 2D and 3D models. The cotraining technique proved effective in improving model performance when the cotraining data sets were sufficiently large.</li>
</ul>

<h3>Title: Local Superior Soups: A Catalyst for Model Merging in Cross-Silo Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Minghui Chen, Meirui Jiang, Xin Zhang, Qi Dou, Zehua Wang, Xiaoxiao Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23660">https://arxiv.org/abs/2410.23660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23660">https://arxiv.org/pdf/2410.23660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23660]] Local Superior Soups: A Catalyst for Model Merging in Cross-Silo Federated Learning(https://arxiv.org/abs/2410.23660)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) is a learning paradigm that enables collaborative training of models using decentralized data. Recently, the utilization of pre-trained weight initialization in FL has been demonstrated to effectively improve model performance. However, the evolving complexity of current pre-trained models, characterized by a substantial increase in parameters, markedly intensifies the challenges associated with communication rounds required for their adaptation to FL. To address these communication cost issues and increase the performance of pre-trained model adaptation in FL, we propose an innovative model interpolation-based local training technique called ``Local Superior Soups.'' Our method enhances local training across different clients, encouraging the exploration of a connected low-loss basin within a few communication rounds through regularized model interpolation. This approach acts as a catalyst for the seamless adaptation of pre-trained models in in FL. We demonstrated its effectiveness and efficiency across diverse widely-used FL datasets. Our code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: DIP: Diffusion Learning of Inconsistency Pattern for General DeepFake Detection</h3>
<ul>
<li><strong>Authors: </strong>Fan Nie, Jiangqun Ni, Jian Zhang, Bin Zhang, Weizhe Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23663">https://arxiv.org/abs/2410.23663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23663">https://arxiv.org/pdf/2410.23663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23663]] DIP: Diffusion Learning of Inconsistency Pattern for General DeepFake Detection(https://arxiv.org/abs/2410.23663)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>With the advancement of deepfake generation techniques, the importance of deepfake detection in protecting multimedia content integrity has become increasingly obvious. Recently, temporal inconsistency clues have been explored to improve the generalizability of deepfake video detection. According to our observation, the temporal artifacts of forged videos in terms of motion information usually exhibits quite distinct inconsistency patterns along horizontal and vertical directions, which could be leveraged to improve the generalizability of detectors. In this paper, a transformer-based framework for Diffusion Learning of Inconsistency Pattern (DIP) is proposed, which exploits directional inconsistencies for deepfake video detection. Specifically, DIP begins with a spatiotemporal encoder to represent spatiotemporal information. A directional inconsistency decoder is adopted accordingly, where direction-aware attention and inconsistency diffusion are incorporated to explore potential inconsistency patterns and jointly learn the inherent relationships. In addition, the SpatioTemporal Invariant Loss (STI Loss) is introduced to contrast spatiotemporally augmented sample pairs and prevent the model from overfitting nonessential forgery artifacts. Extensive experiments on several public datasets demonstrate that our method could effectively identify directional forgery clues and achieve state-of-the-art performance.</li>
</ul>

<h3>Title: Web-Scale Visual Entity Recognition: An LLM-Driven Data Approach</h3>
<ul>
<li><strong>Authors: </strong>Mathilde Caron, Alireza Fathi, Cordelia Schmid, Ahmet Iscen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23676">https://arxiv.org/abs/2410.23676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23676">https://arxiv.org/pdf/2410.23676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23676]] Web-Scale Visual Entity Recognition: An LLM-Driven Data Approach(https://arxiv.org/abs/2410.23676)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Web-scale visual entity recognition, the task of associating images with their corresponding entities within vast knowledge bases like Wikipedia, presents significant challenges due to the lack of clean, large-scale training data. In this paper, we propose a novel methodology to curate such a dataset, leveraging a multimodal large language model (LLM) for label verification, metadata generation, and rationale explanation. Instead of relying on the multimodal LLM to directly annotate data, which we found to be suboptimal, we prompt it to reason about potential candidate entity labels by accessing additional contextually relevant information (such as Wikipedia), resulting in more accurate annotations. We further use the multimodal LLM to enrich the dataset by generating question-answer pairs and a grounded finegrained textual description (referred to as "rationale") that explains the connection between images and their assigned entities. Experiments demonstrate that models trained on this automatically curated data achieve state-of-the-art performance on web-scale visual entity recognition tasks (e.g. +6.9% improvement in OVEN entity task), underscoring the importance of high-quality training data in this domain.</li>
</ul>

<h3>Title: Pseudo-Conversation Injection for LLM Goal Hijacking</h3>
<ul>
<li><strong>Authors: </strong>Zheng Chen, Buhui Yao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23678">https://arxiv.org/abs/2410.23678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23678">https://arxiv.org/pdf/2410.23678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23678]] Pseudo-Conversation Injection for LLM Goal Hijacking(https://arxiv.org/abs/2410.23678)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Goal hijacking is a type of adversarial attack on Large Language Models (LLMs) where the objective is to manipulate the model into producing a specific, predetermined output, regardless of the user's original input. In goal hijacking, an attacker typically appends a carefully crafted malicious suffix to the user's prompt, which coerces the model into ignoring the user's original input and generating the target response. In this paper, we introduce a novel goal hijacking attack method called Pseudo-Conversation Injection, which leverages the weaknesses of LLMs in role identification within conversation contexts. Specifically, we construct the suffix by fabricating responses from the LLM to the user's initial prompt, followed by a prompt for a malicious new task. This leads the model to perceive the initial prompt and fabricated response as a completed conversation, thereby executing the new, falsified prompt. Following this approach, we propose three Pseudo-Conversation construction strategies: Targeted Pseudo-Conversation, Universal Pseudo-Conversation, and Robust Pseudo-Conversation. These strategies are designed to achieve effective goal hijacking across various scenarios. Our experiments, conducted on two mainstream LLM platforms including ChatGPT and Qwen, demonstrate that our proposed method significantly outperforms existing approaches in terms of attack effectiveness.</li>
</ul>

<h3>Title: Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Chiyu Zhang, Xiaogang Xu, Jiafei Wu, Zhe Liu, Lu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23687">https://arxiv.org/abs/2410.23687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23687">https://arxiv.org/pdf/2410.23687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23687]] Adversarial Attacks of Vision Tasks in the Past 10 Years: A Survey(https://arxiv.org/abs/2410.23687)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial attacks, which manipulate input data to undermine model availability and integrity, pose significant security threats during machine learning inference. With the advent of Large Vision-Language Models (LVLMs), new attack vectors, such as cognitive bias, prompt injection, and jailbreak techniques, have emerged. Understanding these attacks is crucial for developing more robust systems and demystifying the inner workings of neural networks. However, existing reviews often focus on attack classifications and lack comprehensive, in-depth analysis. The research community currently needs: 1) unified insights into adversariality, transferability, and generalization; 2) detailed evaluations of existing methods; 3) motivation-driven attack categorizations; and 4) an integrated perspective on both traditional and LVLM attacks. This article addresses these gaps by offering a thorough summary of traditional and LVLM adversarial attacks, emphasizing their connections and distinctions, and providing actionable insights for future research.</li>
</ul>

<h3>Title: Automatically Learning Hybrid Digital Twins of Dynamical Systems</h3>
<ul>
<li><strong>Authors: </strong>Samuel Holt, Tennison Liu, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23691">https://arxiv.org/abs/2410.23691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23691">https://arxiv.org/pdf/2410.23691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23691]] Automatically Learning Hybrid Digital Twins of Dynamical Systems(https://arxiv.org/abs/2410.23691)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Digital Twins (DTs) are computational models that simulate the states and temporal dynamics of real-world systems, playing a crucial role in prediction, understanding, and decision-making across diverse domains. However, existing approaches to DTs often struggle to generalize to unseen conditions in data-scarce settings, a crucial requirement for such models. To address these limitations, our work begins by establishing the essential desiderata for effective DTs. Hybrid Digital Twins ($\textbf{HDTwins}$) represent a promising approach to address these requirements, modeling systems using a composition of both mechanistic and neural components. This hybrid architecture simultaneously leverages (partial) domain knowledge and neural network expressiveness to enhance generalization, with its modular design facilitating improved evolvability. While existing hybrid models rely on expert-specified architectures with only parameters optimized on data, $\textit{automatically}$ specifying and optimizing HDTwins remains intractable due to the complex search space and the need for flexible integration of domain priors. To overcome this complexity, we propose an evolutionary algorithm ($\textbf{HDTwinGen}$) that employs Large Language Models (LLMs) to autonomously propose, evaluate, and optimize HDTwins. Specifically, LLMs iteratively generate novel model specifications, while offline tools are employed to optimize emitted parameters. Correspondingly, proposed models are evaluated and evolved based on targeted feedback, enabling the discovery of increasingly effective hybrid models. Our empirical results reveal that HDTwinGen produces generalizable, sample-efficient, and evolvable models, significantly advancing DTs' efficacy in real-world applications.</li>
</ul>

<h3>Title: Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction</h3>
<ul>
<li><strong>Authors: </strong>Peizhi Tang, Chuang Yang, Tong Xing, Xiaohang Xu, Renhe Jiang, Kaoru Sezaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23692">https://arxiv.org/abs/2410.23692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23692">https://arxiv.org/pdf/2410.23692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23692]] Instruction-Tuning Llama-3-8B Excels in City-Scale Mobility Prediction(https://arxiv.org/abs/2410.23692)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human mobility prediction plays a critical role in applications such as disaster response, urban planning, and epidemic forecasting. Traditional methods often rely on designing crafted, domain-specific models, and typically focus on short-term predictions, which struggle to generalize across diverse urban environments. In this study, we introduce Llama-3-8B-Mob, a large language model fine-tuned with instruction tuning, for long-term citywide mobility prediction -- in a Q&A manner. We validate our approach using large-scale human mobility data from four metropolitan areas in Japan, focusing on predicting individual trajectories over the next 15 days. The results demonstrate that Llama-3-8B-Mob excels in modeling long-term human mobility -- surpassing the state-of-the-art on multiple prediction metrics. It also displays strong zero-shot generalization capabilities -- effectively generalizing to other cities even when fine-tuned only on limited samples from a single city. Source codes are available at this https URL.</li>
</ul>

<h3>Title: Zero-shot Class Unlearning via Layer-wise Relevance Analysis and Neuronal Path Perturbation</h3>
<ul>
<li><strong>Authors: </strong>Wenhan Chang, Tianqing Zhu, Yufeng Wu, Wanlei Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23693">https://arxiv.org/abs/2410.23693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23693">https://arxiv.org/pdf/2410.23693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23693]] Zero-shot Class Unlearning via Layer-wise Relevance Analysis and Neuronal Path Perturbation(https://arxiv.org/abs/2410.23693)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>In the rapid advancement of artificial intelligence, privacy protection has become crucial, giving rise to machine unlearning. Machine unlearning is a technique that removes specific data influences from trained models without the need for extensive retraining. However, it faces several key challenges, including accurately implementing unlearning, ensuring privacy protection during the unlearning process, and achieving effective unlearning without significantly compromising model performance. This paper presents a novel approach to machine unlearning by employing Layer-wise Relevance Analysis and Neuronal Path Perturbation. We address three primary challenges: the lack of detailed unlearning principles, privacy guarantees in zero-shot unlearning scenario, and the balance between unlearning effectiveness and model utility. Our method balances machine unlearning performance and model utility by identifying and perturbing highly relevant neurons, thereby achieving effective unlearning. By using data not present in the original training set during the unlearning process, we satisfy the zero-shot unlearning scenario and ensure robust privacy protection. Experimental results demonstrate that our approach effectively removes targeted data from the target unlearning model while maintaining the model's utility, offering a practical solution for privacy-preserving machine learning.</li>
</ul>

<h3>Title: OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junda Wu, Xintong Li, Ruoyu Wang, Yu Xia, Yuxin Xiong, Jianing Wang, Tong Yu, Xiang Chen, Branislav Kveton, Lina Yao, Jingbo Shang, Julian McAuley</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23703">https://arxiv.org/abs/2410.23703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23703">https://arxiv.org/pdf/2410.23703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23703]] OCEAN: Offline Chain-of-thought Evaluation and Alignment in Large Language Models(https://arxiv.org/abs/2410.23703)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Offline evaluation of LLMs is crucial in understanding their capacities, though current methods remain underexplored in existing research. In this work, we focus on the offline evaluation of the chain-of-thought capabilities and show how to optimize LLMs based on the proposed evaluation method. To enable offline feedback with rich knowledge and reasoning paths, we use knowledge graphs (e.g., Wikidata5m) to provide feedback on the generated chain of thoughts. Due to the heterogeneity between LLM reasoning and KG structures, direct interaction and feedback from KGs on LLM behavior are challenging, as they require accurate entity linking and grounding of LLM-generated chains of thought in the KG. To address the above challenge, we propose an offline chain-of-thought evaluation framework, OCEAN, which models chain-of-thought reasoning in LLMs as an MDP and evaluate the policy's alignment with KG preference modeling. To overcome the reasoning heterogeneity and grounding problems, we leverage on-policy KG exploration and RL to model a KG policy that generates token-level likelihood distributions for LLM-generated chain-of-thought reasoning paths, simulating KG reasoning preference. Then we incorporate the knowledge-graph feedback on the validity and alignment of the generated reasoning paths into inverse propensity scores and propose KG-IPS estimator. Theoretically, we prove the unbiasedness of the proposed KG-IPS estimator and provide a lower bound on its variance. With the off-policy evaluated value function, we can directly enable off-policy optimization to further enhance chain-of-thought alignment. Our empirical study shows that OCEAN can be efficiently optimized for generating chain-of-thought reasoning paths with higher estimated values without affecting LLMs' general abilities in downstream tasks or their internal knowledge.</li>
</ul>

<h3>Title: GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Xiufeng Huang, Ruiqi Li, Yiu-ming Cheung, Ka Chun Cheung, Simon See, Renjie Wan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23718">https://arxiv.org/abs/2410.23718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23718">https://arxiv.org/pdf/2410.23718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23718]] GaussianMarker: Uncertainty-Aware Copyright Protection of 3D Gaussian Splatting(https://arxiv.org/abs/2410.23718)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, watermark</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has become a crucial method for acquiring 3D assets. To protect the copyright of these assets, digital watermarking techniques can be applied to embed ownership information discreetly within 3DGS models. However, existing watermarking methods for meshes, point clouds, and implicit radiance fields cannot be directly applied to 3DGS models, as 3DGS models use explicit 3D Gaussians with distinct structures and do not rely on neural networks. Naively embedding the watermark on a pre-trained 3DGS can cause obvious distortion in rendered images. In our work, we propose an uncertainty-based method that constrains the perturbation of model parameters to achieve invisible watermarking for 3DGS. At the message decoding stage, the copyright messages can be reliably extracted from both 3D Gaussians and 2D rendered images even under various forms of 3D and 2D distortions. We conduct extensive experiments on the Blender, LLFF and MipNeRF-360 datasets to validate the effectiveness of our proposed method, demonstrating state-of-the-art performance on both message decoding accuracy and view synthesis quality.</li>
</ul>

<h3>Title: An Empirical Analysis of GPT-4V's Performance on Fashion Aesthetic Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yuki Hirakawa, Takashi Wada, Kazuya Morishita, Ryotaro Shimizu, Takuya Furusawa, Sai Htaung Kham, Yuki Saito</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23730">https://arxiv.org/abs/2410.23730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23730">https://arxiv.org/pdf/2410.23730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23730]] An Empirical Analysis of GPT-4V's Performance on Fashion Aesthetic Evaluation(https://arxiv.org/abs/2410.23730)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fashion aesthetic evaluation is the task of estimating how well the outfits worn by individuals in images suit them. In this work, we examine the zero-shot performance of GPT-4V on this task for the first time. We show that its predictions align fairly well with human judgments on our datasets, and also find that it struggles with ranking outfits in similar colors. The code is available at this https URL.</li>
</ul>

<h3>Title: MoTaDual: Modality-Task Dual Alignment for Enhanced Zero-shot Composed Image Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Haiwen Li, Fei Su, Zhicheng Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23736">https://arxiv.org/abs/2410.23736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23736">https://arxiv.org/pdf/2410.23736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23736]] MoTaDual: Modality-Task Dual Alignment for Enhanced Zero-shot Composed Image Retrieval(https://arxiv.org/abs/2410.23736)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Composed Image Retrieval (CIR) is a challenging vision-language task, utilizing bi-modal (image+text) queries to retrieve target images. Despite the impressive performance of supervised CIR, the dependence on costly, manually-labeled triplets limits its scalability and zero-shot capability. To address this issue, zero-shot composed image retrieval (ZS-CIR) is presented along with projection-based approaches. However, such methods face two major problems, i.e., task discrepancy between pre-training (image $\leftrightarrow$ text) and inference (image+text $\rightarrow$ image), and modality discrepancy. The latter pertains to approaches based on text-only projection training due to the necessity of feature extraction from the reference image during inference. In this paper, we propose a two-stage framework to tackle both discrepancies. First, to ensure efficiency and scalability, a textual inversion network is pre-trained on large-scale caption datasets. Subsequently, we put forward Modality-Task Dual Alignment (MoTaDual) as the second stage, where large-language models (LLMs) generate triplet data for fine-tuning, and additionally, prompt learning is introduced in a multi-modal context to effectively alleviate both modality and task discrepancies. The experimental results show that our MoTaDual achieves the state-of-the-art performance across four widely used ZS-CIR benchmarks, while maintaining low training time and computational cost. The code will be released soon.</li>
</ul>

<h3>Title: What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective</h3>
<ul>
<li><strong>Authors: </strong>Ming Li, Yanhong Li, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23743">https://arxiv.org/abs/2410.23743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23743">https://arxiv.org/pdf/2410.23743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23743]] What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective(https://arxiv.org/abs/2410.23743)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>What makes a difference in the post-training of LLMs? We investigate the training patterns of different layers in large language models (LLMs), through the lens of gradient, when training with different responses and initial models. We are specifically interested in how fast vs. slow thinking affects the layer-wise gradients, given the recent popularity of training LLMs on reasoning paths such as chain-of-thoughts (CoT) and process rewards. In our study, fast thinking without CoT leads to larger gradients and larger differences of gradients across layers than slow thinking (Detailed CoT), indicating the learning stability brought by the latter. Moreover, pre-trained LLMs are less affected by the instability of fast thinking than instruction-tuned LLMs. Additionally, we study whether the gradient patterns can reflect the correctness of responses when training different LLMs using slow vs. fast thinking paths. The results show that the gradients of slow thinking can distinguish correct and irrelevant reasoning paths. As a comparison, we conduct similar gradient analyses on non-reasoning knowledge learning tasks, on which, however, trivially increasing the response length does not lead to similar behaviors of slow thinking. Our study strengthens fundamental understandings of LLM training and sheds novel insights on its efficiency and stability, which pave the way towards building a generalizable System-2 agent. Our code, data, and gradient statistics can be found in: this https URL.</li>
</ul>

<h3>Title: EchoNarrator: Generating natural text explanations for ejection fraction predictions</h3>
<ul>
<li><strong>Authors: </strong>Sarina Thomas, Qing Cao, Anna Novikova, Daria Kulikova, Guy Ben-Yosef</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23744">https://arxiv.org/abs/2410.23744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23744">https://arxiv.org/pdf/2410.23744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23744]] EchoNarrator: Generating natural text explanations for ejection fraction predictions(https://arxiv.org/abs/2410.23744)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ejection fraction (EF) of the left ventricle (LV) is considered as one of the most important measurements for diagnosing acute heart failure and can be estimated during cardiac ultrasound acquisition. While recent successes in deep learning research successfully estimate EF values, the proposed models often lack an explanation for the prediction. However, providing clear and intuitive explanations for clinical measurement predictions would increase the trust of cardiologists in these models. In this paper, we explore predicting EF measurements with Natural Language Explanation (NLE). We propose a model that in a single forward pass combines estimation of the LV contour over multiple frames, together with a set of modules and routines for computing various motion and shape attributes that are associated with ejection fraction. It then feeds the attributes into a large language model to generate text that helps to explain the network's outcome in a human-like manner. We provide experimental evaluation of our explanatory output, as well as EF prediction, and show that our model can provide EF comparable to state-of-the-art together with meaningful and accurate natural language explanation to the prediction. The project page can be found at this https URL .</li>
</ul>

<h3>Title: DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Junchao Wu, Runzhe Zhan, Derek F. Wong, Shu Yang, Xinyi Yang, Yulin Yuan, Lidia S. Chao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23746">https://arxiv.org/abs/2410.23746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23746">https://arxiv.org/pdf/2410.23746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23746]] DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios(https://arxiv.org/abs/2410.23746)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Detecting text generated by large language models (LLMs) is of great recent interest. With zero-shot methods like DetectGPT, detection capabilities have reached impressive levels. However, the reliability of existing detectors in real-world applications remains underexplored. In this study, we present a new benchmark, DetectRL, highlighting that even state-of-the-art (SOTA) detection techniques still underperformed in this task. We collected human-written datasets from domains where LLMs are particularly prone to misuse. Using popular LLMs, we generated data that better aligns with real-world applications. Unlike previous studies, we employed heuristic rules to create adversarial LLM-generated text, simulating advanced prompt usages, human revisions like word substitutions, and writing errors. Our development of DetectRL reveals the strengths and limitations of current SOTA detectors. More importantly, we analyzed the potential impact of writing styles, model types, attack methods, the text lengths, and real-world human writing factors on different types of detectors. We believe DetectRL could serve as an effective benchmark for assessing detectors in real-world scenarios, evolving with advanced attack methods, thus providing more stressful evaluation to drive the development of more efficient detectors. Data and code are publicly available at: this https URL.</li>
</ul>

<h3>Title: LSEAttention is All You Need for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Dizhen Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23749">https://arxiv.org/abs/2410.23749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23749">https://arxiv.org/pdf/2410.23749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23749]] LSEAttention is All You Need for Time Series Forecasting(https://arxiv.org/abs/2410.23749)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based architectures have achieved remarkable success in natural language processing and computer vision. However, their performance in multivariate long-term forecasting often lags behind simpler linear baselines. Previous studies have identified the traditional attention mechanism as a significant factor contributing to this limitation. To unlock the full potential of transformers for multivariate time series forecasting, I introduce \textbf{LSEAttention}, an approach designed to address entropy collapse and training instability commonly observed in transformer models. I validate the effectiveness of LSEAttention across various real-world multivariate time series datasets, demonstrating that it not only outperforms existing time series transformer models but also exceeds the performance of some state-of-the-art models on specific datasets.</li>
</ul>

<h3>Title: Open-Set 3D object detection in LiDAR data as an Out-of-Distribution problem</h3>
<ul>
<li><strong>Authors: </strong>Louis Soum-Fontez, Jean-Emmanuel Deschaud, François Goulette</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23767">https://arxiv.org/abs/2410.23767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23767">https://arxiv.org/pdf/2410.23767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23767]] Open-Set 3D object detection in LiDAR data as an Out-of-Distribution problem(https://arxiv.org/abs/2410.23767)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D Object Detection from LiDAR data has achieved industry-ready performance in controlled environments through advanced deep learning methods. However, these neural network models are limited by a finite set of inlier object categories. Our work redefines the open-set 3D Object Detection problem in LiDAR data as an Out-Of-Distribution (OOD) problem to detect outlier objects. This approach brings additional information in comparison with traditional object detection. We establish a comparative benchmark and show that two-stage OOD methods, notably autolabelling, show promising results for 3D OOD Object Detection. Our contributions include setting a rigorous evaluation protocol by examining the evaluation of hyperparameters and evaluating strategies for generating additional data to train an OOD-aware 3D object detector. This comprehensive analysis is essential for developing robust 3D object detection systems that can perform reliably in diverse and unpredictable real-world scenarios.</li>
</ul>

<h3>Title: The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams</h3>
<ul>
<li><strong>Authors: </strong>Yunqi Zhu, Wen Tang, Ying Sun, Xuebing Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23769">https://arxiv.org/abs/2410.23769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23769">https://arxiv.org/pdf/2410.23769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23769]] The Potential of LLMs in Medical Education: Generating Questions and Answers for Qualification Exams(https://arxiv.org/abs/2410.23769)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent research on large language models (LLMs) has primarily focused on their adaptation and application in specialized domains. The application of LLMs in the medical field is mainly concentrated on tasks such as the automation of medical report generation, summarization, diagnostic reasoning, and question-and-answer interactions between doctors and patients. The challenge of becoming a good teacher is more formidable than that of becoming a good student, and this study pioneers the application of LLMs in the field of medical education. In this work, we investigate the extent to which LLMs can generate medical qualification exam questions and corresponding answers based on few-shot prompts. Utilizing a real-world Chinese dataset of elderly chronic diseases, we tasked the LLMs with generating open-ended questions and answers based on a subset of sampled admission reports across eight widely used LLMs, including ERNIE 4, ChatGLM 4, Doubao, Hunyuan, Spark 4, Qwen, Llama 3, and Mistral. Furthermore, we engaged medical experts to manually evaluate these open-ended questions and answers across multiple dimensions. The study found that LLMs, after using few-shot prompts, can effectively mimic real-world medical qualification exam questions, whereas there is room for improvement in the correctness, evidence-based statements, and professionalism of the generated answers. Moreover, LLMs also demonstrate a decent level of ability to correct and rectify reference answers. Given the immense potential of artificial intelligence in the medical field, the task of generating questions and answers for medical qualification exams aimed at medical students, interns and residents can be a significant focus of future research.</li>
</ul>

<h3>Title: What is Wrong with Perplexity for Long-context Language Modeling?</h3>
<ul>
<li><strong>Authors: </strong>Lizhe Fang, Yifei Wang, Zhaoyang Liu, Chenheng Zhang, Stefanie Jegelka, Jinyang Gao, Bolin Ding, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23771">https://arxiv.org/abs/2410.23771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23771">https://arxiv.org/pdf/2410.23771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23771]] What is Wrong with Perplexity for Long-context Language Modeling?(https://arxiv.org/abs/2410.23771)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Handling long-context inputs is crucial for large language models (LLMs) in tasks such as extended conversations, document summarization, and many-shot in-context learning. While recent approaches have extended the context windows of LLMs and employed perplexity (PPL) as a standard evaluation metric, PPL has proven unreliable for assessing long-context capabilities. The underlying cause of this limitation has remained unclear. In this work, we provide a comprehensive explanation for this issue. We find that PPL overlooks key tokens, which are essential for long-context understanding, by averaging across all tokens and thereby obscuring the true performance of models in long-context scenarios. To address this, we propose \textbf{LongPPL}, a novel metric that focuses on key tokens by employing a long-short context contrastive method to identify them. Our experiments demonstrate that LongPPL strongly correlates with performance on various long-context benchmarks (e.g., Pearson correlation of -0.96), significantly outperforming traditional PPL in predictive accuracy. Additionally, we introduce \textbf{LongCE} (Long-context Cross-Entropy) loss, a re-weighting strategy for fine-tuning that prioritizes key tokens, leading to consistent improvements across diverse benchmarks. In summary, these contributions offer deeper insights into the limitations of PPL and present effective solutions for accurately evaluating and enhancing the long-context capabilities of LLMs. Code is available at this https URL.</li>
</ul>

<h3>Title: Towards Generative Ray Path Sampling for Faster Point-to-Point Ray Tracing</h3>
<ul>
<li><strong>Authors: </strong>Jérome Eertmans, Nicola Di Cicco, Claude Oestges, Laurent Jacques, Enrico M. Vittuci, Vittorio Degli-Esposti</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23773">https://arxiv.org/abs/2410.23773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23773">https://arxiv.org/pdf/2410.23773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23773]] Towards Generative Ray Path Sampling for Faster Point-to-Point Ray Tracing(https://arxiv.org/abs/2410.23773)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Radio propagation modeling is essential in telecommunication research, as radio channels result from complex interactions with environmental objects. Recently, Machine Learning has been attracting attention as a potential alternative to computationally demanding tools, like Ray Tracing, which can model these interactions in detail. However, existing Machine Learning approaches often attempt to learn directly specific channel characteristics, such as the coverage map, making them highly specific to the frequency and material properties and unable to fully capture the underlying propagation mechanisms. Hence, Ray Tracing, particularly the Point-to-Point variant, remains popular to accurately identify all possible paths between transmitter and receiver nodes. Still, path identification is computationally intensive because the number of paths to be tested grows exponentially while only a small fraction is valid. In this paper, we propose a Machine Learning-aided Ray Tracing approach to efficiently sample potential ray paths, significantly reducing the computational load while maintaining high accuracy. Our model dynamically learns to prioritize potentially valid paths among all possible paths and scales linearly with scene complexity. Unlike recent alternatives, our approach is invariant with translation, scaling, or rotation of the geometry, and avoids dependency on specific environment characteristics.</li>
</ul>

<h3>Title: In-Context LoRA for Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Lianghua Huang, Wei Wang, Zhi-Fan Wu, Yupeng Shi, Huanzhang Dou, Chen Liang, Yutong Feng, Yu Liu, Jingren Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23775">https://arxiv.org/abs/2410.23775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23775">https://arxiv.org/pdf/2410.23775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23775]] In-Context LoRA for Diffusion Transformers(https://arxiv.org/abs/2410.23775)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent research arXiv:2410.15027 has explored the use of diffusion transformers (DiTs) for task-agnostic image generation by simply concatenating attention tokens across images. However, despite substantial computational resources, the fidelity of the generated images remains suboptimal. In this study, we reevaluate and streamline this framework by hypothesizing that text-to-image DiTs inherently possess in-context generation capabilities, requiring only minimal tuning to activate them. Through diverse task experiments, we qualitatively demonstrate that existing text-to-image DiTs can effectively perform in-context generation without any tuning. Building on this insight, we propose a remarkably simple pipeline to leverage the in-context abilities of DiTs: (1) concatenate images instead of tokens, (2) perform joint captioning of multiple images, and (3) apply task-specific LoRA tuning using small datasets (e.g., $20\sim 100$ samples) instead of full-parameter tuning with large datasets. We name our models In-Context LoRA (IC-LoRA). This approach requires no modifications to the original DiT models, only changes to the training data. Remarkably, our pipeline generates high-fidelity image sets that better adhere to prompts. While task-specific in terms of tuning data, our framework remains task-agnostic in architecture and pipeline, offering a powerful tool for the community and providing valuable insights for further research on product-level task-agnostic generation systems. We release our code, data, and models at this https URL</li>
</ul>

<h3>Title: Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Chang, Maixuan Xue, Xinran Liu, Zheng Pan, Xing Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23780">https://arxiv.org/abs/2410.23780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23780">https://arxiv.org/pdf/2410.23780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23780]] Driving by the Rules: A Benchmark for Integrating Traffic Sign Regulations into Vectorized HD Map(https://arxiv.org/abs/2410.23780)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Ensuring adherence to traffic sign regulations is essential for both human and autonomous vehicle navigation. While current benchmark datasets concentrate on lane perception or basic traffic sign recognition, they often overlook the intricate task of integrating these regulations into lane operations. Addressing this gap, we introduce MapDR, a novel dataset designed for the extraction of Driving Rules from traffic signs and their association with vectorized, locally perceived HD Maps. MapDR features over 10,000 annotated video clips that capture the intricate correlation between traffic sign regulations and lanes. We define two pivotal sub-tasks: 1) Rule Extraction from Traffic Sign, which accurately deciphers regulatory instructions, and 2) Rule-Lane Correspondence Reasoning, which aligns these rules with their respective lanes. Built upon this benchmark, we provide a multimodal solution that offers a strong baseline for advancing autonomous driving technologies. It fills a critical gap in the integration of traffic sign rules, contributing to the development of reliable autonomous navigation systems.</li>
</ul>

<h3>Title: Video Token Merging for Long-form Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Seon-Ho Lee, Jue Wang, Zhikang Zhang, David Fan, Xinyu Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23782">https://arxiv.org/abs/2410.23782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23782">https://arxiv.org/pdf/2410.23782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23782]] Video Token Merging for Long-form Video Understanding(https://arxiv.org/abs/2410.23782)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>As the scale of data and models for video understanding rapidly expand, handling long-form video input in transformer-based models presents a practical challenge. Rather than resorting to input sampling or token dropping, which may result in information loss, token merging shows promising results when used in collaboration with transformers. However, the application of token merging for long-form video processing is not trivial. We begin with the premise that token merging should not rely solely on the similarity of video tokens; the saliency of tokens should also be considered. To address this, we explore various video token merging strategies for long-form video classification, starting with a simple extension of image token merging, moving to region-concentrated merging, and finally proposing a learnable video token merging (VTM) algorithm that dynamically merges tokens based on their saliency. Extensive experimental results show that we achieve better or comparable performances on the LVU, COIN, and Breakfast datasets. Moreover, our approach significantly reduces memory costs by 84% and boosts throughput by approximately 6.89 times compared to baseline algorithms.</li>
</ul>

<h3>Title: EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching</h3>
<ul>
<li><strong>Authors: </strong>Xinwang Chen, Ning Liu, Yichen Zhu, Feifei Feng, Jian Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23788">https://arxiv.org/abs/2410.23788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23788">https://arxiv.org/pdf/2410.23788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23788]] EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching(https://arxiv.org/abs/2410.23788)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based Diffusion Probabilistic Models (DPMs) have shown more potential than CNN-based DPMs, yet their extensive computational requirements hinder widespread practical applications. To reduce the computation budget of transformer-based DPMs, this work proposes the Efficient Diffusion Transformer (EDT) framework. The framework includes a lightweight-design diffusion model architecture, and a training-free Attention Modulation Matrix and its alternation arrangement in EDT inspired by human-like sketching. Additionally, we propose a token relation-enhanced masking training strategy tailored explicitly for EDT to augment its token relation learning capability. Our extensive experiments demonstrate the efficacy of EDT. The EDT framework reduces training and inference costs and surpasses existing transformer-based diffusion models in image synthesis performance, thereby achieving a significant overall enhancement. With lower FID, EDT-S, EDT-B, and EDT-XL attained speed-ups of 3.93x, 2.84x, and 1.92x respectively in the training phase, and 2.29x, 2.29x, and 2.22x respectively in inference, compared to the corresponding sizes of MDTv2. The source code is released at this https URL.</li>
</ul>

<h3>Title: SOAR: Self-Occluded Avatar Recovery from a Single Video In the Wild</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyang Pan, Angjoo Kanazawa, Hang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23800">https://arxiv.org/abs/2410.23800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23800">https://arxiv.org/pdf/2410.23800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23800]] SOAR: Self-Occluded Avatar Recovery from a Single Video In the Wild(https://arxiv.org/abs/2410.23800)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Self-occlusion is common when capturing people in the wild, where the performer do not follow predefined motion scripts. This challenges existing monocular human reconstruction systems that assume full body visibility. We introduce Self-Occluded Avatar Recovery (SOAR), a method for complete human reconstruction from partial observations where parts of the body are entirely unobserved. SOAR leverages structural normal prior and generative diffusion prior to address such an ill-posed reconstruction problem. For structural normal prior, we model human with an reposable surfel model with well-defined and easily readable shapes. For generative diffusion prior, we perform an initial reconstruction and refine it using score distillation. On various benchmarks, we show that SOAR performs favorably than state-of-the-art reconstruction and generation methods, and on-par comparing to concurrent works. Additional video results and code are available at this https URL.</li>
</ul>

<h3>Title: Human Action Recognition (HAR) Using Skeleton-based Quantum Spatial Temporal Relative Transformer Network: ST-RTR</h3>
<ul>
<li><strong>Authors: </strong>Faisal Mehmood, Enqing Chen, Touqeer Abbas, Samah M. Alzanin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23806">https://arxiv.org/abs/2410.23806</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23806">https://arxiv.org/pdf/2410.23806</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23806]] Human Action Recognition (HAR) Using Skeleton-based Quantum Spatial Temporal Relative Transformer Network: ST-RTR(https://arxiv.org/abs/2410.23806)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Quantum Human Action Recognition (HAR) is an interesting research area in human-computer interaction used to monitor the activities of elderly and disabled individuals affected by physical and mental health. In the recent era, skeleton-based HAR has received much attention because skeleton data has shown that it can handle changes in striking, body size, camera views, and complex backgrounds. One key characteristic of ST-GCN is automatically learning spatial and temporal patterns from skeleton sequences. It has some limitations, as this method only works for short-range correlation due to its limited receptive field. Consequently, understanding human action requires long-range interconnection. To address this issue, we developed a quantum spatial-temporal relative transformer ST-RTR model. The ST-RTR includes joint and relay nodes, which allow efficient communication and data transmission within the network. These nodes help to break the inherent spatial and temporal skeleton topologies, which enables the model to understand long-range human action better. Furthermore, we combine quantum ST-RTR with a fusion model for further performance improvements. To assess the performance of the quantum ST-RTR method, we conducted experiments on three skeleton-based HAR benchmarks: NTU RGB+D 60, NTU RGB+D 120, and UAV-Human. It boosted CS and CV by 2.11 % and 1.45% on NTU RGB+D 60, 1.25% and 1.05% on NTU RGB+D 120. On UAV-Human datasets, accuracy improved by 2.54%. The experimental outcomes explain that the proposed ST-RTR model significantly improves action recognition associated with the standard ST-GCN method.</li>
</ul>

<h3>Title: Graph Neural Networks Uncover Geometric Neural Representations in Reinforcement-Based Motor Learning</h3>
<ul>
<li><strong>Authors: </strong>Federico Nardi, Jinpei Han, Shlomi Haar, A.Aldo Faisal</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23812">https://arxiv.org/abs/2410.23812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23812">https://arxiv.org/pdf/2410.23812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23812]] Graph Neural Networks Uncover Geometric Neural Representations in Reinforcement-Based Motor Learning(https://arxiv.org/abs/2410.23812)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNN) can capture the geometric properties of neural representations in EEG data. Here we utilise those to study how reinforcement-based motor learning affects neural activity patterns during motor planning, leveraging the inherent graph structure of EEG channels to capture the spatial relationships in brain activity. By exploiting task-specific symmetries, we define different pretraining strategies that not only improve model performance across all participant groups but also validate the robustness of the geometric representations. Explainability analysis based on the graph structures reveals consistent group-specific neural signatures that persist across pretraining conditions, suggesting stable geometric structures in the neural representations associated with motor learning and feedback processing. These geometric patterns exhibit partial invariance to certain task space transformations, indicating symmetries that enable generalisation across conditions while maintaining specificity to individual learning strategies. This work demonstrates how GNNs can uncover the effects of previous outcomes on motor planning, in a complex real-world task, providing insights into the geometric principles governing neural representations. Our experimental design bridges the gap between controlled experiments and ecologically valid scenarios, offering new insights into the organisation of neural representations during naturalistic motor learning, which may open avenues for exploring fundamental principles governing brain activity in complex tasks.</li>
</ul>

<h3>Title: Weight decay induces low-rank attention layers</h3>
<ul>
<li><strong>Authors: </strong>Seijin Kobayashi, Yassir Akram, Johannes Von Oswald</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23819">https://arxiv.org/abs/2410.23819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23819">https://arxiv.org/pdf/2410.23819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23819]] Weight decay induces low-rank attention layers(https://arxiv.org/abs/2410.23819)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The effect of regularizers such as weight decay when training deep neural networks is not well understood. We study the influence of weight decay as well as $L2$-regularization when training neural network models in which parameter matrices interact multiplicatively. This combination is of particular interest as this parametrization is common in attention layers, the workhorse of transformers. Here, key-query, as well as value-projection parameter matrices, are multiplied directly with each other: $W_K^TW_Q$ and $PW_V$. We extend previous results and show on one hand that any local minimum of a $L2$-regularized loss of the form $L(AB^\top) + \lambda (\|A\|^2 + \|B\|^2)$ coincides with a minimum of the nuclear norm-regularized loss $L(AB^\top) + \lambda\|AB^\top\|_*$, and on the other hand that the 2 losses become identical exponentially quickly during training. We thus complement existing works linking $L2$-regularization with low-rank regularization, and in particular, explain why such regularization on the matrix product affects early stages of training. Based on these theoretical insights, we verify empirically that the key-query and value-projection matrix products $W_K^TW_Q, PW_V$ within attention layers, when optimized with weight decay, as usually done in vision tasks and language modelling, indeed induce a significant reduction in the rank of $W_K^TW_Q$ and $PW_V$, even in fully online training. We find that, in accordance with existing work, inducing low rank in attention matrix products can damage language model performance, and observe advantages when decoupling weight decay in attention layers from the rest of the parameters.</li>
</ul>

<h3>Title: Disentangling Disentangled Representations: Towards Improved Latent Units via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Youngjun Jun, Jiwoo Park, Kyobin Choo, Tae Eun Choi, Seong Jae Hwang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23820">https://arxiv.org/abs/2410.23820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23820">https://arxiv.org/pdf/2410.23820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23820]] Disentangling Disentangled Representations: Towards Improved Latent Units via Diffusion Models(https://arxiv.org/abs/2410.23820)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Disentangled representation learning (DRL) aims to break down observed data into core intrinsic factors for a profound understanding of the data. In real-world scenarios, manually defining and labeling these factors are non-trivial, making unsupervised methods attractive. Recently, there have been limited explorations of utilizing diffusion models (DMs), which are already mainstream in generative modeling, for unsupervised DRL. They implement their own inductive bias to ensure that each latent unit input to the DM expresses only one distinct factor. In this context, we design Dynamic Gaussian Anchoring to enforce attribute-separated latent units for more interpretable DRL. This unconventional inductive bias explicitly delineates the decision boundaries between attributes while also promoting the independence among latent units. Additionally, we also propose Skip Dropout technique, which easily modifies the denoising U-Net to be more DRL-friendly, addressing its uncooperative nature with the disentangling feature extractor. Our methods, which carefully consider the latent unit semantics and the distinct DM structure, enhance the practicality of DM-based disentangled representations, demonstrating state-of-the-art disentanglement performance on both synthetic and real data, as well as advantages in downstream tasks.</li>
</ul>

<h3>Title: Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding</h3>
<ul>
<li><strong>Authors: </strong>Jinlong He, Pengfei Li, Gang Liu, Shenjun Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23822">https://arxiv.org/abs/2410.23822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23822">https://arxiv.org/pdf/2410.23822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23822]] Parameter-Efficient Fine-Tuning Medical Multimodal Large Language Models for Medical Visual Grounding(https://arxiv.org/abs/2410.23822)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) inherit the superior text understanding capabilities of LLMs and extend these capabilities to multimodal scenarios. These models achieve excellent results in the general domain of multimodal tasks. However, in the medical domain, the substantial training costs and the requirement for extensive medical data pose challenges to the development of medical MLLMs. Furthermore, due to the free-text form of answers, tasks such as visual grounding that need to produce output in a prescribed form become difficult for MLLMs. So far, there have been no medical MLLMs works in medical visual grounding area. For the medical vision grounding task, which involves identifying locations in medical images based on short text descriptions, we propose Parameter-efficient Fine-tuning medical multimodal large language models for Medcial Visual Grounding (PFMVG). To validate the performance of the model, we evaluate it on a public benchmark dataset for medical visual grounding, where it achieves competitive results, and significantly outperforming GPT-4v. Our code will be open sourced after peer review.</li>
</ul>

<h3>Title: Generative AI-Powered Plugin for Robust Federated Learning in Heterogeneous IoT Networks</h3>
<ul>
<li><strong>Authors: </strong>Youngjoon Lee, Jinu Gong, Joonhyuk Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23824">https://arxiv.org/abs/2410.23824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23824">https://arxiv.org/pdf/2410.23824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23824]] Generative AI-Powered Plugin for Robust Federated Learning in Heterogeneous IoT Networks(https://arxiv.org/abs/2410.23824)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, generative</a></li>
<li><strong>Abstract: </strong>Federated learning enables edge devices to collaboratively train a global model while maintaining data privacy by keeping data localized. However, the Non-IID nature of data distribution across devices often hinders model convergence and reduces performance. In this paper, we propose a novel plugin for federated optimization techniques that approximates Non-IID data distributions to IID through generative AI-enhanced data augmentation and balanced sampling strategy. Key idea is to synthesize additional data for underrepresented classes on each edge device, leveraging generative AI to create a more balanced dataset across the FL network. Additionally, a balanced sampling approach at the central server selectively includes only the most IID-like devices, accelerating convergence while maximizing the global model's performance. Experimental results validate that our approach significantly improves convergence speed and robustness against data imbalance, establishing a flexible, privacy-preserving FL plugin that is applicable even in data-scarce environments.</li>
</ul>

<h3>Title: Stereo-Talker: Audio-driven 3D Human Synthesis with Prior-Guided Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Xiang Deng, Youxin Pang, Xiaochen Zhao, Chao Xu, Lizhen Wang, Hongjiang Xiao, Shi Yan, Hongwen Zhang, Yebin Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23836">https://arxiv.org/abs/2410.23836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23836">https://arxiv.org/pdf/2410.23836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23836]] Stereo-Talker: Audio-driven 3D Human Synthesis with Prior-Guided Mixture-of-Experts(https://arxiv.org/abs/2410.23836)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Stereo-Talker, a novel one-shot audio-driven human video synthesis system that generates 3D talking videos with precise lip synchronization, expressive body gestures, temporally consistent photo-realistic quality, and continuous viewpoint control. The process follows a two-stage approach. In the first stage, the system maps audio input to high-fidelity motion sequences, encompassing upper-body gestures and facial expressions. To enrich motion diversity and authenticity, large language model (LLM) priors are integrated with text-aligned semantic audio features, leveraging LLMs' cross-modal generalization power to enhance motion quality. In the second stage, we improve diffusion-based video generation models by incorporating a prior-guided Mixture-of-Experts (MoE) mechanism: a view-guided MoE focuses on view-specific attributes, while a mask-guided MoE enhances region-based rendering stability. Additionally, a mask prediction module is devised to derive human masks from motion data, enhancing the stability and accuracy of masks and enabling mask guiding during inference. We also introduce a comprehensive human video dataset with 2,203 identities, covering diverse body gestures and detailed annotations, facilitating broad generalization. The code, data, and pre-trained models will be released for research purposes.</li>
</ul>

<h3>Title: Commonsense Knowledge Editing Based on Free-Text in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xiusheng Huang, Yequan Wang, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23844">https://arxiv.org/abs/2410.23844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23844">https://arxiv.org/pdf/2410.23844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23844]] Commonsense Knowledge Editing Based on Free-Text in LLMs(https://arxiv.org/abs/2410.23844)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge editing technology is crucial for maintaining the accuracy and timeliness of large language models (LLMs) . However, the setting of this task overlooks a significant portion of commonsense knowledge based on free-text in the real world, characterized by broad knowledge scope, long content and non instantiation. The editing objects of previous methods (e.g., MEMIT) were single token or entity, which were not suitable for commonsense knowledge in free-text form. To address the aforementioned challenges, we conducted experiments from two perspectives: knowledge localization and knowledge editing. Firstly, we introduced Knowledge Localization for Free-Text(KLFT) method, revealing the challenges associated with the distribution of commonsense knowledge in MLP and Attention layers, as well as in decentralized distribution. Next, we propose a Dynamics-aware Editing Method(DEM), which utilizes a Dynamics-aware Module to locate the parameter positions corresponding to commonsense knowledge, and uses Knowledge Editing Module to update knowledge. The DEM method fully explores the potential of the MLP and Attention layers, and successfully edits commonsense knowledge based on free-text. The experimental results indicate that the DEM can achieve excellent editing performance.</li>
</ul>

<h3>Title: RAGraph: A General Retrieval-Augmented Graph Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Xinke Jiang, Rihong Qiu, Yongxin Xu, Wentao Zhang, Yichen Zhu, Ruizhe Zhang, Yuchen Fang, Xu Chu, Junfeng Zhao, Yasha Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23855">https://arxiv.org/abs/2410.23855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23855">https://arxiv.org/pdf/2410.23855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23855]] RAGraph: A General Retrieval-Augmented Graph Learning Framework(https://arxiv.org/abs/2410.23855)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have become essential in interpreting relational data across various domains, yet, they often struggle to generalize to unseen graph data that differs markedly from training instances. In this paper, we introduce a novel framework called General Retrieval-Augmented Graph Learning (RAGraph), which brings external graph data into the general graph foundation model to improve model generalization on unseen scenarios. On the top of our framework is a toy graph vector library that we established, which captures key attributes, such as features and task-specific label information. During inference, the RAGraph adeptly retrieves similar toy graphs based on key similarities in downstream tasks, integrating the retrieved data to enrich the learning context via the message-passing prompting mechanism. Our extensive experimental evaluations demonstrate that RAGraph significantly outperforms state-of-the-art graph learning methods in multiple tasks such as node classification, link prediction, and graph classification across both dynamic and static datasets. Furthermore, extensive testing confirms that RAGraph consistently maintains high performance without the need for task-specific fine-tuning, highlighting its adaptability, robustness, and broad applicability.</li>
</ul>

<h3>Title: Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?</h3>
<ul>
<li><strong>Authors: </strong>Zhanke Zhou, Rong Tao, Jianing Zhu, Yiwen Luo, Zengmao Wang, Bo Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23856">https://arxiv.org/abs/2410.23856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23856">https://arxiv.org/pdf/2410.23856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23856]] Can Language Models Perform Robust Reasoning in Chain-of-thought Prompting with Noisy Rationales?(https://arxiv.org/abs/2410.23856)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates an under-explored challenge in large language models (LLMs): chain-of-thought prompting with noisy rationales, which include irrelevant or inaccurate reasoning thoughts within examples used for in-context learning. We construct NoRa dataset that is tailored to evaluate the robustness of reasoning in the presence of noisy rationales. Our findings on NoRa dataset reveal a prevalent vulnerability to such noise among current LLMs, with existing robust methods like self-correction and self-consistency showing limited efficacy. Notably, compared to prompting with clean rationales, base LLM drops by 1.4%-19.8% in accuracy with irrelevant thoughts and more drastically by 2.2%-40.4% with inaccurate thoughts. Addressing this challenge necessitates external supervision that should be accessible in practice. Here, we propose the method of contrastive denoising with noisy chain-of-thought (CD-CoT). It enhances LLMs' denoising-reasoning capabilities by contrasting noisy rationales with only one clean rationale, which can be the minimal requirement for denoising-purpose prompting. This method follows a principle of exploration and exploitation: (1) rephrasing and selecting rationales in the input space to achieve explicit denoising and (2) exploring diverse reasoning paths and voting on answers in the output space. Empirically, CD-CoT demonstrates an average improvement of 17.8% in accuracy over the base model and shows significantly stronger denoising capabilities than baseline methods. The source code is publicly available at: this https URL.</li>
</ul>

<h3>Title: Audio Is the Achilles' Heel: Red Teaming Audio Large Multimodal Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Yang, Lizhen Qu, Ehsan Shareghi, Gholamreza Haffari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23861">https://arxiv.org/abs/2410.23861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23861">https://arxiv.org/pdf/2410.23861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23861]] Audio Is the Achilles' Heel: Red Teaming Audio Large Multimodal Models(https://arxiv.org/abs/2410.23861)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Multimodal Models (LMMs) have demonstrated the ability to interact with humans under real-world conditions by combining Large Language Models (LLMs) and modality encoders to align multimodal information (visual and auditory) with text. However, such models raise new safety challenges of whether models that are safety-aligned on text also exhibit consistent safeguards for multimodal inputs. Despite recent safety-alignment research on vision LMMs, the safety of audio LMMs remains under-explored. In this work, we comprehensively red team the safety of five advanced audio LMMs under three settings: (i) harmful questions in both audio and text formats, (ii) harmful questions in text format accompanied by distracting non-speech audio, and (iii) speech-specific jailbreaks. Our results under these settings demonstrate that open-source audio LMMs suffer an average attack success rate of 69.14% on harmful audio questions, and exhibit safety vulnerabilities when distracted with non-speech audio noise. Our speech-specific jailbreaks on Gemini-1.5-Pro achieve an attack success rate of 70.67% on the harmful query benchmark. We provide insights on what could cause these reported safety-misalignments. Warning: this paper contains offensive examples.</li>
</ul>

<h3>Title: QuACK: A Multipurpose Queuing Algorithm for Cooperative $k$-Armed Bandits</h3>
<ul>
<li><strong>Authors: </strong>Benjamin Howson, Sarah Filippi, Ciara Pike-Burke</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23867">https://arxiv.org/abs/2410.23867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23867">https://arxiv.org/pdf/2410.23867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23867]] QuACK: A Multipurpose Queuing Algorithm for Cooperative $k$-Armed Bandits(https://arxiv.org/abs/2410.23867)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We study the cooperative stochastic $k$-armed bandit problem, where a network of $m$ agents collaborate to find the optimal action. In contrast to most prior work on this problem, which focuses on extending a specific algorithm to the multi-agent setting, we provide a black-box reduction that allows us to extend any single-agent bandit algorithm to the multi-agent setting. Under mild assumptions on the bandit environment, we prove that our reduction transfers the regret guarantees of the single-agent algorithm to the multi-agent setting. These guarantees are tight in subgaussian environments, in that using a near minimax optimal single-player algorithm is near minimax optimal in the multi-player setting up to an additive graph-dependent quantity. Our reduction and theoretical results are also general, and apply to many different bandit settings. By plugging in appropriate single-player algorithms, we can easily develop provably efficient algorithms for many multi-player settings such as heavy-tailed bandits, duelling bandits and bandits with local differential privacy, among others. Experimentally, our approach is competitive with or outperforms specialised multi-agent algorithms.</li>
</ul>

<h3>Title: Noise as a Double-Edged Sword: Reinforcement Learning Exploits Randomized Defenses in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Steve Bakos, Pooria Madani, Heidar Davoudi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23870">https://arxiv.org/abs/2410.23870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23870">https://arxiv.org/pdf/2410.23870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23870]] Noise as a Double-Edged Sword: Reinforcement Learning Exploits Randomized Defenses in Neural Networks(https://arxiv.org/abs/2410.23870)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>This study investigates a counterintuitive phenomenon in adversarial machine learning: the potential for noise-based defenses to inadvertently aid evasion attacks in certain scenarios. While randomness is often employed as a defensive strategy against adversarial examples, our research reveals that this approach can sometimes backfire, particularly when facing adaptive attackers using reinforcement learning (RL). Our findings show that in specific cases, especially with visually noisy classes, the introduction of noise in the classifier's confidence values can be exploited by the RL attacker, leading to a significant increase in evasion success rates. In some instances, the noise-based defense scenario outperformed other strategies by up to 20\% on a subset of classes. However, this effect was not consistent across all classifiers tested, highlighting the complexity of the interaction between noise-based defenses and different models. These results suggest that in some cases, noise-based defenses can inadvertently create an adversarial training loop beneficial to the RL attacker. Our study emphasizes the need for a more nuanced approach to defensive strategies in adversarial machine learning, particularly in safety-critical applications. It challenges the assumption that randomness universally enhances defense against evasion attacks and highlights the importance of considering adaptive, RL-based attackers when designing robust defense mechanisms.</li>
</ul>

<h3>Title: 'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue</h3>
<ul>
<li><strong>Authors: </strong>Rena Gao, Xuetong Wu, Siwen Luo, Caren Han, Feng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23883">https://arxiv.org/abs/2410.23883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23883">https://arxiv.org/pdf/2410.23883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23883]] 'No' Matters: Out-of-Distribution Detection in Multimodality Long Dialogue(https://arxiv.org/abs/2410.23883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Out-of-distribution (OOD) detection in multimodal contexts is essential for identifying deviations in combined inputs from different modalities, particularly in applications like open-domain dialogue systems or real-life dialogue interactions. This paper aims to improve the user experience that involves multi-round long dialogues by efficiently detecting OOD dialogues and images. We introduce a novel scoring framework named Dialogue Image Aligning and Enhancing Framework (DIAEF) that integrates the visual language models with the novel proposed scores that detect OOD in two key scenarios (1) mismatches between the dialogue and image input pair and (2) input pairs with previously unseen labels. Our experimental results, derived from various benchmarks, demonstrate that integrating image and multi-round dialogue OOD detection is more effective with previously unseen labels than using either modality independently. In the presence of mismatched pairs, our proposed score effectively identifies these mismatches and demonstrates strong robustness in long dialogues. This approach enhances domain-aware, adaptive conversational agents and establishes baselines for future studies.</li>
</ul>

<h3>Title: Failure Modes of LLMs for Causal Reasoning on Narratives</h3>
<ul>
<li><strong>Authors: </strong>Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary C. Lipton, Bryan Wilder</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23884">https://arxiv.org/abs/2410.23884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23884">https://arxiv.org/pdf/2410.23884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23884]] Failure Modes of LLMs for Causal Reasoning on Narratives(https://arxiv.org/abs/2410.23884)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we investigate the causal reasoning abilities of large language models (LLMs) through the representative problem of inferring causal relationships from narratives. We find that even state-of-the-art language models rely on unreliable shortcuts, both in terms of the narrative presentation and their parametric knowledge. For example, LLMs tend to determine causal relationships based on the topological ordering of events (i.e., earlier events cause later ones), resulting in lower performance whenever events are not narrated in their exact causal order. Similarly, we demonstrate that LLMs struggle with long-term causal reasoning and often fail when the narratives are long and contain many events. Additionally, we show LLMs appear to rely heavily on their parametric knowledge at the expense of reasoning over the provided narrative. This degrades their abilities whenever the narrative opposes parametric knowledge. We extensively validate these failure modes through carefully controlled synthetic experiments, as well as evaluations on real-world narratives. Finally, we observe that explicitly generating a causal graph generally improves performance while naive chain-of-thought is ineffective. Collectively, our results distill precise failure modes of current state-of-the-art models and can pave the way for future techniques to enhance causal reasoning in LLMs.</li>
</ul>

<h3>Title: Leveraging LLMs for MT in Crisis Scenarios: a blueprint for low-resource languages</h3>
<ul>
<li><strong>Authors: </strong>Séamus Lankford, Andy Way</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23890">https://arxiv.org/abs/2410.23890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23890">https://arxiv.org/pdf/2410.23890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23890]] Leveraging LLMs for MT in Crisis Scenarios: a blueprint for low-resource languages(https://arxiv.org/abs/2410.23890)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In an evolving landscape of crisis communication, the need for robust and adaptable Machine Translation (MT) systems is more pressing than ever, particularly for low-resource languages. This study presents a comprehensive exploration of leveraging Large Language Models (LLMs) and Multilingual LLMs (MLLMs) to enhance MT capabilities in such scenarios. By focusing on the unique challenges posed by crisis situations where speed, accuracy, and the ability to handle a wide range of languages are paramount, this research outlines a novel approach that combines the cutting-edge capabilities of LLMs with fine-tuning techniques and community-driven corpus development strategies. At the core of this study is the development and empirical evaluation of MT systems tailored for two low-resource language pairs, illustrating the process from initial model selection and fine-tuning through to deployment. Bespoke systems are developed and modelled on the recent Covid-19 pandemic. The research highlights the importance of community involvement in creating highly specialised, crisis-specific datasets and compares custom GPTs with NLLB-adapted MLLM models. It identifies fine-tuned MLLM models as offering superior performance compared with their LLM counterparts. A scalable and replicable model for rapid MT system development in crisis scenarios is outlined. Our approach enhances the field of humanitarian technology by offering a blueprint for developing multilingual communication systems during emergencies.</li>
</ul>

<h3>Title: DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Hamidreza Eivazi, André Hebenbrock, Raphael Ginster, Steffen Blömeke, Stefan Wittek, Christoph Hermann, Thomas S. Spengler, Thomas Turek, Andreas Rausch</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23893">https://arxiv.org/abs/2410.23893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23893">https://arxiv.org/pdf/2410.23893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23893]] DiffBatt: A Diffusion Model for Battery Degradation Prediction and Synthesis(https://arxiv.org/abs/2410.23893)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Battery degradation remains a critical challenge in the pursuit of green technologies and sustainable energy solutions. Despite significant research efforts, predicting battery capacity loss accurately remains a formidable task due to its complex nature, influenced by both aging and cycling behaviors. To address this challenge, we introduce a novel general-purpose model for battery degradation prediction and synthesis, DiffBatt. Leveraging an innovative combination of conditional and unconditional diffusion models with classifier-free guidance and transformer architecture, DiffBatt achieves high expressivity and scalability. DiffBatt operates as a probabilistic model to capture uncertainty in aging behaviors and a generative model to simulate battery degradation. The performance of the model excels in prediction tasks while also enabling the generation of synthetic degradation curves, facilitating enhanced model training by data augmentation. In the remaining useful life prediction task, DiffBatt provides accurate results with a mean RMSE of 196 cycles across all datasets, outperforming all other models and demonstrating superior generalizability. This work represents an important step towards developing foundational models for battery degradation.</li>
</ul>

<h3>Title: Metamorphic Malware Evolution: The Potential and Peril of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pooria Madani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23894">https://arxiv.org/abs/2410.23894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23894">https://arxiv.org/pdf/2410.23894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23894]] Metamorphic Malware Evolution: The Potential and Peril of Large Language Models(https://arxiv.org/abs/2410.23894)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Code metamorphism refers to a computer programming exercise wherein the program modifies its own code (partial or entire) consistently and automatically while retaining its core functionality. This technique is often used for online performance optimization and automated crash recovery in certain mission-critical applications. However, the technique has been misappropriated by malware creators to bypass signature-based detection measures instituted by anti-malware engines. However, current code mutation engines used by threat actors offer only a limited degree of mutation, which is frequently detectable via static code analysis. The advent of large language models (LLMs), such as ChatGPT 4.0 and Google Bard may lead to a significant evolution in this landscape. These models have demonstrated a level of algorithm comprehension and code synthesis capability that closely resembles human abilities. This advancement has sparked concerns among experts that such models could be exploited by threat actors to generate sophisticated metamorphic malware. This paper explores the potential of several prominent LLMs for software code mutation that may be used to reconstruct (with mutation) existing malware code bases or create new forms of embedded mutation engines for next-gen metamorphic malwares. In this work, we introduce a framework for creating self-testing program mutation engines based on LLM/Transformer-based models. The proposed framework serves as an essential tool in testing next-gen metamorphic malware detection engines.</li>
</ul>

<h3>Title: NeFF-BioNet: Crop Biomass Prediction from Point Cloud to Drone Imagery</h3>
<ul>
<li><strong>Authors: </strong>Xuesong Li, Zeeshan Hayder, Ali Zia, Connor Cassidy, Shiming Liu, Warwick Stiller, Eric Stone, Warren Conaty, Lars Petersson, Vivien Rolland</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23901">https://arxiv.org/abs/2410.23901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23901">https://arxiv.org/pdf/2410.23901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23901]] NeFF-BioNet: Crop Biomass Prediction from Point Cloud to Drone Imagery(https://arxiv.org/abs/2410.23901)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Crop biomass offers crucial insights into plant health and yield, making it essential for crop science, farming systems, and agricultural research. However, current measurement methods, which are labor-intensive, destructive, and imprecise, hinder large-scale quantification of this trait. To address this limitation, we present a biomass prediction network (BioNet), designed for adaptation across different data modalities, including point clouds and drone imagery. Our BioNet, utilizing a sparse 3D convolutional neural network (CNN) and a transformer-based prediction module, processes point clouds and other 3D data representations to predict biomass. To further extend BioNet for drone imagery, we integrate a neural feature field (NeFF) module, enabling 3D structure reconstruction and the transformation of 2D semantic features from vision foundation models into the corresponding 3D surfaces. For the point cloud modality, BioNet demonstrates superior performance on two public datasets, with an approximate 6.1% relative improvement (RI) over the state-of-the-art. In the RGB image modality, the combination of BioNet and NeFF achieves a 7.9% RI. Additionally, the NeFF-based approach utilizes inexpensive, portable drone-mounted cameras, providing a scalable solution for large field applications.</li>
</ul>

<h3>Title: Responsible Retrieval Augmented Generation for Climate Decision Making from Documents</h3>
<ul>
<li><strong>Authors: </strong>Matyas Juhasz, Kalyan Dutia, Henry Franks, Conor Delahunty, Patrick Fawbert Mills, Harrison Pim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23902">https://arxiv.org/abs/2410.23902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23902">https://arxiv.org/pdf/2410.23902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23902]] Responsible Retrieval Augmented Generation for Climate Decision Making from Documents(https://arxiv.org/abs/2410.23902)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Climate decision making is constrained by the complexity and inaccessibility of key information within lengthy, technical, and multi-lingual documents. Generative AI technologies offer a promising route for improving the accessibility of information contained within these documents, but suffer from limitations. These include (1) a tendency to hallucinate or mis-represent information, (2) difficulty in steering or guaranteeing properties of generated output, and (3) reduced performance in specific technical domains. To address these challenges, we introduce a novel evaluation framework with domain-specific dimensions tailored for climate-related documents. We then apply this framework to evaluate Retrieval-Augmented Generation (RAG) approaches and assess retrieval- and generation-quality within a prototype tool that answers questions about individual climate law and policy documents. In addition, we publish a human-annotated dataset and scalable automated evaluation tools, with the aim of facilitating broader adoption and robust assessment of these systems in the climate domain. Our findings highlight the key components of responsible deployment of RAG to enhance decision-making, while also providing insights into user experience (UX) considerations for safely deploying such systems to build trust with users in high-risk domains.</li>
</ul>

<h3>Title: EZ-HOI: VLM Adaptation via Guided Prompt Learning for Zero-Shot HOI Detection</h3>
<ul>
<li><strong>Authors: </strong>Qinqian Lei, Bo Wang, Robby T. Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23904">https://arxiv.org/abs/2410.23904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23904">https://arxiv.org/pdf/2410.23904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23904]] EZ-HOI: VLM Adaptation via Guided Prompt Learning for Zero-Shot HOI Detection(https://arxiv.org/abs/2410.23904)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting Human-Object Interactions (HOI) in zero-shot settings, where models must handle unseen classes, poses significant challenges. Existing methods that rely on aligning visual encoders with large Vision-Language Models (VLMs) to tap into the extensive knowledge of VLMs, require large, computationally expensive models and encounter training difficulties. Adapting VLMs with prompt learning offers an alternative to direct alignment. However, fine-tuning on task-specific datasets often leads to overfitting to seen classes and suboptimal performance on unseen classes, due to the absence of unseen class labels. To address these challenges, we introduce a novel prompt learning-based framework for Efficient Zero-Shot HOI detection (EZ-HOI). First, we introduce Large Language Model (LLM) and VLM guidance for learnable prompts, integrating detailed HOI descriptions and visual semantics to adapt VLMs to HOI tasks. However, because training datasets contain seen-class labels alone, fine-tuning VLMs on such datasets tends to optimize learnable prompts for seen classes instead of unseen ones. Therefore, we design prompt learning for unseen classes using information from related seen classes, with LLMs utilized to highlight the differences between unseen and related seen classes. Quantitative evaluations on benchmark datasets demonstrate that our EZ-HOI achieves state-of-the-art performance across various zero-shot settings with only 10.35% to 33.95% of the trainable parameters compared to existing methods. Code is available at this https URL.</li>
</ul>

<h3>Title: Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhang, Lei Cao, Jiayi Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23905">https://arxiv.org/abs/2410.23905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23905">https://arxiv.org/pdf/2410.23905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23905]] Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model(https://arxiv.org/abs/2410.23905)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Existing multi-modal image fusion methods fail to address the compound degradations presented in source images, resulting in fusion images plagued by noise, color bias, improper exposure, \textit{etc}. Additionally, these methods often overlook the specificity of foreground objects, weakening the salience of the objects of interest within the fused images. To address these challenges, this study proposes a novel interactive multi-modal image fusion framework based on the text-modulated diffusion model, called Text-DiFuse. First, this framework integrates feature-level information integration into the diffusion process, allowing adaptive degradation removal and multi-modal information fusion. This is the first attempt to deeply and explicitly embed information fusion within the diffusion process, effectively addressing compound degradation in image fusion. Second, by embedding the combination of the text and zero-shot location model into the diffusion fusion process, a text-controlled fusion re-modulation strategy is developed. This enables user-customized text control to improve fusion performance and highlight foreground objects in the fused images. Extensive experiments on diverse public datasets show that our Text-DiFuse achieves state-of-the-art fusion performance across various scenarios with complex degradation. Moreover, the semantic segmentation experiment validates the significant enhancement in semantic performance achieved by our text-controlled fusion re-modulation strategy. The code is publicly available at this https URL.</li>
</ul>

<h3>Title: IP-MOT: Instance Prompt Learning for Cross-Domain Multi-Object Tracking</h3>
<ul>
<li><strong>Authors: </strong>Run Luo, Zikai Song, Longze Chen, Yunshui Li, Min Yang, Wei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23907">https://arxiv.org/abs/2410.23907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23907">https://arxiv.org/pdf/2410.23907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23907]] IP-MOT: Instance Prompt Learning for Cross-Domain Multi-Object Tracking(https://arxiv.org/abs/2410.23907)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multi-Object Tracking (MOT) aims to associate multiple objects across video frames and is a challenging vision task due to inherent complexities in the tracking environment. Most existing approaches train and track within a single domain, resulting in a lack of cross-domain generalizability to data from other domains. While several works have introduced natural language representation to bridge the domain gap in visual tracking, these textual descriptions often provide too high-level a view and fail to distinguish various instances within the same class. In this paper, we address this limitation by developing IP-MOT, an end-to-end transformer model for MOT that operates without concrete textual descriptions. Our approach is underpinned by two key innovations: Firstly, leveraging a pre-trained vision-language model, we obtain instance-level pseudo textual descriptions via prompt-tuning, which are invariant across different tracking scenes; Secondly, we introduce a query-balanced strategy, augmented by knowledge distillation, to further boost the generalization capabilities of our model. Extensive experiments conducted on three widely used MOT benchmarks, including MOT17, MOT20, and DanceTrack, demonstrate that our approach not only achieves competitive performance on same-domain data compared to state-of-the-art models but also significantly improves the performance of query-based trackers by large margins for cross-domain inputs.</li>
</ul>

<h3>Title: BitStack: Fine-Grained Size Control for Compressed Large Language Models in Variable Memory Environments</h3>
<ul>
<li><strong>Authors: </strong>Xinghao Wang, Pengyu Wang, Bo Wang, Dong Zhang, Yunhua Zhou, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23918">https://arxiv.org/abs/2410.23918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23918">https://arxiv.org/pdf/2410.23918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23918]] BitStack: Fine-Grained Size Control for Compressed Large Language Models in Variable Memory Environments(https://arxiv.org/abs/2410.23918)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized numerous applications, yet their deployment remains challenged by memory constraints on local devices. While scaling laws have enhanced LLM capabilities, the primary bottleneck has shifted from \textit{capability} to \textit{availability}, emphasizing the need for efficient memory management. Traditional compression methods, such as quantization, often require predefined compression ratios and separate compression processes for each setting, complicating deployment in variable memory environments. In this paper, we introduce \textbf{BitStack}, a novel, training-free weight compression approach that enables megabyte-level trade-offs between memory usage and model performance. By leveraging weight decomposition, BitStack can dynamically adjust the model size with minimal transmission between running memory and storage devices. Our approach iteratively decomposes weight matrices while considering the significance of each parameter, resulting in an approximately 1-bit per parameter residual block in each decomposition iteration. These blocks are sorted and stacked in storage as basic transmission units, with different quantities loaded based on current memory availability. Extensive experiments across a wide range of tasks demonstrate that, despite offering fine-grained size control, BitStack consistently matches or surpasses strong quantization baselines, particularly at extreme compression ratios. To the best of our knowledge, this is the first decomposition-based method that effectively bridges the gap to practical compression techniques like quantization. Code is available at this https URL.</li>
</ul>

<h3>Title: Language Models can Self-Lengthen to Generate Long Texts</h3>
<ul>
<li><strong>Authors: </strong>Shanghaoran Quan, Tianyi Tang, Bowen Yu, An Yang, Dayiheng Liu, Bofei Gao, Jianhong Tu, Yichang Zhang, Jingren Zhou, Junyang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23933">https://arxiv.org/abs/2410.23933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23933">https://arxiv.org/pdf/2410.23933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23933]] Language Models can Self-Lengthen to Generate Long Texts(https://arxiv.org/abs/2410.23933)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have significantly enhanced their ability to process long contexts, yet a notable gap remains in generating long, aligned outputs. This limitation stems from a training gap where pre-training lacks effective instructions for long-text generation, and post-training data primarily consists of short query-response pairs. Current approaches, such as instruction backtranslation and behavior imitation, face challenges including data quality, copyright issues, and constraints on proprietary model usage. In this paper, we introduce an innovative iterative training framework called Self-Lengthen that leverages only the intrinsic knowledge and skills of LLMs without the need for auxiliary data or proprietary models. The framework consists of two roles: the Generator and the Extender. The Generator produces the initial response, which is then split and expanded by the Extender. This process results in a new, longer response, which is used to train both the Generator and the Extender iteratively. Through this process, the models are progressively trained to handle increasingly longer responses. Experiments on benchmarks and human evaluations show that Self-Lengthen outperforms existing methods in long-text generation, when applied to top open-source LLMs such as Qwen2 and LLaMA3. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Robust Sparse Regression with Non-Isotropic Designs</h3>
<ul>
<li><strong>Authors: </strong>Chih-Hung Liu, Gleb Novikov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23937">https://arxiv.org/abs/2410.23937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23937">https://arxiv.org/pdf/2410.23937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23937]] Robust Sparse Regression with Non-Isotropic Designs(https://arxiv.org/abs/2410.23937)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We develop a technique to design efficiently computable estimators for sparse linear regression in the simultaneous presence of two adversaries: oblivious and adaptive. We design several robust algorithms that outperform the state of the art even in the special case when oblivious adversary simply adds Gaussian noise. In particular, we provide a polynomial-time algorithm that with high probability recovers the signal up to error $O(\sqrt{\varepsilon})$ as long as the number of samples $n \ge \tilde{O}(k^2/\varepsilon)$, only assuming some bounds on the third and the fourth moments of the distribution ${D}$ of the design. In addition, prior to this work, even in the special case of Gaussian design and noise, no polynomial time algorithm was known to achieve error $o(\sqrt{\varepsilon})$ in the sparse setting $n < d^2$. We show that under some assumptions on the fourth and the eighth moments of ${D}$, there is a polynomial-time algorithm that achieves error $o(\sqrt{\varepsilon})$ as long as $n \ge \tilde{O}(k^4 / \varepsilon^3)$. For Gaussian distribution, this algorithm achieves error $O(\varepsilon^{3/4})$. Moreover, our algorithm achieves error $o(\sqrt{\varepsilon})$ for all log-concave distributions if $\varepsilon \le 1/\text{polylog(d)}$. Our algorithms are based on the filtering of the covariates that uses sum-of-squares relaxations, and weighted Huber loss minimization with $\ell_1$ regularizer. We provide a novel analysis of weighted penalized Huber loss that is suitable for heavy-tailed designs in the presence of two adversaries. Furthermore, we complement our algorithmic results with Statistical Query lower bounds, providing evidence that our estimators are likely to have nearly optimal sample complexity.</li>
</ul>

<h3>Title: Learning Macroscopic Dynamics from Partial Microscopic Observations</h3>
<ul>
<li><strong>Authors: </strong>Mengyi Chen, Qianxiao Li</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23938">https://arxiv.org/abs/2410.23938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23938">https://arxiv.org/pdf/2410.23938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23938]] Learning Macroscopic Dynamics from Partial Microscopic Observations(https://arxiv.org/abs/2410.23938)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Macroscopic observables of a system are of keen interest in real applications such as the design of novel materials. Current methods rely on microscopic trajectory simulations, where the forces on all microscopic coordinates need to be computed or measured. However, this can be computationally prohibitive for realistic systems. In this paper, we propose a method to learn macroscopic dynamics requiring only force computations on a subset of the microscopic coordinates. Our method relies on a sparsity assumption: the force on each microscopic coordinate relies only on a small number of other coordinates. The main idea of our approach is to map the training procedure on the macroscopic coordinates back to the microscopic coordinates, on which partial force computations can be used as stochastic estimation to update model parameters. We provide a theoretical justification of this under suitable conditions. We demonstrate the accuracy, force computation efficiency, and robustness of our method on learning macroscopic closure models from a variety of microscopic systems, including those modeled by partial differential equations or molecular dynamics simulations.</li>
</ul>

<h3>Title: Transformers to Predict the Applicability of Symbolic Integration Routines</h3>
<ul>
<li><strong>Authors: </strong>Rashid Barket, Uzma Shafiq, Matthew England, Juergen Gerhard</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23948">https://arxiv.org/abs/2410.23948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23948">https://arxiv.org/pdf/2410.23948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23948]] Transformers to Predict the Applicability of Symbolic Integration Routines(https://arxiv.org/abs/2410.23948)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Symbolic integration is a fundamental problem in mathematics: we consider how machine learning may be used to optimise this task in a Computer Algebra System (CAS). We train transformers that predict whether a particular integration method will be successful, and compare against the existing human-made heuristics (called guards) that perform this task in a leading CAS. We find the transformer can outperform these guards, gaining up to 30% accuracy and 70% precision. We further show that the inference time of the transformer is inconsequential which shows that it is well-suited to include as a guard in a CAS. Furthermore, we use Layer Integrated Gradients to interpret the decisions that the transformer is making. If guided by a subject-matter expert, the technique can explain some of the predictions based on the input tokens, which can lead to further optimisations.</li>
</ul>

<h3>Title: Multilingual Pretraining Using a Large Corpus Machine-Translated from a Single Source Language</h3>
<ul>
<li><strong>Authors: </strong>Jiayi Wang, Yao Lu, Maurice Weber, Max Ryabinin, Yihong Chen, Raphael Tang, Pontus Stenetorp</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23956">https://arxiv.org/abs/2410.23956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23956">https://arxiv.org/pdf/2410.23956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23956]] Multilingual Pretraining Using a Large Corpus Machine-Translated from a Single Source Language(https://arxiv.org/abs/2410.23956)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>English, as a very high-resource language, enables the pretraining of high-quality large language models (LLMs). The same cannot be said for most other languages, as leading LLMs still underperform for non-English languages, likely due to a gap in the quality and diversity of the available multilingual pretraining corpora. In this work, we find that machine-translated text from a single high-quality source language can contribute significantly to the pretraining of multilingual LLMs. We translate FineWeb-Edu, a high-quality English web dataset, into French, German, and Spanish, resulting in a final 300B-token dataset, which we call TransWeb-Edu, and pretrain a 1.3B-parameter model, CuatroLLM, from scratch on this dataset. Across five non-English reasoning tasks, we show that CuatroLLM matches or outperforms state-of-the-art multilingual models trained using closed data, such as Llama3.2 and Gemma2, despite using an order of magnitude less data, such as about 6% of the tokens used for Llama3.2's training. We further demonstrate that with additional domain-specific pretraining, amounting to less than 1% of TransWeb-Edu, CuatroLLM surpasses the state of the art in multilingual reasoning. To promote reproducibility, we release our corpus, models, and training pipeline under open licenses at this http URL.</li>
</ul>

<h3>Title: Image Synthesis with Class-Aware Semantic Diffusion Models for Surgical Scene Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yihang Zhou, Rebecca Towning, Zaid Awad, Stamatia Giannarou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23962">https://arxiv.org/abs/2410.23962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23962">https://arxiv.org/pdf/2410.23962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23962]] Image Synthesis with Class-Aware Semantic Diffusion Models for Surgical Scene Segmentation(https://arxiv.org/abs/2410.23962)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Surgical scene segmentation is essential for enhancing surgical precision, yet it is frequently compromised by the scarcity and imbalance of available data. To address these challenges, semantic image synthesis methods based on generative adversarial networks and diffusion models have been developed. However, these models often yield non-diverse images and fail to capture small, critical tissue classes, limiting their effectiveness. In response, we propose the Class-Aware Semantic Diffusion Model (CASDM), a novel approach which utilizes segmentation maps as conditions for image synthesis to tackle data scarcity and imbalance. Novel class-aware mean squared error and class-aware self-perceptual loss functions have been defined to prioritize critical, less visible classes, thereby enhancing image quality and relevance. Furthermore, to our knowledge, we are the first to generate multi-class segmentation maps using text prompts in a novel fashion to specify their contents. These maps are then used by CASDM to generate surgical scene images, enhancing datasets for training and validating segmentation models. Our evaluation, which assesses both image quality and downstream segmentation performance, demonstrates the strong effectiveness and generalisability of CASDM in producing realistic image-map pairs, significantly advancing surgical scene segmentation across diverse and challenging datasets.</li>
</ul>

<h3>Title: TrAct: Making First-layer Pre-Activations Trainable</h3>
<ul>
<li><strong>Authors: </strong>Felix Petersen, Christian Borgelt, Stefano Ermon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23970">https://arxiv.org/abs/2410.23970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23970">https://arxiv.org/pdf/2410.23970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23970]] TrAct: Making First-layer Pre-Activations Trainable(https://arxiv.org/abs/2410.23970)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We consider the training of the first layer of vision models and notice the clear relationship between pixel values and gradient update magnitudes: the gradients arriving at the weights of a first layer are by definition directly proportional to (normalized) input pixel values. Thus, an image with low contrast has a smaller impact on learning than an image with higher contrast, and a very bright or very dark image has a stronger impact on the weights than an image with moderate brightness. In this work, we propose performing gradient descent on the embeddings produced by the first layer of the model. However, switching to discrete inputs with an embedding layer is not a reasonable option for vision models. Thus, we propose the conceptual procedure of (i) a gradient descent step on first layer activations to construct an activation proposal, and (ii) finding the optimal weights of the first layer, i.e., those weights which minimize the squared distance to the activation proposal. We provide a closed form solution of the procedure and adjust it for robust stochastic training while computing everything efficiently. Empirically, we find that TrAct (Training Activations) speeds up training by factors between 1.25x and 4x while requiring only a small computational overhead. We demonstrate the utility of TrAct with different optimizers for a range of different vision models including convolutional and transformer architectures.</li>
</ul>

<h3>Title: JEMA: A Joint Embedding Framework for Scalable Co-Learning with Multimodal Alignment</h3>
<ul>
<li><strong>Authors: </strong>Joao Sousa, Roya Darabi, Armando Sousa, Frank Brueckner, Luís Paulo Reis, Ana Reis</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23988">https://arxiv.org/abs/2410.23988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23988">https://arxiv.org/pdf/2410.23988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23988]] JEMA: A Joint Embedding Framework for Scalable Co-Learning with Multimodal Alignment(https://arxiv.org/abs/2410.23988)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>This work introduces JEMA (Joint Embedding with Multimodal Alignment), a novel co-learning framework tailored for laser metal deposition (LMD), a pivotal process in metal additive manufacturing. As Industry 5.0 gains traction in industrial applications, efficient process monitoring becomes increasingly crucial. However, limited data and the opaque nature of AI present challenges for its application in an industrial setting. JEMA addresses this challenges by leveraging multimodal data, including multi-view images and metadata such as process parameters, to learn transferable semantic representations. By applying a supervised contrastive loss function, JEMA enables robust learning and subsequent process monitoring using only the primary modality, simplifying hardware requirements and computational overhead. We investigate the effectiveness of JEMA in LMD process monitoring, focusing specifically on its generalization to downstream tasks such as melt pool geometry prediction, achieved without extensive fine-tuning. Our empirical evaluation demonstrates the high scalability and performance of JEMA, particularly when combined with Vision Transformer models. We report an 8% increase in performance in multimodal settings and a 1% improvement in unimodal settings compared to supervised contrastive learning. Additionally, the learned embedding representation enables the prediction of metadata, enhancing interpretability and making possible the assessment of the added metadata's contributions. Our framework lays the foundation for integrating multisensor data with metadata, enabling diverse downstream tasks within the LMD domain and beyond.</li>
</ul>

<h3>Title: Ada-MSHyper: Adaptive Multi-Scale Hypergraph Transformer for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Zongjiang Shang, Ling Chen, Binqing wu, Dongliang Cui</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23992">https://arxiv.org/abs/2410.23992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23992">https://arxiv.org/pdf/2410.23992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23992]] Ada-MSHyper: Adaptive Multi-Scale Hypergraph Transformer for Time Series Forecasting(https://arxiv.org/abs/2410.23992)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Although transformer-based methods have achieved great success in multi-scale temporal pattern interaction modeling, two key challenges limit their further development: (1) Individual time points contain less semantic information, and leveraging attention to model pair-wise interactions may cause the information utilization bottleneck. (2) Multiple inherent temporal variations (e.g., rising, falling, and fluctuating) entangled in temporal patterns. To this end, we propose Adaptive Multi-Scale Hypergraph Transformer (Ada-MSHyper) for time series forecasting. Specifically, an adaptive hypergraph learning module is designed to provide foundations for modeling group-wise interactions, then a multi-scale interaction module is introduced to promote more comprehensive pattern interactions at different scales. In addition, a node and hyperedge constraint mechanism is introduced to cluster nodes with similar semantic information and differentiate the temporal variations within each scales. Extensive experiments on 11 real-world datasets demonstrate that Ada-MSHyper achieves state-of-the-art performance, reducing prediction errors by an average of 4.56%, 10.38%, and 4.97% in MSE for long-range, short-range, and ultra-long-range time series forecasting, respectively. Code is available at this https URL.</li>
</ul>

<h3>Title: Breaking Determinism: Fuzzy Modeling of Sequential Recommendation Using Discrete State Space Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Wenjia Xie, Hao Wang, Luankang Zhang, Rui Zhou, Defu Lian, Enhong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23994">https://arxiv.org/abs/2410.23994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23994">https://arxiv.org/pdf/2410.23994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23994]] Breaking Determinism: Fuzzy Modeling of Sequential Recommendation Using Discrete State Space Diffusion Model(https://arxiv.org/abs/2410.23994)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Sequential recommendation (SR) aims to predict items that users may be interested in based on their historical behavior sequences. We revisit SR from a novel information-theoretic perspective and find that conventional sequential modeling methods fail to adequately capture the randomness and unpredictability of user behavior. Inspired by fuzzy information processing theory, this paper introduces the DDSR model, which uses fuzzy sets of interaction sequences to overcome the limitations and better capture the evolution of users' real interests. Formally based on diffusion transition processes in discrete state spaces, which is unlike common diffusion models such as DDPM that operate in continuous domains. It is better suited for discrete data, using structured transitions instead of arbitrary noise introduction to avoid information loss. Additionally, to address the inefficiency of matrix transformations due to the vast discrete space, we use semantic labels derived from quantization or RQ-VAE to replace item IDs, enhancing efficiency and improving cold start issues. Testing on three public benchmark datasets shows that DDSR outperforms existing state-of-the-art methods in various settings, demonstrating its potential and effectiveness in handling SR tasks.</li>
</ul>

<h3>Title: An Information Criterion for Controlled Disentanglement of Multimodal Data</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Wang, Sharut Gupta, Xinyi Zhang, Sana Tonekaboni, Stefanie Jegelka, Tommi Jaakkola, Caroline Uhler</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.23996">https://arxiv.org/abs/2410.23996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.23996">https://arxiv.org/pdf/2410.23996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.23996]] An Information Criterion for Controlled Disentanglement of Multimodal Data(https://arxiv.org/abs/2410.23996)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Multimodal representation learning seeks to relate and decompose information inherent in multiple modalities. By disentangling modality-specific information from information that is shared across modalities, we can improve interpretability and robustness and enable downstream tasks such as the generation of counterfactual outcomes. Separating the two types of information is challenging since they are often deeply entangled in many real-world applications. We propose Disentangled Self-Supervised Learning (DisentangledSSL), a novel self-supervised approach for learning disentangled representations. We present a comprehensive analysis of the optimality of each disentangled representation, particularly focusing on the scenario not covered in prior work where the so-called Minimum Necessary Information (MNI) point is not attainable. We demonstrate that DisentangledSSL successfully learns shared and modality-specific features on multiple synthetic and real-world datasets and consistently outperforms baselines on various downstream tasks, including prediction tasks for vision-language data, as well as molecule-phenotype retrieval tasks for biological data.</li>
</ul>

<h3>Title: Context-Aware Testing: A New Paradigm for Model Testing with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Paulius Rauba, Nabeel Seedat, Max Ruiz Luyten, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24005">https://arxiv.org/abs/2410.24005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24005">https://arxiv.org/pdf/2410.24005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24005]] Context-Aware Testing: A New Paradigm for Model Testing with Large Language Models(https://arxiv.org/abs/2410.24005)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The predominant de facto paradigm of testing ML models relies on either using only held-out data to compute aggregate evaluation metrics or by assessing the performance on different subgroups. However, such data-only testing methods operate under the restrictive assumption that the available empirical data is the sole input for testing ML models, disregarding valuable contextual information that could guide model testing. In this paper, we challenge the go-to approach of data-only testing and introduce context-aware testing (CAT) which uses context as an inductive bias to guide the search for meaningful model failures. We instantiate the first CAT system, SMART Testing, which employs large language models to hypothesize relevant and likely failures, which are evaluated on data using a self-falsification mechanism. Through empirical evaluations in diverse settings, we show that SMART automatically identifies more relevant and impactful failures than alternatives, demonstrating the potential of CAT as a testing paradigm.</li>
</ul>

<h3>Title: DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination</h3>
<ul>
<li><strong>Authors: </strong>Jia Fu, Xiao Zhang, Sepideh Pashami, Fatemeh Rahimian, Anders Holst</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24006">https://arxiv.org/abs/2410.24006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24006">https://arxiv.org/pdf/2410.24006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24006]] DiffPAD: Denoising Diffusion-based Adversarial Patch Decontamination(https://arxiv.org/abs/2410.24006)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>In the ever-evolving adversarial machine learning landscape, developing effective defenses against patch attacks has become a critical challenge, necessitating reliable solutions to safeguard real-world AI systems. Although diffusion models have shown remarkable capacity in image synthesis and have been recently utilized to counter $\ell_p$-norm bounded attacks, their potential in mitigating localized patch attacks remains largely underexplored. In this work, we propose DiffPAD, a novel framework that harnesses the power of diffusion models for adversarial patch decontamination. DiffPAD first performs super-resolution restoration on downsampled input images, then adopts binarization, dynamic thresholding scheme and sliding window for effective localization of adversarial patches. Such a design is inspired by the theoretically derived correlation between patch size and diffusion restoration error that is generalized across diverse patch attack scenarios. Finally, DiffPAD applies inpainting techniques to the original input images with the estimated patch region being masked. By integrating closed-form solutions for super-resolution restoration and image inpainting into the conditional reverse sampling process of a pre-trained diffusion model, DiffPAD obviates the need for text guidance or fine-tuning. Through comprehensive experiments, we demonstrate that DiffPAD not only achieves state-of-the-art adversarial robustness against patch attacks but also excels in recovering naturalistic images without patch remnants.</li>
</ul>

<h3>Title: Diffusion Twigs with Loop Guidance for Conditional Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Giangiacomo Mercatali, Yogesh Verma, Andre Freitas, Vikas Garg</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24012">https://arxiv.org/abs/2410.24012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24012">https://arxiv.org/pdf/2410.24012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24012]] Diffusion Twigs with Loop Guidance for Conditional Graph Generation(https://arxiv.org/abs/2410.24012)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce a novel score-based diffusion framework named Twigs that incorporates multiple co-evolving flows for enriching conditional generation tasks. Specifically, a central or trunk diffusion process is associated with a primary variable (e.g., graph structure), and additional offshoot or stem processes are dedicated to dependent variables (e.g., graph properties or labels). A new strategy, which we call loop guidance, effectively orchestrates the flow of information between the trunk and the stem processes during sampling. This approach allows us to uncover intricate interactions and dependencies, and unlock new generative capabilities. We provide extensive experiments to demonstrate strong performance gains of the proposed method over contemporary baselines in the context of conditional graph generation, underscoring the potential of Twigs in challenging generative tasks such as inverse molecular design and molecular optimization.</li>
</ul>

<h3>Title: Unveiling Synthetic Faces: How Synthetic Datasets Can Expose Real Identities</h3>
<ul>
<li><strong>Authors: </strong>Hatef Otroshi Shahreza, Sébastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24015">https://arxiv.org/abs/2410.24015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24015">https://arxiv.org/pdf/2410.24015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24015]] Unveiling Synthetic Faces: How Synthetic Datasets Can Expose Real Identities(https://arxiv.org/abs/2410.24015)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer, generative</a></li>
<li><strong>Abstract: </strong>Synthetic data generation is gaining increasing popularity in different computer vision applications. Existing state-of-the-art face recognition models are trained using large-scale face datasets, which are crawled from the Internet and raise privacy and ethical concerns. To address such concerns, several works have proposed generating synthetic face datasets to train face recognition models. However, these methods depend on generative models, which are trained on real face images. In this work, we design a simple yet effective membership inference attack to systematically study if any of the existing synthetic face recognition datasets leak any information from the real data used to train the generator model. We provide an extensive study on 6 state-of-the-art synthetic face recognition datasets, and show that in all these synthetic datasets, several samples from the original real dataset are leaked. To our knowledge, this paper is the first work which shows the leakage from training data of generator models into the generated synthetic face recognition datasets. Our study demonstrates privacy pitfalls in synthetic face recognition datasets and paves the way for future studies on generating responsible synthetic face datasets.</li>
</ul>

<h3>Title: Speech is More Than Words: Do Speech-to-Text Translation Systems Leverage Prosody?</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Tsiamas, Matthias Sperber, Andrew Finch, Sarthak Garg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24019">https://arxiv.org/abs/2410.24019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24019">https://arxiv.org/pdf/2410.24019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24019]] Speech is More Than Words: Do Speech-to-Text Translation Systems Leverage Prosody?(https://arxiv.org/abs/2410.24019)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The prosody of a spoken utterance, including features like stress, intonation and rhythm, can significantly affect the underlying semantics, and as a consequence can also affect its textual translation. Nevertheless, prosody is rarely studied within the context of speech-to-text translation (S2TT) systems. In particular, end-to-end (E2E) systems have been proposed as well-suited for prosody-aware translation because they have direct access to the speech signal when making translation decisions, but the understanding of whether this is successful in practice is still limited. A main challenge is the difficulty of evaluating prosody awareness in translation. To address this challenge, we introduce an evaluation methodology and a focused benchmark (named ContraProST) aimed at capturing a wide range of prosodic phenomena. Our methodology uses large language models and controllable text-to-speech (TTS) to generate contrastive examples. Through experiments in translating English speech into German, Spanish, and Japanese, we find that (a) S2TT models possess some internal representation of prosody, but the prosody signal is often not strong enough to affect the translations, (b) E2E systems outperform cascades of speech recognition and text translation systems, confirming their theoretical advantage in this regard, and (c) certain cascaded systems also capture prosodic information in the translation, but only to a lesser extent that depends on the particulars of the transcript's surface form.</li>
</ul>

<h3>Title: A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps</h3>
<ul>
<li><strong>Authors: </strong>Ariel Larey, Eyal Rond, Omer Achrack</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24031">https://arxiv.org/abs/2410.24031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24031">https://arxiv.org/pdf/2410.24031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24031]] A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps(https://arxiv.org/abs/2410.24031)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Face recognition technologies are increasingly used in various applications, yet they are vulnerable to face spoofing attacks. These spoofing attacks often involve unique 3D structures, such as printed papers or mobile device screens. Although stereo-depth cameras can detect such attacks effectively, their high-cost limits their widespread adoption. Conversely, two-sensor systems without extrinsic calibration offer a cost-effective alternative but are unable to calculate depth using stereo techniques. In this work, we propose a method to overcome this challenge by leveraging facial attributes to derive disparity information and estimate relative depth for anti-spoofing purposes, using non-calibrated systems. We introduce a multi-modal anti-spoofing model, coined Disparity Model, that incorporates created disparity maps as a third modality alongside the two original sensor modalities. We demonstrate the effectiveness of the Disparity Model in countering various spoof attacks using a comprehensive dataset collected from the Intel RealSense ID Solution F455. Our method outperformed existing methods in the literature, achieving an Equal Error Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False Positive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the errors of the best comparison method, respectively. Additionally, we introduce a model ensemble that addresses 3D spoof attacks as well, achieving an EER of 2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a state-of-the-art solution for the challenging task of anti-spoofing in non-calibrated systems that lack depth information.</li>
</ul>

<h3>Title: Handwriting Recognition in Historical Documents with Multimodal LLM</h3>
<ul>
<li><strong>Authors: </strong>Lucian Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24034">https://arxiv.org/abs/2410.24034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24034">https://arxiv.org/pdf/2410.24034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24034]] Handwriting Recognition in Historical Documents with Multimodal LLM(https://arxiv.org/abs/2410.24034)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>There is an immense quantity of historical and cultural documentation that exists only as handwritten manuscripts. At the same time, performing OCR across scripts and different handwriting styles has proven to be an enormously difficult problem relative to the process of digitizing print. While recent Transformer based models have achieved relatively strong performance, they rely heavily on manually transcribed training data and have difficulty generalizing across writers. Multimodal LLM, such as GPT-4v and Gemini, have demonstrated effectiveness in performing OCR and computer vision tasks with few shot prompting. In this paper, I evaluate the accuracy of handwritten document transcriptions generated by Gemini against the current state of the art Transformer based methods. Keywords: Optical Character Recognition, Multimodal Language Models, Cultural Preservation, Mass digitization, Handwriting Recognitio</li>
</ul>

<h3>Title: TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation</h3>
<ul>
<li><strong>Authors: </strong>Sunjae Yoon, Gwanhyeong Koo, Younghwan Lee, Chang D. Yoo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24037">https://arxiv.org/abs/2410.24037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24037">https://arxiv.org/pdf/2410.24037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24037]] TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation(https://arxiv.org/abs/2410.24037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Human image animation aims to generate a human motion video from the inputs of a reference human image and a target motion video. Current diffusion-based image animation systems exhibit high precision in transferring human identity into targeted motion, yet they still exhibit irregular quality in their outputs. Their optimal precision is achieved only when the physical compositions (i.e., scale and rotation) of the human shapes in the reference image and target pose frame are aligned. In the absence of such alignment, there is a noticeable decline in fidelity and consistency. Especially, in real-world environments, this compositional misalignment commonly occurs, posing significant challenges to the practical usage of current systems. To this end, we propose Test-time Procrustes Calibration (TPC), which enhances the robustness of diffusion-based image animation systems by maintaining optimal performance even when faced with compositional misalignment, effectively addressing real-world scenarios. The TPC provides a calibrated reference image for the diffusion model, enhancing its capability to understand the correspondence between human shapes in the reference and target images. Our method is simple and can be applied to any diffusion-based image animation system in a model-agnostic manner, improving the effectiveness at test time without additional training.</li>
</ul>

<h3>Title: Desert Camels and Oil Sheikhs: Arab-Centric Red Teaming of Frontier LLMs</h3>
<ul>
<li><strong>Authors: </strong>Muhammed Saeed, Elgizouli Mohamed, Mukhtar Mohamed, Shaina Raza, Shady Shehata, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24049">https://arxiv.org/abs/2410.24049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24049">https://arxiv.org/pdf/2410.24049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24049]] Desert Camels and Oil Sheikhs: Arab-Centric Red Teaming of Frontier LLMs(https://arxiv.org/abs/2410.24049)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are widely used but raise ethical concerns due to embedded social biases. This study examines LLM biases against Arabs versus Westerners across eight domains, including women's rights, terrorism, and anti-Semitism and assesses model resistance to perpetuating these biases. To this end, we create two datasets: one to evaluate LLM bias toward Arabs versus Westerners and another to test model safety against prompts that exaggerate negative traits ("jailbreaks"). We evaluate six LLMs -- GPT-4, GPT-4o, LlaMA 3.1 (8B & 405B), Mistral 7B, and Claude 3.5 Sonnet. We find 79% of cases displaying negative biases toward Arabs, with LlaMA 3.1-405B being the most biased. Our jailbreak tests reveal GPT-4o as the most vulnerable, despite being an optimized version, followed by LlaMA 3.1-8B and Mistral 7B. All LLMs except Claude exhibit attack success rates above 87% in three categories. We also find Claude 3.5 Sonnet the safest, but it still displays biases in seven of eight categories. Despite being an optimized version of GPT4, We find GPT-4o to be more prone to biases and jailbreaks, suggesting optimization flaws. Our findings underscore the pressing need for more robust bias mitigation strategies and strengthened security measures in LLMs.</li>
</ul>

<h3>Title: A Visual Case Study of the Training Dynamics in Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Ambroise Odonnat, Wassim Bouaziz, Vivien Cabannes</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24050">https://arxiv.org/abs/2410.24050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24050">https://arxiv.org/pdf/2410.24050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24050]] A Visual Case Study of the Training Dynamics in Neural Networks(https://arxiv.org/abs/2410.24050)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces a visual sandbox designed to explore the training dynamics of a small-scale transformer model, with the embedding dimension constrained to $d=2$. This restriction allows for a comprehensive two-dimensional visualization of each layer's dynamics. Through this approach, we gain insights into training dynamics, circuit transferability, and the causes of loss spikes, including those induced by the high curvature of normalization layers. We propose strategies to mitigate these spikes, demonstrating how good visualization facilitates the design of innovative ideas of practical interest. Additionally, we believe our sandbox could assist theoreticians in assessing essential training dynamics mechanisms and integrating them into future theories. The code is available at this https URL.</li>
</ul>

<h3>Title: Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</h3>
<ul>
<li><strong>Authors: </strong>Xiang Li, Yixiang Dai, Qing Qu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.IV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24060">https://arxiv.org/abs/2410.24060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24060">https://arxiv.org/pdf/2410.24060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24060]] Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure(https://arxiv.org/abs/2410.24060)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we study the generalizability of diffusion models by looking into the hidden properties of the learned score functions, which are essentially a series of deep denoisers trained on various noise levels. We observe that as diffusion models transition from memorization to generalization, their corresponding nonlinear diffusion denoisers exhibit increasing linearity. This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers. Surprisingly, these linear denoisers are approximately the optimal denoisers for a multivariate Gaussian distribution characterized by the empirical mean and covariance of the training dataset. This finding implies that diffusion models have the inductive bias towards capturing and utilizing the Gaussian structure (covariance information) of the training dataset for data generation. We empirically demonstrate that this inductive bias is a unique property of diffusion models in the generalization regime, which becomes increasingly evident when the model's capacity is relatively small compared to the training dataset size. In the case that the model is highly overparameterized, this inductive bias emerges during the initial training phases before the model fully memorizes its training data. Our study provides crucial insights into understanding the notable strong generalization phenomenon recently observed in real-world diffusion models.</li>
</ul>

<h3>Title: Dynamical similarity analysis uniquely captures how computations develop in RNNs</h3>
<ul>
<li><strong>Authors: </strong>Quentin Guilhot, Jascha Achterberg, Michał Wójcik, Rui Ponte Costa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.NE, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24070">https://arxiv.org/abs/2410.24070</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24070">https://arxiv.org/pdf/2410.24070</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24070]] Dynamical similarity analysis uniquely captures how computations develop in RNNs(https://arxiv.org/abs/2410.24070)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Methods for analyzing representations in neural systems are increasingly popular tools in neuroscience and mechanistic interpretability. Measures comparing neural activations across conditions, architectures, and species give scalable ways to understand information transformation within different neural networks. However, recent findings show that some metrics respond to spurious signals, leading to misleading results. Establishing benchmark test cases is thus essential for identifying the most reliable metric and potential improvements. We propose that compositional learning in recurrent neural networks (RNNs) can provide a test case for dynamical representation alignment metrics. Implementing this case allows us to evaluate if metrics can identify representations that develop throughout learning and determine if representations identified by metrics reflect the network's actual computations. Building both attractor and RNN based test cases, we show that the recently proposed Dynamical Similarity Analysis (DSA) is more noise robust and reliably identifies behaviorally relevant representations compared to prior metrics (Procrustes, CKA). We also demonstrate how such test cases can extend beyond metric evaluation to study new architectures. Specifically, testing DSA in modern (Mamba) state space models suggests that these models, unlike RNNs, may not require changes in recurrent dynamics due to their expressive hidden states. Overall, we develop test cases that showcase how DSA's enhanced ability to detect dynamical motifs makes it highly effective for identifying ongoing computations in RNNs and revealing how networks learn tasks.</li>
</ul>

<h3>Title: Progressive Safeguards for Safe and Model-Agnostic Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Nabil Omi, Hosein Hasanbeig, Hiteshi Sharma, Sriram K. Rajamani, Siddhartha Sen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24096">https://arxiv.org/abs/2410.24096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24096">https://arxiv.org/pdf/2410.24096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24096]] Progressive Safeguards for Safe and Model-Agnostic Reinforcement Learning(https://arxiv.org/abs/2410.24096)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In this paper we propose a formal, model-agnostic meta-learning framework for safe reinforcement learning. Our framework is inspired by how parents safeguard their children across a progression of increasingly riskier tasks, imparting a sense of safety that is carried over from task to task. We model this as a meta-learning process where each task is synchronized with a safeguard that monitors safety and provides a reward signal to the agent. The safeguard is implemented as a finite-state machine based on a safety specification; the reward signal is formally shaped around this specification. The safety specification and its corresponding safeguard can be arbitrarily complex and non-Markovian, which adds flexibility to the training process and explainability to the learned policy. The design of the safeguard is manual but it is high-level and model-agnostic, which gives rise to an end-to-end safe learning approach with wide applicability, from pixel-level game control to language model fine-tuning. Starting from a given set of safety specifications (tasks), we train a model such that it can adapt to new specifications using only a small number of training samples. This is made possible by our method for efficiently transferring safety bias between tasks, which effectively minimizes the number of safety violations. We evaluate our framework in a Minecraft-inspired Gridworld, a VizDoom game environment, and an LLM fine-tuning application. Agents trained with our approach achieve near-minimal safety violations, while baselines are shown to underperform.</li>
</ul>

<h3>Title: Matchmaker: Self-Improving Large Language Model Programs for Schema Matching</h3>
<ul>
<li><strong>Authors: </strong>Nabeel Seedat, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24105">https://arxiv.org/abs/2410.24105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24105">https://arxiv.org/pdf/2410.24105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24105]] Matchmaker: Self-Improving Large Language Model Programs for Schema Matching(https://arxiv.org/abs/2410.24105)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce -- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic or suffer from poor zero-shot performance. To this end, we propose Matchmaker - a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process. Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.</li>
</ul>

<h3>Title: On Sampling Strategies for Spectral Model Sharding</h3>
<ul>
<li><strong>Authors: </strong>Denis Korzhenkov, Christos Louizos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24106">https://arxiv.org/abs/2410.24106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24106">https://arxiv.org/pdf/2410.24106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24106]] On Sampling Strategies for Spectral Model Sharding(https://arxiv.org/abs/2410.24106)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The problem of heterogeneous clients in federated learning has recently drawn a lot of attention. Spectral model sharding, i.e., partitioning the model parameters into low-rank matrices based on the singular value decomposition, has been one of the proposed solutions for more efficient on-device training in such settings. In this work, we present two sampling strategies for such sharding, obtained as solutions to specific optimization problems. The first produces unbiased estimators of the original weights, while the second aims to minimize the squared approximation error. We discuss how both of these estimators can be incorporated in the federated learning loop and practical considerations that arise during local training. Empirically, we demonstrate that both of these methods can lead to improved performance on various commonly used datasets.</li>
</ul>

<h3>Title: Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Kai Yan, Alexander G. Schwing, Yu-Xiong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24108">https://arxiv.org/abs/2410.24108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24108">https://arxiv.org/pdf/2410.24108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24108]] Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers(https://arxiv.org/abs/2410.24108)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Decision Transformers have recently emerged as a new and compelling paradigm for offline Reinforcement Learning (RL), completing a trajectory in an autoregressive way. While improvements have been made to overcome initial shortcomings, online finetuning of decision transformers has been surprisingly under-explored. The widely adopted state-of-the-art Online Decision Transformer (ODT) still struggles when pretrained with low-reward offline data. In this paper, we theoretically analyze the online-finetuning of the decision transformer, showing that the commonly used Return-To-Go (RTG) that's far from the expected return hampers the online fine-tuning process. This problem, however, is well-addressed by the value function and advantage of standard RL algorithms. As suggested by our analysis, in our experiments, we hence find that simply adding TD3 gradients to the finetuning process of ODT effectively improves the online finetuning performance of ODT, especially if ODT is pretrained with low-reward offline data. These findings provide new directions to further improve decision transformers.</li>
</ul>

<h3>Title: COSNet: A Novel Semantic Segmentation Network using Enhanced Boundaries in Cluttered Scenes</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ali, Mamoona Javaid, Mubashir Noman, Mustansar Fiaz, Salman Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24139">https://arxiv.org/abs/2410.24139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24139">https://arxiv.org/pdf/2410.24139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24139]] COSNet: A Novel Semantic Segmentation Network using Enhanced Boundaries in Cluttered Scenes(https://arxiv.org/abs/2410.24139)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Automated waste recycling aims to efficiently separate the recyclable objects from the waste by employing vision-based systems. However, the presence of varying shaped objects having different material types makes it a challenging problem, especially in cluttered environments. Existing segmentation methods perform reasonably on many semantic segmentation datasets by employing multi-contextual representations, however, their performance is degraded when utilized for waste object segmentation in cluttered scenarios. In addition, plastic objects further increase the complexity of the problem due to their translucent nature. To address these limitations, we introduce an efficacious segmentation network, named COSNet, that uses boundary cues along with multi-contextual information to accurately segment the objects in cluttered scenes. COSNet introduces novel components including feature sharpening block (FSB) and boundary enhancement module (BEM) for enhancing the features and highlighting the boundary information of irregular waste objects in cluttered environment. Extensive experiments on three challenging datasets including ZeroWaste-f, SpectralWaste, and ADE20K demonstrate the effectiveness of the proposed method. Our COSNet achieves a significant gain of 1.8% on ZeroWaste-f and 2.1% on SpectralWaste datasets respectively in terms of mIoU metric.</li>
</ul>

<h3>Title: Exploring Vision Language Models for Facial Attribute Recognition: Emotion, Race, Gender, and Age</h3>
<ul>
<li><strong>Authors: </strong>Nouar AlDahoul, Myles Joshua Toledo Tan, Harishwar Reddy Kasireddy, Yasir Zaki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24148">https://arxiv.org/abs/2410.24148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24148">https://arxiv.org/pdf/2410.24148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24148]] Exploring Vision Language Models for Facial Attribute Recognition: Emotion, Race, Gender, and Age(https://arxiv.org/abs/2410.24148)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, transformer, generative</a></li>
<li><strong>Abstract: </strong>Technologies for recognizing facial attributes like race, gender, age, and emotion have several applications, such as surveillance, advertising content, sentiment analysis, and the study of demographic trends and social behaviors. Analyzing demographic characteristics based on images and analyzing facial expressions have several challenges due to the complexity of humans' facial attributes. Traditional approaches have employed CNNs and various other deep learning techniques, trained on extensive collections of labeled images. While these methods demonstrated effective performance, there remains potential for further enhancements. In this paper, we propose to utilize vision language models (VLMs) such as generative pre-trained transformer (GPT), GEMINI, large language and vision assistant (LLAVA), PaliGemma, and Microsoft Florence2 to recognize facial attributes such as race, gender, age, and emotion from images with human faces. Various datasets like FairFace, AffectNet, and UTKFace have been utilized to evaluate the solutions. The results show that VLMs are competitive if not superior to traditional techniques. Additionally, we propose "FaceScanPaliGemma"--a fine-tuned PaliGemma model--for race, gender, age, and emotion recognition. The results show an accuracy of 81.1%, 95.8%, 80%, and 59.4% for race, gender, age group, and emotion classification, respectively, outperforming pre-trained version of PaliGemma, other VLMs, and SotA methods. Finally, we propose "FaceScanGPT", which is a GPT-4o model to recognize the above attributes when several individuals are present in the image using a prompt engineered for a person with specific facial and/or physical attributes. The results underscore the superior multitasking capability of FaceScanGPT to detect the individual's attributes like hair cut, clothing color, postures, etc., using only a prompt to drive the detection and recognition tasks.</li>
</ul>

<h3>Title: Scaling Concept With Text-Guided Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Chao Huang, Susan Liang, Yunlong Tang, Yapeng Tian, Anurag Kumar, Chenliang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24151">https://arxiv.org/abs/2410.24151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24151">https://arxiv.org/pdf/2410.24151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24151]] Scaling Concept With Text-Guided Diffusion Models(https://arxiv.org/abs/2410.24151)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-guided diffusion models have revolutionized generative tasks by producing high-fidelity content from text descriptions. They have also enabled an editing paradigm where concepts can be replaced through text conditioning (e.g., a dog to a tiger). In this work, we explore a novel approach: instead of replacing a concept, can we enhance or suppress the concept itself? Through an empirical study, we identify a trend where concepts can be decomposed in text-guided diffusion models. Leveraging this insight, we introduce ScalingConcept, a simple yet effective method to scale decomposed concepts up or down in real input without introducing new elements. To systematically evaluate our approach, we present the WeakConcept-10 dataset, where concepts are imperfect and need to be enhanced. More importantly, ScalingConcept enables a variety of novel zero-shot applications across image and audio domains, including tasks such as canonical pose generation and generative sound highlighting or removal.</li>
</ul>

<h3>Title: Thought Space Explorer: Navigating and Expanding Thought Space for Large Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jinghan Zhang, Fengran Mo, Xiting Wang, Kunpeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24155">https://arxiv.org/abs/2410.24155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24155">https://arxiv.org/pdf/2410.24155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24155]] Thought Space Explorer: Navigating and Expanding Thought Space for Large Language Model Reasoning(https://arxiv.org/abs/2410.24155)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have demonstrated their potential in handling complex reasoning tasks, which are usually achieved by constructing a thought chain to guide the model to solve the problem with multi-step thinking. However, existing methods often remain confined to previously explored solution spaces and thus overlook the critical blind spot within LLMs' cognitive range. To address these issues, we design the Thought Space Explorer (TSE), a novel framework to expand and optimize thought structures to guide LLMs to explore their blind spots of thinking. By generating new reasoning steps and branches based on the original thought structure with various designed strategies, TSE broadens the thought space and alleviates the impact of blind spots for LLM reasoning. Experimental results on multiple levels of reasoning tasks demonstrate the efficacy of TSE. We also conduct extensive analysis to understand how structured and expansive thought can contribute to unleashing the potential of LLM reasoning capabilities.</li>
</ul>

<h3>Title: GPT or BERT: why not both?</h3>
<ul>
<li><strong>Authors: </strong>Lucas Georges Gabriel Charpentier, David Samuel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24159">https://arxiv.org/abs/2410.24159</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24159">https://arxiv.org/pdf/2410.24159</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24159]] GPT or BERT: why not both?(https://arxiv.org/abs/2410.24159)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a simple way to merge masked language modeling with causal language modeling. This hybrid training objective results in a model that combines the strengths of both modeling paradigms within a single transformer stack: GPT-BERT can be transparently used like any standard causal or masked language model. We test the pretraining process that enables this flexible behavior on the BabyLM Challenge 2024. The results show that the hybrid pretraining outperforms masked-only or causal-only models. We openly release the models, training corpora and code.</li>
</ul>

<h3>Title: Redefining <Creative> in Dictionary: Towards a Enhanced Semantic Understanding of Creative Generation</h3>
<ul>
<li><strong>Authors: </strong>Fu Feng, Yucheng Xie, Jing Wang, Xin Geng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24160">https://arxiv.org/abs/2410.24160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24160">https://arxiv.org/pdf/2410.24160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24160]] Redefining <Creative> in Dictionary: Towards a Enhanced Semantic Understanding of Creative Generation(https://arxiv.org/abs/2410.24160)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Creativity, both in human and diffusion models, remains an inherently abstract concept; thus, simply adding "creative" to a prompt does not yield reliable semantic recognition by the model. In this work, we concretize the abstract notion of "creative" through the TP2O task, which aims to merge two unrelated concepts, and introduce CreTok, redefining "creative" as the token $\texttt{<CreTok>}$. This redefinition offers a more concrete and universally adaptable representation for concept blending. This redefinition occurs continuously, involving the repeated random sampling of text pairs with different concepts and optimizing cosine similarity between target and constant prompts. This approach enables $\texttt{<CreTok>}$ to learn a method for creative concept fusion. Extensive experiments demonstrate that the creative capability enabled by $\texttt{<CreTok>}$ substantially surpasses recent SOTA diffusion models and achieves superior creative generation. CreTok exhibits greater flexibility and reduced time overhead, as $\texttt{<CreTok>}$ can function as a universal token for any concept, facilitating creative generation without retraining.</li>
</ul>

<h3>Title: Conformalized Prediction of Post-Fault Voltage Trajectories Using Pre-trained and Finetuned Attention-Driven Neural Operators</h3>
<ul>
<li><strong>Authors: </strong>Amirhossein Mollaali, Gabriel Zufferey, Gonzalo Constante-Flores, Christian Moya, Can Li, Guang Lin, Meng Yue</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24162">https://arxiv.org/abs/2410.24162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24162">https://arxiv.org/pdf/2410.24162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24162]] Conformalized Prediction of Post-Fault Voltage Trajectories Using Pre-trained and Finetuned Attention-Driven Neural Operators(https://arxiv.org/abs/2410.24162)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>This paper proposes a new data-driven methodology for predicting intervals of post-fault voltage trajectories in power systems. We begin by introducing the Quantile Attention-Fourier Deep Operator Network (QAF-DeepONet), designed to capture the complex dynamics of voltage trajectories and reliably estimate quantiles of the target trajectory without any distributional assumptions. The proposed operator regression model maps the observed portion of the voltage trajectory to its unobserved post-fault trajectory. Our methodology employs a pre-training and fine-tuning process to address the challenge of limited data availability. To ensure data privacy in learning the pre-trained model, we use merging via federated learning with data from neighboring buses, enabling the model to learn the underlying voltage dynamics from such buses without directly sharing their data. After pre-training, we fine-tune the model with data from the target bus, allowing it to adapt to unique dynamics and operating conditions. Finally, we integrate conformal prediction into the fine-tuned model to ensure coverage guarantees for the predicted intervals. We evaluated the performance of the proposed methodology using the New England 39-bus test system considering detailed models of voltage and frequency controllers. Two metrics, Prediction Interval Coverage Probability (PICP) and Prediction Interval Normalized Average Width (PINAW), are used to numerically assess the model's performance in predicting intervals. The results show that the proposed approach offers practical and reliable uncertainty quantification in predicting the interval of post-fault voltage trajectories.</li>
</ul>

<h3>Title: $\pi_0$: A Vision-Language-Action Flow Model for General Robot Control</h3>
<ul>
<li><strong>Authors: </strong>Kevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Lucy Xiaoyang Shi, James Tanner, Quan Vuong, Anna Walling, Haohuan Wang, Ury Zhilinsky</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24164">https://arxiv.org/abs/2410.24164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24164">https://arxiv.org/pdf/2410.24164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24164]] $\pi_0$: A Vision-Language-Action Flow Model for General Robot Control(https://arxiv.org/abs/2410.24164)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.</li>
</ul>

<h3>Title: Approaches to human activity recognition via passive radar</h3>
<ul>
<li><strong>Authors: </strong>Christian Bresciani, Federico Cerutti, Marco Cominelli</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24166">https://arxiv.org/abs/2410.24166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24166">https://arxiv.org/pdf/2410.24166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24166]] Approaches to human activity recognition via passive radar(https://arxiv.org/abs/2410.24166)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, interpretability</a></li>
<li><strong>Abstract: </strong>The thesis explores novel methods for Human Activity Recognition (HAR) using passive radar with a focus on non-intrusive Wi-Fi Channel State Information (CSI) data. Traditional HAR approaches often use invasive sensors like cameras or wearables, raising privacy issues. This study leverages the non-intrusive nature of CSI, using Spiking Neural Networks (SNN) to interpret signal variations caused by human movements. These networks, integrated with symbolic reasoning frameworks such as DeepProbLog, enhance the adaptability and interpretability of HAR systems. SNNs offer reduced power consumption, ideal for privacy-sensitive applications. Experimental results demonstrate SNN-based neurosymbolic models achieve high accuracy making them a promising alternative for HAR across various domains.</li>
</ul>

<h3>Title: Constraint Back-translation Improves Complex Instruction Following of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yunjia Qi, Hao Peng, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24175">https://arxiv.org/abs/2410.24175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24175">https://arxiv.org/pdf/2410.24175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24175]] Constraint Back-translation Improves Complex Instruction Following of Large Language Models(https://arxiv.org/abs/2410.24175)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) struggle to follow instructions with complex constraints in format, length, etc. Following the conventional instruction-tuning practice, previous works conduct post-training on complex instruction-response pairs generated by feeding complex instructions to advanced LLMs. However, even advanced LLMs cannot follow complex instructions well, thus limiting the quality of generated data. In this work, we find that existing datasets inherently contain implicit complex constraints and propose a novel data generation technique, constraint back-translation. Specifically, we take the high-quality instruction-response pairs in existing datasets and only adopt advanced LLMs to add complex constraints already met by the responses to the instructions, which naturally reduces costs and data noise. In the experiments, we adopt Llama3-70B-Instruct to back-translate constraints and create a high-quality complex instruction-response dataset, named CRAB. We present that post-training on CRAB improves multiple backbone LLMs' complex instruction-following ability, evaluated on extensive instruction-following benchmarks. We further find that constraint back-translation also serves as a useful auxiliary training objective in post-training. Our code, data, and models will be released to facilitate future research.</li>
</ul>

<h3>Title: AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties</h3>
<ul>
<li><strong>Authors: </strong>Xiayan Ji, Anton Xue, Eric Wong, Oleg Sokolsky, Insup Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24178">https://arxiv.org/abs/2410.24178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24178">https://arxiv.org/pdf/2410.24178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24178]] AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties(https://arxiv.org/abs/2410.24178)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Anomaly detection is widely used for identifying critical errors and suspicious behaviors, but current methods lack interpretability. We leverage common properties of existing methods and recent advances in generative models to introduce counterfactual explanations for anomaly detection. Given an input, we generate its counterfactual as a diffusion-based repair that shows what a non-anomalous version should have looked like. A key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata, offering a unified framework for generating and evaluating explanations. We demonstrate the effectiveness of our anomaly explainability framework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI) anomaly datasets. The code used for the experiments is accessible at: this https URL.</li>
</ul>

<h3>Title: Federated Black-Box Adaptation for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jay N. Paranjape, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24181">https://arxiv.org/abs/2410.24181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24181">https://arxiv.org/pdf/2410.24181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24181]] Federated Black-Box Adaptation for Semantic Segmentation(https://arxiv.org/abs/2410.24181)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate, segmentation</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a form of distributed learning that allows multiple institutions or clients to collaboratively learn a global model to solve a task. This allows the model to utilize the information from every institute while preserving data privacy. However, recent studies show that the promise of protecting the privacy of data is not upheld by existing methods and that it is possible to recreate the training data from the different institutions. This is done by utilizing gradients transferred between the clients and the global server during training or by knowing the model architecture at the client end. In this paper, we propose a federated learning framework for semantic segmentation without knowing the model architecture nor transferring gradients between the client and the server, thus enabling better privacy preservation. We propose BlackFed - a black-box adaptation of neural networks that utilizes zero order optimization (ZOO) to update the client model weights and first order optimization (FOO) to update the server weights. We evaluate our approach on several computer vision and medical imaging datasets to demonstrate its effectiveness. To the best of our knowledge, this work is one of the first works in employing federated learning for segmentation, devoid of gradients or model information exchange. Code: this https URL</li>
</ul>

<h3>Title: Group Crosscoders for Mechanistic Analysis of Symmetry</h3>
<ul>
<li><strong>Authors: </strong>Liv Gorton</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24184">https://arxiv.org/abs/2410.24184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24184">https://arxiv.org/pdf/2410.24184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24184]] Group Crosscoders for Mechanistic Analysis of Symmetry(https://arxiv.org/abs/2410.24184)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce group crosscoders, an extension of crosscoders that systematically discover and analyse symmetrical features in neural networks. While neural networks often develop equivariant representations without explicit architectural constraints, understanding these emergent symmetries has traditionally relied on manual analysis. Group crosscoders automate this process by performing dictionary learning across transformed versions of inputs under a symmetry group. Applied to InceptionV1's mixed3b layer using the dihedral group $\mathrm{D}_{32}$, our method reveals several key insights: First, it naturally clusters features into interpretable families that correspond to previously hypothesised feature types, providing more precise separation than standard sparse autoencoders. Second, our transform block analysis enables the automatic characterisation of feature symmetries, revealing how different geometric features (such as curves versus lines) exhibit distinct patterns of invariance and equivariance. These results demonstrate that group crosscoders can provide systematic insights into how neural networks represent symmetry, offering a promising new tool for mechanistic interpretability.</li>
</ul>

<h3>Title: SelfCodeAlign: Self-Alignment for Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuxiang Wei, Federico Cassano, Jiawei Liu, Yifeng Ding, Naman Jain, Zachary Mueller, Harm de Vries, Leandro von Werra, Arjun Guha, Lingming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24198">https://arxiv.org/abs/2410.24198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24198">https://arxiv.org/pdf/2410.24198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24198]] SelfCodeAlign: Self-Alignment for Code Generation(https://arxiv.org/abs/2410.24198)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models (LLMs) to follow human instructions. We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs without extensive human annotations or distillation. SelfCodeAlign employs the same base model for inference throughout the data generation process. It first extracts diverse coding concepts from high-quality seed snippets to generate new tasks. It then samples multiple responses per task, pairs each with test cases, and validates them in a sandbox environment. Finally, passing examples are selected for instruction tuning. In our primary experiments, we use SelfCodeAlign with CodeQwen1.5-7B to generate a dataset of 74k instruction-response pairs. Finetuning on this dataset leads to a model that achieves a 67.1 pass@1 on HumanEval+, surpassing CodeLlama-70B-Instruct despite being ten times smaller. Across all benchmarks, this finetuned model consistently outperforms the original version trained with OctoPack, the previous state-of-the-art method for instruction tuning without human annotations or distillation. Additionally, we show that SelfCodeAlign is effective across LLMs of various sizes, from 3B to 33B, and that the base models can benefit more from alignment with their own data distribution. We further validate each component's effectiveness in our pipeline, showing that SelfCodeAlign outperforms both direct distillation from GPT-4o and leading GPT-3.5-based distillation methods, such as OSS-Instruct and Evol-Instruct. SelfCodeAlign has also led to the creation of StarCoder2-Instruct, the first fully transparent, permissively licensed, and self-aligned code LLM that achieves state-of-the-art coding performance.</li>
</ul>

<h3>Title: Length-Induced Embedding Collapse in Transformer-based Models</h3>
<ul>
<li><strong>Authors: </strong>Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24200">https://arxiv.org/abs/2410.24200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24200">https://arxiv.org/pdf/2410.24200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24200]] Length-Induced Embedding Collapse in Transformer-based Models(https://arxiv.org/abs/2410.24200)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Text embeddings enable various applications, but their performance deteriorates on longer texts. In this paper, we find that the performance degradation is due to a phenomenon called Length Collapse, where longer text embeddings collapse into a narrow space. This collapse results in a distributional inconsistency between embeddings of different text lengths, ultimately hurting the performance of downstream tasks. Theoretically, by considering the self-attention mechanism inherently functions as a low-pass filter, we prove that long sequences increase the attenuation rate of the low-pass filter effect of the self-attention mechanism. With layers going deeper, excessive low-pass filtering causes the token signals to retain only their Direct-Current (DC) component, which means the input token feature maps will collapse into a narrow space, especially in long texts. Based on the above analysis, we propose to mitigate the undesirable length collapse limitation by introducing a temperature in softmax(), which achieves a higher low-filter attenuation rate. The tuning-free method, called TempScale, can be plugged into multiple transformer-based embedding models. Empirically, we demonstrate that TempScale can improve existing embedding models, especially on long text inputs, bringing up to 0.53% performance gains on 40 datasets from Massive Text Embedding Benchmark (MTEB) and 0.82% performance gains on 4 datasets from LongEmbed, which specifically focuses on long context retrieval.</li>
</ul>

<h3>Title: P-Masking: Power Law Masking Improves Multi-attribute Controlled Generation</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Elgaar, Hadi Amiri</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24201">https://arxiv.org/abs/2410.24201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24201">https://arxiv.org/pdf/2410.24201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24201]] P-Masking: Power Law Masking Improves Multi-attribute Controlled Generation(https://arxiv.org/abs/2410.24201)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce LingGen, a novel approach for controlled text generation that offers precise control over a wide array of linguistic attributes, even as the number of attributes varies. LingGen employs a dynamic P-MASKING strategy, which samples masking rates from a power law distribution during training. This innovative approach enables the model to develop robust representations and adapt its attribute control capabilities across a variable number of attributes, from a single attribute to multiple complex configurations. The P-MASKING technique enhances LingGen's ability to manage different levels of attribute visibility, resulting in superior performance in multi-attribute generation tasks. Our experiments demonstrate that LingGen surpasses current state-of-the-art models in both attribute control accuracy and text fluency, particularly excelling in scenarios with varying attribute demands. Additionally, our ablation studies highlight the effectiveness of P-MASKING and the influence of different base language models on performance. These findings demonstrate LingGen's potential for applications requiring precise and adaptable control over multiple linguistic attributes in text generation.</li>
</ul>

<h3>Title: DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Weicai Ye, Chenhao Ji, Zheng Chen, Junyao Gao, Xiaoshui Huang, Song-Hai Zhang, Wanli Ouyang, Tong He, Cairong Zhao, Guofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24203">https://arxiv.org/abs/2410.24203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24203">https://arxiv.org/pdf/2410.24203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24203]] DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion(https://arxiv.org/abs/2410.24203)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion-based methods have achieved remarkable achievements in 2D image or 3D object generation, however, the generation of 3D scenes and even $360^{\circ}$ images remains constrained, due to the limited number of scene datasets, the complexity of 3D scenes themselves, and the difficulty of generating consistent multi-view images. To address these issues, we first establish a large-scale panoramic video-text dataset containing millions of consecutive panoramic keyframes with corresponding panoramic depths, camera poses, and text descriptions. Then, we propose a novel text-driven panoramic generation framework, termed DiffPano, to achieve scalable, consistent, and diverse panoramic scene generation. Specifically, benefiting from the powerful generative capabilities of stable diffusion, we fine-tune a single-view text-to-panorama diffusion model with LoRA on the established panoramic video-text dataset. We further design a spherical epipolar-aware multi-view diffusion model to ensure the multi-view consistency of the generated panoramic images. Extensive experiments demonstrate that DiffPano can generate scalable, consistent, and diverse panoramic images with given unseen text descriptions and camera poses.</li>
</ul>

<h3>Title: TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling</h3>
<ul>
<li><strong>Authors: </strong>Yury Gorishniy, Akim Kotelnikov, Artem Babenko</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24210">https://arxiv.org/abs/2410.24210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24210">https://arxiv.org/pdf/2410.24210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24210]] TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling(https://arxiv.org/abs/2410.24210)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods. This study highlights a major, yet so far overlooked opportunity for substantially improving tabular MLPs: namely, parameter-efficient ensembling -- a paradigm for implementing an ensemble of models as one model producing multiple predictions. We start by developing TabM -- a simple model based on MLP and our variations of BatchEnsemble (an existing technique). Then, we perform a large-scale evaluation of tabular DL architectures on public benchmarks in terms of both task performance and efficiency, which renders the landscape of tabular DL in a new light. Generally, we show that MLPs, including TabM, form a line of stronger and more practical models compared to attention- and retrieval-based architectures. In particular, we find that TabM demonstrates the best performance among tabular DL models. Lastly, we conduct an empirical analysis on the ensemble-like nature of TabM. For example, we observe that the multiple predictions of TabM are weak individually, but powerful collectively. Overall, our work brings an impactful technique to tabular DL, analyses its behaviour, and advances the performance-efficiency trade-off with TabM -- a simple and powerful baseline for researchers and practitioners.</li>
</ul>

<h3>Title: DELTA: Dense Efficient Long-range 3D Tracking for any video</h3>
<ul>
<li><strong>Authors: </strong>Tuan Duc Ngo, Peiye Zhuang, Chuang Gan, Evangelos Kalogerakis, Sergey Tulyakov, Hsin-Ying Lee, Chaoyang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24211">https://arxiv.org/abs/2410.24211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24211">https://arxiv.org/pdf/2410.24211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24211]] DELTA: Dense Efficient Long-range 3D Tracking for any video(https://arxiv.org/abs/2410.24211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Tracking dense 3D motion from monocular videos remains challenging, particularly when aiming for pixel-level precision over long sequences. We introduce \Approach, a novel method that efficiently tracks every pixel in 3D space, enabling accurate motion estimation across entire videos. Our approach leverages a joint global-local attention mechanism for reduced-resolution tracking, followed by a transformer-based upsampler to achieve high-resolution predictions. Unlike existing methods, which are limited by computational inefficiency or sparse tracking, \Approach delivers dense 3D tracking at scale, running over 8x faster than previous methods while achieving state-of-the-art accuracy. Furthermore, we explore the impact of depth representation on tracking performance and identify log-depth as the optimal choice. Extensive experiments demonstrate the superiority of \Approach on multiple benchmarks, achieving new state-of-the-art results in both 2D and 3D dense tracking tasks. Our method provides a robust solution for applications requiring fine-grained, long-term motion tracking in 3D space.</li>
</ul>

<h3>Title: Learning Video Representations without Natural Videos</h3>
<ul>
<li><strong>Authors: </strong>Xueyang Yu, Xinlei Chen, Yossi Gandelsman</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24213">https://arxiv.org/abs/2410.24213</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24213">https://arxiv.org/pdf/2410.24213</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24213]] Learning Video Representations without Natural Videos(https://arxiv.org/abs/2410.24213)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we show that useful video representations can be learned from synthetic videos and natural images, without incorporating natural videos in the training. We propose a progression of video datasets synthesized by simple generative processes, that model a growing set of natural video properties (e.g. motion, acceleration, and shape transformations). The downstream performance of video models pre-trained on these generated datasets gradually increases with the dataset progression. A VideoMAE model pre-trained on our synthetic videos closes 97.2% of the performance gap on UCF101 action classification between training from scratch and self-supervised pre-training from natural videos, and outperforms the pre-trained model on HMDB51. Introducing crops of static images to the pre-training stage results in similar performance to UCF101 pre-training and outperforms the UCF101 pre-trained model on 11 out of 14 out-of-distribution datasets of UCF101-P. Analyzing the low-level properties of the datasets, we identify correlations between frame diversity, frame similarity to natural data, and downstream performance. Our approach provides a more controllable and transparent alternative to video data curation processes for pre-training.</li>
</ul>

<h3>Title: ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Yang, Shubham Ugare, Yifan Zhao, Gagandeep Singh, Sasa Misailovic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24214">https://arxiv.org/abs/2410.24214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24214">https://arxiv.org/pdf/2410.24214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24214]] ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs(https://arxiv.org/abs/2410.24214)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Mixed precision quantization has become an important technique for enabling the execution of deep neural networks (DNNs) on limited resource computing platforms. Traditional quantization methods have primarily concentrated on maintaining neural network accuracy, either ignoring the impact of quantization on the robustness of the network, or using only empirical techniques for improving robustness. In contrast, techniques for robustness certification, which can provide strong guarantees about the robustness of DNNs have not been used during quantization due to their high computation cost. This paper introduces ARQ, an innovative mixed-precision quantization method that not only preserves the clean accuracy of the smoothed classifiers but also maintains their certified robustness. ARQ uses reinforcement learning to find accurate and robust DNN quantization, while efficiently leveraging randomized smoothing, a popular class of statistical DNN verification algorithms, to guide the search process. We compare ARQ with multiple state-of-the-art quantization techniques on several DNN architectures commonly used in quantization studies: ResNet-20 on CIFAR-10, ResNet-50 on ImageNet, and MobileNetV2 on ImageNet. We demonstrate that ARQ consistently performs better than these baselines across all the benchmarks and the input perturbation levels. In many cases, the performance of ARQ quantized networks can reach that of the original DNN with floating-point weights, but with only 1.5% instructions.</li>
</ul>

<h3>Title: Bridging Geometric States via Geometric Diffusion Bridge</h3>
<ul>
<li><strong>Authors: </strong>Shengjie Luo, Yixian Xu, Di He, Shuxin Zheng, Tie-Yan Liu, Liwei Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24220">https://arxiv.org/abs/2410.24220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24220">https://arxiv.org/pdf/2410.24220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24220]] Bridging Geometric States via Geometric Diffusion Bridge(https://arxiv.org/abs/2410.24220)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling. Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality. In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states. GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob's $h$-transform for connecting geometric states. This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics. Theoretically, we conduct a thorough examination to confirm our framework's ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability.</li>
</ul>

<h3>Title: Robust Gaussian Processes via Relevance Pursuit</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Ament, Elizabeth Santorella, David Eriksson, Ben Letham, Maximilian Balandat, Eytan Bakshy</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2410.24222">https://arxiv.org/abs/2410.24222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2410.24222">https://arxiv.org/pdf/2410.24222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2410.24222]] Robust Gaussian Processes via Relevance Pursuit(https://arxiv.org/abs/2410.24222)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates. However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions. Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees. In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit. We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods. This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm. We compare the model's performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
