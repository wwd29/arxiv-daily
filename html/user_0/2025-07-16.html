<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-07-16</h1>
<h3>Title: When and Where do Data Poisons Attack Textual Inversion?</h3>
<ul>
<li><strong>Authors: </strong>Jeremy Styborski, Mingzhi Lyu, Jiayou Lu, Nupur Kapur, Adams Kong</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10578">https://arxiv.org/abs/2507.10578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10578">https://arxiv.org/pdf/2507.10578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10578]] When and Where do Data Poisons Attack Textual Inversion?(https://arxiv.org/abs/2507.10578)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Poisoning attacks pose significant challenges to the robustness of diffusion models (DMs). In this paper, we systematically analyze when and where poisoning attacks textual inversion (TI), a widely used personalization technique for DMs. We first introduce Semantic Sensitivity Maps, a novel method for visualizing the influence of poisoning on text embeddings. Second, we identify and experimentally verify that DMs exhibit non-uniform learning behavior across timesteps, focusing on lower-noise samples. Poisoning attacks inherit this bias and inject adversarial signals predominantly at lower timesteps. Lastly, we observe that adversarial signals distract learning away from relevant concept regions within training data, corrupting the TI process. Based on these insights, we propose Safe-Zone Training (SZT), a novel defense mechanism comprised of 3 key components: (1) JPEG compression to weaken high-frequency poison signals, (2) restriction to high timesteps during TI training to avoid adversarial signals at lower timesteps, and (3) loss masking to constrain learning to relevant regions. Extensive experiments across multiple poisoning methods demonstrate that SZT greatly enhances the robustness of TI against all poisoning attacks, improving generative quality beyond prior published defenses. Code: this http URL Data: this http URL</li>
</ul>

<h3>Title: An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Vimaleswar A, Prabhu Nandan Sahu, Nilesh Kumar Sahu, Haroon R Lone</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10580">https://arxiv.org/abs/2507.10580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10580">https://arxiv.org/pdf/2507.10580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10580]] An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation(https://arxiv.org/abs/2507.10580)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Mental health plays a crucial role in the overall well-being of an individual. In recent years, digital platforms have been increasingly used to expand mental health and emotional support. However, there are persistent challenges related to limited user accessibility, internet connectivity, and data privacy, which highlight the need for an offline, smartphone-based solution. To address these challenges, we propose EmoSApp (Emotional Support App): an entirely offline, smartphone-based conversational app designed for mental health and emotional support. The system leverages Large Language Models (LLMs), specifically fine-tuned, quantized and deployed using Torchtune and Executorch for resource-constrained devices, allowing all inferences to occur on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of 14,582 mental-health QA pairs, along with the multi-turn conversational data. Through qualitative human evaluation with the student population, we demonstrate that EmoSApp has the ability to respond coherently, empathetically, maintain interactive dialogue, and provide relevant suggestions to user's mental health problems. Additionally, quantitative evaluations on nine standard commonsense and reasoning benchmarks demonstrate the efficacy of our fine-tuned, quantized model in low-resource settings. By prioritizing on-device deployment and specialized domain adaptation, EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions.</li>
</ul>

<h3>Title: Universal Approximation Theorem for a Single-Layer Transformer</h3>
<ul>
<li><strong>Authors: </strong>Esmail Gumaan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10581">https://arxiv.org/abs/2507.10581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10581">https://arxiv.org/pdf/2507.10581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10581]] Universal Approximation Theorem for a Single-Layer Transformer(https://arxiv.org/abs/2507.10581)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep learning employs multi-layer neural networks trained via the backpropagation algorithm. This approach has achieved success across many domains and relies on adaptive gradient methods such as the Adam optimizer. Sequence modeling evolved from recurrent neural networks to attention-based models, culminating in the Transformer architecture. Transformers have achieved state-of-the-art performance in natural language processing (for example, BERT and GPT-3) and have been applied in computer vision and computational biology. However, theoretical understanding of these models remains limited. In this paper, we examine the mathematical foundations of deep learning and Transformers and present a novel theoretical result. We review key concepts from linear algebra, probability, and optimization that underpin deep learning, and we analyze the multi-head self-attention mechanism and the backpropagation algorithm in detail. Our main contribution is a universal approximation theorem for Transformers: we prove that a single-layer Transformer, comprising one self-attention layer followed by a position-wise feed-forward network with ReLU activation, can approximate any continuous sequence-to-sequence mapping on a compact domain to arbitrary precision. We provide a formal statement and a complete proof. Finally, we present case studies that demonstrate the practical implications of this result. Our findings advance the theoretical understanding of Transformer models and help bridge the gap between theory and practice.</li>
</ul>

<h3>Title: Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis</h3>
<ul>
<li><strong>Authors: </strong>Anders Ledberg, Anna Thal√©n</a></li>
<li><strong>Subjects: </strong>cs.CL, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10582">https://arxiv.org/abs/2507.10582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10582">https://arxiv.org/pdf/2507.10582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10582]] Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis(https://arxiv.org/abs/2507.10582)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Unstructured text from legal, medical, and administrative sources offers a rich but underutilized resource for research in public health and the social sciences. However, large-scale analysis is hampered by two key challenges: the presence of sensitive, personally identifiable information, and significant heterogeneity in structure and language. We present a modular toolchain that prepares such text data for embedding-based analysis, relying entirely on open-weight models that run on local hardware, requiring only a workstation-level GPU and supporting privacy-sensitive research. The toolchain employs large language model (LLM) prompting to standardize, summarize, and, when needed, translate texts to English for greater comparability. Anonymization is achieved via LLM-based redaction, supplemented with named entity recognition and rule-based methods to minimize the risk of disclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court decisions under the Care of Abusers Act (LVM), comprising over 56,000 pages. Each document is processed into an anonymized, standardized summary and transformed into a document-level embedding. Validation, including manual review, automated scanning, and predictive evaluation shows the toolchain effectively removes identifying information while retaining semantic content. As an illustrative application, we train a predictive model using embedding vectors derived from a small set of manually labeled summaries, demonstrating the toolchain's capacity for semi-automated content analysis at scale. By enabling structured, privacy-conscious analysis of sensitive documents, our toolchain opens new possibilities for large-scale research in domains where textual data was previously inaccessible due to privacy and heterogeneity constraints.</li>
</ul>

<h3>Title: A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations</h3>
<ul>
<li><strong>Authors: </strong>Isar Nejadgholi, Mona Omidyeganeh, Marc-Antoine Drouin, Jonathan Boisvert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10585">https://arxiv.org/abs/2507.10585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10585">https://arxiv.org/pdf/2507.10585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10585]] A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations(https://arxiv.org/abs/2507.10585)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effective AI governance requires structured approaches for stakeholders to access and verify AI system behavior. With the rise of large language models, Natural Language Explanations (NLEs) are now key to articulating model behavior, which necessitates a focused examination of their characteristics and governance implications. We draw on Explainable AI (XAI) literature to create an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, including task, data, audience, and goals; (2) Generation and Presentation, covering generation methods, inputs, interactivity, outputs, and forms; and (3) Evaluation, focusing on content, presentation, and user-centered properties, as well as the setting of the evaluation. This taxonomy provides a framework for researchers, auditors, and policymakers to characterize, design, and enhance NLEs for transparent AI systems.</li>
</ul>

<h3>Title: AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters</h3>
<ul>
<li><strong>Authors: </strong>Kaushik Dwivedi, Padmanabh Patanjali Mishra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10586">https://arxiv.org/abs/2507.10586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10586">https://arxiv.org/pdf/2507.10586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10586]] AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters(https://arxiv.org/abs/2507.10586)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable fluency across a range of natural language tasks, yet remain vulnerable to hallucinations - factual inaccuracies that undermine trust in real world deployment. We present AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that tackles hallucination in large language models through lightweight LoRA-based adapters and KL-regularized training. Our pipeline integrates automated prompt rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in retrieved evidence. A hallucination detection module, using both classifier-based and self-evaluation techniques, assigns confidence scores to generated outputs, triggering an optional feedback correction loop. This loop enforces factual alignment via contrastive KL loss and adapter fine tuning. We demonstrate that AutoRAG-LoRA significantly reduces the factual drift while preserving the efficiency and modularity of the model.</li>
</ul>

<h3>Title: Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing</h3>
<ul>
<li><strong>Authors: </strong>Dennis Ulmer, Alexandra Lorson, Ivan Titov, Christian Hardmeier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10587">https://arxiv.org/abs/2507.10587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10587">https://arxiv.org/pdf/2507.10587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10587]] Anthropomimetic Uncertainty: What Verbalized Uncertainty in Language Models is Missing(https://arxiv.org/abs/2507.10587)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human users increasingly rely on natural language interactions with large language models (LLMs) in order to receive help on a large variety of tasks and problems. However, the trustworthiness and perceived legitimacy of LLMs is undermined by the fact that their output is frequently stated in very confident terms, even when its accuracy is questionable. Therefore, there is a need to signal the confidence of the language model to a user in order to reap the benefits of human-machine collaboration and mitigate potential harms. Verbalized uncertainty is the expression of confidence with linguistic means, an approach that integrates perfectly into language-based interfaces. Nevertheless, most recent research in natural language processing (NLP) overlooks the nuances surrounding human uncertainty communication and the data biases that influence machine uncertainty communication. We argue for anthropomimetic uncertainty, meaning that intuitive and trustworthy uncertainty communication requires a degree of linguistic authenticity and personalization to the user, which could be achieved by emulating human communication. We present a thorough overview over the research in human uncertainty communication, survey ongoing research, and perform additional analyses to demonstrate so-far overlooked biases in verbalized uncertainty. We conclude by pointing out unique factors in human-machine communication of uncertainty and deconstruct anthropomimetic uncertainty into future research directions for NLP.</li>
</ul>

<h3>Title: Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer</h3>
<ul>
<li><strong>Authors: </strong>Steve Tippeconnic</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10592">https://arxiv.org/abs/2507.10592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10592">https://arxiv.org/pdf/2507.10592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10592]] Breaking a 5-Bit Elliptic Curve Key using a 133-Qubit Quantum Computer(https://arxiv.org/abs/2507.10592)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>This experiment breaks a 5-bit elliptic curve cryptographic key using a Shor-style quantum attack. Executed on IBM's 133-qubit ibm_torino with Qiskit Runtime 2.0, a 15-qubit circuit, comprised of 10 logical qubits and 5 ancilla, interferes over an order-32 elliptic curve subgroup to extract the secret scalar k from the public key relation Q = kP, without ever encoding k directly into the oracle. From 16,384 shots, the quantum interference reveals a diagonal ridge in the 32 x 32 QFT outcome space. The quantum circuit, over 67,000 layers deep, produced valid interference patterns despite extreme circuit depth, and classical post-processing revealed k = 7 in the top 100 invertible (a, b) results. All code, circuits, and raw data are publicly available for replication.</li>
</ul>

<h3>Title: PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification</h3>
<ul>
<li><strong>Authors: </strong>Yogachandran Rahulamathavan, Misbah Farooq, Varuna De Silva</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10596">https://arxiv.org/abs/2507.10596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10596">https://arxiv.org/pdf/2507.10596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10596]] PLEX: Perturbation-free Local Explanations for LLM-Based Text Classification(https://arxiv.org/abs/2507.10596)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in text classification, but their complexity hinders interpretability, making it difficult to understand the reasoning behind their predictions. Explainable AI (XAI) methods like LIME and SHAP offer local explanations by identifying influential words, but they rely on computationally expensive perturbations. These methods typically generate thousands of perturbed sentences and perform inferences on each, incurring a substantial computational burden, especially with LLMs. To address this, we propose \underline{P}erturbation-free \underline{L}ocal \underline{Ex}planation (PLEX), a novel method that leverages the contextual embeddings extracted from the LLM and a ``Siamese network" style neural network trained to align with feature importance scores. This one-off training eliminates the need for subsequent perturbations, enabling efficient explanations for any new sentence. We demonstrate PLEX's effectiveness on four different classification tasks (sentiment, fake news, fake COVID-19 news and depression), showing more than 92\% agreement with LIME and SHAP. Our evaluation using a ``stress test" reveals that PLEX accurately identifies influential words, leading to a similar decline in classification accuracy as observed with LIME and SHAP when these words are removed. Notably, in some cases, PLEX demonstrates superior performance in capturing the impact of key features. PLEX dramatically accelerates explanation, reducing time and computational overhead by two and four orders of magnitude, respectively. This work offers a promising solution for explainable LLM-based text classification.</li>
</ul>

<h3>Title: Emergence of Hierarchical Emotion Organization in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Bo Zhao, Maya Okawa, Eric J. Bigelow, Rose Yu, Tomer Ullman, Ekdeep Singh Lubana, Hidenori Tanaka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10599">https://arxiv.org/abs/2507.10599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10599">https://arxiv.org/pdf/2507.10599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10599]] Emergence of Hierarchical Emotion Organization in Large Language Models(https://arxiv.org/abs/2507.10599)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) increasingly power conversational agents, understanding how they model users' emotional states is critical for ethical deployment. Inspired by emotion wheels -- a psychological framework that argues emotions organize hierarchically -- we analyze probabilistic dependencies between emotional states in model outputs. We find that LLMs naturally form hierarchical emotion trees that align with human psychological models, and larger models develop more complex hierarchies. We also uncover systematic biases in emotion recognition across socioeconomic personas, with compounding misclassifications for intersectional, underrepresented groups. Human studies reveal striking parallels, suggesting that LLMs internalize aspects of social perception. Beyond highlighting emergent emotional reasoning in LLMs, our results hint at the potential of using cognitively-grounded theories for developing better model evaluations.</li>
</ul>

<h3>Title: RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services</h3>
<ul>
<li><strong>Authors: </strong>Fei Zhao, Chonggang Lu, Yue Wang, Zheyong Xie, Ziyan Liu, Haofu Qian, JianZhao Huang, Fangcheng Shi, Zijie Meng, Hongcheng Guo, Mingqian He, Xinze Lyu, Yiming Lu, Ziyang Xiang, Zheyu Ye, Chengqiang Lu, Zhe Xu, Yi Wu, Yao Hu, Yan Gao, Jun Fan, Xiaolong Jiang, Weiting Liu, Boyang Wang, Shaosheng Cao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10605">https://arxiv.org/abs/2507.10605</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10605">https://arxiv.org/pdf/2507.10605</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10605]] RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services(https://arxiv.org/abs/2507.10605)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.</li>
</ul>

<h3>Title: DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design</h3>
<ul>
<li><strong>Authors: </strong>Bing-Yue Wu, Vidya A. Chhabria</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10606">https://arxiv.org/abs/2507.10606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10606">https://arxiv.org/pdf/2507.10606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10606]] DALI-PD: Diffusion-based Synthetic Layout Heatmap Generation for ML in Physical Design(https://arxiv.org/abs/2507.10606)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) has demonstrated significant promise in various physical design (PD) tasks. However, model generalizability remains limited by the availability of high-quality, large-scale training datasets. Creating such datasets is often computationally expensive and constrained by IP. While very few public datasets are available, they are typically static, slow to generate, and require frequent updates. To address these limitations, we present DALI-PD, a scalable framework for generating synthetic layout heatmaps to accelerate ML in PD research. DALI-PD uses a diffusion model to generate diverse layout heatmaps via fast inference in seconds. The heatmaps include power, IR drop, congestion, macro placement, and cell density maps. Using DALI-PD, we created a dataset comprising over 20,000 layout configurations with varying macro counts and placements. These heatmaps closely resemble real layouts and improve ML accuracy on downstream ML tasks such as IR drop or congestion prediction.</li>
</ul>

<h3>Title: LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents</h3>
<ul>
<li><strong>Authors: </strong>Zihe Yan, Zhuosheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10610">https://arxiv.org/abs/2507.10610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10610">https://arxiv.org/pdf/2507.10610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10610]] LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents(https://arxiv.org/abs/2507.10610)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Graphical user interface (GUI) agents built on multimodal large language models (MLLMs) have recently demonstrated strong decision-making abilities in screen-based interaction tasks. However, they remain highly vulnerable to pop-up-based environmental injection attacks, where malicious visual elements divert model attention and lead to unsafe or incorrect actions. Existing defense methods either require costly retraining or perform poorly under inductive interference. In this work, we systematically study how such attacks alter the attention behavior of GUI agents and uncover a layer-wise attention divergence pattern between correct and incorrect outputs. Based on this insight, we propose \textbf{LaSM}, a \textit{Layer-wise Scaling Mechanism} that selectively amplifies attention and MLP modules in critical layers. LaSM improves the alignment between model saliency and task-relevant regions without additional training. Extensive experiments across 12 types of pop-up perturbations and 4 different model backbones show that LaSM consistently enhances the defense success rate. When combined with prompt-level alerts, LaSM achieves over 98\% robustness even under strong inductive attacks. Our findings reveal that attention misalignment is a core vulnerability in MLLM agents and can be effectively addressed through selective layer-wise modulation.</li>
</ul>

<h3>Title: FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise</h3>
<ul>
<li><strong>Authors: </strong>Mengwen Ye, Yingzi Huangfu, Shujian Gao, Wei Ren, Weifan Liu, Zekuan Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10611">https://arxiv.org/abs/2507.10611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10611">https://arxiv.org/pdf/2507.10611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10611]] FedGSCA: Medical Federated Learning with Global Sample Selector and Client Adaptive Adjuster under Label Noise(https://arxiv.org/abs/2507.10611)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) emerged as a solution for collaborative medical image classification while preserving data privacy. However, label noise, which arises from inter-institutional data variability, can cause training instability and degrade model performance. Existing FL methods struggle with noise heterogeneity and the imbalance in medical data. Motivated by these challenges, we propose FedGSCA, a novel framework for enhancing robustness in noisy medical FL. FedGSCA introduces a Global Sample Selector that aggregates noise knowledge from all clients, effectively addressing noise heterogeneity and improving global model stability. Furthermore, we develop a Client Adaptive Adjustment (CAA) mechanism that combines adaptive threshold pseudo-label generation and Robust Credal Labeling Loss. CAA dynamically adjusts to class distributions, ensuring the inclusion of minority samples and carefully managing noisy labels by considering multiple plausible labels. This dual approach mitigates the impact of noisy data and prevents overfitting during local training, which improves the generalizability of the model. We evaluate FedGSCA on one real-world colon slides dataset and two synthetic medical datasets under various noise conditions, including symmetric, asymmetric, extreme, and heterogeneous types. The results show that FedGSCA outperforms the state-of-the-art methods, excelling in extreme and heterogeneous noise scenarios. Moreover, FedGSCA demonstrates significant advantages in improving model stability and handling complex noise, making it well-suited for real-world medical federated learning scenarios.</li>
</ul>

<h3>Title: Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10613">https://arxiv.org/abs/2507.10613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10613">https://arxiv.org/pdf/2507.10613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10613]] Sub-Scaling Laws: On the Role of Data Density and Training Strategies in LLMs(https://arxiv.org/abs/2507.10613)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional scaling laws in natural language processing suggest that increasing model size and training data enhances performance. However, recent studies reveal deviations, particularly in large language models, where performance improvements decelerate, which is a phenomenon known as sub-scaling. This paper revisits these scaling laws by examining the impact of data quality and training strategies on model performance. Through extensive empirical analysis of over 400 models, we identify high data density and non-optimal resource allocation as key factors contributing to sub-scaling. High data density leads to diminishing returns due to redundant information, while optimal resource allocation is crucial for sustained performance improvements. We propose a sub-optimal scaling law that better predicts performance in sub-scaling regimes, highlighting the importance of data quality and diversity.</li>
</ul>

<h3>Title: Fine-tuning Large Language Model for Automated Algorithm Design</h3>
<ul>
<li><strong>Authors: </strong>Fei Liu, Rui Zhang, Xi Lin, Zhichao Lu, Qingfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10614">https://arxiv.org/abs/2507.10614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10614">https://arxiv.org/pdf/2507.10614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10614]] Fine-tuning Large Language Model for Automated Algorithm Design(https://arxiv.org/abs/2507.10614)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The integration of large language models (LLMs) into automated algorithm design has shown promising potential. A prevalent approach embeds LLMs within search routines to iteratively generate and refine candidate algorithms. However, most existing methods rely on off-the-shelf LLMs trained for general coding tasks,leaving a key question open: Do we need LLMs specifically tailored for algorithm design? If so, how can such LLMs be effectively obtained and how well can they generalize across different algorithm design tasks? In this paper, we take a first step toward answering these questions by exploring fine-tuning of LLMs for algorithm design. We introduce a Diversity-Aware Rank based (DAR) sampling strategy to balance training data diversity and quality, then we leverage direct preference optimization to efficiently align LLM outputs with task objectives. Our experiments, conducted on Llama-3.2-1B-Instruct and Llama- 3.1-8B-Instruct, span three distinct algorithm design tasks. Results suggest that finetuned LLMs can significantly outperform their off-the-shelf counterparts with the smaller Llama-3.2-1B-Instruct and match the larger Llama-3.1-8B-Instruct on the admissible set problem. Moreover, we observe promising generalization: LLMs finetuned on specific algorithm design tasks also improve performance on related tasks with varying settings. These findings highlight the value of task-specific adaptation for LLMs in algorithm design and open new avenues for future research.</li>
</ul>

<h3>Title: Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them</h3>
<ul>
<li><strong>Authors: </strong>Neel Rajani, Aryo Pradipta Gema, Seraphina Goldfarb-Tarrant, Ivan Titov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10616">https://arxiv.org/abs/2507.10616</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10616">https://arxiv.org/pdf/2507.10616</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10616]] Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces Them(https://arxiv.org/abs/2507.10616)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) for reasoning via maths and code datasets has become a major new focus in LLM post-training. Two particularly popular approaches are reinforcement learning (RL) and supervised fine-tuning (SFT), but their training dynamics are poorly understood. We present a comparative analysis of RL and SFT on the same maths problems with the same model and similar hyperparameters. We find that RL yields minor in-domain gains on maths and slight degradation on knowledge-intensive benchmarks like MMLU, while both trends are more pronounced in SFT. We also analyse model parameters across checkpoints, observing that both algorithms modify query and key weights the most. Meanwhile, SFT exhibits greater updates and also affects mid-layer MLPs more, leading us to hypothesise that this may have caused the out-of-domain degradation. We therefore investigate whether freezing parts of the model during training can mitigate the reduced performance on knowledge-intensive benchmarks. However, our results are inconclusive, with benefits on GPQA:Diamond and degradation on other benchmarks. Taken together, our observations provide a preliminary indication for why RL amplifies existing capabilities, while SFT replaces old skills with new ones.</li>
</ul>

<h3>Title: Compute Requirements for Algorithmic Innovation in Frontier AI Models</h3>
<ul>
<li><strong>Authors: </strong>Peter Barnett</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10618">https://arxiv.org/abs/2507.10618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10618">https://arxiv.org/pdf/2507.10618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10618]] Compute Requirements for Algorithmic Innovation in Frontier AI Models(https://arxiv.org/abs/2507.10618)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Algorithmic innovation in the pretraining of large language models has driven a massive reduction in the total compute required to reach a given level of capability. In this paper we empirically investigate the compute requirements for developing algorithmic innovations. We catalog 36 pre-training algorithmic innovations used in Llama 3 and DeepSeek-V3. For each innovation we estimate both the total FLOP used in development and the FLOP/s of the hardware utilized. Innovations using significant resources double in their requirements each year. We then use this dataset to investigate the effect of compute caps on innovation. Our analysis suggests that compute caps alone are unlikely to dramatically slow AI algorithmic progress. Even stringent compute caps -- such as capping total operations to the compute used to train GPT-2 or capping hardware capacity to 8 H100 GPUs -- could still have allowed for half of the cataloged innovations.</li>
</ul>

<h3>Title: Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks</h3>
<ul>
<li><strong>Authors: </strong>Oluwaseyi Giwa, Tobi Awodunmila, Muhammad Ahmed Mohsin, Ahsan Bilal, Muhammad Ali Jamshed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10619">https://arxiv.org/abs/2507.10619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10619">https://arxiv.org/pdf/2507.10619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10619]] Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks(https://arxiv.org/abs/2507.10619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety risks associated with unguided exploration, which can cause severe network interference. To address these challenges, we propose a meta-learning framework that enables agents to learn a robust initial policy and rapidly adapt to new wireless scenarios with minimal data. We implement three meta-learning architectures, model-agnostic meta-learning (MAML), recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate them against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a clear performance gap. The attention-based meta-learning agent reaches a peak mean network throughput of 48 Mbps, while the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method reduces SINR and latency violations by more than 50% compared to PPO. It also shows quick adaptation, with a fairness index 0.7, showing better resource allocation. This work proves that meta-learning is a very effective and safer option for intelligent control in complex wireless systems.</li>
</ul>

<h3>Title: LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Liu, Hao Miao, Cheng Long, Yan Zhao, Ziyue Li, Panos Kalnis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10620">https://arxiv.org/abs/2507.10620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10620">https://arxiv.org/pdf/2507.10620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10620]] LLMs Meet Cross-Modal Time Series Analytics: Overview and Directions(https://arxiv.org/abs/2507.10620)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have emerged as a promising paradigm for time series analytics, leveraging their massive parameters and the shared sequential nature of textual and time series data. However, a cross-modality gap exists between time series and textual data, as LLMs are pre-trained on textual corpora and are not inherently optimized for time series. In this tutorial, we provide an up-to-date overview of LLM-based cross-modal time series analytics. We introduce a taxonomy that classifies existing approaches into three groups based on cross-modal modeling strategies, e.g., conversion, alignment, and fusion, and then discuss their applications across a range of downstream tasks. In addition, we summarize several open challenges. This tutorial aims to expand the practical application of LLMs in solving real-world problems in cross-modal time series analytics while balancing effectiveness and efficiency. Participants will gain a thorough understanding of current advancements, methodologies, and future research directions in cross-modal time series analytics.</li>
</ul>

<h3>Title: Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats</h3>
<ul>
<li><strong>Authors: </strong>Quanyan Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10621">https://arxiv.org/abs/2507.10621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10621">https://arxiv.org/pdf/2507.10621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10621]] Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats(https://arxiv.org/abs/2507.10621)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation. The rise of Large Language Models (LLMs) and agentic AI offers a new path to bridge this gap. LLM-powered agents can operationalize abstract strategies into real-world decisions. Conversely, game theory can inform the reasoning and coordination of these agents across complex workflows. LLMs also challenge classical game-theoretic assumptions, such as perfect rationality or static payoffs, prompting new models aligned with cognitive and computational realities. This co-evolution promises richer theoretical foundations and novel solution concepts. Agentic AI also reshapes software design: systems must now be modular, adaptive, and trust-aware from the outset. This chapter explores the intersection of game theory, agentic AI, and cybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic, Bayesian, and signaling games) and solution concepts. We then examine how LLM agents can enhance cyber defense and introduce LLM-driven games that embed reasoning into AI agents. Finally, we explore multi-agent workflows and coordination games, outlining how this convergence fosters secure, intelligent, and adaptive cyber systems.</li>
</ul>

<h3>Title: Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs</h3>
<ul>
<li><strong>Authors: </strong>HyeYoung Lee, Muhammad Nadeem, Pavel Tsoi</a></li>
<li><strong>Subjects: </strong>cs.CR, cond-mat.dis-nn, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10622">https://arxiv.org/abs/2507.10622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10622">https://arxiv.org/pdf/2507.10622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10622]] Spectral Feature Extraction for Robust Network Intrusion Detection Using MFCCs(https://arxiv.org/abs/2507.10622)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>The rapid expansion of Internet of Things (IoT) networks has led to a surge in security vulnerabilities, emphasizing the critical need for robust anomaly detection and classification techniques. In this work, we propose a novel approach for identifying anomalies in IoT network traffic by leveraging the Mel-frequency cepstral coefficients (MFCC) and ResNet-18, a deep learning model known for its effectiveness in feature extraction and image-based tasks. Learnable MFCCs enable adaptive spectral feature representation, capturing the temporal patterns inherent in network traffic more effectively than traditional fixed MFCCs. We demonstrate that transforming raw signals into MFCCs maps the data into a higher-dimensional space, enhancing class separability and enabling more effective multiclass classification. Our approach combines the strengths of MFCCs with the robust feature extraction capabilities of ResNet-18, offering a powerful framework for anomaly detection. The proposed model is evaluated on three widely used IoT intrusion detection datasets: CICIoT2023, NSL-KDD, and IoTID20. The experimental results highlight the potential of integrating adaptive signal processing techniques with deep learning architectures to achieve robust and scalable anomaly detection in heterogeneous IoT network landscapes.</li>
</ul>

<h3>Title: Flows and Diffusions on the Neural Manifold</h3>
<ul>
<li><strong>Authors: </strong>Daniel Saragih, Deyu Cao, Tejas Balaji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10623">https://arxiv.org/abs/2507.10623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10623">https://arxiv.org/pdf/2507.10623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10623]] Flows and Diffusions on the Neural Manifold(https://arxiv.org/abs/2507.10623)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion and flow-based generative models have achieved remarkable success in domains such as image synthesis, video generation, and natural language modeling. In this work, we extend these advances to weight space learning by leveraging recent techniques to incorporate structural priors derived from optimization dynamics. Central to our approach is modeling the trajectory induced by gradient descent as a trajectory inference problem. We unify several trajectory inference techniques under the framework of gradient flow matching, providing a theoretical framework for treating optimization paths as inductive bias. We further explore architectural and algorithmic choices, including reward fine-tuning by adjoint matching, the use of autoencoders for latent weight representation, conditioning on task-specific context data, and adopting informative source distributions such as Kaiming uniform. Experiments demonstrate that our method matches or surpasses baselines in generating in-distribution weights, improves initialization for downstream training, and supports fine-tuning to enhance performance. Finally, we illustrate a practical application in safety-critical systems: detecting harmful covariate shifts, where our method outperforms the closest comparable baseline.</li>
</ul>

<h3>Title: Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction</h3>
<ul>
<li><strong>Authors: </strong>Lintao Wang, Shiwen Xu, Michael Horton, Joachim Gudmundsson, Zhiyong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10626">https://arxiv.org/abs/2507.10626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10626">https://arxiv.org/pdf/2507.10626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10626]] Player-Team Heterogeneous Interaction Graph Transformer for Soccer Outcome Prediction(https://arxiv.org/abs/2507.10626)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Predicting soccer match outcomes is a challenging task due to the inherently unpredictable nature of the game and the numerous dynamic factors influencing results. While it conventionally relies on meticulous feature engineering, deep learning techniques have recently shown a great promise in learning effective player and team representations directly for soccer outcome prediction. However, existing methods often overlook the heterogeneous nature of interactions among players and teams, which is crucial for accurately modeling match dynamics. To address this gap, we propose HIGFormer (Heterogeneous Interaction Graph Transformer), a novel graph-augmented transformer-based deep learning model for soccer outcome prediction. HIGFormer introduces a multi-level interaction framework that captures both fine-grained player dynamics and high-level team interactions. Specifically, it comprises (1) a Player Interaction Network, which encodes player performance through heterogeneous interaction graphs, combining local graph convolutions with a global graph-augmented transformer; (2) a Team Interaction Network, which constructs interaction graphs from a team-to-team perspective to model historical match relationships; and (3) a Match Comparison Transformer, which jointly analyzes both team and player-level information to predict match outcomes. Extensive experiments on the WyScout Open Access Dataset, a large-scale real-world soccer dataset, demonstrate that HIGFormer significantly outperforms existing methods in prediction accuracy. Furthermore, we provide valuable insights into leveraging our model for player performance evaluation, offering a new perspective on talent scouting and team strategy analysis.</li>
</ul>

<h3>Title: Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Xiaojian Zhang, Junqing Wang, Kerui Chen, Peiyuan Zhao, Huiyuan Bai</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10627">https://arxiv.org/abs/2507.10627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10627">https://arxiv.org/pdf/2507.10627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10627]] Crypto-Assisted Graph Degree Sequence Release under Local Differential Privacy(https://arxiv.org/abs/2507.10627)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Given a graph $G$ defined in a domain $\mathcal{G}$, we investigate locally differentially private mechanisms to release a degree sequence on $\mathcal{G}$ that accurately approximates the actual degree distribution. Existing solutions for this problem mostly use graph projection techniques based on edge deletion process, using a threshold parameter $\theta$ to bound node degrees. However, this approach presents a fundamental trade-off in threshold parameter selection. While large $\theta$ values introduce substantial noise in the released degree sequence, small $\theta$ values result in more edges removed than necessary. Furthermore, $\theta$ selection leads to an excessive communication cost. To remedy existing solutions' deficiencies, we present CADR-LDP, an efficient framework incorporating encryption techniques and differentially private mechanisms to release the degree sequence. In CADR-LDP, we first use the crypto-assisted Optimal-$\theta$-Selection method to select the optimal parameter with a low communication cost. Then, we use the LPEA-LOW method to add some edges for each node with the edge addition process in local projection. LPEA-LOW prioritizes the projection with low-degree nodes, which can retain more edges for such nodes and reduce the projection error. Theoretical analysis shows that CADR-LDP satisfies $\epsilon$-node local differential privacy. The experimental results on eight graph datasets show that our solution outperforms existing methods.</li>
</ul>

<h3>Title: GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziru Liu, Cheng Gong, Xinyu Fu, Yaofang Liu, Ran Chen, Shoubo Hu, Suiyun Zhang, Rui Liu, Qingfu Zhang, Dandan Tu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10628">https://arxiv.org/abs/2507.10628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10628">https://arxiv.org/pdf/2507.10628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10628]] GHPO: Adaptive Guidance for Stable and Efficient LLM Reinforcement Learning(https://arxiv.org/abs/2507.10628)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as a powerful paradigm for facilitating the self-improvement of large language models (LLMs), particularly in the domain of complex reasoning tasks. However, prevailing on-policy RL methods often contend with significant training instability and inefficiency. This is primarily due to a capacity-difficulty mismatch, where the complexity of training data frequently outpaces the model's current capabilities, leading to critically sparse reward signals and stalled learning progress. This challenge is particularly acute for smaller, more resource-efficient LLMs. To overcome this, we introduce the Guided Hybrid Policy Optimization (GHPO), a novel difficulty-aware reinforcement learning framework. GHPO dynamically calibrates task difficulty by employing adaptive prompt refinement to provide targeted guidance. This unique approach adaptively balances direct imitation learning for problems currently beyond the model's reach with exploration-based reinforcement learning for more manageable tasks, effectively creating a smooth and optimized learning curriculum. Extensive experiments demonstrate that GHPO achieves an average performance gain of approximately 5% across six challenging mathematics benchmarks, consistently outperforming strong on-policy reinforcement learning and curriculum learning baselines. Further analysis confirms that our framework significantly enhances both training stability and final reasoning performance, thus offering a scalable and efficient solution for developing powerful and robust reasoning models.</li>
</ul>

<h3>Title: Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process</h3>
<ul>
<li><strong>Authors: </strong>Issei Saito, Masatoshi Nagano, Tomoaki Nakamura, Daichi Mochihashi, Koki Mimura</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10632">https://arxiv.org/abs/2507.10632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10632">https://arxiv.org/pdf/2507.10632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10632]] Scalable Unsupervised Segmentation via Random Fourier Feature-based Gaussian Process(https://arxiv.org/abs/2507.10632)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this paper, we propose RFF-GP-HSMM, a fast unsupervised time-series segmentation method that incorporates random Fourier features (RFF) to address the high computational cost of the Gaussian process hidden semi-Markov model (GP-HSMM). GP-HSMM models time-series data using Gaussian processes, requiring inversion of an N times N kernel matrix during training, where N is the number of data points. As the scale of the data increases, matrix inversion incurs a significant computational cost. To address this, the proposed method approximates the Gaussian process with linear regression using RFF, preserving expressive power while eliminating the need for inversion of the kernel matrix. Experiments on the Carnegie Mellon University (CMU) motion-capture dataset demonstrate that the proposed method achieves segmentation performance comparable to that of conventional methods, with approximately 278 times faster segmentation on time-series data comprising 39,200 frames.</li>
</ul>

<h3>Title: ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space</h3>
<ul>
<li><strong>Authors: </strong>Shim Soon Yong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10638">https://arxiv.org/abs/2507.10638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10638">https://arxiv.org/pdf/2507.10638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10638]] ZClassifier: Temperature Tuning and Manifold Approximation via KL Divergence on Logit Space(https://arxiv.org/abs/2507.10638)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce a novel classification framework, ZClassifier, that replaces conventional deterministic logits with diagonal Gaussian-distributed logits. Our method simultaneously addresses temperature scaling and manifold approximation by minimizing the Kullback-Leibler (KL) divergence between the predicted Gaussian distributions and a unit isotropic Gaussian. This unifies uncertainty calibration and latent control in a principled probabilistic manner, enabling a natural interpretation of class confidence and geometric consistency. Experiments on CIFAR-10 and CIFAR-100 show that ZClassifier improves over softmax classifiers in robustness, calibration, and latent separation. We also demonstrate its effectiveness for classifier-guided generation by interpreting logits as Gaussian semantic potentials.</li>
</ul>

<h3>Title: CWNet: Causal Wavelet Network for Low-Light Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Tongshun Zhang, Pingping Liu, Yubing Lu, Mengen Cai, Zijian Zhang, Zhe Zhang, Qiuzhan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10689">https://arxiv.org/abs/2507.10689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10689">https://arxiv.org/pdf/2507.10689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10689]] CWNet: Causal Wavelet Network for Low-Light Image Enhancement(https://arxiv.org/abs/2507.10689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on uniform brightness adjustment, often neglecting instance-level semantic information and the inherent characteristics of different features. To address these limitations, we propose CWNet (Causal Wavelet Network), a novel architecture that leverages wavelet transforms for causal reasoning. Specifically, our approach comprises two key components: 1) Inspired by the concept of intervention in causality, we adopt a causal reasoning perspective to reveal the underlying causal relationships in low-light enhancement. From a global perspective, we employ a metric learning strategy to ensure causal embeddings adhere to causal principles, separating them from non-causal confounding factors while focusing on the invariance of causal factors. At the local level, we introduce an instance-level CLIP semantic loss to precisely maintain causal factor consistency. 2) Based on our causal analysis, we present a wavelet transform-based backbone network that effectively optimizes the recovery of frequency information, ensuring precise enhancement tailored to the specific attributes of wavelet transforms. Extensive experiments demonstrate that CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes. Code is available at this https URL.</li>
</ul>

<h3>Title: A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models</h3>
<ul>
<li><strong>Authors: </strong>Bright Kwaku Manu, Trevor Reckell, Beckett Sterner, Petar Jevtic</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10714">https://arxiv.org/abs/2507.10714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10714">https://arxiv.org/pdf/2507.10714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10714]] A Simple Approximate Bayesian Inference Neural Surrogate for Stochastic Petri Net Models(https://arxiv.org/abs/2507.10714)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Stochastic Petri Nets (SPNs) are an increasingly popular tool of choice for modeling discrete-event dynamics in areas such as epidemiology and systems biology, yet their parameter estimation remains challenging in general and in particular when transition rates depend on external covariates and explicit likelihoods are unavailable. We introduce a neural-surrogate (neural-network--based approximation of the posterior distribution) framework that predicts the coefficients of known covariate-dependent rate functions directly from noisy, partially observed token trajectories. Our model employs a lightweight 1D Convolutional Residual Network trained end-to-end on Gillespie-simulated SPN realizations, learning to invert system dynamics under realistic conditions of event dropout. During inference, Monte Carlo dropout provides calibrated uncertainty bounds together with point estimates. On synthetic SPNs with 20% missing events, our surrogate recovers rate-function coefficients with an RMSE = 0.108 and substantially runs faster than traditional Bayesian approaches. These results demonstrate that data-driven, likelihood-free surrogates can enable accurate, robust, and real-time parameter recovery in complex, partially observed discrete-event systems.</li>
</ul>

<h3>Title: Distributionally Robust Optimization with Adversarial Data Contamination</h3>
<ul>
<li><strong>Authors: </strong>Shuyao Li, Ilias Diakonikolas, Jelena Diakonikolas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10718">https://arxiv.org/abs/2507.10718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10718">https://arxiv.org/pdf/2507.10718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10718]] Distributionally Robust Optimization with Adversarial Data Contamination(https://arxiv.org/abs/2507.10718)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Distributionally Robust Optimization (DRO) provides a framework for decision-making under distributional uncertainty, yet its effectiveness can be compromised by outliers in the training data. This paper introduces a principled approach to simultaneously address both challenges. We focus on optimizing Wasserstein-1 DRO objectives for generalized linear models with convex Lipschitz loss functions, where an $\epsilon$-fraction of the training data is adversarially corrupted. Our primary contribution lies in a novel modeling framework that integrates robustness against training data contamination with robustness against distributional shifts, alongside an efficient algorithm inspired by robust statistics to solve the resulting optimization problem. We prove that our method achieves an estimation error of $O(\sqrt{\epsilon})$ for the true DRO objective value using only the contaminated data under the bounded covariance assumption. This work establishes the first rigorous guarantees, supported by efficient computation, for learning under the dual challenges of data contamination and distributional shifts.</li>
</ul>

<h3>Title: Access Control for Information-Theoretically Secure Key-Document Stores</h3>
<ul>
<li><strong>Authors: </strong>Yin Li, Sharad Mehrota, Shantanu Sharma, Komal Kumari</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB, cs.DC, cs.DS, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10730">https://arxiv.org/abs/2507.10730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10730">https://arxiv.org/pdf/2507.10730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10730]] Access Control for Information-Theoretically Secure Key-Document Stores(https://arxiv.org/abs/2507.10730)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>This paper presents a novel key-based access control technique for secure outsourcing key-value stores where values correspond to documents that are indexed and accessed using keys. The proposed approach adopts Shamir's secret-sharing that offers unconditional or information-theoretic security. It supports keyword-based document retrieval while preventing leakage of the data, access rights of users, or the size (\textit{i}.\textit{e}., volume of the output that satisfies a query). The proposed approach allows servers to detect (and abort) malicious clients from gaining unauthorized access to data, and prevents malicious servers from altering data undetected while ensuring efficient access -- it takes 231.5ms over 5,000 keywords across 500,000 files.</li>
</ul>

<h3>Title: 3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models</h3>
<ul>
<li><strong>Authors: </strong>Jianyao Yin, Luca Arnaboldi, Honglong Chen, Pascal Berrang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10733">https://arxiv.org/abs/2507.10733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10733">https://arxiv.org/pdf/2507.10733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10733]] 3S-Attack: Spatial, Spectral and Semantic Invisible Backdoor Attack Against DNN Models(https://arxiv.org/abs/2507.10733)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, steal, extraction</a></li>
<li><strong>Abstract: </strong>Backdoor attacks involve either poisoning the training data or directly modifying the model in order to implant a hidden behavior, that causes the model to misclassify inputs when a specific trigger is present. During inference, the model maintains high accuracy on benign samples but misclassifies poisoned samples into an attacker-specified target class. Existing research on backdoor attacks has explored developing triggers in the spatial, spectral (frequency), and semantic (feature) domains, aiming to make them stealthy. While some approaches have considered designing triggers that are imperceptible in both spatial and spectral domains, few have incorporated the semantic domain. In this paper, we propose a novel backdoor attack, termed 3S-attack, which is stealthy across the spatial, spectral, and semantic domains. The key idea is to exploit the semantic features of benign samples as triggers, using Gradient-weighted Class Activation Mapping (Grad-CAM) and a preliminary model for extraction. The trigger is then embedded in the spectral domain, followed by pixel-level restrictions after converting the samples back to the spatial domain. This process minimizes the distance between poisoned and benign samples, making the attack harder to detect by existing defenses and human inspection. Extensive experiments on various datasets, along with theoretical analysis, demonstrate the stealthiness of 3S-attack and highlight the need for stronger defenses to ensure AI security. Our code is available at: this https URL</li>
</ul>

<h3>Title: Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines</h3>
<ul>
<li><strong>Authors: </strong>Jiayuan Chen, Thai-Hoang Pham, Yuanlong Wang, Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10737">https://arxiv.org/abs/2507.10737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10737">https://arxiv.org/pdf/2507.10737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10737]] Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines(https://arxiv.org/abs/2507.10737)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>High-throughput screening techniques, such as microscopy imaging of cellular responses to genetic and chemical perturbations, play a crucial role in drug discovery and biomedical research. However, robust perturbation screening for \textit{de novo} cell lines remains challenging due to the significant morphological and biological heterogeneity across cell lines. To address this, we propose a novel framework that integrates external biological knowledge into existing pretraining strategies to enhance microscopy image profiling models. Our approach explicitly disentangles perturbation-specific and cell line-specific representations using external biological information. Specifically, we construct a knowledge graph leveraging protein interaction data from STRING and Hetionet databases to guide models toward perturbation-specific features during pretraining. Additionally, we incorporate transcriptomic features from single-cell foundation models to capture cell line-specific representations. By learning these disentangled features, our method improves the generalization of imaging models to \textit{de novo} cell lines. We evaluate our framework on the RxRx database through one-shot fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from the RxRx19a dataset. Experimental results demonstrate that our method enhances microscopy image profiling for \textit{de novo} cell lines, highlighting its effectiveness in real-world phenotype-based drug discovery applications.</li>
</ul>

<h3>Title: Language Models for Adult Service Website Text Analysis</h3>
<ul>
<li><strong>Authors: </strong>Nickolas Freeman, Thanh Nguyen, Gregory Bott, Jason Parton, Collin Francel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10743">https://arxiv.org/abs/2507.10743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10743">https://arxiv.org/pdf/2507.10743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10743]] Language Models for Adult Service Website Text Analysis(https://arxiv.org/abs/2507.10743)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sex trafficking refers to the use of force, fraud, or coercion to compel an individual to perform in commercial sex acts against their will. Adult service websites (ASWs) have and continue to be linked to sex trafficking, offering a platform for traffickers to advertise their victims. Thus, organizations involved in the fight against sex trafficking often use ASW data when attempting to identify potential sex trafficking victims. A critical challenge in transforming ASW data into actionable insight is text analysis. Previous research using ASW data has shown that ASW ad text is important for linking ads. However, working with this text is challenging due to its extensive use of emojis, poor grammar, and deliberate obfuscation to evade law enforcement scrutiny. We conduct a comprehensive study of language modeling approaches for this application area, including simple information retrieval methods, pre-trained transformers, and custom transformer models. We demonstrate that characteristics of ASW text data allow efficient custom transformer models to be trained with relatively small GPU resources and used efficiently for inference on consumer hardware. Our custom models outperform fine-tuned variants of well-known encoder-only transformer models, including BERT-base, RoBERTa, and ModernBERT, on accuracy, recall, F1 score, and ROC AUC. We demonstrate the use of our best-performing custom configuration on three tasks related to ASW data analysis: (i) decomposing the giant component in a graph representation of ASW data, (ii) clustering ASW ad text, and (iii) using the learned token embeddings to understand the use of emojis in the illicit context we study. The models we develop represent a significant advancement in ASW text analysis, which can be leveraged in a variety of downstream applications and research.</li>
</ul>

<h3>Title: Spatial Reasoners for Continuous Variables in Any Domain</h3>
<ul>
<li><strong>Authors: </strong>Bart Pogodzinski, Christopher Wewer, Bernt Schiele, Jan Eric Lenssen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10768">https://arxiv.org/abs/2507.10768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10768">https://arxiv.org/pdf/2507.10768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10768]] Spatial Reasoners for Continuous Variables in Any Domain(https://arxiv.org/abs/2507.10768)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present Spatial Reasoners, a software framework to perform spatial reasoning over continuous variables with generative denoising models. Denoising generative models have become the de-facto standard for image generation, due to their effectiveness in sampling from complex, high-dimensional distributions. Recently, they have started being explored in the context of reasoning over multiple continuous variables. Providing infrastructure for generative reasoning with such models requires a high effort, due to a wide range of different denoising formulations, samplers, and inference strategies. Our presented framework aims to facilitate research in this area, providing easy-to-use interfaces to control variable mapping from arbitrary data domains, generative model paradigms, and inference strategies. Spatial Reasoners are openly available at this https URL</li>
</ul>

<h3>Title: FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching</h3>
<ul>
<li><strong>Authors: </strong>Ionu≈£ Grigore, CƒÉlin-Adrian Popa, Claudiu Leoveanu-Condrei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10770">https://arxiv.org/abs/2507.10770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10770">https://arxiv.org/pdf/2507.10770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10770]] FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching(https://arxiv.org/abs/2507.10770)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The extraction and matching of interest points are fundamental to many geometric computer vision tasks. Traditionally, matching is performed by assigning descriptors to interest points and identifying correspondences based on descriptor similarity. This work introduces a technique where interest points are inherently associated during detection, eliminating the need for computing, storing, transmitting, or matching descriptors. Although the matching accuracy is marginally lower than that of conventional approaches, our method completely eliminates the need for descriptors, leading to a drastic reduction in memory usage for localization systems. We assess its effectiveness by comparing it against both classical handcrafted methods and modern learned approaches.</li>
</ul>

<h3>Title: Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs</h3>
<ul>
<li><strong>Authors: </strong>Michal Podstawski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10772">https://arxiv.org/abs/2507.10772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10772">https://arxiv.org/pdf/2507.10772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10772]] Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs(https://arxiv.org/abs/2507.10772)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Labeled property graphs often contain rich textual attributes that can enhance analytical tasks when properly leveraged. This work explores the use of pretrained text embedding models to enable efficient semantic analysis in such graphs. By embedding textual node and edge properties, we support downstream tasks including node classification and relation prediction with improved contextual understanding. Our approach integrates language model embeddings into the graph pipeline without altering its structure, demonstrating that textual semantics can significantly enhance the accuracy and interpretability of property graph analysis.</li>
</ul>

<h3>Title: A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers</h3>
<ul>
<li><strong>Authors: </strong>Jeffrey Joan Sam, Janhavi Sathe, Nikhil Chigali, Naman Gupta, Radhey Ruparel, Yicheng Jiang, Janmajay Singh, James W. Berck, Arko Barman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10775">https://arxiv.org/abs/2507.10775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10775">https://arxiv.org/pdf/2507.10775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10775]] A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers(https://arxiv.org/abs/2507.10775)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Spacecraft deployed in outer space are routinely subjected to various forms of damage due to exposure to hazardous environments. In addition, there are significant risks to the subsequent process of in-space repairs through human extravehicular activity or robotic manipulation, incurring substantial operational costs. Recent developments in image segmentation could enable the development of reliable and cost-effective autonomous inspection systems. While these models often require large amounts of training data to achieve satisfactory results, publicly available annotated spacecraft segmentation data are very scarce. Here, we present a new dataset of nearly 64k annotated spacecraft images that was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds generated using NASA's TTALOS pipeline. To mimic camera distortions and noise in real-world image acquisition, we also added different types of noise and distortion to the images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to generate performance benchmarks for the dataset under well-defined hardware and inference time constraints to mimic real-world image segmentation challenges for real-time onboard applications in space on NASA's inspector spacecraft. The resulting models, when tested under these constraints, achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second. The dataset and models for performance benchmark are available at this https URL.</li>
</ul>

<h3>Title: Warehouse Spatial Question Answering with LLM Agent</h3>
<ul>
<li><strong>Authors: </strong>Hsiang-Wei Huang, Jen-Hao Cheng, Kuang-Ming Chen, Cheng-Yen Yang, Bahaa Alattar, Yi-Ru Lin, Pyongkun Kim, Sangwon Kim, Kwangju Kim, Chung-I Huang, Jenq-Neng Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10778">https://arxiv.org/abs/2507.10778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10778">https://arxiv.org/pdf/2507.10778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10778]] Warehouse Spatial Question Answering with LLM Agent(https://arxiv.org/abs/2507.10778)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: this https URL</li>
</ul>

<h3>Title: ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference</h3>
<ul>
<li><strong>Authors: </strong>Ali Hojjat, Janek Haberer, Soren Pirk, Olaf Landsiedel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10800">https://arxiv.org/abs/2507.10800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10800">https://arxiv.org/pdf/2507.10800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10800]] ThinkingViT: Matryoshka Thinking Vision Transformer for Elastic Inference(https://arxiv.org/abs/2507.10800)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformers deliver state-of-the-art performance, yet their fixed computational budget prevents scalable deployment across heterogeneous hardware. Recent nested Transformer architectures mitigate this by embedding nested subnetworks within a single model to enable scalable inference. However, these models allocate the same amount of compute to all inputs, regardless of their complexity, which leads to inefficiencies. To address this, we introduce ThinkingViT, a nested ViT architecture that employs progressive thinking stages to dynamically adjust inference computation based on input difficulty. ThinkingViT initiates inference by activating a small subset of the most important attention heads and terminates early if predictions reach sufficient certainty. Otherwise, it activates additional attention heads and re-evaluates the input. At the core of ThinkingViT is our Token Recycling mechanism, which conditions each subsequent inference stage on the embeddings from the previous stage, enabling progressive improvement. Due to its backbone-preserving design, ThinkingViT also serves as a plugin upgrade for vanilla ViT. Experiments show that ThinkingViT surpasses nested baselines by up to 2.0 percentage points (p.p.) in accuracy at the same throughput and by up to 2.9 p.p. at equal GMACs on ImageNet-1K. The source code is available at this https URL.</li>
</ul>

<h3>Title: Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Alikhani, Reza Kazemi</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SP, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10808">https://arxiv.org/abs/2507.10808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10808">https://arxiv.org/pdf/2507.10808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10808]] Contrastive-KAN: A Semi-Supervised Intrusion Detection Framework for Cybersecurity with scarce Labeled Data(https://arxiv.org/abs/2507.10808)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>In the era of the Fourth Industrial Revolution, cybersecurity and intrusion detection systems are vital for the secure and reliable operation of IoT and IIoT environments. A key challenge in this domain is the scarcity of labeled cyber-attack data, as most industrial systems operate under normal conditions. This data imbalance, combined with the high cost of annotation, hinders the effective training of machine learning models. Moreover, rapid detection of attacks is essential, especially in critical infrastructure, to prevent large-scale disruptions. To address these challenges, we propose a real-time intrusion detection system based on a semi-supervised contrastive learning framework using the Kolmogorov-Arnold Network (KAN). Our method leverages abundant unlabeled data to distinguish between normal and attack behaviors effectively. We validate our approach on three benchmark datasets: UNSW-NB15, BoT-IoT, and Gas Pipeline, using only 2.20 percent, 1.28 percent, and 8 percent of labeled samples, respectively, to simulate real-world conditions. Experimental results show that our method outperforms existing contrastive learning-based approaches. We further compare KAN with a traditional multilayer perceptron (MLP), demonstrating KAN's superior performance in both detection accuracy and robustness under limited supervision. KAN's ability to model complex relationships and its learnable activation functions are also explored and visualized, offering interpretability and potential for rule extraction. The method supports multi-class classification and proves effective in safety-critical environments where reliability is paramount.</li>
</ul>

<h3>Title: Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions</h3>
<ul>
<li><strong>Authors: </strong>Kazi Tasnim Zinat, Yun Zhou, Xiang Lyu, Yawei Wang, Zhicheng Liu, Panpan Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10809">https://arxiv.org/abs/2507.10809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10809">https://arxiv.org/pdf/2507.10809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10809]] Uncovering Causal Relation Shifts in Event Sequences under Out-of-Domain Interventions(https://arxiv.org/abs/2507.10809)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Inferring causal relationships between event pairs in a temporal sequence is applicable in many domains such as healthcare, manufacturing, and transportation. Most existing work on causal inference primarily focuses on event types within the designated domain, without considering the impact of exogenous out-of-domain interventions. In real-world settings, these out-of-domain interventions can significantly alter causal dynamics. To address this gap, we propose a new causal framework to define average treatment effect (ATE), beyond independent and identically distributed (i.i.d.) data in classic Rubin's causal framework, to capture the causal relation shift between events of temporal process under out-of-domain intervention. We design an unbiased ATE estimator, and devise a Transformer-based neural network model to handle both long-range temporal dependencies and local patterns while integrating out-of-domain intervention information into process modeling. Extensive experiments on both simulated and real-world datasets demonstrate that our method outperforms baselines in ATE estimation and goodness-of-fit under out-of-domain-augmented point processes.</li>
</ul>

<h3>Title: Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER</h3>
<ul>
<li><strong>Authors: </strong>Pedro Almansa Jim√©nez, Lorenzo Fern√°ndez Maim√≥, √Ångel Luis Per√°les G√≥mez</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10819">https://arxiv.org/abs/2507.10819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10819">https://arxiv.org/pdf/2507.10819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10819]] Reporte de vulnerabilidades en IIoT. Proyecto DEFENDER(https://arxiv.org/abs/2507.10819)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The main objective of this technical report is to conduct a comprehensive study on devices operating within Industrial Internet of Things (IIoT) environments, describing the scenarios that define this category and analysing the vulnerabilities that compromise their security. To this end, the report seeks to identify and examine the main classes of IIoT devices, detailing their characteristics, functionalities, and roles within industrial systems. This analysis enables a better understanding of how these devices interact and fulfil the requirements of critical industrial environments. The report also explores the specific contexts in which these devices operate, highlighting the distinctive features of industrial scenarios and the conditions under which the devices function. Furthermore, it analyses the vulnerabilities affecting IIoT devices, outlining their vectors, targets, impact, and consequences. The report then describes the typical phases of an attack, along with a selection of real-world documented incidents. These cases are classified according to the taxonomy presented in Section 3, providing a comprehensive view of the potential threats to security and assessing the impact these vulnerabilities may have on industrial environments. Finally, the report presents a compilation of some of the most recent and effective security countermeasures as potential solutions to the security challenges faced by industrial systems. Special emphasis is placed on the role of Machine Learning in the development of these approaches, underscoring its importance in enhancing industrial cybersecurity.</li>
</ul>

<h3>Title: Semantic Context for Tool Orchestration</h3>
<ul>
<li><strong>Authors: </strong>Robert M√ºller</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10820">https://arxiv.org/abs/2507.10820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10820">https://arxiv.org/pdf/2507.10820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10820]] Semantic Context for Tool Orchestration(https://arxiv.org/abs/2507.10820)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.</li>
</ul>

<h3>Title: REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack</h3>
<ul>
<li><strong>Authors: </strong>Zhonghao Zhan, Huichi Zhou, Hamed Haddadi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10836">https://arxiv.org/abs/2507.10836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10836">https://arxiv.org/pdf/2507.10836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10836]] REAL-IoT: Characterizing GNN Intrusion Detection Robustness under Practical Adversarial Attack(https://arxiv.org/abs/2507.10836)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Graph Neural Network (GNN)-based network intrusion detection systems (NIDS) are often evaluated on single datasets, limiting their ability to generalize under distribution drift. Furthermore, their adversarial robustness is typically assessed using synthetic perturbations that lack realism. This measurement gap leads to an overestimation of GNN-based NIDS resilience. To address the limitations, we propose \textbf{REAL-IoT}, a comprehensive framework for robustness evaluation of GNN-based NIDS in IoT environments. Our framework presents a methodology that creates a unified dataset from canonical datasets to assess generalization under drift. In addition, it features a novel intrusion dataset collected from a physical IoT testbed, which captures network traffic and attack scenarios under real-world settings. Furthermore, using REAL-IoT, we explore the usage of Large Language Models (LLMs) to analyze network data and mitigate the impact of adversarial examples by filtering suspicious flows. Our evaluations using REAL-IoT reveal performance drops in GNN models compared to results from standard benchmarks, quantifying their susceptibility to drift and realistic attacks. We also demonstrate the potential of LLM-based filtering to enhance robustness. These findings emphasize the necessity of realistic threat modeling and rigorous measurement practices for developing resilient IoT intrusion detection systems.</li>
</ul>

<h3>Title: Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps</h3>
<ul>
<li><strong>Authors: </strong>Motoki Omura, Yusuke Mukuta, Kazuki Ota, Takayuki Osa, Tatsuya Harada</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10843">https://arxiv.org/abs/2507.10843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10843">https://arxiv.org/pdf/2507.10843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10843]] Offline Reinforcement Learning with Wasserstein Regularization via Optimal Transport Maps(https://arxiv.org/abs/2507.10843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) aims to learn an optimal policy from a static dataset, making it particularly valuable in scenarios where data collection is costly, such as robotics. A major challenge in offline RL is distributional shift, where the learned policy deviates from the dataset distribution, potentially leading to unreliable out-of-distribution actions. To mitigate this issue, regularization techniques have been employed. While many existing methods utilize density ratio-based measures, such as the $f$-divergence, for regularization, we propose an approach that utilizes the Wasserstein distance, which is robust to out-of-distribution data and captures the similarity between actions. Our method employs input-convex neural networks (ICNNs) to model optimal transport maps, enabling the computation of the Wasserstein distance in a discriminator-free manner, thereby avoiding adversarial training and ensuring stable learning. Our approach demonstrates comparable or superior performance to widely used existing methods on the D4RL benchmark dataset. The code is available at this https URL .</li>
</ul>

<h3>Title: LLM-Guided Agentic Object Detection for Open-World Understanding</h3>
<ul>
<li><strong>Authors: </strong>Furkan Mumcu, Michael J. Jones, Anoop Cherian, Yasin Yilmaz</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10844">https://arxiv.org/abs/2507.10844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10844">https://arxiv.org/pdf/2507.10844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10844]] LLM-Guided Agentic Object Detection for Open-World Understanding(https://arxiv.org/abs/2507.10844)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Object detection traditionally relies on fixed category sets, requiring costly re-training to handle novel objects. While Open-World and Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting autonomy. We propose an LLM-guided agentic object detection (LAOD) framework that enables fully label-free, zero-shot detection by prompting a Large Language Model (LLM) to generate scene-specific object names. These are passed to an open-vocabulary detector for localization, allowing the system to adapt its goals dynamically. We introduce two new metrics, Class-Agnostic Average Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD validate our approach, showing strong performance in detecting and naming novel objects. Our method offers enhanced autonomy and adaptability for open-world understanding.</li>
</ul>

<h3>Title: BandFuzz: An ML-powered Collaborative Fuzzing Framework</h3>
<ul>
<li><strong>Authors: </strong>Wenxuan Shi, Hongwei Li, Jiahao Yu, Xinqian Sun, Wenbo Guo, Xinyu Xing</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10845">https://arxiv.org/abs/2507.10845</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10845">https://arxiv.org/pdf/2507.10845</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10845]] BandFuzz: An ML-powered Collaborative Fuzzing Framework(https://arxiv.org/abs/2507.10845)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Collaborative fuzzing has recently emerged as a technique that combines multiple individual fuzzers and dynamically chooses the appropriate combinations suited for different programs. Unlike individual fuzzers, which rely on specific assumptions to maintain their effectiveness, collaborative fuzzing relaxes the assumptions on target programs, providing constant and robust performance across various programs. Ideally, collaborative fuzzing should be a more promising direction toward generic fuzzing solutions, as it mitigates the need for manual cherry-picking of individual fuzzers. However, the effectiveness of existing collaborative fuzzing frameworks is limited by major challenges, such as the need for additional computational resources compared to individual fuzzers and the inefficient allocation of resources among the various fuzzers.</li>
</ul>

<h3>Title: Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization</h3>
<ul>
<li><strong>Authors: </strong>Casey Wall, Longwei Wang, Rodrigue Rizk, KC Santosh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10846">https://arxiv.org/abs/2507.10846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10846">https://arxiv.org/pdf/2507.10846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10846]] Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization(https://arxiv.org/abs/2507.10846)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Interpreting the decision-making process of Convolutional Neural Networks (CNNs) is critical for deploying models in high-stakes domains. Gradient-weighted Class Activation Mapping (Grad-CAM) is a widely used method for visual explanations, yet it typically focuses on the final convolutional layer or na√Øvely averages across layers, strategies that can obscure important semantic cues or amplify irrelevant noise. We propose Winsor-CAM, a novel, human-tunable extension of Grad-CAM that generates robust and coherent saliency maps by aggregating information across all convolutional layers. To mitigate the influence of noisy or extreme attribution values, Winsor-CAM applies Winsorization, a percentile-based outlier attenuation technique. A user-controllable threshold allows for semantic-level tuning, enabling flexible exploration of model behavior across representational hierarchies. Evaluations on standard architectures (ResNet50, DenseNet121, VGG16, InceptionV3) using the PASCAL VOC 2012 dataset demonstrate that Winsor-CAM produces more interpretable heatmaps and achieves superior performance in localization metrics, including intersection-over-union and center-of-mass alignment, when compared to Grad-CAM and uniform layer-averaging baselines. Winsor-CAM advances the goal of trustworthy AI by offering interpretable, multi-layer insights with human-in-the-loop control.</li>
</ul>

<h3>Title: LLMs on Trial: Evaluating Judicial Fairness for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yiran Hu, Zongyue Xue, Haitao Li, Siyuan Zheng, Qingjing Chen, Shaochun Wang, Xihan Zhang, Ning Zheng, Yun Liu, Qingyao Ai, Yiqun Liu, Charles L.A. Clarke, Weixing Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10852">https://arxiv.org/abs/2507.10852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10852">https://arxiv.org/pdf/2507.10852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10852]] LLMs on Trial: Evaluating Judicial Fairness for Large Language Models(https://arxiv.org/abs/2507.10852)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used in high-stakes fields where their decisions impact rights and equity. However, LLMs' judicial fairness and implications for social justice remain underexplored. When LLMs act as judges, the ability to fairly resolve judicial issues is a prerequisite to ensure their trustworthiness. Based on theories of judicial fairness, we construct a comprehensive framework to measure LLM fairness, leading to a selection of 65 labels and 161 corresponding values. Applying this framework to the judicial system, we compile an extensive dataset, JudiFair, comprising 177,100 unique case facts. To achieve robust statistical inference, we develop three evaluation metrics, inconsistency, bias, and imbalanced inaccuracy, and introduce a method to assess the overall fairness of multiple LLMs across various labels. Through experiments with 16 LLMs, we uncover pervasive inconsistency, bias, and imbalanced inaccuracy across models, underscoring severe LLM judicial unfairness. Particularly, LLMs display notably more pronounced biases on demographic labels, with slightly less bias on substance labels compared to procedure ones. Interestingly, increased inconsistency correlates with reduced biases, but more accurate predictions exacerbate biases. While we find that adjusting the temperature parameter can influence LLM fairness, model size, release date, and country of origin do not exhibit significant effects on judicial fairness. Accordingly, we introduce a publicly available toolkit containing all datasets and code, designed to support future research in evaluating and improving LLM fairness.</li>
</ul>

<h3>Title: PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Thomas Dalton, Hemanth Gowda, Girish Rao, Sachin Pargi, Alireza Hadj Khodabakhshi, Joseph Rombs, Stephan Jou, Manish Marwah</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10854">https://arxiv.org/abs/2507.10854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10854">https://arxiv.org/pdf/2507.10854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10854]] PhreshPhish: A Real-World, High-Quality, Large-Scale Phishing Website Dataset and Benchmark(https://arxiv.org/abs/2507.10854)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Phishing remains a pervasive and growing threat, inflicting heavy economic and reputational damage. While machine learning has been effective in real-time detection of phishing attacks, progress is hindered by lack of large, high-quality datasets and benchmarks. In addition to poor-quality due to challenges in data collection, existing datasets suffer from leakage and unrealistic base rates, leading to overly optimistic performance results. In this paper, we introduce PhreshPhish, a large-scale, high-quality dataset of phishing websites that addresses these limitations. Compared to existing public datasets, PhreshPhish is substantially larger and provides significantly higher quality, as measured by the estimated rate of invalid or mislabeled data points. Additionally, we propose a comprehensive suite of benchmark datasets specifically designed for realistic model evaluation by minimizing leakage, increasing task difficulty, enhancing dataset diversity, and adjustment of base rates more likely to be seen in the real world. We train and evaluate multiple solution approaches to provide baseline performance on the benchmark sets. We believe the availability of this dataset and benchmarks will enable realistic, standardized model comparison and foster further advances in phishing detection. The datasets and benchmarks are available on Hugging Face (this https URL).</li>
</ul>

<h3>Title: Sparse Fine-Tuning of Transformers for Generative Tasks</h3>
<ul>
<li><strong>Authors: </strong>Wei Chen, Jingxi Yu, Zichen Miao, Qiang Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10855">https://arxiv.org/abs/2507.10855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10855">https://arxiv.org/pdf/2507.10855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10855]] Sparse Fine-Tuning of Transformers for Generative Tasks(https://arxiv.org/abs/2507.10855)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Large pre-trained transformers have revolutionized artificial intelligence across various domains, and fine-tuning remains the dominant approach for adapting these models to downstream tasks due to the cost of training from scratch. However, in existing fine-tuning methods, the updated representations are formed as a dense combination of modified parameters, making it challenging to interpret their contributions and understand how the model adapts to new tasks. In this work, we introduce a fine-tuning framework inspired by sparse coding, where fine-tuned features are represented as a sparse combination of basic elements, i.e., feature dictionary atoms. The feature dictionary atoms function as fundamental building blocks of the representation, and tuning atoms allows for seamless adaptation to downstream tasks. Sparse coefficients then serve as indicators of atom importance, identifying the contribution of each atom to the updated representation. Leveraging the atom selection capability of sparse coefficients, we first demonstrate that our method enhances image editing performance by improving text alignment through the removal of unimportant feature dictionary atoms. Additionally, we validate the effectiveness of our approach in the text-to-image concept customization task, where our method efficiently constructs the target concept using a sparse combination of feature dictionary atoms, outperforming various baseline fine-tuning methods.</li>
</ul>

<h3>Title: Visually grounded emotion regulation via diffusion models and user-driven reappraisal</h3>
<ul>
<li><strong>Authors: </strong>Edoardo Pinzuti, Oliver T√ºscher, Andr√© Ferreira Castro</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10861">https://arxiv.org/abs/2507.10861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10861">https://arxiv.org/pdf/2507.10861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10861]] Visually grounded emotion regulation via diffusion models and user-driven reappraisal(https://arxiv.org/abs/2507.10861)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Cognitive reappraisal is a key strategy in emotion regulation, involving reinterpretation of emotionally charged stimuli to alter affective responses. Despite its central role in clinical and cognitive science, real-world reappraisal interventions remain cognitively demanding, abstract, and primarily verbal. This reliance on higher-order cognitive and linguistic processes is often impaired in individuals with trauma or depression, limiting the effectiveness of standard approaches. Here, we propose a novel, visually based augmentation of cognitive reappraisal by integrating large-scale text-to-image diffusion models into the emotional regulation process. Specifically, we introduce a system in which users reinterpret emotionally negative images via spoken reappraisals, which are transformed into supportive, emotionally congruent visualizations using stable diffusion models with a fine-tuned IP-adapter. This generative transformation visually instantiates users' reappraisals while maintaining structural similarity to the original stimuli, externalizing and reinforcing regulatory intent. To test this approach, we conducted a within-subject experiment (N = 20) using a modified cognitive emotion regulation (CER) task. Participants reappraised or described aversive images from the International Affective Picture System (IAPS), with or without AI-generated visual feedback. Results show that AI-assisted reappraisal significantly reduced negative affect compared to both non-AI and control conditions. Further analyses reveal that sentiment alignment between participant reappraisals and generated images correlates with affective relief, suggesting that multimodal coherence enhances regulatory efficacy. These findings demonstrate that generative visual input can support cogitive reappraisal and open new directions at the intersection of generative AI, affective computing, and therapeutic technology.</li>
</ul>

<h3>Title: A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n</h3>
<ul>
<li><strong>Authors: </strong>Saadat Behzadi, Danial Sharifrazi, Bita Mesbahzadeh, Javad Hassannataj Joloudarid, Roohallah Alizadehsani</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10864">https://arxiv.org/abs/2507.10864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10864">https://arxiv.org/pdf/2507.10864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10864]] A Lightweight and Robust Framework for Real-Time Colorectal Polyp Detection Using LOF-Based Preprocessing and YOLO-v11n(https://arxiv.org/abs/2507.10864)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Objectives: Timely and accurate detection of colorectal polyps plays a crucial role in diagnosing and preventing colorectal cancer, a major cause of mortality worldwide. This study introduces a new, lightweight, and efficient framework for polyp detection that combines the Local Outlier Factor (LOF) algorithm for filtering noisy data with the YOLO-v11n deep learning model. Study design: An experimental study leveraging deep learning and outlier removal techniques across multiple public datasets. Methods: The proposed approach was tested on five diverse and publicly available datasets: CVC-ColonDB, CVC-ClinicDB, Kvasir-SEG, ETIS, and EndoScene. Since these datasets originally lacked bounding box annotations, we converted their segmentation masks into suitable detection labels. To enhance the robustness and generalizability of our model, we apply 5-fold cross-validation and remove anomalous samples using the LOF method configured with 30 neighbors and a contamination ratio of 5%. Cleaned data are then fed into YOLO-v11n, a fast and resource-efficient object detection architecture optimized for real-time applications. We train the model using a combination of modern augmentation strategies to improve detection accuracy under diverse conditions. Results: Our approach significantly improves polyp localization performance, achieving a precision of 95.83%, recall of 91.85%, F1-score of 93.48%, mAP@0.5 of 96.48%, and mAP@0.5:0.95 of 77.75%. Compared to previous YOLO-based methods, our model demonstrates enhanced accuracy and efficiency. Conclusions: These results suggest that the proposed method is well-suited for real-time colonoscopy support in clinical settings. Overall, the study underscores how crucial data preprocessing and model efficiency are when designing effective AI systems for medical imaging.</li>
</ul>

<h3>Title: From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection</h3>
<ul>
<li><strong>Authors: </strong>Danyu Sun, Jinghuai Zhang, Jiacen Xu, Yu Zheng, Yuan Tian, Zhou Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10873">https://arxiv.org/abs/2507.10873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10873">https://arxiv.org/pdf/2507.10873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10873]] From Alerts to Intelligence: A Novel LLM-Aided Framework for Host-based Intrusion Detection(https://arxiv.org/abs/2507.10873)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Host-based intrusion detection system (HIDS) is a key defense component to protect the organizations from advanced threats like Advanced Persistent Threats (APT). By analyzing the fine-grained logs with approaches like data provenance, HIDS has shown successes in capturing sophisticated attack traces. Despite the progresses embarked by the research community and industry, HIDS still frequently encounters backlash from their operators in the deployed environments, due to issues like high false-positive rate, inconsistent outcomes across environments and human-unfriendly detection results. Large Language Models (LLMs) have great potentials to advance the state of HIDS, given their extensive knowledge of attack techniques and their ability to detect anomalies through semantic analysis, anchored by recent studies. Yet, our preliminary analysis indicates that building an HIDS by naively prompting an LLM is unlikely to succeed. In this work, we explore the direction of building a customized LLM pipeline for HIDS and develop a system named SHIELD. SHIELD addresses challenges related to LLM's token limits, confusion of background noises, etc., by integrating a variety of techniques like event-level Masked Autoencoder (MAE) for attack window detection, attack evidence identification and expansion, Deterministic Data Augmentation (DDA) for profiling normal activities, and multi-purpose prompting that guides the LLM to conduct precise and interpretable attack investigations. Extensive experiments on three log datasets (DARPA-E3, NodLink-simulated-data and ATLASv2) show that SHIELD consistently achieves outstanding performance in comparison with 5 representative HIDS. These findings highlight the potential of LLMs as powerful tools for intrusion detection and pave the way for future research in this domain.</li>
</ul>

<h3>Title: Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model</h3>
<ul>
<li><strong>Authors: </strong>Hyunwoo Cho, Hyeontae Jo, Hyung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10884">https://arxiv.org/abs/2507.10884</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10884">https://arxiv.org/pdf/2507.10884</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10884]] Learning from Imperfect Data: Robust Inference of Dynamic Systems using Simulation-based Generative Model(https://arxiv.org/abs/2507.10884)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>System inference for nonlinear dynamic models, represented by ordinary differential equations (ODEs), remains a significant challenge in many fields, particularly when the data are noisy, sparse, or partially observable. In this paper, we propose a Simulation-based Generative Model for Imperfect Data (SiGMoID) that enables precise and robust inference for dynamic systems. The proposed approach integrates two key methods: (1) physics-informed neural networks with hyper-networks that constructs an ODE solver, and (2) Wasserstein generative adversarial networks that estimates ODE parameters by effectively capturing noisy data distributions. We demonstrate that SiGMoID quantifies data noise, estimates system parameters, and infers unobserved system components. Its effectiveness is validated validated through realistic experimental examples, showcasing its broad applicability in various domains, from scientific research to engineered systems, and enabling the discovery of full system dynamics.</li>
</ul>

<h3>Title: How to Protect Models against Adversarial Unlearning?</h3>
<ul>
<li><strong>Authors: </strong>Patryk Jasiorski, Marek Klonowski, Micha≈Ç Wo≈∫niak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10886">https://arxiv.org/abs/2507.10886</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10886">https://arxiv.org/pdf/2507.10886</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10886]] How to Protect Models against Adversarial Unlearning?(https://arxiv.org/abs/2507.10886)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>AI models need to be unlearned to fulfill the requirements of legal acts such as the AI Act or GDPR, and also because of the need to remove toxic content, debiasing, the impact of malicious instances, or changes in the data distribution structure in which a model works. Unfortunately, removing knowledge may cause undesirable side effects, such as a deterioration in model performance. In this paper, we investigate the problem of adversarial unlearning, where a malicious party intentionally sends unlearn requests to deteriorate the model's performance maximally. We show that this phenomenon and the adversary's capabilities depend on many factors, primarily on the backbone model itself and strategy/limitations in selecting data to be unlearned. The main result of this work is a new method of protecting model performance from these side effects, both in the case of unlearned behavior resulting from spontaneous processes and adversary actions.</li>
</ul>

<h3>Title: Outbound Modeling for Inventory Management</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Savorgnan, Udaya Ghai, Carson Eisenach, Dean Foster</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10890">https://arxiv.org/abs/2507.10890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10890">https://arxiv.org/pdf/2507.10890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10890]] Outbound Modeling for Inventory Management(https://arxiv.org/abs/2507.10890)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the problem of forecasting the number of units fulfilled (or ``drained'') from each inventory warehouse to meet customer demand, along with the associated outbound shipping costs. The actual drain and shipping costs are determined by complex production systems that manage the planning and execution of customers' orders fulfillment, i.e. from where and how to ship a unit to be delivered to a customer. Accurately modeling these processes is critical for regional inventory planning, especially when using Reinforcement Learning (RL) to develop control policies. For the RL usecase, a drain model is incorporated into a simulator to produce long rollouts, which we desire to be differentiable. While simulating the calls to the internal software systems can be used to recover this transition, they are non-differentiable and too slow and costly to run within an RL training environment. Accordingly, we frame this as a probabilistic forecasting problem, modeling the joint distribution of outbound drain and shipping costs across all warehouses at each time period, conditioned on inventory positions and exogenous customer demand. To ensure robustness in an RL environment, the model must handle out-of-distribution scenarios that arise from off-policy trajectories. We propose a validation scheme that leverages production systems to evaluate the drain model on counterfactual inventory states induced by RL policies. Preliminary results demonstrate the model's accuracy within the in-distribution setting.</li>
</ul>

<h3>Title: Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Minjong Cheon, Eunhan Goo, Su-Hyeon Shin, Muhammad Ahmed, Hyungjun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10893">https://arxiv.org/abs/2507.10893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10893">https://arxiv.org/pdf/2507.10893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10893]] Modernizing CNN-based Weather Forecast Model towards Higher Computational Efficiency(https://arxiv.org/abs/2507.10893)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Recently, AI-based weather forecast models have achieved impressive advances. These models have reached accuracy levels comparable to traditional NWP systems, marking a significant milestone in data-driven weather prediction. However, they mostly leverage Transformer-based architectures, which often leads to high training complexity and resource demands due to the massive parameter sizes. In this study, we introduce a modernized CNN-based model for global weather forecasting that delivers competitive accuracy while significantly reducing computational requirements. To present a systematic modernization roadmap, we highlight key architectural enhancements across multiple design scales from an earlier CNN-based approach. KAI-a incorporates a scale-invariant architecture and InceptionNeXt-based blocks within a geophysically-aware design, tailored to the structure of Earth system data. Trained on the ERA5 daily dataset with 67 atmospheric variables, the model contains about 7 million parameters and completes training in just 12 hours on a single NVIDIA L40s GPU. Our evaluation shows that KAI-a matches the performance of state-of-the-art models in medium-range weather forecasting, while offering a significantly lightweight design. Furthermore, case studies on the 2018 European heatwave and the East Asian summer monsoon demonstrate KAI-a's robust skill in capturing extreme events, reinforcing its practical utility.</li>
</ul>

<h3>Title: Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xiaocong Zeng, Craig Michoski, Yan Pang, Dongyang Kuang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10895">https://arxiv.org/abs/2507.10895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10895">https://arxiv.org/pdf/2507.10895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10895]] Commuting Distance Regularization for Timescale-Dependent Label Inconsistency in EEG Emotion Recognition(https://arxiv.org/abs/2507.10895)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, transformer</a></li>
<li><strong>Abstract: </strong>In this work, we address the often-overlooked issue of Timescale Dependent Label Inconsistency (TsDLI) in training neural network models for EEG-based human emotion recognition. To mitigate TsDLI and enhance model generalization and explainability, we propose two novel regularization strategies: Local Variation Loss (LVL) and Local-Global Consistency Loss (LGCL). Both methods incorporate classical mathematical principles--specifically, functions of bounded variation and commute-time distances--within a graph theoretic framework. Complementing our regularizers, we introduce a suite of new evaluation metrics that better capture the alignment between temporally local predictions and their associated global emotion labels. We validate our approach through comprehensive experiments on two widely used EEG emotion datasets, DREAMER and DEAP, across a range of neural architectures including LSTM and transformer-based models. Performance is assessed using five distinct metrics encompassing both quantitative accuracy and qualitative consistency. Results consistently show that our proposed methods outperform state-of-the-art baselines, delivering superior aggregate performance and offering a principled trade-off between interpretability and predictive power under label inconsistency. Notably, LVL achieves the best aggregate rank across all benchmarked backbones and metrics, while LGCL frequently ranks the second, highlighting the effectiveness of our framework.</li>
</ul>

<h3>Title: MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jugal Gajjar, Kamalasankari Subramaniakuppusamy, Noha El Kachach</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10898">https://arxiv.org/abs/2507.10898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10898">https://arxiv.org/pdf/2507.10898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10898]] MalCodeAI: Autonomous Vulnerability Detection and Remediation via Language Agnostic Code Reasoning(https://arxiv.org/abs/2507.10898)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, interpretability</a></li>
<li><strong>Abstract: </strong>The growing complexity of cyber threats and the limitations of traditional vulnerability detection tools necessitate novel approaches for securing software systems. We introduce MalCodeAI, a language-agnostic, multi-stage AI pipeline for autonomous code security analysis and remediation. MalCodeAI combines code decomposition and semantic reasoning using fine-tuned Qwen2.5-Coder-3B-Instruct models, optimized through Low-Rank Adaptation (LoRA) within the MLX framework, and delivers scalable, accurate results across 14 programming languages. In Phase 1, the model achieved a validation loss as low as 0.397 for functional decomposition and summarization of code segments after 200 iterations, 6 trainable layers, and a learning rate of 2 x 10^(-5). In Phase 2, for vulnerability detection and remediation, it achieved a best validation loss of 0.199 using the same number of iterations and trainable layers but with an increased learning rate of 4 x 10^(-5), effectively identifying security flaws and suggesting actionable fixes. MalCodeAI supports red-hat-style exploit tracing, CVSS-based risk scoring, and zero-shot generalization to detect complex, zero-day vulnerabilities. In a qualitative evaluation involving 15 developers, the system received high scores in usefulness (mean 8.06/10), interpretability (mean 7.40/10), and readability of outputs (mean 7.53/10), confirming its practical value in real-world development workflows. This work marks a significant advancement toward intelligent, explainable, and developer-centric software security solutions.</li>
</ul>

<h3>Title: Class-Proportional Coreset Selection for Difficulty-Separable Data</h3>
<ul>
<li><strong>Authors: </strong>Elisa Tsai, Haizhong Zheng, Atul Prakash</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10904">https://arxiv.org/abs/2507.10904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10904">https://arxiv.org/pdf/2507.10904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10904]] Class-Proportional Coreset Selection for Difficulty-Separable Data(https://arxiv.org/abs/2507.10904)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>High-quality training data is essential for building reliable and efficient machine learning systems. One-shot coreset selection addresses this by pruning the dataset while maintaining or even improving model performance, often relying on training-dynamics-based data difficulty scores. However, most existing methods implicitly assume class-wise homogeneity in data difficulty, overlooking variation in data difficulty across different classes. In this work, we challenge this assumption by showing that, in domains such as network intrusion detection and medical imaging, data difficulty often clusters by class. We formalize this as class-difficulty separability and introduce the Class Difficulty Separability Coefficient (CDSC) as a quantitative measure. We demonstrate that high CDSC values correlate with performance degradation in class-agnostic coreset methods, which tend to overrepresent easy majority classes while neglecting rare but informative ones. To address this, we introduce class-proportional variants of multiple sampling strategies. Evaluated on five diverse datasets spanning security and medical domains, our methods consistently achieve state-of-the-art data efficiency. For instance, on CTU-13, at an extreme 99% pruning rate, a class-proportional variant of Coverage-centric Coreset Selection (CCS-CP) shows remarkable stability, with accuracy dropping only 2.58%, precision 0.49%, and recall 0.19%. In contrast, the class-agnostic CCS baseline, the next best method, suffers sharper declines of 7.59% in accuracy, 4.57% in precision, and 4.11% in recall. We further show that aggressive pruning enhances generalization in noisy, imbalanced, and large-scale datasets. Our results underscore that explicitly modeling class-difficulty separability leads to more effective, robust, and generalizable data pruning, particularly in high-stakes scenarios.</li>
</ul>

<h3>Title: HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Seungho Choi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10920">https://arxiv.org/abs/2507.10920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10920">https://arxiv.org/pdf/2507.10920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10920]] HanjaBridge: Resolving Semantic Ambiguity in Korean LLMs via Hanja-Augmented Pre-Training(https://arxiv.org/abs/2507.10920)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often show poor performance in low-resource languages like Korean, partly due to unique linguistic challenges such as homophonous Sino-Korean words that are indistinguishable in Hangul script. To address this semantic ambiguity, we propose HanjaBridge, a novel meaning-injection technique integrated into a continual pre-training (CPT) framework. Instead of deterministically mapping a word to a single Hanja (Chinese character), HanjaBridge presents the model with all possible Hanja candidates for a given homograph, encouraging the model to learn contextual disambiguation. This process is paired with token-level knowledge distillation to prevent catastrophic forgetting. Experimental results show that HanjaBridge significantly improves Korean language understanding, achieving a 21\% relative improvement on the KoBALT benchmark. Notably, by reinforcing semantic alignment between Korean and Chinese through shared Hanja, we observe a strong positive cross-lingual transfer. Furthermore, these gains persist even when Hanja augmentation is omitted at inference time, ensuring practical efficiency with no additional run-time cost.</li>
</ul>

<h3>Title: DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Xiaohong Li, Man Zheng, Zhe Hou, Guangdong Bai, Ruitao Feng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10927">https://arxiv.org/abs/2507.10927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10927">https://arxiv.org/pdf/2507.10927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10927]] DVFS: A Dynamic Verifiable Fuzzy Search Service for Encrypted Cloud Data(https://arxiv.org/abs/2507.10927)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>Cloud storage introduces critical privacy challenges for encrypted data retrieval, where fuzzy multi-keyword search enables approximate matching while preserving data confidentiality. Existing solutions face fundamental trade-offs between security and efficiency: linear-search mechanisms provide adaptive security but incur prohibitive overhead for large-scale data, while tree-based indexes improve performance at the cost of branch leakage vulnerabilities. To address these limitations, we propose DVFS - a dynamic verifiable fuzzy search service with three core innovations: (1) An \textit{adaptive-secure fuzzy search} method integrating locality-sensitive hashing with virtual binary trees, eliminating branch leakage while reducing search complexity from linear to sublinear ($O(\log n)$ time); (2) A \textit{dual-repository version control} mechanism supporting dynamic updates with forward privacy, preventing information leakage during operations; (3) A \textit{blockchain-based verification system} that ensures correctness and completeness via smart contracts, achieving $O(\log n)$ verification complexity. Our solution advances secure encrypted retrieval by simultaneously resolving the security-performance paradox and enabling trustworthy dynamic operations.</li>
</ul>

<h3>Title: GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization</h3>
<ul>
<li><strong>Authors: </strong>Shaowen Tong, Zimin Xia, Alexandre Alahi, Xuming He, Yujiao Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10935">https://arxiv.org/abs/2507.10935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10935">https://arxiv.org/pdf/2507.10935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10935]] GeoDistill: Geometry-Guided Self-Distillation for Weakly Supervised Cross-View Localization(https://arxiv.org/abs/2507.10935)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-view localization, the task of estimating a camera's 3-degrees-of-freedom (3-DoF) pose by aligning ground-level images with satellite images, is crucial for large-scale outdoor applications like autonomous navigation and augmented reality. Existing methods often rely on fully supervised learning, which requires costly ground-truth pose annotations. In this work, we propose GeoDistill, a Geometry guided weakly supervised self distillation framework that uses teacher-student learning with Field-of-View (FoV)-based masking to enhance local feature learning for robust cross-view localization. In GeoDistill, the teacher model localizes a panoramic image, while the student model predicts locations from a limited FoV counterpart created by FoV-based masking. By aligning the student's predictions with those of the teacher, the student focuses on key features like lane lines and ignores textureless regions, such as roads. This results in more accurate predictions and reduced uncertainty, regardless of whether the query images are panoramas or limited FoV images. Our experiments show that GeoDistill significantly improves localization performance across different frameworks. Additionally, we introduce a novel orientation estimation network that predicts relative orientation without requiring precise planar position ground truth. GeoDistill provides a scalable and efficient solution for real-world cross-view localization challenges. Code and model can be found at this https URL.</li>
</ul>

<h3>Title: Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing</h3>
<ul>
<li><strong>Authors: </strong>Zhengyi Xu, Haoran Wu, Wen Jiang, Jie Geng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10938">https://arxiv.org/abs/2507.10938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10938">https://arxiv.org/pdf/2507.10938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10938]] Graph Aggregation Prototype Learning for Semantic Change Detection in Remote Sensing(https://arxiv.org/abs/2507.10938)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Semantic change detection (SCD) extends the binary change detection task to provide not only the change locations but also the detailed "from-to" categories in multi-temporal remote sensing data. Such detailed semantic insights into changes offer considerable advantages for a wide array of applications. However, since SCD involves the simultaneous optimization of multiple tasks, the model is prone to negative transfer due to task-specific learning difficulties and conflicting gradient flows. To address this issue, we propose Graph Aggregation Prototype Learning for Semantic Change Detection in remote sensing(GAPL-SCD). In this framework, a multi-task joint optimization method is designed to optimize the primary task of semantic segmentation and change detection, along with the auxiliary task of graph aggregation prototype learning. Adaptive weight allocation and gradient rotation methods are used to alleviate the conflict between training tasks and improve multi-task learning capabilities. Specifically, the graph aggregation prototype learning module constructs an interaction graph using high-level features. Prototypes serve as class proxies, enabling category-level domain alignment across time points and reducing interference from irrelevant changes. Additionally, the proposed self-query multi-level feature interaction and bi-temporal feature fusion modules further enhance multi-scale feature representation, improving performance in complex scenes. Experimental results on the SECOND and Landsat-SCD datasets demonstrate that our method achieves state-of-the-art performance, with significant improvements in accuracy and robustness for SCD task.</li>
</ul>

<h3>Title: Robust ID-Specific Face Restoration via Alignment Learning</h3>
<ul>
<li><strong>Authors: </strong>Yushun Fang, Lu Liu, Xiang Gao, Qiang Hu, Ning Cao, Jianghe Cui, Gang Chen, Xiaoyun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10943">https://arxiv.org/abs/2507.10943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10943">https://arxiv.org/pdf/2507.10943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10943]] Robust ID-Specific Face Restoration via Alignment Learning(https://arxiv.org/abs/2507.10943)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The latest developments in Face Restoration have yielded significant advancements in visual quality through the utilization of diverse diffusion priors. Nevertheless, the uncertainty of face identity introduced by identity-obscure inputs and stochastic generative processes remains unresolved. To address this challenge, we present Robust ID-Specific Face Restoration (RIDFR), a novel ID-specific face restoration framework based on diffusion models. Specifically, RIDFR leverages a pre-trained diffusion model in conjunction with two parallel conditioning modules. The Content Injection Module inputs the severely degraded image, while the Identity Injection Module integrates the specific identity from a given image. Subsequently, RIDFR incorporates Alignment Learning, which aligns the restoration results from multiple references with the same identity in order to suppress the interference of ID-irrelevant face semantics (e.g. pose, expression, make-up, hair style). Experiments demonstrate that our framework outperforms the state-of-the-art methods, reconstructing high-quality ID-specific results with high identity fidelity and demonstrating strong robustness.</li>
</ul>

<h3>Title: Diffusion Decoding for Peptide De Novo Sequencing</h3>
<ul>
<li><strong>Authors: </strong>Chi-en Amy Tai, Alexander Wong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10955">https://arxiv.org/abs/2507.10955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10955">https://arxiv.org/pdf/2507.10955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10955]] Diffusion Decoding for Peptide De Novo Sequencing(https://arxiv.org/abs/2507.10955)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Peptide de novo sequencing is a method used to reconstruct amino acid sequences from tandem mass spectrometry data without relying on existing protein sequence databases. Traditional deep learning approaches, such as Casanovo, mainly utilize autoregressive decoders and predict amino acids sequentially. Subsequently, they encounter cascading errors and fail to leverage high-confidence regions effectively. To address these issues, this paper investigates using diffusion decoders adapted for the discrete data domain. These decoders provide a different approach, allowing sequence generation to start from any peptide segment, thereby enhancing prediction accuracy. We experiment with three different diffusion decoder designs, knapsack beam search, and various loss functions. We find knapsack beam search did not improve performance metrics and simply replacing the transformer decoder with a diffusion decoder lowered performance. Although peptide precision and recall were still 0, the best diffusion decoder design with the DINOISER loss function obtained a statistically significant improvement in amino acid recall by 0.373 compared to the baseline autoregressive decoder-based Casanovo model. These findings highlight the potential of diffusion decoders to not only enhance model sensitivity but also drive significant advancements in peptide de novo sequencing.</li>
</ul>

<h3>Title: Modeling Understanding of Story-Based Analogies Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kalit Inani, Keshav Kabra, Vijay Marupudi, Sashank Varma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10957">https://arxiv.org/abs/2507.10957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10957">https://arxiv.org/pdf/2507.10957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10957]] Modeling Understanding of Story-Based Analogies Using Large Language Models(https://arxiv.org/abs/2507.10957)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have brought them closer to matching human cognition across a variety of tasks. How well do these models align with human performance in detecting and mapping analogies? Prior research has shown that LLMs can extract similarities from analogy problems but lack robust human-like reasoning. Building on Webb, Holyoak, and Lu (2023), the current study focused on a story-based analogical mapping task and conducted a fine-grained evaluation of LLM reasoning abilities compared to human performance. First, it explored the semantic representation of analogies in LLMs, using sentence embeddings to assess whether they capture the similarity between the source and target texts of an analogy, and the dissimilarity between the source and distractor texts. Second, it investigated the effectiveness of explicitly prompting LLMs to explain analogies. Throughout, we examine whether LLMs exhibit similar performance profiles to those observed in humans by evaluating their reasoning at the level of individual analogies, and not just at the level of overall accuracy (as prior studies have done). Our experiments include evaluating the impact of model size (8B vs. 70B parameters) and performance variation across state-of-the-art model architectures such as GPT-4 and LLaMA3. This work advances our understanding of the analogical reasoning abilities of LLMs and their potential as models of human reasoning.</li>
</ul>

<h3>Title: Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data</h3>
<ul>
<li><strong>Authors: </strong>Palash Ray, Mahuya Sasmal, Asish Bera</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10969">https://arxiv.org/abs/2507.10969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10969">https://arxiv.org/pdf/2507.10969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10969]] Women Sport Actions Dataset for Visual Classification Using Small Scale Training Data(https://arxiv.org/abs/2507.10969)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Sports action classification representing complex body postures and player-object interactions is an emerging area in image-based sports analysis. Some works have contributed to automated sports action recognition using machine learning techniques over the past decades. However, sufficient image datasets representing women sports actions with enough intra- and inter-class variations are not available to the researchers. To overcome this limitation, this work presents a new dataset named WomenSports for women sports classification using small-scale training data. This dataset includes a variety of sports activities, covering wide variations in movements, environments, and interactions among players. In addition, this study proposes a convolutional neural network (CNN) for deep feature extraction. A channel attention scheme upon local contextual regions is applied to refine and enhance feature representation. The experiments are carried out on three different sports datasets and one dance dataset for generalizing the proposed algorithm, and the performances on these datasets are noteworthy. The deep learning method achieves 89.15% top-1 classification accuracy using ResNet-50 on the proposed WomenSports dataset, which is publicly available for research at Mendeley Data.</li>
</ul>

<h3>Title: Teach Me Sign: Stepwise Prompting LLM for Sign Language Production</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyi An, Rei Kawakami</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10972">https://arxiv.org/abs/2507.10972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10972">https://arxiv.org/pdf/2507.10972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10972]] Teach Me Sign: Stepwise Prompting LLM for Sign Language Production(https://arxiv.org/abs/2507.10972)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models, with their strong reasoning ability and rich knowledge, have brought revolution to many tasks of AI, but their impact on sign language generation remains limited due to its complexity and unique rules. In this paper, we propose TEAch Me Sign (TEAM-Sign), treating sign language as another natural language. By fine-tuning an LLM, we enable it to learn the correspondence between text and sign language, and facilitate generation. Considering the differences between sign and spoken language, we employ a stepwise prompting strategy to extract the inherent sign language knowledge within the LLM, thereby supporting the learning and generation process. Experimental results on How2Sign and Phoenix14T datasets demonstrate that our approach effectively leverages both the sign language knowledge and reasoning capabilities of LLM to align the different distribution and grammatical rules between sign and spoken language.</li>
</ul>

<h3>Title: Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review</h3>
<ul>
<li><strong>Authors: </strong>Tao Han, Zahra Taheri, Hyunwoong Ko</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10983">https://arxiv.org/abs/2507.10983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10983">https://arxiv.org/pdf/2507.10983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10983]] Physics-Informed Neural Networks For Semiconductor Film Deposition: A Review(https://arxiv.org/abs/2507.10983)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Semiconductor manufacturing relies heavily on film deposition processes, such as Chemical Vapor Deposition and Physical Vapor Deposition. These complex processes require precise control to achieve film uniformity, proper adhesion, and desired functionality. Recent advancements in Physics-Informed Neural Networks (PINNs), an innovative machine learning (ML) approach, have shown significant promise in addressing challenges related to process control, quality assurance, and predictive modeling within semiconductor film deposition and other manufacturing domains. This paper provides a comprehensive review of ML applications targeted at semiconductor film deposition processes. Through a thematic analysis, we identify key trends, existing limitations, and research gaps, offering insights into both the advantages and constraints of current methodologies. Our structured analysis aims to highlight the potential integration of these ML techniques to enhance interpretability, accuracy, and robustness in film deposition processes. Additionally, we examine state-of-the-art PINN methods, discussing strategies for embedding physical knowledge, governing laws, and partial differential equations into advanced neural network architectures tailored for semiconductor manufacturing. Based on this detailed review, we propose novel research directions that integrate the strengths of PINNs to significantly advance film deposition processes. The contributions of this study include establishing a clear pathway for future research in integrating physics-informed ML frameworks, addressing existing methodological gaps, and ultimately improving precision, scalability, and operational efficiency within semiconductor manufacturing.</li>
</ul>

<h3>Title: Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Zhipeng He, Alexander Stevens, Chun Ouyang, Johannes De Smedt, Alistair Barros, Catarina Moreira</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10998">https://arxiv.org/abs/2507.10998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10998">https://arxiv.org/pdf/2507.10998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10998]] Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data(https://arxiv.org/abs/2507.10998)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Adversarial attacks on tabular data present fundamental challenges distinct from image or text domains due to the heterogeneous nature of mixed categorical and numerical features. Unlike images where pixel perturbations maintain visual similarity, tabular data lacks intuitive similarity metrics, making it difficult to define imperceptible modifications. Additionally, traditional gradient-based methods prioritise $\ell_p$-norm constraints, often producing adversarial examples that deviate from the original data distributions, making them detectable. We propose a latent space perturbation framework using a mixed-input Variational Autoencoder (VAE) to generate imperceptible adversarial examples. The proposed VAE integrates categorical embeddings and numerical features into a unified latent manifold, enabling perturbations that preserve statistical consistency. We specify In-Distribution Success Rate (IDSR) to measure the proportion of adversarial examples that remain statistically indistinguishable from the input distribution. Evaluation across six publicly available datasets and three model architectures demonstrates that our method achieves substantially lower outlier rates and more consistent performance compared to traditional input-space attacks and other VAE-based methods adapted from image domain approaches. Our comprehensive analysis includes hyperparameter sensitivity, sparsity control mechanisms, and generative architectural comparisons, revealing that VAE-based attacks depend critically on reconstruction quality but offer superior practical utility when sufficient training data is available. This work highlights the importance of on-manifold perturbations for realistic adversarial attacks on tabular data, offering a robust approach for practical deployment. The source code can be accessed through this https URL.</li>
</ul>

<h3>Title: SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition</h3>
<ul>
<li><strong>Authors: </strong>Quan Bi Pay, Vishnu Monn Baskaran, Junn Yong Loo, KokSheik Wong, Simon See</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.10999">https://arxiv.org/abs/2507.10999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.10999">https://arxiv.org/pdf/2507.10999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.10999]] SpaRTAN: Spatial Reinforcement Token-based Aggregation Network for Visual Recognition(https://arxiv.org/abs/2507.10999)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The resurgence of convolutional neural networks (CNNs) in visual recognition tasks, exemplified by ConvNeXt, has demonstrated their capability to rival transformer-based architectures through advanced training methodologies and ViT-inspired design principles. However, both CNNs and transformers exhibit a simplicity bias, favoring straightforward features over complex structural representations. Furthermore, modern CNNs often integrate MLP-like blocks akin to those in transformers, but these blocks suffer from significant information redundancies, necessitating high expansion ratios to sustain competitive performance. To address these limitations, we propose SpaRTAN, a lightweight architectural design that enhances spatial and channel-wise information processing. SpaRTAN employs kernels with varying receptive fields, controlled by kernel size and dilation factor, to capture discriminative multi-order spatial features effectively. A wave-based channel aggregation module further modulates and reinforces pixel interactions, mitigating channel-wise redundancies. Combining the two modules, the proposed network can efficiently gather and dynamically contextualize discriminative features. Experimental results in ImageNet and COCO demonstrate that SpaRTAN achieves remarkable parameter efficiency while maintaining competitive performance. In particular, on the ImageNet-1k benchmark, SpaRTAN achieves 77. 7% accuracy with only 3.8M parameters and approximately 1.0 GFLOPs, demonstrating its ability to deliver strong performance through an efficient design. On the COCO benchmark, it achieves 50.0% AP, surpassing the previous benchmark by 1.2% with only 21.5M parameters. The code is publicly available at [this https URL].</li>
</ul>

<h3>Title: Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuhu Bai, Jiangning Zhang, Yunkang Cao, Guangyuan Lu, Qingdong He, Xiangtai Li, Guanzhong Tian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11003">https://arxiv.org/abs/2507.11003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11003">https://arxiv.org/pdf/2507.11003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11003]] Bridge Feature Matching and Cross-Modal Alignment with Mutual-filtering for Zero-shot Anomaly Detection(https://arxiv.org/abs/2507.11003)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>With the advent of vision-language models (e.g., CLIP) in zero- and few-shot settings, CLIP has been widely applied to zero-shot anomaly detection (ZSAD) in recent research, where the rare classes are essential and expected in many applications. This study introduces \textbf{FiSeCLIP} for ZSAD with training-free \textbf{CLIP}, combining the feature matching with the cross-modal alignment. Testing with the entire dataset is impractical, while batch-based testing better aligns with real industrial needs, and images within a batch can serve as mutual reference points. Accordingly, FiSeCLIP utilizes other images in the same batch as reference information for the current image. However, the lack of labels for these references can introduce ambiguity, we apply text information to \textbf{fi}lter out noisy features. In addition, we further explore CLIP's inherent potential to restore its local \textbf{se}mantic correlation, adapting it for fine-grained anomaly detection tasks to enable a more accurate filtering process. Our approach exhibits superior performance for both anomaly classification and segmentation on anomaly detection benchmarks, building a stronger baseline for the direction, e.g., on MVTec-AD, FiSeCLIP outperforms the SOTA AdaCLIP by +4.6\%$\uparrow$/+5.7\%$\uparrow$ in segmentation metrics AU-ROC/$F_1$-max.</li>
</ul>

<h3>Title: First-Order Error Matters: Accurate Compensation for Quantized Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xingyu Zheng, Haotong Qin, Yuye Li, Jiakai Wang, Jinyang Guo, Michele Magno, Xianglong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11017">https://arxiv.org/abs/2507.11017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11017">https://arxiv.org/pdf/2507.11017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11017]] First-Order Error Matters: Accurate Compensation for Quantized Large Language Models(https://arxiv.org/abs/2507.11017)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) offers an efficient approach to compressing large language models (LLMs), significantly reducing memory access and computational costs. Existing compensation-based weight calibration methods often rely on a second-order Taylor expansion to model quantization error, under the assumption that the first-order term is negligible in well-trained full-precision models. However, we reveal that the progressive compensation process introduces accumulated first-order deviations between latent weights and their full-precision counterparts, making this assumption fundamentally flawed. To address this, we propose FOEM, a novel PTQ method that explicitly incorporates first-order gradient terms to improve quantization error compensation. FOEM approximates gradients by directly computing the difference between latent and full-precision weights, avoiding the high cost and limited generalization of backpropagation-based gradient computation. This approach introduces minimal additional computational overhead. Moreover, FOEM leverages precomputed Cholesky factors to efficiently recover the inverse of Hessian submatrices in real time. Extensive experiments across a wide range of models and benchmarks demonstrate that FOEM consistently outperforms the classical GPTQ method. In 3-bit weight-only quantization, FOEM reduces the perplexity of Llama3-8B by 89.6%, and improves the 5-shot MMLU accuracy of Llama3-70B from 51.7% to 74.9%, approaching the full-precision performance of 78.6%. Furthermore, FOEM can be seamlessly integrated with advanced techniques such as GPTAQ and SpinQuant, yielding additional improvements under the challenging W4A4KV4 setting, and further narrowing the accuracy gap with full-precision baselines beyond what current state-of-the-art methods achieve. The code is available at this https URL.</li>
</ul>

<h3>Title: Relative Entropy Pathwise Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Claas Voelcker, Axel Brunnbauer, Marcel Hussing, Michal Nauman, Pieter Abbeel, Eric Eaton, Radu Grosu, Amir-massoud Farahmand, Igor Gilitschenski</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11019">https://arxiv.org/abs/2507.11019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11019">https://arxiv.org/pdf/2507.11019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11019]] Relative Entropy Pathwise Policy Optimization(https://arxiv.org/abs/2507.11019)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Score-function policy gradients have delivered strong results in game-playing, robotics and language-model fine-tuning. Yet its high-variance often undermines training stability. On the other hand, pathwise policy gradients alleviate the training variance, but are reliable only when driven by an accurate action-conditioned value function which is notoriously hard to train without relying on past off-policy data. In this paper, we discuss how to construct a value-gradient driven, on-policy algorithm that allow training Q-value models purely from on-policy data, unlocking the possibility of using pathwise policy updates in the context of on-policy learning. We show how to balance stochastic policies for exploration with constrained policy updates for stable training, and evaluate important architectural components that facilitate accurate value function learning. Building on these insights, we propose Relative Entropy Pathwise Policy Optimization (REPPO), an efficient on-policy algorithm that combines the sample-efficiency of pathwise policy gradients with the simplicity and minimal memory footprint of standard on-policy learning. We demonstrate that REPPO provides strong empirical performance at decreased sample requirements, wall-clock time, memory footprint as well as high hyperparameter robustness in a set of experiments on two standard GPU-parallelized benchmarks.</li>
</ul>

<h3>Title: Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schr√∂dinger Bridge with Conditional Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Sung Ho Kang, Hyun-Cheol Park</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11025">https://arxiv.org/abs/2507.11025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11025">https://arxiv.org/pdf/2507.11025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11025]] Human-Guided Shade Artifact Suppression in CBCT-to-MDCT Translation via Schr√∂dinger Bridge with Conditional Diffusion(https://arxiv.org/abs/2507.11025)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We present a novel framework for CBCT-to-MDCT translation, grounded in the Schrodinger Bridge (SB) formulation, which integrates GAN-derived priors with human-guided conditional diffusion. Unlike conventional GANs or diffusion models, our approach explicitly enforces boundary consistency between CBCT inputs and pseudo targets, ensuring both anatomical fidelity and perceptual controllability. Binary human feedback is incorporated via classifier-free guidance (CFG), effectively steering the generative process toward clinically preferred outcomes. Through iterative refinement and tournament-based preference selection, the model internalizes human preferences without relying on a reward model. Subtraction image visualizations reveal that the proposed method selectively attenuates shade artifacts in key anatomical regions while preserving fine structural detail. Quantitative evaluations further demonstrate superior performance across RMSE, SSIM, LPIPS, and Dice metrics on clinical datasets -- outperforming prior GAN- and fine-tuning-based feedback methods -- while requiring only 10 sampling steps. These findings underscore the effectiveness and efficiency of our framework for real-time, preference-aligned medical image translation.</li>
</ul>

<h3>Title: Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Sunghyun Park, Jungsoo Lee, Shubhankar Borse, Munawar Hayat, Sungha Choi, Kyuwoong Hwang, Fatih Porikli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11030">https://arxiv.org/abs/2507.11030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11030">https://arxiv.org/pdf/2507.11030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11030]] Personalized OVSS: Understanding Personal Concept in Open-Vocabulary Semantic Segmentation(https://arxiv.org/abs/2507.11030)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>While open-vocabulary semantic segmentation (OVSS) can segment an image into semantic regions based on arbitrarily given text descriptions even for classes unseen during training, it fails to understand personal texts (e.g., `my mug cup') for segmenting regions of specific interest to users. This paper addresses challenges like recognizing `my mug cup' among `multiple mug cups'. To overcome this challenge, we introduce a novel task termed \textit{personalized open-vocabulary semantic segmentation} and propose a text prompt tuning-based plug-in method designed to recognize personal visual concepts using a few pairs of images and masks, while maintaining the performance of the original OVSS. Based on the observation that reducing false predictions is essential when applying text prompt tuning to this task, our proposed method employs `negative mask proposal' that captures visual concepts other than the personalized concept. We further improve the performance by enriching the representation of text prompts by injecting visual embeddings of the personal concept into them. This approach enhances personalized OVSS without compromising the original OVSS performance. We demonstrate the superiority of our method on our newly established benchmarks for this task, including FSS$^\text{per}$, CUB$^\text{per}$, and ADE$^\text{per}$.</li>
</ul>

<h3>Title: Efficient Dual-domain Image Dehazing with Haze Prior Perception</h3>
<ul>
<li><strong>Authors: </strong>Lirong Zheng, Yanshan Li, Rui Yu, Kaihao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11035">https://arxiv.org/abs/2507.11035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11035">https://arxiv.org/pdf/2507.11035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11035]] Efficient Dual-domain Image Dehazing with Haze Prior Perception(https://arxiv.org/abs/2507.11035)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models exhibit strong global modeling capabilities in single-image dehazing, but their high computational cost limits real-time applicability. Existing methods predominantly rely on spatial-domain features to capture long-range dependencies, which are computationally expensive and often inadequate under complex haze conditions. While some approaches introduce frequency-domain cues, the weak coupling between spatial and frequency branches limits the overall performance. To overcome these limitations, we propose the Dark Channel Guided Frequency-aware Dehazing Network (DGFDNet), a novel dual-domain framework that performs physically guided degradation alignment across spatial and frequency domains. At its core, the DGFDBlock comprises two key modules: 1) the Haze-Aware Frequency Modulator (HAFM), which generates a pixel-level haze confidence map from dark channel priors to adaptively enhance haze-relevant frequency components, thereby achieving global degradation-aware spectral modulation; 2) the Multi-level Gating Aggregation Module (MGAM), which fuses multi-scale features through diverse convolutional kernels and hybrid gating mechanisms to recover fine structural details. Additionally, a Prior Correction Guidance Branch (PCGB) incorporates a closed-loop feedback mechanism, enabling iterative refinement of the prior by intermediate dehazed features and significantly improving haze localization accuracy, especially in challenging outdoor scenes. Extensive experiments on four benchmark haze datasets demonstrate that DGFDNet achieves state-of-the-art performance with superior robustness and real-time efficiency. Code is available at: this https URL.</li>
</ul>

<h3>Title: A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion</h3>
<ul>
<li><strong>Authors: </strong>Jie-Wen Li, Zi-Han Ye, Qingyuan Zhou, Jiayi Song, Ying He, Ben Fei, Wen-Ming Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11037">https://arxiv.org/abs/2507.11037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11037">https://arxiv.org/pdf/2507.11037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11037]] A Multi-View High-Resolution Foot-Ankle Complex Point Cloud Dataset During Gait for Occlusion-Robust 3D Completion(https://arxiv.org/abs/2507.11037)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The kinematics analysis of foot-ankle complex during gait is essential for advancing biomechanical research and clinical assessment. Collecting accurate surface geometry data from the foot and ankle during dynamic gait conditions is inherently challenging due to swing foot occlusions and viewing limitations. Thus, this paper introduces FootGait3D, a novel multi-view dataset of high-resolution ankle-foot surface point clouds captured during natural gait. Different from existing gait datasets that typically target whole-body or lower-limb motion, FootGait3D focuses specifically on the detailed modeling of the ankle-foot region, offering a finer granularity of motion data. To address this, FootGait3D consists of 8,403 point cloud frames collected from 46 subjects using a custom five-camera depth sensing system. Each frame includes a complete 5-view reconstruction of the foot and ankle (serving as ground truth) along with partial point clouds obtained from only four, three, or two views. This structured variation enables rigorous evaluation of 3D point cloud completion methods under varying occlusion levels and viewpoints. Our dataset is designed for shape completion tasks, facilitating the benchmarking of state-of-the-art single-modal (e.g., PointTr, SnowflakeNet, Anchorformer) and multi-modal (e.g., SVDFormer, PointSea, CSDN) completion networks on the challenge of recovering the full foot geometry from occluded inputs. FootGait3D has significant potential to advance research in biomechanics and multi-segment foot modeling, offering a valuable testbed for clinical gait analysis, prosthetic design, and robotics applications requiring detailed 3D models of the foot during motion. The dataset is now available at this https URL.</li>
</ul>

<h3>Title: Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Drapier, Aladine Chetouani, Aur√©lien Chateigner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11040">https://arxiv.org/abs/2507.11040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11040">https://arxiv.org/pdf/2507.11040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11040]] Combining Transformers and CNNs for Efficient Object Detection in High-Resolution Satellite Imagery(https://arxiv.org/abs/2507.11040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>We present GLOD, a transformer-first architecture for object detection in high-resolution satellite imagery. GLOD replaces CNN backbones with a Swin Transformer for end-to-end feature extraction, combined with novel UpConvMixer blocks for robust upsampling and Fusion Blocks for multi-scale feature integration. Our approach achieves 32.95\% on xView, outperforming SOTA methods by 11.46\%. Key innovations include asymmetric fusion with CBAM attention and a multi-path head design capturing objects across scales. The architecture is optimized for satellite imagery challenges, leveraging spatial priors while maintaining computational efficiency.</li>
</ul>

<h3>Title: LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP</h3>
<ul>
<li><strong>Authors: </strong>Haowei Yang, Ziyu Shen, Junli Shao, Luyao Men, Xinyue Han, Jing Dong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11052">https://arxiv.org/abs/2507.11052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11052">https://arxiv.org/pdf/2507.11052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11052]] LLM-Augmented Symptom Analysis for Cardiovascular Disease Risk Prediction: A Clinical NLP(https://arxiv.org/abs/2507.11052)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Timely identification and accurate risk stratification of cardiovascular disease (CVD) remain essential for reducing global mortality. While existing prediction models primarily leverage structured data, unstructured clinical notes contain valuable early indicators. This study introduces a novel LLM-augmented clinical NLP pipeline that employs domain-adapted large language models for symptom extraction, contextual reasoning, and correlation from free-text reports. Our approach integrates cardiovascular-specific fine-tuning, prompt-based inference, and entity-aware reasoning. Evaluations on MIMIC-III and CARDIO-NLP datasets demonstrate improved performance in precision, recall, F1-score, and AUROC, with high clinical relevance (kappa = 0.82) assessed by cardiologists. Challenges such as contextual hallucination, which occurs when plausible information contracts with provided source, and temporal ambiguity, which is related with models struggling with chronological ordering of events are addressed using prompt engineering and hybrid rule-based verification. This work underscores the potential of LLMs in clinical decision support systems (CDSS), advancing early warning systems and enhancing the translation of patient narratives into actionable risk assessments.</li>
</ul>

<h3>Title: GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices</h3>
<ul>
<li><strong>Authors: </strong>Danish Gufran, Sudeep Pasricha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11053">https://arxiv.org/abs/2507.11053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11053">https://arxiv.org/pdf/2507.11053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11053]] GATE: Graph Attention Neural Networks with Real-Time Edge Construction for Robust Indoor Localization using Mobile Embedded Devices(https://arxiv.org/abs/2507.11053)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate indoor localization is crucial for enabling spatial context in smart environments and navigation systems. Wi-Fi Received Signal Strength (RSS) fingerprinting is a widely used indoor localization approach due to its compatibility with mobile embedded devices. Deep Learning (DL) models improve accuracy in localization tasks by learning RSS variations across locations, but they assume fingerprint vectors exist in a Euclidean space, failing to incorporate spatial relationships and the non-uniform distribution of real-world RSS noise. This results in poor generalization across heterogeneous mobile devices, where variations in hardware and signal processing distort RSS readings. Graph Neural Networks (GNNs) can improve upon conventional DL models by encoding indoor locations as nodes and modeling their spatial and signal relationships as edges. However, GNNs struggle with non-Euclidean noise distributions and suffer from the GNN blind spot problem, leading to degraded accuracy in environments with dense access points (APs). To address these challenges, we propose GATE, a novel framework that constructs an adaptive graph representation of fingerprint vectors while preserving an indoor state-space topology, modeling the non-Euclidean structure of RSS noise to mitigate environmental noise and address device heterogeneity. GATE introduces 1) a novel Attention Hyperspace Vector (AHV) for enhanced message passing, 2) a novel Multi-Dimensional Hyperspace Vector (MDHV) to mitigate the GNN blind spot, and 3) an new Real-Time Edge Construction (RTEC) approach for dynamic graph adaptation. Extensive real-world evaluations across multiple indoor spaces with varying path lengths, AP densities, and heterogeneous devices demonstrate that GATE achieves 1.6x to 4.72x lower mean localization errors and 1.85x to 4.57x lower worst-case errors compared to state-of-the-art indoor localization frameworks.</li>
</ul>

<h3>Title: Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation</h3>
<ul>
<li><strong>Authors: </strong>Shuchang Ye, Usman Naseem, Mingyuan Meng, Jinman Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11055">https://arxiv.org/abs/2507.11055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11055">https://arxiv.org/pdf/2507.11055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11055]] Alleviating Textual Reliance in Medical Language-guided Segmentation via Prototype-driven Semantic Approximation(https://arxiv.org/abs/2507.11055)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical language-guided segmentation, integrating textual clinical reports as auxiliary guidance to enhance image segmentation, has demonstrated significant improvements over unimodal approaches. However, its inherent reliance on paired image-text input, which we refer to as ``textual reliance", presents two fundamental limitations: 1) many medical segmentation datasets lack paired reports, leaving a substantial portion of image-only data underutilized for training; and 2) inference is limited to retrospective analysis of cases with paired reports, limiting its applicability in most clinical scenarios where segmentation typically precedes reporting. To address these limitations, we propose ProLearn, the first Prototype-driven Learning framework for language-guided segmentation that fundamentally alleviates textual reliance. At its core, in ProLearn, we introduce a novel Prototype-driven Semantic Approximation (PSA) module to enable approximation of semantic guidance from textual input. PSA initializes a discrete and compact prototype space by distilling segmentation-relevant semantics from textual reports. Once initialized, it supports a query-and-respond mechanism which approximates semantic guidance for images without textual input, thereby alleviating textual reliance. Extensive experiments on QaTa-COV19, MosMedData+ and Kvasir-SEG demonstrate that ProLearn outperforms state-of-the-art language-guided methods when limited text is available.</li>
</ul>

<h3>Title: Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling</h3>
<ul>
<li><strong>Authors: </strong>Hayeon Kim, Ji Ha Jang, Se Young Chun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11061">https://arxiv.org/abs/2507.11061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11061">https://arxiv.org/pdf/2507.11061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11061]] Robust 3D-Masked Part-level Editing in 3D Gaussian Splatting with Regularized Score Distillation Sampling(https://arxiv.org/abs/2507.11061)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in 3D neural representations and instance-level editing models have enabled the efficient creation of high-quality 3D content. However, achieving precise local 3D edits remains challenging, especially for Gaussian Splatting, due to inconsistent multi-view 2D part segmentations and inherently ambiguous nature of Score Distillation Sampling (SDS) loss. To address these limitations, we propose RoMaP, a novel local 3D Gaussian editing framework that enables precise and drastic part-level modifications. First, we introduce a robust 3D mask generation module with our 3D-Geometry Aware Label Prediction (3D-GALP), which uses spherical harmonics (SH) coefficients to model view-dependent label variations and soft-label property, yielding accurate and consistent part segmentations across viewpoints. Second, we propose a regularized SDS loss that combines the standard SDS loss with additional regularizers. In particular, an L1 anchor loss is introduced via our Scheduled Latent Mixing and Part (SLaMP) editing method, which generates high-quality part-edited 2D images and confines modifications only to the target region while preserving contextual coherence. Additional regularizers, such as Gaussian prior removal, further improve flexibility by allowing changes beyond the existing context, and robust 3D masking prevents unintended edits. Experimental results demonstrate that our RoMaP achieves state-of-the-art local 3D editing on both reconstructed and generated Gaussian scenes and objects qualitatively and quantitatively, making it possible for more robust and flexible part-level 3D Gaussian editing.</li>
</ul>

<h3>Title: LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Isaiah Thompson Ocansey, Ritwik Bhattacharya, Tanmay Sen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11071">https://arxiv.org/abs/2507.11071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11071">https://arxiv.org/pdf/2507.11071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11071]] LogTinyLLM: Tiny Large Language Models Based Contextual Log Anomaly Detection(https://arxiv.org/abs/2507.11071)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Log anomaly detection using traditional rule based or deep learning based methods is often challenging due to the large volume and highly complex nature of log sequence. So effective way of detection of anomalous sequence of logs is crucial for system maintenance and development. This paper proposes parameter efficient finetuning specifically low rank adaptation (LoRA) and adapter based approaches for finding contextual anomalies in sequence of logs in large log data set. It compares different tiny large language models (LLMs) on the Thunderbird dataset. The results show that LoRA based finetuning provides substantial performance improvements of 18 to 19 percentage over LogBert based full finetuning approach, achieving accuracy scores between 97.76% and 98.83% compared to 79.37%.</li>
</ul>

<h3>Title: Joint angle model based learning to refine kinematic human pose estimation</h3>
<ul>
<li><strong>Authors: </strong>Chang Peng, Yifei Zhou, Huifeng Xi, Shiqing Huang, Chuangye Chen, Jianming Yang, Bao Yang, Zhenyu Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11075">https://arxiv.org/abs/2507.11075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11075">https://arxiv.org/pdf/2507.11075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11075]] Joint angle model based learning to refine kinematic human pose estimation(https://arxiv.org/abs/2507.11075)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Marker-free human pose estimation (HPE) has found increasing applications in various fields. Current HPE suffers from occasional errors in keypoint recognition and random fluctuation in keypoint trajectories when analyzing kinematic human poses. The performance of existing deep learning-based models for HPE refinement is considerably limited by inaccurate training datasets in which the keypoints are manually annotated. This paper proposed a novel method to overcome the difficulty through joint angle-based modeling. The key techniques include: (i) A joint angle-based model of human pose, which is robust to describe kinematic human poses; (ii) Approximating temporal variation of joint angles through high order Fourier series to get reliable "ground truth"; (iii) A bidirectional recurrent network is designed as a post-processing module to refine the estimation of well-established HRNet. Trained with the high-quality dataset constructed using our method, the network demonstrates outstanding performance to correct wrongly recognized joints and smooth their spatiotemporal trajectories. Tests show that joint angle-based refinement (JAR) outperforms the state-of-the-art HPE refinement network in challenging cases like figure skating and breaking.</li>
</ul>

<h3>Title: Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Md. Sabbir Hossen, Md. Saiduzzaman, Pabon Shaha</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11084">https://arxiv.org/abs/2507.11084</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11084">https://arxiv.org/pdf/2507.11084</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11084]] Social Media Sentiments Analysis on the July Revolution in Bangladesh: A Hybrid Transformer Based Machine Learning Approach(https://arxiv.org/abs/2507.11084)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>The July Revolution in Bangladesh marked a significant student-led mass uprising, uniting people across the nation to demand justice, accountability, and systemic reform. Social media platforms played a pivotal role in amplifying public sentiment and shaping discourse during this historic mass uprising. In this study, we present a hybrid transformer-based sentiment analysis framework to decode public opinion expressed in social media comments during and after the revolution. We used a brand new dataset of 4,200 Bangla comments collected from social media. The framework employs advanced transformer-based feature extraction techniques, including BanglaBERT, mBERT, XLM-RoBERTa, and the proposed hybrid XMB-BERT, to capture nuanced patterns in textual data. Principle Component Analysis (PCA) were utilized for dimensionality reduction to enhance computational efficiency. We explored eleven traditional and advanced machine learning classifiers for identifying sentiments. The proposed hybrid XMB-BERT with the voting classifier achieved an exceptional accuracy of 83.7% and outperform other model classifier combinations. This study underscores the potential of machine learning techniques to analyze social sentiment in low-resource languages like Bangla.</li>
</ul>

<h3>Title: Atmos-Bench: 3D Atmospheric Structures for Climate Insight</h3>
<ul>
<li><strong>Authors: </strong>Tianchi Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11085">https://arxiv.org/abs/2507.11085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11085">https://arxiv.org/pdf/2507.11085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11085]] Atmos-Bench: 3D Atmospheric Structures for Climate Insight(https://arxiv.org/abs/2507.11085)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Atmospheric structure, represented by backscatter coefficients (BC) recovered from satellite LiDAR attenuated backscatter (ATB), provides a volumetric view of clouds, aerosols, and molecules, playing a critical role in human activities, climate understanding, and extreme weather forecasting. Existing methods often rely on auxiliary inputs and simplified physics-based approximations, and lack a standardized 3D benchmark for fair evaluation. However, such approaches may introduce additional uncertainties and insufficiently capture realistic radiative transfer and atmospheric scattering-absorption effects. To bridge these gaps, we present Atmos-Bench: the first 3D atmospheric benchmark, along with a novel FourCastX: Frequency-enhanced Spatio-Temporal Mixture-of-Experts Network that (a) generates 921,600 image slices from 3D scattering volumes simulated at 532 nm and 355 nm by coupling WRF with an enhanced COSP simulator over 384 land-ocean time steps, yielding high-quality voxel-wise references; (b) embeds ATB-BC physical constraints into the model architecture, promoting energy consistency during restoration; (c) achieves consistent improvements on the Atmos-Bench dataset across both 355 nm and 532 nm bands, outperforming state-of-the-art baseline models without relying on auxiliary inputs. Atmos-Bench establishes a new standard for satellite-based 3D atmospheric structure recovery and paves the way for deeper climate insight.</li>
</ul>

<h3>Title: Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification</h3>
<ul>
<li><strong>Authors: </strong>Andres Azqueta-Gavald√≥n, Joaquin Ramos Cosgrove</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11086">https://arxiv.org/abs/2507.11086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11086">https://arxiv.org/pdf/2507.11086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11086]] Beyond Traditional Algorithms: Leveraging LLMs for Accurate Cross-Border Entity Identification(https://arxiv.org/abs/2507.11086)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The growing prevalence of cross-border financial activities in global markets has underscored the necessity of accurately identifying and classifying foreign entities. This practice is essential within the Spanish financial system for ensuring robust risk management, regulatory adherence, and the prevention of financial misconduct. This process involves a labor-intensive entity-matching task, where entities need to be validated against available reference sources. Challenges arise from linguistic variations, special characters, outdated names, and changes in legal forms, complicating traditional matching algorithms like Jaccard, cosine, and Levenshtein distances. These methods struggle with contextual nuances and semantic relationships, leading to mismatches. To address these limitations, we explore Large Language Models (LLMs) as a flexible alternative. LLMs leverage extensive training to interpret context, handle abbreviations, and adapt to legal transitions. We evaluate traditional methods, Hugging Face-based LLMs, and interface-based LLMs (e.g., Microsoft Copilot, Alibaba's Qwen 2.5) using a dataset of 65 Portuguese company cases. Results show traditional methods achieve accuracies over 92% but suffer high false positive rates (20-40%). Interface-based LLMs outperform, achieving accuracies above 93%, F1 scores exceeding 96%, and lower false positives (40-80%).</li>
</ul>

<h3>Title: The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs</h3>
<ul>
<li><strong>Authors: </strong>Zichen Wen, Jiashu Qu, Dongrui Liu, Zhiyuan Liu, Ruixi Wu, Yicun Yang, Xiangqi Jin, Haoyun Xu, Xuyang Liu, Weijia Li, Chaochao Lu, Jing Shao, Conghui He, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11097">https://arxiv.org/abs/2507.11097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11097">https://arxiv.org/pdf/2507.11097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11097]] The Devil behind the mask: An emergent safety vulnerability of Diffusion LLMs(https://arxiv.org/abs/2507.11097)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion-based large language models (dLLMs) have recently emerged as a powerful alternative to autoregressive LLMs, offering faster inference and greater interactivity via parallel decoding and bidirectional modeling. However, despite strong performance in code generation and text infilling, we identify a fundamental safety concern: existing alignment mechanisms fail to safeguard dLLMs against context-aware, masked-input adversarial prompts, exposing novel vulnerabilities. To this end, we present DIJA, the first systematic study and jailbreak attack framework that exploits unique safety weaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial interleaved mask-text prompts that exploit the text generation mechanisms of dLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional modeling drives the model to produce contextually consistent outputs for masked spans, even when harmful, while parallel decoding limits model dynamic filtering and rejection sampling of unsafe content. This causes standard alignment mechanisms to fail, enabling harmful completions in alignment-tuned dLLMs, even when harmful behaviors or unsafe instructions are directly exposed in the prompt. Through comprehensive experiments, we demonstrate that DIJA significantly outperforms existing jailbreak methods, exposing a previously overlooked threat surface in dLLM architectures. Notably, our method achieves up to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior baseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and by 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of harmful content in the jailbreak prompt. Our findings underscore the urgent need for rethinking safety alignment in this emerging class of language models. Code is available at this https URL.</li>
</ul>

<h3>Title: A Survey on Interpretability in Visual Recognition</h3>
<ul>
<li><strong>Authors: </strong>Qiyang Wan, Chengzhi Gao, Ruiping Wang, Xilin Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11099">https://arxiv.org/abs/2507.11099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11099">https://arxiv.org/pdf/2507.11099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11099]] A Survey on Interpretability in Visual Recognition(https://arxiv.org/abs/2507.11099)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In recent years, visual recognition methods have advanced significantly, finding applications across diverse fields. While researchers seek to understand the mechanisms behind the success of these models, there is also a growing impetus to deploy them in critical areas like autonomous driving and medical diagnostics to better diagnose failures, which promotes the development of interpretability research. This paper systematically reviews existing research on the interpretability of visual recognition models and proposes a taxonomy of methods from a human-centered perspective. The proposed taxonomy categorizes interpretable recognition methods based on Intent, Object, Presentation, and Methodology, thereby establishing a systematic and coherent set of grouping criteria for these XAI methods. Additionally, we summarize the requirements for evaluation metrics and explore new opportunities enabled by recent technologies, such as large multimodal models. We aim to organize existing research in this domain and inspire future investigations into the interpretability of visual recognition models.</li>
</ul>

<h3>Title: KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jie Yang, Wang Zeng, Sheng Jin, Lumin Xu, Wentao Liu, Chen Qian, Zhen Li, Ruimao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11102">https://arxiv.org/abs/2507.11102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11102">https://arxiv.org/pdf/2507.11102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11102]] KptLLM++: Towards Generic Keypoint Comprehension with Large Language Model(https://arxiv.org/abs/2507.11102)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The emergence of Multimodal Large Language Models (MLLMs) has revolutionized image understanding by bridging textual and visual modalities. However, these models often struggle with capturing fine-grained semantic information, such as the precise identification and analysis of object keypoints. Keypoints, as structure-aware, pixel-level, and compact representations of objects, particularly articulated ones, play a crucial role in applications such as fine-grained image analysis, object retrieval, and behavior recognition. In this paper, we propose KptLLM++, a novel multimodal large language model that specifically designed for generic keypoint comprehension through the integration of diverse input modalities guided by user-defined instructions. By unifying keypoint detection across varied contexts, KptLLM++ establishes itself as an advanced interface, fostering more effective human-AI collaboration. The model is built upon a novel identify-then-detect paradigm, which first interprets keypoint semantics and subsequently localizes their precise positions through a structured chain-of-thought reasoning mechanism. To push the boundaries of performance, we have scaled up the training dataset to over 500K samples, encompassing diverse objects, keypoint categories, image styles, and scenarios with complex occlusions. This extensive scaling enables KptLLM++ to unlock its potential, achieving remarkable accuracy and generalization. Comprehensive experiments on multiple keypoint detection benchmarks demonstrate its state-of-the-art performance, underscoring its potential as a unified solution for fine-grained image understanding and its transformative implications for human-AI interaction.</li>
</ul>

<h3>Title: Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sanhanat Sivapiromrat, Caiqi Zhang, Marco Basaldella, Nigel Collier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11112">https://arxiv.org/abs/2507.11112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11112">https://arxiv.org/pdf/2507.11112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11112]] Multi-Trigger Poisoning Amplifies Backdoor Vulnerabilities in LLMs(https://arxiv.org/abs/2507.11112)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that Large Language Models (LLMs) are vulnerable to data poisoning attacks, where malicious training examples embed hidden behaviours triggered by specific input patterns. However, most existing works assume a phrase and focus on the attack's effectiveness, offering limited understanding of trigger mechanisms and how multiple triggers interact within the model. In this paper, we present a framework for studying poisoning in LLMs. We show that multiple distinct backdoor triggers can coexist within a single model without interfering with each other, enabling adversaries to embed several triggers concurrently. Using multiple triggers with high embedding similarity, we demonstrate that poisoned triggers can achieve robust activation even when tokens are substituted or separated by long token spans. Our findings expose a broader and more persistent vulnerability surface in LLMs. To mitigate this threat, we propose a post hoc recovery method that selectively retrains specific model components based on a layer-wise weight difference analysis. Our method effectively removes the trigger behaviour with minimal parameter updates, presenting a practical and efficient defence against multi-trigger poisoning.</li>
</ul>

<h3>Title: MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Seif Ahmed, Mohamed T. Younes, Abdelrahman Moustafa, Abdelrahman Allam, Hamza Moustafa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11114">https://arxiv.org/abs/2507.11114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11114">https://arxiv.org/pdf/2507.11114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11114]] MSA at ImageCLEF 2025 Multimodal Reasoning: Multilingual Multimodal Reasoning With Ensemble Vision Language Models(https://arxiv.org/abs/2507.11114)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present a robust ensemble-based system for multilingual multimodal reasoning, designed for the ImageCLEF 2025 EXAMS V challenge. Our approach integrates Gemini 2.5 Flash for visual description, Gemini 1.5 Pro for caption refinement and consistency checks, and Gemini 2.5 Pro as a reasoner which handles final answer selection, all coordinated through carefully engineered few-shot and zero-shot prompts. We conducted an extensive ablation study, training several large language models (Gemini 2.5 Flash, Phi 4, Gemma 3, Mistral) on an English dataset and its multilingual augmented version. Additionally, we evaluated Gemini 2.5 Flash in a zero-shot setting for comparison and found it to substantially outperform the trained models. Prompt design also proved critical: enforcing concise, language-normalized formats and prohibiting explanatory text boosted model accuracy on the English validation set from 55.9% to 61.7%. On the official leaderboard, our system (Team MSA) achieved first place overall in the multilingual track with 81.4% accuracy, and led 11 out of 13 individual language tracks, with top results such as 95.07% for Croatian and 92.12% for Italian. These findings highlight that lightweight OCR-VLM ensembles, when paired with precise prompt strategies and cross-lingual augmentation, can outperform heavier end-to-end models in high-stakes, multilingual educational settings.</li>
</ul>

<h3>Title: Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach</h3>
<ul>
<li><strong>Authors: </strong>Md. Sabbir Hossen, Md. Saiduzzaman, Pabon Shaha, Mostofa Kamal Nasir</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11116">https://arxiv.org/abs/2507.11116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11116">https://arxiv.org/pdf/2507.11116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11116]] Jellyfish Species Identification: A CNN Based Artificial Neural Network Approach(https://arxiv.org/abs/2507.11116)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Jellyfish, a diverse group of gelatinous marine organisms, play a crucial role in maintaining marine ecosystems but pose significant challenges for biodiversity and conservation due to their rapid proliferation and ecological impact. Accurate identification of jellyfish species is essential for ecological monitoring and management. In this study, we proposed a deep learning framework for jellyfish species detection and classification using an underwater image dataset. The framework integrates advanced feature extraction techniques, including MobileNetV3, ResNet50, EfficientNetV2-B0, and VGG16, combined with seven traditional machine learning classifiers and three Feedforward Neural Network classifiers for precise species identification. Additionally, we activated the softmax function to directly classify jellyfish species using the convolutional neural network models. The combination of the Artificial Neural Network with MobileNetV3 is our best-performing model, achieving an exceptional accuracy of 98%, significantly outperforming other feature extractor-classifier combinations. This study demonstrates the efficacy of deep learning and hybrid frameworks in addressing biodiversity challenges and advancing species detection in marine environments.</li>
</ul>

<h3>Title: Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID</h3>
<ul>
<li><strong>Authors: </strong>Hankun Liu, Yujian Zhao, Guanglin Niu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11119">https://arxiv.org/abs/2507.11119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11119">https://arxiv.org/pdf/2507.11119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11119]] Try Harder: Hard Sample Generation and Learning for Clothes-Changing Person Re-ID(https://arxiv.org/abs/2507.11119)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hard samples pose a significant challenge in person re-identification (ReID) tasks, particularly in clothing-changing person Re-ID (CC-ReID). Their inherent ambiguity or similarity, coupled with the lack of explicit definitions, makes them a fundamental bottleneck. These issues not only limit the design of targeted learning strategies but also diminish the model's robustness under clothing or viewpoint changes. In this paper, we propose a novel multimodal-guided Hard Sample Generation and Learning (HSGL) framework, which is the first effort to unify textual and visual modalities to explicitly define, generate, and optimize hard samples within a unified paradigm. HSGL comprises two core components: (1) Dual-Granularity Hard Sample Generation (DGHSG), which leverages multimodal cues to synthesize semantically consistent samples, including both coarse- and fine-grained hard positives and negatives for effectively increasing the hardness and diversity of the training data. (2) Hard Sample Adaptive Learning (HSAL), which introduces a hardness-aware optimization strategy that adjusts feature distances based on textual semantic labels, encouraging the separation of hard positives and drawing hard negatives closer in the embedding space to enhance the model's discriminative capability and robustness to hard samples. Extensive experiments on multiple CC-ReID benchmarks demonstrate the effectiveness of our approach and highlight the potential of multimodal-guided hard sample generation and learning for robust CC-ReID. Notably, HSAL significantly accelerates the convergence of the targeted learning procedure and achieves state-of-the-art performance on both PRCC and LTCC datasets. The code is available at this https URL.</li>
</ul>

<h3>Title: What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests</h3>
<ul>
<li><strong>Authors: </strong>Dimitri Staufer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11128">https://arxiv.org/abs/2507.11128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11128">https://arxiv.org/pdf/2507.11128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11128]] What Should LLMs Forget? Quantifying Personal Data in LLMs for Right-to-Be-Forgotten Requests(https://arxiv.org/abs/2507.11128)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) can memorize and reveal personal information, raising concerns regarding compliance with the EU's GDPR, particularly the Right to Be Forgotten (RTBF). Existing machine unlearning methods assume the data to forget is already known but do not address how to identify which individual-fact associations are stored in the model. Privacy auditing techniques typically operate at the population level or target a small set of identifiers, limiting applicability to individual-level data inquiries. We introduce WikiMem, a dataset of over 5,000 natural language canaries covering 243 human-related properties from Wikidata, and a model-agnostic metric to quantify human-fact associations in LLMs. Our approach ranks ground-truth values against counterfactuals using calibrated negative log-likelihood across paraphrased prompts. We evaluate 200 individuals across 15 LLMs (410M-70B parameters), showing that memorization correlates with subject web presence and model scale. We provide a foundation for identifying memorized personal data in LLMs at the individual level, enabling the dynamic construction of forget sets for machine unlearning and RTBF requests.</li>
</ul>

<h3>Title: Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Yuan Yao, Jin Song, Jian Jin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11137">https://arxiv.org/abs/2507.11137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11137">https://arxiv.org/pdf/2507.11137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11137]] Hashed Watermark as a Filter: Defeating Forging and Overwriting Attacks in Weight-based Neural Network Watermarking(https://arxiv.org/abs/2507.11137)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, robust, watermark, transformer</a></li>
<li><strong>Abstract: </strong>As valuable digital assets, deep neural networks necessitate robust ownership protection, positioning neural network watermarking (NNW) as a promising solution. Among various NNW approaches, weight-based methods are favored for their simplicity and practicality; however, they remain vulnerable to forging and overwriting attacks. To address those challenges, we propose NeuralMark, a robust method built around a hashed watermark filter. Specifically, we utilize a hash function to generate an irreversible binary watermark from a secret key, which is then used as a filter to select the model parameters for embedding. This design cleverly intertwines the embedding parameters with the hashed watermark, providing a robust defense against both forging and overwriting attacks. An average pooling is also incorporated to resist fine-tuning and pruning attacks. Furthermore, it can be seamlessly integrated into various neural network architectures, ensuring broad applicability. Theoretically, we analyze its security boundary. Empirically, we verify its effectiveness and robustness across 13 distinct Convolutional and Transformer architectures, covering five image classification tasks and one text generation task. The source codes are available at this https URL.</li>
</ul>

<h3>Title: FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations</h3>
<ul>
<li><strong>Authors: </strong>Adriano Castro, Simon Hanisch, Matin Fallahi, Thorsten Strufe</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11138">https://arxiv.org/abs/2507.11138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11138">https://arxiv.org/pdf/2507.11138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11138]] FacialMotionID: Identifying Users of Mixed Reality Headsets using Abstract Facial Motion Representations(https://arxiv.org/abs/2507.11138)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, biometric</a></li>
<li><strong>Abstract: </strong>Facial motion capture in mixed reality headsets enables real-time avatar animation, allowing users to convey non-verbal cues during virtual interactions. However, as facial motion data constitutes a behavioral biometric, its use raises novel privacy concerns. With mixed reality systems becoming more immersive and widespread, understanding whether face motion data can lead to user identification or inference of sensitive attributes is increasingly important. To address this, we conducted a study with 116 participants using three types of headsets across three sessions, collecting facial, eye, and head motion data during verbal and non-verbal tasks. The data used is not raw video, but rather, abstract representations that are used to animate digital avatars. Our analysis shows that individuals can be re-identified from this data with up to 98% balanced accuracy, are even identifiable across device types, and that emotional states can be inferred with up to 86% accuracy. These results underscore the potential privacy risks inherent in face motion tracking in mixed reality environments.</li>
</ul>

<h3>Title: RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images</h3>
<ul>
<li><strong>Authors: </strong>Lam Pham, Cam Le, Hieu Tang, Khang Truong, Truong Nguyen, Jasmin Lampert, Alexander Schindler, Martin Boyer, Son Phan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11143">https://arxiv.org/abs/2507.11143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11143">https://arxiv.org/pdf/2507.11143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11143]] RMAU-NET: A Residual-Multihead-Attention U-Net Architecture for Landslide Segmentation and Detection from Remote Sensing Images(https://arxiv.org/abs/2507.11143)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, landslide disasters have reported frequently due to the extreme weather events of droughts, floods , storms, or the consequence of human activities such as deforestation, excessive exploitation of natural resources. However, automatically observing landslide is challenging due to the extremely large observing area and the rugged topography such as mountain or highland. This motivates us to propose an end-to-end deep-learning-based model which explores the remote sensing images for automatically observing landslide events. By considering remote sensing images as the input data, we can obtain free resource, observe large and rough terrains by time. To explore the remote sensing images, we proposed a novel neural network architecture which is for two tasks of landslide detection and landslide segmentation. We evaluated our proposed model on three different benchmark datasets of LandSlide4Sense, Bijie, and Nepal. By conducting extensive experiments, we achieve F1 scores of 98.23, 93.83 for the landslide detection task on LandSlide4Sense, Bijie datasets; mIoU scores of 63.74, 76.88 on the segmentation tasks regarding LandSlide4Sense, Nepal datasets. These experimental results prove potential to integrate our proposed model into real-life landslide observation systems.</li>
</ul>

<h3>Title: Latent Space Consistency for Sparse-View CT Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Duoyou Chen, Yunqing Chen, Can Zhang, Zhou Wang, Cheng Chen, Ruoxiu Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11152">https://arxiv.org/abs/2507.11152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11152">https://arxiv.org/pdf/2507.11152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11152]] Latent Space Consistency for Sparse-View CT Reconstruction(https://arxiv.org/abs/2507.11152)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Computed Tomography (CT) is a widely utilized imaging modality in clinical settings. Using densely acquired rotational X-ray arrays, CT can capture 3D spatial features. However, it is confronted with challenged such as significant time consumption and high radiation exposure. CT reconstruction methods based on sparse-view X-ray images have garnered substantial attention from researchers as they present a means to mitigate costs and risks. In recent years, diffusion models, particularly the Latent Diffusion Model (LDM), have demonstrated promising potential in the domain of 3D CT reconstruction. Nonetheless, due to the substantial differences between the 2D latent representation of X-ray modalities and the 3D latent representation of CT modalities, the vanilla LDM is incapable of achieving effective alignment within the latent space. To address this issue, we propose the Consistent Latent Space Diffusion Model (CLS-DM), which incorporates cross-modal feature contrastive learning to efficiently extract latent 3D information from 2D X-ray images and achieve latent space alignment between modalities. Experimental results indicate that CLS-DM outperforms classical and state-of-the-art generative models in terms of standard voxel-level metrics (PSNR, SSIM) on the LIDC-IDRI and CTSpine1K datasets. This methodology not only aids in enhancing the effectiveness and economic viability of sparse X-ray reconstructed CT but can also be generalized to other cross-modal transformation tasks, such as text-to-image synthesis. We have made our code publicly available at this https URL to facilitate further research and applications in other domains.</li>
</ul>

<h3>Title: Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification</h3>
<ul>
<li><strong>Authors: </strong>Jun Chen, Yonghua Yu, Weifu Li, Yaohui Chen, Hong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11171">https://arxiv.org/abs/2507.11171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11171">https://arxiv.org/pdf/2507.11171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11171]] Clustering-Guided Multi-Layer Contrastive Representation Learning for Citrus Disease Classification(https://arxiv.org/abs/2507.11171)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Citrus, as one of the most economically important fruit crops globally, suffers severe yield depressions due to various diseases. Accurate disease detection and classification serve as critical prerequisites for implementing targeted control measures. Recent advancements in artificial intelligence, particularly deep learning-based computer vision algorithms, have substantially decreased time and labor requirements while maintaining the accuracy of detection and classification. Nevertheless, these methods predominantly rely on massive, high-quality annotated training examples to attain promising performance. By introducing two key designs: contrasting with cluster centroids and a multi-layer contrastive training (MCT) paradigm, this paper proposes a novel clustering-guided self-supervised multi-layer contrastive representation learning (CMCRL) algorithm. The proposed method demonstrates several advantages over existing counterparts: (1) optimizing with massive unannotated samples; (2) effective adaptation to the symptom similarity across distinct citrus diseases; (3) hierarchical feature representation learning. The proposed method achieves state-of-the-art performance on the public citrus image set CDD, outperforming existing methods by 4.5\%-30.1\% accuracy. Remarkably, our method narrows the performance gap with fully supervised counterparts (all samples are labeled). Beyond classification accuracy, our method shows great performance on other evaluation metrics (F1 score, precision, and recall), highlighting the robustness against the class imbalance challenge.</li>
</ul>

<h3>Title: Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction</h3>
<ul>
<li><strong>Authors: </strong>Deepak Kumar Panda, Weisi Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11173">https://arxiv.org/abs/2507.11173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11173">https://arxiv.org/pdf/2507.11173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11173]] Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction(https://arxiv.org/abs/2507.11173)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Autonomous unmanned aerial vehicles (UAVs) rely on global navigation satellite system (GNSS) pseudorange measurements for accurate real-time localization and navigation. However, this dependence exposes them to sophisticated spoofing threats, where adversaries manipulate pseudoranges to deceive UAV receivers. Among these, drift-evasive spoofing attacks subtly perturb measurements, gradually diverting the UAVs trajectory without triggering conventional signal-level anti-spoofing mechanisms. Traditional distributional shift detection techniques often require accumulating a threshold number of samples, causing delays that impede rapid detection and timely response. Consequently, robust temporal-scale detection methods are essential to identify attack onset and enable contingency planning with alternative sensing modalities, improving resilience against stealthy adversarial manipulations. This study explores a Bayesian online change point detection (BOCPD) approach that monitors temporal shifts in value estimates from a reinforcement learning (RL) critic network to detect subtle behavioural deviations in UAV navigation. Experimental results show that this temporal value-based framework outperforms conventional GNSS spoofing detectors, temporal semi-supervised learning frameworks, and the Page-Hinkley test, achieving higher detection accuracy and lower false-positive and false-negative rates for drift-evasive spoofing attacks.</li>
</ul>

<h3>Title: Mixture of Experts in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Danyang Zhang, Junhao Song, Ziqian Bi, Yingfang Yuan, Tianyang Wang, Joe Yeong, Junfeng Hao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11181">https://arxiv.org/abs/2507.11181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11181">https://arxiv.org/pdf/2507.11181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11181]] Mixture of Experts in Large Language Models(https://arxiv.org/abs/2507.11181)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive review of the Mixture-of-Experts (MoE) architecture in large language models, highlighting its ability to significantly enhance model performance while maintaining minimal computational overhead. Through a systematic analysis spanning theoretical foundations, core architectural designs, and large language model (LLM) applications, we examine expert gating and routing mechanisms, hierarchical and sparse MoE configurations, meta-learning approaches, multimodal and multitask learning scenarios, real-world deployment cases, and recent advances and challenges in deep learning. Our analysis identifies key advantages of MoE, including superior model capacity compared to equivalent Bayesian approaches, improved task-specific performance, and the ability to scale model capacity efficiently. We also underscore the importance of ensuring expert diversity, accurate calibration, and reliable inference aggregation, as these are essential for maximizing the effectiveness of MoE architectures. Finally, this review outlines current research limitations, open challenges, and promising future directions, providing a foundation for continued innovation in MoE architecture and its applications.</li>
</ul>

<h3>Title: Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications</h3>
<ul>
<li><strong>Authors: </strong>Dimitrios Kritsiolis, Constantine Kotropoulos</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11183">https://arxiv.org/abs/2507.11183</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11183">https://arxiv.org/pdf/2507.11183</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11183]] Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications(https://arxiv.org/abs/2507.11183)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a machine learning approach that enables multiple devices (i.e., agents) to train a shared model cooperatively without exchanging raw data. This technique keeps data localized on user devices, ensuring privacy and security, while each agent trains the model on their own data and only shares model updates. The communication overhead is a significant challenge due to the frequent exchange of model updates between the agents and the central server. In this paper, we propose a communication-efficient federated learning scheme that utilizes low-rank approximation of neural network gradients and quantization to significantly reduce the network load of the decentralized learning process with minimal impact on the model's accuracy.</li>
</ul>

<h3>Title: An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment</h3>
<ul>
<li><strong>Authors: </strong>Md. Emon Akter Sourov, Md. Sabbir Hossen, Pabon Shaha, Mohammad Minoar Hossain, Md Sadiq Iqbal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11185">https://arxiv.org/abs/2507.11185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11185">https://arxiv.org/pdf/2507.11185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11185]] An Explainable AI-Enhanced Machine Learning Approach for Cardiovascular Disease Detection and Risk Assessment(https://arxiv.org/abs/2507.11185)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Heart disease remains a major global health concern, particularly in regions with limited access to medical resources and diagnostic facilities. Traditional diagnostic methods often fail to accurately identify and manage heart disease risks, leading to adverse outcomes. Machine learning has the potential to significantly enhance the accuracy, efficiency, and speed of heart disease diagnosis. In this study, we proposed a comprehensive framework that combines classification models for heart disease detection and regression models for risk prediction. We employed the Heart Disease dataset, which comprises 1,035 cases. To address the issue of class imbalance, the Synthetic Minority Oversampling Technique (SMOTE) was applied, resulting in the generation of an additional 100,000 synthetic data points. Performance metrics, including accuracy, precision, recall, F1-score, R2, MSE, RMSE, and MAE, were used to evaluate the model's effectiveness. Among the classification models, Random Forest emerged as the standout performer, achieving an accuracy of 97.2% on real data and 97.6% on synthetic data. For regression tasks, Linear Regression demonstrated the highest R2 values of 0.992 and 0.984 on real and synthetic datasets, respectively, with the lowest error metrics. Additionally, Explainable AI techniques were employed to enhance the interpretability of the models. This study highlights the potential of machine learning to revolutionize heart disease diagnosis and risk prediction, thereby facilitating early intervention and enhancing clinical decision-making.</li>
</ul>

<h3>Title: Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms</h3>
<ul>
<li><strong>Authors: </strong>Shao-Bo Lin, Xiaotong Liu, Yao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11187">https://arxiv.org/abs/2507.11187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11187">https://arxiv.org/pdf/2507.11187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11187]] Striking the Perfect Balance: Preserving Privacy While Boosting Utility in Collaborative Medical Prediction Platforms(https://arxiv.org/abs/2507.11187)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, extraction</a></li>
<li><strong>Abstract: </strong>Online collaborative medical prediction platforms offer convenience and real-time feedback by leveraging massive electronic health records. However, growing concerns about privacy and low prediction quality can deter patient participation and doctor cooperation. In this paper, we first clarify the privacy attacks, namely attribute attacks targeting patients and model extraction attacks targeting doctors, and specify the corresponding privacy principles. We then propose a privacy-preserving mechanism and integrate it into a novel one-shot distributed learning framework, aiming to simultaneously meet both privacy requirements and prediction performance objectives. Within the framework of statistical learning theory, we theoretically demonstrate that the proposed distributed learning framework can achieve the optimal prediction performance under specific privacy requirements. We further validate the developed privacy-preserving collaborative medical prediction platform through both toy simulations and real-world data experiments.</li>
</ul>

<h3>Title: Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding</h3>
<ul>
<li><strong>Authors: </strong>Conrad Borchers, Bahar Shahrokhian, Francesco Balzan, Elham Tajik, Sreecharan Sankaranarayanan, Sebastian Simon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11198">https://arxiv.org/abs/2507.11198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11198">https://arxiv.org/pdf/2507.11198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11198]] Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding(https://arxiv.org/abs/2507.11198)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) enable new possibilities for qualitative research at scale, including coding and data annotation. While multi-agent systems (MAS) can emulate human coding workflows, their benefits over single-agent coding remain poorly understood. We conducted an experimental study of how agent persona and temperature shape consensus-building and coding accuracy of dialog segments based on a codebook with 8 codes. Our open-source MAS mirrors deductive human coding through structured agent discussion and consensus arbitration. Using six open-source LLMs (with 3 to 32 billion parameters) and 18 experimental configurations, we analyze over 77,000 coding decisions against a gold-standard dataset of human-annotated transcripts from online math tutoring sessions. Temperature significantly impacted whether and when consensus was reached across all six LLMs. MAS with multiple personas (including neutral, assertive, or empathetic), significantly delayed consensus in four out of six LLMs compared to uniform personas. In three of those LLMs, higher temperatures significantly diminished the effects of multiple personas on consensus. However, neither temperature nor persona pairing lead to robust improvements in coding accuracy. Single agents matched or outperformed MAS consensus in most conditions. Only one model (OpenHermesV2:7B) and code category showed above-chance gains from MAS deliberation when temperature was 0.5 or lower and especially when the agents included at least one assertive persona. Qualitative analysis of MAS collaboration for these configurations suggests that MAS may nonetheless aid in narrowing ambiguous code applications that could improve codebooks and human-AI coding. We contribute new insight into the limits of LLM-based qualitative methods, challenging the notion that diverse MAS personas lead to better outcomes. We open-source our MAS and experimentation code.</li>
</ul>

<h3>Title: A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Xinkui Zhao, Jinsong Shu, Yangyang Wu, Guanjie Cheng, Zihe Liu, Naibo Wang, Shuiguang Deng, Zhongle Xie, Jianwei Yin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11202">https://arxiv.org/abs/2507.11202</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11202">https://arxiv.org/pdf/2507.11202</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11202]] A Robust Incomplete Multimodal Low-Rank Adaptation Approach for Emotion Recognition(https://arxiv.org/abs/2507.11202)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Multimodal Emotion Recognition (MER) often encounters incomplete multimodality in practical applications due to sensor failures or privacy protection requirements. While existing methods attempt to address various incomplete multimodal scenarios by balancing the training of each modality combination through additional gradients, these approaches face a critical limitation: training gradients from different modality combinations conflict with each other, ultimately degrading the performance of the final prediction model. In this paper, we propose a unimodal decoupled dynamic low-rank adaptation method based on modality combinations, named MCULoRA, which is a novel framework for the parameter-efficient training of incomplete multimodal learning models. MCULoRA consists of two key modules, modality combination aware low-rank adaptation (MCLA) and dynamic parameter fine-tuning (DPFT). The MCLA module effectively decouples the shared information from the distinct characteristics of individual modality combinations. The DPFT module adjusts the training ratio of modality combinations based on the separability of each modality's representation space, optimizing the learning efficiency across different modality combinations. Our extensive experimental evaluation in multiple benchmark datasets demonstrates that MCULoRA substantially outperforms previous incomplete multimodal learning approaches in downstream task accuracy.</li>
</ul>

<h3>Title: EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Valle Ruiz-Fern√°ndez, Mario Mina, J√∫lia Falc√£o, Luis Vasquez-Reina, Anna Sall√©s, Aitor Gonzalez-Agirre, Olatz Perez-de-Vi√±aspre</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11216">https://arxiv.org/abs/2507.11216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11216">https://arxiv.org/pdf/2507.11216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11216]] EsBBQ and CaBBQ: The Spanish and Catalan Bias Benchmarks for Question Answering(https://arxiv.org/abs/2507.11216)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Previous literature has largely shown that Large Language Models (LLMs) perpetuate social biases learnt from their pre-training data. Given the notable lack of resources for social bias evaluation in languages other than English, and for social contexts outside of the United States, this paper introduces the Spanish and the Catalan Bias Benchmarks for Question Answering (EsBBQ and CaBBQ). Based on the original BBQ, these two parallel datasets are designed to assess social bias across 10 categories using a multiple-choice QA setting, now adapted to the Spanish and Catalan languages and to the social context of Spain. We report evaluation results on different LLMs, factoring in model family, size and variant. Our results show that models tend to fail to choose the correct answer in ambiguous scenarios, and that high QA accuracy often correlates with greater reliance on social biases.</li>
</ul>

<h3>Title: An Agentic Flow for Finite State Machine Extraction using Prompt Chaining</h3>
<ul>
<li><strong>Authors: </strong>Fares Wael, Youssef Maklad, Ali Hamdi, Wael Elsersy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11222">https://arxiv.org/abs/2507.11222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11222">https://arxiv.org/pdf/2507.11222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11222]] An Agentic Flow for Finite State Machine Extraction using Prompt Chaining(https://arxiv.org/abs/2507.11222)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Finite-State Machines (FSMs) are critical for modeling the operational logic of network protocols, enabling verification, analysis, and vulnerability discovery. However, existing FSM extraction techniques face limitations such as scalability, incomplete coverage, and ambiguity in natural language specifications. In this paper, we propose FlowFSM, a novel agentic framework that leverages Large Language Models (LLMs) combined with prompt chaining and chain-of-thought reasoning to extract accurate FSMs from raw RFC documents. FlowFSM systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs. Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM achieves high extraction precision while minimizing hallucinated transitions, showing promising results. Our findings highlight the potential of agent-based LLM systems in the advancement of protocol analysis and FSM inference for cybersecurity and reverse engineering applications.</li>
</ul>

<h3>Title: Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages</h3>
<ul>
<li><strong>Authors: </strong>Lyzander Marciano Andrylie, Inaya Rahmanisa, Mahardika Krisna Ihsani, Alfan Farizki Wicaksono, Haryo Akbarianto Wibowo, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11230">https://arxiv.org/abs/2507.11230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11230">https://arxiv.org/pdf/2507.11230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11230]] Sparse Autoencoders Can Capture Language-Specific Concepts Across Diverse Languages(https://arxiv.org/abs/2507.11230)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Understanding the multilingual mechanisms of large language models (LLMs) provides insight into how they process different languages, yet this remains challenging. Existing studies often focus on individual neurons, but their polysemantic nature makes it difficult to isolate language-specific units from cross-lingual representations. To address this, we explore sparse autoencoders (SAEs) for their ability to learn monosemantic features that represent concrete and abstract concepts across languages in LLMs. While some of these features are language-independent, the presence of language-specific features remains underexplored. In this work, we introduce SAE-LAPE, a method based on feature activation probability, to identify language-specific features within the feed-forward network. We find that many such features predominantly appear in the middle to final layers of the model and are interpretable. These features influence the model's multilingual performance and language output and can be used for language identification with performance comparable to fastText along with more interpretability. Our code is available at this https URL .</li>
</ul>

<h3>Title: Generative Click-through Rate Prediction with Applications to Search Advertising</h3>
<ul>
<li><strong>Authors: </strong>Lingwei Kong, Lu Wang, Changping Peng, Zhangang Lin, Ching Law, Jingping Shao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11246">https://arxiv.org/abs/2507.11246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11246">https://arxiv.org/pdf/2507.11246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11246]] Generative Click-through Rate Prediction with Applications to Search Advertising(https://arxiv.org/abs/2507.11246)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Click-Through Rate (CTR) prediction models are integral to a myriad of industrial settings, such as personalized search advertising. Current methods typically involve feature extraction from users' historical behavior sequences combined with product information, feeding into a discriminative model that is trained on user feedback to estimate CTR. With the success of models such as GPT, the potential for generative models to enrich expressive power beyond discriminative models has become apparent. In light of this, we introduce a novel model that leverages generative models to enhance the precision of CTR predictions in discriminative models. To reconcile the disparate data aggregation needs of both model types, we design a two-stage training process: 1) Generative pre-training for next-item prediction with the given item category in user behavior sequences; 2) Fine-tuning the well-trained generative model within a discriminative CTR prediction framework. Our method's efficacy is substantiated through extensive experiments on a new dataset, and its significant utility is further corroborated by online A/B testing results. Currently, the model is deployed on one of the world's largest e-commerce platforms, and we intend to release the associated code and dataset in the future.</li>
</ul>

<h3>Title: Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone</h3>
<ul>
<li><strong>Authors: </strong>Veronika Shilova, Emmanuel Malherbe, Giovanni Palma, Laurent Risser, Jean-Michel Loubes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11247">https://arxiv.org/abs/2507.11247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11247">https://arxiv.org/pdf/2507.11247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11247]] Fairness-Aware Grouping for Continuous Sensitive Variables: Application for Debiasing Face Analysis with respect to Skin Tone(https://arxiv.org/abs/2507.11247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, segmentation</a></li>
<li><strong>Abstract: </strong>Within a legal framework, fairness in datasets and models is typically assessed by dividing observations into predefined groups and then computing fairness measures (e.g., Disparate Impact or Equality of Odds with respect to gender). However, when sensitive attributes such as skin color are continuous, dividing into default groups may overlook or obscure the discrimination experienced by certain minority subpopulations. To address this limitation, we propose a fairness-based grouping approach for continuous (possibly multidimensional) sensitive attributes. By grouping data according to observed levels of discrimination, our method identifies the partition that maximizes a novel criterion based on inter-group variance in discrimination, thereby isolating the most critical subgroups. We validate the proposed approach using multiple synthetic datasets and demonstrate its robustness under changing population distributions - revealing how discrimination is manifested within the space of sensitive attributes. Furthermore, we examine a specialized setting of monotonic fairness for the case of skin color. Our empirical results on both CelebA and FFHQ, leveraging the skin tone as predicted by an industrial proprietary algorithm, show that the proposed segmentation uncovers more nuanced patterns of discrimination than previously reported, and that these findings remain stable across datasets for a given model. Finally, we leverage our grouping model for debiasing purpose, aiming at predicting fair scores with group-by-group post-processing. The results demonstrate that our approach improves fairness while having minimal impact on accuracy, thus confirming our partition method and opening the door for industrial deployment.</li>
</ul>

<h3>Title: MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection</h3>
<ul>
<li><strong>Authors: </strong>Guanghao Wu, Chen Xu, Hai Song, Chong Wang, Qixing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11252">https://arxiv.org/abs/2507.11252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11252">https://arxiv.org/pdf/2507.11252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11252]] MFGDiffusion: Mask-Guided Smoke Synthesis for Enhanced Forest Fire Detection(https://arxiv.org/abs/2507.11252)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Smoke is the first visible indicator of a this http URL the advancement of deep learning, image-based smoke detection has become a crucial method for detecting and preventing forest fires. However, the scarcity of smoke image data from forest fires is one of the significant factors hindering the detection of forest fire smoke. Image generation models offer a promising solution for synthesizing realistic smoke images. However, current inpainting models exhibit limitations in generating high-quality smoke representations, particularly manifesting as inconsistencies between synthesized smoke and background contexts. To solve these problems, we proposed a comprehensive framework for generating forest fire smoke images. Firstly, we employed the pre-trained segmentation model and the multimodal model to obtain smoke masks and image this http URL, to address the insufficient utilization of masks and masked images by inpainting models, we introduced a network architecture guided by mask and masked image features. We also proposed a new loss function, the mask random difference loss, which enhances the consistency of the generated effects around the mask by randomly expanding and eroding the mask this http URL, to generate a smoke image dataset using random masks for subsequent detection tasks, we incorporated smoke characteristics and use a multimodal large language model as a filtering tool to select diverse and reasonable smoke images, thereby improving the quality of the synthetic dataset. Experiments showed that our generated smoke images are realistic and diverse, and effectively enhance the performance of forest fire smoke detection models. Code is available at this https URL.</li>
</ul>

<h3>Title: ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Ronggang Huang, Haoxin Yang, Yan Cai, Xuemiao Xu, Huaidong Zhang, Shengfeng He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11261">https://arxiv.org/abs/2507.11261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11261">https://arxiv.org/pdf/2507.11261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11261]] ViewSRD: 3D Visual Grounding via Structured Multi-View Decomposition(https://arxiv.org/abs/2507.11261)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D visual grounding aims to identify and localize objects in a 3D space based on textual descriptions. However, existing methods struggle with disentangling targets from anchors in complex multi-anchor queries and resolving inconsistencies in spatial descriptions caused by perspective variations. To tackle these challenges, we propose ViewSRD, a framework that formulates 3D visual grounding as a structured multi-view decomposition process. First, the Simple Relation Decoupling (SRD) module restructures complex multi-anchor queries into a set of targeted single-anchor statements, generating a structured set of perspective-aware descriptions that clarify positional relationships. These decomposed representations serve as the foundation for the Multi-view Textual-Scene Interaction (Multi-TSI) module, which integrates textual and scene features across multiple viewpoints using shared, Cross-modal Consistent View Tokens (CCVTs) to preserve spatial correlations. Finally, a Textual-Scene Reasoning module synthesizes multi-view predictions into a unified and robust 3D visual grounding. Experiments on 3D visual grounding datasets show that ViewSRD significantly outperforms state-of-the-art methods, particularly in complex queries requiring precise spatial differentiation.</li>
</ul>

<h3>Title: LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments</h3>
<ul>
<li><strong>Authors: </strong>Elmira Mirzabeigi, Sepehr Rezaee, Kourosh Parand</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11262">https://arxiv.org/abs/2507.11262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11262">https://arxiv.org/pdf/2507.11262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11262]] LyAm: Robust Non-Convex Optimization for Stable Learning in Noisy Environments(https://arxiv.org/abs/2507.11262)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Training deep neural networks, particularly in computer vision tasks, often suffers from noisy gradients and unstable convergence, which hinder performance and generalization. In this paper, we propose LyAm, a novel optimizer that integrates Adam's adaptive moment estimation with Lyapunov-based stability mechanisms. LyAm dynamically adjusts the learning rate using Lyapunov stability theory to enhance convergence robustness and mitigate training noise. We provide a rigorous theoretical framework proving the convergence guarantees of LyAm in complex, non-convex settings. Extensive experiments on like as CIFAR-10 and CIFAR-100 show that LyAm consistently outperforms state-of-the-art optimizers in terms of accuracy, convergence speed, and stability, establishing it as a strong candidate for robust deep learning optimization.</li>
</ul>

<h3>Title: YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery</h3>
<ul>
<li><strong>Authors: </strong>Aon Safdar, Usman Akram, Waseem Anwar, Basit Malik, Mian Ibad Ali</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11267">https://arxiv.org/abs/2507.11267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11267">https://arxiv.org/pdf/2507.11267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11267]] YOLOatr : Deep Learning Based Automatic Target Detection and Localization in Thermal Infrared Imagery(https://arxiv.org/abs/2507.11267)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>Automatic Target Detection (ATD) and Recognition (ATR) from Thermal Infrared (TI) imagery in the defense and surveillance domain is a challenging computer vision (CV) task in comparison to the commercial autonomous vehicle perception domain. Limited datasets, peculiar domain-specific and TI modality-specific challenges, i.e., limited hardware, scale invariance issues due to greater distances, deliberate occlusion by tactical vehicles, lower sensor resolution and resultant lack of structural information in targets, effects of weather, temperature, and time of day variations, and varying target to clutter ratios all result in increased intra-class variability and higher inter-class similarity, making accurate real-time ATR a challenging CV task. Resultantly, contemporary state-of-the-art (SOTA) deep learning architectures underperform in the ATR domain. We propose a modified anchor-based single-stage detector, called YOLOatr, based on a modified YOLOv5s, with optimal modifications to the detection heads, feature fusion in the neck, and a custom augmentation profile. We evaluate the performance of our proposed model on a comprehensive DSIAC MWIR dataset for real-time ATR over both correlated and decorrelated testing protocols. The results demonstrate that our proposed model achieves state-of-the-art ATR performance of up to 99.6%.</li>
</ul>

<h3>Title: KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding</h3>
<ul>
<li><strong>Authors: </strong>Luohe Shi, Zuchao Li, Lefei Zhang, Guoming Liu, Baoyuan Qi, Hai Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11273">https://arxiv.org/abs/2507.11273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11273">https://arxiv.org/pdf/2507.11273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11273]] KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding(https://arxiv.org/abs/2507.11273)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) based on Transformer Decoders have become the preferred choice for conversational generative AI. Despite the overall superiority of the Decoder architecture, the gradually increasing Key-Value (KV) cache during inference has emerged as a primary efficiency bottleneck, both in aspects of memory consumption and data transfer bandwidth limitations. To address these challenges, we propose a paradigm called KV-Latent. By down-sampling the Key-Value vector dimensions into a latent space, we can significantly reduce the KV Cache footprint and improve inference speed, only with a small amount of extra training, less than 1\% of pre-training takes. Besides, we enhanced the stability of Rotary Positional Embedding applied on lower-dimensional vectors by modifying its frequency sampling mechanism, avoiding noise introduced by higher frequencies while retaining position attenuation. Our experiments, including both models with Grouped Query Attention and those without, have yielded satisfactory results. Finally, we conducted comparative experiments to study the impact of separately reducing Key and Value components on model's performance. Our approach allows for the construction of more efficient language model systems, and opens the new possibility on KV Cache saving and efficient LLMs. Our code is available at this https URL.</li>
</ul>

<h3>Title: FMC: Formalization of Natural Language Mathematical Competition Problems</h3>
<ul>
<li><strong>Authors: </strong>Jiaxuan Xie, Chengwu Liu, Ye Yuan, Siqi Li, Zhiping Xiao, Ming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11275">https://arxiv.org/abs/2507.11275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11275">https://arxiv.org/pdf/2507.11275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11275]] FMC: Formalization of Natural Language Mathematical Competition Problems(https://arxiv.org/abs/2507.11275)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Efficient and accurate autoformalization methods, which leverage large-scale datasets of extensive natural language mathematical problems to construct formal language datasets, are key to advancing formal mathematical reasoning. In this paper, we propose an autoformalization pipeline based on large language models with error feedback, achieving a fully automatic and training-free formalization approach. Using this pipeline, we curate an Olympiad-level dataset aligning natural language problems with Lean formalizations. The dataset comprises $3,922$ mathematical problems in natural language and $9,787$ in Lean, of which $64.46\%$ were assessed as at least above-average quality, making it suitable as a benchmark for automated theorem provers. Additionally, we investigate the formalization and reasoning capabilities of various LLMs and empirically demonstrate that few-shot learning, error feedback, and increasing sampling numbers enhance the autoformalization process. Experiments of three automated theorem provers on the \dataset\ dataset also highlight its challenging nature and its value as a benchmark for formal reasoning tasks.</li>
</ul>

<h3>Title: Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping</h3>
<ul>
<li><strong>Authors: </strong>Yujie Zhang, Sabine Struckmeyer, Andreas Kolb, Sven Reichardt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11279">https://arxiv.org/abs/2507.11279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11279">https://arxiv.org/pdf/2507.11279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11279]] Tomato Multi-Angle Multi-Pose Dataset for Fine-Grained Phenotyping(https://arxiv.org/abs/2507.11279)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Observer bias and inconsistencies in traditional plant phenotyping methods limit the accuracy and reproducibility of fine-grained plant analysis. To overcome these challenges, we developed TomatoMAP, a comprehensive dataset for Solanum lycopersicum using an Internet of Things (IoT) based imaging system with standardized data acquisition protocols. Our dataset contains 64,464 RGB images that capture 12 different plant poses from four camera elevation angles. Each image includes manually annotated bounding boxes for seven regions of interest (ROIs), including leaves, panicle, batch of flowers, batch of fruits, axillary shoot, shoot and whole plant area, along with 50 fine-grained growth stage classifications based on the BBCH scale. Additionally, we provide 3,616 high-resolution image subset with pixel-wise semantic and instance segmentation annotations for fine-grained phenotyping. We validated our dataset using a cascading model deep learning framework combining MobileNetv3 for classification, YOLOv11 for object detection, and MaskRCNN for segmentation. Through AI vs. Human analysis involving five domain experts, we demonstrate that the models trained on our dataset achieve accuracy and speed comparable to the experts. Cohen's Kappa and inter-rater agreement heatmap confirm the reliability of automated fine-grained phenotyping using our approach.</li>
</ul>

<h3>Title: Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks</h3>
<ul>
<li><strong>Authors: </strong>Zewen Bai, Liang Yang, Shengdi Yin, Yuanyuan Sun, Hongfei Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11292">https://arxiv.org/abs/2507.11292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11292">https://arxiv.org/pdf/2507.11292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11292]] Fine-Grained Chinese Hate Speech Understanding: Span-Level Resources, Coded Term Lexicon, and Enhanced Detection Frameworks(https://arxiv.org/abs/2507.11292)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>The proliferation of hate speech has inflicted significant societal harm, with its intensity and directionality closely tied to specific targets and arguments. In recent years, numerous machine learning-based methods have been developed to detect hateful comments on online platforms automatically. However, research on Chinese hate speech detection lags behind, and interpretability studies face two major challenges: first, the scarcity of span-level fine-grained annotated datasets limits models' deep semantic understanding of hate speech; second, insufficient research on identifying and interpreting coded hate speech restricts model explainability in complex real-world scenarios. To address these, we make the following contributions: (1) We introduce the Span-level Target-Aware Toxicity Extraction dataset (STATE ToxiCN), the first span-level Chinese hate speech dataset, and evaluate the hate semantic understanding of existing models using it. (2) We conduct the first comprehensive study on Chinese coded hate terms, LLMs' ability to interpret hate semantics. (3) We propose a method to integrate an annotated lexicon into models, significantly enhancing hate speech detection performance. Our work provides valuable resources and insights to advance the interpretability of Chinese hate speech detection research.</li>
</ul>

<h3>Title: Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian</h3>
<ul>
<li><strong>Authors: </strong>Andrei Niculae, Adrian Cosma, Cosmin Dumitrache, Emilian R«édoi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11299">https://arxiv.org/abs/2507.11299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11299">https://arxiv.org/pdf/2507.11299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11299]] Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian(https://arxiv.org/abs/2507.11299)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text-based telemedicine has become increasingly common, yet the quality of medical advice in doctor-patient interactions is often judged more on how advice is communicated rather than its clinical accuracy. To address this, we introduce this http URL , a multi-agent large language model (LLM) system that supports Romanian-speaking doctors by evaluating and enhancing the presentation quality of their written responses. Rather than assessing medical correctness, this http URL provides feedback along 17 interpretable axes. The system comprises of three LLM agents with prompts automatically optimized via DSPy. Designed with low-resource Romanian data and deployed using open-weight models, it delivers real-time specific feedback to doctors within a telemedicine platform. Empirical evaluations and live deployment with 41 doctors show measurable improvements in user reviews and response quality, marking one of the first real-world deployments of LLMs in Romanian medical settings.</li>
</ul>

<h3>Title: Detecci√≥n y Cuantificaci√≥n de Erosi√≥n Fluvial con Visi√≥n Artificial</h3>
<ul>
<li><strong>Authors: </strong>Pa√∫l Maji, Marlon T√∫querres, Stalin Valencia, Marcela Valenzuela, Christian Mejia-Escobar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11301">https://arxiv.org/abs/2507.11301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11301">https://arxiv.org/pdf/2507.11301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11301]] Detecci√≥n y Cuantificaci√≥n de Erosi√≥n Fluvial con Visi√≥n Artificial(https://arxiv.org/abs/2507.11301)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Fluvial erosion is a natural process that can generate significant impacts on soil stability and strategic infrastructures. The detection and monitoring of this phenomenon is traditionally addressed by photogrammetric methods and analysis in geographic information systems. These tasks require specific knowledge and intensive manual processing. This study proposes an artificial intelligence-based approach for automatic identification of eroded zones and estimation of their area. The state-of-the-art computer vision model YOLOv11, adjusted by fine-tuning and trained with photographs and LiDAR images, is used. This combined dataset was segmented and labeled using the Roboflow platform. Experimental results indicate efficient detection of erosion patterns with an accuracy of 70%, precise identification of eroded areas and reliable calculation of their extent in pixels and square meters. As a final product, the EROSCAN system has been developed, an interactive web application that allows users to upload images and obtain automatic segmentations of fluvial erosion, together with the estimated area. This tool optimizes the detection and quantification of the phenomenon, facilitating decision making in risk management and territorial planning.</li>
</ul>

<h3>Title: LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification</h3>
<ul>
<li><strong>Authors: </strong>Fengxiao Tang, Huan Li, Ming Zhao, Zongzong Wu, Shisong Peng, Tao Yin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11310">https://arxiv.org/abs/2507.11310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11310">https://arxiv.org/pdf/2507.11310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11310]] LRCTI: A Large Language Model-Based Framework for Multi-Step Evidence Retrieval and Reasoning in Cyber Threat Intelligence Credibility Verification(https://arxiv.org/abs/2507.11310)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>Verifying the credibility of Cyber Threat Intelligence (CTI) is essential for reliable cybersecurity defense. However, traditional approaches typically treat this task as a static classification problem, relying on handcrafted features or isolated deep learning models. These methods often lack the robustness needed to handle incomplete, heterogeneous, or noisy intelligence, and they provide limited transparency in decision-making-factors that reduce their effectiveness in real-world threat environments. To address these limitations, we propose LRCTI, a Large Language Model (LLM)-based framework designed for multi-step CTI credibility verification. The framework first employs a text summarization module to distill complex intelligence reports into concise and actionable threat claims. It then uses an adaptive multi-step evidence retrieval mechanism that iteratively identifies and refines supporting information from a CTI-specific corpus, guided by LLM feedback. Finally, a prompt-based Natural Language Inference (NLI) module is applied to evaluate the credibility of each claim while generating interpretable justifications for the classification outcome. Experiments conducted on two benchmark datasets, CTI-200 and PolitiFact show that LRCTI improves F1-Macro and F1-Micro scores by over 5%, reaching 90.9% and 93.6%, respectively, compared to state-of-the-art baselines. These results demonstrate that LRCTI effectively addresses the core limitations of prior methods, offering a scalable, accurate, and explainable solution for automated CTI credibility verification</li>
</ul>

<h3>Title: Internal Value Alignment in Large Language Models through Controlled Value Vector Activation</h3>
<ul>
<li><strong>Authors: </strong>Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11316">https://arxiv.org/abs/2507.11316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11316">https://arxiv.org/pdf/2507.11316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11316]] Internal Value Alignment in Large Language Models through Controlled Value Vector Activation(https://arxiv.org/abs/2507.11316)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Aligning Large Language Models (LLMs) with human values has attracted increasing attention since it provides clarity, transparency, and the ability to adapt to evolving scenarios. In this paper, we introduce a Controlled Value Vector Activation (ConVA) method that directly aligns the internal values of LLMs by interpreting how a value is encoded in their latent representations and modifies relevant activations to ensure consistent values in LLMs. To ensure an accurate and unbiased interpretation, we propose a context-controlled value vector identification method. To consistently control values without sacrificing model performance, we introduce a gated value vector activation method for effective and minimum degree of value control. Experiments show that our method achieves the highest control success rate across 10 basic values without hurting LLM performance and fluency, and ensures target values even with opposite and potentially malicious input prompts. Source code and data are available at~ this https URL.</li>
</ul>

<h3>Title: A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation</h3>
<ul>
<li><strong>Authors: </strong>Frederik Marinus Trudslev, Matteo Lissandrini, Juan Manuel Rodriguez, Martin B√∏gsted, Daniele Dell'Aglio</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11324">https://arxiv.org/abs/2507.11324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11324">https://arxiv.org/pdf/2507.11324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11324]] A Review of Privacy Metrics for Privacy-Preserving Synthetic Data Generation(https://arxiv.org/abs/2507.11324)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Privacy Preserving Synthetic Data Generation (PP-SDG) has emerged to produce synthetic datasets from personal data while maintaining privacy and utility. Differential privacy (DP) is the property of a PP-SDG mechanism that establishes how protected individuals are when sharing their sensitive data. It is however difficult to interpret the privacy loss ($\varepsilon$) expressed by DP. To make the actual risk associated with the privacy loss more transparent, multiple privacy metrics (PMs) have been proposed to assess the privacy risk of the data. These PMs are utilized in separate studies to assess newly introduced PP-SDG mechanisms. Consequently, these PMs embody the same assumptions as the PP-SDG mechanism they were made to assess. Therefore, a thorough definition of how these are calculated is necessary. In this work, we present the assumptions and mathematical formulations of 17 distinct privacy metrics.</li>
</ul>

<h3>Title: HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging</h3>
<ul>
<li><strong>Authors: </strong>Arefin Ittesafun Abian, Ripon Kumar Debnath, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, Md Rafiqul Islam, Asif Karim, Reem E. Mohamed, Sami Azam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11325">https://arxiv.org/abs/2507.11325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11325">https://arxiv.org/pdf/2507.11325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11325]] HANS-Net: Hyperbolic Convolution and Adaptive Temporal Attention for Accurate and Generalizable Liver and Tumor Segmentation in CT Imaging(https://arxiv.org/abs/2507.11325)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate liver and tumor segmentation on abdominal CT images is critical for reliable diagnosis and treatment planning, but remains challenging due to complex anatomical structures, variability in tumor appearance, and limited annotated data. To address these issues, we introduce Hyperbolic-convolutions Adaptive-temporal-attention with Neural-representation and Synaptic-plasticity Network (HANS-Net), a novel segmentation framework that synergistically combines hyperbolic convolutions for hierarchical geometric representation, a wavelet-inspired decomposition module for multi-scale texture learning, a biologically motivated synaptic plasticity mechanism for adaptive feature enhancement, and an implicit neural representation branch to model fine-grained and continuous anatomical boundaries. Additionally, we incorporate uncertainty-aware Monte Carlo dropout to quantify prediction confidence and lightweight temporal attention to improve inter-slice consistency without sacrificing efficiency. Extensive evaluations of the LiTS dataset demonstrate that HANS-Net achieves a mean Dice score of 93.26%, an IoU of 88.09%, an average symmetric surface distance (ASSD) of 0.72 mm, and a volume overlap error (VOE) of 11.91%. Furthermore, cross-dataset validation on the 3D-IRCADb-01 dataset obtains an average Dice of 87.45%, IoU of 80.30%, ASSD of 1.525 mm, and VOE of 19.71%, indicating strong generalization across different datasets. These results confirm the effectiveness and robustness of HANS-Net in providing anatomically consistent, accurate, and confident liver and tumor segmentation.</li>
</ul>

<h3>Title: Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Wenqing Wu, Chengzhi Zhang, Yi Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11330">https://arxiv.org/abs/2507.11330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11330">https://arxiv.org/pdf/2507.11330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11330]] Automated Novelty Evaluation of Academic Paper: A Collaborative Approach Integrating Human and Large Language Model Knowledge(https://arxiv.org/abs/2507.11330)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Novelty is a crucial criterion in the peer review process for evaluating academic papers. Traditionally, it's judged by experts or measure by unique reference combinations. Both methods have limitations: experts have limited knowledge, and the effectiveness of the combination method is uncertain. Moreover, it's unclear if unique citations truly measure novelty. The large language model (LLM) possesses a wealth of knowledge, while human experts possess judgment abilities that the LLM does not possess. Therefore, our research integrates the knowledge and abilities of LLM and human experts to address the limitations of novelty assessment. The most common novelty in academic papers is the introduction of new methods. In this paper, we propose leveraging human knowledge and LLM to assist pretrained language models (PLMs, e.g. BERT etc.) in predicting the method novelty of papers. Specifically, we extract sentences related to the novelty of the academic paper from peer review reports and use LLM to summarize the methodology section of the academic paper, which are then used to fine-tune PLMs. In addition, we have designed a text-guided fusion module with novel Sparse-Attention to better integrate human and LLM knowledge. We compared the method we proposed with a large number of baselines. Extensive experiments demonstrate that our method achieves superior performance.</li>
</ul>

<h3>Title: MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network</h3>
<ul>
<li><strong>Authors: </strong>Jianfei Jiang, Qiankun Liu, Haochen Yu, Hongyuan Liu, Liyong Wang, Jiansheng Chen, Huimin Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11333">https://arxiv.org/abs/2507.11333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11333">https://arxiv.org/pdf/2507.11333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11333]] MonoMVSNet: Monocular Priors Guided Multi-View Stereo Network(https://arxiv.org/abs/2507.11333)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning-based Multi-View Stereo (MVS) methods aim to predict depth maps for a sequence of calibrated images to recover dense point clouds. However, existing MVS methods often struggle with challenging regions, such as textureless regions and reflective surfaces, where feature matching fails. In contrast, monocular depth estimation inherently does not require feature matching, allowing it to achieve robust relative depth estimation in these regions. To bridge this gap, we propose MonoMVSNet, a novel monocular feature and depth guided MVS network that integrates powerful priors from a monocular foundation model into multi-view geometry. Firstly, the monocular feature of the reference view is integrated into source view features by the attention mechanism with a newly designed cross-view position encoding. Then, the monocular depth of the reference view is aligned to dynamically update the depth candidates for edge regions during the sampling procedure. Finally, a relative consistency loss is further designed based on the monocular depth to supervise the depth prediction. Extensive experiments demonstrate that MonoMVSNet achieves state-of-the-art performance on the DTU and Tanks-and-Temples datasets, ranking first on the Tanks-and-Temples Intermediate and Advanced benchmarks. The source code is available at this https URL.</li>
</ul>

<h3>Title: Guiding LLM Decision-Making with Fairness Reward Models</h3>
<ul>
<li><strong>Authors: </strong>Zara Hall, Melanie Subbiah, Thomas P Zollo, Kathleen McKeown, Richard Zemel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11344">https://arxiv.org/abs/2507.11344</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11344">https://arxiv.org/pdf/2507.11344</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11344]] Guiding LLM Decision-Making with Fairness Reward Models(https://arxiv.org/abs/2507.11344)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are increasingly used to support high-stakes decisions, potentially influencing who is granted bail or receives a loan. Naive chain-of-thought sampling can improve average decision accuracy, but has also been shown to amplify unfair bias. To address this challenge and enable the trustworthy use of reasoning models in high-stakes decision-making, we propose a framework for training a generalizable Fairness Reward Model (FRM). Our model assigns a fairness score to LLM reasoning, enabling the system to down-weight biased trajectories and favor equitable ones when aggregating decisions across reasoning chains. We show that a single Fairness Reward Model, trained on weakly supervised, LLM-annotated examples of biased versus unbiased reasoning, transfers across tasks, domains, and model families without additional fine-tuning. Applied to real-world decision-making tasks including recidivism prediction and social media moderation, we show that our approach consistently improves fairness while matching, or even surpassing, baseline accuracy.</li>
</ul>

<h3>Title: What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alexis Brissard, Fr√©d√©ric Cuppens, Amal Zouaq</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11356">https://arxiv.org/abs/2507.11356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11356">https://arxiv.org/pdf/2507.11356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11356]] What is the Best Process Model Representation? A Comparative Analysis for Process Modeling with Large Language Models(https://arxiv.org/abs/2507.11356)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly applied for Process Modeling (PMo) tasks such as Process Model Generation (PMG). To support these tasks, researchers have introduced a variety of Process Model Representations (PMRs) that serve as model abstractions or generation targets. However, these PMRs differ widely in structure, complexity, and usability, and have never been systematically compared. Moreover, recent PMG approaches rely on distinct evaluation strategies and generation techniques, making comparison difficult. This paper presents the first empirical study that evaluates multiple PMRs in the context of PMo with LLMs. We introduce the PMo Dataset, a new dataset containing 55 process descriptions paired with models in nine different PMRs. We evaluate PMRs along two dimensions: suitability for LLM-based PMo and performance on PMG. \textit{Mermaid} achieves the highest overall score across six PMo criteria, whereas \textit{BPMN text} delivers the best PMG results in terms of process element similarity.</li>
</ul>

<h3>Title: Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Gabriel Bo, Koa Chang, Justin Gu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11371">https://arxiv.org/abs/2507.11371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11371">https://arxiv.org/pdf/2507.11371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11371]] Step-wise Policy for Rare-tool Knowledge (SPaRK): Offline RL that Drives Diverse Tool Use in LLMs(https://arxiv.org/abs/2507.11371)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present Step-wise Policy for Rare-tool Knowledge (SPaRK), a novel reinforcement learning framework that teaches large language models to explore diverse tool usage patterns beyond conventional high-temperature sampling. Building on recent advances in step-wise reinforcement learning, we introduce a dual-objective reward system that simultaneously optimizes for answer quality and tool diversity, training a Llama-3.1 8B model through offline PPO on synthetically generated trajectories from the MMLU-Pro dataset. Our approach uniquely employs a rarity-first exploitation strategy where a GPT-4o judge scores candidate actions across eight distinct tools plus chain-of-thought reasoning, with the policy favoring less-frequently used but still viable tools to encourage systematic exploration. Empirical results demonstrate that SPaRK achieves competitive performance across 14 MMLU-Pro categories while exhibiting significantly higher entropy in tool selection compared to both baseline and supervised fine-tuning approaches, suggesting that algorithmic exploration through explicit tool diversity can enhance reasoning capabilities without sacrificing accuracy.</li>
</ul>

<h3>Title: Attributes Shape the Embedding Space of Face Recognition Models</h3>
<ul>
<li><strong>Authors: </strong>Pierrick Leroy, Antonio Mastropietro, Marco Nurisso, Francesco Vaccarino</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11372">https://arxiv.org/abs/2507.11372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11372">https://arxiv.org/pdf/2507.11372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11372]] Attributes Shape the Embedding Space of Face Recognition Models(https://arxiv.org/abs/2507.11372)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Face Recognition (FR) tasks have made significant progress with the advent of Deep Neural Networks, particularly through margin-based triplet losses that embed facial images into high-dimensional feature spaces. During training, these contrastive losses focus exclusively on identity information as labels. However, we observe a multiscale geometric structure emerging in the embedding space, influenced by interpretable facial (e.g., hair color) and image attributes (e.g., contrast). We propose a geometric approach to describe the dependence or invariance of FR models to these attributes and introduce a physics-inspired alignment metric. We evaluate the proposed metric on controlled, simplified models and widely used FR models fine-tuned with synthetic data for targeted attribute augmentation. Our findings reveal that the models exhibit varying degrees of invariance across different attributes, providing insight into their strengths and weaknesses and enabling deeper interpretability. Code available here: this https URL}{this https URL</li>
</ul>

<h3>Title: Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss</h3>
<ul>
<li><strong>Authors: </strong>Xia Cui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11384">https://arxiv.org/abs/2507.11384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11384">https://arxiv.org/pdf/2507.11384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11384]] Addressing Data Imbalance in Transformer-Based Multi-Label Emotion Detection with Weighted Loss(https://arxiv.org/abs/2507.11384)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper explores the application of a simple weighted loss function to Transformer-based models for multi-label emotion detection in SemEval-2025 Shared Task 11. Our approach addresses data imbalance by dynamically adjusting class weights, thereby enhancing performance on minority emotion classes without the computational burden of traditional resampling methods. We evaluate BERT, RoBERTa, and BART on the BRIGHTER dataset, using evaluation metrics such as Micro F1, Macro F1, ROC-AUC, Accuracy, and Jaccard similarity coefficients. The results demonstrate that the weighted loss function improves performance on high-frequency emotion classes but shows limited impact on minority classes. These findings underscore both the effectiveness and the challenges of applying this approach to imbalanced multi-label emotion detection.</li>
</ul>

<h3>Title: A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>James P Jun, Vijay Marupudi, Raj Sanjay Shah, Sashank Varma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11393">https://arxiv.org/abs/2507.11393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11393">https://arxiv.org/pdf/2507.11393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11393]] A Neural Network Model of Complementary Learning Systems: Pattern Separation and Completion for Continual Learning(https://arxiv.org/abs/2507.11393)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning new information without forgetting prior knowledge is central to human intelligence. In contrast, neural network models suffer from catastrophic forgetting: a significant degradation in performance on previously learned tasks when acquiring new information. The Complementary Learning Systems (CLS) theory offers an explanation for this human ability, proposing that the brain has distinct systems for pattern separation (encoding distinct memories) and pattern completion (retrieving complete memories from partial cues). To capture these complementary functions, we leverage the representational generalization capabilities of variational autoencoders (VAEs) and the robust memory storage properties of Modern Hopfield networks (MHNs), combining them into a neurally plausible continual learning model. We evaluate this model on the Split-MNIST task, a popular continual learning benchmark, and achieve close to state-of-the-art accuracy (~90%), substantially reducing forgetting. Representational analyses empirically confirm the functional dissociation: the VAE underwrites pattern completion, while the MHN drives pattern separation. By capturing pattern separation and completion in scalable architectures, our work provides a functional template for modeling memory consolidation, generalization, and continual learning in both biological and artificial systems.</li>
</ul>

<h3>Title: DCR: Quantifying Data Contamination in LLMs Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Cheng Xu, Nan Yan, Shuhao Guan, Changhong Jin, Yuke Mei, Yibing Guo, M-Tahar Kechadi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11405">https://arxiv.org/abs/2507.11405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11405">https://arxiv.org/pdf/2507.11405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11405]] DCR: Quantifying Data Contamination in LLMs Evaluation(https://arxiv.org/abs/2507.11405)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has heightened concerns about benchmark data contamination (BDC), where models inadvertently memorize evaluation data, inflating performance metrics and undermining genuine generalization assessment. This paper introduces the Data Contamination Risk (DCR) framework, a lightweight, interpretable pipeline designed to detect and quantify BDC across four granular levels: semantic, informational, data, and label. By synthesizing contamination scores via a fuzzy inference system, DCR produces a unified DCR Factor that adjusts raw accuracy to reflect contamination-aware performance. Validated on 9 LLMs (0.5B-72B) across sentiment analysis, fake news detection, and arithmetic reasoning tasks, the DCR framework reliably diagnoses contamination severity and with accuracy adjusted using the DCR Factor to within 4% average error across the three benchmarks compared to the uncontaminated baseline. Emphasizing computational efficiency and transparency, DCR provides a practical tool for integrating contamination assessment into routine evaluations, fostering fairer comparisons and enhancing the credibility of LLM benchmarking practices.</li>
</ul>

<h3>Title: EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes</h3>
<ul>
<li><strong>Authors: </strong>LG AI Research: Kyunghoon Bae, Eunbi Choi, Kibong Choi, Stanley Jungkyu Choi, Yemuk Choi, Kyubeen Han, Seokhee Hong, Junwon Hwang, Taewan Hwang, Joonwon Jang, Hyojin Jeon, Kijeong Jeon, Gerrard Jeongwon Jo, Hyunjik Jo, Jiyeon Jung, Euisoon Kim, Hyosang Kim, Jihoon Kim, Joonkee Kim, Seonghwan Kim, Soyeon Kim, Sunkyoung Kim, Yireun Kim, Yongil Kim, Youchul Kim, Edward Hwayoung Lee, Gwangho Lee, Haeju Lee, Honglak Lee, Jinsik Lee, Kyungmin Lee, Sangha Park, Young Min Paik, Yongmin Park, Youngyong Park, Sanghyun Seo, Sihoon Yang, Heuiyeen Yeen, Sihyuk Yi, Hyeongu Yun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11407">https://arxiv.org/abs/2507.11407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11407">https://arxiv.org/pdf/2507.11407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11407]] EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes(https://arxiv.org/abs/2507.11407)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via this https URL.</li>
</ul>

<h3>Title: KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?</h3>
<ul>
<li><strong>Authors: </strong>Soumadeep Saha, Akshay Chaturvedi, Saptarshi Saha, Utpal Garain, Nicholas Asher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11408">https://arxiv.org/abs/2507.11408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11408">https://arxiv.org/pdf/2507.11408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11408]] KisMATH: Do LLMs Have Knowledge of Implicit Structures in Mathematical Reasoning?(https://arxiv.org/abs/2507.11408)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-thought traces have been shown to improve performance of large language models in a plethora of reasoning tasks, yet there is no consensus on the mechanism through which this performance boost is achieved. To shed more light on this, we introduce Causal CoT Graphs (CCGs), which are directed acyclic graphs automatically extracted from reasoning traces that model fine-grained causal dependencies in the language model output. A collection of $1671$ mathematical reasoning problems from MATH500, GSM8K and AIME, and their associated CCGs are compiled into our dataset -- \textbf{KisMATH}. Our detailed empirical analysis with 15 open-weight LLMs shows that (i) reasoning nodes in the CCG are mediators for the final answer, a condition necessary for reasoning; and (ii) LLMs emphasise reasoning paths given by the CCG, indicating that models internally realise structures akin to our graphs. KisMATH enables controlled, graph-aligned interventions and opens up avenues for further investigation into the role of chain-of-thought in LLM reasoning.</li>
</ul>

<h3>Title: Robust-Multi-Task Gradient Boosting</h3>
<ul>
<li><strong>Authors: </strong>Seyedsaman Emami, Gonzalo Mart√≠nez-Mu√±oz, Daniel Hern√°ndez-Lobato</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11411">https://arxiv.org/abs/2507.11411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11411">https://arxiv.org/pdf/2507.11411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11411]] Robust-Multi-Task Gradient Boosting(https://arxiv.org/abs/2507.11411)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-task learning (MTL) has shown effectiveness in exploiting shared information across tasks to improve generalization. MTL assumes tasks share similarities that can improve performance. In addition, boosting algorithms have demonstrated exceptional performance across diverse learning problems, primarily due to their ability to focus on hard-to-learn instances and iteratively reduce residual errors. This makes them a promising approach for learning multi-task problems. However, real-world MTL scenarios often involve tasks that are not well-aligned (known as outlier or adversarial tasks), which do not share beneficial similarities with others and can, in fact, deteriorate the performance of the overall model. To overcome this challenge, we propose Robust-Multi-Task Gradient Boosting (R-MTGB), a novel boosting framework that explicitly models and adapts to task heterogeneity during training. R-MTGB structures the learning process into three sequential blocks: (1) learning shared patterns, (2) partitioning tasks into outliers and non-outliers with regularized parameters, and (3) fine-tuning task-specific predictors. This architecture enables R-MTGB to automatically detect and penalize outlier tasks while promoting effective knowledge transfer among related tasks. Our method integrates these mechanisms seamlessly within gradient boosting, allowing robust handling of noisy or adversarial tasks without sacrificing accuracy. Extensive experiments on both synthetic benchmarks and real-world datasets demonstrate that our approach successfully isolates outliers, transfers knowledge, and consistently reduces prediction errors for each task individually, and achieves overall performance gains across all tasks. These results highlight robustness, adaptability, and reliable convergence of R-MTGB in challenging MTL environments.</li>
</ul>

<h3>Title: Seq vs Seq: An Open Suite of Paired Encoders and Decoders</h3>
<ul>
<li><strong>Authors: </strong>Orion Weller, Kathryn Ricci, Marc Marone, Antoine Chaffin, Dawn Lawrie, Benjamin Van Durme</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11412">https://arxiv.org/abs/2507.11412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11412">https://arxiv.org/pdf/2507.11412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11412]] Seq vs Seq: An Open Suite of Paired Encoders and Decoders(https://arxiv.org/abs/2507.11412)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The large language model (LLM) community focuses almost exclusively on decoder-only language models, since they are easier to use for text generation. However, a large subset of the community still uses encoder-only models for tasks such as classification or retrieval. Previous work has attempted to compare these architectures, but is forced to make comparisons with models that have different numbers of parameters, training techniques, and datasets. We introduce the SOTA open-data Ettin suite of models: paired encoder-only and decoder-only models ranging from 17 million parameters to 1 billion, trained on up to 2 trillion tokens. Using the same recipe for both encoder-only and decoder-only models produces SOTA recipes in both categories for their respective sizes, beating ModernBERT as an encoder and Llama 3.2 and SmolLM2 as decoders. Like previous work, we find that encoder-only models excel at classification and retrieval tasks while decoders excel at generative tasks. However, we show that adapting a decoder model to encoder tasks (and vice versa) through continued training is subpar compared to using only the reverse objective (i.e. a 400M encoder outperforms a 1B decoder on MNLI, and vice versa for generative tasks). We open-source all artifacts of this study including training data, training order segmented by checkpoint, and 200+ checkpoints to allow future work to analyze or extend all aspects of training.</li>
</ul>

<h3>Title: Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?</h3>
<ul>
<li><strong>Authors: </strong>Yanjian Zhang, Guillaume Wisniewski, Nadi Tomeh, Thierry Charnois</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11423">https://arxiv.org/abs/2507.11423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11423">https://arxiv.org/pdf/2507.11423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11423]] Reasoning Strategies in Large Language Models: Can They Follow, Prefer, and Optimize?(https://arxiv.org/abs/2507.11423)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Human reasoning involves different strategies, each suited to specific problems. Prior work shows that large language model (LLMs) tend to favor a single reasoning strategy, potentially limiting their effectiveness in diverse reasoning challenges. In this work, we investigate whether prompting can control LLMs reasoning strategies and assess its impact on logical problem-solving. While our experiments show that no single strategy consistently improves accuracy, performance could be enhanced if models could adaptively choose the optimal strategy. We propose methods to guide LLMs in strategy selection, highlighting new ways to refine their reasoning abilities.</li>
</ul>

<h3>Title: Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures</h3>
<ul>
<li><strong>Authors: </strong>Behtom Adeli, John McLinden, Pankaj Pandey, Ming Shao, Yalda Shahriari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11436">https://arxiv.org/abs/2507.11436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11436">https://arxiv.org/pdf/2507.11436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11436]] Toward Improving fNIRS Classification: A Study on Activation Functions in Deep Neural Architectures(https://arxiv.org/abs/2507.11436)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Activation functions are critical to the performance of deep neural networks, particularly in domains such as functional near-infrared spectroscopy (fNIRS), where nonlinearity, low signal-to-noise ratio (SNR), and signal variability poses significant challenges to model accuracy. However, the impact of activation functions on deep learning (DL) performance in the fNIRS domain remains underexplored and lacks systematic investigation in the current literature. This study evaluates a range of conventional and field-specific activation functions for fNIRS classification tasks using multiple deep learning architectures, including the domain-specific fNIRSNet, AbsoluteNet, MDNN, and shallowConvNet (as the baseline), all tested on a single dataset recorded during an auditory task. To ensure fair a comparison, all networks were trained and tested using standardized preprocessing and consistent training parameters. The results show that symmetrical activation functions such as Tanh and the Absolute value function Abs(x) can outperform commonly used functions like the Rectified Linear Unit (ReLU), depending on the architecture. Additionally, a focused analysis of the role of symmetry was conducted using a Modified Absolute Function (MAF), with results further supporting the effectiveness of symmetrical activation functions on performance gains. These findings underscore the importance of selecting proper activation functions that align with the signal characteristics of fNIRS data.</li>
</ul>

<h3>Title: Data Augmentation in Time Series Forecasting through Inverted Framework</h3>
<ul>
<li><strong>Authors: </strong>Hongming Tan, Ting Chen, Ruochong Jin, Wai Kin Chan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11439">https://arxiv.org/abs/2507.11439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11439">https://arxiv.org/pdf/2507.11439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11439]] Data Augmentation in Time Series Forecasting through Inverted Framework(https://arxiv.org/abs/2507.11439)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Currently, iTransformer is one of the most popular and effective models for multivariate time series (MTS) forecasting. Thanks to its inverted framework, iTransformer effectively captures multivariate correlation. However, the inverted framework still has some limitations. It diminishes temporal interdependency information, and introduces noise in cases of nonsignificant variable correlation. To address these limitations, we introduce a novel data augmentation method on inverted framework, called DAIF. Unlike previous data augmentation methods, DAIF stands out as the first real-time augmentation specifically designed for the inverted framework in MTS forecasting. We first define the structure of the inverted sequence-to-sequence framework, then propose two different DAIF strategies, Frequency Filtering and Cross-variation Patching to address the existing challenges of the inverted framework. Experiments across multiple datasets and inverted models have demonstrated the effectiveness of our DAIF.</li>
</ul>

<h3>Title: Implementing Adaptations for Vision AutoRegressive Model</h3>
<ul>
<li><strong>Authors: </strong>Kaif Shaikh, Antoni Kowalczuk, Franziska Boenisch, Adam Dziedzic</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11441">https://arxiv.org/abs/2507.11441</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11441">https://arxiv.org/pdf/2507.11441</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11441]] Implementing Adaptations for Vision AutoRegressive Model(https://arxiv.org/abs/2507.11441)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Vision AutoRegressive model (VAR) was recently introduced as an alternative to Diffusion Models (DMs) in image generation domain. In this work we focus on its adaptations, which aim to fine-tune pre-trained models to perform specific downstream tasks, like medical data generation. While for DMs there exist many techniques, adaptations for VAR remain underexplored. Similarly, differentially private (DP) adaptations-ones that aim to preserve privacy of the adaptation data-have been extensively studied for DMs, while VAR lacks such solutions. In our work, we implement and benchmark many strategies for VAR, and compare them to state-of-the-art DM adaptation strategies. We observe that VAR outperforms DMs for non-DP adaptations, however, the performance of DP suffers, which necessitates further research in private adaptations for VAR. Code is available at this https URL.</li>
</ul>

<h3>Title: LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer</h3>
<ul>
<li><strong>Authors: </strong>Yaoxian Dong, Yifan Gao, Haoyue Li, Yanfen Cui, Xin Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11457">https://arxiv.org/abs/2507.11457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11457">https://arxiv.org/pdf/2507.11457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11457]] LRMR: LLM-Driven Relational Multi-node Ranking for Lymph Node Metastasis Assessment in Rectal Cancer(https://arxiv.org/abs/2507.11457)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Accurate preoperative assessment of lymph node (LN) metastasis in rectal cancer guides treatment decisions, yet conventional MRI evaluation based on morphological criteria shows limited diagnostic performance. While some artificial intelligence models have been developed, they often operate as black boxes, lacking the interpretability needed for clinical trust. Moreover, these models typically evaluate nodes in isolation, overlooking the patient-level context. To address these limitations, we introduce LRMR, an LLM-Driven Relational Multi-node Ranking framework. This approach reframes the diagnostic task from a direct classification problem into a structured reasoning and ranking process. The LRMR framework operates in two stages. First, a multimodal large language model (LLM) analyzes a composite montage image of all LNs from a patient, generating a structured report that details ten distinct radiological features. Second, a text-based LLM performs pairwise comparisons of these reports between different patients, establishing a relative risk ranking based on the severity and number of adverse features. We evaluated our method on a retrospective cohort of 117 rectal cancer patients. LRMR achieved an area under the curve (AUC) of 0.7917 and an F1-score of 0.7200, outperforming a range of deep learning baselines, including ResNet50 (AUC 0.7708). Ablation studies confirmed the value of our two main contributions: removing the relational ranking stage or the structured prompting stage led to a significant performance drop, with AUCs falling to 0.6875 and 0.6458, respectively. Our work demonstrates that decoupling visual perception from cognitive reasoning through a two-stage LLM framework offers a powerful, interpretable, and effective new paradigm for assessing lymph node metastasis in rectal cancer.</li>
</ul>

<h3>Title: D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data</h3>
<ul>
<li><strong>Authors: </strong>Harsha Varun Marisetty, Manik Gupta, Yogesh Simmhan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11471">https://arxiv.org/abs/2507.11471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11471">https://arxiv.org/pdf/2507.11471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11471]] D3FL: Data Distribution and Detrending for Robust Federated Learning in Non-linear Time-series Data(https://arxiv.org/abs/2507.11471)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>With advancements in computing and communication technologies, the Internet of Things (IoT) has seen significant growth. IoT devices typically collect data from various sensors, such as temperature, humidity, and energy meters. Much of this data is temporal in nature. Traditionally, data from IoT devices is centralized for analysis, but this approach introduces delays and increased communication costs. Federated learning (FL) has emerged as an effective alternative, allowing for model training across distributed devices without the need to centralize data. In many applications, such as smart home energy and environmental monitoring, the data collected by IoT devices across different locations can exhibit significant variation in trends and seasonal patterns. Accurately forecasting such non-stationary, non-linear time-series data is crucial for applications like energy consumption estimation and weather forecasting. However, these data variations can severely impact prediction accuracy. The key contributions of this paper are: (1) Investigating how non-linear, non-stationary time-series data distributions, like generalized extreme value (gen-extreme) and log norm distributions, affect FL performance. (2) Analyzing how different detrending techniques for non-linear time-series data influence the forecasting model's performance in a FL setup. We generated several synthetic time-series datasets using non-linear data distributions and trained an LSTM-based forecasting model using both centralized and FL approaches. Additionally, we evaluated the impact of detrending on real-world datasets with non-linear time-series data distributions. Our experimental results show that: (1) FL performs worse than centralized approaches when dealing with non-linear data distributions. (2) The use of appropriate detrending techniques improves FL performance, reducing loss across different data distributions.</li>
</ul>

<h3>Title: HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing</h3>
<ul>
<li><strong>Authors: </strong>Pan Du, Mingqi Xu, Xiaozhi Zhu, Jian-xun Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11474">https://arxiv.org/abs/2507.11474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11474">https://arxiv.org/pdf/2507.11474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11474]] HUG-VAS: A Hierarchical NURBS-Based Generative Model for Aortic Geometry Synthesis and Controllable Editing(https://arxiv.org/abs/2507.11474)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate characterization of vascular geometry is essential for cardiovascular diagnosis and treatment planning. Traditional statistical shape modeling (SSM) methods rely on linear assumptions, limiting their expressivity and scalability to complex topologies such as multi-branch vascular structures. We introduce HUG-VAS, a Hierarchical NURBS Generative model for Vascular geometry Synthesis, which integrates NURBS surface parameterization with diffusion-based generative modeling to synthesize realistic, fine-grained aortic geometries. Trained with 21 patient-specific samples, HUG-VAS generates anatomically faithful aortas with supra-aortic branches, yielding biomarker distributions that closely match those of the original dataset. HUG-VAS adopts a hierarchical architecture comprising a denoising diffusion model that generates centerlines and a guided diffusion model that synthesizes radial profiles conditioned on those centerlines, thereby capturing two layers of anatomical variability. Critically, the framework supports zero-shot conditional generation from image-derived priors, enabling practical applications such as interactive semi-automatic segmentation, robust reconstruction under degraded imaging conditions, and implantable device optimization. To our knowledge, HUG-VAS is the first SSM framework to bridge image-derived priors with generative shape modeling via a unified integration of NURBS parameterization and hierarchical diffusion processes.</li>
</ul>

<h3>Title: C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images</h3>
<ul>
<li><strong>Authors: </strong>Esteban Rom√°n Catafau, Torbj√∂rn E.M. Nordling</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11476">https://arxiv.org/abs/2507.11476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11476">https://arxiv.org/pdf/2507.11476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11476]] C-FBI: A Combinatorial method using Convolutions for Circle Fitting in Blurry Images(https://arxiv.org/abs/2507.11476)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper addresses the fundamental computer vision challenge of robust circle detection and fitting in degraded imaging conditions. We present Combinatorial Convolution-based Circle Fitting for Blurry Images (3C-FBI), an algorithm that bridges the gap between circle detection and precise parametric fitting by combining (1) efficient combinatorial edge pixel (edgel) sampling and (2) convolution-based density estimation in parameter space. We evaluate 3C-FBI across three experimental frameworks: (1) real-world medical data from Parkinson's disease assessments (144 frames from 36 videos), (2) controlled synthetic data following established circle-fitting benchmarks, and (3) systematic analysis across varying spatial resolutions and outlier contamination levels. Results show that 3C-FBI achieves state-of-the-art accuracy (Jaccard index 0.896) while maintaining real-time performance (40.3 fps), significantly outperforming classical methods like RCD (6.8 fps) on a standard CPU (i7-10875H). It maintains near-perfect accuracy (Jaccard almost 1.0) at high resolutions (480x480) and reliable performance (Jaccard higher than 0.95) down to 160x160 with up to 20% outliers. In extensive synthetic testing, 3C-FBI achieves a mean Jaccard Index of 0.989 across contamination levels, comparable to modern methods like Qi et al. (2024, 0.991), and surpassing RHT (0.964). This combination of accuracy, speed, and robustness makes 3C-FBI ideal for medical imaging, robotics, and industrial inspection under challenging conditions.</li>
</ul>

<h3>Title: Exploring the robustness of TractOracle methods in RL-based tractography</h3>
<ul>
<li><strong>Authors: </strong>Jeremi Levesque, Antoine Th√©berge, Maxime Descoteaux, Pierre-Marc Jodoin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11486">https://arxiv.org/abs/2507.11486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11486">https://arxiv.org/pdf/2507.11486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11486]] Exploring the robustness of TractOracle methods in RL-based tractography(https://arxiv.org/abs/2507.11486)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Tractography algorithms leverage diffusion MRI to reconstruct the fibrous architecture of the brain's white matter. Among machine learning approaches, reinforcement learning (RL) has emerged as a promising framework for tractography, outperforming traditional methods in several key aspects. TractOracle-RL, a recent RL-based approach, reduces false positives by incorporating anatomical priors into the training process via a reward-based mechanism. In this paper, we investigate four extensions of the original TractOracle-RL framework by integrating recent advances in RL, and we evaluate their performance across five diverse diffusion MRI datasets. Results demonstrate that combining an oracle with the RL framework consistently leads to robust and reliable tractography, regardless of the specific method or dataset used. We also introduce a novel RL training scheme called Iterative Reward Training (IRT), inspired by the Reinforcement Learning from Human Feedback (RLHF) paradigm. Instead of relying on human input, IRT leverages bundle filtering methods to iteratively refine the oracle's guidance throughout training. Experimental results show that RL methods trained with oracle feedback significantly outperform widely used tractography techniques in terms of accuracy and anatomical validity.</li>
</ul>

<h3>Title: Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN</h3>
<ul>
<li><strong>Authors: </strong>Adhwaa Alchaab, Ayman Younis, Dario Pompili</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11499">https://arxiv.org/abs/2507.11499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11499">https://arxiv.org/pdf/2507.11499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11499]] Demo: Secure Edge Server for Network Slicing and Resource Allocation in Open RAN(https://arxiv.org/abs/2507.11499)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Next-Generation Radio Access Networks (NGRAN) aim to support diverse vertical applications with strict security, latency, and Service-Level Agreement (SLA) requirements. These demands introduce challenges in securing the infrastructure, allocating resources dynamically, and enabling real-time reconfiguration. This demo presents SnSRIC, a secure and intelligent network slicing framework that mitigates a range of Distributed Denial-of-Service (DDoS) attacks in Open RAN environments. SnSRIC incorporates an AI-driven xApp that dynamically allocates Physical Resource Blocks (PRBs) to active users while enforcing slice-level security. The system detects anomalous behavior, distinguishes between benign and malicious devices, and uses the E2 interface to throttle rogue signaling while maintaining service continuity for legitimate users.</li>
</ul>

<h3>Title: ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhengyue Zhao, Yingzi Ma, Somesh Jha, Marco Pavone, Chaowei Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11500">https://arxiv.org/abs/2507.11500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11500">https://arxiv.org/pdf/2507.11500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11500]] ARMOR: Aligning Secure and Safe Large Language Models via Meticulous Reasoning(https://arxiv.org/abs/2507.11500)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable generative capabilities. However, their susceptibility to misuse has raised significant safety concerns. While post-training safety alignment methods have been widely adopted, LLMs remain vulnerable to malicious instructions that can bypass safety constraints. Recent efforts have introduced inference-time safety reasoning (system-2 alignment), where LLMs conduct a reasoning process to perform safety verification before final response. We show, however, that these checks are driven by ad-hoc reasoning that diverges from the structured human process, where they first discern a user's true intent, then evaluate the associated risk based on the true intent. Consequently, these defenses remain vulnerable to sophisticated jailbreak prompts that cloak harmful goals in seemingly benign language. To build secure and safe LLMs, we propose a reasoning-based safety alignment framework, ARMOR, that replaces the ad-hoc chains of thought reasoning process with human-aligned, structured one. At inference, ARMOR (1) detects likely jailbreak strategies, (2) extracts the user's core intent while discarding deceptive instructions, and (3) applies a policy-grounded safety analysis to the purified request. ARMOR is evaluated on adaptive jailbreak attacks and multiple safety benchmarks, and a test-time scaling is conducted to further improve its performance. Results demonstrate that ARMOR significantly enhances the robustness against state-of-the-art adaptive jailbreak attacks and outperforms recent reasoning-based aligned models across various safety benchmarks.</li>
</ul>

<h3>Title: HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong</h3>
<ul>
<li><strong>Authors: </strong>Sirui Han, Junqi Zhu, Ruiyuan Zhang, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CE, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11502">https://arxiv.org/abs/2507.11502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11502">https://arxiv.org/pdf/2507.11502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11502]] HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong(https://arxiv.org/abs/2507.11502)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents the development of HKGAI-V1, a foundational sovereign large language model (LLM), developed as part of an initiative to establish value-aligned AI infrastructure specifically tailored for Hong Kong. Addressing the region's unique multilingual environment (Cantonese, Mandarin, and English), its distinct socio-legal context under the "one country, two systems" framework, and specific local cultural and value considerations, the model is built upon the DeepSeek architecture and systematically aligned with regional norms through a multifaceted full parameter fine-tuning process. It is further integrated with a retrieval-augmented generation (RAG) system to ensure timely and factually grounded information access. The core contribution lies in the design and implementation of a comprehensive, region-specific AI alignment and safety framework, demonstrated through two key achievements: 1) The successful development of HKGAI-V1 itself - which outper-forms general-purpose models in handling Hong Kong-specific culturally sensitive queries, and embodies a "governance-embedded" approach to digital sovereignty - empowers Hong Kong to exercise control over AI applications in critical sectors including public services, legal systems, and edu-cation. 2) The development of the proprietary Adversarial HK Value Benchmark, a rigorous tool for evaluating model alignment with local ethical and legal stand-ards under challenging conditions. By documenting these achievements, the paper provides not only a technological artifact but also a replicable blueprint for developing advanced, regionally focused AI systems deeply rooted in their local identities.</li>
</ul>

<h3>Title: AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air</h3>
<ul>
<li><strong>Authors: </strong>Shiyi Yang, Xiaoxue Yu, Rongpeng Li, Jianhang Zhu, Zhifeng Zhao, Honggang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11515">https://arxiv.org/abs/2507.11515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11515">https://arxiv.org/pdf/2507.11515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11515]] AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air(https://arxiv.org/abs/2507.11515)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Operating Large Language Models (LLMs) on edge devices is increasingly challenged by limited communication bandwidth and strained computational and memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable. Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ fixed or heuristic rank configurations, and the subsequent over-the-air transmission of all LoRA parameters could be rather inefficient. To address this limitation, we develop AirLLM, a hierarchical diffusion policy framework for communication-aware LoRA adaptation. Specifically, AirLLM models the rank configuration as a structured action vector that spans all LoRA-inserted projections. To solve the underlying high-dimensional sequential decision-making problem, a Proximal Policy Optimization (PPO) agent generates coarse-grained decisions by jointly observing wireless states and linguistic complexity, which are then refined via Denoising Diffusion Implicit Models (DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The two modules are optimized alternatively, with the DDIM trained under the Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards. Experiments under varying signal-to-noise ratios demonstrate that AirLLM consistently enhances fine-tuning performance while significantly reducing transmission costs, highlighting the effectiveness of reinforcement-driven, diffusion-refined rank adaptation for scalable and efficient remote fine-tuning over the air.</li>
</ul>

<h3>Title: CATVis: Context-Aware Thought Visualization</h3>
<ul>
<li><strong>Authors: </strong>Tariq Mehmood, Hamza Ahmad, Muhammad Haroon Shakeel, Murtaza Taj</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11522">https://arxiv.org/abs/2507.11522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11522">https://arxiv.org/pdf/2507.11522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11522]] CATVis: Context-Aware Thought Visualization(https://arxiv.org/abs/2507.11522)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>EEG-based brain-computer interfaces (BCIs) have shown promise in various applications, such as motor imagery and cognitive state monitoring. However, decoding visual representations from EEG signals remains a significant challenge due to their complex and noisy nature. We thus propose a novel 5-stage framework for decoding visual representations from EEG signals: (1) an EEG encoder for concept classification, (2) cross-modal alignment of EEG and text embeddings in CLIP feature space, (3) caption refinement via re-ranking, (4) weighted interpolation of concept and caption embeddings for richer semantics, and (5) image generation using a pre-trained Stable Diffusion model. We enable context-aware EEG-to-image generation through cross-modal alignment and re-ranking. Experimental results demonstrate that our method generates high-quality images aligned with visual stimuli, outperforming SOTA approaches by 13.43% in Classification Accuracy, 15.21% in Generation Accuracy and reducing Fr√©chet Inception Distance by 36.61%, indicating superior semantic alignment and image quality.</li>
</ul>

<h3>Title: Langevin Flows for Modeling Neural Latent Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Yue Song, T. Anderson Keller, Yisong Yue, Pietro Perona, Max Welling</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11531">https://arxiv.org/abs/2507.11531</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11531">https://arxiv.org/pdf/2507.11531</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11531]] Langevin Flows for Modeling Neural Latent Dynamics(https://arxiv.org/abs/2507.11531)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural populations exhibit latent dynamical structures that drive time-evolving spiking activities, motivating the search for models that capture both intrinsic network dynamics and external unobserved influences. In this work, we introduce LangevinFlow, a sequential Variational Auto-Encoder where the time evolution of latent variables is governed by the underdamped Langevin equation. Our approach incorporates physical priors -- such as inertia, damping, a learned potential function, and stochastic forces -- to represent both autonomous and non-autonomous processes in neural systems. Crucially, the potential function is parameterized as a network of locally coupled oscillators, biasing the model toward oscillatory and flow-like behaviors observed in biological neural populations. Our model features a recurrent encoder, a one-layer Transformer decoder, and Langevin dynamics in the latent space. Empirically, our method outperforms state-of-the-art baselines on synthetic neural populations generated by a Lorenz attractor, closely matching ground-truth firing rates. On the Neural Latents Benchmark (NLB), the model achieves superior held-out neuron likelihoods (bits per spike) and forward prediction accuracy across four challenging datasets. It also matches or surpasses alternative methods in decoding behavioral metrics such as hand velocity. Overall, this work introduces a flexible, physics-inspired, high-performing framework for modeling complex neural population dynamics and their unobserved influences.</li>
</ul>

<h3>Title: Streaming 4D Visual Geometry Transformer</h3>
<ul>
<li><strong>Authors: </strong>Dong Zhuo, Wenzhao Zheng, Jiahe Guo, Yuqi Wu, Jie Zhou, Jiwen Lu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11539">https://arxiv.org/abs/2507.11539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11539">https://arxiv.org/pdf/2507.11539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11539]] Streaming 4D Visual Geometry Transformer(https://arxiv.org/abs/2507.11539)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Perceiving and reconstructing 4D spatial-temporal geometry from videos is a fundamental yet challenging computer vision task. To facilitate interactive and real-time applications, we propose a streaming 4D visual geometry transformer that shares a similar philosophy with autoregressive large language models. We explore a simple and efficient design and employ a causal transformer architecture to process the input sequence in an online manner. We use temporal causal attention and cache the historical keys and values as implicit memory to enable efficient streaming long-term 4D reconstruction. This design can handle real-time 4D reconstruction by incrementally integrating historical information while maintaining high-quality spatial consistency. For efficient training, we propose to distill knowledge from the dense bidirectional visual geometry grounded transformer (VGGT) to our causal model. For inference, our model supports the migration of optimized efficient attention operator (e.g., FlashAttention) from the field of large language models. Extensive experiments on various 4D geometry perception benchmarks demonstrate that our model increases the inference speed in online scenarios while maintaining competitive performance, paving the way for scalable and interactive 4D vision systems. Code is available at: this https URL.</li>
</ul>

<h3>Title: Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation</h3>
<ul>
<li><strong>Authors: </strong>Zhen Xu, Hongyu Zhou, Sida Peng, Haotong Lin, Haoyu Guo, Jiahao Shao, Peishan Yang, Qinglin Yang, Sheng Miao, Xingyi He, Yifan Wang, Yue Wang, Ruizhen Hu, Yiyi Liao, Xiaowei Zhou, Hujun Bao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.11540">https://arxiv.org/abs/2507.11540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.11540">https://arxiv.org/pdf/2507.11540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.11540]] Towards Depth Foundation Model: Recent Trends in Vision-Based Depth Estimation(https://arxiv.org/abs/2507.11540)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Depth estimation is a fundamental task in 3D computer vision, crucial for applications such as 3D reconstruction, free-viewpoint rendering, robotics, autonomous driving, and AR/VR technologies. Traditional methods relying on hardware sensors like LiDAR are often limited by high costs, low resolution, and environmental sensitivity, limiting their applicability in real-world scenarios. Recent advances in vision-based methods offer a promising alternative, yet they face challenges in generalization and stability due to either the low-capacity model architectures or the reliance on domain-specific and small-scale datasets. The emergence of scaling laws and foundation models in other domains has inspired the development of "depth foundation models": deep neural networks trained on large datasets with strong zero-shot generalization capabilities. This paper surveys the evolution of deep learning architectures and paradigms for depth estimation across the monocular, stereo, multi-view, and monocular video settings. We explore the potential of these models to address existing challenges and provide a comprehensive overview of large-scale datasets that can facilitate their development. By identifying key architectures and training strategies, we aim to highlight the path towards robust depth foundation models, offering insights into their future research and applications.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
