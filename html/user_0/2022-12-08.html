<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning. (arXiv:2212.03334v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03334">http://arxiv.org/abs/2212.03334</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03334] Pre-trained Encoders in Self-Supervised Learning Improve Secure and Privacy-preserving Supervised Learning](http://arxiv.org/abs/2212.03334) #secure</code></li>
<li>Summary: <p>Classifiers in supervised learning have various security and privacy issues,
e.g., 1) data poisoning attacks, backdoor attacks, and adversarial examples on
the security side as well as 2) inference attacks and the right to be forgotten
for the training data on the privacy side. Various secure and
privacy-preserving supervised learning algorithms with formal guarantees have
been proposed to address these issues. However, they suffer from various
limitations such as accuracy loss, small certified security guarantees, and/or
inefficiency. Self-supervised learning is an emerging technique to pre-train
encoders using unlabeled data. Given a pre-trained encoder as a feature
extractor, supervised learning can train a simple yet accurate classifier using
a small amount of labeled training data. In this work, we perform the first
systematic, principled measurement study to understand whether and when a
pre-trained encoder can address the limitations of secure or privacy-preserving
supervised learning algorithms. Our key findings are that a pre-trained encoder
substantially improves 1) both accuracy under no attacks and certified security
guarantees against data poisoning and backdoor attacks of state-of-the-art
secure learning algorithms (i.e., bagging and KNN), 2) certified security
guarantees of randomized smoothing against adversarial examples without
sacrificing its accuracy under no attacks, 3) accuracy of differentially
private classifiers, and 4) accuracy and/or efficiency of exact machine
unlearning.
</p></li>
</ul>

<h3>Title: Last Mile of Blockchains: RPC and Node-as-a-service. (arXiv:2212.03383v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03383">http://arxiv.org/abs/2212.03383</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03383] Last Mile of Blockchains: RPC and Node-as-a-service](http://arxiv.org/abs/2212.03383) #secure</code></li>
<li>Summary: <p>While much research focuses on different methods to secure blockchain,
information on the chain needs to be accessed by end-users to be useful. This
position paper surveys different ways that end-users may access blockchains. We
observe that between the two extremes of running a full node and fully
utilizing a trusted third-party service, many solutions regarding light nodes
are emerging. We analyze these solutions based on three basic properties of web
communication: integrity, availability and privacy. We conclude that currently,
the best way to access a blockchain while maintaining these three properties is
still to run a full node. We consider it essential that future blockchain
accessibility services should be built while considering these three
expectations.
</p></li>
</ul>

<h3>Title: Bringing the Algorithms to the Data -- Secure Distributed Medical Analytics using the Personal Health Train (PHT-meDIC). (arXiv:2212.03481v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03481">http://arxiv.org/abs/2212.03481</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03481] Bringing the Algorithms to the Data -- Secure Distributed Medical Analytics using the Personal Health Train (PHT-meDIC)](http://arxiv.org/abs/2212.03481) #secure</code></li>
<li>Summary: <p>The need for data privacy and security -- enforced through increasingly
strict data protection regulations -- renders the use of healthcare data for
machine learning difficult. In particular, the transfer of data between
different hospitals is often not permissible and thus cross-site pooling of
data not an option. The Personal Health Train (PHT) paradigm proposed within
the GO-FAIR initiative implements an 'algorithm to the data' paradigm that
ensures that distributed data can be accessed for analysis without transferring
any sensitive data. We present PHT-meDIC, a productively deployed open-source
implementation of the PHT concept. Containerization allows us to easily deploy
even complex data analysis pipelines (e.g, genomics, image analysis) across
multiple sites in a secure and scalable manner. We discuss the underlying
technological concepts, security models, and governance processes. The
implementation has been successfully applied to distributed analyses of
large-scale data, including applications of deep neural networks to medical
image data.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Artificial Intelligence Security Competition (AISC). (arXiv:2212.03412v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03412">http://arxiv.org/abs/2212.03412</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03412] Artificial Intelligence Security Competition (AISC)](http://arxiv.org/abs/2212.03412) #security</code></li>
<li>Summary: <p>The security of artificial intelligence (AI) is an important research area
towards safe, reliable, and trustworthy AI systems. To accelerate the research
on AI security, the Artificial Intelligence Security Competition (AISC) was
organized by the Zhongguancun Laboratory, China Industrial Control Systems
Cyber Emergency Response Team, Institute for Artificial Intelligence, Tsinghua
University, and RealAI as part of the Zhongguancun International Frontier
Technology Innovation Competition (https://www.zgc-aisc.com/en). The
competition consists of three tracks, including Deepfake Security Competition,
Autonomous Driving Security Competition, and Face Recognition Security
Competition. This report will introduce the competition rules of these three
tracks and the solutions of top-ranking teams in each track.
</p></li>
</ul>

<h3>Title: A Systematic Literature Review on 5G Security. (arXiv:2212.03299v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03299">http://arxiv.org/abs/2212.03299</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03299] A Systematic Literature Review on 5G Security](http://arxiv.org/abs/2212.03299) #security</code></li>
<li>Summary: <p>It is expected that the creation of next-generation wireless networks would
result in the availability of high-speed and low-latency connectivity for every
part of our life. As a result, it is important that the network is secure. The
network's security environment has grown more complicated as a result of the
growing number of devices and the diversity of services that 5G will provide.
This is why it is important that the development of effective security
solutions is carried out early. Our findings of this review have revealed the
various directions that will be pursued in the development of next-generation
wireless networks. Some of these include the use of Artificial Intelligence and
Software Defined Mobile Networks. The threat environment for 5G networks,
security weaknesses in the new technology paradigms that 5G will embrace, and
provided solutions presented in the key studies in the field of 5G cyber
security are all described in this systematic literature review for prospective
researchers. Future research directions to protect wireless networks beyond 5G
are also covered.
</p></li>
</ul>

<h3>Title: Systematic review of automatic translation of high-level security policy into firewall rules. (arXiv:2212.03645v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03645">http://arxiv.org/abs/2212.03645</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03645] Systematic review of automatic translation of high-level security policy into firewall rules](http://arxiv.org/abs/2212.03645) #security</code></li>
<li>Summary: <p>Firewalls are security devices that perform network traffic filtering. They
are ubiquitous in the industry and are a common method used to enforce
organizational security policy. Security policy is specified on a high level of
abstraction, with statements such as "web browsing is allowed only on
workstations inside the office network", and needs to be translated into
low-level firewall rules to be enforceable. There has been a lot of work
regarding optimization, analysis and platform independence of firewall rules,
but an area that has seen much less success is automatic translation of
high-level security policies into firewall rules. In addition to improving
rules' readability, such translation would make it easier to detect errors.This
paper surveys of over twenty papers that aim to generate firewall rules
according to a security policy specified on a higher level of abstraction. It
also presents an overview of similar features in modern firewall systems. Most
approaches define specialized domain languages that get compiled into firewall
rule sets, with some of them relying on formal specification, ontology, or
graphical models. The approaches' have improved over time, but there are still
many drawbacks that need to be solved before wider application.
</p></li>
</ul>

<h3>Title: RADAR: Effective Network-based Malware Detection based on the MITRE ATT&amp;CK Framework. (arXiv:2212.03793v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03793">http://arxiv.org/abs/2212.03793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03793] RADAR: Effective Network-based Malware Detection based on the MITRE ATT&amp;CK Framework](http://arxiv.org/abs/2212.03793) #security</code></li>
<li>Summary: <p>MITRE ATT&amp;CK is a widespread ontology that specifies tactics, techniques, and
procedures (TTPs) typical of malware behaviour, making it possible to exploit
such TTPs for malware identification. However, this is far from being an easy
task given that benign usage of software can also match some of these TTPs. In
this paper, we present RADAR, a system that can identify malicious behaviour in
network traffic in two stages: first, RADAR extracts MITRE ATT&amp;CK TTPs from
arbitrary network traffic captures, and, secondly, it deploys decision trees to
differentiate between malicious and benign uses of the detected TTPs. In order
to evaluate RADAR, we created a dataset comprising of 2,286,907 malicious and
benign samples, for a total of 84,792,452 network flows. The experimental
analysis confirms that RADAR is able to $(i)$ match samples to multiple
different TTPs, and $(ii)$ effectively detect malware with an AUC score of
0.868. Beside being effective, RADAR is also highly configurable,
interpretable, privacy preserving, efficient and can be easily integrated with
existing security infrastructure to complement their capabilities.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: A Study on Extracting Named Entities from Fine-tuned vs. Differentially Private Fine-tuned BERT Models. (arXiv:2212.03749v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03749">http://arxiv.org/abs/2212.03749</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03749] A Study on Extracting Named Entities from Fine-tuned vs](http://arxiv.org/abs/2212.03749) #privacy</code></li>
<li>Summary: <p>Privacy preserving deep learning is an emerging field in machine learning
that aims to mitigate the privacy risks in the use of deep neural networks. One
such risk is training data extraction from language models that have been
trained on datasets , which contain personal and privacy sensitive information.
In our study, we investigate the extent of named entity memorization in
fine-tuned BERT models. We use single-label text classification as
representative downstream task and employ three different fine-tuning setups in
our experiments, including one with Differentially Privacy (DP). We create a
large number of text samples from the fine-tuned BERT models utilizing a custom
sequential sampling strategy with two prompting strategies. We search in these
samples for named entities and check if they are also present in the
fine-tuning datasets. We experiment with two benchmark datasets in the domains
of emails and blogs. We show that the application of DP has a huge effect on
the text generation capabilities of BERT. Furthermore, we show that a
fine-tuned BERT does not generate more named entities entities specific to the
fine-tuning dataset than a BERT model that is pre-trained only. This suggests
that BERT is unlikely to emit personal or privacy sensitive named entities.
Overall, our results are important to understand to what extent BERT-based
services are prone to training data extraction attacks.
</p></li>
</ul>

<h3>Title: Privacy protection and service evaluation methods for location-based services in edge computing environments. (arXiv:2212.03417v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03417">http://arxiv.org/abs/2212.03417</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03417] Privacy protection and service evaluation methods for location-based services in edge computing environments](http://arxiv.org/abs/2212.03417) #privacy</code></li>
<li>Summary: <p>This paper proposes a privacy protection and evaluation method for location
services based on edge computing environment. By constructing the site service
data protection and system evaluation system in the edge computing environment,
based on the existing user privacy protection work, the data processing module
and service evaluation module are constructed, and the evaluation algorithm is
designed. NPE evaluation model and POE evaluation model are designed according
to relevant research recommended by IPE. Specifically, in the NPE evaluation
model, we regard each user's decision as a group of factors, and propose a
method to integrate learning factors. In the poe evaluation model, users'
hidden intentions for the next action are understood by unifying metadata
information, two time contexts and other different factors. The experiment
verifies the effectiveness and feasibility of this method.
</p></li>
</ul>

<h3>Title: Towards Fleet-wide Sharing of Wind Turbine Condition Information through Privacy-preserving Federated Learning. (arXiv:2212.03529v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03529">http://arxiv.org/abs/2212.03529</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03529] Towards Fleet-wide Sharing of Wind Turbine Condition Information through Privacy-preserving Federated Learning](http://arxiv.org/abs/2212.03529) #privacy</code></li>
<li>Summary: <p>Terabytes of data are collected every day by wind turbine manufacturers from
their fleets. The data contain valuable real-time information for turbine
health diagnostics and performance monitoring, for predicting rare failures and
the remaining service life of critical parts. And yet, this wealth of data from
wind turbine fleets remains inaccessible to operators, utility companies, and
researchers as manufacturing companies prefer the privacy of their fleets'
turbine data for business strategic reasons. The lack of data access impedes
the exploitation of opportunities, such as improving data-driven turbine
operation and maintenance strategies and reducing downtimes. We present a
distributed federated machine learning approach that leaves the data on the
wind turbines to preserve the data privacy, as desired by manufacturers, while
still enabling fleet-wide learning on those local data. We demonstrate in a
case study that wind turbines which are scarce in representative training data
benefit from more accurate fault detection models with federated learning,
while no turbine experiences a loss in model performance by participating in
the federated learning process. When comparing conventional and federated
training processes, the average model training time rises significantly by a
factor of 7 in the federated training due to increased communication and
overhead operations. Thus, model training times might constitute an impediment
that needs to be further explored and alleviated in federated learning
applications, especially for large wind turbine fleets.
</p></li>
</ul>

<h3>Title: Not Your Average App: A Large-scale Privacy Analysis of Android Browsers. (arXiv:2212.03615v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03615">http://arxiv.org/abs/2212.03615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03615] Not Your Average App: A Large-scale Privacy Analysis of Android Browsers](http://arxiv.org/abs/2212.03615) #privacy</code></li>
<li>Summary: <p>The transparency and privacy behavior of mobile browsers has remained widely
unexplored by the research community. In fact, as opposed to regular Android
apps, mobile browsers may present contradicting privacy behaviors. On the one
end, they can have access to (and can expose) a unique combination of sensitive
user data, from users' browsing history to permission-protected personally
identifiable information (PII) such as unique identifiers and geolocation.
However, on the other end, they also are in a unique position to protect users'
privacy by limiting data sharing with other parties by implementing ad-blocking
features. In this paper, we perform a comparative and empirical analysis on how
hundreds of Android web browsers protect or expose user data during browsing
sessions. To this end, we collect the largest dataset of Android browsers to
date, from the Google Play Store and four Chinese app stores. Then, we
developed a novel analysis pipeline that combines static and dynamic analysis
methods to find a wide range of privacy-enhancing (e.g., ad-blocking) and
privacy-harming behaviors (e.g., sending browsing histories to third parties,
not validating TLS certificates, and exposing PII -- including non-resettable
identifiers -- to third parties) across browsers. We find that various popular
apps on both Google Play and Chinese stores have these privacy-harming
behaviors, including apps that claim to be privacy-enhancing in their
descriptions. Overall, our study not only provides new insights into important
yet overlooked considerations for browsers' adoption and transparency, but also
that automatic app analysis systems (e.g., sandboxes) need context-specific
analysis to reveal such privacy behaviors.
</p></li>
</ul>

<h3>Title: Reconstructing Training Data from Model Gradient, Provably. (arXiv:2212.03714v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03714">http://arxiv.org/abs/2212.03714</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03714] Reconstructing Training Data from Model Gradient, Provably](http://arxiv.org/abs/2212.03714) #privacy</code></li>
<li>Summary: <p>Understanding when and how much a model gradient leaks information about the
training sample is an important question in privacy. In this paper, we present
a surprising result: even without training or memorizing the data, we can fully
reconstruct the training samples from a single gradient query at a randomly
chosen parameter value. We prove the identifiability of the training data under
mild conditions: with shallow or deep neural networks and a wide range of
activation functions. We also present a statistically and computationally
efficient algorithm based on tensor decomposition to reconstruct the training
data. As a provable attack that reveals sensitive training data, our findings
suggest potential severe threats to privacy, especially in federated learning.
</p></li>
</ul>

<h3>Title: Achieving Transparency in Distributed Machine Learning with Explainable Data Collaboration. (arXiv:2212.03373v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03373">http://arxiv.org/abs/2212.03373</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03373] Achieving Transparency in Distributed Machine Learning with Explainable Data Collaboration](http://arxiv.org/abs/2212.03373) #privacy</code></li>
<li>Summary: <p>Transparency of Machine Learning models used for decision support in various
industries becomes essential for ensuring their ethical use. To that end,
feature attribution methods such as SHAP (SHapley Additive exPlanations) are
widely used to explain the predictions of black-box machine learning models to
customers and developers. However, a parallel trend has been to train machine
learning models in collaboration with other data holders without accessing
their data. Such models, trained over horizontally or vertically partitioned
data, present a challenge for explainable AI because the explaining party may
have a biased view of background data or a partial view of the feature space.
As a result, explanations obtained from different participants of distributed
machine learning might not be consistent with one another, undermining trust in
the product. This paper presents an Explainable Data Collaboration Framework
based on a model-agnostic additive feature attribution algorithm (KernelSHAP)
and Data Collaboration method of privacy-preserving distributed machine
learning. In particular, we present three algorithms for different scenarios of
explainability in Data Collaboration and verify their consistency with
experiments on open-access datasets. Our results demonstrated a significant (by
at least a factor of 1.75) decrease in feature attribution discrepancies among
the users of distributed machine learning.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Face Presentation Attack Detection. (arXiv:2212.03680v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03680">http://arxiv.org/abs/2212.03680</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03680] Face Presentation Attack Detection](http://arxiv.org/abs/2212.03680) #attack</code></li>
<li>Summary: <p>Face recognition technology has been widely used in daily interactive
applications such as checking-in and mobile payment due to its convenience and
high accuracy. However, its vulnerability to presentation attacks (PAs) limits
its reliable use in ultra-secure applicational scenarios. A presentation attack
is first defined in ISO standard as: a presentation to the biometric data
capture subsystem with the goal of interfering with the operation of the
biometric system. Specifically, PAs range from simple 2D print, replay and more
sophisticated 3D masks and partial masks. To defend the face recognition
systems against PAs, both academia and industry have paid extensive attention
to developing face presentation attack detection (PAD) technology (or namely
`face anti-spoofing (FAS)').
</p></li>
</ul>

<h3>Title: COVID-bit: Keep a Distance of (at least) 2m From My Air-Gap Computer!. (arXiv:2212.03520v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03520">http://arxiv.org/abs/2212.03520</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03520] COVID-bit: Keep a Distance of (at least) 2m From My Air-Gap Computer!](http://arxiv.org/abs/2212.03520) #attack</code></li>
<li>Summary: <p>Air-gapped systems are isolated from the Internet due to the sensitive
information they handle. This paper presents COVID-bit, a new COVert channel
attack that leaks sensitive information over the air from highly isolated
systems. The information emanates from the air-gapped computer over the air to
a distance of 2m and more and can be picked up by a nearby insider or spy with
a mobile phone or laptop. Malware on an air-gapped computer can generate radio
waves by executing crafted code on the target system. The malicious code
exploits the dynamic power consumption of modern computers and manipulates the
momentary loads on CPU cores. This technique allows the malware to control the
computer's internal utilization and generate low-frequency electromagnetic
radiation in the 0 - 60 kHz band. Sensitive information (e.g., files,
encryption keys, biometric data, and keylogging) can be modulated over the
emanated signals and received by a nearby mobile phone at a max speed of 1000
bits/sec. We show that a smartphone or laptop with a small \$1 antenna carried
by a malicious insider or visitor can be used as a covert receiver. Notably,
the attack is highly evasive since it executes from an ordinary user-level
process, does not require root privileges, and is effective even within a
Virtual Machine (VM). We discuss the attack model and provide technical
details. We implement air-gap transmission of texts and files, and present
signal generation and data modulation. We test the covert channel and show
evaluation results. Finally, we present a set of countermeasures to this
air-gap attack.
</p></li>
</ul>

<h3>Title: A Temporal Graph Neural Network for Cyber Attack Detection and Localization in Smart Grids. (arXiv:2212.03390v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03390">http://arxiv.org/abs/2212.03390</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03390] A Temporal Graph Neural Network for Cyber Attack Detection and Localization in Smart Grids](http://arxiv.org/abs/2212.03390) #attack</code></li>
<li>Summary: <p>This paper presents a Temporal Graph Neural Network (TGNN) framework for
detection and localization of false data injection and ramp attacks on the
system state in smart grids. Capturing the topological information of the
system through the GNN framework along with the state measurements can improve
the performance of the detection mechanism. The problem is formulated as a
classification problem through a GNN with message passing mechanism to identify
abnormal measurements. The residual block used in the aggregation process of
message passing and the gated recurrent unit can lead to improved computational
time and performance. The performance of the proposed model has been evaluated
through extensive simulations of power system states and attack scenarios
showing promising performance. The sensitivity of the model to intensity and
location of the attacks and model's detection delay versus detection accuracy
have also been evaluated.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Supervised Tractogram Filtering using Geometric Deep Learning. (arXiv:2212.03300v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03300">http://arxiv.org/abs/2212.03300</a></li>
<li>Code URL: <a href="https://github.com/fbk-nilab/verifyber">https://github.com/fbk-nilab/verifyber</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03300] Supervised Tractogram Filtering using Geometric Deep Learning](http://arxiv.org/abs/2212.03300) #robust</code></li>
<li>Summary: <p>A tractogram is a virtual representation of the brain white matter. It is
composed of millions of virtual fibers, encoded as 3D polylines, which
approximate the white matter axonal pathways. To date, tractograms are the most
accurate white matter representation and thus are used for tasks like
presurgical planning and investigations of neuroplasticity, brain disorders, or
brain networks. However, it is a well-known issue that a large portion of
tractogram fibers is not anatomically plausible and can be considered artifacts
of the tracking procedure. With Verifyber, we tackle the problem of filtering
out such non-plausible fibers using a novel fully-supervised learning approach.
Differently from other approaches based on signal reconstruction and/or brain
topology regularization, we guide our method with the existing anatomical
knowledge of the white matter. Using tractograms annotated according to
anatomical principles, we train our model, Verifyber, to classify fibers as
either anatomically plausible or non-plausible. The proposed Verifyber model is
an original Geometric Deep Learning method that can deal with variable size
fibers, while being invariant to fiber orientation. Our model considers each
fiber as a graph of points, and by learning features of the edges between
consecutive points via the proposed sequence Edge Convolution, it can capture
the underlying anatomical properties. The output filtering results highly
accurate and robust across an extensive set of experiments, and fast; with a
12GB GPU, filtering a tractogram of 1M fibers requires less than a minute.
Verifyber implementation and trained models are available at
https://github.com/FBK-NILab/verifyber.
</p></li>
</ul>

<h3>Title: DroneAttention: Sparse Weighted Temporal Attention for Drone-Camera Based Activity Recognition. (arXiv:2212.03384v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03384">http://arxiv.org/abs/2212.03384</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03384] DroneAttention: Sparse Weighted Temporal Attention for Drone-Camera Based Activity Recognition](http://arxiv.org/abs/2212.03384) #robust</code></li>
<li>Summary: <p>Human activity recognition (HAR) using drone-mounted cameras has attracted
considerable interest from the computer vision research community in recent
years. A robust and efficient HAR system has a pivotal role in fields like
video surveillance, crowd behavior analysis, sports analysis, and
human-computer interaction. What makes it challenging are the complex poses,
understanding different viewpoints, and the environmental scenarios where the
action is taking place. To address such complexities, in this paper, we propose
a novel Sparse Weighted Temporal Attention (SWTA) module to utilize sparsely
sampled video frames for obtaining global weighted temporal attention. The
proposed SWTA is comprised of two parts. First, temporal segment network that
sparsely samples a given set of frames. Second, weighted temporal attention,
which incorporates a fusion of attention maps derived from optical flow, with
raw RGB images. This is followed by a basenet network, which comprises a
convolutional neural network (CNN) module along with fully connected layers
that provide us with activity recognition. The SWTA network can be used as a
plug-in module to the existing deep CNN architectures, for optimizing them to
learn temporal information by eliminating the need for a separate temporal
stream. It has been evaluated on three publicly available benchmark datasets,
namely Okutama, MOD20, and Drone-Action. The proposed model has received an
accuracy of 72.76%, 92.56%, and 78.86% on the respective datasets thereby
surpassing the previous state-of-the-art performances by a margin of 25.26%,
18.56%, and 2.94%, respectively.
</p></li>
</ul>

<h3>Title: PADDLES: Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels. (arXiv:2212.03462v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03462">http://arxiv.org/abs/2212.03462</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03462] PADDLES: Phase-Amplitude Spectrum Disentangled Early Stopping for Learning with Noisy Labels](http://arxiv.org/abs/2212.03462) #robust</code></li>
<li>Summary: <p>Convolutional Neural Networks (CNNs) have demonstrated superiority in
learning patterns, but are sensitive to label noises and may overfit noisy
labels during training. The early stopping strategy averts updating CNNs during
the early training phase and is widely employed in the presence of noisy
labels. Motivated by biological findings that the amplitude spectrum (AS) and
phase spectrum (PS) in the frequency domain play different roles in the
animal's vision system, we observe that PS, which captures more semantic
information, can increase the robustness of DNNs to label noise, more so than
AS can. We thus propose early stops at different times for AS and PS by
disentangling the features of some layer(s) into AS and PS using Discrete
Fourier Transform (DFT) during training. Our proposed Phase-AmplituDe
DisentangLed Early Stopping (PADDLES) method is shown to be effective on both
synthetic and real-world label-noise datasets. PADDLES outperforms other early
stopping methods and obtains state-of-the-art performance.
</p></li>
</ul>

<h3>Title: BoxPolyp:Boost Generalized Polyp Segmentation Using Extra Coarse Bounding Box Annotations. (arXiv:2212.03498v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03498">http://arxiv.org/abs/2212.03498</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03498] BoxPolyp:Boost Generalized Polyp Segmentation Using Extra Coarse Bounding Box Annotations](http://arxiv.org/abs/2212.03498) #robust</code></li>
<li>Summary: <p>Accurate polyp segmentation is of great importance for colorectal cancer
diagnosis and treatment. However, due to the high cost of producing accurate
mask annotations, existing polyp segmentation methods suffer from severe data
shortage and impaired model generalization. Reversely, coarse polyp bounding
box annotations are more accessible. Thus, in this paper, we propose a boosted
BoxPolyp model to make full use of both accurate mask and extra coarse box
annotations. In practice, box annotations are applied to alleviate the
over-fitting issue of previous polyp segmentation models, which generate
fine-grained polyp area through the iterative boosted segmentation model. To
achieve this goal, a fusion filter sampling (FFS) module is firstly proposed to
generate pixel-wise pseudo labels from box annotations with less noise, leading
to significant performance improvements. Besides, considering the appearance
consistency of the same polyp, an image consistency (IC) loss is designed. Such
IC loss explicitly narrows the distance between features extracted by two
different networks, which improves the robustness of the model. Note that our
BoxPolyp is a plug-and-play model, which can be merged into any appealing
backbone. Quantitative and qualitative experimental results on five challenging
benchmarks confirm that our proposed model outperforms previous
state-of-the-art methods by a large margin.
</p></li>
</ul>

<h3>Title: Cyclically Disentangled Feature Translation for Face Anti-spoofing. (arXiv:2212.03651v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03651">http://arxiv.org/abs/2212.03651</a></li>
<li>Code URL: <a href="https://github.com/vis-face/cdftn">https://github.com/vis-face/cdftn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03651] Cyclically Disentangled Feature Translation for Face Anti-spoofing](http://arxiv.org/abs/2212.03651) #robust</code></li>
<li>Summary: <p>Current domain adaptation methods for face anti-spoofing leverage labeled
source domain data and unlabeled target domain data to obtain a promising
generalizable decision boundary. However, it is usually difficult for these
methods to achieve a perfect domain-invariant liveness feature disentanglement,
which may degrade the final classification performance by domain differences in
illumination, face category, spoof type, etc. In this work, we tackle
cross-scenario face anti-spoofing by proposing a novel domain adaptation method
called cyclically disentangled feature translation network (CDFTN).
Specifically, CDFTN generates pseudo-labeled samples that possess: 1) source
domain-invariant liveness features and 2) target domain-specific content
features, which are disentangled through domain adversarial training. A robust
classifier is trained based on the synthetic pseudo-labeled images under the
supervision of source domain labels. We further extend CDFTN for multi-target
domain adaptation by leveraging data from more unlabeled target domains.
Extensive experiments on several public datasets demonstrate that our proposed
approach significantly outperforms the state of the art.
</p></li>
</ul>

<h3>Title: Face Forgery Detection Based on Facial Region Displacement Trajectory Series. (arXiv:2212.03678v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03678">http://arxiv.org/abs/2212.03678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03678] Face Forgery Detection Based on Facial Region Displacement Trajectory Series](http://arxiv.org/abs/2212.03678) #robust</code></li>
<li>Summary: <p>Deep-learning-based technologies such as deepfakes ones have been attracting
widespread attention in both society and academia, particularly ones used to
synthesize forged face images. These automatic and professional-skill-free face
manipulation technologies can be used to replace the face in an original image
or video with any target object while maintaining the expression and demeanor.
Since human faces are closely related to identity characteristics, maliciously
disseminated identity manipulated videos could trigger a crisis of public trust
in the media and could even have serious political, social, and legal
implications. To effectively detect manipulated videos, we focus on the
position offset in the face blending process, resulting from the forced affine
transformation of the normalized forged face. We introduce a method for
detecting manipulated videos that is based on the trajectory of the facial
region displacement. Specifically, we develop a virtual-anchor-based method for
extracting the facial trajectory, which can robustly represent displacement
information. This information was used to construct a network for exposing
multidimensional artifacts in the trajectory sequences of manipulated videos
that is based on dual-stream spatial-temporal graph attention and a gated
recurrent unit backbone. Testing of our method on various manipulation datasets
demonstrated that its accuracy and generalization ability is competitive with
that of the leading detection methods.
</p></li>
</ul>

<h3>Title: iQuery: Instruments as Queries for Audio-Visual Sound Separation. (arXiv:2212.03814v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03814">http://arxiv.org/abs/2212.03814</a></li>
<li>Code URL: <a href="https://github.com/jiabenchen/iquery">https://github.com/jiabenchen/iquery</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03814] iQuery: Instruments as Queries for Audio-Visual Sound Separation](http://arxiv.org/abs/2212.03814) #robust</code></li>
<li>Summary: <p>Current audio-visual separation methods share a standard architecture design
where an audio encoder-decoder network is fused with visual encoding features
at the encoder bottleneck. This design confounds the learning of multi-modal
feature encoding with robust sound decoding for audio separation. To generalize
to a new instrument: one must finetune the entire visual and audio network for
all musical instruments. We re-formulate visual-sound separation task and
propose Instrument as Query (iQuery) with a flexible query expansion mechanism.
Our approach ensures cross-modal consistency and cross-instrument
disentanglement. We utilize "visually named" queries to initiate the learning
of audio queries and use cross-modal attention to remove potential sound source
interference at the estimated waveforms. To generalize to a new instrument or
event class, drawing inspiration from the text-prompt design, we insert an
additional query as an audio prompt while freezing the attention mechanism.
Experimental results on three benchmarks demonstrate that our iQuery improves
audio-visual sound source separation performance.
</p></li>
</ul>

<h3>Title: Point Cloud Registration of non-rigid objects in sparse 3D Scans with applications in Mixed Reality. (arXiv:2212.03856v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03856">http://arxiv.org/abs/2212.03856</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03856] Point Cloud Registration of non-rigid objects in sparse 3D Scans with applications in Mixed Reality](http://arxiv.org/abs/2212.03856) #robust</code></li>
<li>Summary: <p>Point Cloud Registration is the problem of aligning the corresponding points
of two 3D point clouds referring to the same object. The challenges include
dealing with noise and partial match of real-world 3D scans. For non-rigid
objects, there is an additional challenge of accounting for deformations in the
object shape that happen to the object in between the two 3D scans. In this
project, we study the problem of non-rigid point cloud registration for use
cases in the Augmented/Mixed Reality domain. We focus our attention on a
special class of non-rigid deformations that happen in rigid objects with parts
that move relative to one another about joints, for example, robots with hands
and machines with hinges. We propose an efficient and robust point-cloud
registration workflow for such objects and evaluate it on real-world data
collected using Microsoft Hololens 2, a leading Mixed Reality Platform.
</p></li>
</ul>

<h3>Title: Counterfactual reasoning: Do language models need world knowledge for causal understanding?. (arXiv:2212.03278v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03278">http://arxiv.org/abs/2212.03278</a></li>
<li>Code URL: <a href="https://github.com/goldengua/counterfactual_inference_lm">https://github.com/goldengua/counterfactual_inference_lm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03278] Counterfactual reasoning: Do language models need world knowledge for causal understanding?](http://arxiv.org/abs/2212.03278) #robust</code></li>
<li>Summary: <p>Current pre-trained language models have enabled remarkable improvements in
downstream tasks, but it remains difficult to distinguish effects of
statistical correlation from more systematic logical reasoning grounded on
understanding of the real world. In this paper we tease these factors apart by
leveraging counterfactual conditionals, which force language models to predict
unusual consequences based on hypothetical propositions. We introduce a set of
tests drawn from psycholinguistic experiments, as well as larger-scale
controlled datasets, to probe counterfactual predictions from a variety of
popular pre-trained language models. We find that models are consistently able
to override real-world knowledge in counterfactual scenarios, and that this
effect is more robust in case of stronger baseline world knowledge -- however,
we also find that for most models this effect appears largely to be driven by
simple lexical cues. When we mitigate effects of both world knowledge and
lexical cues to test knowledge of linguistic nuances of counterfactuals, we
find that only GPT-3 shows sensitivity to these nuances, though this
sensitivity is also non-trivially impacted by lexical associative factors.
</p></li>
</ul>

<h3>Title: Transformer-Based Named Entity Recognition for French Using Adversarial Adaptation to Similar Domain Corpora. (arXiv:2212.03692v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03692">http://arxiv.org/abs/2212.03692</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03692] Transformer-Based Named Entity Recognition for French Using Adversarial Adaptation to Similar Domain Corpora](http://arxiv.org/abs/2212.03692) #robust</code></li>
<li>Summary: <p>Named Entity Recognition (NER) involves the identification and classification
of named entities in unstructured text into predefined classes. NER in
languages with limited resources, like French, is still an open problem due to
the lack of large, robust, labelled datasets. In this paper, we propose a
transformer-based NER approach for French using adversarial adaptation to
similar domain or general corpora for improved feature extraction and better
generalization. We evaluate our approach on three labelled datasets and show
that our adaptation framework outperforms the corresponding non-adaptive models
for various combinations of transformer models, source datasets and target
corpora.
</p></li>
</ul>

<h3>Title: Robustness of Learning from Task Instructions. (arXiv:2212.03813v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03813">http://arxiv.org/abs/2212.03813</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03813] Robustness of Learning from Task Instructions](http://arxiv.org/abs/2212.03813) #robust</code></li>
<li>Summary: <p>Traditional supervised learning mostly works on individual tasks and requires
training on a large set of task-specific examples. This paradigm seriously
hinders the development of task generalization since preparing a task-specific
example set is costly. To build a system that can quickly and easily generalize
to new tasks, task instructions have been adopted as an emerging trend of
supervision recently. These instructions give the model the definition of the
task and allow the model to output the appropriate answer based on the
instructions and inputs. However, task instructions are often expressed in
different forms, which can be interpreted from two threads: first, some
instructions are short sentences and are pretrained language model (PLM)
oriented, such as prompts, while other instructions are paragraphs and are
human-oriented, such as those in Amazon MTurk; second, different end-users very
likely explain the same task with instructions of different textual
expressions. A robust system for task generalization should be able to handle
any new tasks regardless of the variability of instructions.
</p></li>
</ul>

<p>However, the system robustness in dealing with instruction-driven task
generalization is still unexplored. This work investigates the system
robustness when the instructions of new tasks are (i) maliciously manipulated,
(ii) paraphrased, or (iii) from different levels of conciseness. To our
knowledge, this is the first work that systematically studies how robust a PLM
is when it is supervised by instructions with different factors of variability.
</p>

<h3>Title: Copula Conformal Prediction for Multi-step Time Series Forecasting. (arXiv:2212.03281v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03281">http://arxiv.org/abs/2212.03281</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03281] Copula Conformal Prediction for Multi-step Time Series Forecasting](http://arxiv.org/abs/2212.03281) #robust</code></li>
<li>Summary: <p>Accurate uncertainty measurement is a key step to building robust and
reliable machine learning systems. Conformal prediction is a distribution-free
uncertainty quantification algorithm popular for its ease of implementation,
statistical coverage guarantees, and versatility for underlying forecasters.
However, existing conformal prediction algorithms for time series are limited
to single-step prediction without considering the temporal dependency. In this
paper we propose a Copula Conformal Prediction algorithm for multivariate,
multi-step Time Series forecasting, CopulaCPTS. On several synthetic and
real-world multivariate time series datasets, we show that CopulaCPTS produces
more calibrated and sharp confidence intervals for multi-step prediction tasks
than existing techniques.
</p></li>
</ul>

<h3>Title: Understanding Self-Predictive Learning for Reinforcement Learning. (arXiv:2212.03319v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03319">http://arxiv.org/abs/2212.03319</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03319] Understanding Self-Predictive Learning for Reinforcement Learning](http://arxiv.org/abs/2212.03319) #robust</code></li>
<li>Summary: <p>We study the learning dynamics of self-predictive learning for reinforcement
learning, a family of algorithms that learn representations by minimizing the
prediction error of their own future latent representations. Despite its recent
empirical success, such algorithms have an apparent defect: trivial
representations (such as constants) minimize the prediction error, yet it is
obviously undesirable to converge to such solutions. Our central insight is
that careful designs of the optimization dynamics are critical to learning
meaningful representations. We identify that a faster paced optimization of the
predictor and semi-gradient updates on the representation, are crucial to
preventing the representation collapse. Then in an idealized setup, we show
self-predictive learning dynamics carries out spectral decomposition on the
state transition matrix, effectively capturing information of the transition
dynamics. Building on the theoretical insights, we propose bidirectional
self-predictive learning, a novel self-predictive algorithm that learns two
representations simultaneously. We examine the robustness of our theoretical
insights with a number of small-scale experiments and showcase the promise of
the novel representation learning algorithm with large-scale experiments.
</p></li>
</ul>

<h3>Title: General multi-fidelity surrogate models: Framework and active learning strategies for efficient rare event simulation. (arXiv:2212.03375v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03375">http://arxiv.org/abs/2212.03375</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03375] General multi-fidelity surrogate models: Framework and active learning strategies for efficient rare event simulation](http://arxiv.org/abs/2212.03375) #robust</code></li>
<li>Summary: <p>Estimating the probability of failure for complex real-world systems using
high-fidelity computational models is often prohibitively expensive, especially
when the probability is small. Exploiting low-fidelity models can make this
process more feasible, but merging information from multiple low-fidelity and
high-fidelity models poses several challenges. This paper presents a robust
multi-fidelity surrogate modeling strategy in which the multi-fidelity
surrogate is assembled using an active learning strategy using an on-the-fly
model adequacy assessment set within a subset simulation framework for
efficient reliability analysis. The multi-fidelity surrogate is assembled by
first applying a Gaussian process correction to each low-fidelity model and
assigning a model probability based on the model's local predictive accuracy
and cost. Three strategies are proposed to fuse these individual surrogates
into an overall surrogate model based on model averaging and
deterministic/stochastic model selection. The strategies also dictate which
model evaluations are necessary. No assumptions are made about the
relationships between low-fidelity models, while the high-fidelity model is
assumed to be the most accurate and most computationally expensive model.
Through two analytical and two numerical case studies, including a case study
evaluating the failure probability of Tristructural isotropic-coated (TRISO)
nuclear fuels, the algorithm is shown to be highly accurate while drastically
reducing the number of high-fidelity model calls (and hence computational
cost).
</p></li>
</ul>

<h3>Title: Phase2vec: Dynamical systems embedding with a physics-informed convolutional network. (arXiv:2212.03857v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03857">http://arxiv.org/abs/2212.03857</a></li>
<li>Code URL: <a href="https://github.com/nitzanlab/phase2vec">https://github.com/nitzanlab/phase2vec</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03857] Phase2vec: Dynamical systems embedding with a physics-informed convolutional network](http://arxiv.org/abs/2212.03857) #robust</code></li>
<li>Summary: <p>Dynamical systems are found in innumerable forms across the physical and
biological sciences, yet all these systems fall naturally into universal
equivalence classes: conservative or dissipative, stable or unstable,
compressible or incompressible. Predicting these classes from data remains an
essential open challenge in computational physics at which existing time-series
classification methods struggle. Here, we propose, \texttt{phase2vec}, an
embedding method that learns high-quality, physically-meaningful
representations of 2D dynamical systems without supervision. Our embeddings are
produced by a convolutional backbone that extracts geometric features from flow
data and minimizes a physically-informed vector field reconstruction loss. In
an auxiliary training period, embeddings are optimized so that they robustly
encode the equations of unseen data over and above the performance of a
per-equation fitting method. The trained architecture can not only predict the
equations of unseen data, but also, crucially, learns embeddings that respect
the underlying semantics of the embedded physical systems. We validate the
quality of learned embeddings investigating the extent to which physical
categories of input data can be decoded from embeddings compared to standard
blackbox classifiers and state-of-the-art time series classification
techniques. We find that our embeddings encode important physical properties of
the underlying data, including the stability of fixed points, conservation of
energy, and the incompressibility of flows, with greater fidelity than
competing methods. We finally apply our embeddings to the analysis of
meteorological data, showing we can detect climatically meaningful features.
Collectively, our results demonstrate the viability of embedding approaches for
the discovery of dynamical features in physical systems.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data. (arXiv:2212.03306v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03306">http://arxiv.org/abs/2212.03306</a></li>
<li>Code URL: <a href="https://github.com/erneternet/ernet">https://github.com/erneternet/ernet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03306] ERNet: Unsupervised Collective Extraction and Registration in Neuroimaging Data](http://arxiv.org/abs/2212.03306) #extraction</code></li>
<li>Summary: <p>Brain extraction and registration are important preprocessing steps in
neuroimaging data analysis, where the goal is to extract the brain regions from
MRI scans (i.e., extraction step) and align them with a target brain image
(i.e., registration step). Conventional research mainly focuses on developing
methods for the extraction and registration tasks separately under supervised
settings. The performance of these methods highly depends on the amount of
training samples and visual inspections performed by experts for error
correction. However, in many medical studies, collecting voxel-level labels and
conducting manual quality control in high-dimensional neuroimages (e.g., 3D
MRI) are very expensive and time-consuming. Moreover, brain extraction and
registration are highly related tasks in neuroimaging data and should be solved
collectively. In this paper, we study the problem of unsupervised collective
extraction and registration in neuroimaging data. We propose a unified
end-to-end framework, called ERNet (Extraction-Registration Network), to
jointly optimize the extraction and registration tasks, allowing feedback
between them. Specifically, we use a pair of multi-stage extraction and
registration modules to learn the extraction mask and transformation, where the
extraction network improves the extraction accuracy incrementally and the
registration network successively warps the extracted image until it is
well-aligned with the target image. Experiment results on real-world datasets
show that our proposed method can effectively improve the performance on
extraction and registration tasks in neuroimaging data. Our code and data can
be found at https://github.com/ERNetERNet/ERNet
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Partial Disentanglement with Partially-Federated GANs (PaDPaF). (arXiv:2212.03836v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03836">http://arxiv.org/abs/2212.03836</a></li>
<li>Code URL: <a href="https://github.com/zeligism/fedgan">https://github.com/zeligism/fedgan</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03836] Partial Disentanglement with Partially-Federated GANs (PaDPaF)](http://arxiv.org/abs/2212.03836) #federate</code></li>
<li>Summary: <p>Federated learning has become a popular machine learning paradigm with many
potential real-life applications, including recommendation systems, the
Internet of Things (IoT), healthcare, and self-driving cars. Though most
current applications focus on classification-based tasks, learning personalized
generative models remains largely unexplored, and their benefits in the
heterogeneous setting still need to be better understood. This work proposes a
novel architecture combining global client-agnostic and local client-specific
generative models. We show that using standard techniques for training
federated models, our proposed model achieves privacy and personalization that
is achieved by implicitly disentangling the globally-consistent representation
(i.e. content) from the client-dependent variations (i.e. style). Using such
decomposition, personalized models can generate locally unseen labels while
preserving the given style of the client and can predict the labels for all
clients with high accuracy by training a simple linear classifier on the global
content features. Furthermore, disentanglement enables other essential
applications, such as data anonymization, by sharing only content. Extensive
experimental evaluation corroborates our findings, and we also provide partial
theoretical justifications for the proposed approach.
</p></li>
</ul>

<h3>Title: MOB-FL: Mobility-Aware Federated Learning for Intelligent Connected Vehicles. (arXiv:2212.03519v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03519">http://arxiv.org/abs/2212.03519</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03519] MOB-FL: Mobility-Aware Federated Learning for Intelligent Connected Vehicles](http://arxiv.org/abs/2212.03519) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is a promising approach to enable the future Internet
of vehicles consisting of intelligent connected vehicles (ICVs) with powerful
sensing, computing and communication capabilities. We consider a base station
(BS) coordinating nearby ICVs to train a neural network in a collaborative yet
distributed manner, in order to limit data traffic and privacy leakage.
However, due to the mobility of vehicles, the connections between the BS and
ICVs are short-lived, which affects the resource utilization of ICVs, and thus,
the convergence speed of the training process. In this paper, we propose an
accelerated FL-ICV framework, by optimizing the duration of each training round
and the number of local iterations, for better convergence performance of FL.
We propose a mobility-aware optimization algorithm called MOB-FL, which aims at
maximizing the resource utilization of ICVs under short-lived wireless
connections, so as to increase the convergence speed. Simulation results based
on the beam selection and the trajectory prediction tasks verify the
effectiveness of the proposed solution.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: GLeaD: Improving GANs with A Generator-Leading Task. (arXiv:2212.03752v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03752">http://arxiv.org/abs/2212.03752</a></li>
<li>Code URL: <a href="https://github.com/ezioby/glead">https://github.com/ezioby/glead</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03752] GLeaD: Improving GANs with A Generator-Leading Task](http://arxiv.org/abs/2212.03752) #fair</code></li>
<li>Summary: <p>Generative adversarial network (GAN) is formulated as a two-player game
between a generator (G) and a discriminator (D), where D is asked to
differentiate whether an image comes from real data or is produced by G. Under
such a formulation, D plays as the rule maker and hence tends to dominate the
competition. Towards a fairer game in GANs, we propose a new paradigm for
adversarial training, which makes G assign a task to D as well. Specifically,
given an image, we expect D to extract representative features that can be
adequately decoded by G to reconstruct the input. That way, instead of learning
freely, D is urged to align with the view of G for domain classification.
Experimental results on various datasets demonstrate the substantial
superiority of our approach over the baselines. For instance, we improve the
FID of StyleGAN2 from 4.30 to 2.55 on LSUN Bedroom and from 4.04 to 2.82 on
LSUN Church. We believe that the pioneering attempt present in this work could
inspire the community with better designed generator-leading tasks for GAN
improvement.
</p></li>
</ul>

<h3>Title: Fairness and Explainability: Bridging the Gap Towards Fair Model Explanations. (arXiv:2212.03840v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03840">http://arxiv.org/abs/2212.03840</a></li>
<li>Code URL: <a href="https://github.com/yuyingzhao/fairexplanations-cfa">https://github.com/yuyingzhao/fairexplanations-cfa</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03840] Fairness and Explainability: Bridging the Gap Towards Fair Model Explanations](http://arxiv.org/abs/2212.03840) #fair</code></li>
<li>Summary: <p>While machine learning models have achieved unprecedented success in
real-world applications, they might make biased/unfair decisions for specific
demographic groups and hence result in discriminative outcomes. Although
research efforts have been devoted to measuring and mitigating bias, they
mainly study bias from the result-oriented perspective while neglecting the
bias encoded in the decision-making procedure. This results in their inability
to capture procedure-oriented bias, which therefore limits the ability to have
a fully debiasing method. Fortunately, with the rapid development of
explainable machine learning, explanations for predictions are now available to
gain insights into the procedure. In this work, we bridge the gap between
fairness and explainability by presenting a novel perspective of
procedure-oriented fairness based on explanations. We identify the
procedure-based bias by measuring the gap of explanation quality between
different groups with Ratio-based and Value-based Explanation Fairness. The new
metrics further motivate us to design an optimization objective to mitigate the
procedure-based bias where we observe that it will also mitigate bias from the
prediction. Based on our designed optimization objective, we propose a
Comprehensive Fairness Algorithm (CFA), which simultaneously fulfills multiple
objectives - improving traditional fairness, satisfying explanation fairness,
and maintaining the utility performance. Extensive experiments on real-world
datasets demonstrate the effectiveness of our proposed CFA and highlight the
importance of considering fairness from the explainability perspective. Our
code is publicly available at
https://github.com/YuyingZhao/FairExplanations-CFA .
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling. (arXiv:2212.03396v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03396">http://arxiv.org/abs/2212.03396</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03396] Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling](http://arxiv.org/abs/2212.03396) #interpretability</code></li>
<li>Summary: <p>Prototype-based interpretability methods provide intuitive explanations of
model prediction by comparing samples to a reference set of memorized exemplars
or typical representatives in terms of similarity. In the field of sequential
data modeling, similarity calculations of prototypes are usually based on
encoded representation vectors. However, due to highly recursive functions,
there is usually a non-negligible disparity between the prototype-based
explanations and the original input. In this work, we propose a Self-Explaining
Selective Model (SESM) that uses a linear combination of prototypical concepts
to explain its own predictions. The model employs the idea of case-based
reasoning by selecting sub-sequences of the input that mostly activate
different concepts as prototypical parts, which users can compare to
sub-sequences selected from different example inputs to understand model
decisions. For better interpretability, we design multiple constraints
including diversity, stability, and locality as training objectives. Extensive
experiments in different domains demonstrate that our method exhibits promising
interpretability and competitive accuracy.
</p></li>
</ul>

<h3>Title: Truthful Meta-Explanations for Local Interpretability of Machine Learning Models. (arXiv:2212.03513v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03513">http://arxiv.org/abs/2212.03513</a></li>
<li>Code URL: <a href="https://github.com/iamollas/tmx-truthfulmetaexplanations">https://github.com/iamollas/tmx-truthfulmetaexplanations</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03513] Truthful Meta-Explanations for Local Interpretability of Machine Learning Models](http://arxiv.org/abs/2212.03513) #interpretability</code></li>
<li>Summary: <p>Automated Machine Learning-based systems' integration into a wide range of
tasks has expanded as a result of their performance and speed. Although there
are numerous advantages to employing ML-based systems, if they are not
interpretable, they should not be used in critical, high-risk applications
where human lives are at risk. To address this issue, researchers and
businesses have been focusing on finding ways to improve the interpretability
of complex ML systems, and several such methods have been developed. Indeed,
there are so many developed techniques that it is difficult for practitioners
to choose the best among them for their applications, even when using
evaluation metrics. As a result, the demand for a selection tool, a
meta-explanation technique based on a high-quality evaluation metric, is
apparent. In this paper, we present a local meta-explanation technique which
builds on top of the truthfulness metric, which is a faithfulness-based metric.
We demonstrate the effectiveness of both the technique and the metric by
concretely defining all the concepts and through experimentation.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Neural Cell Video Synthesis via Optical-Flow Diffusion. (arXiv:2212.03250v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03250">http://arxiv.org/abs/2212.03250</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03250] Neural Cell Video Synthesis via Optical-Flow Diffusion](http://arxiv.org/abs/2212.03250) #diffusion</code></li>
<li>Summary: <p>The biomedical imaging world is notorious for working with small amounts of
data, frustrating state-of-the-art efforts in the computer vision and deep
learning worlds. With large datasets, it is easier to make progress we have
seen from the natural image distribution. It is the same with microscopy videos
of neuron cells moving in a culture. This problem presents several challenges
as it can be difficult to grow and maintain the culture for days, and it is
expensive to acquire the materials and equipment. In this work, we explore how
to alleviate this data scarcity problem by synthesizing the videos. We,
therefore, take the recent work of the video diffusion model to synthesize
videos of cells from our training dataset. We then analyze the model's
strengths and consistent shortcomings to guide us on improving video generation
to be as high-quality as possible. To improve on such a task, we propose
modifying the denoising function and adding motion information (dense optical
flow) so that the model has more context regarding how video frames transition
over time and how each pixel changes over time.
</p></li>
</ul>

<h3>Title: NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors. (arXiv:2212.03267v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03267">http://arxiv.org/abs/2212.03267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03267] NeRDi: Single-View NeRF Synthesis with Language-Guided Diffusion as General Image Priors](http://arxiv.org/abs/2212.03267) #diffusion</code></li>
<li>Summary: <p>2D-to-3D reconstruction is an ill-posed problem, yet humans are good at
solving this problem due to their prior knowledge of the 3D world developed
over years. Driven by this observation, we propose NeRDi, a single-view NeRF
synthesis framework with general image priors from 2D diffusion models.
Formulating single-view reconstruction as an image-conditioned 3D generation
problem, we optimize the NeRF representations by minimizing a diffusion loss on
its arbitrary view renderings with a pretrained image diffusion model under the
input-view constraint. We leverage off-the-shelf vision-language models and
introduce a two-section language guidance as conditioning inputs to the
diffusion model. This is essentially helpful for improving multiview content
coherence as it narrows down the general image prior conditioned on the
semantic and visual features of the single-view input image. Additionally, we
introduce a geometric loss based on estimated depth maps to regularize the
underlying 3D geometry of the NeRF. Experimental results on the DTU MVS dataset
show that our method can synthesize novel views with higher quality even
compared to existing methods trained on this dataset. We also demonstrate our
generalizability in zero-shot NeRF synthesis for in-the-wild images.
</p></li>
</ul>

<h3>Title: Diffusion-SDF: Text-to-Shape via Voxelized Diffusion. (arXiv:2212.03293v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03293">http://arxiv.org/abs/2212.03293</a></li>
<li>Code URL: <a href="https://github.com/ttlmh/diffusion-sdf">https://github.com/ttlmh/diffusion-sdf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03293] Diffusion-SDF: Text-to-Shape via Voxelized Diffusion](http://arxiv.org/abs/2212.03293) #diffusion</code></li>
<li>Summary: <p>With the rising industrial attention to 3D virtual modeling technology,
generating novel 3D content based on specified conditions (e.g. text) has
become a hot issue. In this paper, we propose a new generative 3D modeling
framework called Diffusion-SDF for the challenging task of text-to-shape
synthesis. Previous approaches lack flexibility in both 3D data representation
and shape generation, thereby failing to generate highly diversified 3D shapes
conforming to the given text descriptions. To address this, we propose a SDF
autoencoder together with the Voxelized Diffusion model to learn and generate
representations for voxelized signed distance fields (SDFs) of 3D shapes.
Specifically, we design a novel UinU-Net architecture that implants a
local-focused inner network inside the standard U-Net architecture, which
enables better reconstruction of patch-independent SDF representations. We
extend our approach to further text-to-shape tasks including text-conditioned
shape completion and manipulation. Experimental results show that Diffusion-SDF
is capable of generating both high-quality and highly diversified 3D shapes
that conform well to the given text descriptions. Diffusion-SDF has
demonstrated its superiority compared to previous state-of-the-art
text-to-shape approaches.
</p></li>
</ul>

<h3>Title: Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for Text-to-Image Generation. (arXiv:2212.03507v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03507">http://arxiv.org/abs/2212.03507</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03507] Judge, Localize, and Edit: Ensuring Visual Commonsense Morality for Text-to-Image Generation](http://arxiv.org/abs/2212.03507) #diffusion</code></li>
<li>Summary: <p>Text-to-image generation methods produce high-resolution and high-quality
images, but these methods should not produce immoral images that may contain
inappropriate content from the commonsense morality perspective. Conventional
approaches often neglect these ethical concerns, and existing solutions are
limited in avoiding immoral image generation. In this paper, we aim to
automatically judge the immorality of synthesized images and manipulate these
images into a moral alternative. To this end, we build a model that has the
three main primitives: (1) our model recognizes the visual commonsense
immorality of a given image, (2) our model localizes or highlights immoral
visual (and textual) attributes that make the image immoral, and (3) our model
manipulates a given immoral image into a morally-qualifying alternative. We
experiment with the state-of-the-art Stable Diffusion text-to-image generation
model and show the effectiveness of our ethical image manipulation. Our human
study confirms that ours is indeed able to generate morally-satisfying images
from immoral ones. Our implementation will be publicly available upon
publication to be widely used as a new safety checker for text-to-image
generation models.
</p></li>
</ul>

<h3>Title: Magic: Multi Art Genre Intelligent Choreography Dataset and Network for 3D Dance Generation. (arXiv:2212.03741v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03741">http://arxiv.org/abs/2212.03741</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03741] Magic: Multi Art Genre Intelligent Choreography Dataset and Network for 3D Dance Generation](http://arxiv.org/abs/2212.03741) #diffusion</code></li>
<li>Summary: <p>Achieving multiple genres and long-term choreography sequences from given
music is a challenging task, due to the lack of a multi-genre dataset. To
tackle this problem,we propose a Multi Art Genre Intelligent Choreography
Dataset (MagicDance). The data of MagicDance is captured from professional
dancers assisted by motion capture technicians. It has a total of 8 hours 3D
motioncapture human dances with paired music, and 16 different dance genres. To
the best of our knowledge, MagicDance is the 3D dance dataset with the most
genres. In addition, we find that the existing two types of methods
(generation-based method and synthesis-based method) can only satisfy one of
the diversity and duration, but they can complement to some extent. Based on
this observation, we also propose a generation-synthesis choreography network
(MagicNet), which cascades a Diffusion-based 3D Diverse Dance fragments
Generation Network (3DGNet) and a Genre&amp;Coherent aware Retrieval Module (GCRM).
The former can generate various dance fragments from only one music clip. The
latter is utilized to select the best dance fragment generated by 3DGNet and
switch them into a complete dance according to the genre and coherent matching
score. Quantitative and qualitative experiments demonstrate the quality of
MagicDance, and the state-of-the-art performance of MagicNet.
</p></li>
</ul>

<h3>Title: Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models. (arXiv:2212.03860v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03860">http://arxiv.org/abs/2212.03860</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03860] Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models](http://arxiv.org/abs/2212.03860) #diffusion</code></li>
<li>Summary: <p>Cutting-edge diffusion models produce images with high quality and
customizability, enabling them to be used for commercial art and graphic design
purposes. But do diffusion models create unique works of art, or are they
stealing content directly from their training sets? In this work, we study
image retrieval frameworks that enable us to compare generated images with
training samples and detect when content has been replicated. Applying our
frameworks to diffusion models trained on multiple datasets including Oxford
flowers, Celeb-A, ImageNet, and LAION, we discuss how factors such as training
set size impact rates of content replication. We also identify cases where
diffusion models, including the popular Stable Diffusion model, blatantly copy
from their training data.
</p></li>
</ul>

<h3>Title: X-Paste: Revisit Copy-Paste at Scale with CLIP and StableDiffusion. (arXiv:2212.03863v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.03863">http://arxiv.org/abs/2212.03863</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.03863] X-Paste: Revisit Copy-Paste at Scale with CLIP and StableDiffusion](http://arxiv.org/abs/2212.03863) #diffusion</code></li>
<li>Summary: <p>Copy-Paste is a simple and effective data augmentation strategy for instance
segmentation. By randomly pasting object instances onto new background images,
it creates new training data for free and significantly boosts the segmentation
performance, especially for rare object categories. Although diverse,
high-quality object instances used in Copy-Paste result in more performance
gain, previous works utilize object instances either from human-annotated
instance segmentation datasets or rendered from 3D object models, and both
approaches are too expensive to scale up to obtain good diversity. In this
paper, we revisit Copy-Paste at scale with the power of newly emerged zero-shot
recognition models (e.g., CLIP) and text2image models (e.g., StableDiffusion).
We demonstrate for the first time that using a text2image model to generate
images or zero-shot recognition model to filter noisily crawled images for
different object categories is a feasible way to make Copy-Paste truly
scalable. To make such success happen, we design a data acquisition and
processing framework, dubbed "X-Paste", upon which a systematic study is
conducted. On the LVIS dataset, X-Paste provides impressive improvements over
the strong baseline CenterNet2 with Swin-L as the backbone. Specifically, it
archives +2.6 box AP and +2.1 mask AP gains on all classes and even more
significant gains with +6.8 box AP +6.5 mask AP on long-tail classes.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
