<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-10-07</h1>
<h3>Title: VIFO: Visual Feature Empowered Multivariate Time Series Forecasting with Cross-Modal Fusion</h3>
<ul>
<li><strong>Authors: </strong>Yanlong Wang, Hang Yu, Jian Xu, Fei Ma, Hongkang Zhang, Tongtong Feng, Zijian Zhang, Shao-Lun Huang, Danny Dongning Sun, Xiao-Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03244">https://arxiv.org/abs/2510.03244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03244">https://arxiv.org/pdf/2510.03244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03244]] VIFO: Visual Feature Empowered Multivariate Time Series Forecasting with Cross-Modal Fusion(https://arxiv.org/abs/2510.03244)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Large time series foundation models often adopt channel-independent architectures to handle varying data dimensions, but this design ignores crucial cross-channel dependencies. Concurrently, existing multimodal approaches have not fully exploited the power of large vision models (LVMs) to interpret spatiotemporal data. Additionally, there remains significant unexplored potential in leveraging the advantages of information extraction from different modalities to enhance time series forecasting performance. To address these gaps, we propose the VIFO, a cross-modal forecasting model. VIFO uniquely renders multivariate time series into image, enabling pre-trained LVM to extract complex cross-channel patterns that are invisible to channel-independent models. These visual features are then aligned and fused with representations from the time series modality. By freezing the LVM and training only 7.45% of its parameters, VIFO achieves competitive performance on multiple benchmarks, offering an efficient and effective solution for capturing cross-variable relationships in</li>
</ul>

<h3>Title: Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability</h3>
<ul>
<li><strong>Authors: </strong>Ali Yavari, Alireza Mohamadi, Elham Beydaghi, Rainer A. Leitgeb</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03245">https://arxiv.org/abs/2510.03245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03245">https://arxiv.org/pdf/2510.03245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03245]] Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability(https://arxiv.org/abs/2510.03245)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, explainability</a></li>
<li><strong>Abstract: </strong>Ensuring the reliability of deep neural networks (DNNs) in the presence of real world noise and intentional perturbations remains a significant challenge. To address this, attribution methods have been proposed, though their efficacy remains suboptimal and necessitates further refinement. In this paper, we propose a novel category of transferable adversarial attacks, called transferable frequency-aware attacks, enabling frequency-aware exploration via both high-and low-frequency components. Based on this type of attacks, we also propose a novel attribution method, named Frequency-Aware Model Parameter Explorer (FAMPE), which improves the explainability for DNNs. Relative to the current state-of-the-art method AttEXplore, our FAMPE attains an average gain of 13.02% in Insertion Score, thereby outperforming existing approaches. Through detailed ablation studies, we also investigate the role of both high- and low-frequency components in explainability.</li>
</ul>

<h3>Title: StructPrune: Structured Global Pruning asymptotics with $\mathcal{O}(\sqrt{N})$ GPU Memory</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Song, Guangji Bai, Liang Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03246">https://arxiv.org/abs/2510.03246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03246">https://arxiv.org/pdf/2510.03246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03246]] StructPrune: Structured Global Pruning asymptotics with $\mathcal{O}(\sqrt{N})$ GPU Memory(https://arxiv.org/abs/2510.03246)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pruning is critical for scaling large language models (LLMs). Global pruning achieves strong performance but requires $\mathcal{O}(N)$ memory, which is infeasible for billion-parameter models. Local pruning reduces GPU memory usage to that of a single layer by pruning layers independently, but it neglects inter-layer dependencies and often leads to suboptimal performance in high-sparsity regimes. Unlike unstructured pruning, structured pruning produces regular sparsity patterns that align well with GPU kernels and library optimizations, making it more hardware-efficient. However, structured pruning typically relies on global pruning, since structured patterns are more prone to severe performance degradation under local optimization. To jointly achieve structured pruning and the memory efficiency of local pruning, we propose a divide-and-conquer strategy that decomposes the global pruning problem into coordinated subproblems across different modules, each of which fits within limited GPU memory. Building on this idea, we design \textbf{STRUPRUNE}, an ADMM-based framework that integrates structured sparsity into the pruning process, combining the memory efficiency of local pruning with the hardware compatibility of structured methods. We derive a closed-form analytical solution for structured pruning masks that provides an explicit rule for layer-wise sparsity allocation, and further develop an energy-based asymptotic framework yielding a softmax-form allocation scheme that simplifies optimization while adapting to heterogeneous layer importance. Experiments demonstrate that STRUPRUNE matches the perplexity of global structured pruning while reducing memory cost from $\mathcal{O}(N)$ to $\mathcal{O}(\sqrt{N})$, enabling practical deployment at the billion-parameter scale.</li>
</ul>

<h3>Title: Real-Time Brain Biomechanics Prediction with Neural Operators: Toward Clinically Deployable Traumatic Brain Injury Models</h3>
<ul>
<li><strong>Authors: </strong>Anusha Agarwal, Dibakar Roy Sarkar, Somdatta Goswami</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03248">https://arxiv.org/abs/2510.03248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03248">https://arxiv.org/pdf/2510.03248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03248]] Real-Time Brain Biomechanics Prediction with Neural Operators: Toward Clinically Deployable Traumatic Brain Injury Models(https://arxiv.org/abs/2510.03248)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Traumatic brain injury (TBI) remains a major public health concern, with over 69 million cases annually worldwide. Finite element (FE) models offer high-fidelity predictions of brain deformation but are computationally expensive, requiring hours per simulation and limiting their clinical utility for rapid decision-making. This study benchmarks state-of-the-art neural operator (NO) architectures for rapid, patient-specific prediction of brain displacement fields, aiming to enable real-time TBI modeling in clinical and translational settings. We formulated TBI modeling as an operator learning problem, mapping subject-specific anatomical MRI, magnetic resonance elastography (MRE) stiffness maps, and demographic features to full-field 3D brain displacement predictions. Four architectures - Fourier Neural Operator (FNO), Factorized FNO (F-FNO), Multi-Grid FNO (MG-FNO), and Deep Operator Network (DeepONet) were trained and evaluated on 249 MRE datasets across physiologically relevant frequencies (20 - 90 Hz). MG-FNO achieved the highest accuracy (MSE = 0.0023, 94.3\% spatial fidelity) and preserved fine-scale features, while F-FNO converged 2$\times$ faster than standard FNO. DeepONet offered the fastest inference (14.5 iterations/s) with a 7$\times$ computational speed-up over MG-FNO, suggesting utility for embedded or edge computing applications. All NOs reduced computation time from hours to milliseconds without sacrificing anatomical realism. NOs provide an efficient, resolution-invariant approach for predicting brain deformation, opening the door to real-time, patient-specific TBI risk assessment, clinical triage support, and optimization of protective equipment. These results highlight the potential for NO-based digital twins of the human brain, enabling scalable, on-demand biomechanical modeling in both clinical and population health contexts.</li>
</ul>

<h3>Title: Numerion: A Multi-Hypercomplex Model for Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Hanzhong Cao, Wenbo Yan, Ying Tan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03251">https://arxiv.org/abs/2510.03251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03251">https://arxiv.org/pdf/2510.03251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03251]] Numerion: A Multi-Hypercomplex Model for Time Series Forecasting(https://arxiv.org/abs/2510.03251)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many methods aim to enhance time series forecasting by decomposing the series through intricate model structures and prior knowledge, yet they are inevitably limited by computational complexity and the robustness of the assumptions. Our research uncovers that in the complex domain and higher-order hypercomplex spaces, the characteristic frequencies of time series naturally decrease. Leveraging this insight, we propose Numerion, a time series forecasting model based on multiple hypercomplex spaces. Specifically, grounded in theoretical support, we generalize linear layers and activation functions to hypercomplex spaces of arbitrary power-of-two dimensions and introduce a novel Real-Hypercomplex-Real Domain Multi-Layer Perceptron (RHR-MLP) architecture. Numerion utilizes multiple RHR-MLPs to map time series into hypercomplex spaces of varying dimensions, naturally decomposing and independently modeling the series, and adaptively fuses the latent patterns exhibited in different spaces through a dynamic fusion mechanism. Experiments validate the model`s performance, achieving state-of-the-art results on multiple public datasets. Visualizations and quantitative analyses comprehensively demonstrate the ability of multi-dimensional RHR-MLPs to naturally decompose time series and reveal the tendency of higher dimensional hypercomplex spaces to capture lower frequency features.</li>
</ul>

<h3>Title: Universal Multi-Domain Translation via Diffusion Routers</h3>
<ul>
<li><strong>Authors: </strong>Duc Kieu, Kien Do, Tuan Hoang, Thao Minh Le, Tung Kieu, Dang Nguyen, Thin Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03252">https://arxiv.org/abs/2510.03252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03252">https://arxiv.org/pdf/2510.03252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03252]] Universal Multi-Domain Translation via Diffusion Routers(https://arxiv.org/abs/2510.03252)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Multi-domain translation (MDT) aims to learn translations between multiple domains, yet existing approaches either require fully aligned tuples or can only handle domain pairs seen in training, limiting their practicality and excluding many cross-domain mappings. We introduce universal MDT (UMDT), a generalization of MDT that seeks to translate between any pair of $K$ domains using only $K-1$ paired datasets with a central domain. To tackle this problem, we propose Diffusion Router (DR), a unified diffusion-based framework that models all central$\leftrightarrow$non-central translations with a single noise predictor conditioned on the source and target domain labels. DR enables indirect non-central translations by routing through the central domain. We further introduce a novel scalable learning strategy with a variational-bound objective and an efficient Tweedie refinement procedure to support direct non-central mappings. Through evaluation on three large-scale UMDT benchmarks, DR achieves state-of-the-art results for both indirect and direct translations, while lowering sampling cost and unlocking novel tasks such as sketch$\leftrightarrow$segmentation. These results establish DR as a scalable and versatile framework for universal translation across multiple domains.</li>
</ul>

<h3>Title: Solving the Granularity Mismatch: Hierarchical Preference Learning for Long-Horizon LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Heyang Gao, Zexu Sun, Erxue Min, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Xu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03253">https://arxiv.org/abs/2510.03253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03253">https://arxiv.org/pdf/2510.03253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03253]] Solving the Granularity Mismatch: Hierarchical Preference Learning for Long-Horizon LLM Agents(https://arxiv.org/abs/2510.03253)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) as autonomous agents are increasingly tasked with solving complex, long-horizon problems. Aligning these agents via preference-based offline methods like Direct Preference Optimization (DPO) is a promising direction, yet it faces a critical granularity mismatch. Trajectory-level DPO provides a signal that is too coarse for precise credit assignment, while step-level DPO is often too myopic to capture the value of multi-step behaviors. To resolve this challenge, we introduce Hierarchical Preference Learning (HPL), a hierarchical framework that optimizes LLM agents by leveraging preference signals at multiple, synergistic granularities. While HPL incorporates trajectory- and step-level DPO for global and local policy stability, its core innovation lies in group-level preference optimization guided by a dual-layer curriculum. Our approach first decomposes expert trajectories into semantically coherent action groups and then generates contrasting suboptimal groups to enable preference learning at a fine-grained, sub-task level. Then, instead of treating all preference pairs equally, HPL introduces a curriculum scheduler that organizes the learning process from simple to complex. This curriculum is structured along two axes: the group length, representing sub-task complexity, and the sample difficulty, defined by the reward gap between preferred and dispreferred action groups. Experiments on three challenging agent benchmarks show that HPL outperforms existing state-of-the-art methods. Our analyses demonstrate that the hierarchical DPO loss effectively integrates preference signals across multiple granularities, while the dual-layer curriculum is crucial for enabling the agent to solve a wide range of tasks, from simple behaviors to complex multi-step sequences.</li>
</ul>

<h3>Title: Adversarial training with restricted data manipulation</h3>
<ul>
<li><strong>Authors: </strong>David Benfield, Stefano Coniglio, Phan Tu Vuong, Alain Zemkoho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03254">https://arxiv.org/abs/2510.03254</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03254">https://arxiv.org/pdf/2510.03254</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03254]] Adversarial training with restricted data manipulation(https://arxiv.org/abs/2510.03254)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Adversarial machine learning concerns situations in which learners face attacks from active adversaries. Such scenarios arise in applications such as spam email filtering, malware detection and fake image generation, where security methods must be actively updated to keep up with the everimproving generation of malicious data. Pessimistic Bilevel optimisation has been shown to be an effective method of training resilient classifiers against such adversaries. By modelling these scenarios as a game between the learner and the adversary, we anticipate how the adversary will modify their data and then train a resilient classifier accordingly. However, since existing pessimistic bilevel approaches feature an unrestricted adversary, the model is vulnerable to becoming overly pessimistic and unrealistic. When finding the optimal solution that defeats the classifier, it is possible that the adversary's data becomes nonsensical and loses its intended nature. Such an adversary will not properly reflect reality, and consequently, will lead to poor classifier performance when implemented on real-world data. By constructing a constrained pessimistic bilevel optimisation model, we restrict the adversary's movements and identify a solution that better reflects reality. We demonstrate through experiments that this model performs, on average, better than the existing approach.</li>
</ul>

<h3>Title: SciTS: Scientific Time Series Understanding and Generation with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wen Wu, Ziyang Zhang, Liwei Liu, Xuenan Xu, Junlin Liu, Ke Fan, Qitan Lv, Jimin Zhuang, Chen Zhang, Zheqi Yuan, Siyuan Hou, Tianyi Lin, Kai Chen, Bowen Zhou, Chao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03255">https://arxiv.org/abs/2510.03255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03255">https://arxiv.org/pdf/2510.03255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03255]] SciTS: Scientific Time Series Understanding and Generation with LLMs(https://arxiv.org/abs/2510.03255)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention. Time series, as a fundamental modality in scientific data, presents unique challenges that are often overlooked in current multimodal LLMs, which either encode numerical sequences as text or convert them into images. Such approaches may be insufficient for comprehensive scientific time series understanding and generation. Existing unified time series models typically specialise in either forecasting or analysis, and their effectiveness on non-periodic, heterogeneous scientific signals remains unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12 scientific domains and 43 tasks, with over 50k+ instances, both univariate and multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz in frequency. We benchmark 17 models, including text-only LLMs, multimodal LLMs, and unified time series models, and find that general-purpose LLMs exhibit stronger generalisability than specialised time series models, while representing time series as text or images limits their performance due to excessively long sequences and loss of numerical precision, respectively. We then introduce TimeOmni, a framework that equips LLMs with the ability to understand and generate time series while remaining compatible with general-purpose LLM training. This work fills a gap in both dedicated benchmarks and modelling frameworks for scientific time series, paving the way for LLMs to understand and generate complex temporal scientific data.</li>
</ul>

<h3>Title: Data-Driven Temperature Modelling of Machine Tools by Neural Networks: A Benchmark</h3>
<ul>
<li><strong>Authors: </strong>C. Coelho, M. Hohmann, D. Fernández, L. Penter, S. Ihlenfeldt, O. Niggemann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03261">https://arxiv.org/abs/2510.03261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03261">https://arxiv.org/pdf/2510.03261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03261]] Data-Driven Temperature Modelling of Machine Tools by Neural Networks: A Benchmark(https://arxiv.org/abs/2510.03261)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Thermal errors in machine tools significantly impact machining precision and productivity. Traditional thermal error correction/compensation methods rely on measured temperature-deformation fields or on transfer functions. Most existing data-driven compensation strategies employ neural networks (NNs) to directly predict thermal errors or specific compensation values. While effective, these approaches are tightly bound to particular error types, spatial locations, or machine configurations, limiting their generality and adaptability. In this work, we introduce a novel paradigm in which NNs are trained to predict high-fidelity temperature and heat flux fields within the machine tool. The proposed framework enables subsequent computation and correction of a wide range of error types using modular, swappable downstream components. The NN is trained using data obtained with the finite element method under varying initial conditions and incorporates a correlation-based selection strategy that identifies the most informative measurement points, minimising hardware requirements during inference. We further benchmark state-of-the-art time-series NN architectures, namely Recurrent NN, Gated Recurrent Unit, Long-Short Term Memory (LSTM), Bidirectional LSTM, Transformer, and Temporal Convolutional Network, by training both specialised models, tailored for specific initial conditions, and general models, capable of extrapolating to unseen scenarios. The results show accurate and low-cost prediction of temperature and heat flux fields, laying the basis for enabling flexible and generalisable thermal error correction in machine tool environments.</li>
</ul>

<h3>Title: Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned Models</h3>
<ul>
<li><strong>Authors: </strong>Agnieszka Polowczyk, Alicja Polowczyk, Joanna Waczyńska, Piotr Borycki, Przemysław Spurek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03263">https://arxiv.org/abs/2510.03263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03263">https://arxiv.org/pdf/2510.03263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03263]] Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned Models(https://arxiv.org/abs/2510.03263)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, generative</a></li>
<li><strong>Abstract: </strong>The impressive capability of modern text-to-image models to generate realistic visuals has come with a serious drawback: they can be misused to create harmful, deceptive or unlawful content. This has accelerated the push for machine unlearning. This new field seeks to selectively remove specific knowledge from a model's training data without causing a drop in its overall performance. However, it turns out that actually forgetting a given concept is an extremely difficult task. Models exposed to attacks using adversarial prompts show the ability to generate so-called unlearned concepts, which can be not only harmful but also illegal. In this paper, we present considerations regarding the ability of models to forget and recall knowledge, introducing the Memory Self-Regeneration task. Furthermore, we present MemoRa strategy, which we consider to be a regenerative approach supporting the effective recovery of previously lost knowledge. Moreover, we propose that robustness in knowledge retrieval is a crucial yet underexplored evaluation measure for developing more robust and effective unlearning techniques. Finally, we demonstrate that forgetting occurs in two distinct ways: short-term, where concepts can be quickly recalled, and long-term, where recovery is more challenging.</li>
</ul>

<h3>Title: Variational Autoencoders-based Detection of Extremes in Plant Productivity in an Earth System Model</h3>
<ul>
<li><strong>Authors: </strong>Bharat Sharma, Jitendra Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.OT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03266">https://arxiv.org/abs/2510.03266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03266">https://arxiv.org/pdf/2510.03266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03266]] Variational Autoencoders-based Detection of Extremes in Plant Productivity in an Earth System Model(https://arxiv.org/abs/2510.03266)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Climate anomalies significantly impact terrestrial carbon cycle dynamics, necessitating robust methods for detecting and analyzing anomalous behavior in plant productivity. This study presents a novel application of variational autoencoders (VAE) for identifying extreme events in gross primary productivity (GPP) from Community Earth System Model version 2 simulations across four AR6 regions in the Continental United States. We compare VAE-based anomaly detection with traditional singular spectral analysis (SSA) methods across three time periods: 1850-80, 1950-80, and 2050-80 under the SSP585 scenario. The VAE architecture employs three dense layers and a latent space with an input sequence length of 12 months, trained on a normalized GPP time series to reconstruct the GPP and identifying anomalies based on reconstruction errors. Extreme events are defined using 5th percentile thresholds applied to both VAE and SSA anomalies. Results demonstrate strong regional agreement between VAE and SSA methods in spatial patterns of extreme event frequencies, despite VAE producing higher threshold values (179-756 GgC for VAE vs. 100-784 GgC for SSA across regions and periods). Both methods reveal increasing magnitudes and frequencies of negative carbon cycle extremes toward 2050-80, particularly in Western and Central North America. The VAE approach shows comparable performance to established SSA techniques, while offering computational advantages and enhanced capability for capturing non-linear temporal dependencies in carbon cycle variability. Unlike SSA, the VAE method does not require one to define the periodicity of the signals in the data; it discovers them from the data.</li>
</ul>

<h3>Title: PT$^2$-LLM: Post-Training Ternarization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xianglong Yan, Chengzhu Bao, Zhiteng Li, Tianao Zhang, Kaicheng Yang, Haotong Qin, Ruobing Xie, Xingwu Sun, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03267">https://arxiv.org/abs/2510.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03267">https://arxiv.org/pdf/2510.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03267]] PT$^2$-LLM: Post-Training Ternarization for Large Language Models(https://arxiv.org/abs/2510.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have shown impressive capabilities across diverse tasks, but their large memory and compute demands hinder deployment. Ternarization has gained attention as a promising compression technique, delivering substantial size reduction and high computational efficiency. However, its potential in the post-training quantization (PTQ) setting remains underexplored, due to the challenge of training-free parameter optimization and the quantization difficulty posed by outliers and dispersed weights. To address these issues, we propose PT$^2$-LLM, a post-training ternarization framework tailored for LLMs. At its core is an Asymmetric Ternary Quantizer equipped with a two-stage refinement pipeline: (1) Iterative Ternary Fitting (ITF), which alternates between optimal ternary grid construction and flexible rounding to minimize quantization error, and (2) Activation-aware Grid Alignment (AGA), which further refines the ternary grid to better match full-precision outputs. In addition, we propose a plug-and-play Structural Similarity-based Reordering (SSR) strategy that leverages inter-column structural similarity to ease quantization and mitigate outlier effects, further enhancing overall performance. Extensive experiments demonstrate that PT$^2$-LLM delivers competitive performance against state-of-the-art (SOTA) 2-bit PTQ methods with lower memory cost, while also accelerating both prefill and decoding to achieve end-to-end speedup. The code and models will be available at this https URL.</li>
</ul>

<h3>Title: General Exploratory Bonus for Optimistic Exploration in RLHF</h3>
<ul>
<li><strong>Authors: </strong>Wendi Li, Changdae Oh, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03269">https://arxiv.org/abs/2510.03269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03269">https://arxiv.org/pdf/2510.03269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03269]] General Exploratory Bonus for Optimistic Exploration in RLHF(https://arxiv.org/abs/2510.03269)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Optimistic exploration is central to improving sample efficiency in reinforcement learning with human feedback, yet existing exploratory bonus methods to incentivize exploration often fail to realize optimism. We provide a theoretical analysis showing that current formulations, under KL or $\alpha$-divergence regularization, unintentionally bias exploration toward high-probability regions of the reference model, thereby reinforcing conservative behavior instead of promoting discovery of uncertain regions. To address this pitfall, we introduce the General Exploratory Bonus (GEB), a novel theoretical framework that provably satisfies the optimism principle. GEB counteracts divergence-induced bias via reference-dependent reward regulation and unifies prior heuristic bonuses as special cases, while extending naturally across the full $\alpha$-divergence family. Empirically, GEB consistently outperforms baselines on alignment tasks across multiple divergence settings and large language model backbones. These results demonstrate that GEB offers both a principled and practical solution for optimistic exploration in RLHF.</li>
</ul>

<h3>Title: CoDA: Coding LM via Diffusion Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Haolin Chen, Shiyu Wang, Can Qin, Bo Pang, Zuxin Liu, Jielin Qiu, Jianguo Zhang, Yingbo Zhou, Zeyuan Chen, Ran Xu, Shelby Heinecke, Silvio Savarese, Caiming Xiong, Huan Wang, Weiran Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03270">https://arxiv.org/abs/2510.03270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03270">https://arxiv.org/pdf/2510.03270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03270]] CoDA: Coding LM via Diffusion Adaptation(https://arxiv.org/abs/2510.03270)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models promise bidirectional context and infilling capabilities that autoregressive coders lack, yet practical systems remain heavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU with a fully open-source training pipeline. CoDA pairs large-scale diffusion pre-training with code-centric mid-training and instruction tuning, enabling confidence-guided sampling that keeps inference latency competitive. On Humaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses diffusion models up to 7B parameters. Our release includes model checkpoints, evaluation harnesses, and TPU training pipelines to accelerate research on lightweight diffusion-based coding assistants.</li>
</ul>

<h3>Title: Decision Potential Surface: A Theoretical and Practical Approximation of LLM's Decision Boundary</h3>
<ul>
<li><strong>Authors: </strong>Zi Liang, Zhiyao Wu, Haoyang Shang, Yulin Jin, Qingqing Ye, Huadi Zheng, Peizhao Hu, Haibo Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03271">https://arxiv.org/abs/2510.03271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03271">https://arxiv.org/pdf/2510.03271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03271]] Decision Potential Surface: A Theoretical and Practical Approximation of LLM's Decision Boundary(https://arxiv.org/abs/2510.03271)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Decision boundary, the subspace of inputs where a machine learning model assigns equal classification probabilities to two classes, is pivotal in revealing core model properties and interpreting behaviors. While analyzing the decision boundary of large language models (LLMs) has raised increasing attention recently, constructing it for mainstream LLMs remains computationally infeasible due to the enormous vocabulary-sequence sizes and the auto-regressive nature of LLMs. To address this issue, in this paper we propose Decision Potential Surface (DPS), a new notion for analyzing LLM decision boundary. DPS is defined on the confidences in distinguishing different sampling sequences for each input, which naturally captures the potential of decision boundary. We prove that the zero-height isohypse in DPS is equivalent to the decision boundary of an LLM, with enclosed regions representing decision regions. By leveraging DPS, for the first time in the literature, we propose an approximate decision boundary construction algorithm, namely $K$-DPS, which only requires K-finite times of sequence sampling to approximate an LLM's decision boundary with negligible error. We theoretically derive the upper bounds for the absolute error, expected error, and the error concentration between K-DPS and the ideal DPS, demonstrating that such errors can be trade-off with sampling times. Our results are empirically validated by extensive experiments across various LLMs and corpora.</li>
</ul>

<h3>Title: PDE-Transformer: A Continuous Dynamical Systems Approach to Sequence Modeling</h3>
<ul>
<li><strong>Authors: </strong>Yukun Zhang, Xueqing Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03272">https://arxiv.org/abs/2510.03272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03272">https://arxiv.org/pdf/2510.03272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03272]] PDE-Transformer: A Continuous Dynamical Systems Approach to Sequence Modeling(https://arxiv.org/abs/2510.03272)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has revolutionized artificial intelligence, yet a principled theoretical understanding of its internal mechanisms remains elusive. This paper introduces a novel analytical framework that reconceptualizes the Transformer's discrete, layered structure as a continuous spatiotemporal dynamical system governed by a master Partial Differential Equation (PDE). Within this paradigm, we map core architectural components to distinct mathematical operators: self-attention as a non-local interaction, the feed-forward network as a local reaction, and, critically, residual connections and layer normalization as indispensable stabilization mechanisms. We do not propose a new model, but rather employ the PDE system as a theoretical probe to analyze the mathematical necessity of these components. By comparing a standard Transformer with a PDE simulator that lacks explicit stabilizers, our experiments provide compelling empirical evidence for our central thesis. We demonstrate that without residual connections, the system suffers from catastrophic representational drift, while the absence of layer normalization leads to unstable, explosive training dynamics. Our findings reveal that these seemingly heuristic "tricks" are, in fact, fundamental mathematical stabilizers required to tame an otherwise powerful but inherently unstable continuous system. This work offers a first-principles explanation for the Transformer's design and establishes a new paradigm for analyzing deep neural networks through the lens of continuous dynamics.</li>
</ul>

<h3>Title: Learning without Global Backpropagation via Synergistic Information Distillation</h3>
<ul>
<li><strong>Authors: </strong>Chenhao Ye, Ming Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03273">https://arxiv.org/abs/2510.03273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03273">https://arxiv.org/pdf/2510.03273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03273]] Learning without Global Backpropagation via Synergistic Information Distillation(https://arxiv.org/abs/2510.03273)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Backpropagation (BP), while foundational to deep learning, imposes two critical scalability bottlenecks: update locking, where network modules remain idle until the entire backward pass completes, and high memory consumption due to storing activations for gradient computation. To address these limitations, we introduce Synergistic Information Distillation (SID), a novel training framework that reframes deep learning as a cascade of local cooperative refinement problems. In SID, a deep network is structured as a pipeline of modules, each imposed with a local objective to refine a probabilistic belief about the ground-truth target. This objective balances fidelity to the target with consistency to the belief from its preceding module. By decoupling the backward dependencies between modules, SID enables parallel training and hence eliminates update locking and drastically reduces memory requirements. Meanwhile, this design preserves the standard feed-forward inference pass, making SID a versatile drop-in replacement for BP. We provide a theoretical foundation, proving that SID guarantees monotonic performance improvement with network depth. Empirically, SID consistently matches or surpasses the classification accuracy of BP, exhibiting superior scalability and pronounced robustness to label this http URL is available at: this https URL</li>
</ul>

<h3>Title: Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tianao Zhang, Zhiteng Li, Xianglong Yan, Haotong Qin, Yong Guo, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03274">https://arxiv.org/abs/2510.03274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03274">https://arxiv.org/pdf/2510.03274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03274]] Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models(https://arxiv.org/abs/2510.03274)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs), which offer bidirectional context and flexible masked-denoising generation, are emerging as a compelling alternative to autoregressive (AR) LLMs. However, like AR LLMs, their model sizes continue to grow, motivating weight compression for deployment. Although post-training quantization (PTQ) is effective for AR LLMs, directly transferring it to dLLMs at 2-bit leads to unsatisfactory performance. To tackle these challenges, we propose Quant-dLLM, an ultra-low-bit PTQ framework tailored to dLLMs. Since masked-denoising activations in dLLMs differ from the fully visible signals assumed by standard PTQ methods, we introduce Masked Calibration Simulation (MCS) to align calibration with the timestep-dependent masking, which yields more reliable calibrations. Moreover, we propose a Data-aware Any-order Quantizer (DAQ) that learns ultra-low-bit weight representations via an optimization algorithm. It performs iterative approximation guided by our simulated calibration data. In addition, under a strict 2-bit budget, we introduce Adaptive Blockwise Mixed Precision (ABMP), a sensitivity-based precision allocation scheme that adaptively assigns bit width across channel groups. When restricted to 2-bit precision, Quant-dLLM consistently achieves higher accuracy than state-of-the-art (SOTA) AR-transfer PTQ methods on dLLMs. The code and models will be available at: this https URL.</li>
</ul>

<h3>Title: SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size</h3>
<ul>
<li><strong>Authors: </strong>Junhao Xia, Ming Zhao, Limin Xiao, Xiujun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03275">https://arxiv.org/abs/2510.03275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03275">https://arxiv.org/pdf/2510.03275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03275]] SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size(https://arxiv.org/abs/2510.03275)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) face significant computational and memory challenges, making extremely low-bit quantization crucial for their efficient deployment. In this work, we introduce SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size, a novel framework that enables extremely low-bit quantization of LLMs while preserving their linguistic reasoning capabilities. A distinctive feature of SDQ-LLM is the continuous adjustability of the Over-Sampling Ratio (OSR), enabling dynamic adaptation to memory or VRAM constraints by selecting fractional OSR (e.g. 2.5 times) for an optimal trade-off between model size and accuracy. SDQ-LLM uses upsampling combined with Sigma-Delta Quantizer to binarize or ternarize LLMs weights, encoding high-precision parameters into 1-bit or 1.58-bit representations, replacing the multiplication operations within linear layers with addition. This approach significantly enhances inference efficiency under extremely low-bit quantization. To further reduce the loss of quantization precision, we incorporate Hadamard-based weight smoothing prior to quantization, improving the stability and robustness of the weight representations. Furthermore, to fully leverage the continuity of the OSR and reduce precision loss, recognizing the correlation between quantization sensitivity and weight variance, we propose a fine-grained, layer- and linear-wise OSR allocation strategy, MultiOSR. This strategy distributes OSR both across layers and within each layer, based on weight variance and parameter scale. Finally, extensive experiments on OPT and LLaMA model families demonstrate that SDQ-LLM achieves a more efficient and high-precision performance even under highly aggressive low-OSR settings. Our code is available at this https URL.</li>
</ul>

<h3>Title: MemMamba: Rethinking Memory Patterns in State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Youjin Wang, Yangjingyi Chen, Jiahao Yan, Jiaxuan Lu, Xiao Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03279">https://arxiv.org/abs/2510.03279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03279">https://arxiv.org/pdf/2510.03279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03279]] MemMamba: Rethinking Memory Patterns in State Space Model(https://arxiv.org/abs/2510.03279)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>With the explosive growth of data, long-sequence modeling has become increasingly important in tasks such as natural language processing and bioinformatics. However, existing methods face inherent trade-offs between efficiency and memory. Recurrent neural networks suffer from gradient vanishing and explosion, making them hard to scale. Transformers can model global dependencies but are constrained by quadratic complexity. Recently, selective state-space models such as Mamba have demonstrated high efficiency with O(n) time and O(1) recurrent inference, yet their long-range memory decays exponentially. In this work, we conduct mathematical derivations and information-theoretic analysis to systematically uncover the memory decay mechanism of Mamba, answering a fundamental question: what is the nature of Mamba's long-range memory and how does it retain information? To quantify key information loss, we further introduce horizontal-vertical memory fidelity metrics that capture degradation both within and across layers. Inspired by how humans distill and retain salient information when reading long documents, we propose MemMamba, a novel architectural framework that integrates state summarization mechanism together with cross-layer and cross-token attention, which alleviates long-range forgetting while preserving linear complexity. MemMamba achieves significant improvements over existing Mamba variants and Transformers on long-sequence benchmarks such as PG19 and Passkey Retrieval, while delivering a 48% speedup in inference efficiency. Both theoretical analysis and empirical results demonstrate that MemMamba achieves a breakthrough in the complexity-memory trade-off, offering a new paradigm for ultra-long sequence modeling.</li>
</ul>

<h3>Title: Training Optimal Large Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jinjie Ni, Qian Liu, Chao Du, Longxu Dou, Hang Yan, Zili Wang, Tianyu Pang, Michael Qizhe Shieh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03280">https://arxiv.org/abs/2510.03280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03280">https://arxiv.org/pdf/2510.03280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03280]] Training Optimal Large Diffusion Language Models(https://arxiv.org/abs/2510.03280)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce Quokka, the first systematic scaling law for diffusion language models (DLMs), encompassing both compute-constrained and data-constrained regimes, and studying the key modeling and optimization designs. Quokka is a good friend of Chinchilla and provides wider scopes. We hope the results would bring short-term practical guidance in DLMs training and long-term inspirations for the whole AI community.</li>
</ul>

<h3>Title: Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework</h3>
<ul>
<li><strong>Authors: </strong>Hao Gu, Vibhas Nair, Amrithaa Ashok Kumar, Jayvart Sharma, Ryan Lagasse</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03282">https://arxiv.org/abs/2510.03282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03282">https://arxiv.org/pdf/2510.03282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03282]] Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework(https://arxiv.org/abs/2510.03282)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Interpreting language models often involves circuit analysis, which aims to identify sparse subnetworks, or circuits, that accomplish specific tasks. Existing circuit discovery algorithms face a fundamental trade-off: attribution patching is fast but unfaithful to the full model, while edge pruning is faithful but computationally expensive. This research proposes a hybrid attribution and pruning (HAP) framework that uses attribution patching to identify a high-potential subgraph, then applies edge pruning to extract a faithful circuit from it. We show that HAP is 46\% faster than baseline algorithms without sacrificing circuit faithfulness. Furthermore, we present a case study on the Indirect Object Identification task, showing that our method preserves cooperative circuit components (e.g. S-inhibition heads) that attribution patching methods prune at high sparsity. Our results show that HAP could be an effective approach for improving the scalability of mechanistic interpretability research to larger models. Our code is available at this https URL.</li>
</ul>

<h3>Title: MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous Retraining Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yufei Li, Yu Fu, Yue Dong, Cong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03283">https://arxiv.org/abs/2510.03283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03283">https://arxiv.org/pdf/2510.03283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03283]] MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous Retraining Alignment(https://arxiv.org/abs/2510.03283)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) deployed on edge servers are increasingly used in latency-sensitive applications such as personalized assistants, recommendation, and content moderation. However, the non-stationary nature of user data necessitates frequent retraining, which introduces a fundamental tension between inference latency and model accuracy under constrained GPU resources. Existing retraining strategies either delay model updates, over-commit resources to retraining, or overlook iteration-level retraining granularity. In this paper, we identify that iteration-level scheduling is crucial for adapting retraining frequency to model drift without violating service-level objectives (SLOs). We propose MACE, a hybrid LLM system that colocates concurrent inference (prefill, decode) and fine-tuning, with intelligent memory management to maximize task performance while promising inference throughput. MACE leverages the insight that not all model updates equally affect output alignment and allocates GPU cycles accordingly to balance throughput, latency, and update freshness. Our trace-driven evaluation shows that MACE matches or exceeds continuous retraining while reducing inference latency by up to 63% and maintaining throughput under resource constraints. Compared to periodic retraining, MACE improves latency breakdown across prefill, decode, and finetune stages, and sustains GPU utilization above 85% in NVIDIA AGX Orin. These results demonstrate that iteration-level hybrid scheduling is a promising direction for deploying LLMs with continual learning capabilities on edge platforms.</li>
</ul>

<h3>Title: Edge-FIT: Federated Instruction Tuning of Quantized LLMs for Privacy-Preserving Smart Home Environments</h3>
<ul>
<li><strong>Authors: </strong>Vinay Venkatesh, Vamsidhar R Kamanuru, Lav Kumar, Nikita Kothari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03284">https://arxiv.org/abs/2510.03284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03284">https://arxiv.org/pdf/2510.03284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03284]] Edge-FIT: Federated Instruction Tuning of Quantized LLMs for Privacy-Preserving Smart Home Environments(https://arxiv.org/abs/2510.03284)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes Edge-FIT (Federated Instruction Tuning on the Edge), a scalable framework for Federated Instruction Tuning (FIT) of Large Language Models (LLMs). Traditional Federated Learning (TFL) methods, like FedAvg, fail when confronted with the massive parameter size of LLMs [3], [6]. Our Edge-FIT framework combines federated learning with 4-bit Quantized Low-Rank Adaptation (QLORA), mitigating the core issues of communication and computational overhead. We demonstrate this by filtering the general-purpose Databricks Dolly 15k dataset for the IoT domain. Experimental results show the Edge-FIT tuned Llama 2(7B) achieves an F1-Score of 0.89. We also demonstrate a viable trade-off using the 3.8B Phi-3-mini model, validating Edge-FIT as a scalable framework for decentralized LLM deployment on home compute gateways.</li>
</ul>

<h3>Title: SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific Tumor Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Moinak Bhattacharya, Gagandeep Singh, Prateek Prasanna</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03287">https://arxiv.org/abs/2510.03287</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03287">https://arxiv.org/pdf/2510.03287</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03287]] SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific Tumor Dynamics(https://arxiv.org/abs/2510.03287)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion</a></li>
<li><strong>Abstract: </strong>Accurate prediction of tumor trajectories under standard-of-care (SoC) therapies remains a major unmet need in oncology. This capability is essential for optimizing treatment planning and anticipating disease progression. Conventional reaction-diffusion models are limited in scope, as they fail to capture tumor dynamics under heterogeneous therapeutic paradigms. There is hence a critical need for computational frameworks that can realistically simulate SoC interventions while accounting for inter-patient variability in genomics, demographics, and treatment regimens. We introduce Standard-of-Care Digital Twin (SoC-DT), a differentiable framework that unifies reaction-diffusion tumor growth models, discrete SoC interventions (surgery, chemotherapy, radiotherapy) along with genomic and demographic personalization to predict post-treatment tumor structure on imaging. An implicit-explicit exponential time-differencing solver, IMEX-SoC, is also proposed, which ensures stability, positivity, and scalability in SoC treatment situations. Evaluated on both synthetic data and real world glioma data, SoC-DT consistently outperforms classical PDE baselines and purely data-driven neural models in predicting tumor dynamics. By bridging mechanistic interpretability with modern differentiable solvers, SoC-DT establishes a principled foundation for patient-specific digital twins in oncology, enabling biologically consistent tumor dynamics estimation. Code will be made available upon acceptance.</li>
</ul>

<h3>Title: Why mask diffusion does not work</h3>
<ul>
<li><strong>Authors: </strong>Haocheng Sun, Cynthia Xin Wen, Edward Hong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03289">https://arxiv.org/abs/2510.03289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03289">https://arxiv.org/pdf/2510.03289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03289]] Why mask diffusion does not work(https://arxiv.org/abs/2510.03289)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The main advantages of diffusion language models over autoregressive (AR) models lie in their ability to support parallel generation and bidirectional attention, enabling a more controllable generation process. In recent years, open-source mask diffusion language models have emerged, most of which are based on a variant known as absorbing diffusion. However, this paper demonstrates why mask diffusion faces inherent difficulties in achieving parallel generation and bidirectional attention. We also propose the most effective training and inference strategies for mask diffusion.</li>
</ul>

<h3>Title: UniPruning: Unifying Local Metric and Global Feedback for Scalable Sparse LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yizhuo Ding, Wanying Qu, Jiawei Geng, Wenqi Shao, Yanwei Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03291">https://arxiv.org/abs/2510.03291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03291">https://arxiv.org/pdf/2510.03291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03291]] UniPruning: Unifying Local Metric and Global Feedback for Scalable Sparse LLMs(https://arxiv.org/abs/2510.03291)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) achieve strong performance across diverse tasks but face prohibitive computational and memory costs. Pruning offers a promising path by inducing sparsity while preserving architectural flexibility. However, existing methods struggle to balance efficiency and robustness: local metric approaches prune layer by layer but often collapse under high sparsity, whereas global feedback methods enforce consistency at the cost of expensive weight updates or restrictive semi-structured formats. We present UniPruning, a unified post-training pruning framework that combines the speed of local saliency metrics with the stability of global coordination, enabled by a mirror descent based optimization, all without updating model weights. UniPruning leverages fast layer-wise scoring and a lightweight global controller to allocate a single sparsity budget, supporting both unstructured and semi-structured N :M pruning within one framework. After a brief calibration, it can generate pruning masks for arbitrary sparsity levels in one shot, and adapts seamlessly to hardware-aware constraints. Extensive experiments on multiple pretrained LLM families and standard benchmarks show that UniPruning consistently delivers competitive or superior perplexity and zero-shot accuracy. Ablation studies further highlight the importance of mirror descent and local saliency anchoring. Overall, UniPruning provides an efficient, principled, and scalable solution for sparsifying large-scale LLMs. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Domain-Robust Marine Plastic Detection Using Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Saanvi Kataria</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03294">https://arxiv.org/abs/2510.03294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03294">https://arxiv.org/pdf/2510.03294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03294]] Domain-Robust Marine Plastic Detection Using Vision Models(https://arxiv.org/abs/2510.03294)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Marine plastic pollution is a pressing environmental threat, making reliable automation for underwater debris detection essential. However, vision systems trained on one dataset often degrade on new imagery due to domain shift. This study benchmarks models for cross-domain robustness, training convolutional neural networks - CNNs (MobileNetV2, ResNet-18, EfficientNet-B0) and vision transformers (DeiT-Tiny, ViT-B16) on a labeled underwater dataset and then evaluates them on a balanced cross-domain test set built from plastic-positive images drawn from a different source and negatives from the training domain. Two zero-shot models were assessed, CLIP ViT-L14 and Google's Gemini 2.0 Flash, that leverage pretraining to classify images without fine-tuning. Results show the lightweight MobileNetV2 delivers the strongest cross-domain performance (F1 0.97), surpassing larger models. All fine-tuned models achieved high Precision (around 99%), but differ in Recall, indicating varying sensitivity to plastic instances. Zero-shot CLIP is comparatively sensitive (Recall around 80%) yet prone to false positives (Precision around 56%), whereas Gemini exhibits the inverse profile (Precision around 99%, Recall around 81%). Error analysis highlights recurring confusions with coral textures, suspended particulates, and specular glare. Overall, compact CNNs with supervised training can generalize effectively for cross-domain underwater detection, while large pretrained vision-language models provide complementary strengths.</li>
</ul>

<h3>Title: Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes</h3>
<ul>
<li><strong>Authors: </strong>Akshar Gothi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03297">https://arxiv.org/abs/2510.03297</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03297">https://arxiv.org/pdf/2510.03297</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03297]] Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes(https://arxiv.org/abs/2510.03297)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a controlled comparison of a convolutional neural network (EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two label-distribution regimes: a naturally imbalanced five-class split and a balanced-resampled split with 700 images per class (70:20:10 train/val/test). With matched preprocessing (224x224, ImageNet normalization), lightweight augmentations, and a 40-epoch budget on a single NVIDIA P100, we report accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics (model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93% test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive at 93% with a larger parameter count and runtime. On the balanced split, both models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains competitive, indicating that balancing narrows architecture gaps while CNNs retain an efficiency edge. We release manifests, logs, and per-image predictions to support reproducibility.</li>
</ul>

<h3>Title: CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual Optimization for On-Device Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dongqi Zheng, Wenjin Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03298">https://arxiv.org/abs/2510.03298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03298">https://arxiv.org/pdf/2510.03298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03298]] CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual Optimization for On-Device Language Models(https://arxiv.org/abs/2510.03298)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We introduce Constraint-Aware Federated Learning with Lagrangian Dual Optimization (CAFL-L), a principled extension of FedAvg that explicitly incorporates device-level resource constraints including energy, communication, memory, and thermal budgets. CAFL-L employs Lagrangian dual optimization to dynamically adapt training hyperparameters -- freezing depth, local steps, batch size, and communication compression -- while preserving training stability through token-budget preservation via gradient accumulation. Experiments on a character-level language model demonstrate that CAFL-L achieves superior constraint satisfaction compared to standard FedAvg (reducing memory usage by 20% and communication by 95%) while maintaining competitive validation performance, making it practical for deployment on resource-constrained edge devices.</li>
</ul>

<h3>Title: Dynamic Meta-Learning for Adaptive XGBoost-Neural Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Arthur Sedek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03301">https://arxiv.org/abs/2510.03301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03301">https://arxiv.org/pdf/2510.03301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03301]] Dynamic Meta-Learning for Adaptive XGBoost-Neural Ensembles(https://arxiv.org/abs/2510.03301)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel adaptive ensemble framework that synergistically combines XGBoost and neural networks through sophisticated meta-learning. The proposed method leverages advanced uncertainty quantification techniques and feature importance integration to dynamically orchestrate model selection and combination. Experimental results demonstrate superior predictive performance and enhanced interpretability across diverse datasets, contributing to the development of more intelligent and flexible machine learning systems.</li>
</ul>

<h3>Title: Revoking Amnesia: RL-based Trajectory Optimization to Resurrect Erased Concepts in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Daiheng Gao, Nanxiang Jiang, Andi Zhang, Shilin Lu, Yufei Tang, Wenbo Zhou, Weiming Zhang, Zhaoxin Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03302">https://arxiv.org/abs/2510.03302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03302">https://arxiv.org/pdf/2510.03302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03302]] Revoking Amnesia: RL-based Trajectory Optimization to Resurrect Erased Concepts in Diffusion Models(https://arxiv.org/abs/2510.03302)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Concept erasure techniques have been widely deployed in T2I diffusion models to prevent inappropriate content generation for safety and copyright considerations. However, as models evolve to next-generation architectures like Flux, established erasure methods (\textit{e.g.}, ESD, UCE, AC) exhibit degraded effectiveness, raising questions about their true mechanisms. Through systematic analysis, we reveal that concept erasure creates only an illusion of ``amnesia": rather than genuine forgetting, these methods bias sampling trajectories away from target concepts, making the erasure fundamentally reversible. This insight motivates the need to distinguish superficial safety from genuine concept removal. In this work, we propose \textbf{RevAm} (\underline{Rev}oking \underline{Am}nesia), an RL-based trajectory optimization framework that resurrects erased concepts by dynamically steering the denoising process without modifying model weights. By adapting Group Relative Policy Optimization (GRPO) to diffusion models, RevAm explores diverse recovery trajectories through trajectory-level rewards, overcoming local optima that limit existing methods. Extensive experiments demonstrate that RevAm achieves superior concept resurrection fidelity while reducing computational time by 10$\times$, exposing critical vulnerabilities in current safety mechanisms and underscoring the need for more robust erasure techniques beyond trajectory manipulation.</li>
</ul>

<h3>Title: Machine Learning Workflows in Climate Modeling: Design Patterns and Insights from Case Studies</h3>
<ul>
<li><strong>Authors: </strong>Tian Zheng, Subashree Venkatasubramanian, Shuolin Li, Amy Braverman, Xinyi Ke, Zhewen Hou, Peter Jin, Samarth Sanjay Agrawal</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.ao-ph, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03305">https://arxiv.org/abs/2510.03305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03305">https://arxiv.org/pdf/2510.03305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03305]] Machine Learning Workflows in Climate Modeling: Design Patterns and Insights from Case Studies(https://arxiv.org/abs/2510.03305)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning has been increasingly applied in climate modeling on system emulation acceleration, data-driven parameter inference, forecasting, and knowledge discovery, addressing challenges such as physical consistency, multi-scale coupling, data sparsity, robust generalization, and integration with scientific workflows. This paper analyzes a series of case studies from applied machine learning research in climate modeling, with a focus on design choices and workflow structure. Rather than reviewing technical details, we aim to synthesize workflow design patterns across diverse projects in ML-enabled climate modeling: from surrogate modeling, ML parameterization, probabilistic programming, to simulation-based inference, and physics-informed transfer learning. We unpack how these workflows are grounded in physical knowledge, informed by simulation data, and designed to integrate observations. We aim to offer a framework for ensuring rigor in scientific machine learning through more transparent model development, critical evaluation, informed adaptation, and reproducibility, and to contribute to lowering the barrier for interdisciplinary collaboration at the interface of data science and climate modeling.</li>
</ul>

<h3>Title: Scaling Laws Revisited: Modeling the Role of Data Quality in Language Model Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Anirudh Subramanyam, Yuxin Chen, Robert L. Grossman</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03313">https://arxiv.org/abs/2510.03313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03313">https://arxiv.org/pdf/2510.03313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03313]] Scaling Laws Revisited: Modeling the Role of Data Quality in Language Model Pretraining(https://arxiv.org/abs/2510.03313)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Scaling laws for language model training traditionally characterize how performance scales with model size and dataset volume. Prior work has explored architecture variants and data treatments such as dataset filtering and noise injection in language model pretraining; however, these studies have not formalized data quality within a principled scaling law. We introduce a dimensionless data-quality parameter Q, and propose a quality-aware scaling law extending the Chinchilla framework to predict loss as a joint function of model size, data volume, and data quality. The law is motivated by an effective-sample-size and information-theoretic view of noisy or redundant corpora, and it admits two practical estimators for Q: (i) a corruption rate proxy and (ii) a deficiency measure. Through synthetic experiments in neural machine translation and autoregressive modeling -- where we systematically control data quality via multiple levels of noise injection and coverage variation -- we show that loss scales predictably with data quality and that higher-quality data can substantially reduce model size and hence compute requirements. Our results demonstrate a sublinear decay of effective data with quality and robustness to moderate data corruption; out-of-sample evaluations further validate the predictive form of the law. Unlike prior empirical analyses, our work establishes an explicit, generalizable law for data quality, offering concrete guidance for balancing data curation effort and model scale in large-scale pretraining.</li>
</ul>

<h3>Title: A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety</h3>
<ul>
<li><strong>Authors: </strong>Shucheng Zhang, Yan Shi, Bingzhang Wang, Yuang Zhang, Muhammad Monjurul Karim, Kehua Chen, Chenxi Liu, Mehrdad Nasri, Yinhai Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03314">https://arxiv.org/abs/2510.03314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03314">https://arxiv.org/pdf/2510.03314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03314]] A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety(https://arxiv.org/abs/2510.03314)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and cyclists, remains a critical global challenge, as conventional infrastructure-based measures often prove inadequate in dynamic urban environments. Recent advances in artificial intelligence (AI), particularly in visual perception and reasoning, open new opportunities for proactive and context-aware VRU protection. However, existing surveys on AI applications for VRUs predominantly focus on detection, offering limited coverage of other vision-based tasks that are essential for comprehensive VRU understanding and protection. This paper presents a state-of-the-art review of recent progress in camera-based AI sensing systems for VRU safety, with an emphasis on developments from the past five years and emerging research trends. We systematically examine four core tasks, namely detection and classification, tracking and reidentification, trajectory prediction, and intent recognition and prediction, which together form the backbone of AI-empowered proactive solutions for VRU protection in intelligent transportation systems. To guide future research, we highlight four major open challenges from the perspectives of data, model, and deployment. By linking advances in visual AI with practical considerations for real-world implementation, this survey aims to provide a foundational reference for the development of next-generation sensing systems to enhance VRU safety.</li>
</ul>

<h3>Title: Decomposing Attention To Find Context-Sensitive Neurons</h3>
<ul>
<li><strong>Authors: </strong>Alex Gibson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03315">https://arxiv.org/abs/2510.03315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03315">https://arxiv.org/pdf/2510.03315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03315]] Decomposing Attention To Find Context-Sensitive Neurons(https://arxiv.org/abs/2510.03315)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study transformer language models, analyzing attention heads whose attention patterns are spread out, and whose attention scores depend weakly on content. We argue that the softmax denominators of these heads are stable when the underlying token distribution is fixed. By sampling softmax denominators from a "calibration text", we can combine together the outputs of multiple such stable heads in the first layer of GPT2-Small, approximating their combined output by a linear summary of the surrounding text. This approximation enables a procedure where from the weights alone - and a single calibration text - we can uncover hundreds of first layer neurons that respond to high-level contextual properties of the surrounding text, including neurons that didn't activate on the calibration text.</li>
</ul>

<h3>Title: The View From Space: Navigating Instrumentation Differences with EOFMs</h3>
<ul>
<li><strong>Authors: </strong>Ryan P. Demilt, Nicholas LaHaye, Karis Tenneson</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03316">https://arxiv.org/abs/2510.03316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03316">https://arxiv.org/pdf/2510.03316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03316]] The View From Space: Navigating Instrumentation Differences with EOFMs(https://arxiv.org/abs/2510.03316)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Earth Observation Foundation Models (EOFMs) have exploded in prevalence as tools for processing the massive volumes of remotely sensed and other earth observation data, and for delivering impact on the many essential earth monitoring tasks. An emerging trend posits using the outputs of pre-trained models as 'embeddings' which summarize high dimensional data to be used for generic tasks such as similarity search and content-specific queries. However, most EOFM models are trained only on single modalities of data and then applied or benchmarked by matching bands across different modalities. It is not clear from existing work what impact diverse sensor architectures have on the internal representations of the present suite of EOFMs. We show in this work that the representation space of EOFMs is highly sensitive to sensor architecture and that understanding this difference gives a vital perspective on the pitfalls of current EOFM design and signals for how to move forward as model developers, users, and a community guided by robust remote-sensing science.</li>
</ul>

<h3>Title: Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring</h3>
<ul>
<li><strong>Authors: </strong>Günel Aghakishiyeva, Jiayi Zhou, Saagar Arya, James David Poling, Holly R. Houliston, Jamie N. Womble, David W. Johnston, Brinnae Bent</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03317">https://arxiv.org/abs/2510.03317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03317">https://arxiv.org/pdf/2510.03317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03317]] Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring(https://arxiv.org/abs/2510.03317)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Ecological monitoring is increasingly automated by vision models, yet opaque predictions limit trust and field adoption. We present an inpainting-guided, perturbation-based explanation technique that produces photorealistic, mask-localized edits that preserve scene context. Unlike masking or blurring, these edits stay in-distribution and reveal which fine-grained morphological cues drive predictions in tasks such as species recognition and trait attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for harbor seal detection in Glacier Bay drone imagery, using Segment-Anything-Model-refined masks to support two interventions: (i) object removal/replacement (e.g., replacing seals with plausible ice/water or boats) and (ii) background replacement with original animals composited onto new scenes. Explanations are assessed by re-scoring perturbed images (flip rate, confidence drop) and by expert review for ecological plausibility and interpretability. The resulting explanations localize diagnostic structures, avoid deletion artifacts common to traditional perturbations, and yield domain-relevant insights that support expert validation and more trustworthy deployment of AI in ecology.</li>
</ul>

<h3>Title: Advances in Medical Image Segmentation: A Comprehensive Survey with a Focus on Lumbar Spine Applications</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Kabil, Ghada Khoriba, Mina Yousef, Essam A. Rashed</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03318">https://arxiv.org/abs/2510.03318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03318">https://arxiv.org/pdf/2510.03318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03318]] Advances in Medical Image Segmentation: A Comprehensive Survey with a Focus on Lumbar Spine Applications(https://arxiv.org/abs/2510.03318)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, interpretability, transformer, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Medical Image Segmentation (MIS) stands as a cornerstone in medical image analysis, playing a pivotal role in precise diagnostics, treatment planning, and monitoring of various medical conditions. This paper presents a comprehensive and systematic survey of MIS methodologies, bridging the gap between traditional image processing techniques and modern deep learning approaches. The survey encompasses thresholding, edge detection, region-based segmentation, clustering algorithms, and model-based techniques while also delving into state-of-the-art deep learning architectures such as Convolutional Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely adopted U-Net and its variants. Moreover, integrating attention mechanisms, semi-supervised learning, generative adversarial networks (GANs), and Transformer-based models is thoroughly explored. In addition to covering established methods, this survey highlights emerging trends, including hybrid architectures, cross-modality learning, federated and distributed learning frameworks, and active learning strategies, which aim to address challenges such as limited labeled datasets, computational complexity, and model generalizability across diverse imaging modalities. Furthermore, a specialized case study on lumbar spine segmentation is presented, offering insights into the challenges and advancements in this relatively underexplored anatomical region. Despite significant progress in the field, critical challenges persist, including dataset bias, domain adaptation, interpretability of deep learning models, and integration into real-world clinical workflows.</li>
</ul>

<h3>Title: SVDefense: Effective Defense against Gradient Inversion Attacks via Singular Value Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Chenxiang Luo, David K.Y. Yau, Qun Song</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03319">https://arxiv.org/abs/2510.03319</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03319">https://arxiv.org/pdf/2510.03319</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03319]] SVDefense: Effective Defense against Gradient Inversion Attacks via Singular Value Decomposition(https://arxiv.org/abs/2510.03319)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enables collaborative model training without sharing raw data but is vulnerable to gradient inversion attacks (GIAs), where adversaries reconstruct private data from shared gradients. Existing defenses either incur impractical computational overhead for embedded platforms or fail to achieve privacy protection and good model utility at the same time. Moreover, many defenses can be easily bypassed by adaptive adversaries who have obtained the defense details. To address these limitations, we propose SVDefense, a novel defense framework against GIAs that leverages the truncated Singular Value Decomposition (SVD) to obfuscate gradient updates. SVDefense introduces three key innovations, a Self-Adaptive Energy Threshold that adapts to client vulnerability, a Channel-Wise Weighted Approximation that selectively preserves essential gradient information for effective model training while enhancing privacy protection, and a Layer-Wise Weighted Aggregation for effective model aggregation under class imbalance. Our extensive evaluation shows that SVDefense outperforms existing defenses across multiple applications, including image classification, human activity recognition, and keyword spotting, by offering robust privacy protection with minimal impact on model accuracy. Furthermore, SVDefense is practical for deployment on various resource-constrained embedded platforms. We will make our code publicly available upon paper acceptance.</li>
</ul>

<h3>Title: Attack logics, not outputs: Towards efficient robustification of deep neural networks by falsifying concept-based properties</h3>
<ul>
<li><strong>Authors: </strong>Raik Dankworth, Gesina Schwalbe</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03320">https://arxiv.org/abs/2510.03320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03320">https://arxiv.org/pdf/2510.03320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03320]] Attack logics, not outputs: Towards efficient robustification of deep neural networks by falsifying concept-based properties(https://arxiv.org/abs/2510.03320)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks (NNs) for computer vision are vulnerable to adversarial attacks, i.e., miniscule malicious changes to inputs may induce unintuitive outputs. One key approach to verify and mitigate such robustness issues is to falsify expected output behavior. This allows, e.g., to locally proof security, or to (re)train NNs on obtained adversarial input examples. Due to the black-box nature of NNs, current attacks only falsify a class of the final output, such as flipping from $\texttt{stop_sign}$ to $\neg\texttt{stop_sign}$. In this short position paper we generalize this to search for generally illogical behavior, as considered in NN verification: falsify constraints (concept-based properties) involving further human-interpretable concepts, like $\texttt{red}\wedge\texttt{octogonal}\rightarrow\texttt{stop_sign}$. For this, an easy implementation of concept-based properties on already trained NNs is proposed using techniques from explainable artificial intelligence. Further, we sketch the theoretical proof that attacks on concept-based properties are expected to have a reduced search space compared to simple class falsification, whilst arguably be more aligned with intuitive robustness targets. As an outlook to this work in progress we hypothesize that this approach has potential to efficiently and simultaneously improve logical compliance and robustness.</li>
</ul>

<h3>Title: Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision</h3>
<ul>
<li><strong>Authors: </strong>Ge Chang, Jinbo Su, Jiacheng Liu, Pengfei Yang, Yuhao Shang, Huiwen Zheng, Hongli Ma, Yan Liang, Yuanchun Li, Yunxin Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03323">https://arxiv.org/abs/2510.03323</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03323">https://arxiv.org/pdf/2510.03323</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03323]] Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision(https://arxiv.org/abs/2510.03323)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A significant portion of real-world data is inherently represented as textual graphs, and integrating these graphs into large language models (LLMs) is promising to enable complex graph-based question answering. However, a key challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e., how to retrieve relevant content from large graphs that is sufficiently informative while remaining compact for the LLM context. Existing retrievers suffer from poor performance since they either rely on shallow embedding similarity or employ interactive retrieving policies that demand excessive data labeling and training cost. To address these issues, we present Graph-$S^3$, an agentic textual graph reasoning framework that employs an LLM-based retriever trained with synthetic stepwise supervision. Instead of rewarding the agent based on the final answers, which may lead to sparse and unstable training signals, we propose to closely evaluate each step of the retriever based on offline-extracted golden subgraphs. Our main techniques include a data synthesis pipeline to extract the golden subgraphs for reward generation and a two-stage training scheme to learn the interactive graph exploration policy based on the synthesized rewards. Based on extensive experiments on three common datasets in comparison with seven strong baselines, our approach achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score. The advantage is even higher in more complicated multi-hop reasoning tasks. Our code will be open-sourced.</li>
</ul>

<h3>Title: DECOR: Deep Embedding Clustering with Orientation Robustness</h3>
<ul>
<li><strong>Authors: </strong>Fiona Victoria Stanley Jothiraj, Arunaggiri Pandian Karunanidhi, Seth A. Eichmeyer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03328">https://arxiv.org/abs/2510.03328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03328">https://arxiv.org/pdf/2510.03328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03328]] DECOR: Deep Embedding Clustering with Orientation Robustness(https://arxiv.org/abs/2510.03328)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In semiconductor manufacturing, early detection of wafer defects is critical for product yield optimization. However, raw wafer data from wafer quality tests are often complex, unlabeled, imbalanced and can contain multiple defects on a single wafer, making it crucial to design clustering methods that remain reliable under such imperfect data conditions. We introduce DECOR, a deep clustering with orientation robustness framework that groups complex defect patterns from wafer maps into consistent clusters. We evaluate our method on the open source MixedWM38 dataset, demonstrating its ability to discover clusters without manual tuning. DECOR explicitly accounts for orientation variations in wafer maps, ensuring that spatially similar defects are consistently clustered regardless of its rotation or alignment. Experiments indicate that our method outperforms existing clustering baseline methods, thus providing a reliable and scalable solution in automated visual inspection systems.</li>
</ul>

<h3>Title: Semantic-Aware Scheduling for GPU Clusters with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zerui Wang, Qinghao Hu, Ana Klimovic, Tianwei Zhang, Yonggang Wen, Peng Sun, Dahua Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03334">https://arxiv.org/abs/2510.03334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03334">https://arxiv.org/pdf/2510.03334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03334]] Semantic-Aware Scheduling for GPU Clusters with Large Language Models(https://arxiv.org/abs/2510.03334)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) schedulers are pivotal in optimizing resource allocation in GPU clusters, but operate with a critical limitation: they are largely blind to the semantic context of the jobs they manage. This forces them to rely on limited metadata, leading to high profiling overhead, unreliable duration estimation, inadequate failure handling, and poor observability. To this end, we propose SchedMate, a framework that bridges this semantic gap by systematically extracting deep insights from overlooked, unstructured data sources: source code, runtime logs, and historical jobs. SchedMate enhances existing schedulers non-intrusively through three LLM-based components. Our implementation integrates seamlessly with existing deep learning schedulers. Evaluations on a 128-GPU physical cluster and extensive simulations on production traces show SchedMate reduces average job completion times by up to 1.91x, substantially enhancing the scheduling performance, demonstrating the critical role of semantic-awareness in modern DL scheduling.</li>
</ul>

<h3>Title: Matching the Optimal Denoiser in Point Cloud Diffusion with (Improved) Rotational Alignment</h3>
<ul>
<li><strong>Authors: </strong>Ameya Daigavane, YuQing Xie, Bodhi P. Vani, Saeed Saremi, Joseph Kleinhenz, Tess Smidt</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03335">https://arxiv.org/abs/2510.03335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03335">https://arxiv.org/pdf/2510.03335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03335]] Matching the Optimal Denoiser in Point Cloud Diffusion with (Improved) Rotational Alignment(https://arxiv.org/abs/2510.03335)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are a popular class of generative models trained to reverse a noising process starting from a target data distribution. Training a diffusion model consists of learning how to denoise noisy samples at different noise levels. When training diffusion models for point clouds such as molecules and proteins, there is often no canonical orientation that can be assigned. To capture this symmetry, the true data samples are often augmented by transforming them with random rotations sampled uniformly over $SO(3)$. Then, the denoised predictions are often rotationally aligned via the Kabsch-Umeyama algorithm to the ground truth samples before computing the loss. However, the effect of this alignment step has not been well studied. Here, we show that the optimal denoiser can be expressed in terms of a matrix Fisher distribution over $SO(3)$. Alignment corresponds to sampling the mode of this distribution, and turns out to be the zeroth order approximation for small noise levels, explaining its effectiveness. We build on this perspective to derive better approximators to the optimal denoiser in the limit of small noise. Our experiments highlight that alignment is often a `good enough' approximation for the noise levels that matter most for training diffusion models.</li>
</ul>

<h3>Title: Pool Me Wisely: On the Effect of Pooling in Transformer-Based Models</h3>
<ul>
<li><strong>Authors: </strong>Sofiane Ennadir, Levente Zólyomi, Oleg Smirnov, Tianze Wang, John Pertoft, Filip Cornell, Lele Cao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03339">https://arxiv.org/abs/2510.03339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03339">https://arxiv.org/pdf/2510.03339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03339]] Pool Me Wisely: On the Effect of Pooling in Transformer-Based Models(https://arxiv.org/abs/2510.03339)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models have become the dominant backbone for sequence modeling, leveraging self-attention to produce contextualized token representations. These are typically aggregated into fixed-size vectors via pooling operations for downstream tasks. While much of the literature has focused on attention mechanisms, the role of pooling remains underexplored despite its critical impact on model behavior. In this paper, we introduce a theoretical framework that rigorously characterizes the expressivity of Transformer-based models equipped with widely used pooling methods by deriving closed-form bounds on their representational capacity and the ability to distinguish similar inputs. Our analysis extends to different variations of attention formulations, demonstrating that these bounds hold across diverse architectural variants. We empirically evaluate pooling strategies across tasks requiring both global and local contextual understanding, spanning three major modalities: computer vision, natural language processing, and time-series analysis. Results reveal consistent trends in how pooling choices affect accuracy, sensitivity, and optimization behavior. Our findings unify theoretical and empirical perspectives, providing practical guidance for selecting or designing pooling mechanisms suited to specific tasks. This work positions pooling as a key architectural component in Transformer models and lays the foundation for more principled model design beyond attention alone.</li>
</ul>

<h3>Title: Learning Pareto-Optimal Pandemic Intervention Policies with MORL</h3>
<ul>
<li><strong>Authors: </strong>Marian Chen, Miri Zilka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, q-bio.PE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03340">https://arxiv.org/abs/2510.03340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03340">https://arxiv.org/pdf/2510.03340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03340]] Learning Pareto-Optimal Pandemic Intervention Policies with MORL(https://arxiv.org/abs/2510.03340)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The COVID-19 pandemic underscored a critical need for intervention strategies that balance disease containment with socioeconomic stability. We approach this challenge by designing a framework for modeling and evaluating disease-spread prevention strategies. Our framework leverages multi-objective reinforcement learning (MORL) - a formulation necessitated by competing objectives - combined with a new stochastic differential equation (SDE) pandemic simulator, calibrated and validated against global COVID-19 data. Our simulator reproduces national-scale pandemic dynamics with orders of magnitude higher fidelity than other models commonly used in reinforcement learning (RL) approaches to pandemic intervention. Training a Pareto-Conditioned Network (PCN) agent on this simulator, we illustrate the direct policy trade-offs between epidemiological control and economic stability for COVID-19. Furthermore, we demonstrate the framework's generality by extending it to pathogens with different epidemiological profiles, such as polio and influenza, and show how these profiles lead the agent to discover fundamentally different intervention policies. To ground our work in contemporary policymaking challenges, we apply the model to measles outbreaks, quantifying how a modest 5% drop in vaccination coverage necessitates significantly more stringent and costly interventions to curb disease spread. This work provides a robust and adaptable framework to support transparent, evidence-based policymaking for mitigating public health crises.</li>
</ul>

<h3>Title: OpusAnimation: Code-Based Dynamic Chart Generation</h3>
<ul>
<li><strong>Authors: </strong>Bozheng Li, Miao Yang, Zhenhan Chen, Jiawang Cao, Mushui Liu, Yi Lu, Yongliang Wu, Bin Zhang, Yangguang Ji, Licheng Tang, Jay Wu, Wenbo Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03341">https://arxiv.org/abs/2510.03341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03341">https://arxiv.org/pdf/2510.03341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03341]] OpusAnimation: Code-Based Dynamic Chart Generation(https://arxiv.org/abs/2510.03341)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dynamic Chart Generation (DCG) involves producing code-rendered animated visualizations as charts. While recent advances in multi-modal large language models (MLLMs) have significantly improved their capability on static chart generation and comprehension, MLLMs' potential for handling dynamic chart generation and understanding remains underexplored. To bridge this research gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first benchmark evaluating MLLM's capability on dynamic chart generation tasks from three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with annotations covering instruction-code-video triplets and QA pairs for both code and video evaluation. Based on DCG-8K, we explored a two-stage training recipe, proposing Joint-Code-Visual Reward for group relative policy optimization to construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking result reveals shortcomings of existing MLLMs in the visual-to-chart task, and our model beats the best open-sourced MLLM with an average 8.31% performance gain across three tasks, and shows on par performance against proprietary models with only 3B parameters, proving the effectiveness of our training recipe. Our code and dataset will be publicly available.</li>
</ul>

<h3>Title: KVComm: Enabling Efficient LLM Communication through Selective KV Sharing</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Shi, Marco Chiesa, Gerald Q. Maguire Jr., Dejan Kostic</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03346">https://arxiv.org/abs/2510.03346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03346">https://arxiv.org/pdf/2510.03346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03346]] KVComm: Enabling Efficient LLM Communication through Selective KV Sharing(https://arxiv.org/abs/2510.03346)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in multi-agent systems, where effective inter-model communication is crucial. Existing communication protocols either rely on natural language, incurring high inference costs and information loss, or on hidden states, which suffer from information concentration bias and inefficiency. To address these limitations, we propose KVComm, a novel communication framework that enables efficient communication between LLMs through selective sharing of KV pairs. KVComm leverages the rich information encoded in the KV pairs while avoiding the pitfalls of hidden states. We introduce a KV layer-wise selection strategy based on attention importance scores with a Gaussian prior to identify the most informative KV pairs for communication. Extensive experiments across diverse tasks and model pairs demonstrate that KVComm achieves comparable performance to the upper-bound method, which directly merges inputs to one model without any communication, while transmitting as few as 30\% of layers' KV pairs. Our study highlights the potential of KV pairs as an effective medium for inter-LLM communication, paving the way for scalable and efficient multi-agent systems.</li>
</ul>

<h3>Title: Visual Odometry with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Vlardimir Yugay, Duy-Kien Nguyen, Theo Gevers, Cees G. M. Snoek, Martin R. Oswald</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03348">https://arxiv.org/abs/2510.03348</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03348">https://arxiv.org/pdf/2510.03348</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03348]] Visual Odometry with Transformers(https://arxiv.org/abs/2510.03348)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Modern monocular visual odometry methods typically combine pre-trained deep learning components with optimization modules, resulting in complex pipelines that rely heavily on camera calibration and hyperparameter tuning, and often struggle in unseen real-world scenarios. Recent large-scale 3D models trained on massive amounts of multi-modal data have partially alleviated these challenges, providing generalizable dense reconstruction and camera pose estimation. Still, they remain limited in handling long videos and providing accurate per-frame estimates, which are required for visual odometry. In this work, we demonstrate that monocular visual odometry can be addressed effectively in an end-to-end manner, thereby eliminating the need for handcrafted components such as bundle adjustment, feature matching, camera calibration, or dense 3D reconstruction. We introduce VoT, short for Visual odometry Transformer, which processes sequences of monocular frames by extracting features and modeling global relationships through temporal and spatial attention. Unlike prior methods, VoT directly predicts camera motion without estimating dense geometry and relies solely on camera poses for supervision. The framework is modular and flexible, allowing seamless integration of various pre-trained encoders as feature extractors. Experimental results demonstrate that VoT scales effectively with larger datasets, benefits substantially from stronger pre-trained backbones, generalizes across diverse camera motions and calibration settings, and outperforms traditional methods while running more than 3 times faster. The code will be released.</li>
</ul>

<h3>Title: AgentCaster: Reasoning-Guided Tornado Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Michael Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03349">https://arxiv.org/abs/2510.03349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03349">https://arxiv.org/pdf/2510.03349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03349]] AgentCaster: Reasoning-Guided Tornado Forecasting(https://arxiv.org/abs/2510.03349)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>There is a growing need to evaluate Large Language Models (LLMs) on complex, high-impact, real-world tasks to assess their true readiness as reasoning agents. To address this gap, we introduce AgentCaster, a contamination-free framework employing multimodal LLMs end-to-end for the challenging, long-horizon task of tornado forecasting. Within AgentCaster, models interpret heterogeneous spatiotemporal data from a high-resolution convection-allowing forecast archive. We assess model performance over a 40-day period featuring diverse historical data, spanning several major tornado outbreaks and including over 500 tornado reports. Each day, models query interactively from a pool of 3,625 forecast maps and 40,125 forecast soundings for a forecast horizon of 12-36 hours. Probabilistic tornado-risk polygon predictions are verified against ground truths derived from geometric comparisons across disjoint risk bands in projected coordinate space. To quantify accuracy, we propose domain-specific TornadoBench and TornadoHallucination metrics, with TornadoBench highly challenging for both LLMs and domain expert human forecasters. Notably, human experts significantly outperform state-of-the-art models, which demonstrate a strong tendency to hallucinate and overpredict risk intensity, struggle with precise geographic placement, and exhibit poor spatiotemporal reasoning in complex, dynamically evolving systems. AgentCaster aims to advance research on improving LLM agents for challenging reasoning tasks in critical domains.</li>
</ul>

<h3>Title: Interpretable Neuropsychiatric Diagnosis via Concept-Guided Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Song Wang, Zhenyu Lei, Zhen Tan, Jundong Li, Javier Rasero, Aiying Zhang, Chirag Agarwal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03351">https://arxiv.org/abs/2510.03351</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03351">https://arxiv.org/pdf/2510.03351</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03351]] Interpretable Neuropsychiatric Diagnosis via Concept-Guided Graph Neural Networks(https://arxiv.org/abs/2510.03351)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Nearly one in five adolescents currently live with a diagnosed mental or behavioral health condition, such as anxiety, depression, or conduct disorder, underscoring the urgency of developing accurate and interpretable diagnostic tools. Resting-state functional magnetic resonance imaging (rs-fMRI) provides a powerful lens into large-scale functional connectivity, where brain regions are modeled as nodes and inter-regional synchrony as edges, offering clinically relevant biomarkers for psychiatric disorders. While prior works use graph neural network (GNN) approaches for disorder prediction, they remain complex black-boxes, limiting their reliability and clinical translation. In this work, we propose CONCEPTNEURO, a concept-based diagnosis framework that leverages large language models (LLMs) and neurobiological domain knowledge to automatically generate, filter, and encode interpretable functional connectivity concepts. Each concept is represented as a structured subgraph linking specific brain regions, which are then passed through a concept classifier. Our design ensures predictions through clinically meaningful connectivity patterns, enabling both interpretability and strong predictive performance. Extensive experiments across multiple psychiatric disorder datasets demonstrate that CONCEPTNEURO-augmented GNNs consistently outperform their vanilla counterparts, improving accuracy while providing transparent, clinically aligned explanations. Furthermore, concept analyses highlight disorder-specific connectivity patterns that align with expert knowledge and suggest new hypotheses for future investigation, establishing CONCEPTNEURO as an interpretable, domain-informed framework for psychiatric disorder diagnosis.</li>
</ul>

<h3>Title: Inference-Time Search using Side Information for Diffusion-based Image Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Mahdi Farahbakhsh, Vishnu Teja Kunde, Dileep Kalathil, Krishna Narayanan, Jean-Francois Chamberland</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03352">https://arxiv.org/abs/2510.03352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03352">https://arxiv.org/pdf/2510.03352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03352]] Inference-Time Search using Side Information for Diffusion-based Image Reconstruction(https://arxiv.org/abs/2510.03352)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as powerful priors for solving inverse problems. However, existing approaches typically overlook side information that could significantly improve reconstruction quality, especially in severely ill-posed settings. In this work, we propose a novel inference-time search algorithm that guides the sampling process using the side information in a manner that balances exploration and exploitation. This enables more accurate and reliable reconstructions, providing an alternative to the gradient-based guidance that is prone to reward-hacking artifacts. Our approach can be seamlessly integrated into a wide range of existing diffusion-based image reconstruction pipelines. Through extensive experiments on a number of inverse problems, such as box inpainting, super-resolution, and various deblurring tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that our approach consistently improves the qualitative and quantitative performance of diffusion-based image reconstruction algorithms. We also show the superior performance of our approach with respect to other baselines, including reward gradient-based guidance algorithms. The code is available at \href{this https URL}{this repository}.</li>
</ul>

<h3>Title: Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges, and Applications</h3>
<ul>
<li><strong>Authors: </strong>Larissa S. Gomes, Gustavo P. Almeida, Bryan U. Moreira, Marco Quiroz, Breno Xavier, Lucas Soares, Stephanie L. Brião, Felipe G. Oliveira, Paulo L. J. Drews-Jr</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03353">https://arxiv.org/abs/2510.03353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03353">https://arxiv.org/pdf/2510.03353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03353]] Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges, and Applications(https://arxiv.org/abs/2510.03353)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Sonar images are relevant for advancing underwater exploration, autonomous navigation, and ecosystem monitoring. However, the progress depends on data availability. The scarcity of publicly available, well-annotated sonar image datasets creates a significant bottleneck for the development of robust machine learning models. This paper presents a comprehensive and concise review of the current landscape of sonar image datasets, seeking not only to catalog existing resources but also to contextualize them, identify gaps, and provide a clear roadmap, serving as a base guide for researchers of any kind who wish to start or advance in the field of underwater acoustic data analysis. We mapped publicly accessible datasets across various sonar modalities, including Side Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS), Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar (DIDSON). An analysis was conducted on applications such as classification, detection, segmentation, and 3D reconstruction. This work focuses on state-of-the-art advancements, incorporating newly released datasets. The findings are synthesized into a master table and a chronological timeline, offering a clear and accessible comparison of characteristics, sizes, and annotation details datasets.</li>
</ul>

<h3>Title: Understanding Transformers for Time Series: Rank Structure, Flow-of-ranks, and Compressibility</h3>
<ul>
<li><strong>Authors: </strong>Annan Yu, Danielle C. Maddix, Boran Han, Xiyuan Zhang, Abdul Fatir Ansari, Oleksandr Shchur, Christos Faloutsos, Andrew Gordon Wilson, Michael W. Mahoney, Yuyang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03358">https://arxiv.org/abs/2510.03358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03358">https://arxiv.org/pdf/2510.03358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03358]] Understanding Transformers for Time Series: Rank Structure, Flow-of-ranks, and Compressibility(https://arxiv.org/abs/2510.03358)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers are widely used across data modalities, and yet the principles distilled from text models often transfer imperfectly to models trained to other modalities. In this paper, we analyze Transformers through the lens of rank structure. Our focus is on the time series setting, where the structural properties of the data differ remarkably from those of text or vision. We show that time-series embeddings, unlike text or vision, exhibit sharply decaying singular value spectra: small patch sizes and smooth continuous mappings concentrate the data into low-rank subspaces. From this, we prove that the associated $Q/K/V$ projections admit accurate low-rank approximations, and that attention layers become compressible in proportion to the decay of the embedding spectrum. We introduce the concept of flow-of-ranks, a phenomenon by which nonlinear mixing across depth inflates the rank, explaining why early layers are most amenable to compression and why ranks grow with depth. Guided by these theoretical and empirical results, we use these insights to compress Chronos, a large time series foundation model, achieving a reduction of $65\%$ in inference time and $81\%$ in memory, without loss of accuracy. Our findings provide principled guidance for allocating width, depth, and heads in time series foundation models, and for exploiting their inherent compressibility.</li>
</ul>

<h3>Title: Provenance Networks: End-to-End Exemplar-Based Explainability</h3>
<ul>
<li><strong>Authors: </strong>Ali Kayyam, Anusha Madan Gopal, M. Anthony Lewis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03361">https://arxiv.org/abs/2510.03361</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03361">https://arxiv.org/pdf/2510.03361</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03361]] Provenance Networks: End-to-End Exemplar-Based Explainability(https://arxiv.org/abs/2510.03361)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We introduce provenance networks, a novel class of neural models designed to provide end-to-end, training-data-driven explainability. Unlike conventional post-hoc methods, provenance networks learn to link each prediction directly to its supporting training examples as part of the model's normal operation, embedding interpretability into the architecture itself. Conceptually, the model operates similarly to a learned KNN, where each output is justified by concrete exemplars weighted by relevance in the feature space. This approach facilitates systematic investigations of the trade-off between memorization and generalization, enables verification of whether a given input was included in the training set, aids in the detection of mislabeled or anomalous data points, enhances resilience to input perturbations, and supports the identification of similar inputs contributing to the generation of a new data point. By jointly optimizing the primary task and the explainability objective, provenance networks offer insights into model behavior that traditional deep networks cannot provide. While the model introduces additional computational cost and currently scales to moderately sized datasets, it provides a complementary approach to existing explainability techniques. In particular, it addresses critical challenges in modern deep learning, including model opaqueness, hallucination, and the assignment of credit to data contributors, thereby improving transparency, robustness, and trustworthiness in neural models.</li>
</ul>

<h3>Title: Unified Unsupervised Anomaly Detection via Matching Cost Filtering</h3>
<ul>
<li><strong>Authors: </strong>Zhe Zhang, Mingxiu Cai, Gaochang Wu, Jing Zhang, Lingqiao Liu, Dacheng Tao, Tianyou Chai, Xiatian Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03363">https://arxiv.org/abs/2510.03363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03363">https://arxiv.org/pdf/2510.03363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03363]] Unified Unsupervised Anomaly Detection via Matching Cost Filtering(https://arxiv.org/abs/2510.03363)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level anomalies using only normal training data, with wide applications such as industrial inspection and medical analysis, where anomalies are scarce due to privacy concerns and cold-start constraints. Existing methods, whether reconstruction-based (restoring normal counterparts) or embedding-based (pretrained representations), fundamentally conduct image- or feature-level matching to generate anomaly maps. Nonetheless, matching noise has been largely overlooked, limiting their detection ability. Beyond earlier focus on unimodal RGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB--3D and RGB--Text, enabled by point cloud sensing and vision--language models. Despite shared challenges, these lines remain largely isolated, hindering a comprehensive understanding and knowledge transfer. In this paper, we advocate unified UAD for both unimodal and multimodal settings in the matching perspective. Under this insight, we present Unified Cost Filtering (UCF), a generic post-hoc refinement framework for refining anomaly cost volume of any UAD model. The cost volume is constructed by matching a test sample against normal samples from the same or different modalities, followed by a learnable filtering module with multi-layer attention guidance from the test sample, mitigating matching noise and highlighting subtle anomalies. Comprehensive experiments on 22 diverse benchmarks demonstrate the efficacy of UCF in enhancing a variety of UAD methods, consistently achieving new state-of-the-art results in both unimodal (RGB) and multimodal (RGB--3D, RGB--Text) UAD scenarios. Code and models will be released at this https URL.</li>
</ul>

<h3>Title: Diffusion-Based, Data-Assimilation-Enabled Super-Resolution of Hub-height Winds</h3>
<ul>
<li><strong>Authors: </strong>Xiaolong Ma, Xu Dong, Ashley Tarrant, Lei Yang, Rao Kotamarthi, Jiali Wang, Feng Yan, Rajkumar Kettimuthu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03364">https://arxiv.org/abs/2510.03364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03364">https://arxiv.org/pdf/2510.03364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03364]] Diffusion-Based, Data-Assimilation-Enabled Super-Resolution of Hub-height Winds(https://arxiv.org/abs/2510.03364)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>High-quality observations of hub-height winds are valuable but sparse in space and time. Simulations are widely available on regular grids but are generally biased and too coarse to inform wind-farm siting or to assess extreme-weather-related risks (e.g., gusts) at infrastructure scales. To fully utilize both data types for generating high-quality, high-resolution hub-height wind speeds (tens to ~100m above ground), this study introduces WindSR, a diffusion model with data assimilation for super-resolution downscaling of hub-height winds. WindSR integrates sparse observational data with simulation fields during downscaling using state-of-the-art diffusion models. A dynamic-radius blending method is introduced to merge observations with simulations, providing conditioning for the diffusion process. Terrain information is incorporated during both training and inference to account for its role as a key driver of winds. Evaluated against convolutional-neural-network and generative-adversarial-network baselines, WindSR outperforms them in both downscaling efficiency and accuracy. Our data assimilation reduces WindSR's model bias by approximately 20% relative to independent observations.</li>
</ul>

<h3>Title: Disentangling Recall and Reasoning in Transformer Models through Layer-wise Attention and Activation Analysis</h3>
<ul>
<li><strong>Authors: </strong>Harshwardhan Fartale, Ashish Kattamuri, Rahul Raja, Arpita Vats, Ishita Prasad, Akshata Kishore Moharir</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03366">https://arxiv.org/abs/2510.03366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03366">https://arxiv.org/pdf/2510.03366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03366]] Disentangling Recall and Reasoning in Transformer Models through Layer-wise Attention and Activation Analysis(https://arxiv.org/abs/2510.03366)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer-based language models excel at both recall (retrieving memorized facts) and reasoning (performing multi-step inference), but whether these abilities rely on distinct internal mechanisms remains unclear. Distinguishing recall from reasoning is crucial for predicting model generalization, designing targeted evaluations, and building safer interventions that affect one ability without disrupting the this http URL approach this question through mechanistic interpretability, using controlled datasets of synthetic linguistic puzzles to probe transformer models at the layer, head, and neuron level. Our pipeline combines activation patching and structured ablations to causally measure component contributions to each task type. Across two model families (Qwen and LLaMA), we find that interventions on distinct layers and attention heads lead to selective impairments: disabling identified "recall circuits" reduces fact-retrieval accuracy by up to 15\% while leaving reasoning intact, whereas disabling "reasoning circuits" reduces multi-step inference by a comparable margin. At the neuron level, we observe task-specific firing patterns, though these effects are less robust, consistent with neuronal this http URL results provide the first causal evidence that recall and reasoning rely on separable but interacting circuits in transformer models. These findings advance mechanistic interpretability by linking circuit-level structure to functional specialization and demonstrate how controlled datasets and causal interventions can yield mechanistic insights into model cognition, informing safer deployment of large language models.</li>
</ul>

<h3>Title: Distributed Low-Communication Training with Decoupled Momentum Optimization</h3>
<ul>
<li><strong>Authors: </strong>Sasho Nedelkoski, Alexander Acker, Odej Kao, Soeren Becker, Dominik Scheinert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03371">https://arxiv.org/abs/2510.03371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03371">https://arxiv.org/pdf/2510.03371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03371]] Distributed Low-Communication Training with Decoupled Momentum Optimization(https://arxiv.org/abs/2510.03371)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The training of large models demands substantial computational resources, typically available only in data centers with high-bandwidth interconnects. However, reducing the reliance on high-bandwidth interconnects between nodes enables the use of distributed compute resources as an alternative to centralized data center training. Building on recent advances in distributed model training, we propose an approach that further reduces communication by combining infrequent synchronizations across distributed model replicas with gradient momentum compression. In particular, we treat the optimizer momentum as a signal and decompose the Nesterov momentum into high- and low-frequency components via the discrete cosine transform (DCT). Only the high-frequency components are synchronized across model replicas every $H$ steps. Empirically, our method achieves up to a $16\times$ reduction in communication compared to the baseline DiLoCo, and it generalizes across architectures, including transformer-based language models and convolutional neural networks for images. Overall, this work advances the feasibility of training large models on distributed nodes with low-bandwidth interconnects.</li>
</ul>

<h3>Title: Conditional Pseudo-Supervised Contrast for Data-Free Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Renrong Shao, Wei Zhang, Jun wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03375">https://arxiv.org/abs/2510.03375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03375">https://arxiv.org/pdf/2510.03375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03375]] Conditional Pseudo-Supervised Contrast for Data-Free Knowledge Distillation(https://arxiv.org/abs/2510.03375)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, data-free, generative</a></li>
<li><strong>Abstract: </strong>Data-free knowledge distillation~(DFKD) is an effective manner to solve model compression and transmission restrictions while retaining privacy protection, which has attracted extensive attention in recent years. Currently, the majority of existing methods utilize a generator to synthesize images to support the distillation. Although the current methods have achieved great success, there are still many issues to be explored. Firstly, the outstanding performance of supervised learning in deep learning drives us to explore a pseudo-supervised paradigm on DFKD. Secondly, current synthesized methods cannot distinguish the distributions of different categories of samples, thus producing ambiguous samples that may lead to an incorrect evaluation by the teacher. Besides, current methods cannot optimize the category-wise diversity samples, which will hinder the student model learning from diverse samples and further achieving better performance. In this paper, to address the above limitations, we propose a novel learning paradigm, i.e., conditional pseudo-supervised contrast for data-free knowledge distillation~(CPSC-DFKD). The primary innovations of CPSC-DFKD are: (1) introducing a conditional generative adversarial network to synthesize category-specific diverse images for pseudo-supervised learning, (2) improving the modules of the generator to distinguish the distributions of different categories, and (3) proposing pseudo-supervised contrastive learning based on teacher and student views to enhance diversity. Comprehensive experiments on three commonly-used datasets validate the performance lift of both the student and generator brought by CPSC-DFKD. The code is available at this https URL</li>
</ul>

<h3>Title: A Robust Clustered Federated Learning Approach for Non-IID Data with Quantity Skew</h3>
<ul>
<li><strong>Authors: </strong>Michael Ben Ali (IRIT, IRIT-SIG, UT3), Imen Megdiche (IRIT, IRIT-SIG, INUC), André Peninou (IRIT, IRIT-SIG, UT2J), Olivier Teste (IRIT-SIG, IRIT, UT2J, Comue de Toulouse)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03380">https://arxiv.org/abs/2510.03380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03380">https://arxiv.org/pdf/2510.03380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03380]] A Robust Clustered Federated Learning Approach for Non-IID Data with Quantity Skew(https://arxiv.org/abs/2510.03380)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a decentralized paradigm that enables a client-server architecture to collaboratively train a global Artificial Intelligence model without sharing raw data, thereby preserving privacy. A key challenge in FL is Non-IID data. Quantity Skew (QS) is a particular problem of Non-IID, where clients hold highly heterogeneous data volumes. Clustered Federated Learning (CFL) is an emergent variant of FL that presents a promising solution to Non-IID problem. It improves models' performance by grouping clients with similar data distributions into clusters. CFL methods generally fall into two operating strategies. In the first strategy, clients select the cluster that minimizes the local training loss. In the second strategy, the server groups clients based on local model similarities. However, most CFL methods lack systematic evaluation under QS but present significant challenges because of it.  In this paper, we present two main contributions. The first one is an evaluation of state-of-the-art CFL algorithms under various Non-IID settings, applying multiple QS scenarios to assess their robustness. Our second contribution is a novel iterative CFL algorithm, named CORNFLQS, which proposes an optimal coordination between both operating strategies of CFL. Our approach is robust against the different variations of QS settings. We conducted intensive experiments on six image classification datasets, resulting in 270 Non-IID configurations. The results show that CORNFLQS achieves the highest average ranking in both accuracy and clustering quality, as well as strong robustness to QS perturbations. Overall, our approach outperforms actual CFL algorithms.</li>
</ul>

<h3>Title: Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks</h3>
<ul>
<li><strong>Authors: </strong>Arjun Arunasalam, Madison Pickering, Z. Berkay Celik, Blase Ur</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03384">https://arxiv.org/abs/2510.03384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03384">https://arxiv.org/pdf/2510.03384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03384]] Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks(https://arxiv.org/abs/2510.03384)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can underpin AI assistants that help users with everyday tasks, such as by making recommendations or performing basic computation. Despite AI assistants' promise, little is known about the implicit values these assistants display while completing subjective everyday tasks. Humans may consider values like environmentalism, charity, and diversity. To what extent do LLMs exhibit these values in completing everyday tasks? How do they compare with humans? We answer these questions by auditing how six popular LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human crowdworkers from the US. We find LLMs often do not align with humans, nor with other LLMs, in the implicit values exhibited.</li>
</ul>

<h3>Title: Studying the Korean Word-Chain Game with RLVR:Mitigating Reward Conflicts via Curriculum Learning</h3>
<ul>
<li><strong>Authors: </strong>Donghwan Rho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03394">https://arxiv.org/abs/2510.03394</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03394">https://arxiv.org/pdf/2510.03394</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03394]] Studying the Korean Word-Chain Game with RLVR:Mitigating Reward Conflicts via Curriculum Learning(https://arxiv.org/abs/2510.03394)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards (RLVR) is a promising approach for training large language models (LLMs) with stronger reasoning abilities. It has also been applied to a variety of logic puzzles. In this work, we study the Korean word-chain game using RLVR. We show that rule-derived rewards can naturally conflict, and demonstrate through experiments that a curriculum-learning scheme mitigates these conflicts. Our findings motivate further studies of puzzle tasks in diverse languages.</li>
</ul>

<h3>Title: Security Analysis and Threat Modeling of Research Management Applications [Extended Version]</h3>
<ul>
<li><strong>Authors: </strong>Boniface M. Sindala, Ragib Hasan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03407">https://arxiv.org/abs/2510.03407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03407">https://arxiv.org/pdf/2510.03407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03407]] Security Analysis and Threat Modeling of Research Management Applications [Extended Version](https://arxiv.org/abs/2510.03407)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack</a></li>
<li><strong>Abstract: </strong>Research management applications (RMA) are widely used in clinical research environments to collect, transmit, analyze, and store sensitive data. This data is so valuable making RMAs susceptible to security threats. This analysis, analyzes RMAs' security, focusing on Research Electronic Data Capture (REDCap) as an example. We explore the strengths and vulnerabilities within RMAs by evaluating the architecture, data flow, and security features. We identify and assess potential risks using the MITRE ATT\&CK framework and STRIDE model. We assess REDCap's defenses against common attack vectors focusing on security to provide confidentiality, integrity, availability, non-repudiation, and authentication. We conclude by proposing recommendations for enhancing the security of RMAs, ensuring that critical research data remains protected without compromising usability. This research aims to contribute towards a more secure framework for managing sensitive information in research-intensive environments.</li>
</ul>

<h3>Title: Training Variation of Physically-Informed Deep Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Ashley Lenau, Dennis Dimiduk, Stephen R. Niezgoda</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03416">https://arxiv.org/abs/2510.03416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03416">https://arxiv.org/pdf/2510.03416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03416]] Training Variation of Physically-Informed Deep Learning Models(https://arxiv.org/abs/2510.03416)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>A successful deep learning network is highly dependent not only on the training dataset, but the training algorithm used to condition the network for a given task. The loss function, dataset, and tuning of hyperparameters all play an essential role in training a network, yet there is not much discussion on the reliability or reproducibility of a training algorithm. With the rise in popularity of physics-informed loss functions, this raises the question of how reliable one's loss function is in conditioning a network to enforce a particular boundary condition. Reporting the model variation is needed to assess a loss function's ability to consistently train a network to obey a given boundary condition, and provides a fairer comparison among different methods. In this work, a Pix2Pix network predicting the stress fields of high elastic contrast composites is used as a case study. Several different loss functions enforcing stress equilibrium are implemented, with each displaying different levels of variation in convergence, accuracy, and enforcing stress equilibrium across many training sessions. Suggested practices in reporting model variation are also shared.</li>
</ul>

<h3>Title: NEXUS: Network Exploration for eXploiting Unsafe Sequences in Multi-Turn LLM Jailbreaks</h3>
<ul>
<li><strong>Authors: </strong>Javad Rafiei Asl, Sidhant Narula, Mohammad Ghasemigol, Eduardo Blanco, Daniel Takabi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03417">https://arxiv.org/abs/2510.03417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03417">https://arxiv.org/pdf/2510.03417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03417]] NEXUS: Network Exploration for eXploiting Unsafe Sequences in Multi-Turn LLM Jailbreaks(https://arxiv.org/abs/2510.03417)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have revolutionized natural language processing but remain vulnerable to jailbreak attacks, especially multi-turn jailbreaks that distribute malicious intent across benign exchanges and bypass alignment mechanisms. Existing approaches often explore the adversarial space poorly, rely on hand-crafted heuristics, or lack systematic query refinement. We present NEXUS (Network Exploration for eXploiting Unsafe Sequences), a modular framework for constructing, refining, and executing optimized multi-turn attacks. NEXUS comprises: (1) ThoughtNet, which hierarchically expands a harmful intent into a structured semantic network of topics, entities, and query chains; (2) a feedback-driven Simulator that iteratively refines and prunes these chains through attacker-victim-judge LLM collaboration using harmfulness and semantic-similarity benchmarks; and (3) a Network Traverser that adaptively navigates the refined query space for real-time attacks. This pipeline uncovers stealthy, high-success adversarial paths across LLMs. On several closed-source and open-source LLMs, NEXUS increases attack success rate by 2.1% to 19.4% over prior methods. Code: this https URL</li>
</ul>

<h3>Title: Multi-task neural diffusion processes for uncertainty-quantified wind power prediction</h3>
<ul>
<li><strong>Authors: </strong>Joseph Rawson, Domniki Ladopoulou, Petros Dellaportas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03419">https://arxiv.org/abs/2510.03419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03419">https://arxiv.org/pdf/2510.03419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03419]] Multi-task neural diffusion processes for uncertainty-quantified wind power prediction(https://arxiv.org/abs/2510.03419)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Uncertainty-aware wind power prediction is essential for grid integration and reliable wind farm operation. We apply neural diffusion processes (NDPs)-a recent class of models that learn distributions over functions-and extend them to a multi-task NDP (MT-NDP) framework for wind power prediction. We provide the first empirical evaluation of NDPs in real supervisory control and data acquisition (SCADA) data. We introduce a task encoder within MT-NDPs to capture cross-turbine correlations and enable few-shot adaptation to unseen turbines. The proposed MT-NDP framework outperforms single-task NDPs and GPs in terms of point accuracy and calibration, particularly for wind turbines whose behaviour deviates from the fleet average. In general, NDP-based models deliver calibrated and scalable predictions suitable for operational deployment, offering sharper, yet trustworthy, predictive intervals that can support dispatch and maintenance decisions in modern wind farms.</li>
</ul>

<h3>Title: Memory-Efficient Backpropagation for Fine-Tuning LLMs on Resource-Constrained Mobile Devices</h3>
<ul>
<li><strong>Authors: </strong>Congzheng Song, Xinyu Tang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03425">https://arxiv.org/abs/2510.03425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03425">https://arxiv.org/pdf/2510.03425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03425]] Memory-Efficient Backpropagation for Fine-Tuning LLMs on Resource-Constrained Mobile Devices(https://arxiv.org/abs/2510.03425)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) with backpropagation\textemdash even for a subset of parameters such as LoRA\textemdash can be much more memory-consuming than inference and is often deemed impractical for resource-constrained mobile devices. Alternative methods, such as zeroth-order optimization (ZO), can greatly reduce the memory footprint but come at the cost of significantly slower model convergence (10$\times$ to 100$\times$ more steps than backpropagation). We propose a memory-efficient implementation of backpropagation (MeBP) on mobile devices that provides better trade-off between memory usage and compute time, while converging faster and achieving better performance than the ZO baseline. We verify the effectiveness of MeBP on an iPhone 15 Pro Max and show that various LLMs, ranging from 0.5B to 4B parameters, can be fine-tuned using less than 1GB of memory. We release an example of the MeBP implementation at this https URL.</li>
</ul>

<h3>Title: Generalized Orders of Magnitude for Scalable, Parallel, High-Dynamic-Range Computation</h3>
<ul>
<li><strong>Authors: </strong>Franz A. Heinsen, Leo Kozachkov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03426">https://arxiv.org/abs/2510.03426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03426">https://arxiv.org/pdf/2510.03426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03426]] Generalized Orders of Magnitude for Scalable, Parallel, High-Dynamic-Range Computation(https://arxiv.org/abs/2510.03426)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Many domains, from deep learning to finance, require compounding real numbers over long sequences, often leading to catastrophic numerical underflow or overflow. We introduce generalized orders of magnitude (GOOMs), a principled extension of traditional orders of magnitude that incorporates floating-point numbers as a special case, and which in practice enables stable computation over significantly larger dynamic ranges of real numbers than previously possible. We implement GOOMs, along with an efficient custom parallel prefix scan, to support native execution on parallel hardware such as GPUs. We demonstrate that our implementation of GOOMs outperforms traditional approaches with three representative experiments, all of which were previously considered impractical or impossible, and now become possible and practical: (1) compounding real matrix products far beyond standard floating-point limits; (2) estimating spectra of Lyapunov exponents in parallel, orders of magnitude faster than with previous methods, applying a novel selective-resetting method to prevent state colinearity; and (3) capturing long-range dependencies in deep recurrent neural networks with non-diagonal recurrent states, computed in parallel via a prefix scan, without requiring any form of stabilization. Our results show that our implementation of GOOMs, combined with efficient parallel scanning, offers a scalable and numerically robust alternative to conventional floating-point numbers for high-dynamic-range applications.</li>
</ul>

<h3>Title: LHGEL: Large Heterogeneous Graph Ensemble Learning using Batch View Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Shen, Yufei Jin, Yi He, Xingquan Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03432">https://arxiv.org/abs/2510.03432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03432">https://arxiv.org/pdf/2510.03432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03432]] LHGEL: Large Heterogeneous Graph Ensemble Learning using Batch View Aggregation(https://arxiv.org/abs/2510.03432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning from large heterogeneous graphs presents significant challenges due to the scale of networks, heterogeneity in node and edge types, variations in nodal features, and complex local neighborhood structures. This paper advocates for ensemble learning as a natural solution to this problem, whereby training multiple graph learners under distinct sampling conditions, the ensemble inherently captures different aspects of graph heterogeneity. Yet, the crux lies in combining these learners to meet global optimization objective while maintaining computational efficiency on large-scale graphs. In response, we propose LHGEL, an ensemble framework that addresses these challenges through batch sampling with three key components, namely batch view aggregation, residual attention, and diversity regularization. Specifically, batch view aggregation samples subgraphs and forms multiple graph views, while residual attention adaptively weights the contributions of these views to guide node embeddings toward informative subgraphs, thereby improving the accuracy of base learners. Diversity regularization encourages representational disparity across embedding matrices derived from different views, promoting model diversity and ensemble robustness. Our theoretical study demonstrates that residual attention mitigates gradient vanishing issues commonly faced in ensemble learning. Empirical results on five real heterogeneous networks validate that our LHGEL approach consistently outperforms its state-of-the-art competitors by substantial margin. Codes and datasets are available at this https URL.</li>
</ul>

<h3>Title: Consistent Kernel Change-Point Detection under m-Dependence for Text Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jairo Diaz-Rodriguez, Mumin Jia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03437">https://arxiv.org/abs/2510.03437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03437">https://arxiv.org/pdf/2510.03437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03437]] Consistent Kernel Change-Point Detection under m-Dependence for Text Segmentation(https://arxiv.org/abs/2510.03437)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Kernel change-point detection (KCPD) has become a widely used tool for identifying structural changes in complex data. While existing theory establishes consistency under independence assumptions, real-world sequential data such as text exhibits strong dependencies. We establish new guarantees for KCPD under $m$-dependent data: specifically, we prove consistency in the number of detected change points and weak consistency in their locations under mild additional assumptions. We perform an LLM-based simulation that generates synthetic $m$-dependent text to validate the asymptotics. To complement these results, we present the first comprehensive empirical study of KCPD for text segmentation with modern embeddings. Across diverse text datasets, KCPD with text embeddings outperforms baselines in standard text segmentation metrics. We demonstrate through a case study on Taylor Swift's tweets that KCPD not only provides strong theoretical and simulated reliability but also practical effectiveness for text segmentation tasks.</li>
</ul>

<h3>Title: The Argument is the Explanation: Structured Argumentation for Trust in Agents</h3>
<ul>
<li><strong>Authors: </strong>Ege Cakar, Per Ola Kristensson</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03442">https://arxiv.org/abs/2510.03442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03442">https://arxiv.org/pdf/2510.03442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03442]] The Argument is the Explanation: Structured Argumentation for Trust in Agents(https://arxiv.org/abs/2510.03442)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Humans are black boxes -- we cannot observe their neural processes, yet society functions by evaluating verifiable arguments. AI explainability should follow this principle: stakeholders need verifiable reasoning chains, not mechanistic transparency. We propose using structured argumentation to provide a level of explanation and verification neither interpretability nor LLM-generated explanation is able to offer. Our pipeline achieves state-of-the-art 94.44 macro F1 on the AAEC published train/test split (5.7 points above prior work) and $0.81$ macro F1, $\sim$0.07 above previous published results with comparable data setups, for Argumentative MicroTexts relation classification, converting LLM text into argument graphs and enabling verification at each inferential step. We demonstrate this idea on multi-agent risk assessment using the Structured What-If Technique, where specialized agents collaborate transparently to carry out risk assessment otherwise achieved by humans alone. Using Bipolar Assumption-Based Argumentation, we capture support/attack relationships, thereby enabling automatic hallucination detection via fact nodes attacking arguments. We also provide a verification mechanism that enables iterative refinement through test-time feedback without retraining. For easy deployment, we provide a Docker container for the fine-tuned AMT model, and the rest of the code with the Bipolar ABA Python package on GitHub.</li>
</ul>

<h3>Title: PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology</h3>
<ul>
<li><strong>Authors: </strong>Sejuti Majumder, Saarthak Kapse, Moinak Bhattacharya, Xuan Xu, Alisa Yurovsky, Prateek Prasanna</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03455">https://arxiv.org/abs/2510.03455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03455">https://arxiv.org/pdf/2510.03455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03455]] PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology(https://arxiv.org/abs/2510.03455)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Integrating histopathology with spatial transcriptomics (ST) provides a powerful opportunity to link tissue morphology with molecular function. Yet most existing multimodal approaches rely on a small set of highly variable genes, which limits predictive scope and overlooks the coordinated biological programs that shape tissue phenotypes. We present PEaRL (Pathway Enhanced Representation Learning), a multimodal framework that represents transcriptomics through pathway activation scores computed with ssGSEA. By encoding biologically coherent pathway signals with a transformer and aligning them with histology features via contrastive learning, PEaRL reduces dimensionality, improves interpretability, and strengthens cross-modal correspondence. Across three cancer ST datasets (breast, skin, and lymph node), PEaRL consistently outperforms SOTA methods, yielding higher accuracy for both gene- and pathway-level expression prediction (up to 58.9 percent and 20.4 percent increase in Pearson correlation coefficient compared to SOTA). These results demonstrate that grounding transcriptomic representation in pathways produces more biologically faithful and interpretable multimodal models, advancing computational pathology beyond gene-level embeddings.</li>
</ul>

<h3>Title: On residual network depth</h3>
<ul>
<li><strong>Authors: </strong>Benoit Dherin, Michael Munn</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03470">https://arxiv.org/abs/2510.03470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03470">https://arxiv.org/pdf/2510.03470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03470]] On residual network depth(https://arxiv.org/abs/2510.03470)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Deep residual architectures, such as ResNet and the Transformer, have enabled models of unprecedented depth, yet a formal understanding of why depth is so effective remains an open question. A popular intuition, following Veit et al. (2016), is that these residual networks behave like ensembles of many shallower models. Our key finding is an explicit analytical formula that verifies this ensemble perspective, proving that increasing network depth is mathematically equivalent to expanding the size of this implicit ensemble. Furthermore, our expansion reveals a hierarchical ensemble structure in which the combinatorial growth of computation paths leads to an explosion in the output signal, explaining the historical necessity of normalization layers in training deep models. This insight offers a first principles explanation for the historical dependence on normalization layers and sheds new light on a family of successful normalization-free techniques like SkipInit and Fixup. However, while these previous approaches infer scaling factors through optimizer analysis or a heuristic analogy to Batch Normalization, our work offers the first explanation derived directly from the network's inherent functional structure. Specifically, our Residual Expansion Theorem reveals that scaling each residual module provides a principled solution to taming the combinatorial explosion inherent to these architectures. We further show that this scaling acts as a capacity controls that also implicitly regularizes the model's complexity.</li>
</ul>

<h3>Title: DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical Image Segmentation and Prognosis</h3>
<ul>
<li><strong>Authors: </strong>Numan Saeed, Tausifa Jan Saleem, Fadillah Maani, Muhammad Ridzuan, Hu Wang, Mohammad Yaqub</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03483">https://arxiv.org/abs/2510.03483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03483">https://arxiv.org/pdf/2510.03483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03483]] DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical Image Segmentation and Prognosis(https://arxiv.org/abs/2510.03483)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning for medical imaging is hampered by task-specific models that lack generalizability and prognostic capabilities, while existing 'universal' approaches suffer from simplistic conditioning and poor medical semantic understanding. To address these limitations, we introduce DuPLUS, a deep learning framework for efficient multi-modal medical image analysis. DuPLUS introduces a novel vision-language framework that leverages hierarchical semantic prompts for fine-grained control over the analysis task, a capability absent in prior universal models. To enable extensibility to other medical tasks, it includes a hierarchical, text-controlled architecture driven by a unique dual-prompt mechanism. For segmentation, DuPLUS is able to generalize across three imaging modalities, ten different anatomically various medical datasets, encompassing more than 30 organs and tumor types. It outperforms the state-of-the-art task specific and universal models on 8 out of 10 datasets. We demonstrate extensibility of its text-controlled architecture by seamless integration of electronic health record (EHR) data for prognosis prediction, and on a head and neck cancer dataset, DuPLUS achieved a Concordance Index (CI) of 0.69. Parameter-efficient fine-tuning enables rapid adaptation to new tasks and modalities from varying centers, establishing DuPLUS as a versatile and clinically relevant solution for medical image analysis. The code for this work is made available at: this https URL</li>
</ul>

<h3>Title: SEER: The Span-based Emotion Evidence Retrieval Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Aneesha Sampath, Oya Aran, Emily Mower Provost</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03490">https://arxiv.org/abs/2510.03490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03490">https://arxiv.org/pdf/2510.03490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03490]] SEER: The Span-based Emotion Evidence Retrieval Benchmark(https://arxiv.org/abs/2510.03490)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to test Large Language Models' (LLMs) ability to identify the specific spans of text that express emotion. Unlike traditional emotion recognition tasks that assign a single label to an entire sentence, SEER targets the underexplored task of emotion evidence detection: pinpointing which exact phrases convey emotion. This span-level approach is crucial for applications like empathetic dialogue and clinical support, which need to know how emotion is expressed, not just what the emotion is. SEER includes two tasks: identifying emotion evidence within a single sentence, and identifying evidence across a short passage of five consecutive sentences. It contains new annotations for both emotion and emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs and find that, while some models approach average human performance on single-sentence inputs, their accuracy degrades in longer passages. Our error analysis reveals key failure modes, including overreliance on emotion keywords and false positives in neutral text.</li>
</ul>

<h3>Title: Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms</h3>
<ul>
<li><strong>Authors: </strong>Lyes Saad Saoud, Loic Lesobre, Enrico Sorato, Irfan Hussain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03501">https://arxiv.org/abs/2510.03501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03501">https://arxiv.org/pdf/2510.03501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03501]] Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms(https://arxiv.org/abs/2510.03501)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Real-time animal detection and segmentation in natural environments are vital for wildlife conservation, enabling non-invasive monitoring through remote camera streams. However, these tasks remain challenging due to limited computational resources and the cryptic appearance of many species. We propose a mobile-optimized two-stage deep learning framework that integrates a Threading Detection Model (TDM) to parallelize YOLOv10-based detection and MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach improves real-time performance by reducing latency through threading. YOLOv10 handles detection while MobileSAM performs lightweight segmentation, both executed concurrently for efficient resource use. On the cryptic Houbara Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627, mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10 operates at 43.7 ms per frame, confirming real-time readiness. We introduce a curated Houbara dataset of 40,000 annotated images to support model training and evaluation across diverse conditions. The code and dataset used in this study are publicly available on GitHub at this https URL. For interactive demos and additional resources, visit this https URL.</li>
</ul>

<h3>Title: D2 Actor Critic: Diffusion Actor Meets Distributional Critic</h3>
<ul>
<li><strong>Authors: </strong>Lunjun Zhang, Shuo Han, Hanrui Lyu, Bradly C Stadie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03508">https://arxiv.org/abs/2510.03508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03508">https://arxiv.org/pdf/2510.03508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03508]] D2 Actor Critic: Diffusion Actor Meets Distributional Critic(https://arxiv.org/abs/2510.03508)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>We introduce D2AC, a new model-free reinforcement learning (RL) algorithm designed to train expressive diffusion policies online effectively. At its core is a policy improvement objective that avoids the high variance of typical policy gradients and the complexity of backpropagation through time. This stable learning process is critically enabled by our second contribution: a robust distributional critic, which we design through a fusion of distributional RL and clipped double Q-learning. The resulting algorithm is highly effective, achieving state-of-the-art performance on a benchmark of eighteen hard RL tasks, including Humanoid, Dog, and Shadow Hand domains, spanning both dense-reward and goal-conditioned RL scenarios. Beyond standard benchmarks, we also evaluate a biologically motivated predator-prey task to examine the behavioral robustness and generalization capacity of our approach.</li>
</ul>

<h3>Title: Platonic Transformers: A Solid Choice For Equivariance</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mohaiminul Islam, Rishabh Anand, David R. Wessels, Friso de Kruiff, Thijs P. Kuipers, Rex Ying, Clara I. Sánchez, Sharvaree Vadgama, Georg Bökman, Erik J. Bekkers</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03511">https://arxiv.org/abs/2510.03511</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03511">https://arxiv.org/pdf/2510.03511</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03511]] Platonic Transformers: A Solid Choice For Equivariance(https://arxiv.org/abs/2510.03511)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While widespread, Transformers lack inductive biases for geometric symmetries common in science and computer vision. Existing equivariant methods often sacrifice the efficiency and flexibility that make Transformers so effective through complex, computationally intensive designs. We introduce the Platonic Transformer to resolve this trade-off. By defining attention relative to reference frames from the Platonic solid symmetry groups, our method induces a principled weight-sharing scheme. This enables combined equivariance to continuous translations and Platonic symmetries, while preserving the exact architecture and computational cost of a standard Transformer. Furthermore, we show that this attention is formally equivalent to a dynamic group convolution, which reveals that the model learns adaptive geometric filters and enables a highly scalable, linear-time convolutional variant. Across diverse benchmarks in computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular property prediction (QM9, OMol25), the Platonic Transformer achieves competitive performance by leveraging these geometric constraints at no additional cost.</li>
</ul>

<h3>Title: A Lightweight Federated Learning Approach for Privacy-Preserving Botnet Detection in IoT</h3>
<ul>
<li><strong>Authors: </strong>Taha M. Mahmoud, Naima Kaabouch</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03513">https://arxiv.org/abs/2510.03513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03513">https://arxiv.org/pdf/2510.03513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03513]] A Lightweight Federated Learning Approach for Privacy-Preserving Botnet Detection in IoT(https://arxiv.org/abs/2510.03513)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>The rapid growth of the Internet of Things (IoT) has expanded opportunities for innovation but also increased exposure to botnet-driven cyberattacks. Conventional detection methods often struggle with scalability, privacy, and adaptability in resource-constrained IoT environments. To address these challenges, we present a lightweight and privacy-preserving botnet detection framework based on federated learning. This approach enables distributed devices to collaboratively train models without exchanging raw data, thus maintaining user privacy while preserving detection accuracy. A communication-efficient aggregation strategy is introduced to reduce overhead, ensuring suitability for constrained IoT networks. Experiments on benchmark IoT botnet datasets demonstrate that the framework achieves high detection accuracy while substantially reducing communication costs. These findings highlight federated learning as a practical path toward scalable, secure, and privacy-aware intrusion detection for IoT ecosystems.</li>
</ul>

<h3>Title: TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Fangxu Yu, Hongyu Zhao, Tianyi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03519">https://arxiv.org/abs/2510.03519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03519">https://arxiv.org/pdf/2510.03519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03519]] TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning(https://arxiv.org/abs/2510.03519)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series reasoning is crucial to decision-making in diverse domains, including finance, energy usage, traffic, weather, and scientific discovery. While existing time series foundation models (TSFMs) can capture low-level dynamic patterns and provide accurate forecasting, further analysis usually requires additional background knowledge and sophisticated reasoning, which are lacking in most TSFMs but can be achieved through large language models (LLMs). On the other hand, without expensive post-training, LLMs often struggle with the numerical understanding of time series data. Although it is intuitive to integrate the two types of models, developing effective training recipes that align the two modalities for reasoning tasks is still an open challenge. To this end, we propose TS-Reasoner that aligns the latent representations of TSFMs with the textual inputs of LLMs for downstream understanding/reasoning tasks. Specifically, we propose a simple yet effective method to curate diverse, synthetic pairs of time series and textual captions for alignment training. We then develop a two-stage training recipe that applies instruction finetuning after the alignment pretraining. Unlike existing works that train an LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it during training. Extensive experiments on several benchmarks demonstrate that TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision Language Models (VLMs), and Time Series LLMs, but also achieves this with remarkable data efficiency, e.g., using less than half the training data.</li>
</ul>

<h3>Title: Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kartik Pandit, Sourav Ganguly, Arnesh Banerjee, Shaahin Angizi, Arnob Ghosh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03520">https://arxiv.org/abs/2510.03520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03520">https://arxiv.org/pdf/2510.03520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03520]] Certifiable Safe RLHF: Fixed-Penalty Constraint Optimization for Safer Language Models(https://arxiv.org/abs/2510.03520)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensuring safety is a foundational requirement for large language models (LLMs). Achieving an appropriate balance between enhancing the utility of model outputs and mitigating their potential for harm is a complex and persistent challenge. Contemporary approaches frequently formalize this problem within the framework of Constrained Markov Decision Processes (CMDPs) and employ established CMDP optimization techniques. However, these methods exhibit two notable limitations. First, their reliance on reward and cost functions renders performance highly sensitive to the underlying scoring mechanism, which must capture semantic meaning rather than being triggered by superficial keywords. Second, CMDP-based training entails tuning dual-variable, a process that is both computationally expensive and does not provide any provable safety guarantee for a fixed dual variable that can be exploitable through adversarial jailbreaks. To overcome these limitations, we introduce Certifiable Safe-RLHF (CS-RLHF) that introduces a cost model trained on a large-scale corpus to assign semantically grounded safety scores. In contrast to the lagrangian-based approach, CS-RLHF adopts a rectified penalty-based formulation. This design draws on the theory of exact penalty functions in constrained optimization, wherein constraint satisfaction is enforced directly through a suitably chosen penalty term. With an appropriately scaled penalty, feasibility of the safety constraints can be guaranteed at the optimizer, eliminating the need for dual-variable updates. Empirical evaluation demonstrates that CS-RLHF outperforms state-of-the-art LLM model responses rendering at-least 5 times efficient against nominal and jail-breaking prompts</li>
</ul>

<h3>Title: Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Alajrami, Xingwei Tan, Nikolaos Aletras</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03528">https://arxiv.org/abs/2510.03528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03528">https://arxiv.org/pdf/2510.03528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03528]] Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance(https://arxiv.org/abs/2510.03528)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Instruction-tuning plays a vital role in enhancing the task-solving abilities of large language models (LLMs), improving their usability in generating helpful responses on various tasks. However, previous work has demonstrated that they are sensitive to minor variations in instruction phrasing. In this paper, we explore whether introducing perturbations in instruction-tuning data can enhance LLMs' resistance against noisy instructions. We focus on how instruction-tuning with perturbations, such as removing stop words or shuffling words, affects LLMs' performance on the original and perturbed versions of widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics and potential shifts in model behavior. Surprisingly, our results suggest that instruction-tuning on perturbed instructions can, in some cases, improve downstream performance. These findings highlight the importance of including perturbed instructions in instruction-tuning, which can make LLMs more resilient to noisy user inputs.</li>
</ul>

<h3>Title: TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zhaohan Meng, Zaiqiao Meng, Siwei Liu, Iadh Ounis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03536">https://arxiv.org/abs/2510.03536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03536">https://arxiv.org/pdf/2510.03536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03536]] TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering(https://arxiv.org/abs/2510.03536)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) perform strongly in static and single-turn medical Question Answer (QA) benchmarks, yet such settings diverge from the iterative information gathering process required in practical clinical consultations. The MEDIQ framework addresses this mismatch by recasting the diagnosis as an interactive dialogue between a patient and an expert system, but the reliability of LLMs drops dramatically when forced to reason with dialogue logs, where clinical facts appear in sentences without clear links. To bridge this gap, we introduce TriMediQ, a triplet-structured approach that summarises patient responses into triplets and integrates them into a Knowledge Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet generator that extracts clinically relevant triplets, using prompts designed to ensure factual consistency. In parallel, a trainable projection module, comprising a graph encoder and a projector, captures relational information from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i) the projection module fine-tuning with all LLM weights frozen; and (ii) using the fine-tuned module to guide multi-hop reasoning during inference. We evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset. These results demonstrate that converting patient responses into structured triplet-based graphs enables more accurate clinical reasoning in multi-turn settings, providing a solution for the deployment of LLM-based medical assistants.</li>
</ul>

<h3>Title: Domain Generalization for Semantic Segmentation: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Manuel Schwonberg, Hanno Gottschalk</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03540">https://arxiv.org/abs/2510.03540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03540">https://arxiv.org/pdf/2510.03540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03540]] Domain Generalization for Semantic Segmentation: A Survey(https://arxiv.org/abs/2510.03540)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The generalization of deep neural networks to unknown domains is a major challenge despite their tremendous progress in recent years. For this reason, the dynamic area of domain generalization (DG) has emerged. In contrast to unsupervised domain adaptation, there is no access to or knowledge about the target domains, and DG methods aim to generalize across multiple different unseen target domains. Domain generalization is particularly relevant for the task semantic segmentation which is used in several areas such as biomedicine or automated driving. This survey provides a comprehensive overview of the rapidly evolving topic of domain generalized semantic segmentation. We cluster and review existing approaches and identify the paradigm shift towards foundation-model-based domain generalization. Finally, we provide an extensive performance comparison of all approaches, which highlights the significant influence of foundation models on domain generalization. This survey seeks to advance domain generalization research and inspire scientists to explore new research directions.</li>
</ul>

<h3>Title: What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification</h3>
<ul>
<li><strong>Authors: </strong>Andrew Halterman, Katherine A. Keith</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03541">https://arxiv.org/abs/2510.03541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03541">https://arxiv.org/pdf/2510.03541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03541]] What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification(https://arxiv.org/abs/2510.03541)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Generative large language models (LLMs) are now used extensively for text classification in computational social science (CSS). In this work, focus on the steps before and after LLM prompting -- conceptualization of concepts to be classified and using LLM predictions in downstream statistical inference -- which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can tempt analysts to skip the conceptualization step, creating conceptualization errors that bias downstream estimates. Using simulations, we show that this conceptualization-induced bias cannot be corrected for solely by increasing LLM accuracy or post-hoc bias correction methods. We conclude by reminding CSS analysts that conceptualization is still a first-order concern in the LLM-era and provide concrete advice on how to pursue low-cost, unbiased, low-variance downstream estimates.</li>
</ul>

<h3>Title: A Multi-Layer Electronic and Cyber Interference Model for AI-Driven Cruise Missiles: The Case of Khuzestan Province</h3>
<ul>
<li><strong>Authors: </strong>Pouriya Alimoradi, Ali Barati, Hamid Barati</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03542">https://arxiv.org/abs/2510.03542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03542">https://arxiv.org/pdf/2510.03542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03542]] A Multi-Layer Electronic and Cyber Interference Model for AI-Driven Cruise Missiles: The Case of Khuzestan Province(https://arxiv.org/abs/2510.03542)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>The rapid advancement of Artificial Intelligence has enabled the development of cruise missiles endowed with high levels of autonomy, adaptability, and precision. These AI driven missiles integrating deep learning algorithms, real time data processing, and advanced guidance systems pose critical threats to strategic infrastructures, especially under complex geographic and climatic conditions such as those found in Irans Khuzestan Province. In this paper, we propose a multi layer interference model, encompassing electronic warfare, cyberattacks, and deception strategies, to degrade the performance of AI guided cruise missiles significantly. Our experimental results, derived from 400 simulation runs across four distinct scenarios, demonstrate notable improvements when employing the integrated multi layer approach compared to single layer or no interference baselines. Specifically, the average missile deviation from its intended target increases from 0.25 to 8.65 under multi layer interference a more than 3300 increase in angular deviation. Furthermore, the target acquisition success rate is reduced from 92.7 in the baseline scenario to 31.5, indicating a 66 decrease in successful strikes. While resource consumption for multi layer strategies rises by approximately 25 compared to single layer methods, the significant drop in missile accuracy and reliability justifies the more intensive deployment of jamming power, cyber resources, and decoy measures. Beyond these quantitative improvements, the proposed framework uses a deep reinforcement learning based defense coordinator to adaptively select the optimal configuration of EW, cyber, and deception tactics in real time.</li>
</ul>

<h3>Title: From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy</h3>
<ul>
<li><strong>Authors: </strong>Evandros Kaklamanos, Kristjana Kristinsdottir, Jonathan Huang, Dustin Carlson, Rajesh Keswani, John Pandolfino, Mozziyar Etemadi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03543">https://arxiv.org/abs/2510.03543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03543">https://arxiv.org/pdf/2510.03543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03543]] From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy(https://arxiv.org/abs/2510.03543)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and colonoscopy play a critical role in diagnosing and managing gastrointestinal (GI) disorders. However, the documentation burden associated with these procedures place significant strain on gastroenterologists, contributing to inefficiencies in clinical workflows and physician burnout. To address this challenge, we propose a novel automated report generation model that leverages a transformer-based vision encoder and text decoder within a two-stage training framework. In the first stage, both components are pre-trained on image/text caption pairs to capture generalized vision-language features, followed by fine-tuning on images/report pairs to generate clinically meaningful findings. Our approach not only streamlines the documentation process but also holds promise for reducing physician workload and improving patient care.</li>
</ul>

<h3>Title: SketchPlan: Diffusion Based Drone Planning From Human Sketches</h3>
<ul>
<li><strong>Authors: </strong>Sixten Norelius, Aaron O. Feldman, Mac Schwager</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03545">https://arxiv.org/abs/2510.03545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03545">https://arxiv.org/pdf/2510.03545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03545]] SketchPlan: Diffusion Based Drone Planning From Human Sketches(https://arxiv.org/abs/2510.03545)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We propose SketchPlan, a diffusion-based planner that interprets 2D hand-drawn sketches over depth images to generate 3D flight paths for drone navigation. SketchPlan comprises two components: a SketchAdapter that learns to map the human sketches to projected 2D paths, and DiffPath, a diffusion model that infers 3D trajectories from 2D projections and a first person view depth image. Our model achieves zero-shot sim-to-real transfer, generating accurate and safe flight paths in previously unseen real-world environments. To train the model, we build a synthetic dataset of 32k flight paths using a diverse set of photorealistic 3D Gaussian Splatting scenes. We automatically label the data by computing 2D projections of the 3D flight paths onto the camera plane, and use this to train the DiffPath diffusion model. However, since real human 2D sketches differ significantly from ideal 2D projections, we additionally label 872 of the 3D flight paths with real human sketches and use this to train the SketchAdapter to infer the 2D projection from the human sketch. We demonstrate SketchPlan's effectiveness in both simulated and real-world experiments, and show through ablations that training on a mix of human labeled and auto-labeled data together with a modular design significantly boosts its capabilities to correctly interpret human intent and infer 3D paths. In real-world drone tests, SketchPlan achieved 100\% success in low/medium clutter and 40\% in unseen high-clutter environments, outperforming key ablations by 20-60\% in task completion.</li>
</ul>

<h3>Title: Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing</h3>
<ul>
<li><strong>Authors: </strong>Danial Samadi Vahdati, Tai Duc Nguyen, Ekta Prashnani, Koki Nagano, David Luebke, Orazio Gallo, Matthew Stamm</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03548">https://arxiv.org/abs/2510.03548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03548">https://arxiv.org/pdf/2510.03548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03548]] Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing(https://arxiv.org/abs/2510.03548)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, biometric</a></li>
<li><strong>Abstract: </strong>AI-based talking-head videoconferencing systems reduce bandwidth by sending a compact pose-expression latent and re-synthesizing RGB at the receiver, but this latent can be puppeteered, letting an attacker hijack a victim's likeness in real time. Because every frame is synthetic, deepfake and synthetic video detectors fail outright. To address this security problem, we exploit a key observation: the pose-expression latent inherently contains biometric information of the driving identity. Therefore, we introduce the first biometric leakage defense without ever looking at the reconstructed RGB video: a pose-conditioned, large-margin contrastive encoder that isolates persistent identity cues inside the transmitted latent while cancelling transient pose and expression. A simple cosine test on this disentangled embedding flags illicit identity swaps as the video is rendered. Our experiments on multiple talking-head generation models show that our method consistently outperforms existing puppeteering defenses, operates in real-time, and shows strong generalization to out-of-distribution scenarios.</li>
</ul>

<h3>Title: Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!</h3>
<ul>
<li><strong>Authors: </strong>Junbao Zhou, Yuan Zhou, Kesen Zhao, Qingshan Xu, Beier Zhu, Richang Hong, Hanwang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03550">https://arxiv.org/abs/2510.03550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03550">https://arxiv.org/pdf/2510.03550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03550]] Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!(https://arxiv.org/abs/2510.03550)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Achieving streaming, fine-grained control over the outputs of autoregressive video diffusion models remains challenging, making it difficult to ensure that they consistently align with user expectations. To bridge this gap, we propose \textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new task that enables users to modify generated videos \emph{anytime} on \emph{anything} via fine-grained, interactive drag. Beyond DragVideo and SG-I2V, REVEL unifies drag-style video manipulation as editing and animating video frames with both supporting user-specified translation, deformation, and rotation effects, making drag operations versatile. In resolving REVEL, we observe: \emph{i}) drag-induced perturbations accumulate in latent space, causing severe latent distribution drift that halts the drag process; \emph{ii}) streaming drag is easily disturbed by context frames, thereby yielding visually unnatural outcomes. We thus propose a training-free approach, \textbf{DragStream}, comprising: \emph{i}) an adaptive distribution self-rectification strategy that leverages neighboring frames' statistics to effectively constrain the drift of latent embeddings; \emph{ii}) a spatial-frequency selective optimization mechanism, allowing the model to fully exploit contextual information while mitigating its interference via selectively propagating visual cues along generation. Our method can be seamlessly integrated into existing autoregressive video diffusion models, and extensive experiments firmly demonstrate the effectiveness of our DragStream.</li>
</ul>

<h3>Title: CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Hasibur Rahman, Hanan Salam</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03553">https://arxiv.org/abs/2510.03553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03553">https://arxiv.org/pdf/2510.03553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03553]] CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making(https://arxiv.org/abs/2510.03553)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) are increasingly implicated in interpersonal and societal decision-making, their ability to navigate explicit conflicts between legitimately different cultural value systems remains largely unexamined. Existing benchmarks predominantly target cultural knowledge (CulturalBench), value prediction (WorldValuesBench), or single-axis bias diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple culturally grounded values directly clash. We address this gap with CCD-Bench, a benchmark that assesses LLM decision-making under cross-cultural value conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains, each paired with ten anonymized response options corresponding to the ten GLOBE cultural clusters. These dilemmas are presented using a stratified Latin square to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe (12.4 percent), while options for Eastern Europe and the Middle East and North Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of rationales reference multiple GLOBE dimensions, this pluralism is superficial: models recombine Future Orientation and Performance Orientation, and rarely ground choices in Assertiveness or Gender Egalitarianism (both under 3 percent). Ordering effects are negligible (Cramer's V less than 0.10), and symmetrized KL divergence shows clustering by developer lineage rather than geography. These patterns suggest that current alignment pipelines promote a consensus-oriented worldview that underserves scenarios demanding power negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts evaluation beyond isolated bias detection toward pluralistic decision making and highlights the need for alignment strategies that substantively engage diverse worldviews.</li>
</ul>

<h3>Title: GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Peiran Quan, Zifan Gu, Zhuo Zhao, Qin Zhou, Donghan M. Yang, Ruichen Rong, Yang Xie, Guanghua Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03555">https://arxiv.org/abs/2510.03555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03555">https://arxiv.org/pdf/2510.03555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03555]] GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis(https://arxiv.org/abs/2510.03555)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models (FMs) have transformed computational pathology by providing powerful, general-purpose feature extractors. However, adapting and benchmarking individual FMs for specific diagnostic tasks is often time-consuming and resource-intensive, especially given their scale and diversity. To address this challenge, we introduce Group-Aggregative Selection Multi-Instance Learning (GAS-MIL), a flexible ensemble framework that seamlessly integrates features from multiple FMs, preserving their complementary strengths without requiring manual feature selection or extensive task-specific fine-tuning. Across classification tasks in three cancer datasets-prostate (PANDA), ovarian (UBC-OCEAN), and breast (TCGA-BrCa)-GAS-MIL consistently achieves superior or on-par performance relative to individual FMs and established MIL methods, demonstrating its robustness and generalizability. By enabling efficient integration of heterogeneous FMs, GAS-MIL streamlines model deployment for pathology and provides a scalable foundation for future multimodal and precision oncology applications.</li>
</ul>

<h3>Title: Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted First Aid</h3>
<ul>
<li><strong>Authors: </strong>Shen Chang, Renran Tian, Nicole Adams, Nan Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03558">https://arxiv.org/abs/2510.03558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03558">https://arxiv.org/pdf/2510.03558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03558]] Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted First Aid(https://arxiv.org/abs/2510.03558)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Rapid naloxone delivery via drones offers a promising solution for responding to opioid overdose emergencies (OOEs), by extending lifesaving interventions to medically untrained bystanders before emergency medical services (EMS) arrive. Recognizing the critical role of bystander situational awareness (SA) in human-autonomy teaming (HAT), we address a key research gap in real-time SA assessment by introducing the Drone-Assisted Naloxone Delivery Simulation Dataset (DANDSD). This pioneering dataset captures HAT during simulated OOEs, where college students without medical training act as bystanders tasked with administering intranasal naloxone to a mock overdose victim. Leveraging this dataset, we propose a video-based real-time SA assessment framework that utilizes graph embeddings and transformer models to assess bystander SA in real time. Our approach integrates visual perception and comprehension cues--such as geometric, kinematic, and interaction graph features--and achieves high-performance SA prediction. It also demonstrates strong temporal segmentation accuracy, outperforming the FINCH baseline by 9% in Mean over Frames (MoF) and 5% in Intersection over Union (IoU). This work supports the development of adaptive drone systems capable of guiding bystanders effectively, ultimately improving emergency response outcomes and saving lives.</li>
</ul>

<h3>Title: PrivacyMotiv: Speculative Persona Journeys for Empathic and Motivating Privacy Reviews in UX Design</h3>
<ul>
<li><strong>Authors: </strong>Zeya Chen, Jianing Wen, Ruth Schmidt, Yaxing Yao, Toby Jia-Jun Li, Tianshi Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03559">https://arxiv.org/abs/2510.03559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03559">https://arxiv.org/pdf/2510.03559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03559]] PrivacyMotiv: Speculative Persona Journeys for Empathic and Motivating Privacy Reviews in UX Design(https://arxiv.org/abs/2510.03559)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>UX professionals routinely conduct design reviews, yet privacy concerns are often overlooked -- not only due to limited tools, but more critically because of low intrinsic motivation. Limited privacy knowledge, weak empathy for unexpectedly affected users, and low confidence in identifying harms make it difficult to address risks. We present PrivacyMotiv, an LLM-powered system that supports privacy-oriented design diagnosis by generating speculative personas with UX user journeys centered on individuals vulnerable to privacy risks. Drawing on narrative strategies, the system constructs relatable and attention-drawing scenarios that show how ordinary design choices may cause unintended harms, expanding the scope of privacy reflection in UX. In a within-subjects study with professional UX practitioners (N=16), we compared participants' self-proposed methods with PrivacyMotiv across two privacy review tasks. Results show significant improvements in empathy, intrinsic motivation, and perceived usefulness. This work contributes a promising privacy review approach which addresses the motivational barriers in privacy-aware UX.</li>
</ul>

<h3>Title: Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models</h3>
<ul>
<li><strong>Authors: </strong>Adam Filipek</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03561">https://arxiv.org/abs/2510.03561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03561">https://arxiv.org/pdf/2510.03561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03561]] Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models(https://arxiv.org/abs/2510.03561)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has become the de facto standard for Large Language Models (LLMs), demonstrating remarkable capabilities in language understanding and generation. However, its application in conversational AI is fundamentally constrained by its stateless nature and the quadratic computational complexity ($O(L^2)$) with respect to sequence length $L$. Current models emulate memory by reprocessing an ever-expanding conversation history with each turn, leading to prohibitive costs and latency in long dialogues. This paper introduces the Reactive Transformer (RxT), a novel architecture designed to overcome these limitations by shifting from a data-driven to an event-driven paradigm. RxT processes each conversational turn as a discrete event in real-time, maintaining context in an integrated, fixed-size Short-Term Memory (STM) system. The architecture features a distinct operational cycle where a generator-decoder produces a response based on the current query and the previous memory state, after which a memory-encoder and a dedicated Memory Attention network asynchronously update the STM with a representation of the complete interaction. This design fundamentally alters the scaling dynamics, reducing the total user-facing cost of a conversation from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to the number of interactions $N$. By decoupling response generation from memory updates, RxT achieves low latency, enabling truly real-time, stateful, and economically viable long-form conversations. We validated our architecture with a series of proof-of-concept experiments on synthetic data, demonstrating superior performance and constant-time inference latency compared to a baseline stateless model of comparable size.</li>
</ul>

<h3>Title: CryptOracle: A Modular Framework to Characterize Fully Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Cory Brynds, Parker McLeod, Lauren Caccamise, Asmita Pal, Dewan Saiham, Sazadur Rahman, Joshua San Miguel, Di Wu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03565">https://arxiv.org/abs/2510.03565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03565">https://arxiv.org/pdf/2510.03565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03565]] CryptOracle: A Modular Framework to Characterize Fully Homomorphic Encryption(https://arxiv.org/abs/2510.03565)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>Privacy-preserving machine learning has become an important long-term pursuit in this era of artificial intelligence (AI). Fully Homomorphic Encryption (FHE) is a uniquely promising solution, offering provable privacy and security guarantees. Unfortunately, computational cost is impeding its mass adoption. Modern solutions are up to six orders of magnitude slower than plaintext execution. Understanding and reducing this overhead is essential to the advancement of FHE, particularly as the underlying algorithms evolve rapidly. This paper presents a detailed characterization of OpenFHE, a comprehensive open-source library for FHE, with a particular focus on the CKKS scheme due to its significant potential for AI and machine learning applications. We introduce CryptOracle, a modular evaluation framework comprising (1) a benchmark suite, (2) a hardware profiler, and (3) a predictive performance model. The benchmark suite encompasses OpenFHE kernels at three abstraction levels: workloads, microbenchmarks, and primitives. The profiler is compatible with standard and user-specified security parameters. CryptOracle monitors application performance, captures microarchitectural events, and logs power and energy usage for AMD and Intel systems. These metrics are consumed by a modeling engine to estimate runtime and energy efficiency across different configuration scenarios, with error geomean of $-7.02\%\sim8.40\%$ for runtime and $-9.74\%\sim15.67\%$ for energy. CryptOracle is open source, fully modular, and serves as a shared platform to facilitate the collaborative advancements of applications, algorithms, software, and hardware in FHE. The CryptOracle code can be accessed at this https URL.</li>
</ul>

<h3>Title: CrossLag: Predicting Major Dengue Outbreaks with a Domain Knowledge Informed Transformer</h3>
<ul>
<li><strong>Authors: </strong>Ashwin Prabu, Nhat Thanh Tran, Guofa Zhou, Jack Xin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03566">https://arxiv.org/abs/2510.03566</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03566">https://arxiv.org/pdf/2510.03566</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03566]] CrossLag: Predicting Major Dengue Outbreaks with a Domain Knowledge Informed Transformer(https://arxiv.org/abs/2510.03566)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>A variety of models have been developed to forecast dengue cases to date. However, it remains a challenge to predict major dengue outbreaks that need timely public warnings the most. In this paper, we introduce CrossLag, an environmentally informed attention that allows for the incorporation of lagging endogenous signals behind the significant events in the exogenous data into the architecture of the transformer at low parameter counts. Outbreaks typically lag behind major changes in climate and oceanic anomalies. We use TimeXer, a recent general-purpose transformer distinguishing exogenous-endogenous inputs, as the baseline for this study. Our proposed model outperforms TimeXer by a considerable margin in detecting and predicting major outbreaks in Singapore dengue data over a 24-week prediction window.</li>
</ul>

<h3>Title: Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs</h3>
<ul>
<li><strong>Authors: </strong>Fatmazohra Rezkellah, Ramzi Dakhmouche</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR, cs.CY, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03567">https://arxiv.org/abs/2510.03567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03567">https://arxiv.org/pdf/2510.03567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03567]] Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs(https://arxiv.org/abs/2510.03567)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>With the increasing adoption of Large Language Models (LLMs), more customization is needed to ensure privacy-preserving and safe generation. We address this objective from two critical aspects: unlearning of sensitive information and robustness to jail-breaking attacks. We investigate various constrained optimization formulations that address both aspects in a \emph{unified manner}, by finding the smallest possible interventions on LLM weights that either make a given vocabulary set unreachable or embed the LLM with robustness to tailored attacks by shifting part of the weights to a \emph{safer} region. Beyond unifying two key properties, this approach contrasts with previous work in that it doesn't require an oracle classifier that is typically not available or represents a computational overhead. Surprisingly, we find that the simplest point-wise constraint-based intervention we propose leads to better performance than max-min interventions, while having a lower computational cost. Comparison against state-of-the-art defense methods demonstrates superior performance of the proposed approach.</li>
</ul>

<h3>Title: Longitudinal Flow Matching for Trajectory Modeling</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Mohaiminul Islam, Thijs P. Kuipers, Sharvaree Vadgama, Coen de Vente, Afsana Khan, Clara I. Sánchez, Erik J. Bekkers</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03569">https://arxiv.org/abs/2510.03569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03569">https://arxiv.org/pdf/2510.03569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03569]] Longitudinal Flow Matching for Trajectory Modeling(https://arxiv.org/abs/2510.03569)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models for sequential data often struggle with sparsely sampled and high-dimensional trajectories, typically reducing the learning of dynamics to pairwise transitions. We propose \textit{Interpolative Multi-Marginal Flow Matching} (IMMFM), a framework that learns continuous stochastic dynamics jointly consistent with multiple observed time points. IMMFM employs a piecewise-quadratic interpolation path as a smooth target for flow matching and jointly optimizes drift and a data-driven diffusion coefficient, supported by a theoretical condition for stable learning. This design captures intrinsic stochasticity, handles irregular sparse sampling, and yields subject-specific trajectories. Experiments on synthetic benchmarks and real-world longitudinal neuroimaging datasets show that IMMFM outperforms existing methods in both forecasting accuracy and further downstream tasks.</li>
</ul>

<h3>Title: Generalization of Graph Neural Network Models for Distribution Grid Fault Detection</h3>
<ul>
<li><strong>Authors: </strong>Burak Karabulut, Carlo Manna, Chris Develder</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03571">https://arxiv.org/abs/2510.03571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03571">https://arxiv.org/pdf/2510.03571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03571]] Generalization of Graph Neural Network Models for Distribution Grid Fault Detection(https://arxiv.org/abs/2510.03571)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fault detection in power distribution grids is critical for ensuring system reliability and preventing costly outages. Moreover, fault detection methodologies should remain robust to evolving grid topologies caused by factors such as reconfigurations, equipment failures, and Distributed Energy Resource (DER) integration. Current data-driven state-of-the-art methods use Recurrent Neural Networks (RNNs) for temporal modeling and Graph Neural Networks (GNNs) for spatial learning, in an RNN+GNN pipeline setting (RGNN in short). Specifically, for power system fault diagnosis, Graph Convolutional Networks (GCNs) have been adopted. Yet, various more advanced GNN architectures have been proposed and adopted in domains outside of power systems. In this paper, we set out to systematically and consistently benchmark various GNN architectures in an RNN+GNN pipeline model. Specifically, to the best of our knowledge, we are the first to (i) propose to use GraphSAGE and Graph Attention (GAT, GATv2) in an RGNN for fault diagnosis, and (ii) provide a comprehensive benchmark against earlier proposed RGNN solutions (RGCN) as well as pure RNN models (especially Gated Recurrent Unit (GRU)), particularly (iii) exploring their generalization potential for deployment in different settings than those used for training them. Our experimental results on the IEEE 123-node distribution network show that RGATv2 has superior generalization capabilities, maintaining high performance with an F1-score reduction of $\sim$12% across different topology settings. In contrast, pure RNN models largely fail, experiencing an F1-score reduction of up to $\sim$60%, while other RGNN variants also exhibit significant performance degradation, i.e., up to $\sim$25% lower F1-scores.</li>
</ul>

<h3>Title: LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction</h3>
<ul>
<li><strong>Authors: </strong>Ikram Belmadani, Parisa Nazari Hashemi, Thomas Sebbag, Benoit Favre, Guillaume Fortier, Solen Quiniou, Emmanuel Morin, Richard Dufour</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03577">https://arxiv.org/abs/2510.03577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03577">https://arxiv.org/pdf/2510.03577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03577]] LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction(https://arxiv.org/abs/2510.03577)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This work presents our participation in the EvalLLM 2025 challenge on biomedical Named Entity Recognition (NER) and health event extraction in French (few-shot setting). For NER, we propose three approaches combining large language models (LLMs), annotation guidelines, synthetic data, and post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating automatic selection of 10 examples and a summary of the annotation guidelines into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic corpus and then verified by an LLM in post-processing, and (3) the open LLM LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event extraction uses the same ICL strategy with GPT-4.1, reusing the guideline summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for NER and 15.02% for event extraction, highlighting the importance of well-crafted prompting to maximize performance in very low-resource scenarios.</li>
</ul>

<h3>Title: FieldFormer: Physics-Informed Transformers for Spatio-Temporal Field Reconstruction from Sparse Sensors</h3>
<ul>
<li><strong>Authors: </strong>Ankit Bhardwaj, Ananth Balashankar, Lakshminarayanan Subramanian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03589">https://arxiv.org/abs/2510.03589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03589">https://arxiv.org/pdf/2510.03589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03589]] FieldFormer: Physics-Informed Transformers for Spatio-Temporal Field Reconstruction from Sparse Sensors(https://arxiv.org/abs/2510.03589)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Spatio-temporal sensor data is often sparse, noisy, and irregular, and existing interpolation or learning methods struggle here because they either ignore governing PDEs or do not scale. We introduce FieldFormer, a transformer-based framework for mesh-free spatio-temporal field reconstruction that combines data-driven flexibility with physics-based structure. For each query, FieldFormer gathers a local neighborhood using a learnable velocity-scaled distance metric, enabling anisotropic adaptation to different propagation regimes. Neighborhoods are built efficiently via per-batch offset recomputation, and refined in an expectation-maximization style as the velocity scales evolve. Predictions are made by a local transformer encoder, and physics consistency is enforced through autograd-based PDE residuals and boundary-specific penalties. Across three benchmarks--a scalar anisotropic heat equation, a vector-valued shallow-water system, and a realistic advection-diffusion pollution simulation--FieldFormer consistently outperforms strong baselines by more than 40%. Our results demonstrate that FieldFormer enables accurate (RMSE$<10^{-2}$), efficient, and physically consistent field reconstruction from sparse (0.4%-2%) and noisy(10%) data.</li>
</ul>

<h3>Title: A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games</h3>
<ul>
<li><strong>Authors: </strong>Faliu Yi, Sherif Abdelfattah, Wei Huang, Adrian Brown</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03591">https://arxiv.org/abs/2510.03591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03591">https://arxiv.org/pdf/2510.03591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03591]] A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games(https://arxiv.org/abs/2510.03591)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Manual identification of visual bugs in video games is a resource-intensive and costly process, often demanding specialized domain knowledge. While supervised visual bug detection models offer a promising solution, their reliance on extensive labeled datasets presents a significant challenge due to the infrequent occurrence of such bugs. To overcome this limitation, we propose a hybrid Co-FineTuning (CFT) method that effectively integrates both labeled and unlabeled data. Our approach leverages labeled samples from the target game and diverse co-domain games, additionally incorporating unlabeled data to enhance feature representation learning. This strategy maximizes the utility of all available data, substantially reducing the dependency on labeled examples from the specific target game. The developed framework demonstrates enhanced scalability and adaptability, facilitating efficient visual bug detection across various game titles. Our experimental results show the robustness of the proposed method for game visual bug detection, exhibiting superior performance compared to conventional baselines across multiple gaming environments. Furthermore, CFT maintains competitive performance even when trained with only 50% of the labeled data from the target game.</li>
</ul>

<h3>Title: Deep Reinforcement Learning for Multi-Agent Coordination</h3>
<ul>
<li><strong>Authors: </strong>Kehinde O. Aina, Sehoon Ha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03592">https://arxiv.org/abs/2510.03592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03592">https://arxiv.org/pdf/2510.03592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03592]] Deep Reinforcement Learning for Multi-Agent Coordination(https://arxiv.org/abs/2510.03592)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We address the challenge of coordinating multiple robots in narrow and confined environments, where congestion and interference often hinder collective task performance. Drawing inspiration from insect colonies, which achieve robust coordination through stigmergy -- modifying and interpreting environmental traces -- we propose a Stigmergic Multi-Agent Deep Reinforcement Learning (S-MADRL) framework that leverages virtual pheromones to model local and social interactions, enabling decentralized emergent coordination without explicit communication. To overcome the convergence and scalability limitations of existing algorithms such as MADQN, MADDPG, and MAPPO, we leverage curriculum learning, which decomposes complex tasks into progressively harder sub-problems. Simulation results show that our framework achieves the most effective coordination of up to eight agents, where robots self-organize into asymmetric workload distributions that reduce congestion and modulate group performance. This emergent behavior, analogous to strategies observed in nature, demonstrates a scalable solution for decentralized multi-agent coordination in crowded environments with communication constraints.</li>
</ul>

<h3>Title: Decoupling Task-Solving and Output Formatting in LLM Generation</h3>
<ul>
<li><strong>Authors: </strong>Haikang Deng, Po-Nien Kung, Nanyun Peng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03595">https://arxiv.org/abs/2510.03595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03595">https://arxiv.org/pdf/2510.03595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03595]] Decoupling Task-Solving and Output Formatting in LLM Generation(https://arxiv.org/abs/2510.03595)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly adept at following instructions containing task descriptions to solve complex problems, such as mathematical reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow more complex, models often struggle to adhere to all instructions. This difficulty is especially common when instructive prompts intertwine reasoning directives -- specifying what the model should solve -- with rigid formatting requirements that dictate how the solution must be presented. The entanglement creates competing goals for the model, suggesting that more explicit separation of these two aspects could lead to improved performance. To this front, we introduce Deco-G, a decoding framework that explicitly decouples format adherence from task solving. Deco-G handles format compliance with a separate tractable probabilistic model (TPM), while prompts LLMs with only task instructions. At each decoding step, Deco-G combines next token probabilities from the LLM with the TPM calculated format compliance likelihood to form the output probability. To make this approach both practical and scalable for modern instruction-tuned LLMs, we introduce three key innovations: instruction-aware distillation, a flexible trie-building algorithm, and HMM state pruning for computational efficiency. We demonstrate the effectiveness of Deco-G across a wide range of tasks with diverse format requirements, including mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall, our approach yields 1.0% to 6.0% relative gain over regular prompting practice with guaranteed format compliance.</li>
</ul>

<h3>Title: Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Alexander V. Mantzaris</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03598">https://arxiv.org/abs/2510.03598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03598">https://arxiv.org/pdf/2510.03598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03598]] Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation(https://arxiv.org/abs/2510.03598)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper asks whether the Hierarchical Reasoning Model (HRM) with the two Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a deliberately raw regime: no data augmentation, identical optimizer family with one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes stably and performs well on MNIST ($\approx 98\%$ test accuracy), but on small natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches 65.0\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains 77.2\% while training $\sim 30\times$ faster per epoch; on CIFAR-100, HRM achieves only 29.7\% test accuracy despite 91.5\% train accuracy, while the same CNN reaches 45.3\% test with 50.5\% train accuracy. Loss traces and error analyses indicate healthy optimization but insufficient image-specific inductive bias for HRM in this regime. It is concluded that, for small-resolution image classification without augmentation, HRM is not competitive with even simple convolutional architectures as the HRM currently exist but this does not exclude possibilities that modifications to the model may allow it to improve greatly.</li>
</ul>

<h3>Title: MECKD: Deep Learning-Based Fall Detection in Multilayer Mobile Edge Computing With Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Wei-Lung Mao, Chun-Chi Wang, Po-Heng Chou, Kai-Chun Liu, Yu Tsao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, cs.NI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03601">https://arxiv.org/abs/2510.03601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03601">https://arxiv.org/pdf/2510.03601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03601]] MECKD: Deep Learning-Based Fall Detection in Multilayer Mobile Edge Computing With Knowledge Distillation(https://arxiv.org/abs/2510.03601)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rising aging population has increased the importance of fall detection (FD) systems as an assistive technology, where deep learning techniques are widely applied to enhance accuracy. FD systems typically use edge devices (EDs) worn by individuals to collect real-time data, which are transmitted to a cloud center (CC) or processed locally. However, this architecture faces challenges such as a limited ED model size and data transmission latency to the CC. Mobile edge computing (MEC), which allows computations at MEC servers deployed between EDs and CC, has been explored to address these challenges. We propose a multilayer MEC (MLMEC) framework to balance accuracy and latency. The MLMEC splits the architecture into stations, each with a neural network model. If front-end equipment cannot detect falls reliably, data are transmitted to a station with more robust back-end computing. The knowledge distillation (KD) approach was employed to improve front-end detection accuracy by allowing high-power back-end stations to provide additional learning experiences, enhancing precision while reducing latency and processing loads. Simulation results demonstrate that the KD approach improved accuracy by 11.65% on the SisFall dataset and 2.78% on the FallAllD dataset. The MLMEC with KD also reduced the data latency rate by 54.15% on the FallAllD dataset and 46.67% on the SisFall dataset compared to the MLMEC without KD. In summary, the MLMEC FD system exhibits improved accuracy and reduced latency.</li>
</ul>

<h3>Title: Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops</h3>
<ul>
<li><strong>Authors: </strong>Mattia Scardecchia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03606">https://arxiv.org/abs/2510.03606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03606">https://arxiv.org/pdf/2510.03606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03606]] Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops(https://arxiv.org/abs/2510.03606)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in self-supervised learning (SSL) have made it possible to learn general-purpose visual features that capture both the high-level semantics and the fine-grained spatial structure of images. Most notably, the recent DINOv2 has established a new state of the art by surpassing weakly supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we examine the core ideas behind its approach, multi-crop view augmentation and self-distillation with a mean teacher, and trace their development in previous work. We then compare the performance of DINO and DINOv2 with other SSL and WSL methods across various downstream tasks, and highlight some remarkable emergent properties of their learned features with transformer backbones. We conclude by briefly discussing DINOv2's limitations, its impact, and future research directions.</li>
</ul>

<h3>Title: Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL</h3>
<ul>
<li><strong>Authors: </strong>Ruitao Wu, Yifan Zhao, Guangyao Chen, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03608">https://arxiv.org/abs/2510.03608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03608">https://arxiv.org/pdf/2510.03608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03608]] Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL(https://arxiv.org/abs/2510.03608)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially learn new classes from minimal examples without forgetting prior knowledge, a task complicated by the stability-plasticity dilemma and data scarcity. Current FSCIL methods often struggle with generalization due to their reliance on limited datasets. While diffusion models offer a path for data augmentation, their direct application can lead to semantic misalignment or ineffective guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel framework that establishes a mutual boosting loop between diffusion model and FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a dynamic, multi-faceted reward function derived from the classifier's state directs the diffusion model. This reward system operates at two levels: the feature level ensures semantic coherence and diversity using prototype-anchored maximum mean discrepancy and dimension-wise variance matching, while the logits level promotes exploratory image generation and enhances inter-class discriminability through confidence recalibration and cross-session confusion-aware mechanisms. This co-evolutionary process, where generated images refine the classifier and an improved classifier state yields better reward signals, demonstrably achieves state-of-the-art performance on FSCIL benchmarks, significantly enhancing both knowledge retention and new class learning.</li>
</ul>

<h3>Title: PentestMCP: A Toolkit for Agentic Penetration Testing</h3>
<ul>
<li><strong>Authors: </strong>Zachary Ezetta, Wu-chang Feng</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03610">https://arxiv.org/abs/2510.03610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03610">https://arxiv.org/pdf/2510.03610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03610]] PentestMCP: A Toolkit for Agentic Penetration Testing(https://arxiv.org/abs/2510.03610)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Agentic AI is transforming security by automating many tasks being performed manually. While initial agentic approaches employed a monolithic architecture, the Model-Context-Protocol has now enabled a remote-procedure call (RPC) paradigm to agentic applications, allowing for the flexible construction and composition of multi-function agents. This paper describes PentestMCP, a library of MCP server implementations that support agentic penetration testing. By supporting common penetration testing tasks such as network scanning, resource enumeration, service fingerprinting, vulnerability scanning, exploitation, and post-exploitation, PentestMCP allows a developer to customize multi-agent workflows for performing penetration tests.</li>
</ul>

<h3>Title: Can an LLM Induce a Graph? Investigating Memory Drift and Context Length</h3>
<ul>
<li><strong>Authors: </strong>Raquib Bin Yousuf, Aadyant Khatri, Shengzhe Xu, Mandar Sharma, Naren Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03611">https://arxiv.org/abs/2510.03611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03611">https://arxiv.org/pdf/2510.03611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03611]] Can an LLM Induce a Graph? Investigating Memory Drift and Context Length(https://arxiv.org/abs/2510.03611)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently proposed evaluation benchmarks aim to characterize the effective context length and the forgetting tendencies of large language models (LLMs). However, these benchmarks often rely on simplistic 'needle in a haystack' retrieval or continuation tasks that may not accurately reflect the performance of these models in information-dense scenarios. Thus, rather than simple next token prediction, we argue for evaluating these models on more complex reasoning tasks that requires them to induce structured relational knowledge from the text - such as graphs from potentially noisy natural language content. While the input text can be viewed as generated in terms of a graph, its structure is not made explicit and connections must be induced from distributed textual cues, separated by long contexts and interspersed with irrelevant information. Our findings reveal that LLMs begin to exhibit memory drift and contextual forgetting at much shorter effective lengths when tasked with this form of relational reasoning, compared to what existing benchmarks suggest. With these findings, we offer recommendations for the optimal use of popular LLMs for complex reasoning tasks. We further show that even models specialized for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in these settings. These results point to significant limitations in the models' ability to abstract structured knowledge from unstructured input and highlight the need for architectural adaptations to improve long-range reasoning.</li>
</ul>

<h3>Title: Neural Bayesian Filtering</h3>
<ul>
<li><strong>Authors: </strong>Christopher Solinas, Radovan Haluska, David Sychrovsky, Finbarr Timbers, Nolan Bard, Michael Buro, Martin Schmid, Nathan R. Sturtevant, Michael Bowling</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03614">https://arxiv.org/abs/2510.03614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03614">https://arxiv.org/pdf/2510.03614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03614]] Neural Bayesian Filtering(https://arxiv.org/abs/2510.03614)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present Neural Bayesian Filtering (NBF), an algorithm for maintaining distributions over hidden states, called beliefs, in partially observable systems. NBF is trained to find a good latent representation of the beliefs induced by a task. It maps beliefs to fixed-length embedding vectors, which condition generative models for sampling. During filtering, particle-style updates compute posteriors in this embedding space using incoming observations and the environment's dynamics. NBF combines the computational efficiency of classical filters with the expressiveness of deep generative models - tracking rapidly shifting, multimodal beliefs while mitigating the risk of particle impoverishment. We validate NBF in state estimation tasks in three partially observable environments.</li>
</ul>

<h3>Title: Explainable but Vulnerable: Adversarial Attacks on XAI Explanation in Cybersecurity Applications</h3>
<ul>
<li><strong>Authors: </strong>Maraz Mia, Mir Mehedi A. Pritom</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03623">https://arxiv.org/abs/2510.03623</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03623">https://arxiv.org/pdf/2510.03623</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03623]] Explainable but Vulnerable: Adversarial Attacks on XAI Explanation in Cybersecurity Applications(https://arxiv.org/abs/2510.03623)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, fair</a></li>
<li><strong>Abstract: </strong>Explainable Artificial Intelligence (XAI) has aided machine learning (ML) researchers with the power of scrutinizing the decisions of the black-box models. XAI methods enable looking deep inside the models' behavior, eventually generating explanations along with a perceived trust and transparency. However, depending on any specific XAI method, the level of trust can vary. It is evident that XAI methods can themselves be a victim of post-adversarial attacks that manipulate the expected outcome from the explanation module. Among such attack tactics, fairwashing explanation (FE), manipulation explanation (ME), and backdoor-enabled manipulation attacks (BD) are the notable ones. In this paper, we try to understand these adversarial attack techniques, tactics, and procedures (TTPs) on explanation alteration and thus the effect on the model's decisions. We have explored a total of six different individual attack procedures on post-hoc explanation methods such as SHAP (SHapley Additive exPlanations), LIME (Local Interpretable Model-agnostic Explanation), and IG (Integrated Gradients), and investigated those adversarial attacks in cybersecurity applications scenarios such as phishing, malware, intrusion, and fraudulent website detection. Our experimental study reveals the actual effectiveness of these attacks, thus providing an urgency for immediate attention to enhance the resiliency of XAI methods and their applications.</li>
</ul>

<h3>Title: QPADL: Post-Quantum Private Spectrum Access with Verified Location and DoS Resilience</h3>
<ul>
<li><strong>Authors: </strong>Saleh Darzi, Saif Eddine Nouma, Kiarash Sedghighadikolaei, Attila Altay</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03631">https://arxiv.org/abs/2510.03631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03631">https://arxiv.org/pdf/2510.03631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03631]] QPADL: Post-Quantum Private Spectrum Access with Verified Location and DoS Resilience(https://arxiv.org/abs/2510.03631)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>With advances in wireless communication and growing spectrum scarcity, Spectrum Access Systems (SASs) offer an opportunistic solution but face significant security challenges. Regulations require disclosure of location coordinates and transmission details, exposing user privacy and anonymity during spectrum queries, while the database operations themselves permit Denial-of-Service (DoS) attacks. As location-based services, SAS is also vulnerable to compromised or malicious users conducting spoofing attacks. These threats are further amplified given the quantum computing advancements. Thus, we propose QPADL, the first post-quantum (PQ) secure framework that simultaneously ensures privacy, anonymity, location verification, and DoS resilience while maintaining efficiency for large-scale spectrum access systems. QPADL introduces SAS-tailored private information retrieval for location privacy, a PQ-variant of Tor for anonymity, and employs advanced signature constructions for location verification alongside client puzzle protocols and rate-limiting technique for DoS defense. We formally assess its security and conduct a comprehensive performance evaluation, incorporating GPU parallelization and optimization strategies to demonstrate practicality and scalability.</li>
</ul>

<h3>Title: Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis</h3>
<ul>
<li><strong>Authors: </strong>An Vuong, Susan Gauch</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03633">https://arxiv.org/abs/2510.03633</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03633">https://arxiv.org/pdf/2510.03633</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03633]] Predicting Stock Price Movement with LLM-Enhanced Tweet Emotion Analysis(https://arxiv.org/abs/2510.03633)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Accurately predicting short-term stock price movement remains a challenging task due to the market's inherent volatility and sensitivity to investor sentiment. This paper discusses a deep learning framework that integrates emotion features extracted from tweet data with historical stock price information to forecast significant price changes on the following day. We utilize Meta's Llama 3.1-8B-Instruct model to preprocess tweet data, thereby enhancing the quality of emotion features derived from three emotion analysis approaches: a transformer-based DistilRoBERTa classifier from the Hugging Face library and two lexicon-based methods using National Research Council Canada (NRC) resources. These features are combined with previous-day stock price data to train a Long Short-Term Memory (LSTM) model. Experimental results on TSLA, AAPL, and AMZN stocks show that all three emotion analysis methods improve the average accuracy for predicting significant price movements, compared to the baseline model using only historical stock prices, which yields an accuracy of 13.5%. The DistilRoBERTa-based stock prediction model achieves the best performance, with accuracy rising from 23.6% to 38.5% when using LLaMA-enhanced emotion analysis. These results demonstrate that using large language models to preprocess tweet content enhances the effectiveness of emotion analysis which in turn improves the accuracy of predicting significant stock price movements.</li>
</ul>

<h3>Title: From Theory to Practice: Evaluating Data Poisoning Attacks and Defenses in In-Context Learning on Social Media Health Discourse</h3>
<ul>
<li><strong>Authors: </strong>Rabeya Amin Jhuma, Mostafa Mohaimen Akand Faisal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03636">https://arxiv.org/abs/2510.03636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03636">https://arxiv.org/pdf/2510.03636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03636]] From Theory to Practice: Evaluating Data Poisoning Attacks and Defenses in In-Context Learning on Social Media Health Discourse(https://arxiv.org/abs/2510.03636)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>This study explored how in-context learning (ICL) in large language models can be disrupted by data poisoning attacks in the setting of public health sentiment analysis. Using tweets of Human Metapneumovirus (HMPV), small adversarial perturbations such as synonym replacement, negation insertion, and randomized perturbation were introduced into the support examples. Even these minor manipulations caused major disruptions, with sentiment labels flipping in up to 67% of cases. To address this, a Spectral Signature Defense was applied, which filtered out poisoned examples while keeping the data's meaning and sentiment intact. After defense, ICL accuracy remained steady at around 46.7%, and logistic regression validation reached 100% accuracy, showing that the defense successfully preserved the dataset's integrity. Overall, the findings extend prior theoretical studies of ICL poisoning to a practical, high-stakes setting in public health discourse analysis, highlighting both the risks and potential defenses for robust LLM deployment. This study also highlights the fragility of ICL under attack and the value of spectral defenses in making AI systems more reliable for health-related social media monitoring.</li>
</ul>

<h3>Title: SAFA-SNN: Sparsity-Aware On-Device Few-Shot Class-Incremental Learning with Fast-Adaptive Structure of Spiking Neural Network</h3>
<ul>
<li><strong>Authors: </strong>Huijing Zhang, Muyang Cao, Linshan Jiang, Xin Du, Di Yu, Changze Lv, Shuiguang Deng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03648">https://arxiv.org/abs/2510.03648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03648">https://arxiv.org/pdf/2510.03648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03648]] SAFA-SNN: Sparsity-Aware On-Device Few-Shot Class-Incremental Learning with Fast-Adaptive Structure of Spiking Neural Network(https://arxiv.org/abs/2510.03648)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Continuous learning of novel classes is crucial for edge devices to preserve data privacy and maintain reliable performance in dynamic environments. However, the scenario becomes particularly challenging when data samples are insufficient, requiring on-device few-shot class-incremental learning (FSCIL) to maintain consistent model performance. Although existing work has explored parameter-efficient FSCIL frameworks based on artificial neural networks (ANNs), their deployment is still fundamentally constrained by limited device resources. Inspired by neural mechanisms, Spiking neural networks (SNNs) process spatiotemporal information efficiently, offering lower energy consumption, greater biological plausibility, and compatibility with neuromorphic hardware than ANNs. In this work, we present an SNN-based method for On-Device FSCIL, i.e., Sparsity-Aware and Fast Adaptive SNN (SAFA-SNN). We first propose sparsity-conditioned neuronal dynamics, in which most neurons remain stable while a subset stays active, thereby mitigating catastrophic forgetting. To further cope with spike non-differentiability in gradient estimation, we employ zeroth-order optimization. Moreover, during incremental learning sessions, we enhance the discriminability of new classes through subspace projection, which alleviates overfitting to novel classes. Extensive experiments conducted on two standard benchmark datasets (CIFAR100 and Mini-ImageNet) and three neuromorphic datasets (CIFAR-10-DVS, DVS128gesture, and N-Caltech101) demonstrate that SAFA-SNN outperforms baseline methods, specifically achieving at least 4.01% improvement at the last incremental session on Mini-ImageNet and 20% lower energy cost over baseline methods with practical implementation.</li>
</ul>

<h3>Title: Does higher interpretability imply better utility? A Pairwise Analysis on Sparse Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Xu Wang, Yan Hu, Benyou Wang, Difan Zou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03659">https://arxiv.org/abs/2510.03659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03659">https://arxiv.org/pdf/2510.03659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03659]] Does higher interpretability imply better utility? A Pairwise Analysis on Sparse Autoencoders(https://arxiv.org/abs/2510.03659)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Sparse Autoencoders (SAEs) are widely used to steer large language models (LLMs), based on the assumption that their interpretable features naturally enable effective model behavior steering. Yet, a fundamental question remains unanswered: does higher interpretability indeed imply better steering utility? To answer this question, we train 90 SAEs across three LLMs (Gemma-2-2B, Qwen-2.5-3B, Gemma-2-9B), spanning five architectures and six sparsity levels, and evaluate their interpretability and steering utility based on SAEBench (arXiv:2501.12345) and AxBench (arXiv:2502.23456) respectively, and perform a rank-agreement analysis via Kendall's rank coefficients (tau b). Our analysis reveals only a relatively weak positive association (tau b approx 0.298), indicating that interpretability is an insufficient proxy for steering performance. We conjecture the interpretability utility gap may stem from the selection of SAE features, as not all of them are equally effective for steering. To further find features that truly steer the behavior of LLMs, we propose a novel selection criterion called Delta Token Confidence, which measures how much amplifying a feature changes the next token distribution. We show that our method improves the steering performance of three LLMs by 52.52 percent compared to the current best output score based criterion (arXiv:2503.34567). Strikingly, after selecting features with high Delta Token Confidence, the correlation between interpretability and utility vanishes (tau b approx 0), and can even become negative. This further highlights the divergence between interpretability and utility for the most effective steering features.</li>
</ul>

<h3>Title: Operationalizing Data Minimization for Privacy-Preserving LLM Prompting</h3>
<ul>
<li><strong>Authors: </strong>Jijie Zhou, Niloofar Mireshghallah, Tianshi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03662">https://arxiv.org/abs/2510.03662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03662">https://arxiv.org/pdf/2510.03662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03662]] Operationalizing Data Minimization for Privacy-Preserving LLM Prompting(https://arxiv.org/abs/2510.03662)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>The rapid deployment of large language models (LLMs) in consumer applications has led to frequent exchanges of personal information. To obtain useful responses, users often share more than necessary, increasing privacy risks via memorization, context-based personalization, or security breaches. We present a framework to formally define and operationalize data minimization: for a given user prompt and response model, quantifying the least privacy-revealing disclosure that maintains utility, and we propose a priority-queue tree search to locate this optimal point within a privacy-ordered transformation space. We evaluated the framework on four datasets spanning open-ended conversations (ShareGPT, WildChat) and knowledge-intensive tasks with single-ground-truth answers (CaseHold, MedQA), quantifying achievable data minimization with nine LLMs as the response model. Our results demonstrate that larger frontier LLMs can tolerate stronger data minimization while maintaining task quality than smaller open-source models (85.7% redaction for GPT-5 vs. 19.3% for Qwen2.5-0.5B). By comparing with our search-derived benchmarks, we find that LLMs struggle to predict optimal data minimization directly, showing a bias toward abstraction that leads to oversharing. This suggests not just a privacy gap, but a capability gap: models may lack awareness of what information they actually need to solve a task.</li>
</ul>

<h3>Title: UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Peng, Cab Qin, Zeyuan Chen, Ran Xu, Caiming Xiong, Chien-Sheng Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03663">https://arxiv.org/abs/2510.03663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03663">https://arxiv.org/pdf/2510.03663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03663]] UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG(https://arxiv.org/abs/2510.03663)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal retrieval-augmented generation (MM-RAG) is a key approach for applying large language models (LLMs) and agents to real-world knowledge bases, yet current evaluations are fragmented, focusing on either text or images in isolation or on simplified multimodal setups that fail to capture document-centric multimodal use cases. In this paper, we introduce UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from 70k real-world PDF pages across eight domains. Our pipeline extracts and links evidence from text, tables, and figures, then generates 1,600 multimodal QA pairs spanning factual retrieval, comparison, summarization, and logical reasoning queries. To ensure reliability, 20% of QA pairs are validated by multiple annotators and expert adjudication. UniDoc-Bench supports apples-to-apples comparison across four paradigms: (1) text-only, (2) image-only, (3) multimodal text-image fusion, and (4) multimodal joint retrieval -- under a unified protocol with standardized candidate pools, prompts, and evaluation metrics. Our experiments show that multimodal text-image fusion RAG systems consistently outperform both unimodal and jointly multimodal embedding-based retrieval, indicating that neither text nor images alone are sufficient and that current multimodal embeddings remain inadequate. Beyond benchmarking, our analysis reveals when and how visual context complements textual evidence, uncovers systematic failure modes, and offers actionable guidance for developing more robust MM-RAG pipelines.</li>
</ul>

<h3>Title: Token Hidden Reward: Steering Exploration-Exploitation in Group Relative Deep Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenlong Deng, Yi Ren, Yushu Li, Boying Gong, Danica J. Sutherland, Xiaoxiao Li, Christos Thrampoulidis</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03669">https://arxiv.org/abs/2510.03669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03669">https://arxiv.org/pdf/2510.03669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03669]] Token Hidden Reward: Steering Exploration-Exploitation in Group Relative Deep Reinforcement Learning(https://arxiv.org/abs/2510.03669)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards has significantly advanced the reasoning capabilities of large language models, yet how to explicitly steer training toward exploration or exploitation remains an open problem. We introduce Token Hidden Reward (THR), a token-level metric that quantifies each token's influence on the likelihood of correct responses under Group Relative Policy Optimization (GRPO). We find that training dynamics are dominated by a small subset of tokens with high absolute THR values. Most interestingly, tokens with positive THR strengthen confidence in correct outputs, thus favoring exploitation, while tokens with negative THR preserve probability mass for alternative outputs, enabling exploration. This insight suggests a natural intervention: a THR-guided reweighting algorithm that modulates GRPO's learning signals to explicitly bias training toward exploitation or exploration. We validate the efficacy of this algorithm on diverse math reasoning benchmarks. By amplifying tokens with positive THR value and weakening negative ones, our algorithm improves greedy-decoding accuracy, favoring exploitation. The reverse strategy yields consistent gains in Pass@K accuracy, favoring exploration. We further demonstrate that our algorithm integrates seamlessly with other RL objectives such as GSPO and generalizes across architectures including Llama. These findings establish THR as a principled and fine-grained mechanism for dynamically controlling exploration and exploitation in RL-tuned LLMs, providing new tools for targeted fine-tuning in reasoning-intensive applications.</li>
</ul>

<h3>Title: A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems</h3>
<ul>
<li><strong>Authors: </strong>Siva Sai, Saksham Gupta, Vinay Chamola, Rajkumar Buyya</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03675">https://arxiv.org/abs/2510.03675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03675">https://arxiv.org/pdf/2510.03675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03675]] A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems(https://arxiv.org/abs/2510.03675)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>The integration of Diffusion Models into Intelligent Transportation Systems (ITS) is a substantial improvement in the detection of accidents. We present a novel hybrid model integrating guidance classification with diffusion techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input for our proposed diffusion model and processing image tensors as our conditioning, our approach creates a robust classification framework. Our model consists of multiple conditional modules, which aim to modulate the linear projection of inputs using time embeddings and image covariate embeddings, allowing the network to adapt its behavior dynamically throughout the diffusion process. To address the computationally intensive nature of diffusion models, our implementation is cloud-based, enabling scalable and efficient processing. Our strategy overcomes the shortcomings of conventional classification approaches by leveraging diffusion models inherent capacity to effectively understand complicated data distributions. We investigate important diffusion characteristics, such as timestep schedulers, timestep encoding techniques, timestep count, and architectural design changes, using a thorough ablation study, and have conducted a comprehensive evaluation of the proposed model against the baseline models on a publicly available dataset. The proposed diffusion model performs best in image-based accident detection with an accuracy of 97.32%.</li>
</ul>

<h3>Title: Towards Sampling Data Structures for Tensor Products in Turnstile Streams</h3>
<ul>
<li><strong>Authors: </strong>Zhao Song, Shenghao Xie, Samson Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03678">https://arxiv.org/abs/2510.03678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03678">https://arxiv.org/pdf/2510.03678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03678]] Towards Sampling Data Structures for Tensor Products in Turnstile Streams(https://arxiv.org/abs/2510.03678)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper studies the computational challenges of large-scale attention-based models in artificial intelligence by utilizing importance sampling methods in the streaming setting. Inspired by the classical definition of the $\ell_2$ sampler and the recent progress of the attention scheme in Large Language Models (LLMs), we propose the definition of the attention sampler. Our approach significantly reduces the computational burden of traditional attention mechanisms. We analyze the effectiveness of the attention sampler from a theoretical perspective, including space and update time. Additionally, our framework exhibits scalability and broad applicability across various model architectures and domains.</li>
</ul>

<h3>Title: Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text</h3>
<ul>
<li><strong>Authors: </strong>Nisar Hussain, Amna Qasim, Gull Mehak, Muhammad Zain, Momina Hafeez, Grigori Sidorov</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03683">https://arxiv.org/abs/2510.03683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03683">https://arxiv.org/pdf/2510.03683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03683]] Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text(https://arxiv.org/abs/2510.03683)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The use of derogatory terms in languages that employ code mixing, such as Roman Urdu, presents challenges for Natural Language Processing systems due to unstated grammar, inconsistent spelling, and a scarcity of labeled data. In this work, we propose a QLoRA based fine tuning framework to improve offensive language detection in Roman Urdu-English text. We translated the Roman Urdu-English code mixed dataset into English using Google Translate to leverage English LLMs, while acknowledging that this translation reduces direct engagement with code mixing features. Our focus is on classification performance using English translated low resource inputs. We fine tuned several transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient adaptation. Models were trained and evaluated on a manually annotated Roman Urdu dataset for offensive vs non offensive content. Of all tested models, the highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral 7B at 89.66, surpassing traditional transformer baselines. These results demonstrate the efficacy of QLoRA in fine tuning high performing models for low resource environments such as code mixed offensive language detection, and confirm the potential of LLMs for this task. This work advances a scalable approach to Roman Urdu moderation and paves the way for future multilingual offensive detection systems based on LLMs.</li>
</ul>

<h3>Title: MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction</h3>
<ul>
<li><strong>Authors: </strong>Yue Huang, Yanyuan Chen, Dexuan Xu, Weihua Yue, Huamin Zhang, Meikang Qiu, Yu Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03687">https://arxiv.org/abs/2510.03687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03687">https://arxiv.org/pdf/2510.03687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03687]] MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction(https://arxiv.org/abs/2510.03687)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical problem solving demands expert knowledge and intricate reasoning. Recent studies of large language models (LLMs) attempt to ease this complexity by introducing external knowledge verification through retrieval-augmented generation or by training on reasoning datasets. However, these approaches suffer from drawbacks such as retrieval overhead and high annotation costs, and they heavily rely on substituted external assistants to reach limited performance in medical field. In this paper, we introduce MedReflect, a generalizable framework designed to inspire LLMs with a physician-like reflective thinking mode. MedReflect generates a single-pass reflection chain that includes initial hypothesis generation, self-questioning, self-answering and decision refinement. This self-verified and self-reflective nature releases large language model's latent capability in medical problem-solving without external retrieval or heavy annotation. We demonstrate that MedReflect enables cost-efficient medical dataset construction: with merely 2,000 randomly sampled training examples and a light fine-tuning, this approach achieves notable absolute accuracy improvements across a series of medical benchmarks while cutting annotation requirements. Our results provide evidence that LLMs can learn to solve specialized medical problems via self-reflection and self-improve, reducing reliance on external supervision and extensive task-specific fine-tuning data.</li>
</ul>

<h3>Title: From Moments to Models: Graphon Mixture-Aware Mixup and Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Ali Azizpour, Reza Ramezanpour, Ashutosh Sabharwal, Santiago Segarra</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03690">https://arxiv.org/abs/2510.03690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03690">https://arxiv.org/pdf/2510.03690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03690]] From Moments to Models: Graphon Mixture-Aware Mixup and Contrastive Learning(https://arxiv.org/abs/2510.03690)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Real-world graph datasets often consist of mixtures of populations, where graphs are generated from multiple distinct underlying distributions. However, modern representation learning approaches, such as graph contrastive learning (GCL) and augmentation methods like Mixup, typically overlook this mixture structure. In this work, we propose a unified framework that explicitly models data as a mixture of underlying probabilistic graph generative models represented by graphons. To characterize these graphons, we leverage graph moments (motif densities) to cluster graphs arising from the same model. This enables us to disentangle the mixture components and identify their distinct generative mechanisms. This model-aware partitioning benefits two key graph learning tasks: 1) It enables a graphon-mixture-aware mixup (GMAM), a data augmentation technique that interpolates in a semantically valid space guided by the estimated graphons, instead of assuming a single graphon per class. 2) For GCL, it enables model-adaptive and principled augmentations. Additionally, by introducing a new model-aware objective, our proposed approach (termed MGCL) improves negative sampling by restricting negatives to graphs from other models. We establish a key theoretical guarantee: a novel, tighter bound showing that graphs sampled from graphons with small cut distance will have similar motif densities with high probability. Extensive experiments on benchmark datasets demonstrate strong empirical performance. In unsupervised learning, MGCL achieves state-of-the-art results, obtaining the top average rank across eight datasets. In supervised learning, GMAM consistently outperforms existing strategies, achieving new state-of-the-art accuracy in 6 out of 7 datasets.</li>
</ul>

<h3>Title: REG: A Regularization Optimizer for Robust Training Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Zehua Liu, Han Wu, Xiaojin Fu, Shuqi Liu, Xiongwei Han, Tao Zhong, Mingxuan Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03691">https://arxiv.org/abs/2510.03691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03691">https://arxiv.org/pdf/2510.03691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03691]] REG: A Regularization Optimizer for Robust Training Dynamics(https://arxiv.org/abs/2510.03691)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Optimizers are crucial for the efficient training of Large Language Models (LLMs). While AdamW is the de facto standard, recent structure-aware optimizers like Muon have emerged, which regularize gradient updates by operating on entire weight matrices. The Muon optimizer balances the gradient updates along all the directions. However, Muon's reliance on the matrix sign function can lead to training instability, exhibits incompatibility when fine-tuning models pre-trained with AdamW. To address these limitations, we propose \textbf{REG}, a novel optimizer that replaces Muon's aggressive matrix sign operator with the Row-and-Column-Scaling (RACS) operator. Theoretically grounded in balancing a matrix, the RACS operator regularizes the update steps in a less drastic manner, making it simpler to implement and more compatible with established training dynamics. Through extensive empirical experiments on LLM training, we demonstrate that our REG optimizer not only achieves superior performance and stability over AdamW, but also maintains consistency with the AdamW training paradigm. This consistency is particularly evident during the fine-tuning stage, where REG optimizer avoids the performance degradation observed with Muon.</li>
</ul>

<h3>Title: Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods</h3>
<ul>
<li><strong>Authors: </strong>Yulin Chen, Haoran Li, Yuan Sui, Yangqiu Song, Bryan Hooi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03705">https://arxiv.org/abs/2510.03705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03705">https://arxiv.org/pdf/2510.03705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03705]] Backdoor-Powered Prompt Injection Attacks Nullify Defense Methods(https://arxiv.org/abs/2510.03705)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the development of technology, large language models (LLMs) have dominated the downstream natural language processing (NLP) tasks. However, because of the LLMs' instruction-following abilities and inability to distinguish the instructions in the data content, such as web pages from search engines, the LLMs are vulnerable to prompt injection attacks. These attacks trick the LLMs into deviating from the original input instruction and executing the attackers' target instruction. Recently, various instruction hierarchy defense strategies are proposed to effectively defend against prompt injection attacks via fine-tuning. In this paper, we explore more vicious attacks that nullify the prompt injection defense methods, even the instruction hierarchy: backdoor-powered prompt injection attacks, where the attackers utilize the backdoor attack for prompt injection attack purposes. Specifically, the attackers poison the supervised fine-tuning samples and insert the backdoor into the model. Once the trigger is activated, the backdoored model executes the injected instruction surrounded by the trigger. We construct a benchmark for comprehensive evaluation. Our experiments demonstrate that backdoor-powered prompt injection attacks are more harmful than previous prompt injection attacks, nullifying existing prompt injection defense methods, even the instruction hierarchy techniques.</li>
</ul>

<h3>Title: Artery-Vein Segmentation from Fundus Images using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Sharan SK, Subin Sahayam, Umarani Jayaraman, Lakshmi Priya A</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03717">https://arxiv.org/abs/2510.03717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03717">https://arxiv.org/pdf/2510.03717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03717]] Artery-Vein Segmentation from Fundus Images using Deep Learning(https://arxiv.org/abs/2510.03717)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segmenting of clinically important retinal blood vessels into arteries and veins is a prerequisite for retinal vessel analysis. Such analysis can provide potential insights and bio-markers for identifying and diagnosing various retinal eye diseases. Alteration in the regularity and width of the retinal blood vessels can act as an indicator of the health of the vasculature system all over the body. It can help identify patients at high risk of developing vasculature diseases like stroke and myocardial infarction. Over the years, various Deep Learning architectures have been proposed to perform retinal vessel segmentation. Recently, attention mechanisms have been increasingly used in image segmentation tasks. The work proposes a new Deep Learning approach for artery-vein segmentation. The new approach is based on the Attention mechanism that is incorporated into the WNet Deep Learning model, and we call the model as Attention-WNet. The proposed approach has been tested on publicly available datasets such as HRF and DRIVE datasets. The proposed approach has outperformed other state-of-art models available in the literature.</li>
</ul>

<h3>Title: Shrinking the Kernel Attack Surface Through Static and Dynamic Syscall Limitation</h3>
<ul>
<li><strong>Authors: </strong>Dongyang Zhan (1), Zhaofeng Yu (1), Xiangzhan Yu (1), Hongli Zhang (1), Lin Ye (1) ((1) Harbin Institute of Technology)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03720">https://arxiv.org/abs/2510.03720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03720">https://arxiv.org/pdf/2510.03720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03720]] Shrinking the Kernel Attack Surface Through Static and Dynamic Syscall Limitation(https://arxiv.org/abs/2510.03720)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Linux Seccomp is widely used by the program developers and the system maintainers to secure the operating systems, which can block unused syscalls for different applications and containers to shrink the attack surface of the operating systems. However, it is difficult to configure the whitelist of a container or application without the help of program developers. Docker containers block about only 50 syscalls by default, and lots of unblocked useless syscalls introduce a big kernel attack surface. To obtain the dependent syscalls, dynamic tracking is a straight-forward approach but it cannot get the full syscall list. Static analysis can construct an over-approximated syscall list, but the list contains many false positives. In this paper, a systematic dependent syscall analysis approach, sysverify, is proposed by combining static analysis and dynamic verification together to shrink the kernel attack surface. The semantic gap between the binary executables and syscalls is bridged by analyzing the binary and the source code, which builds the mapping between the library APIs and syscalls systematically. To further reduce the attack surface at best effort, we propose a dynamic verification approach to intercept and analyze the security of the invocations of indirect-call-related or rarely invoked syscalls with low overhead.</li>
</ul>

<h3>Title: Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models</h3>
<ul>
<li><strong>Authors: </strong>Leander Girrbach, Stephan Alaniz, Genevieve Smith, Trevor Darrell, Zeynep Akata</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03721">https://arxiv.org/abs/2510.03721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03721">https://arxiv.org/pdf/2510.03721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03721]] Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models(https://arxiv.org/abs/2510.03721)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Vision-language models trained on large-scale multimodal datasets show strong demographic biases, but the role of training data in producing these biases remains unclear. A major barrier has been the lack of demographic annotations in web-scale datasets such as LAION-400M. We address this gap by creating person-centric annotations for the full dataset, including over 276 million bounding boxes, perceived gender and race/ethnicity labels, and automatically generated captions. These annotations are produced through validated automatic labeling pipelines combining object detection, multimodal captioning, and finetuned classifiers. Using them, we uncover demographic imbalances and harmful associations, such as the disproportionate linking of men and individuals perceived as Black or Middle Eastern with crime-related and negative content. We also show that 60-70% of gender bias in CLIP and Stable Diffusion can be linearly explained by direct co-occurrences in the data. Our resources establish the first large-scale empirical link between dataset composition and downstream model bias.</li>
</ul>

<h3>Title: Balancing Interpretability and Performance in Reinforcement Learning: An Adaptive Spectral Based Linear Approach</h3>
<ul>
<li><strong>Authors: </strong>Qianxin Yi, Shao-Bo Lin, Jun Fan, Yao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03722">https://arxiv.org/abs/2510.03722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03722">https://arxiv.org/pdf/2510.03722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03722]] Balancing Interpretability and Performance in Reinforcement Learning: An Adaptive Spectral Based Linear Approach(https://arxiv.org/abs/2510.03722)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has been widely applied to sequential decision making, where interpretability and performance are both critical for practical adoption. Current approaches typically focus on performance and rely on post hoc explanations to account for interpretability. Different from these approaches, we focus on designing an interpretability-oriented yet performance-enhanced RL approach. Specifically, we propose a spectral based linear RL method that extends the ridge regression-based approach through a spectral filter function. The proposed method clarifies the role of regularization in controlling estimation error and further enables the design of an adaptive regularization parameter selection strategy guided by the bias-variance trade-off principle. Theoretical analysis establishes near-optimal bounds for both parameter estimation and generalization error. Extensive experiments on simulated environments and real-world datasets from Kuaishou and Taobao demonstrate that our method either outperforms or matches existing baselines in decision quality. We also conduct interpretability analyses to illustrate how the learned policies make decisions, thereby enhancing user trust. These results highlight the potential of our approach to bridge the gap between RL theory and practical decision making, providing interpretability, accuracy, and adaptability in management contexts.</li>
</ul>

<h3>Title: Personalized federated prototype learning in mixed heterogeneous data scenarios</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Zeng, Wolong Xing, Liangtao Shi, Xin Huang, Jialin Wang, Zhile Cao, Zhenkui Shi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03726">https://arxiv.org/abs/2510.03726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03726">https://arxiv.org/pdf/2510.03726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03726]] Personalized federated prototype learning in mixed heterogeneous data scenarios(https://arxiv.org/abs/2510.03726)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Federated learning has received significant attention for its ability to simultaneously protect customer privacy and leverage distributed data from multiple devices for model training. However, conventional approaches often focus on isolated heterogeneous scenarios, resulting in skewed feature distributions or label distributions. Meanwhile, data heterogeneity is actually a key factor in improving model performance. To address this issue, we propose a new approach called PFPL in mixed heterogeneous scenarios. The method provides richer domain knowledge and unbiased convergence targets by constructing personalized, unbiased prototypes for each client. Moreover, in the local update phase, we introduce consistent regularization to align local instances with their personalized prototypes, which significantly improves the convergence of the loss function. Experimental results on Digits and Office Caltech datasets validate the effectiveness of our approach and successfully reduce the communication cost.</li>
</ul>

<h3>Title: Optimizing Fine-Tuning through Advanced Initialization Strategies for Low-Rank Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yongfu Xue</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03731">https://arxiv.org/abs/2510.03731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03731">https://arxiv.org/pdf/2510.03731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03731]] Optimizing Fine-Tuning through Advanced Initialization Strategies for Low-Rank Adaptation(https://arxiv.org/abs/2510.03731)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of parameter-efficient fine-tuning methods has noticeably improved the efficiency of adapting large language models. Among these, LoRA has gained widespread popularity due to its strong balance of effectiveness and parameter efficiency. However, LoRA relies on initializing two low-rank matrices whose product is zero, which limits its ability to effectively activate and leverage the original model weights-creating a potential bottleneck for optimal performance. To address this limitation, we propose \textbf{IniLoRA}, a novel initialization strategy that initializes the low-rank matrices to closely approximate the original model weights. Experimental results indicate that IniLoRA achieves better performance than LoRA across a range of models and tasks. Additionally, we introduce two variants, IniLoRA-$\alpha$ and IniLoRA-$\beta$, both leveraging distinct initialization methods to enhance performance further.</li>
</ul>

<h3>Title: Cost Efficient Fairness Audit Under Partial Feedback</h3>
<ul>
<li><strong>Authors: </strong>Nirjhar Das, Mohit Sharma, Praharsh Nanavati, Kirankumar Shiragur, Amit Deshpande</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03734">https://arxiv.org/abs/2510.03734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03734">https://arxiv.org/pdf/2510.03734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03734]] Cost Efficient Fairness Audit Under Partial Feedback(https://arxiv.org/abs/2510.03734)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We study the problem of auditing the fairness of a given classifier under partial feedback, where true labels are available only for positively classified individuals, (e.g., loan repayment outcomes are observed only for approved applicants). We introduce a novel cost model for acquiring additional labeled data, designed to more accurately reflect real-world costs such as credit assessment, loan processing, and potential defaults. Our goal is to find optimal fairness audit algorithms that are more cost-effective than random exploration and natural baselines. In our work, we consider two audit settings: a black-box model with no assumptions on the data distribution, and a mixture model, where features and true labels follow a mixture of exponential family distributions. In the black-box setting, we propose a near-optimal auditing algorithm under mild assumptions and show that a natural baseline can be strictly suboptimal. In the mixture model setting, we design a novel algorithm that achieves significantly lower audit cost than the black-box case. Our approach leverages prior work on learning from truncated samples and maximum-a-posteriori oracles, and extends known results on spherical Gaussian mixtures to handle exponential family mixtures, which may be of independent interest. Moreover, our algorithms apply to popular fairness metrics including demographic parity, equal opportunity, and equalized odds. Empirically, we demonstrate strong performance of our algorithms on real-world fair classification datasets like Adult Income and Law School, consistently outperforming natural baselines by around 50% in terms of audit cost.</li>
</ul>

<h3>Title: Securing Operating Systems Through Fine-grained Kernel Access Limitation for IoT Systems</h3>
<ul>
<li><strong>Authors: </strong>Dongyang Zhan (1), Zhaofeng Yu (1), Xiangzhan Yu (1), Hongli Zhang (1), Lin Ye (1), Likun Liu (1) ((1) Harbin Institute of Technology)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03737">https://arxiv.org/abs/2510.03737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03737">https://arxiv.org/pdf/2510.03737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03737]] Securing Operating Systems Through Fine-grained Kernel Access Limitation for IoT Systems(https://arxiv.org/abs/2510.03737)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>With the development of Internet of Things (IoT), it is gaining a lot of attention. It is important to secure the embedded systems with low overhead. The Linux Seccomp is widely used by developers to secure the kernels by blocking the access of unused syscalls, which introduces less overhead. However, there are no systematic Seccomp configuration approaches for IoT applications without the help of developers. In addition, the existing Seccomp configuration approaches are coarse-grained, which cannot analyze and limit the syscall arguments. In this paper, a novel static dependent syscall analysis approach for embedded applications is proposed, which can obtain all of the possible dependent syscalls and the corresponding arguments of the target applications. So, a fine-grained kernel access limitation can be performed for the IoT applications. To this end, the mappings between dynamic library APIs and syscalls according with their arguments are built, by analyzing the control flow graphs and the data dependency relationships of the dynamic libraries. To the best of our knowledge, this is the first work to generate the fine-grained Seccomp profile for embedded applications.</li>
</ul>

<h3>Title: HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model Adaptation for Long-Term Daily Runoff Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Qianfei Fan, Jiayu Wei, Peijun Zhu, Wensheng Ye, Meie Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.NE, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03744">https://arxiv.org/abs/2510.03744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03744">https://arxiv.org/pdf/2510.03744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03744]] HydroFusion-LMF: Semi-Supervised Multi-Network Fusion with Large-Model Adaptation for Long-Term Daily Runoff Forecasting(https://arxiv.org/abs/2510.03744)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Accurate decade-scale daily runoff forecasting in small watersheds is difficult because signals blend drifting trends, multi-scale seasonal cycles, regime shifts, and sparse extremes. Prior deep models (DLinear, TimesNet, PatchTST, TiDE, Nonstationary Transformer, LSTNet, LSTM) usually target single facets and under-utilize unlabeled spans, limiting regime adaptivity. We propose HydroFusion-LMF, a unified framework that (i) performs a learnable trend-seasonal-residual decomposition to reduce non-stationarity, (ii) routes residuals through a compact heterogeneous expert set (linear refinement, frequency kernel, patch Transformer, recurrent memory, dynamically normalized attention), (iii) fuses expert outputs via a hydrologic context-aware gate conditioned on day-of-year phase, antecedent precipitation, local variance, flood indicators, and static basin attributes, and (iv) augments supervision with a semi-supervised multi-task objective (composite MSE/MAE + extreme emphasis + NSE/KGE, masked reconstruction, multi-scale contrastive alignment, augmentation consistency, variance-filtered pseudo-labeling). Optional adapter / LoRA layers inject a frozen foundation time-series encoder efficiently. On a ~10-year daily dataset HydroFusion-LMF attains MSE 1.0128 / MAE 0.5818, improving the strongest baseline (DLinear) by 10.2% / 10.3% and the mean baseline by 24.6% / 17.1%. We observe simultaneous MSE and MAE reductions relative to baselines. The framework balances interpretability (explicit components, sparse gating) with performance, advancing label-efficient hydrologic forecasting under non-stationarity.</li>
</ul>

<h3>Title: LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes</h3>
<ul>
<li><strong>Authors: </strong>Zuomin Qu, Yimao Guo, Qianyue Hu, Wei Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03747">https://arxiv.org/abs/2510.03747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03747">https://arxiv.org/pdf/2510.03747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03747]] LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes(https://arxiv.org/abs/2510.03747)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, robust</a></li>
<li><strong>Abstract: </strong>Deepfakes pose significant societal risks, motivating the development of proactive defenses that embed adversarial perturbations in facial images to prevent manipulation. However, in this paper, we show that these preemptive defenses often lack robustness and reliability. We propose a novel approach, Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch into Deepfake generators to bypass state-of-the-art defenses. A learnable gating mechanism adaptively controls the effect of the LoRA patch and prevents gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature Alignment (MMFA) loss, encouraging the features of adversarial outputs to align with those of the desired outputs at the semantic level. Beyond bypassing, we present defensive LoRA patching, embedding visible warnings in the outputs as a complementary solution to mitigate this newly identified security vulnerability. With only 1,000 facial examples and a single epoch of fine-tuning, LoRA patching successfully defeats multiple proactive defenses. These results reveal a critical weakness in current paradigms and underscore the need for more robust Deepfake defense strategies. Our code is available at this https URL.</li>
</ul>

<h3>Title: TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation</h3>
<ul>
<li><strong>Authors: </strong>Ramtin Kakavand, Ebrahim Ansari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03748">https://arxiv.org/abs/2510.03748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03748">https://arxiv.org/pdf/2510.03748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03748]] TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation(https://arxiv.org/abs/2510.03748)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have consistently demonstrated strong performance in machine translation, especially when guided by high-quality prompts. Few-shot prompting is an effective technique to improve translation quality; however, most existing example selection methods focus solely on query-to-example similarity and do not account for the quality of the examples. In this work, we propose TreePrompt, a novel example selection approach that learns LLM preferences to identify high-quality, contextually relevant examples within a tree-structured framework. To further explore the balance between similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN) and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs - English-Persian (MIZAN) and English-German (WMT19) - show that integrating TreePrompt with AFSP or Random selection leads to improved translation performance.</li>
</ul>

<h3>Title: The Overlooked Value of Test-time Reference Sets in Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Mubariz Zaffar, Liangliang Nan, Sebastian Scherer, Julian F. P. Kooij</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03751">https://arxiv.org/abs/2510.03751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03751">https://arxiv.org/pdf/2510.03751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03751]] The Overlooked Value of Test-time Reference Sets in Visual Place Recognition(https://arxiv.org/abs/2510.03751)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Given a query image, Visual Place Recognition (VPR) is the task of retrieving an image of the same place from a reference database with robustness to viewpoint and appearance changes. Recent works show that some VPR benchmarks are solved by methods using Vision-Foundation-Model backbones and trained on large-scale and diverse VPR-specific datasets. Several benchmarks remain challenging, particularly when the test environments differ significantly from the usual VPR training datasets. We propose a complementary, unexplored source of information to bridge the train-test domain gap, which can further improve the performance of State-of-the-Art (SOTA) VPR methods on such challenging benchmarks. Concretely, we identify that the test-time reference set, the "map", contains images and poses of the target domain, and must be available before the test-time query is received in several VPR applications. Therefore, we propose to perform simple Reference-Set-Finetuning (RSF) of VPR models on the map, boosting the SOTA (~2.3% increase on average for Recall@1) on these challenging datasets. Finetuned models retain generalization, and RSF works across diverse test datasets.</li>
</ul>

<h3>Title: EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ping Guo, Chenyu Zhu, Siyuan Chen, Fei Liu, Xi Lin, Zhichao Lu, Qingfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03760">https://arxiv.org/abs/2510.03760</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03760">https://arxiv.org/pdf/2510.03760</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03760]] EvoEngineer: Mastering Automated CUDA Kernel Code Evolution with Large Language Models(https://arxiv.org/abs/2510.03760)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>CUDA kernel optimization has become a critical bottleneck for AI performance, as deep learning training and inference efficiency directly depends on highly optimized GPU kernels. Despite the promise of Large Language Models (LLMs) for automating kernel optimization, this field suffers from a fragmented ecosystem of isolated and incomparable approaches with unclear problem formulations. Furthermore, general-purpose LLM code evolution methods cannot meet strict correctness requirements of CUDA kernel optimization. We address these fundamental challenges by first formalizing CUDA kernel optimization as a code optimization task with a clear objective, constraints, and evaluation metrics. We then establish the first systematic LLM-based code evolution framework, EvoEngineer, that provides guidance for designing and adapting optimization strategies to achieve a balance between performance and correctness. Finally, we implement a kernel optimization system based on this framework and conduct extensive experiments on 91 real-world CUDA kernels. Our results demonstrate that EvoEngineer achieves a principled balance between performance and correctness, with the highest averaged median speedup of \textbf{2.72}$\times$ over baseline CUDA kernels and a code validity rate of \textbf{69.8}\%, outperforming existing methods on both dimensions. Our method achieves a maximum speedup of \textbf{36.75}$\times$ among all operations over PyTorch kernels and delivers the highest speedup on \textbf{28} (\textbf{56.0\%}) of 50 operations that achieve over \textbf{2$\times$} acceleration.</li>
</ul>

<h3>Title: You Have Been LaTeXpOsEd: A Systematic Analysis of Information Leakage in Preprint Archives Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Richard A. Dubniczky, Bertalan Borsos, Tihanyi Norbert</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03761">https://arxiv.org/abs/2510.03761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03761">https://arxiv.org/pdf/2510.03761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03761]] You Have Been LaTeXpOsEd: A Systematic Analysis of Information Leakage in Preprint Archives Using Large Language Models(https://arxiv.org/abs/2510.03761)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The widespread use of preprint repositories such as arXiv has accelerated the communication of scientific results but also introduced overlooked security risks. Beyond PDFs, these platforms provide unrestricted access to original source materials, including LaTeX sources, auxiliary code, figures, and embedded comments. In the absence of sanitization, submissions may disclose sensitive information that adversaries can harvest using open-source intelligence. In this work, we present the first large-scale security audit of preprint archives, analyzing more than 1.2 TB of source data from 100,000 arXiv submissions. We introduce LaTeXpOsEd, a four-stage framework that integrates pattern matching, logical filtering, traditional harvesting techniques, and large language models (LLMs) to uncover hidden disclosures within non-referenced files and LaTeX comments. To evaluate LLMs' secret-detection capabilities, we introduce LLMSec-DB, a benchmark on which we tested 25 state-of-the-art models. Our analysis uncovered thousands of PII leaks, GPS-tagged EXIF files, publicly available Google Drive and Dropbox folders, editable private SharePoint links, exposed GitHub and Google credentials, and cloud API keys. We also uncovered confidential author communications, internal disagreements, and conference submission credentials, exposing information that poses serious reputational risks to both researchers and institutions. We urge the research community and repository operators to take immediate action to close these hidden security gaps. To support open science, we release all scripts and methods from this study but withhold sensitive findings that could be misused, in line with ethical principles. The source code and related material are available at the project website this https URL</li>
</ul>

<h3>Title: Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Deshan Sumanathilaka, Nicholas Micallef, Julian Hough</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03762">https://arxiv.org/abs/2510.03762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03762">https://arxiv.org/pdf/2510.03762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03762]] Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs(https://arxiv.org/abs/2510.03762)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have significantly reshaped the landscape of Natural Language Processing (NLP). Among the various prompting techniques, few-shot prompting has gained considerable attention for its practicality and effectiveness. This study investigates how few-shot prompting strategies impact the Word Sense Disambiguation (WSD) task, particularly focusing on the biases introduced by imbalanced sample distributions. We use the GLOSSGPT prompting method, an advanced approach for English WSD, to test its effectiveness across five languages: English, German, Spanish, French, and Italian. Our results show that imbalanced few-shot examples can cause incorrect sense predictions in multilingual languages, but this issue does not appear in English. To assess model behavior, we evaluate both the GPT-4o and LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual WSD to sample distribution in few-shot settings, emphasizing the need for balanced and representative prompting strategies.</li>
</ul>

<h3>Title: CoPA: Hierarchical Concept Prompting and Aggregating Network for Explainable Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Yiheng Dong, Yi Lin, Xin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03767">https://arxiv.org/abs/2510.03767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03767">https://arxiv.org/pdf/2510.03767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03767]] CoPA: Hierarchical Concept Prompting and Aggregating Network for Explainable Diagnosis(https://arxiv.org/abs/2510.03767)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The transparency of deep learning models is essential for clinical diagnostics. Concept Bottleneck Model provides clear decision-making processes for diagnosis by transforming the latent space of black-box models into human-understandable concepts. However, concept-based methods still face challenges in concept capture capabilities. These methods often rely on encode features solely from the final layer, neglecting shallow and multiscale features, and lack effective guidance in concept encoding, hindering fine-grained concept extraction. To address these issues, we introduce Concept Prompting and Aggregating (CoPA), a novel framework designed to capture multilayer concepts under prompt guidance. This framework utilizes the Concept-aware Embedding Generator (CEG) to extract concept representations from each layer of the visual encoder. Simultaneously, these representations serve as prompts for Concept Prompt Tuning (CPT), steering the model towards amplifying critical concept-related visual cues. Visual representations from each layer are aggregated to align with textual concept representations. With the proposed method, valuable concept-wise information in the images is captured and utilized effectively, thus improving the performance of concept and disease prediction. Extensive experimental results demonstrate that CoPA outperforms state-of-the-art methods on three public datasets. Code is available at this https URL.</li>
</ul>

<h3>Title: Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shimaa Elbana, Ahmad Kamal, Shahd Ahmed Ali, Ahmad Al-Kabbany</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03769">https://arxiv.org/abs/2510.03769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03769">https://arxiv.org/pdf/2510.03769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03769]] Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation(https://arxiv.org/abs/2510.03769)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The increasing size and complexity of medical imaging datasets, particularly in 3D formats, present significant barriers to collaborative research and transferability. This study investigates whether the ZFP compression technique can mitigate these challenges without compromising the performance of automated cerebrovascular segmentation, a critical first step in intracranial aneurysm detection. We apply ZFP in both its error tolerance and fixed-rate modes to a large scale, and one of the most recent, datasets in the literature, 3D medical dataset containing ground-truth vascular segmentations. The segmentation quality on the compressed volumes is rigorously compared to the uncompressed baseline (Dice approximately equals 0.8774). Our findings reveal that ZFP can achieve substantial data reduction--up to a 22.89:1 ratio in error tolerance mode--while maintaining a high degree of fidelity, with the mean Dice coefficient remaining high at 0.87656. These results demonstrate that ZFP is a viable and powerful tool for enabling more efficient and accessible research on large-scale medical datasets, fostering broader collaboration across the community.</li>
</ul>

<h3>Title: Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data</h3>
<ul>
<li><strong>Authors: </strong>David Megias</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03770">https://arxiv.org/abs/2510.03770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03770">https://arxiv.org/pdf/2510.03770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03770]] Complex Domain Approach for Reversible Data Hiding and Homomorphic Encryption: General Framework and Application to Dispersed Data(https://arxiv.org/abs/2510.03770)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, watermark</a></li>
<li><strong>Abstract: </strong>Ensuring the trustworthiness of data from distributed and resource-constrained environments, such as Wireless Sensor Networks or IoT devices, is critical. Existing Reversible Data Hiding (RDH) methods for scalar data suffer from low embedding capacity and poor intrinsic mixing between host data and watermark. This paper introduces Hiding in the Imaginary Domain with Data Encryption (H[i]dden), a novel framework based on complex number arithmetic for simultaneous information embedding and encryption. The H[i]dden framework offers perfect reversibility, in-principle unlimited watermark size, and intrinsic data-watermark mixing. The paper further introduces two protocols: H[i]dden-EG, for joint reversible data hiding and encryption, and H[i]dden-AggP, for privacy-preserving aggregation of watermarked data, based on partially homomorphic encryption. These protocols provide efficient and resilient solutions for data integrity, provenance and confidentiality, serving as a foundation for new schemes based on the algebraic properties of the complex domain.</li>
</ul>

<h3>Title: Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development</h3>
<ul>
<li><strong>Authors: </strong>Majid Asgari-Bidhendi, Muhammad Amin Ghaseminia, Alireza Shahbazi, Sayyed Ali Hossayni, Najmeh Torabian, Behrouz Minaei-Bidgoli</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03781">https://arxiv.org/abs/2510.03781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03781">https://arxiv.org/pdf/2510.03781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03781]] Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development(https://arxiv.org/abs/2510.03781)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents the development of Rezwan, a large-scale AI-assisted Hadith corpus comprising over 1.2M narrations, extracted and structured through a fully automated pipeline. Building on digital repositories such as Maktabat Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for segmentation, chain--text separation, validation, and multi-layer enrichment. Each narration is enhanced with machine translation into twelve languages, intelligent diacritization, abstractive summarization, thematic tagging, and cross-text semantic analysis. This multi-step process transforms raw text into a richly annotated research-ready infrastructure for digital humanities and Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled narrations, assessed by six domain experts. Results show near-human accuracy in structured tasks such as chain--text separation (9.33/10) and summarization (9.33/10), while highlighting ongoing challenges in diacritization and semantic similarity detection. Comparative analysis against the manually curated Noor Corpus demonstrates the superiority of Najm in both scale and quality, with a mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis confirms the economic feasibility of the AI approach: tasks requiring over 229,000 hours of expert labor were completed within months at a fraction of the cost. The work introduces a new paradigm in religious text processing by showing how AI can augment human expertise, enabling large-scale, multilingual, and semantically enriched access to Islamic heritage.</li>
</ul>

<h3>Title: Merge and Guide: Unifying Model Merging and Guided Decoding for Controllable Multi-Objective Generation</h3>
<ul>
<li><strong>Authors: </strong>Guofu Xie, Chen Zhang, Xiao Zhang, Yunsheng Shi, Ting Yao, Jun Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03782">https://arxiv.org/abs/2510.03782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03782">https://arxiv.org/pdf/2510.03782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03782]] Merge and Guide: Unifying Model Merging and Guided Decoding for Controllable Multi-Objective Generation(https://arxiv.org/abs/2510.03782)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Adapting to diverse user needs at test time is a key challenge in controllable multi-objective generation. Existing methods are insufficient: merging-based approaches provide indirect, suboptimal control at the parameter level, often disregarding the impacts of multiple objectives. While decoding-based guidance is more direct, it typically requires aggregating logits from multiple expert models, incurring significant space overhead and relying heavily on individual model capacity. To address these issues, we introduce Merge-And-GuidE (MAGE), a two-stage framework that leverages model merging for guided decoding. We first identify a critical compatibility problem between the guidance and base models. In Stage 1, MAGE resolves this by dynamically constructing a more robust base model, merging a series of backbone models that account for multiple objectives. In Stage 2, we merge explicit and implicit value models into a unified guidance proxy, which then steers the decoding of the base model from Stage 1. Our analysis empirically validates Linear Mode Connectivity (LMC) in value models, explores the relationship between model merging and prediction ensembling, and demonstrates the enhanced controllability afforded by our approach. Extensive experiments show that our method outperforms existing approaches, achieving superior controllability, Pareto-optimal performance, and enhanced adaptability.</li>
</ul>

<h3>Title: Allocation of Parameters in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Ruoxi Yu, Haotian Jiang, Jingpu Cheng, Penghao Yu, Qianxiao Li, Zhong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03784">https://arxiv.org/abs/2510.03784</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03784">https://arxiv.org/pdf/2510.03784</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03784]] Allocation of Parameters in Transformers(https://arxiv.org/abs/2510.03784)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have achieved remarkable successes across a wide range of applications, yet the theoretical foundation of their model efficiency remains underexplored. In this work, we investigate how the model parameters -- mainly attention heads and head dimensions -- should be allocated across layers to balance expressivity and efficiency. We first provide mathematical analysis on the role of early layers in information extraction from an approximation perspective, with a theoretical characterization on the trade-off between the number of heads and head dimension under a fixed parameter budget. In addition, we uncover and prove the \emph{saturation} behavior of softmax activations: Continuously increasing head dimensions can lead to diminishing returns in learning errors, particularly for long sequences. Supported by both theory and experiments, this saturation pattern suggests that later layers can operate more efficiently with reduced parameters. Combining these insights, we propose principled strategies for allocating attention heads and dimensions across Transformers' layers, shedding light on theoretically-grounded model efficiency of Transformer-based architectures.</li>
</ul>

<h3>Title: MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based Fusion for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>T-Mai Bui, Fares Bougourzi, Fadi Dornaika, Vinh Truong Hoang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03786">https://arxiv.org/abs/2510.03786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03786">https://arxiv.org/pdf/2510.03786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03786]] MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based Fusion for Medical Image Segmentation(https://arxiv.org/abs/2510.03786)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In recent years, deep learning has shown near-expert performance in segmenting complex medical tissues and tumors. However, existing models are often task-specific, with performance varying across modalities and anatomical regions. Balancing model complexity and performance remains challenging, particularly in clinical settings where both accuracy and efficiency are critical. To address these issues, we propose a hybrid segmentation architecture featuring a three-branch encoder that integrates CNNs, Transformers, and a Mamba-based Attention Fusion (MAF) mechanism to capture local, global, and long-range dependencies. A multi-scale attention-based CNN decoder reconstructs fine-grained segmentation maps while preserving contextual consistency. Additionally, a co-attention gate enhances feature selection by emphasizing relevant spatial and semantic information across scales during both encoding and decoding, improving feature interaction and cross-scale communication. Extensive experiments on multiple benchmark datasets show that our approach outperforms state-of-the-art methods in accuracy and generalization, while maintaining comparable computational complexity. By effectively balancing efficiency and effectiveness, our architecture offers a practical and scalable solution for diverse medical imaging tasks. Source code and trained models will be publicly released upon acceptance to support reproducibility and further research.</li>
</ul>

<h3>Title: Robust Batched Bandits</h3>
<ul>
<li><strong>Authors: </strong>Yunwen Guo, Yunlun Shu, Gongyi Zhuo, Tianyu Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03798">https://arxiv.org/abs/2510.03798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03798">https://arxiv.org/pdf/2510.03798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03798]] Robust Batched Bandits(https://arxiv.org/abs/2510.03798)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The batched multi-armed bandit (MAB) problem, in which rewards are collected in batches, is crucial for applications such as clinical trials. Existing research predominantly assumes light-tailed reward distributions, yet many real-world scenarios, including clinical outcomes, exhibit heavy-tailed characteristics. This paper bridges this gap by proposing robust batched bandit algorithms designed for heavy-tailed rewards, within both finite-arm and Lipschitz-continuous settings. We reveal a surprising phenomenon: in the instance-independent regime, as well as in the Lipschitz setting, heavier-tailed rewards necessitate a smaller number of batches to achieve near-optimal regret. In stark contrast, for the instance-dependent setting, the required number of batches to attain near-optimal regret remains invariant with respect to tail heaviness.</li>
</ul>

<h3>Title: Mechanistic Interpretability of Socio-Political Frames in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hadi Asghari, Sami Nenno</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03799">https://arxiv.org/abs/2510.03799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03799">https://arxiv.org/pdf/2510.03799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03799]] Mechanistic Interpretability of Socio-Political Frames in Language Models(https://arxiv.org/abs/2510.03799)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>This paper explores the ability of large language models to generate and recognize deep cognitive frames, particularly in socio-political contexts. We demonstrate that LLMs are highly fluent in generating texts that evoke specific frames and can recognize these frames in zero-shot settings. Inspired by mechanistic interpretability research, we investigate the location of the `strict father' and `nurturing parent' frames within the model's hidden representation, identifying singular dimensions that correlate strongly with their presence. Our findings contribute to understanding how LLMs capture and express meaningful human concepts.</li>
</ul>

<h3>Title: Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Canhui Wu, Qiong Cao, Chang Li, Zhenfang Wang, Chao Xue, Yuwei Fan, Wei Xi, Xiaodong He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03805">https://arxiv.org/abs/2510.03805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03805">https://arxiv.org/pdf/2510.03805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03805]] Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models(https://arxiv.org/abs/2510.03805)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks but often suffer from excessive verbosity, known as "overthinking." Existing solutions via reinforcement learning (RL) typically penalize generated tokens to promote conciseness. However, these methods encounter two challenges: responses with fewer tokens do not always correspond to fewer reasoning steps, and models may develop hacking behavior in later stages of training by discarding reasoning steps to minimize token usage. In this work, we introduce \textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more efficient reasoning by favoring compact reasoning steps. Our step-aware reward function prioritizes correctness while imposing penalties for redundant steps, and withholds rewards for incorrect responses to prevent the reinforcement of erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when the length of any output step exceeds the upper limit, we halt updates to prevent hacking behavior caused by merging steps. Extensive experiments across four reasoning benchmarks demonstrate that SP achieves state-of-the-art accuracy while significantly reducing response length. For instance, on AIME24, SP reduces token usage by \textbf{69.7\%}.</li>
</ul>

<h3>Title: Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches</h3>
<ul>
<li><strong>Authors: </strong>Mehedi Hasan Emon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03808">https://arxiv.org/abs/2510.03808</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03808">https://arxiv.org/pdf/2510.03808</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03808]] Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches(https://arxiv.org/abs/2510.03808)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>This research explores the annotation of rhetorical relations in discourse using the INCEpTION tool and compares manual annotation with automatic approaches based on large language models. The study focuses on sports reports (specifically cricket news) and evaluates the performance of BERT, DistilBERT, and Logistic Regression models in classifying rhetorical relations such as elaboration, contrast, background, and cause-effect. The results show that DistilBERT achieved the highest accuracy, highlighting its potential for efficient discourse relation prediction. This work contributes to the growing intersection of discourse parsing and transformer-based NLP. (This paper was conducted as part of an academic requirement under the supervision of Prof. Dr. Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords: Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing, NLP.</li>
</ul>

<h3>Title: Curriculum-Augmented GFlowNets For mRNA Sequence Generation</h3>
<ul>
<li><strong>Authors: </strong>Aya Laajil, Abduragim Shtanchaev, Sajan Muhammad, Eric Moulines, Salem Lahlou</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03811">https://arxiv.org/abs/2510.03811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03811">https://arxiv.org/pdf/2510.03811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03811]] Curriculum-Augmented GFlowNets For mRNA Sequence Generation(https://arxiv.org/abs/2510.03811)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Designing mRNA sequences is a major challenge in developing next-generation therapeutics, since it involves exploring a vast space of possible nucleotide combinations while optimizing sequence properties like stability, translation efficiency, and protein expression. While Generative Flow Networks are promising for this task, their training is hindered by sparse, long-horizon rewards and multi-objective trade-offs. We propose Curriculum-Augmented GFlowNets (CAGFN), which integrate curriculum learning with multi-objective GFlowNets to generate de novo mRNA sequences. CAGFN integrates a length-based curriculum that progressively adapts the maximum sequence length guiding exploration from easier to harder subproblems. We also provide a new mRNA design environment for GFlowNets which, given a target protein sequence and a combination of biological objectives, allows for the training of models that generate plausible mRNA candidates. This provides a biologically motivated setting for applying and advancing GFlowNets in therapeutic sequence design. On different mRNA design tasks, CAGFN improves Pareto performance and biological plausibility, while maintaining diversity. Moreover, CAGFN reaches higher-quality solutions faster than a GFlowNet trained with random sequence sampling (no curriculum), and enables generalization to out-of-distribution sequences.</li>
</ul>

<h3>Title: TROLL: Trust Regions improve Reinforcement Learning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Philipp Becker, Niklas Freymuth, Serge Thilges, Fabian Otto, Gerhard Neumann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03817">https://arxiv.org/abs/2510.03817</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03817">https://arxiv.org/pdf/2510.03817</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03817]] TROLL: Trust Regions improve Reinforcement Learning for Large Language Models(https://arxiv.org/abs/2510.03817)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>On-policy Reinforcement Learning (RL) with PPO-like clip objectives has become the standard choice for reward-based fine-tuning of large language models (LLMs). Although recent work has explored improved estimators of advantages and normalization, the clipping mechanism itself has remained untouched. Originally introduced as a proxy for principled KL-based trust regions, clipping is a crude approximation that often causes unstable updates and suboptimal performance. We replace the clip objective with a novel discrete differentiable trust region projection, which provides principled token-level KL constraints. The projection operates on a sparse subset of the model's most important token logits to balance computational cost and projection effectiveness. Our approach, Trust Region Optimization for Large Language Models (TROLL), serves as a direct replacement for PPO-like clipping during training and does not alter the model's inference behavior. Across datasets, model families, and advantage-estimation methods, TROLL consistently outperforms PPO-like clipping in terms of training speed, stability, and final success rates.</li>
</ul>

<h3>Title: Security Analysis of Ponzi Schemes in Ethereum Smart Contracts</h3>
<ul>
<li><strong>Authors: </strong>Chunyi Zhang, Qinghong Wei, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03819">https://arxiv.org/abs/2510.03819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03819">https://arxiv.org/pdf/2510.03819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03819]] Security Analysis of Ponzi Schemes in Ethereum Smart Contracts(https://arxiv.org/abs/2510.03819)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The rapid advancement of blockchain technology has precipitated the widespread adoption of Ethereum and smart contracts across a variety of sectors. However, this has also given rise to numerous fraudulent activities, with many speculators embedding Ponzi schemes within smart contracts, resulting in significant financial losses for investors. Currently, there is a lack of effective methods for identifying and analyzing such new types of fraudulent activities. This paper categorizes these scams into four structural types and explores the intrinsic characteristics of Ponzi scheme contract source code from a program analysis perspective. The Mythril tool is employed to conduct static and dynamic analyses of representative cases, thereby revealing their vulnerabilities and operational mechanisms. Furthermore, this paper employs shell scripts and command patterns to conduct batch detection of open-source smart contract code, thereby unveiling the common characteristics of Ponzi scheme smart contracts.</li>
</ul>

<h3>Title: Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation</h3>
<ul>
<li><strong>Authors: </strong>Venkata Narendra Kotyada, Revanth Eranki, Nagesh Bhattu Sristy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03821">https://arxiv.org/abs/2510.03821</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03821">https://arxiv.org/pdf/2510.03821</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03821]] Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation(https://arxiv.org/abs/2510.03821)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Unpaired image-to-image translation involves learning mappings between source domain and target domain in the absence of aligned or corresponding samples. Score based diffusion models have demonstrated state-of-the-art performance in generative tasks. Their ability to approximate complex data distributions through stochastic differential equations (SDEs) enables them to generate high-fidelity and diverse outputs, making them particularly well-suited for unpaired I2I settings. In parallel, contrastive learning provides a powerful framework for learning semantic similarities without the need for explicit supervision or paired data. By pulling together representations of semantically similar samples and pushing apart dissimilar ones, contrastive methods are inherently aligned with the objectives of unpaired translation. Its ability to selectively enforce semantic consistency at the feature level makes contrastive learning particularly effective for guiding generation in unpaired scenarios. In this work, we propose a time-dependent contrastive learning approach where a model is trained with SimCLR by considering an image and its domain invarient feature as a positive pair, enabling the preservation of domain-invariant features and the discarding of domain-specific ones. The learned contrastive model then guides the inference of a pretrained SDE for the I2I translation task. We empirically compare Contrastive-SDE with several baselines across three common unpaired I2I tasks, using four metrics for evaluation. Constrastive-SDE achieves comparable results to the state-of-the-art on several metrics. Furthermore, we observe that our model converges significantly faster and requires no label supervision or classifier training, making it a more efficient alternative for this task.</li>
</ul>

<h3>Title: Proximal Diffusion Neural Sampler</h3>
<ul>
<li><strong>Authors: </strong>Wei Guo, Jaemoo Choi, Yuchen Zhu, Molei Tao, Yongxin Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03824">https://arxiv.org/abs/2510.03824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03824">https://arxiv.org/pdf/2510.03824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03824]] Proximal Diffusion Neural Sampler(https://arxiv.org/abs/2510.03824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>The task of learning a diffusion-based neural sampler for drawing samples from an unnormalized target distribution can be viewed as a stochastic optimal control problem on path measures. However, the training of neural samplers can be challenging when the target distribution is multimodal with significant barriers separating the modes, potentially leading to mode collapse. We propose a framework named \textbf{Proximal Diffusion Neural Sampler (PDNS)} that addresses these challenges by tackling the stochastic optimal control problem via proximal point method on the space of path measures. PDNS decomposes the learning process into a series of simpler subproblems that create a path gradually approaching the desired distribution. This staged procedure traces a progressively refined path to the desired distribution and promotes thorough exploration across modes. For a practical and efficient realization, we instantiate each proximal step with a proximal weighted denoising cross-entropy (WDCE) objective. We demonstrate the effectiveness and robustness of PDNS through extensive experiments on both continuous and discrete sampling tasks, including challenging scenarios in molecular dynamics and statistical physics.</li>
</ul>

<h3>Title: LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization</h3>
<ul>
<li><strong>Authors: </strong>Xueyang Zhou, Yangming Xu, Guiyao Tie, Yongchao Chen, Guowen Zhang, Duanfeng Chu, Pan Zhou, Lichao Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03827">https://arxiv.org/abs/2510.03827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03827">https://arxiv.org/pdf/2510.03827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03827]] LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization(https://arxiv.org/abs/2510.03827)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>LIBERO has emerged as a widely adopted benchmark for evaluating Vision-Language-Action (VLA) models; however, its current training and evaluation settings are problematic, often leading to inflated performance estimates and preventing fair model comparison. To address these issues, we introduce LIBERO-PRO, an extended LIBERO benchmark that systematically evaluates model performance under reasonable perturbations across four dimensions: manipulated objects, initial states, task instructions, and environments. Experimental results reveal that, although existing models achieve over 90% accuracy under the standard LIBERO evaluation, their performance collapses to 0.0% under our generalized setting. Crucially, this discrepancy exposes the models' reliance on rote memorization of action sequences and environment layouts from the training set, rather than genuine task understanding or environmental perception. For instance, models persist in executing grasping actions when the target object is replaced with irrelevant items, and their outputs remain unchanged even when given corrupted instructions or even messy tokens. These findings expose the severe flaws in current evaluation practices, and we call on the community to abandon misleading methodologies in favor of robust assessments of model generalization and comprehension. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Pilot Contamination Attacks Detection with Machine Learning for Multi-User Massive MIMO</h3>
<ul>
<li><strong>Authors: </strong>Pedro Ivo da Cruz, Dimitri Silva, Tito Spadini, Ricardo Suyama, Murilo Bellezoni Loiola</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03831">https://arxiv.org/abs/2510.03831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03831">https://arxiv.org/pdf/2510.03831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03831]] Pilot Contamination Attacks Detection with Machine Learning for Multi-User Massive MIMO(https://arxiv.org/abs/2510.03831)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Massive multiple-input multiple-output (MMIMO) is essential to modern wireless communication systems, like 5G and 6G, but it is vulnerable to active eavesdropping attacks. One type of such attack is the pilot contamination attack (PCA), where a malicious user copies pilot signals from an authentic user during uplink, intentionally interfering with the base station's (BS) channel estimation accuracy. In this work, we propose to use a Decision Tree (DT) algorithm for PCA detection at the BS in a multi-user system. We present a methodology to generate training data for the DT classifier and select the best DT according to their depth. Then, we simulate different scenarios that could be encountered in practice and compare the DT to a classical technique based on likelihood ratio testing (LRT) submitted to the same scenarios. The results revealed that a DT with only one level of depth is sufficient to outperform the LRT. The DT shows a good performance regarding the probability of detection in noisy scenarios and when the malicious user transmits with low power, in which case the LRT fails to detect the PCA. We also show that the reason for the good performance of the DT is its ability to compute a threshold that separates PCA data from non-PCA data better than the LRT's threshold. Moreover, the DT does not necessitate prior knowledge of noise power or assumptions regarding the signal power of malicious users, prerequisites typically essential for LRT and other hypothesis testing methodologies.</li>
</ul>

<h3>Title: Technical note on Fisher Information for Robust Federated Cross-Validation</h3>
<ul>
<li><strong>Authors: </strong>Behraj Khan, Tahir Qasim Syed</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03838">https://arxiv.org/abs/2510.03838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03838">https://arxiv.org/pdf/2510.03838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03838]] Technical note on Fisher Information for Robust Federated Cross-Validation(https://arxiv.org/abs/2510.03838)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>When training data are fragmented across batches or federated-learned across different geographic locations, trained models manifest performance degradation. That degradation partly owes to covariate shift induced by data having been fragmented across time and space and producing dissimilar empirical training distributions. Each fragment's distribution is slightly different to a hypothetical unfragmented training distribution of covariates, and to the single validation distribution. To address this problem, we propose Fisher Information for Robust fEderated validation (\textbf{FIRE}). This method accumulates fragmentation-induced covariate shift divergences from the global training distribution via an approximate Fisher information. That term, which we prove to be a more computationally-tractable estimate, is then used as a per-fragment loss penalty, enabling scalable distribution alignment. FIRE outperforms importance weighting benchmarks by $5.1\%$ at maximum and federated learning (FL) benchmarks by up to $5.3\%$ on shifted validation sets.</li>
</ul>

<h3>Title: Technical note on Sequential Test-Time Adaptation via Martingale-Driven Fisher Prompting</h3>
<ul>
<li><strong>Authors: </strong>Behraj Khan, Tahir Qasim Syed</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03839">https://arxiv.org/abs/2510.03839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03839">https://arxiv.org/pdf/2510.03839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03839]] Technical note on Sequential Test-Time Adaptation via Martingale-Driven Fisher Prompting(https://arxiv.org/abs/2510.03839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present a theoretical framework for M-FISHER, a method for sequential distribution shift detection and stable adaptation in streaming data. For detection, we construct an exponential martingale from non-conformity scores and apply Ville's inequality to obtain time-uniform guarantees on false alarm control, ensuring statistical validity at any stopping time. Under sustained shifts, we further bound the expected detection delay as $\mathcal{O}(\log(1/\delta)/\Gamma)$, where $\Gamma$ reflects the post-shift information gain, thereby linking detection efficiency to distributional divergence. For adaptation, we show that Fisher-preconditioned updates of prompt parameters implement natural gradient descent on the distributional manifold, yielding locally optimal updates that minimize KL divergence while preserving stability and parameterization invariance. Together, these results establish M-FISHER as a principled approach for robust, anytime-valid detection and geometrically stable adaptation in sequential decision-making under covariate shift.</li>
</ul>

<h3>Title: On Using Large Language Models to Enhance Clinically-Driven Missing Data Recovery Algorithms in Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Sarah C. Lotspeich, Abbey Collins, Brian J. Wells, Ashish K. Khanna, Joseph Rigdon, Lucy D'Agostino McGowan</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03844">https://arxiv.org/abs/2510.03844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03844">https://arxiv.org/pdf/2510.03844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03844]] On Using Large Language Models to Enhance Clinically-Driven Missing Data Recovery Algorithms in Electronic Health Records(https://arxiv.org/abs/2510.03844)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Objective: Electronic health records (EHR) data are prone to missingness and errors. Previously, we devised an "enriched" chart review protocol where a "roadmap" of auxiliary diagnoses (anchors) was used to recover missing values in EHR data (e.g., a diagnosis of impaired glycemic control might imply that a missing hemoglobin A1c value would be considered unhealthy). Still, chart reviews are expensive and time-intensive, which limits the number of patients whose data can be reviewed. Now, we investigate the accuracy and scalability of a roadmap-driven algorithm, based on ICD-10 codes (International Classification of Diseases, 10th revision), to mimic expert chart reviews and recover missing values. Materials and Methods: In addition to the clinicians' original roadmap from our previous work, we consider new versions that were iteratively refined using large language models (LLM) in conjunction with clinical expertise to expand the list of auxiliary diagnoses. Using chart reviews for 100 patients from the EHR at an extensive learning health system, we examine algorithm performance with different roadmaps. Using the larger study of $1000$ patients, we applied the final algorithm, which used a roadmap with clinician-approved additions from the LLM. Results: The algorithm recovered as much, if not more, missing data as the expert chart reviewers, depending on the roadmap. Discussion: Clinically-driven algorithms (enhanced by LLM) can recover missing EHR data with similar accuracy to chart reviews and can feasibly be applied to large samples. Extending them to monitor other dimensions of data quality (e.g., plausability) is a promising future direction.</li>
</ul>

<h3>Title: UGround: Towards Unified Visual Grounding with Unrolled Transformers</h3>
<ul>
<li><strong>Authors: </strong>Rui Qian, Xin Yin, Chuanhang Deng, Zhiyuan Peng, Jian Xiong, Wei Zhai, Dejing Dou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03853">https://arxiv.org/abs/2510.03853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03853">https://arxiv.org/pdf/2510.03853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03853]] UGround: Towards Unified Visual Grounding with Unrolled Transformers(https://arxiv.org/abs/2510.03853)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>We present UGround, a \textbf{U}nified visual \textbf{Ground}ing paradigm that dynamically selects intermediate layers across \textbf{U}nrolled transformers as ``mask as prompt'', diverging from the prevailing pipeline that leverages the fixed last hidden layer as ``\texttt{<SEG>} as prompt''. UGround addresses two primary challenges posed by the prevailing paradigm: (1) its reliance on the fixed last hidden layer, which sequentially amplifies cumulative errors arising from layer-by-layer propagation without intermediate correction, and (2) its use of \texttt{<SEG>} as a prompt, which implicitly projects textual embeddings into visual space without explicit spatial cues (\eg, coordinates). Central to UGround is Policy-Prompted Masking, which comprises two key components: Stochastic Skip Connection (SSC) and Mask as Prompt (MasP). SSC is a reinforcement learning policy that, via stochastic sampling, allows each \texttt{<SEG>} token to slide across unrolled transformer layers, enabling dynamic layer selection at which it connects to the vision model (\eg, SAM) in a skip-connection fashion. Given the selected hidden layer, MasP uses the similarity map derived from the \texttt{<SEG>} token and image tokens as a soft logit mask to prompt SAM for mask generation, offering explicit spatial cues through its activation regions. To validate the effectiveness of UGround, we, for the first time, have unified visual grounding within a single framework from an attribute perspective, spanning from traditional refer expression segmentation to newly proposed reasoning segmentation, single-target to multi-target, positive query to false premise (empty target). All codes and models are publicly available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Unlocking Reasoning Capabilities in LLMs via Reinforcement Learning Exploration</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Deng, Long Wei, Chenglei Yu, Tailin Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03865">https://arxiv.org/abs/2510.03865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03865">https://arxiv.org/pdf/2510.03865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03865]] Unlocking Reasoning Capabilities in LLMs via Reinforcement Learning Exploration(https://arxiv.org/abs/2510.03865)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning with verifiable rewards (RLVR) has recently enhanced the reasoning capabilities of large language models (LLMs), particularly for mathematical problem solving. However, a fundamental limitation remains: as the sampling budget increases, the advantage of RLVR-trained models over their pretrained bases often diminishes or even vanishes, revealing a strong dependence on the base model's restricted search space. We attribute this phenomenon to the widespread use of the reverse Kullback-Leibler (KL) divergence regularizer, whose mode-seeking behavior keeps the policy trapped inside the base model's support region and hampers wider exploration. To address this issue, we propose RAPO (Rewards-Aware Policy Optimization), an algorithm to promote broader yet focused exploration. Our method (i) utilizes the forward KL penalty to replace the reverse KL penalty for out-of-distribution exploration, and (ii) reweights the reference policy to facilitate adaptive in-distribution exploration. We train Qwen2.5-3B and 7B models with RAPO on the 8K SimpleRL-Zero dataset, without supervised fine-tuning, and evaluate them on AIME2024 and AIME2025. Results show that RAPO consistently improves problem-solving performance. Notably, RAPO enables models to surpass the base model's performance ceiling and solves previously intractable problems, advancing the frontier of RLVR for challenging reasoning tasks.</li>
</ul>

<h3>Title: On Provable Benefits of Muon in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinwen Zhang, Hongchang Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03866">https://arxiv.org/abs/2510.03866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03866">https://arxiv.org/pdf/2510.03866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03866]] On Provable Benefits of Muon in Federated Learning(https://arxiv.org/abs/2510.03866)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The recently introduced optimizer, Muon, has gained increasing attention due to its superior performance across a wide range of applications. However, its effectiveness in federated learning remains unexplored. To address this gap, this paper investigates the performance of Muon in the federated learning setting. Specifically, we propose a new algorithm, FedMuon, and establish its convergence rate for nonconvex problems. Our theoretical analysis reveals multiple favorable properties of FedMuon. In particular, due to its orthonormalized update direction, the learning rate of FedMuon is independent of problem-specific parameters, and, importantly, it can naturally accommodate heavy-tailed noise. The extensive experiments on a variety of neural network architectures validate the effectiveness of the proposed algorithm.</li>
</ul>

<h3>Title: SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks</h3>
<ul>
<li><strong>Authors: </strong>Nikolaos Kaparinos, Vasileios Mezaris</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03870">https://arxiv.org/abs/2510.03870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03870">https://arxiv.org/pdf/2510.03870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03870]] SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks(https://arxiv.org/abs/2510.03870)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative Adversarial Networks (GANs) achieve excellent performance in generative tasks, such as image super-resolution, but their computational requirements make difficult their deployment on resource-constrained devices. While knowledge distillation is a promising research direction for GAN compression, effectively training a smaller student generator is challenging due to the capacity mismatch between the student generator and the teacher discriminator. In this work, we propose Student Discriminator Assisted Knowledge Distillation (SDAKD), a novel GAN distillation methodology that introduces a student discriminator to mitigate this capacity mismatch. SDAKD follows a three-stage training strategy, and integrates an adapted feature map distillation approach in its last two training stages. We evaluated SDAKD on two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our experiments demonstrate consistent improvements over the baselines and SOTA GAN knowledge distillation methods. The SDAKD source code will be made openly available upon acceptance of the paper.</li>
</ul>

<h3>Title: PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and Postural Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Saja Al-Dabet, Sherzod Turaev, Nazar Zaki, Arif O. Khan, Luai Eldweik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03873">https://arxiv.org/abs/2510.03873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03873">https://arxiv.org/pdf/2510.03873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03873]] PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and Postural Diagnosis(https://arxiv.org/abs/2510.03873)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Diagnosing ocular-induced abnormal head posture (AHP) requires a comprehensive analysis of both head pose and ocular movements. However, existing datasets focus on these aspects separately, limiting the development of integrated diagnostic approaches and restricting AI-driven advancements in AHP analysis. To address this gap, we introduce PoseGaze-AHP, a novel 3D dataset that synchronously captures head pose and gaze movement information for ocular-induced AHP assessment. Structured clinical data were extracted from medical literature using large language models (LLMs) through an iterative process with the Claude 3.5 Sonnet model, combining stepwise, hierarchical, and complex prompting strategies. The extracted records were systematically imputed and transformed into 3D representations using the Neural Head Avatar (NHA) framework. The dataset includes 7,920 images generated from two head textures, covering a broad spectrum of ocular conditions. The extraction method achieved an overall accuracy of 91.92%, demonstrating its reliability for clinical dataset construction. PoseGaze-AHP is the first publicly available resource tailored for AI-driven ocular-induced AHP diagnosis, supporting the development of accurate and privacy-compliant diagnostic tools.</li>
</ul>

<h3>Title: Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive Spatial Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Runhao Liu, Ziming Chen, Peng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03876">https://arxiv.org/abs/2510.03876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03876">https://arxiv.org/pdf/2510.03876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03876]] Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive Spatial Feature Fusion(https://arxiv.org/abs/2510.03876)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Skin cancer classification remains a challenging problem due to high inter-class similarity, intra-class variability, and image noise in dermoscopic images. To address these issues, we propose an improved ResNet-50 model enhanced with Adaptive Spatial Feature Fusion (ASFF), which adaptively integrates multi-scale semantic and surface features to improve feature representation and reduce overfitting. The ResNet-50 model is enhanced with an adaptive feature fusion mechanism to achieve more effective multi-scale feature extraction and improve overall performance. Specifically, a dual-branch design fuses high-level semantic and mid-level detail features, which are processed through global average pooling and fully connected layers to generate adaptive weights for weighted fusion, thereby strengthening feature learning and reducing the impact of noise on classification. The method is evaluated on a subset of the ISIC 2020 dataset containing 3297 benign and malignant skin lesion images. Experimental results show that the proposed ASFF-based ResNet-50 achieves the best overall performance compared with 5 classic convolutional neural networks (CNNs) models. The proposed model reached an accuracy of 93.18% along with higher precision, recall, specificity, and F1 score. The improved model achieves an AUC value of 0.9670 and 0.9717 in the P-R and ROC curve, respectively. Then, the evaluation based on Grad-CAM further proved that the improved model adaptively focuses on lesion-relevant regions while suppressing irrelevant background information, thereby validating its enhanced feature learning capability from a deep representation perspective. These findings demonstrate that the proposed approach provides a more effective and efficient solution for computer-aided skin cancer diagnosis.</li>
</ul>

<h3>Title: Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R Ajo Babu George, Sreehari J R</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03878">https://arxiv.org/abs/2510.03878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03878">https://arxiv.org/pdf/2510.03878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03878]] Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional Neural Networks(https://arxiv.org/abs/2510.03878)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aims Late diagnosis of Oral Squamous Cell Carcinoma (OSCC) contributes significantly to its high global mortality rate, with over 50\% of cases detected at advanced stages and a 5-year survival rate below 50\% according to WHO statistics. This study aims to improve early detection of OSCC by developing a multimodal deep learning framework that integrates clinical, radiological, and histopathological images using a weighted ensemble of DenseNet-121 convolutional neural networks (CNNs). Material and Methods A retrospective study was conducted using publicly available datasets representing three distinct medical imaging modalities. Each modality-specific dataset was used to train a DenseNet-121 CNN via transfer learning. Augmentation and modality-specific preprocessing were applied to increase robustness. Predictions were fused using a validation-weighted ensemble strategy. Evaluation was performed using accuracy, precision, recall, F1-score. Results High validation accuracy was achieved for radiological (100\%) and histopathological (95.12\%) modalities, with clinical images performing lower (63.10\%) due to visual heterogeneity. The ensemble model demonstrated improved diagnostic robustness with an overall accuracy of 84.58\% on a multimodal validation dataset of 55 samples. Conclusion The multimodal ensemble framework bridges gaps in the current diagnostic workflow by offering a non-invasive, AI-assisted triage tool that enhances early identification of high-risk lesions. It supports clinicians in decision-making, aligning with global oncology guidelines to reduce diagnostic delays and improve patient outcomes.</li>
</ul>

<h3>Title: Exploring Instruction Data Quality for Explainable Image Quality Assessment</h3>
<ul>
<li><strong>Authors: </strong>Yunhao Li, Sijing Wu, Huiyu Duan, Yucheng Zhu, Qi Jia, Guangtao Zhai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03880">https://arxiv.org/abs/2510.03880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03880">https://arxiv.org/pdf/2510.03880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03880]] Exploring Instruction Data Quality for Explainable Image Quality Assessment(https://arxiv.org/abs/2510.03880)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>In recent years, with the rapid development of powerful multimodal large language models (MLLMs), explainable image quality assessment (IQA) has gradually become popular, aiming at providing quality-related descriptions and answers of images. To achieve this goal, recent methods seek to construct a large-scale instruction tuning dataset to empower the MLLM with quality perception ability following the well-known scaling law. However, a large amount of instruction tuning data may cause substantial computational costs and redundant data, which in turn will cause harm to the performance of the model. To cope with this problem, in this paper, we challenge the scaling law and systematically investigate the role of data quality of the instruction tuning dataset for explainable IQA. Using a powerful pre-trained MLLM, we first investigate the changes in model performance after fine-tuning with different sizes of instruction tuning data. We find that selecting a subset of the data set randomly using an appropriate ratio can even lead to better results than training with the entire instruction tuning dataset, demonstrating the redundancy of current explainable IQA instruction tuning data. Beyond randomly sampling a subset, we propose a clustering-based data selection framework with three stages: clustering feature extraction, cluster quota allocation, and cluster sampling strategy. Then we systematically analyze the choices of each stage and propose a simple but efficient data selection method IQA-Select for explainable IQA. The experimental results demonstrate that IQA-Select can achieve 102.1% and 103.7% performance of full fine-tuning using only 10% selected data in Q-Bench and AesBench respectively, significantly reducing computational costs while achieving better performance.</li>
</ul>

<h3>Title: BONSAI: Structure-exploiting robust Bayesian optimization for networked black-box systems under uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Akshay Kudva, Joel A. Paulson</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03893">https://arxiv.org/abs/2510.03893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03893">https://arxiv.org/pdf/2510.03893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03893]] BONSAI: Structure-exploiting robust Bayesian optimization for networked black-box systems under uncertainty(https://arxiv.org/abs/2510.03893)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Optimal design under uncertainty remains a fundamental challenge in advancing reliable, next-generation process systems. Robust optimization (RO) offers a principled approach by safeguarding against worst-case scenarios across a range of uncertain parameters. However, traditional RO methods typically require known problem structure, which limits their applicability to high-fidelity simulation environments. To overcome these limitations, recent work has explored robust Bayesian optimization (RBO) as a flexible alternative that can accommodate expensive, black-box objectives. Existing RBO methods, however, generally ignore available structural information and struggle to scale to high-dimensional settings. In this work, we introduce BONSAI (Bayesian Optimization of Network Systems under uncertAInty), a new RBO framework that leverages partial structural knowledge commonly available in simulation-based models. Instead of treating the objective as a monolithic black box, BONSAI represents it as a directed graph of interconnected white- and black-box components, allowing the algorithm to utilize intermediate information within the optimization process. We further propose a scalable Thompson sampling-based acquisition function tailored to the structured RO setting, which can be efficiently optimized using gradient-based methods. We evaluate BONSAI across a diverse set of synthetic and real-world case studies, including applications in process systems engineering. Compared to existing simulation-based RO algorithms, BONSAI consistently delivers more sample-efficient and higher-quality robust solutions, highlighting its practical advantages for uncertainty-aware design in complex engineering systems.</li>
</ul>

<h3>Title: Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Liu, Zheng Huang, Xiaoyi Lin, Muzhi Zhu, Canyu Zhao, Zongze Du, Yating Wang, Haoyi Zhu, Hao Chen, Chunhua Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03896">https://arxiv.org/abs/2510.03896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03896">https://arxiv.org/pdf/2510.03896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03896]] Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert(https://arxiv.org/abs/2510.03896)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Although Vision-Language Models (VLM) have demonstrated impressive planning and reasoning capabilities, translating these abilities into the physical world introduces significant challenges. Conventional Vision-Language-Action (VLA) models, which integrate reasoning and action into a monolithic architecture, generalize poorly because they are constrained by scarce, narrow-domain data. While recent dual-system approaches attempt to decouple "thinking" from "acting", they are often constrained by semantic ambiguities within the action module. This ambiguity makes large-scale, cross-task training infeasible. Consequently, these systems typically necessitate fine-tuning on newly collected data when deployed to novel environments, and the cooperation mechanism between the two systems remains ill-defined. To address these limitations, we introduce, for the first time, a framework centered around a generalizable action expert. Our approach utilizes sparse 3D trajectories as an intermediate representation, effectively bridging the high-level planning capabilities of the VLM with the low-level physical action module. During the planning phase, the VLM is only required to generate coarse 3D waypoints. These waypoints are then processed by our generalizable action expert, which refines them into dense, executable action sequences by sampling real-time point cloud observations of the environment. To promote training efficiency and robust generalization, we introduce a novel "Action Pre-training, Pointcloud Fine-tuning" paradigm. Our method combines the broad generalization capabilities of VLMs in visual understanding and planning with the fine-grained, action-level generalization of action expert.</li>
</ul>

<h3>Title: Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles</h3>
<ul>
<li><strong>Authors: </strong>Nusrat Jahan Lia, Shubhashis Roy Dipta, Abdullah Khan Zehady, Naymul Islam, Madhusodan Chakraborty, Abdullah Al Wasif</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03898">https://arxiv.org/abs/2510.03898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03898">https://arxiv.org/pdf/2510.03898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03898]] Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles(https://arxiv.org/abs/2510.03898)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting media bias is crucial, specifically in the South Asian region. Despite this, annotated datasets and computational studies for Bangla political bias research remain scarce. Crucially because, political stance detection in Bangla news requires understanding of linguistic cues, cultural context, subtle biases, rhetorical strategies, code-switching, implicit sentiment, and socio-political background. To address this, we introduce the first benchmark dataset of 200 politically significant and highly debated Bangla news articles, labeled for government-leaning, government-critique, and neutral stances, alongside diagnostic analyses for evaluating large language models (LLMs). Our comprehensive evaluation of 28 proprietary and open-source LLMs shows strong performance in detecting government-critique content (F1 up to 0.83) but substantial difficulty with neutral articles (F1 as low as 0.00). Models also tend to over-predict government-leaning stances, often misinterpreting ambiguous narratives. This dataset and its associated diagnostics provide a foundation for advancing stance detection in Bangla media research and offer insights for improving LLM performance in low-resource languages.</li>
</ul>

<h3>Title: LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Hangting Ye, Jinmeng Li, He Zhao, Mingchen Zhuge, Dandan Guo, Yi Chang, Hongyuan Zha</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03904">https://arxiv.org/abs/2510.03904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03904">https://arxiv.org/pdf/2510.03904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03904]] LLM as an Algorithmist: Enhancing Anomaly Detectors via Programmatic Synthesis(https://arxiv.org/abs/2510.03904)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Existing anomaly detection (AD) methods for tabular data usually rely on some assumptions about anomaly patterns, leading to inconsistent performance in real-world scenarios. While Large Language Models (LLMs) show remarkable reasoning capabilities, their direct application to tabular AD is impeded by fundamental challenges, including difficulties in processing heterogeneous data and significant privacy risks. To address these limitations, we propose LLM-DAS, a novel framework that repositions the LLM from a ``data processor'' to an ``algorithmist''. Instead of being exposed to raw data, our framework leverages the LLM's ability to reason about algorithms. It analyzes a high-level description of a given detector to understand its intrinsic weaknesses and then generates detector-specific, data-agnostic Python code to synthesize ``hard-to-detect'' anomalies that exploit these vulnerabilities. This generated synthesis program, which is reusable across diverse datasets, is then instantiated to augment training data, systematically enhancing the detector's robustness by transforming the problem into a more discriminative two-class classification task. Extensive experiments on 36 TAD benchmarks show that LLM-DAS consistently boosts the performance of mainstream detectors. By bridging LLM reasoning with classic AD algorithms via programmatic synthesis, LLM-DAS offers a scalable, effective, and privacy-preserving approach to patching the logical blind spots of existing detectors.</li>
</ul>

<h3>Title: From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance</h3>
<ul>
<li><strong>Authors: </strong>Ardalan Aryashad, Parsa Razmara, Amin Mahjoub, Seyedarmin Azizi, Mahdi Salmani, Arad Firouzkouhi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03906">https://arxiv.org/abs/2510.03906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03906">https://arxiv.org/pdf/2510.03906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03906]] From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance(https://arxiv.org/abs/2510.03906)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Autonomous driving perception systems are particularly vulnerable in foggy conditions, where light scattering reduces contrast and obscures fine details critical for safe operation. While numerous defogging methods exist-from handcrafted filters to learned restoration models-improvements in image fidelity do not consistently translate into better downstream detection and segmentation. Moreover, prior evaluations often rely on synthetic data, leaving questions about real-world transferability. We present a structured empirical study that benchmarks a comprehensive set of pipelines, including (i) classical filters, (ii) modern defogging networks, (iii) chained variants (filter$\rightarrow$model, model$\rightarrow$filter), and (iv) prompt-driven visual--language image editing models (VLM) applied directly to foggy images. Using Foggy Cityscapes, we assess both image quality and downstream performance on object detection (mAP) and segmentation (PQ, RQ, SQ). Our analysis reveals when defogging helps, when chaining yields synergy or degradation, and how VLM-based editors compare to dedicated approaches. In addition, we evaluate qualitative rubric-based scores from a VLM judge and quantify their alignment with task metrics, showing strong correlations with mAP. Together, these results establish a transparent, task-oriented benchmark for defogging methods and highlight the conditions under which preprocessing genuinely improves autonomous perception in adverse weather.</li>
</ul>

<h3>Title: Generating Human Motion Videos using a Cascaded Text-to-Video Framework</h3>
<ul>
<li><strong>Authors: </strong>Hyelin Nam, Hyojun Go, Byeongjun Park, Byung-Hoon Kim, Hyungjin Chung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03909">https://arxiv.org/abs/2510.03909</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03909">https://arxiv.org/pdf/2510.03909</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03909]] Generating Human Motion Videos using a Cascaded Text-to-Video Framework(https://arxiv.org/abs/2510.03909)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Human video generation is becoming an increasingly important task with broad applications in graphics, entertainment, and embodied AI. Despite the rapid progress of video diffusion models (VDMs), their use for general-purpose human video generation remains underexplored, with most works constrained to image-to-video setups or narrow domains like dance videos. In this work, we propose CAMEO, a cascaded framework for general human motion video generation. It seamlessly bridges Text-to-Motion (T2M) models and conditional VDMs, mitigating suboptimal factors that may arise in this process across both training and inference through carefully designed components. Specifically, we analyze and prepare both textual prompts and visual conditions to effectively train the VDM, ensuring robust alignment between motion descriptions, conditioning signals, and the generated videos. Furthermore, we introduce a camera-aware conditioning module that connects the two stages, automatically selecting viewpoints aligned with the input text to enhance coherence and reduce manual intervention. We demonstrate the effectiveness of our approach on both the MovieGen benchmark and a newly introduced benchmark tailored to the T2M-VDM combination, while highlighting its versatility across diverse use cases.</li>
</ul>

<h3>Title: THEMIS: Unlocking Pretrained Knowledge with Foundation Model Embeddings for Anomaly Detection in Time Series</h3>
<ul>
<li><strong>Authors: </strong>Yadav Mahesh Lorik, Kaushik Sarveswaran, Nagaraj Sundaramahalingam, Aravindakumar Venugopalan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03911">https://arxiv.org/abs/2510.03911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03911">https://arxiv.org/pdf/2510.03911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03911]] THEMIS: Unlocking Pretrained Knowledge with Foundation Model Embeddings for Anomaly Detection in Time Series(https://arxiv.org/abs/2510.03911)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Time series anomaly detection forms a very crucial area in several domains but poses substantial challenges. Due to time series data possessing seasonality, trends, noise, and evolving patterns (concept drift), it becomes very difficult to set a general notion of what constitutes normal behavior. Anomalies themselves could be varied, ranging from a single outlier to contextual or collective anomalies, and are normally very rare; hence, the dataset is largely imbalanced. Additional layers of complexities arise due to the problems of increased dimensionality of modern time series, real-time detection criteria, setting up appropriate detection thresholds, and arriving at results that are interpretable. To embrace these multifaceted challenges, very strong, flexible, and interpretable approaches are required. This paper presents THEMIS, a new framework for time series anomaly detection that exploits pretrained knowledge from foundation models. THEMIS extracts embeddings from the encoder of the Chronos time series foundation model and applies outlier detection techniques like Local Outlier Factor and Spectral Decomposition on the self-similarity matrix, to spot anomalies in the data. Our experiments show that this modular method achieves SOTA results on the MSL dataset and performs quite competitively on the SMAP and SWAT$^*$ datasets. Notably, THEMIS exceeds models trained specifically for anomaly detection, presenting hyperparameter robustness and interpretability by default. This paper advocates for pretrained representations from foundation models for performing efficient and adaptable anomaly detection for time series data.</li>
</ul>

<h3>Title: PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Amin Abbasi, Hassan Naderi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03913">https://arxiv.org/abs/2510.03913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03913">https://arxiv.org/pdf/2510.03913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03913]] PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian(https://arxiv.org/abs/2510.03913)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This study presents PsychoLexTherapy, a framework for simulating psychotherapeutic reasoning in Persian using small language models (SLMs). The framework tackles the challenge of developing culturally grounded, therapeutically coherent dialogue systems with structured memory for multi-turn interactions in underrepresented languages. To ensure privacy and feasibility, PsychoLexTherapy is optimized for on-device deployment, enabling use without external servers. Development followed a three-stage process: (i) assessing SLMs psychological knowledge with PsychoLexEval; (ii) designing and implementing the reasoning-oriented PsychoLexTherapy framework; and (iii) constructing two evaluation datasets-PsychoLexQuery (real Persian user questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark against multiple baselines. Experiments compared simple prompting, multi-agent debate, and structured therapeutic reasoning paths. Results showed that deliberate model selection balanced accuracy, efficiency, and privacy. On PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic LLM-as-a-judge evaluation and was ranked highest by human evaluators in a single-turn preference study. In multi-turn tests with PsychoLexDialogue, the long-term memory module proved essential: while naive history concatenation caused incoherence and information loss, the full framework achieved the highest ratings in empathy, coherence, cultural fit, and personalization. Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and culturally aligned foundation for Persian psychotherapy simulation, contributing novel datasets, a reproducible evaluation pipeline, and empirical insights into structured memory for therapeutic reasoning.</li>
</ul>

<h3>Title: OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications</h3>
<ul>
<li><strong>Authors: </strong>Sagar Bharadwaj, Harrison Williams, Luke Wang, Michael Liang, Tao Jin, Srinivasan Seshan, Anthony Rowe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.DC, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03915">https://arxiv.org/abs/2510.03915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03915">https://arxiv.org/pdf/2510.03915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03915]] OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications(https://arxiv.org/abs/2510.03915)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>World-scale augmented reality (AR) applications need a ubiquitous 6DoF localization backend to anchor content to the real world consistently across devices. Large organizations such as Google and Niantic are 3D scanning outdoor public spaces in order to build their own Visual Positioning Systems (VPS). These centralized VPS solutions fail to meet the needs of many future AR applications -- they do not cover private indoor spaces because of privacy concerns, regulations, and the labor bottleneck of updating and maintaining 3D scans. In this paper, we present OpenFLAME, a federated VPS backend that allows independent organizations to 3D scan and maintain a separate VPS service for their own spaces. This enables access control of indoor 3D scans, distributed maintenance of the VPS backend, and encourages larger coverage. Sharding of VPS services introduces several unique challenges -- coherency of localization results across spaces, quality control of VPS services, selection of the right VPS service for a location, and many others. We introduce the concept of federated image-based localization and provide reference solutions for managing and merging data across maps without sharing private data.</li>
</ul>

<h3>Title: Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Arushi Dashore, Aryan Anumala, Emily Hui, Olivia Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03921">https://arxiv.org/abs/2510.03921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03921">https://arxiv.org/pdf/2510.03921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03921]] Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition(https://arxiv.org/abs/2510.03921)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Automated tennis stroke analysis has advanced significantly with the integration of biomechanical motion cues alongside deep learning techniques, enhancing stroke classification accuracy and player performance evaluation. Despite these advancements, existing systems often fail to connect biomechanical insights with actionable language feedback that is both accessible and meaningful to players and coaches. This research project addresses this gap by developing a novel framework that extracts key biomechanical features (such as joint angles, limb velocities, and kinetic chain patterns) from motion data using Convolutional Neural Network Long Short-Term Memory (CNN-LSTM)-based models. These features are analyzed for relationships influencing stroke effectiveness and injury risk, forming the basis for feedback generation using large language models (LLMs). Leveraging the THETIS dataset and feature extraction techniques, our approach aims to produce feedback that is technically accurate, biomechanically grounded, and actionable for end-users. The experimental setup evaluates this framework on classification performance and interpretability, bridging the gap between explainable AI and sports biomechanics.</li>
</ul>

<h3>Title: LLM Chemistry Estimation for Multi-LLM Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Huascar Sanchez, Briland Hitaj</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03930">https://arxiv.org/abs/2510.03930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03930">https://arxiv.org/pdf/2510.03930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03930]] LLM Chemistry Estimation for Multi-LLM Recommendation(https://arxiv.org/abs/2510.03930)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-LLM collaboration promises accurate, robust, and context-aware solutions, yet existing approaches rely on implicit selection and output assessment without analyzing whether collaborating models truly complement or conflict. We introduce LLM Chemistry -- a framework that measures when LLM combinations exhibit synergistic or antagonistic behaviors that shape collective performance beyond individual capabilities. We formalize the notion of chemistry among LLMs, propose algorithms that quantify it by analyzing interaction dependencies, and recommend optimal model ensembles accordingly. Our theoretical analysis shows that chemistry among collaborating LLMs is most evident under heterogeneous model profiles, with its outcome impact shaped by task type, group size, and complexity. Evaluation on classification, summarization, and program repair tasks provides initial evidence for these task-dependent effects, thereby reinforcing our theoretical results. This establishes LLM Chemistry as both a diagnostic factor in multi-LLM systems and a foundation for ensemble recommendation.</li>
</ul>

<h3>Title: On the Empirical Power of Goodness-of-Fit Tests in Watermark Detection</h3>
<ul>
<li><strong>Authors: </strong>Weiqing He, Xiang Li, Tianqi Shang, Li Shen, Weijie Su, Qi Long</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03944">https://arxiv.org/abs/2510.03944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03944">https://arxiv.org/pdf/2510.03944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03944]] On the Empirical Power of Goodness-of-Fit Tests in Watermark Detection(https://arxiv.org/abs/2510.03944)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) raise concerns about content authenticity and integrity because they can generate human-like text at scale. Text watermarks, which embed detectable statistical signals into generated text, offer a provable way to verify content origin. Many detection methods rely on pivotal statistics that are i.i.d. under human-written text, making goodness-of-fit (GoF) tests a natural tool for watermark detection. However, GoF tests remain largely underexplored in this setting. In this paper, we systematically evaluate eight GoF tests across three popular watermarking schemes, using three open-source LLMs, two datasets, various generation temperatures, and multiple post-editing methods. We find that general GoF tests can improve both the detection power and robustness of watermark detectors. Notably, we observe that text repetition, common in low-temperature settings, gives GoF tests a unique advantage not exploited by existing methods. Our results highlight that classic GoF tests are a simple yet powerful and underused tool for watermark detection in LLMs.</li>
</ul>

<h3>Title: Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sameep Vani, Shreyas Jena, Maitreya Patel, Chitta Baral, Somak Aditya, Yezhou Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03955">https://arxiv.org/abs/2510.03955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03955">https://arxiv.org/pdf/2510.03955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03955]] Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs(https://arxiv.org/abs/2510.03955)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Video Large Language Models (Video-LLMs) have demonstrated remarkable performance across general video understanding benchmarks-particularly in video captioning and descriptive tasks-they consistently underperform on tasks that require fine-grained temporal understanding. This limitation arises due to the lack of visual complexity and temporal nuance in current fine-tuning datasets, leading these models to rely heavily on language-based reasoning rather than truly understanding video dynamics. In this work, we propose TimeWarp, a systematic method to create a targeted synthetic temporal dataset to fine-tune the model's responses to encourage it to focus on the given input video. We introduce a large-scale preference dataset, created using TimeWarp, that captures intricate temporal dynamics often overlooked, grounding the model's responses to visual and temporal information. We demonstrate that when our method is applied to existing models, it significantly improves performance on temporal understanding benchmarks, highlighting the effectiveness of our proposed datasets in advancing temporal understanding in Video-LLMs, resulting in an absolute improvement in performance across seven benchmarks. Code is available at this https URL.</li>
</ul>

<h3>Title: SPEAR: Soft Prompt Enhanced Anomaly Recognition for Time Series Data</h3>
<ul>
<li><strong>Authors: </strong>Hanzhe Wei, Jiajun Wu, Jialin Yang, Henry Leung, Steve Drew</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03962">https://arxiv.org/abs/2510.03962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03962">https://arxiv.org/pdf/2510.03962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03962]] SPEAR: Soft Prompt Enhanced Anomaly Recognition for Time Series Data(https://arxiv.org/abs/2510.03962)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series anomaly detection plays a crucial role in a wide range of fields, such as healthcare and internet traffic monitoring. The emergence of large language models (LLMs) offers new opportunities for detecting anomalies in the ubiquitous time series data. Traditional approaches struggle with variable-length time series sequences and context-based anomalies. We propose Soft Prompt Enhanced Anomaly Recognition (SPEAR), a novel approach to leverage LLMs for anomaly detection with soft prompts and quantization. Our methodology involves quantizing and transforming the time series data into input embeddings and combining them with learnable soft prompt embeddings. These combined embeddings are then fed into a frozen LLM. The soft prompts are updated iteratively based on a cross-entropy loss, allowing the model to adapt to time series anomaly detection. The use of soft prompts helps adapt LLMs effectively to time series tasks, while quantization ensures optimal handling of sequences, as LLMs are designed to handle discrete sequences. Our experimental results demonstrate that soft prompts effectively increase LLMs' performance in downstream tasks regarding time series anomaly detection.</li>
</ul>

<h3>Title: What Can You Do When You Have Zero Rewards During RL?</h3>
<ul>
<li><strong>Authors: </strong>Jatin Prakash, Anirudh Buvanesh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03971">https://arxiv.org/abs/2510.03971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03971">https://arxiv.org/pdf/2510.03971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03971]] What Can You Do When You Have Zero Rewards During RL?(https://arxiv.org/abs/2510.03971)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) with outcome-based rewards has proven effective for improving large language models (LLMs) on complex reasoning tasks. However, its success often depends on the base model occasionally sampling correct solutions. When no correct solutions are sampled, training encounters a zero-reward barrier where learning stalls due to zero gradients. We study this scenario through the graph search task introduced in Bachmann et al. (2024) and evaluate recent methods that incorporate desirable components such as dense rewards, diversity incentives, and improved credit assignment. Our experiments show that none of these approaches overcome the zero-reward barrier if the base model never produces a correct answer. In contrast, we find that a simple data-centric intervention of adding easier samples to the training set enables the model to eventually solve the original hard task despite starting from zero reward. Importantly, this succeeds without modifying the RL algorithm itself. Because official implementations of several baselines were unavailable, we developed our own, which allowed us to conduct a detailed analysis of their failure modes. We release these implementations to support further research at: this https URL</li>
</ul>

<h3>Title: ICEPool: Enhancing Graph Pooling Networks with Inter-cluster Connectivity</h3>
<ul>
<li><strong>Authors: </strong>Michael Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03987">https://arxiv.org/abs/2510.03987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03987">https://arxiv.org/pdf/2510.03987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03987]] ICEPool: Enhancing Graph Pooling Networks with Inter-cluster Connectivity(https://arxiv.org/abs/2510.03987)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hierarchical Pooling Models have demonstrated strong performance in classifying graph-structured data. While numerous innovative methods have been proposed to design cluster assignments and coarsening strategies, the relationships between clusters are often overlooked. In this paper, we introduce Inter-cluster Connectivity Enhancement Pooling (ICEPool), a novel hierarchical pooling framework designed to enhance model's understanding of inter-cluster connectivity and ability of preserving the structural integrity in the original graph. ICEPool is compatible with a wide range of pooling-based GNN models. The deployment of ICEPool as an enhancement to existing models effectively combines the strengths of the original model with ICEPool's capability to emphasize the integration of inter-cluster connectivity, resulting in a more comprehensive and robust graph-level representation. Moreover, we make theoretical analysis to ICEPool's ability of graph reconstruction to demonstrate its effectiveness in learning inter-cluster relationship that is overlooked by conventional models. Finally, the experimental results show the compatibility of ICEPool with wide varieties of models and its potential to boost the performance of existing graph neural network architectures.</li>
</ul>

<h3>Title: A Mathematical Explanation of Transformers for Large Language Models and GPTs</h3>
<ul>
<li><strong>Authors: </strong>Xue-Cheng Tai, Hao Liu, Lingfeng Li, Raymond H. Chan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03989">https://arxiv.org/abs/2510.03989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03989">https://arxiv.org/pdf/2510.03989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03989]] A Mathematical Explanation of Transformers for Large Language Models and GPTs(https://arxiv.org/abs/2510.03989)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The Transformer architecture has revolutionized the field of sequence modeling and underpins the recent breakthroughs in large language models (LLMs). However, a comprehensive mathematical theory that explains its structure and operations remains elusive. In this work, we propose a novel continuous framework that rigorously interprets the Transformer as a discretization of a structured integro-differential equation. Within this formulation, the self-attention mechanism emerges naturally as a non-local integral operator, and layer normalization is characterized as a projection to a time-dependent constraint. This operator-theoretic and variational perspective offers a unified and interpretable foundation for understanding the architecture's core components, including attention, feedforward layers, and normalization. Our approach extends beyond previous theoretical analyses by embedding the entire Transformer operation in continuous domains for both token indices and feature dimensions. This leads to a principled and flexible framework that not only deepens theoretical insight but also offers new directions for architecture design, analysis, and control-based interpretations. This new interpretation provides a step toward bridging the gap between deep learning architectures and continuous mathematical modeling, and contributes a foundational perspective to the ongoing development of interpretable and theoretically grounded neural network models.</li>
</ul>

<h3>Title: Quantifying Distributional Robustness of Agentic Tool-Selection</h3>
<ul>
<li><strong>Authors: </strong>Jehyeok Yeon, Isha Chaudhary, Gagandeep Singh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03992">https://arxiv.org/abs/2510.03992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03992">https://arxiv.org/pdf/2510.03992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03992]] Quantifying Distributional Robustness of Agentic Tool-Selection(https://arxiv.org/abs/2510.03992)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in agentic systems where they map user intents to relevant external tools to fulfill a task. A critical step in this process is tool selection, where a retriever first surfaces candidate tools from a larger pool, after which the LLM selects the most appropriate one. This pipeline presents an underexplored attack surface where errors in selection can lead to severe outcomes like unauthorized data access or denial of service, all without modifying the agent's model or code. While existing evaluations measure task performance in benign settings, they overlook the specific vulnerabilities of the tool selection mechanism under adversarial conditions. To address this gap, we introduce ToolCert, the first statistical framework that formally certifies tool selection robustness. ToolCert models tool selection as a Bernoulli success process and evaluates it against a strong, adaptive attacker who introduces adversarial tools with misleading metadata, and are iteratively refined based on the agent's previous choices. By sampling these adversarial interactions, ToolCert produces a high-confidence lower bound on accuracy, formally quantifying the agent's worst-case performance. Our evaluation with ToolCert uncovers the severe fragility: under attacks injecting deceptive tools or saturating retrieval, the certified accuracy bound drops near zero, an average performance drop of over 60% compared to non-adversarial settings. For attacks targeting the retrieval and selection stages, the certified accuracy bound plummets to less than 20% after just a single round of adversarial adaptation. ToolCert thus reveals previously unexamined security threats inherent to tool selection and provides a principled method to quantify an agent's robustness to such threats, a necessary step for the safe deployment of agentic systems.</li>
</ul>

<h3>Title: PrivSpike: Employing Homomorphic Encryption for Private Inference of Deep Spiking Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Nges Brian Njungle, Eric Jahns, Milan Stojkov, Michel A. Kinsy</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03995">https://arxiv.org/abs/2510.03995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03995">https://arxiv.org/pdf/2510.03995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03995]] PrivSpike: Employing Homomorphic Encryption for Private Inference of Deep Spiking Neural Networks(https://arxiv.org/abs/2510.03995)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy</a></li>
<li><strong>Abstract: </strong>Deep learning has become a cornerstone of modern machine learning. It relies heavily on vast datasets and significant computational resources for high performance. This data often contains sensitive information, making privacy a major concern in deep learning. Spiking Neural Networks (SNNs) have emerged as an energy-efficient alternative to conventional deep learning approaches. Nevertheless, SNNs still depend on large volumes of data, inheriting all the privacy challenges of deep learning. Homomorphic encryption addresses this challenge by allowing computations to be performed on encrypted data, ensuring data confidentiality throughout the entire processing pipeline. In this paper, we introduce PRIVSPIKE, a privacy-preserving inference framework for SNNs using the CKKS homomorphic encryption scheme. PRIVSPIKE supports arbitrary depth SNNs and introduces two key algorithms for evaluating the Leaky Integrate-and-Fire activation function: (1) a polynomial approximation algorithm designed for high-performance SNN inference, and (2) a novel scheme-switching algorithm that optimizes precision at a higher computational cost. We evaluate PRIVSPIKE on MNIST, CIFAR-10, Neuromorphic MNIST, and CIFAR-10 DVS using models from LeNet-5 and ResNet-19 architectures, achieving encrypted inference accuracies of 98.10%, 79.3%, 98.1%, and 66.0%, respectively. On a consumer-grade CPU, SNN LeNet-5 models achieved inference times of 28 seconds on MNIST and 212 seconds on Neuromorphic MNIST. For SNN ResNet-19 models, inference took 784 seconds on CIFAR-10 and 1846 seconds on CIFAR-10 DVS. These results establish PRIVSPIKE as a viable and efficient solution for secure SNN inference, bridging the gap between energy-efficient deep neural networks and strong cryptographic privacy guarantees while outperforming prior encrypted SNN solutions.</li>
</ul>

<h3>Title: FHEON: A Configurable Framework for Developing Privacy-Preserving Neural Networks Using Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Nges Brian Njungle, Eric Jahns, Michel A. Kinsy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03996">https://arxiv.org/abs/2510.03996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03996">https://arxiv.org/pdf/2510.03996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03996]] FHEON: A Configurable Framework for Developing Privacy-Preserving Neural Networks Using Homomorphic Encryption(https://arxiv.org/abs/2510.03996)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>The widespread adoption of Machine Learning as a Service raises critical privacy and security concerns, particularly about data confidentiality and trust in both cloud providers and the machine learning models. Homomorphic Encryption (HE) has emerged as a promising solution to this problems, allowing computations on encrypted data without decryption. Despite its potential, existing approaches to integrate HE into neural networks are often limited to specific architectures, leaving a wide gap in providing a framework for easy development of HE-friendly privacy-preserving neural network models similar to what we have in the broader field of machine learning. In this paper, we present FHEON, a configurable framework for developing privacy-preserving convolutional neural network (CNN) models for inference using HE. FHEON introduces optimized and configurable implementations of privacy-preserving CNN layers including convolutional layers, average pooling layers, ReLU activation functions, and fully connected layers. These layers are configured using parameters like input channels, output channels, kernel size, stride, and padding to support arbitrary CNN architectures. We assess the performance of FHEON using several CNN architectures, including LeNet-5, VGG-11, VGG- 16, ResNet-20, and ResNet-34. FHEON maintains encrypted-domain accuracies within +/- 1% of their plaintext counterparts for ResNet-20 and LeNet-5 models. Notably, on a consumer-grade CPU, the models build on FHEON achieved 98.5% accuracy with a latency of 13 seconds on MNIST using LeNet-5, and 92.2% accuracy with a latency of 403 seconds on CIFAR-10 using ResNet-20. Additionally, FHEON operates within a practical memory budget requiring not more than 42.3 GB for VGG-16.</li>
</ul>

<h3>Title: Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Junjie Luo, Rui Han, Arshana Welivita, Zeleikun Di, Jingfu Wu, Xuzhe Zhi, Ritu Agarwal, Gordon Gao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03997">https://arxiv.org/abs/2510.03997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03997">https://arxiv.org/pdf/2510.03997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03997]] Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs(https://arxiv.org/abs/2510.03997)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Understanding how patients perceive their physicians is essential to improving trust, communication, and satisfaction. We present a large language model (LLM)-based pipeline that infers Big Five personality traits and five patient-oriented subjective judgments. The analysis encompasses 4.1 million patient reviews of 226,999 U.S. physicians from an initial pool of one million. We validate the method through multi-model comparison and human expert benchmarking, achieving strong agreement between human and LLM assessments (correlation coefficients 0.72-0.89) and external validity through correlations with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis reveals systematic patterns: male physicians receive higher ratings across all traits, with largest disparities in clinical competence perceptions; empathy-related traits predominate in pediatrics and psychiatry; and all traits positively predict overall satisfaction. Cluster analysis identifies four distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly high traits) to "Underperforming" (22.6%, consistently low). These findings demonstrate that automated trait extraction from patient narratives can provide interpretable, validated metrics for understanding physician-patient relationships at scale, with implications for quality measurement, bias detection, and workforce development in healthcare.</li>
</ul>

<h3>Title: Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions</h3>
<ul>
<li><strong>Authors: </strong>Yang Xu, Xuanming Zhang, Min-Hsuan Yeh, Jwala Dhamala, Ousmane Dia, Rahul Gupta, Yixuan Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.03999">https://arxiv.org/abs/2510.03999</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.03999">https://arxiv.org/pdf/2510.03999</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.03999]] Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions(https://arxiv.org/abs/2510.03999)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deception is a pervasive feature of human communication and an emerging concern in large language models (LLMs). While recent studies document instances of LLM deception under pressure, most evaluations remain confined to single-turn prompts and fail to capture the long-horizon interactions in which deceptive strategies typically unfold. We introduce the first simulation framework for probing and evaluating deception in LLMs under extended sequences of interdependent tasks and dynamic contextual pressures. Our framework instantiates a multi-agent system: a performer agent tasked with completing tasks and a supervisor agent that evaluates progress, provides feedback, and maintains evolving states of trust. An independent deception auditor then reviews full trajectories to identify when and how deception occurs. We conduct extensive experiments across 11 frontier models, spanning both closed- and open-source systems, and find that deception is model-dependent, increases with event pressure, and consistently erodes supervisor trust. Qualitative analyses further reveal distinct strategies of concealment, equivocation, and falsification. Our findings establish deception as an emergent risk in long-horizon interactions and provide a foundation for evaluating future LLMs in real-world, trust-sensitive contexts.</li>
</ul>

<h3>Title: Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Xuankang Zhang, Jiangming Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04001">https://arxiv.org/abs/2510.04001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04001">https://arxiv.org/pdf/2510.04001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04001]] Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation(https://arxiv.org/abs/2510.04001)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The COVID-19 pandemic causes severe social and economic disruption around the world, raising various subjects that are discussed over social media. Identifying pandemic-related named entities as expressed on social media is fundamental and important to understand the discussions about the pandemic. However, there is limited work on named entity recognition on this topic due to the following challenges: 1) COVID-19 texts in social media are informal and their annotations are rare and insufficient to train a robust recognition model, and 2) named entity recognition in COVID-19 requires extensive domain-specific knowledge. To address these issues, we propose a novel entity knowledge augmentation approach for COVID-19, which can also be applied in general biomedical named entity recognition in both informal text format and formal text format. Experiments carried out on the COVID-19 tweets dataset and PubMed dataset show that our proposed entity knowledge augmentation improves NER performance in both fully-supervised and few-shot settings. Our source code is publicly available: this https URL</li>
</ul>

<h3>Title: AgriGPT-VL: Agricultural Vision-Language Understanding Suite</h3>
<ul>
<li><strong>Authors: </strong>Bo Yang, Yunkui Chen, Lanfei Feng, Yu Zhang, Xiao Xu, Jianyu Zhang, Nueraili Aierken, Runhe Huang, Hongjian Lin, Yibin Ying, Shijian Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04002">https://arxiv.org/abs/2510.04002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04002">https://arxiv.org/pdf/2510.04002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04002]] AgriGPT-VL: Agricultural Vision-Language Understanding Suite(https://arxiv.org/abs/2510.04002)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the scarcity of domain-tailored models, curated vision-language corpora, and rigorous evaluation. To address these challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL, the largest vision-language corpus for agriculture to our knowledge, curated by a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO reinforcement learning samples. Second, we develop AgriGPT-VL, an agriculture-specialized vision-language model trained via a progressive curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO refinement. This method achieves strong multimodal reasoning while preserving text-only capability. Third, we establish AgriBench-VL-4K, a compact yet challenging evaluation suite with open-ended and image-grounded questions, paired with multi-metric evaluation and an LLM-as-a-judge framework. Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K with no noticeable degradation of language ability. Ablation studies further confirm consistent gains from our alignment and GRPO refinement stages. We will open source all of the resources to support reproducible research and deployment in low-resource agricultural settings.</li>
</ul>

<h3>Title: LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Liu, Jivitesh Jain, Mona Diab, Nishant Subramani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04013">https://arxiv.org/abs/2510.04013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04013">https://arxiv.org/pdf/2510.04013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04013]] LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization(https://arxiv.org/abs/2510.04013)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) have tremendous utility, trustworthiness is still a chief concern: models often generate incorrect information with high confidence. While contextual information can help guide generation, identifying when a query would benefit from retrieved context and assessing the effectiveness of that context remains challenging. In this work, we operationalize interpretability methods to ascertain whether we can predict the correctness of model outputs from the model's activations alone. We also explore whether model internals contain signals about the efficacy of external context. We consider correct, incorrect, and irrelevant context and introduce metrics to distinguish amongst them. Experiments on six different models reveal that a simple classifier trained on intermediate layer activations of the first output token can predict output correctness with about 75% accuracy, enabling early auditing. Our model-internals-based metric significantly outperforms prompting baselines at distinguishing between correct and incorrect context, guarding against inaccuracies introduced by polluted context. These findings offer a lens to better understand the underlying decision-making processes of LLMs. Our code is publicly available at this https URL</li>
</ul>

<h3>Title: Thai Semantic End-of-Turn Detection for Real-Time Voice Agents</h3>
<ul>
<li><strong>Authors: </strong>Thanapol Popit, Natthapath Rungseesiripak, Monthol Charattrakool, Saksorn Ruangtanusak</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04016">https://arxiv.org/abs/2510.04016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04016">https://arxiv.org/pdf/2510.04016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04016]] Thai Semantic End-of-Turn Detection for Real-Time Voice Agents(https://arxiv.org/abs/2510.04016)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Fluid voice-to-voice interaction requires reliable and low-latency detection of when a user has finished speaking. Traditional audio-silence end-pointers add hundreds of milliseconds of delay and fail under hesitations or language-specific phenomena. We present, to our knowledge, the first systematic study of Thai text-only end-of-turn (EOT) detection for real-time agents. We compare zero-shot and few-shot prompting of compact LLMs to supervised fine-tuning of lightweight transformers. Using transcribed subtitles from the YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final particles), we formulate EOT as a binary decision over token boundaries. We report a clear accuracy-latency tradeoff and provide a public-ready implementation plan. This work establishes a Thai baseline and demonstrates that small, fine-tuned models can deliver near-instant EOT decisions suitable for on-device agents.</li>
</ul>

<h3>Title: Principled and Tractable RL for Reasoning with Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anthony Zhan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04019">https://arxiv.org/abs/2510.04019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04019">https://arxiv.org/pdf/2510.04019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04019]] Principled and Tractable RL for Reasoning with Diffusion Language Models(https://arxiv.org/abs/2510.04019)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs) are a new paradigm of non-autoregressive language models that are trained to predict multiple tokens in parallel and generate text via iterative unmasking. Recent works have successfully pretrained dLLMs to parity with autoregressive LLMs at the 8B scale, but dLLMs have yet to benefit from modern post-training techniques, e.g. reinforcement learning (RL), that have proven effective for autoregressive models. Crucially, algorithms designed for traditional LLMs aren't directly compatible with diffusion frameworks due to inherent differences in modeling assumptions. Moreover, existing attempts at dLLM post-training with RL rely on heuristic-based objectives with no theoretical grounding. In this work, we present Amortized Group Relative Policy Optimization (AGRPO), a principled on-policy RL algorithm designed specifically for dLLMs. AGRPO uses Monte Carlo sampling to compute an unbiased policy gradient estimate, making it the first tractable, faithful adaptation of policy gradient methods for dLLMs. We demonstrate AGRPO's effectiveness on different math/reasoning tasks, a common setting for RL with LLMs, achieving up to +7.6% absolute gain on GSM8K and 3.8x performance on the Countdown task over the baseline LLaDA-8B-Instruct model and 1.3x performance gains over comparable RL methods such as diffu-GRPO. Furthermore, these gains persist across different numbers of sampling steps at inference time, achieving better tradeoffs between compute and performance. Our results demonstrate that online RL algorithms can be extended to diffusion LLMs in principled ways, maintaining both theoretical soundness and practical effectiveness.</li>
</ul>

<h3>Title: Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models</h3>
<ul>
<li><strong>Authors: </strong>Hao Wu, Yuan Gao, Xingjian Shi, Shuaipeng Li, Fan Xu, Fan Zhang, Zhihong Zhu, Weiyan Wang, Xiao Luo, Kun Wang, Xian Wu, Xiaomeng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04020">https://arxiv.org/abs/2510.04020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04020">https://arxiv.org/pdf/2510.04020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04020]] Spatiotemporal Forecasting as Planning: A Model-Based Reinforcement Learning Approach with Generative World Models(https://arxiv.org/abs/2510.04020)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>To address the dual challenges of inherent stochasticity and non-differentiable metrics in physical spatiotemporal forecasting, we propose Spatiotemporal Forecasting as Planning (SFP), a new paradigm grounded in Model-Based Reinforcement Learning. SFP constructs a novel Generative World Model to simulate diverse, high-fidelity future states, enabling an "imagination-based" environmental simulation. Within this framework, a base forecasting model acts as an agent, guided by a beam search-based planning algorithm that leverages non-differentiable domain metrics as reward signals to explore high-return future sequences. These identified high-reward candidates then serve as pseudo-labels to continuously optimize the agent's policy through iterative self-training, significantly reducing prediction error and demonstrating exceptional performance on critical domain metrics like capturing extreme events.</li>
</ul>

<h3>Title: Fit Pixels, Get Labels: Meta-learned Implicit Networks for Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Kushal Vyas, Ashok Veeraraghavan, Guha Balakrishnan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04021">https://arxiv.org/abs/2510.04021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04021">https://arxiv.org/pdf/2510.04021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04021]] Fit Pixels, Get Labels: Meta-learned Implicit Networks for Image Segmentation(https://arxiv.org/abs/2510.04021)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Implicit neural representations (INRs) have achieved remarkable successes in learning expressive yet compact signal representations. However, they are not naturally amenable to predictive tasks such as segmentation, where they must learn semantic structures over a distribution of signals. In this study, we introduce MetaSeg, a meta-learning framework to train INRs for medical image segmentation. MetaSeg uses an underlying INR that simultaneously predicts per pixel intensity values and class labels. It then uses a meta-learning procedure to find optimal initial parameters for this INR over a training dataset of images and segmentation maps, such that the INR can simply be fine-tuned to fit pixels of an unseen test image, and automatically decode its class labels. We evaluated MetaSeg on 2D and 3D brain MRI segmentation tasks and report Dice scores comparable to commonly used U-Net models, but with $90\%$ fewer parameters. MetaSeg offers a fresh, scalable alternative to traditional resource-heavy architectures such as U-Nets and vision transformers for medical image segmentation. Our project is available at this https URL .</li>
</ul>

<h3>Title: Multi-Class Support Vector Machine with Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Jinseong Park, Yujin Choi, Jaewook Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04027">https://arxiv.org/abs/2510.04027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04027">https://arxiv.org/pdf/2510.04027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04027]] Multi-Class Support Vector Machine with Differential Privacy(https://arxiv.org/abs/2510.04027)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>With the increasing need to safeguard data privacy in machine learning models, differential privacy (DP) is one of the major frameworks to build privacy-preserving models. Support Vector Machines (SVMs) are widely used traditional machine learning models due to their robust margin guarantees and strong empirical performance in binary classification. However, applying DP to multi-class SVMs is inadequate, as the standard one-versus-rest (OvR) and one-versus-one (OvO) approaches repeatedly query each data sample when building multiple binary classifiers, thus consuming the privacy budget proportionally to the number of classes. To overcome this limitation, we explore all-in-one SVM approaches for DP, which access each data sample only once to construct multi-class SVM boundaries with margin maximization properties. We propose a novel differentially Private Multi-class SVM (PMSVM) with weight and gradient perturbation methods, providing rigorous sensitivity and convergence analyses to ensure DP in all-in-one SVMs. Empirical results demonstrate that our approach surpasses existing DP-SVM methods in multi-class scenarios.</li>
</ul>

<h3>Title: The Debate on RLVR Reasoning Capability Boundary: Shrinkage, Expansion, or Both? A Two-Stage Dynamic View</h3>
<ul>
<li><strong>Authors: </strong>Xinhao Yao, Lu Yu, Xiaolin Hu, Fengwei Teng, Qing Cui, Jun Zhou, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04028">https://arxiv.org/abs/2510.04028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04028">https://arxiv.org/pdf/2510.04028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04028]] The Debate on RLVR Reasoning Capability Boundary: Shrinkage, Expansion, or Both? A Two-Stage Dynamic View(https://arxiv.org/abs/2510.04028)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The ongoing debate on whether reinforcement learning with verifiable rewards (RLVR) expands or shrinks the reasoning capabilities of large language models (LLMs) remains unresolved. Some studies contend that RLVR mainly improves sampling efficiency but at the expense of diversity and exploratory capacity, resulting in capability boundary shrinkage. In contrast, others demonstrate that prolonged training can lead to the emergence of novel reasoning strategies, suggesting capability boundary expansion. To reconcile these contradictory findings, we theoretically and empirically show that both perspectives are partially valid-each aligning with a separate phase in an inherent two-stage probability mass dynamic: (1) Exploitation stage: initially, the model primarily samples explored high-reward and low-reward tokens, while rarely selecting the potentially optimal token. Positive advantage estimates increase the probability of high-reward tokens and decrease those of low-reward tokens, yet the optimal token's probability remains largely unchanged during this stage. (2) Exploration stage: as training advances, the growth rate of previously acquired high-reward tokens slows as their probabilities approach saturation. When a potentially optimal token-now receiving positive advantage estimates-is occasionally sampled, its probability increases, while those of the originally high-reward tokens decrease. This dynamic suggests that over-exploitation during the exploitation stage may lead to capability boundary shrinkage, whereas prolonged training into the exploration stage can promote an expansion of the reasoning capability boundary. Building upon our insights, we revisit the potential of only using relative negative gradients for prolonging training, providing a theoretical and empirical foundation for the development of more advanced reasoning capabilities.</li>
</ul>

<h3>Title: Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?</h3>
<ul>
<li><strong>Authors: </strong>Nelvin Tan, James Asikin Cheung, Yu-Ching Shih, Dong Yang, Amol Salunkhe</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04031">https://arxiv.org/abs/2510.04031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04031">https://arxiv.org/pdf/2510.04031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04031]] Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?(https://arxiv.org/abs/2510.04031)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are becoming useful in many domains due to their impressive abilities that arise from large training datasets and large model sizes. More recently, they have been shown to be very effective in textual classification tasks, motivating the need to explain the LLMs' decisions. Motivated by practical constrains where LLMs are black-boxed and LLM calls are expensive, we study how incorporating counterfactuals into LLM reasoning can affect the LLM's ability to identify the top words that have contributed to its classification decision. To this end, we introduce a framework called the decision changing rate that helps us quantify the importance of the top words in classification. Our experimental results show that using counterfactuals can be helpful.</li>
</ul>

<h3>Title: Small Language Models for Emergency Departments Decision Support: A Benchmark Study</h3>
<ul>
<li><strong>Authors: </strong>Zirui Wang, Jiajun Wu, Braden Teitge, Jessalyn Holodinsky, Steve Drew</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04032">https://arxiv.org/abs/2510.04032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04032">https://arxiv.org/pdf/2510.04032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04032]] Small Language Models for Emergency Departments Decision Support: A Benchmark Study(https://arxiv.org/abs/2510.04032)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become increasingly popular in medical domains to assist physicians with a variety of clinical and operational tasks. Given the fast-paced and high-stakes environment of emergency departments (EDs), small language models (SLMs), characterized by a reduction in parameter count compared to LLMs, offer significant potential due to their inherent reasoning capability and efficient performance. This enables SLMs to support physicians by providing timely and accurate information synthesis, thereby improving clinical decision-making and workflow efficiency. In this paper, we present a comprehensive benchmark designed to identify SLMs suited for ED decision support, taking into account both specialized medical expertise and broad general problem-solving capabilities. In our evaluations, we focus on SLMs that have been trained on a mixture of general-domain and medical corpora. A key motivation for emphasizing SLMs is the practical hardware limitations, operational cost constraints, and privacy concerns in the typical real-world deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and PubMedQA, with the medical abstracts dataset emulating tasks aligned with real ED physicians' daily tasks. Experimental results reveal that general-domain SLMs surprisingly outperform their medically fine-tuned counterparts across these diverse benchmarks for ED. This indicates that for ED, specialized medical fine-tuning of the model may not be required.</li>
</ul>

<h3>Title: Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance Existing Frameworks</h3>
<ul>
<li><strong>Authors: </strong>Linn Bieske, Carla Lorente</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04034">https://arxiv.org/abs/2510.04034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04034">https://arxiv.org/pdf/2510.04034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04034]] Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance Existing Frameworks(https://arxiv.org/abs/2510.04034)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in image editing have shifted from manual pixel manipulation to employing deep learning methods like stable diffusion models, which now leverage cross-attention mechanisms for text-driven control. This transition has simplified the editing process but also introduced variability in results, such as inconsistent hair color changes. Our research aims to enhance the precision and reliability of prompt-to-prompt image editing frameworks by exploring and optimizing hyperparameters. We present a comprehensive study of the "word swap" method, develop an "attention re-weight method" for better adaptability, and propose the "CL P2P" framework to address existing limitations like cycle inconsistency. This work contributes to understanding and improving the interaction between hyperparameter settings and the architectural choices of neural network models, specifically their attention mechanisms, which significantly influence the composition and quality of the generated images.</li>
</ul>

<h3>Title: \textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding</h3>
<ul>
<li><strong>Authors: </strong>Bin Lei, Nuo Xu, Ali Payani, Mingyi Hong, Chunhua Liao, Yu Cao, Caiwen Ding</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04039">https://arxiv.org/abs/2510.04039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04039">https://arxiv.org/pdf/2510.04039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04039]] \textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding(https://arxiv.org/abs/2510.04039)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have markedly expanded the competence of graphical user-interface (GUI) systems, propelling them beyond controlled simulations into complex, real-world environments across diverse platforms. However, practical usefulness is still bounded by the reliability of visual grounding, i.e., mapping textual references to exact on-screen elements. This limitation prevents the system from accurately performing pointer-level actions such as clicking or dragging. To address it, we introduce GUI-Spotlight -- a model trained for image-grounded reasoning that dynamically invokes multiple specialized tools to iteratively narrow its focus to the relevant region of the screen, thereby substantially improving visual grounding accuracy. On the ScreenSpot-Pro benchmark, GUI-Spotlight trained with only 18.5K training samples achieves 52.8\% accuracy, surpassing V2P-7B (50.6\% with 9.6M training samples) and GTA-1-7B (50.1\% with 1.56M training samples).</li>
</ul>

<h3>Title: Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yunfan Zhang, Kathleen McKeown, Smaranda Muresan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04045">https://arxiv.org/abs/2510.04045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04045">https://arxiv.org/pdf/2510.04045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04045]] Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment(https://arxiv.org/abs/2510.04045)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are typically trained to reflect a relatively uniform set of values, which limits their applicability to tasks that require understanding of nuanced human perspectives. Recent research has underscored the importance of enabling LLMs to support steerable pluralism -- the capacity to adopt a specific perspective and align generated outputs with it. In this work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be applied to building steerable pluralistic models. We explore several methods, including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on synthetic explanations, and Reinforcement Learning with Verifiable Rewards (RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA datasets. Among the methods studied, RLVR consistently outperforms others and demonstrates strong training sample efficiency. We further analyze the generated CoT traces with respect to faithfulness and safety.</li>
</ul>

<h3>Title: Real-VulLLM: An LLM Based Assessment Framework in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Rijha Safdar, Danyail Mateen, Syed Taha Ali, Wajahat Hussain</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04056">https://arxiv.org/abs/2510.04056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04056">https://arxiv.org/pdf/2510.04056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04056]] Real-VulLLM: An LLM Based Assessment Framework in the Wild(https://arxiv.org/abs/2510.04056)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, large language model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) and more specifically Large Language Models (LLMs) have demonstrated exceptional progress in multiple areas including software engineering, however, their capability for vulnerability detection in the wild scenario and its corresponding reasoning remains underexplored. Prompting pre-trained LLMs in an effective way offers a computationally effective and scalable solution. Our contributions are (i)varied prompt designs for vulnerability detection and its corresponding reasoning in the wild. (ii)a real-world vector data store constructed from the National Vulnerability Database, that will provide real time context to vulnerability detection framework, and (iii)a scoring measure for combined measurement of accuracy and reasoning quality. Our contribution aims to examine whether LLMs are ready for wild deployment, thus enabling the reliable use of LLMs stronger for the development of secure software's.</li>
</ul>

<h3>Title: Variational Diffusion Unlearning: A Variational Inference Framework for Unlearning in Diffusion Models under Data Constraints</h3>
<ul>
<li><strong>Authors: </strong>Subhodip Panda, MS Varun, Shreyans Jain, Sarthak Kumar Maharana, Prathosh A.P</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04058">https://arxiv.org/abs/2510.04058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04058">https://arxiv.org/pdf/2510.04058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04058]] Variational Diffusion Unlearning: A Variational Inference Framework for Unlearning in Diffusion Models under Data Constraints(https://arxiv.org/abs/2510.04058)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>For a responsible and safe deployment of diffusion models in various domains, regulating the generated outputs from these models is desirable because such models could generate undesired, violent, and obscene outputs. To tackle this problem, recent works use machine unlearning methodology to forget training data points containing these undesired features from pre-trained generative models. However, these methods proved to be ineffective in data-constrained settings where the whole training dataset is inaccessible. Thus, the principal objective of this work is to propose a machine unlearning methodology that can prevent the generation of outputs containing undesired features from a pre-trained diffusion model in such a data-constrained setting. Our proposed method, termed as Variational Diffusion Unlearning (VDU), is a computationally efficient method that only requires access to a subset of training data containing undesired features. Our approach is inspired by the variational inference framework with the objective of minimizing a loss function consisting of two terms: plasticity inducer and stability regularizer. Plasticity inducer reduces the log-likelihood of the undesired training data points, while the stability regularizer, essential for preventing loss of image generation quality, regularizes the model in parameter space. We validate the effectiveness of our method through comprehensive experiments for both class unlearning and feature unlearning. For class unlearning, we unlearn some user-identified classes from MNIST, CIFAR-10, and tinyImageNet datasets from a pre-trained unconditional denoising diffusion probabilistic model (DDPM). Similarly, for feature unlearning, we unlearn the generation of certain high-level features from a pre-trained Stable Diffusion model</li>
</ul>

<h3>Title: What Scales in Cross-Entropy Scaling Law?</h3>
<ul>
<li><strong>Authors: </strong>Junxi Yan, Zixi Wei, Jingtao Zhan, Qingyao Ai, Yiqun Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04067">https://arxiv.org/abs/2510.04067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04067">https://arxiv.org/pdf/2510.04067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04067]] What Scales in Cross-Entropy Scaling Law?(https://arxiv.org/abs/2510.04067)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The cross-entropy scaling law has long served as a key tool for guiding the development of large language models. It shows that cross-entropy loss decreases in a predictable power-law rate as the model size increases. However, recent evidence indicates that this law breaks down at very large scales: the loss decreases more slowly than expected, which causes significant trouble for developing large language models. In this paper, we hypothesize that the root cause lies in the fact that cross-entropy itself does not truly scale; instead, only one of its hidden components does. To investigate this, we introduce a novel decomposition of cross-entropy into three parts: Error-Entropy, Self-Alignment, and Confidence. We show both theoretically and empirically that this decomposition precisely captures the training dynamics and optimization objectives. Through extensive experiments on multiple datasets and 32 models spanning five orders of magnitude in size, we find that only error-entropy follows a robust power-law scaling, while the other two terms remain largely invariant. Moreover, error-entropy constitutes the dominant share of cross-entropy in small models but diminishes in proportion as models grow larger. This explains why the cross-entropy scaling law appears accurate at small scales but fails at very large ones. Our findings establish the error-entropy scaling law as a more accurate description of model behavior. We believe it will have wide applications in the training, understanding, and future development of large language models.</li>
</ul>

<h3>Title: Diffusion Low Rank Hybrid Reconstruction for Sparse View Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Zongyin Deng, Qing Zhou, Yuhao Fang, Zijian Wang, Yao Lu, Ye Zhang, Chun Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04069">https://arxiv.org/abs/2510.04069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04069">https://arxiv.org/pdf/2510.04069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04069]] Diffusion Low Rank Hybrid Reconstruction for Sparse View Medical Imaging(https://arxiv.org/abs/2510.04069)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>This work presents TV-LoRA, a novel method for low-dose sparse-view CT reconstruction that combines a diffusion generative prior (NCSN++ with SDE modeling) and multi-regularization constraints, including anisotropic TV and nuclear norm (LoRA), within an ADMM framework. To address ill-posedness and texture loss under extremely sparse views, TV-LoRA integrates generative and physical constraints, and utilizes a 2D slice-based strategy with FFT acceleration and tensor-parallel optimization for efficient inference. Experiments on AAPM-2016, CTHD, and LIDC datasets with $N_{\mathrm{view}}=8,4,2$ show that TV-LoRA consistently surpasses benchmarks in SSIM, texture recovery, edge clarity, and artifact suppression, demonstrating strong robustness and generalizability. Ablation studies confirm the complementary effects of LoRA regularization and diffusion priors, while the FFT-PCG module provides a speedup. Overall, Diffusion + TV-LoRA achieves high-fidelity, efficient 3D CT reconstruction and broad clinical applicability in low-dose, sparse-sampling scenarios.</li>
</ul>

<h3>Title: What Makes Diffusion Language Models Super Data Learners?</h3>
<ul>
<li><strong>Authors: </strong>Zitian Gao, Haoming Luo, Lynx Chen, Jason Klein Liu, Ran Tao, Joey Zhou, Bryan Dai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04071">https://arxiv.org/abs/2510.04071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04071">https://arxiv.org/pdf/2510.04071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04071]] What Makes Diffusion Language Models Super Data Learners?(https://arxiv.org/abs/2510.04071)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent studies have shown that diffusion language models achieve remarkable data efficiency under limited-data constraints, yet the underlying mechanisms remain unclear. In this work, we perform extensive ablation experiments to disentangle the sources of this efficiency. Our results show that random masking of input tokens plays the dominant role. We further show that similar gains can be obtained through in MLP dropout and weight decay, indicating that stochastic regularization broadly enhances data efficiency in multi-epoch training. Our code is available at this https URL.</li>
</ul>

<h3>Title: Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ziyan Wang, Zheng Wang, Jie Fu, Xingwei Qu, Qi Cheng, Shengpu Tang, Minjia Zhang, Xiaoming Huo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04072">https://arxiv.org/abs/2510.04072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04072">https://arxiv.org/pdf/2510.04072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04072]] Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning(https://arxiv.org/abs/2510.04072)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has become central to enhancing reasoning in large language models (LLMs). Yet on-policy algorithms such as Group Relative Policy Optimization (GRPO) often suffer in early training: noisy gradients from low-quality rollouts lead to unstable updates and inefficient exploration. We introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient framework to address these limitations via decomposing each step into three stages: a short fast trajectory of inner steps on the same batch, a reposition mechanism to control off-policy drift, and a final slow correction. This reposition-before-update design preserves the objective and rollout process unchanged, making SFPO plug-compatible with existing policy-gradient pipelines. Extensive experiments demonstrate that SFPO consistently improves stability, reduces rollouts, and accelerates convergence of reasoning RL training. Specifically, it outperforms GRPO by up to 2.80 points in average on math reasoning benchmarks. It also achieves up to 4.93\texttimes{} fewer rollouts and a 4.19\texttimes{} reduction in wall-clock time to match GRPO's best accuracy.</li>
</ul>

<h3>Title: PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity</h3>
<ul>
<li><strong>Authors: </strong>Zixin Song, Bowen Zhang, Qian-Wen Zhang, Di Yin, Xing Sun, Chunping Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04080">https://arxiv.org/abs/2510.04080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04080">https://arxiv.org/pdf/2510.04080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04080]] PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity(https://arxiv.org/abs/2510.04080)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conditional Semantic Textual Similarity (C-STS) measures the semantic proximity between text segments under a specific condition, thereby overcoming the ambiguity inherent in traditional STS. However, existing methods are largely confined to discriminative models, failing to fully integrate recent breakthroughs in the NLP community concerning Large Language Models (LLMs) and Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this task, as it can directly optimize the non-differentiable Spearman ranking metric and guide the reasoning process required by C-STS. However, we find that naively applying listwise RL fails to produce meaningful improvements, as the model is overwhelmed by complex, coarse-grained reward signals. To address this challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning framework. PoLi-RL employs a two-stage curriculum: it first trains the model with simple pointwise rewards to establish fundamental scoring capabilities, then transitions to a hybrid reward that combines pointwise, pairwise, and listwise objectives to refine the model's ability to discern subtle semantic distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward (PSRR) mechanism that computes ranking rewards in parallel slices, where each slice comprises same-indexed completions from different samples. This provides a precise, differentiated learning signal for each individual completion, enabling granular credit assignment and effective optimization. On the official C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18, establishing a new SOTA for the cross-encoder architecture. As the first work to successfully apply RL to C-STS, our study introduces a powerful and precise paradigm for training LLMs on complex, ranking-based conditional judgment tasks.</li>
</ul>

<h3>Title: Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Honglin Lin, Qizhi Pei, Xin Gao, Zhuoshi Pan, Yu Li, Juntao Li, Conghui He, Lijun Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04081">https://arxiv.org/abs/2510.04081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04081">https://arxiv.org/pdf/2510.04081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04081]] Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning(https://arxiv.org/abs/2510.04081)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning capability is pivotal for Large Language Models (LLMs) to solve complex tasks, yet achieving reliable and scalable reasoning remains challenging. While Chain-of-Thought (CoT) prompting has become a mainstream approach, existing methods often suffer from uncontrolled generation, insufficient quality, and limited diversity in reasoning paths. Recent efforts leverage code to enhance CoT by grounding reasoning in executable steps, but such methods are typically constrained to predefined mathematical problems, hindering scalability and generalizability. In this work, we propose Caco (Code-Assisted Chain-of-ThOught), a novel framework that automates the synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning data through code-driven augmentation. Unlike prior work, Caco first fine-tunes a code-based CoT generator on existing math and programming solutions in a unified code format, then scales the data generation to a large amount of diverse reasoning traces. Crucially, we introduce automated validation via code execution and rule-based filtering to ensure logical correctness and structural diversity, followed by reverse-engineering filtered outputs into natural language instructions and language CoTs to enrich task adaptability. This closed-loop process enables fully automated, scalable synthesis of reasoning data with guaranteed executability. Experiments on our created Caco-1.3M dataset demonstrate that Caco-trained models achieve strong competitive performance on mathematical reasoning benchmarks, outperforming existing strong baselines. Further analysis reveals that Caco's code-anchored verification and instruction diversity contribute to superior generalization across unseen tasks. Our work establishes a paradigm for building self-sustaining, trustworthy reasoning systems without human intervention.</li>
</ul>

<h3>Title: Gluing Random Unitaries with Inverses and Applications to Strong Pseudorandom Unitaries</h3>
<ul>
<li><strong>Authors: </strong>Prabhanjan Ananth, John Bostanci, Aditya Gulati, Yao-Ting Lin</a></li>
<li><strong>Subjects: </strong>cs.CR, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04085">https://arxiv.org/abs/2510.04085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04085">https://arxiv.org/pdf/2510.04085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04085]] Gluing Random Unitaries with Inverses and Applications to Strong Pseudorandom Unitaries(https://arxiv.org/abs/2510.04085)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Gluing theorem for random unitaries [Schuster, Haferkamp, Huang, QIP 2025] have found numerous applications, including designing low depth random unitaries [Schuster, Haferkamp, Huang, QIP 2025], random unitaries in ${\sf QAC0}$ [Foxman, Parham, Vasconcelos, Yuen'25] and generically shortening the key length of pseudorandom unitaries [Ananth, Bostanci, Gulati, Lin EUROCRYPT'25]. We present an alternate method of combining Haar random unitaries from the gluing lemma from [Schuster, Haferkamp, Huang, QIP 2025] that is secure against adversaries with inverse query access to the joined unitary. As a consequence, we show for the first time that strong pseudorandom unitaries can generically have their length extended, and can be constructed using only $O(n^{1/c})$ bits of randomness, for any constant $c$, if any family of strong pseudorandom unitaries exists.</li>
</ul>

<h3>Title: Using predefined vector systems as latent space configuration for neural network supervised training on data with arbitrarily large number of classes</h3>
<ul>
<li><strong>Authors: </strong>Nikita Gabdullin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04090">https://arxiv.org/abs/2510.04090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04090">https://arxiv.org/pdf/2510.04090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04090]] Using predefined vector systems as latent space configuration for neural network supervised training on data with arbitrarily large number of classes(https://arxiv.org/abs/2510.04090)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Supervised learning (SL) methods are indispensable for neural network (NN) training used to perform classification tasks. While resulting in very high accuracy, SL training often requires making NN parameter number dependent on the number of classes, limiting their applicability when the number of classes is extremely large or unknown in advance. In this paper we propose a methodology that allows one to train the same NN architecture regardless of the number of classes. This is achieved by using predefined vector systems as the target latent space configuration (LSC) during NN training. We discuss the desired properties of target configurations and choose randomly perturbed vectors of An root system for our experiments. These vectors are used to successfully train encoders and visual transformers (ViT) on Cinic-10 and ImageNet-1K in low- and high-dimensional cases by matching NN predictions with the predefined vectors. Finally, ViT is trained on a dataset with 1.28 million classes illustrating the applicability of the method to training on datasets with extremely large number of classes. In addition, potential applications of LSC in lifelong learning and NN distillation are discussed illustrating versatility of the proposed methodology.</li>
</ul>

<h3>Title: TOPO-Bench: An Open-Source Topological Mapping Evaluation Framework with Quantifiable Perceptual Aliasing</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Wang, Diwen Liu, Jizhuo Chen, Harold Soh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04100">https://arxiv.org/abs/2510.04100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04100">https://arxiv.org/pdf/2510.04100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04100]] TOPO-Bench: An Open-Source Topological Mapping Evaluation Framework with Quantifiable Perceptual Aliasing(https://arxiv.org/abs/2510.04100)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>Topological mapping offers a compact and robust representation for navigation, but progress in the field is hindered by the lack of standardized evaluation metrics, datasets, and protocols. Existing systems are assessed using different environments and criteria, preventing fair and reproducible comparisons. Moreover, a key challenge - perceptual aliasing - remains under-quantified, despite its strong influence on system performance. We address these gaps by (1) formalizing topological consistency as the fundamental property of topological maps and showing that localization accuracy provides an efficient and interpretable surrogate metric, and (2) proposing the first quantitative measure of dataset ambiguity to enable fair comparisons across environments. To support this protocol, we curate a diverse benchmark dataset with calibrated ambiguity levels, implement and release deep-learned baseline systems, and evaluate them alongside classical methods. Our experiments and analysis yield new insights into the limitations of current approaches under perceptual aliasing. All datasets, baselines, and evaluation tools are fully open-sourced to foster consistent and reproducible research in topological mapping.</li>
</ul>

<h3>Title: Can Linear Probes Measure LLM Uncertainty?</h3>
<ul>
<li><strong>Authors: </strong>Ramzi Dakhmouche, Adrien Letellier, Hossein Gorji</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA, math.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04108">https://arxiv.org/abs/2510.04108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04108">https://arxiv.org/pdf/2510.04108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04108]] Can Linear Probes Measure LLM Uncertainty?(https://arxiv.org/abs/2510.04108)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effective Uncertainty Quantification (UQ) represents a key aspect for reliable deployment of Large Language Models (LLMs) in automated decision-making and beyond. Yet, for LLM generation with multiple choice structure, the state-of-the-art in UQ is still dominated by the naive baseline given by the maximum softmax score. To address this shortcoming, we demonstrate that taking a principled approach via Bayesian statistics leads to improved performance despite leveraging the simplest possible model, namely linear regression. More precisely, we propose to train multiple Bayesian linear models, each predicting the output of a layer given the output of the previous one. Based on the obtained layer-level posterior distributions, we infer the global uncertainty level of the LLM by identifying a sparse combination of distributional features, leading to an efficient UQ scheme. Numerical experiments on various LLMs show consistent improvement over state-of-the-art baselines.</li>
</ul>

<h3>Title: Learning Efficient Meshflow and Optical Flow from Event Cameras</h3>
<ul>
<li><strong>Authors: </strong>Xinglong Luo, Ao Luo, Kunming Luo, Zhengning Wang, Ping Tan, Bing Zeng, Shuaicheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04111">https://arxiv.org/abs/2510.04111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04111">https://arxiv.org/pdf/2510.04111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04111]] Learning Efficient Meshflow and Optical Flow from Event Cameras(https://arxiv.org/abs/2510.04111)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we explore the problem of event-based meshflow estimation, a novel task that involves predicting a spatially smooth sparse motion field from event cameras. To start, we review the state-of-the-art in event-based flow estimation, highlighting two key areas for further research: i) the lack of meshflow-specific event datasets and methods, and ii) the underexplored challenge of event data density. First, we generate a large-scale High-Resolution Event Meshflow (HREM) dataset, which showcases its superiority by encompassing the merits of high resolution at 1280x720, handling dynamic objects and complex motion patterns, and offering both optical flow and meshflow labels. These aspects have not been fully explored in previous works. Besides, we propose Efficient Event-based MeshFlow (EEMFlow) network, a lightweight model featuring a specially crafted encoder-decoder architecture to facilitate swift and accurate meshflow estimation. Furthermore, we upgrade EEMFlow network to support dense event optical flow, in which a Confidence-induced Detail Completion (CDC) module is proposed to preserve sharp motion boundaries. We conduct comprehensive experiments to show the exceptional performance and runtime efficiency (30x faster) of our EEMFlow model compared to the recent state-of-the-art flow method. As an extension, we expand HREM into HREM+, a multi-density event dataset contributing to a thorough study of the robustness of existing methods across data with varying densities, and propose an Adaptive Density Module (ADM) to adjust the density of input event data to a more optimal range, enhancing the model's generalization ability. We empirically demonstrate that ADM helps to significantly improve the performance of EEMFlow and EEMFlow+ by 8% and 10%, respectively. Code and dataset are released at this https URL.</li>
</ul>

<h3>Title: Wasserstein projection distance for fairness testing of regression models</h3>
<ul>
<li><strong>Authors: </strong>Wanxin Li, Yongjin P. Park, Khanh Dao Duc</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04114">https://arxiv.org/abs/2510.04114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04114">https://arxiv.org/pdf/2510.04114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04114]] Wasserstein projection distance for fairness testing of regression models(https://arxiv.org/abs/2510.04114)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness in machine learning is a critical concern, yet most research has focused on classification tasks, leaving regression models underexplored. This paper introduces a Wasserstein projection-based framework for fairness testing in regression models, focusing on expectation-based criteria. We propose a hypothesis-testing approach and an optimal data perturbation method to improve fairness while balancing accuracy. Theoretical results include a detailed categorization of fairness criteria for regression, a dual reformulation of the Wasserstein projection test statistic, and the derivation of asymptotic bounds and limiting distributions. Experiments on synthetic and real-world datasets demonstrate that the proposed method offers higher specificity compared to permutation-based tests, and effectively detects and mitigates biases in real applications such as student performance and housing price prediction.</li>
</ul>

<h3>Title: Cyber Warfare During Operation Sindoor: Malware Campaign Analysis and Detection Framework</h3>
<ul>
<li><strong>Authors: </strong>Prakhar Paliwal, Atul Kabra, Manjesh Kumar Hanawal</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04118">https://arxiv.org/abs/2510.04118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04118">https://arxiv.org/pdf/2510.04118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04118]] Cyber Warfare During Operation Sindoor: Malware Campaign Analysis and Detection Framework(https://arxiv.org/abs/2510.04118)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Rapid digitization of critical infrastructure has made cyberwarfare one of the important dimensions of modern conflicts. Attacking the critical infrastructure is an attractive pre-emptive proposition for adversaries as it can be done remotely without crossing borders. Such attacks disturb the support systems of the opponents to launch any offensive activities, crippling their fighting capabilities. Cyberattacks during cyberwarfare can not only be used to steal information, but also to spread disinformation to bring down the morale of the opponents. Recent wars in Europe, Africa, and Asia have demonstrated the scale and sophistication that the warring nations have deployed to take the early upper hand. In this work, we focus on the military action launched by India, code-named Operation Sindoor, to dismantle terror infrastructure emanating from Pakistan and the cyberattacks launched by Pakistan. In particular, we study the malware used by Pakistan APT groups to deploy Remote Access Trojans in Indian systems. We provide details of the tactics and techniques used in the RAT deployment and develop a telemetry framework to collect necessary event logs using Osquery with a custom extension. Finally, we develop a detection rule that can be readily deployed to detect the presence of the RAT or any exploitation performed by the malware.</li>
</ul>

<h3>Title: Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence</h3>
<ul>
<li><strong>Authors: </strong>Fengying Ye, Shanshan Wang, Lidia S. Chao, Derek F. Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04120">https://arxiv.org/abs/2510.04120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04120">https://arxiv.org/pdf/2510.04120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04120]] Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence(https://arxiv.org/abs/2510.04120)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Metaphor analysis is a complex linguistic phenomenon shaped by context and external factors. While Large Language Models (LLMs) demonstrate advanced capabilities in knowledge integration, contextual reasoning, and creative generation, their mechanisms for metaphor comprehension remain insufficiently explored. This study examines LLMs' metaphor-processing abilities from three perspectives: (1) Concept Mapping: using embedding space projections to evaluate how LLMs map concepts in target domains (e.g., misinterpreting "fall in love" as "drop down from love"); (2) Metaphor-Literal Repository: analyzing metaphorical words and their literal counterparts to identify inherent metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how metaphorical syntactic structures influence LLMs' performance. Our findings reveal that LLMs generate 15\%-25\% conceptually irrelevant interpretations, depend on metaphorical indicators in training data rather than contextual cues, and are more sensitive to syntactic irregularities than to structural comprehension. These insights underline the limitations of LLMs in metaphor analysis and call for more robust computational approaches.</li>
</ul>

<h3>Title: Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Seunghyun Lee, Tae-Kyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04125">https://arxiv.org/abs/2510.04125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04125">https://arxiv.org/pdf/2510.04125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04125]] Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation(https://arxiv.org/abs/2510.04125)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Latest diffusion models have shown promising results in category-level 6D object pose estimation by modeling the conditional pose distribution with depth image input. The existing methods, however, suffer from slow convergence during training, learning its encoder with the diffusion denoising network in end-to-end fashion, and require an additional network that evaluates sampled pose hypotheses to filter out low-quality pose candidates. In this paper, we propose a novel pipeline that tackles these limitations by two key components. First, the proposed method pretrains the encoder with the direct pose regression head, and jointly learns the networks via the regression head and the denoising diffusion head, significantly accelerating training convergence while achieving higher accuracy. Second, sampling guidance via time-dependent score scaling is proposed s.t. the exploration-exploitation trade-off is effectively taken, eliminating the need for the additional evaluation network. The sampling guidance maintains multi-modal characteristics of symmetric objects at early denoising steps while ensuring high-quality pose generation at final steps. Extensive experiments on multiple benchmarks including REAL275, HouseCat6D, and ROPE, demonstrate that the proposed method, simple yet effective, achieves state-of-the-art accuracies even with single-pose inference, while being more efficient in both training and inference.</li>
</ul>

<h3>Title: On the Limitations and Capabilities of Position Embeddings for Length Generalization</h3>
<ul>
<li><strong>Authors: </strong>Yang Chen, Yitao Liang, Zhouchen Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04130">https://arxiv.org/abs/2510.04130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04130">https://arxiv.org/pdf/2510.04130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04130]] On the Limitations and Capabilities of Position Embeddings for Length Generalization(https://arxiv.org/abs/2510.04130)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In Transformers, Position Embeddings (PEs) significantly influence Length Generalization (LG) performance, yet their fundamental role remains unclear. In this work, we investigate the limitations and capabilities of PEs in achieving LG. We theoretically analyze PEs in Position-Only Linear Attentions (POLAs), introducing Linear Representation Complexity (LRC) to characterize when PEs enable LG. Our analysis shows that PEs do not expand computational capabilities but structure learned computations across positions. Extending to practical Transformers, we propose Sequential Representation Complexity (SRC) and conjecture that LG is possible if and only if SRC remains invariant across scales. We support this hypothesis with empirical evidence in various reasoning tasks. To enhance LG, we introduce Scale Hint, allowing flexible instance scaling, and a Learning-Based Position Embedding framework that automatically learns positional relations. Our work provides theoretical insights and practical strategies for improving LG in Transformers.</li>
</ul>

<h3>Title: Modeling Time Series Dynamics with Fourier Ordinary Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Muhao Guo, Yang Weng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04133">https://arxiv.org/abs/2510.04133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04133">https://arxiv.org/pdf/2510.04133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04133]] Modeling Time Series Dynamics with Fourier Ordinary Differential Equations(https://arxiv.org/abs/2510.04133)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural ODEs (NODEs) have emerged as powerful tools for modeling time series data, offering the flexibility to adapt to varying input scales and capture complex dynamics. However, they face significant challenges: first, their reliance on time-domain representations often limits their ability to capture long-term dependencies and periodic structures; second, the inherent mismatch between their continuous-time formulation and the discrete nature of real-world data can lead to loss of granularity and predictive accuracy. To address these limitations, we propose Fourier Ordinary Differential Equations (FODEs), an approach that embeds the dynamics in the Fourier domain. By transforming time-series data into the frequency domain using the Fast Fourier Transform (FFT), FODEs uncover global patterns and periodic behaviors that remain elusive in the time domain. Additionally, we introduce a learnable element-wise filtering mechanism that aligns continuous model outputs with discrete observations, preserving granularity and enhancing accuracy. Experiments on various time series datasets demonstrate that FODEs outperform existing methods in terms of both accuracy and efficiency. By effectively capturing both long- and short-term patterns, FODEs provide a robust framework for modeling time series dynamics.</li>
</ul>

<h3>Title: Fine Tuning Methods for Low-resource Languages</h3>
<ul>
<li><strong>Authors: </strong>Tim Bakkenes, Daniel Wang, Anton Johansson</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04139">https://arxiv.org/abs/2510.04139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04139">https://arxiv.org/pdf/2510.04139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04139]] Fine Tuning Methods for Low-resource Languages(https://arxiv.org/abs/2510.04139)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models has not been inclusive of all cultures. The models are mostly trained on English texts and culture which makes them underperform in other languages and cultural contexts. By developing a generalizable method for preparing culturally relevant datasets and post-training the Gemma 2 model, this project aimed to increase the performance of Gemma 2 for an underrepresented language and showcase how others can do the same to unlock the power of Generative AI in their country and preserve their cultural heritage.</li>
</ul>

<h3>Title: Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Yang, Jie Lu, En Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04142">https://arxiv.org/abs/2510.04142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04142">https://arxiv.org/pdf/2510.04142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04142]] Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs(https://arxiv.org/abs/2510.04142)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper identifies a critical yet underexplored challenge in distilling from multimodal large language models (MLLMs): the reasoning trajectories generated by multiple drifting teachers exhibit concept drift, whereby their reasoning distributions evolve unpredictably and transmit biases to the student model, ultimately compromising its performance. To tackle this issue, we pioneer a theoretical connection between concept drift and knowledge distillation, casting the non-stationary reasoning dynamics from multiple MLLM teachers as next-token prediction of multi-stream reasoning this http URL by concept drift, we introduce the "learn, compare, critique" paradigm, culminating in autonomous preference optimization (APO). Under the active guidance of the teachers, the student model first learns and self-distils preferred thinking by comparing multiple teachers. It then engages in critical reflection over the drifting inference from teachers, performing concept alignment through APO, ultimately yielding a robust, consistent, and generalizable this http URL experiments demonstrate our superior performance of consistency, robustness and generalization within knowledge distillation. Besides, we also contributed a large-scale dataset, CXR-MAX (Multi-teachers Alignment X-rays), comprising 170,982 distilled reasoning trajectories derived from publicly accessible MLLMs based on MIMIC-CXR. Our code and data are public at: this https URL.</li>
</ul>

<h3>Title: Automating construction safety inspections using a multi-modal vision-language RAG framework</h3>
<ul>
<li><strong>Authors: </strong>Chenxin Wang, Elyas Asadi Shamsabadi, Zhaohui Chen, Luming Shen, Alireza Ahmadian Fard Fini, Daniel Dias-da-Costa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04145">https://arxiv.org/abs/2510.04145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04145">https://arxiv.org/pdf/2510.04145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04145]] Automating construction safety inspections using a multi-modal vision-language RAG framework(https://arxiv.org/abs/2510.04145)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conventional construction safety inspection methods are often inefficient as they require navigating through large volume of information. Recent advances in large vision-language models (LVLMs) provide opportunities to automate safety inspections through enhanced visual and linguistic understanding. However, existing applications face limitations including irrelevant or unspecific responses, restricted modal inputs and hallucinations. Utilisation of Large Language Models (LLMs) for this purpose is constrained by availability of training data and frequently lack real-time adaptability. This study introduces SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG) framework for automating construction safety inspection reports by integrating visual and audio inputs. Using real-world data, SiteShield outperformed unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04, precision of 0.76, and recall of 0.96. The findings indicate that SiteShield offers a novel pathway to enhance information retrieval and efficiency in generating safety reports.</li>
</ul>

<h3>Title: Beyond Next-Token Prediction: A Performance Characterization of Diffusion versus Autoregressive Language Models</h3>
<ul>
<li><strong>Authors: </strong>Minseo Kim, Coleman Hooper, Aditya Tomar, Chenfeng Xu, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04146">https://arxiv.org/abs/2510.04146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04146">https://arxiv.org/pdf/2510.04146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04146]] Beyond Next-Token Prediction: A Performance Characterization of Diffusion versus Autoregressive Language Models(https://arxiv.org/abs/2510.04146)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved state-of-the-art performance on a broad range of Natural Language Processing (NLP) tasks, including document processing and coding. Autoregressive Language Models (ARMs), which generate tokens sequentially conditioned on all previous tokens, have been the predominant paradigm for LLMs. However, while these networks have achieved high accuracy across a range of downstream tasks, they exhibit low arithmetic intensity due to the inherent sequential dependency with next-token prediction. Recently, Diffusion Language Models (DLMs) have emerged as a promising alternative architecture. DLMs generate output text in parallel, breaking the limitations of sequential dependency. However, the performance implications of DLMs relative to commonly deployed ARMs are not fully understood. In this work, we present a comprehensive performance study analyzing the performance characteristics of ARMs and DLMs, using both theoretical analysis and profiling data to characterize the trade-offs between these approaches. We illustrate that although DLMs exhibit higher arithmetic intensity compared to ARMs because of their capability to utilize parallelism across sequence lengths, they fail to scale effectively to longer contexts. We then explore DLMs with block-wise decoding, outlining how this approach allows for increased arithmetic intensity, while still scaling well to long contexts (similar to ARMs). We also show interesting trade-offs for batched inference, where we find that ARMs exhibit superior throughput, as they benefit more from parallelism across sequences in the batch. Finally, we highlight opportunities for accelerating DLM inference, and, in particular, highlight the importance of reducing the number of sampling steps for allowing open-source DLMs to provide improved latency relative to ARMs.</li>
</ul>

<h3>Title: Self Speculative Decoding for Diffusion Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yifeng Gao, Ziang Ji, Yuxuan Wang, Biqing Qi, Hanlin Xu, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04147">https://arxiv.org/abs/2510.04147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04147">https://arxiv.org/pdf/2510.04147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04147]] Self Speculative Decoding for Diffusion Large Language Models(https://arxiv.org/abs/2510.04147)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion-based Large Language Models (dLLMs) have emerged as a competitive alternative to autoregressive models, offering unique advantages through bidirectional attention and parallel generation paradigms. However, the generation results of current parallel decoding methods deviate from stepwise decoding, introducing potential performance degradation, which limits their practical deployment. To address this problem, we propose \textbf{S}elf \textbf{S}peculative \textbf{D}ecoding (SSD), a lossless inference acceleration method that leverages the dLLM itself as both speculative decoding drafter and verifier without auxiliary modules. SSD introduces a self-drafting mechanism where the model generates predictions for multiple positions, then verifies them through hierarchical verification trees in a single forward pass. Unlike traditional speculative decoding that requires separate draft models, SSD eliminates model redundancy and memory overhead by exploiting the dLLM's inherent parallel prediction capability for multiple positions. This self-speculative approach allows the model to progressively verify and accept multiple tokens in a single forward pass. Our experiments demonstrate that SSD achieves up to 3.46$\times$ speedup while keeping the output identical to stepwise decoding on open source models such as LLaDA and Dream. Code will be made publicly available on GitHub.</li>
</ul>

<h3>Title: ObCLIP: Oblivious CLoud-Device Hybrid Image Generation with Privacy Preservation</h3>
<ul>
<li><strong>Authors: </strong>Haoqi Wu, Wei Dai, Ming Xu, Li Wang, Qiang Yan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04153">https://arxiv.org/abs/2510.04153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04153">https://arxiv.org/pdf/2510.04153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04153]] ObCLIP: Oblivious CLoud-Device Hybrid Image Generation with Privacy Preservation(https://arxiv.org/abs/2510.04153)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion Models have gained significant popularity due to their remarkable capabilities in image generation, albeit at the cost of intensive computation requirement. Meanwhile, despite their widespread deployment in inference services such as Midjourney, concerns about the potential leakage of sensitive information in uploaded user prompts have arisen. Existing solutions either lack rigorous privacy guarantees or fail to strike an effective balance between utility and efficiency. To bridge this gap, we propose ObCLIP, a plug-and-play safeguard that enables oblivious cloud-device hybrid generation. By oblivious, each input prompt is transformed into a set of semantically similar candidate prompts that differ only in sensitive attributes (e.g., gender, ethnicity). The cloud server processes all candidate prompts without knowing which one is the real one, thus preventing any prompt leakage. To mitigate server cost, only a small portion of denoising steps is performed upon the large cloud model. The intermediate latents are then sent back to the client, which selects the targeted latent and completes the remaining denoising using a small device model. Additionally, we analyze and incorporate several cache-based accelerations that leverage temporal and batch redundancy, effectively reducing computation cost with minimal utility degradation. Extensive experiments across multiple datasets demonstrate that ObCLIP provides rigorous privacy and comparable utility to cloud models with slightly increased server cost.</li>
</ul>

<h3>Title: BLADE: Bias-Linked Adaptive DEbiasing</h3>
<ul>
<li><strong>Authors: </strong>Piyush Arora, Navlika Singh, Vasubhya Diwan, Pratik Mazumder</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04174">https://arxiv.org/abs/2510.04174</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04174">https://arxiv.org/pdf/2510.04174</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04174]] BLADE: Bias-Linked Adaptive DEbiasing(https://arxiv.org/abs/2510.04174)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Neural networks have revolutionized numerous fields, yet they remain vulnerable to a critical flaw: the tendency to learn implicit biases, spurious correlations between certain attributes and target labels in training data. These biases are often more prevalent and easier to learn, causing models to rely on superficial patterns rather than task-relevant features necessary for generalization. Existing methods typically rely on strong assumptions, such as prior knowledge of these biases or access to bias-conflicting samples, i.e., samples that contradict spurious correlations and counterbalance bias-aligned samples, samples that conform to these spurious correlations. However, such assumptions are often impractical in real-world settings. We propose BLADE ({B}ias-{L}inked {A}daptive {DE}biasing), a generative debiasing framework that requires no prior knowledge of bias or bias-conflicting samples. BLADE first trains a generative model to translate images across bias domains while preserving task-relevant features. Then, it adaptively refines each image with its synthetic counterpart based on the image's susceptibility to bias. To encourage robust representations, BLADE aligns an image with its bias-translated synthetic counterpart that shares task-relevant features but differs in bias, while misaligning it with samples sharing the same bias. We evaluate BLADE on multiple benchmark datasets and show that it significantly outperforms state-of-the-art methods. Notably, it exceeds the closest baseline by an absolute margin of around 18% on the corrupted CIFAR-10 dataset under the worst group setting, establishing a new benchmark in bias mitigation and demonstrating its potential for developing more robust deep learning models without explicit supervision.</li>
</ul>

<h3>Title: From Segments to Concepts: Interpretable Image Classification via Concept-Guided Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ran Eisenberg, Amit Rozner, Ethan Fetaya, Ofir Lindenbaum</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04180">https://arxiv.org/abs/2510.04180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04180">https://arxiv.org/pdf/2510.04180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04180]] From Segments to Concepts: Interpretable Image Classification via Concept-Guided Segmentation(https://arxiv.org/abs/2510.04180)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Deep neural networks have achieved remarkable success in computer vision; however, their black-box nature in decision-making limits interpretability and trust, particularly in safety-critical applications. Interpretability is crucial in domains where errors have severe consequences. Existing models not only lack transparency but also risk exploiting unreliable or misleading features, which undermines both robustness and the validity of their explanations. Concept Bottleneck Models (CBMs) aim to improve transparency by reasoning through human-interpretable concepts. Still, they require costly concept annotations and lack spatial grounding, often failing to identify which regions support each concept. We propose SEG-MIL-CBM, a novel framework that integrates concept-guided image segmentation into an attention-based multiple instance learning (MIL) framework, where each segmented region is treated as an instance and the model learns to aggregate evidence across them. By reasoning over semantically meaningful regions aligned with high-level concepts, our model highlights task-relevant evidence, down-weights irrelevant cues, and produces spatially grounded, concept-level explanations without requiring annotations of concepts or groups. SEG-MIL-CBM achieves robust performance across settings involving spurious correlations (unintended dependencies between background and label), input corruptions (perturbations that degrade visual quality), and large-scale benchmarks, while providing transparent, concept-level explanations.</li>
</ul>

<h3>Title: Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Wengao Ye, Yan Liang, Lianlei Shan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04182">https://arxiv.org/abs/2510.04182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04182">https://arxiv.org/pdf/2510.04182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04182]] Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization(https://arxiv.org/abs/2510.04182)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have shifted from explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning, where intermediate thoughts are represented as vectors rather than text. However, latent reasoning can be brittle on challenging, out-of-distribution tasks where robust reasoning is most critical. To overcome these limitations, we introduce Latent Thought Policy Optimization (LTPO), a parameter-free framework that enhances LLM reasoning entirely at test time, without requiring model parameter updates. LTPO treats intermediate latent "thought" vectors as dynamic parameters that are actively optimized for each problem instance. It employs an online policy gradient method guided by an intrinsic, confidence-based reward signal computed directly from the frozen LLM's own output distributions, eliminating the need for external supervision or expensive text generation during optimization. Extensive experiments on five reasoning benchmarks show that LTPO not only matches or surpasses strong baselines on standard tasks but also demonstrates remarkable robustness where others fail. Most notably, on highly challenging AIME benchmarks where existing latent reasoning baselines collapse to near-zero accuracy, LTPO delivers substantial improvements, showcasing a unique capability for complex reasoning.</li>
</ul>

<h3>Title: Let Features Decide Their Own Solvers: Hybrid Feature Caching for Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Shikang Zheng, Guantao Chen, Qinming Zhou, Yuqi Lin, Lixuan He, Chang Zou, Peiliang Cai, Jiacheng Liu, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04188">https://arxiv.org/abs/2510.04188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04188">https://arxiv.org/pdf/2510.04188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04188]] Let Features Decide Their Own Solvers: Hybrid Feature Caching for Diffusion Transformers(https://arxiv.org/abs/2510.04188)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers offer state-of-the-art fidelity in image and video synthesis, but their iterative sampling process remains a major bottleneck due to the high cost of transformer forward passes at each timestep. To mitigate this, feature caching has emerged as a training-free acceleration technique that reuses or forecasts hidden representations. However, existing methods often apply a uniform caching strategy across all feature dimensions, ignoring their heterogeneous dynamic behaviors. Therefore, we adopt a new perspective by modeling hidden feature evolution as a mixture of ODEs across dimensions, and introduce HyCa, a Hybrid ODE solver inspired caching framework that applies dimension-wise caching strategies. HyCa achieves near-lossless acceleration across diverse domains and models, including 5.55 times speedup on FLUX, 5.56 times speedup on HunyuanVideo, 6.24 times speedup on Qwen-Image and Qwen-Image-Edit without retraining.</li>
</ul>

<h3>Title: World-To-Image: Grounding Text-to-Image Generation with Agent-Driven World Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Moo Hyun Son, Jintaek Oh, Sun Bin Mun, Jaechul Roh, Sehyun Choi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04201">https://arxiv.org/abs/2510.04201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04201">https://arxiv.org/pdf/2510.04201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04201]] World-To-Image: Grounding Text-to-Image Generation with Agent-Driven World Knowledge(https://arxiv.org/abs/2510.04201)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>While text-to-image (T2I) models can synthesize high-quality images, their performance degrades significantly when prompted with novel or out-of-distribution (OOD) entities due to inherent knowledge cutoffs. We introduce World-To-Image, a novel framework that bridges this gap by empowering T2I generation with agent-driven world knowledge. We design an agent that dynamically searches the web to retrieve images for concepts unknown to the base model. This information is then used to perform multimodal prompt optimization, steering powerful generative backbones toward an accurate synthesis. Critically, our evaluation goes beyond traditional metrics, utilizing modern assessments like LLMGrader and ImageReward to measure true semantic fidelity. Our experiments show that World-To-Image substantially outperforms state-of-the-art methods in both semantic alignment and visual aesthetics, achieving +8.1% improvement in accuracy-to-prompt on our curated NICE benchmark. Our framework achieves these results with high efficiency in less than three iterations, paving the way for T2I systems that can better reflect the ever-changing real world. Our demo code is available here\footnote{this https URL}.</li>
</ul>

<h3>Title: Adaptive Federated Learning via Dynamical System Model</h3>
<ul>
<li><strong>Authors: </strong>Aayushya Agarwal, Larry Pileggi, Gauri Joshi</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04203">https://arxiv.org/abs/2510.04203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04203">https://arxiv.org/pdf/2510.04203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04203]] Adaptive Federated Learning via Dynamical System Model(https://arxiv.org/abs/2510.04203)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Hyperparameter selection is critical for stable and efficient convergence of heterogeneous federated learning, where clients differ in computational capabilities, and data distributions are non-IID. Tuning hyperparameters is a manual and computationally expensive process as the hyperparameter space grows combinatorially with the number of clients. To address this, we introduce an end-to-end adaptive federated learning method in which both clients and central agents adaptively select their local learning rates and momentum parameters. Our approach models federated learning as a dynamical system, allowing us to draw on principles from numerical simulation and physical design. Through this perspective, selecting momentum parameters equates to critically damping the system for fast, stable convergence, while learning rates for clients and central servers are adaptively selected to satisfy accuracy properties from numerical simulation. The result is an adaptive, momentum-based federated learning algorithm in which the learning rates for clients and servers are dynamically adjusted and controlled by a single, global hyperparameter. By designing a fully integrated solution for both adaptive client updates and central agent aggregation, our method is capable of handling key challenges of heterogeneous federated learning, including objective inconsistency and client drift. Importantly, our approach achieves fast convergence while being insensitive to the choice of the global hyperparameter, making it well-suited for rapid prototyping and scalable deployment. Compared to state-of-the-art adaptive methods, our framework is shown to deliver superior convergence for heterogeneous federated learning while eliminating the need for hyperparameter tuning both client and server updates.</li>
</ul>

<h3>Title: PolyKAN: A Polyhedral Analysis Framework for Provable and Minimal KAN Compression</h3>
<ul>
<li><strong>Authors: </strong>Di Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04205">https://arxiv.org/abs/2510.04205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04205">https://arxiv.org/pdf/2510.04205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04205]] PolyKAN: A Polyhedral Analysis Framework for Provable and Minimal KAN Compression(https://arxiv.org/abs/2510.04205)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs), offering enhanced interpretability and a strong mathematical foundation. However, their parameter efficiency remains a significant challenge for practical deployment. This paper introduces PolyKAN, a novel theoretical framework for KAN compression that provides formal guarantees on both model size reduction and approximation error. By leveraging the inherent piecewise polynomial structure of KANs, we formulate the compression problem as one of optimal polyhedral region merging. We establish a rigorous polyhedral characterization of KANs, develop a complete theory of $\epsilon$-equivalent compression, and design an optimal dynamic programming algorithm that guarantees minimal compression under specified error bounds. Our theoretical analysis demonstrates that PolyKAN achieves provably minimal compression while maintaining strict error control, with polynomial-time complexity in all network parameters. The framework provides the first formal foundation for KAN compression with mathematical guarantees, opening new directions for efficient deployment of interpretable neural architectures.</li>
</ul>

<h3>Title: Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention</h3>
<ul>
<li><strong>Authors: </strong>Haiquan Qiu, Quanming Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04212">https://arxiv.org/abs/2510.04212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04212">https://arxiv.org/pdf/2510.04212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04212]] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention(https://arxiv.org/abs/2510.04212)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The pursuit of computational efficiency has driven the adoption of low-precision formats for training transformer models. However, this progress is often hindered by notorious training instabilities. This paper provides the first mechanistic explanation for a long-standing and unresolved failure case where training with flash attention in low-precision settings leads to catastrophic loss explosions. Our in-depth analysis reveals that the failure is not a random artifact but caused by two intertwined phenomena: the emergence of similar low-rank representations within the attention mechanism and the compounding effect of biased rounding errors inherent in low-precision arithmetic. We demonstrate how these factors create a vicious cycle of error accumulation that corrupts weight updates, ultimately derailing the training dynamics. To validate our findings, we introduce a minimal modification to the flash attention that mitigates the bias in rounding errors. This simple change stabilizes the training process, confirming our analysis and offering a practical solution to this persistent problem.</li>
</ul>

<h3>Title: Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards</h3>
<ul>
<li><strong>Authors: </strong>Zhuoran Zhuang, Ye Chen, Xia Zeng, Chao Luo, Luhui Liu, Yihan Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04214">https://arxiv.org/abs/2510.04214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04214">https://arxiv.org/pdf/2510.04214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04214]] Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards(https://arxiv.org/abs/2510.04214)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We study deploying large language models (LLMs) as business development (BD) agents for persuasive price negotiation in online travel agencies (OTAs), where aligning traveler affordability and hotel profitability directly affects bookings, partner relationships, and access to travel. The agent must follow a Standard Operating Procedure (SOP) while conducting multi-turn persuasion, interpreting colloquial inputs, and adhering to guardrails (no over-promising, no hallucinations). Conventional post-training -- supervised fine-tuning (SFT) or single-source reward optimization -- overfits scripts, misses nuanced persuasive style, and fails to enforce verifiable business constraints. We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement learning post-training framework that aligns an LLM with heterogeneous rewards: a preference-trained reward model (RM) for dense human alignment, a reward judge (RJ) for high-level persuasive behavior and SOP compliance, and programmatic reward functions (RF) for deterministic checks on numerics, formatting, and guardrails. A straightforward enhancement mechanism is proposed to combine the RM with RJ and RF signals to curb reward hacking and improve negotiation quality. In production-style evaluations -- approximately 150 turns from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO), increases the share of conversations with at least one excellent response to 66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also observe emergent capabilities -- proactive empathy, localized reasoning, calibrated tactics -- that surpass gold annotations.</li>
</ul>

<h3>Title: MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering</h3>
<ul>
<li><strong>Authors: </strong>Chenlu Ding, Jiancan Wu, Leheng Sheng, Fan Zhang, Yancheng Yuan, Xiang Wang, Xiangnan He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04217">https://arxiv.org/abs/2510.04217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04217">https://arxiv.org/pdf/2510.04217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04217]] MLLMEraser: Achieving Test-Time Unlearning in Multimodal Large Language Models through Activation Steering(https://arxiv.org/abs/2510.04217)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have demonstrated remarkable capabilities across vision-language tasks, yet their large-scale deployment raises pressing concerns about memorized private data, outdated knowledge, and harmful content. Existing unlearning approaches for MLLMs typically adapt training-based strategies such as gradient ascent or preference optimization, but these methods are computationally expensive, irreversible, and often distort retained knowledge. In this work, we propose MLLMEraser, an input-aware, training-free framework for test-time unlearning. Our approach leverages activation steering to enable dynamic knowledge erasure without parameter updates. Specifically, we construct a multimodal erasure direction by contrasting adversarially perturbed, knowledge-recall image-text pairs with knowledge-erasure counterparts, capturing both textual and visual discrepancies. To prevent unnecessary interference, we further design an input-aware steering mechanism that adaptively determines when and how the erasure direction should be applied, preserving utility on retained knowledge while enforcing forgetting on designated content. Experiments on LLaVA-1.5 and Qwen-2.5-VL demonstrate that MLLMEraser consistently outperforms state-of-the-art MLLM unlearning baselines, achieving stronger forgetting performance with lower computational cost and minimal utility degradation.</li>
</ul>

<h3>Title: MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned Semantic Clustering</h3>
<ul>
<li><strong>Authors: </strong>Lixuan He, Shikang Zheng, Linfeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04220">https://arxiv.org/abs/2510.04220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04220">https://arxiv.org/pdf/2510.04220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04220]] MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned Semantic Clustering(https://arxiv.org/abs/2510.04220)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Autoregressive (AR) models have shown great promise in image generation, yet they face a fundamental inefficiency stemming from their core component: a vast, unstructured vocabulary of visual tokens. This conventional approach treats tokens as a flat vocabulary, disregarding the intrinsic structure of the token embedding space where proximity often correlates with semantic similarity. This oversight results in a highly complex prediction task, which hinders training efficiency and limits final generation quality. To resolve this, we propose Manifold-Aligned Semantic Clustering (MASC), a principled framework that constructs a hierarchical semantic tree directly from the codebook's intrinsic structure. MASC employs a novel geometry-aware distance metric and a density-driven agglomerative construction to model the underlying manifold of the token embeddings. By transforming the flat, high-dimensional prediction task into a structured, hierarchical one, MASC introduces a beneficial inductive bias that significantly simplifies the learning problem for the AR model. MASC is designed as a plug-and-play module, and our extensive experiments validate its effectiveness: it accelerates training by up to 57% and significantly improves generation quality, reducing the FID of LlamaGen-XL from 2.87 to 2.58. MASC elevates existing AR frameworks to be highly competitive with state-of-the-art methods, establishing that structuring the prediction space is as crucial as architectural innovation for scalable generative modeling.</li>
</ul>

<h3>Title: Zoom-In to Sort AI-Generated Images Out</h3>
<ul>
<li><strong>Authors: </strong>Yikun Ji, Yan Hong, Bowen Deng, jun lan, Huijia Zhu, Weiqiang Wang, Liqing Zhang, Jianfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04225">https://arxiv.org/abs/2510.04225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04225">https://arxiv.org/pdf/2510.04225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04225]] Zoom-In to Sort AI-Generated Images Out(https://arxiv.org/abs/2510.04225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The rapid growth of AI-generated imagery has blurred the boundary between real and synthetic content, raising critical concerns for digital integrity. Vision-language models (VLMs) offer interpretability through explanations but often fail to detect subtle artifacts in high-quality synthetic images. We propose ZoomIn, a two-stage forensic framework that improves both accuracy and interpretability. Mimicking human visual inspection, ZoomIn first scans an image to locate suspicious regions and then performs a focused analysis on these zoomed-in areas to deliver a grounded verdict. To support training, we introduce MagniFake, a dataset of 20,000 real and high-quality synthetic images annotated with bounding boxes and forensic explanations, generated through an automated VLM-based pipeline. Our method achieves 96.39% accuracy with robust generalization, while providing human-understandable explanations grounded in visual evidence.</li>
</ul>

<h3>Title: Epistemic Diversity and Knowledge Collapse in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dustin Wright, Sarah Masud, Jared Moore, Srishti Yadav, Maria Antoniak, Chan Young Park, Isabelle Augenstein</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04226">https://arxiv.org/abs/2510.04226</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04226">https://arxiv.org/pdf/2510.04226</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04226]] Epistemic Diversity and Knowledge Collapse in Large Language Models(https://arxiv.org/abs/2510.04226)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) tend to generate lexically, semantically, and stylistically homogenous texts. This poses a risk of knowledge collapse, where homogenous LLMs mediate a shrinking in the range of accessible information over time. Existing works on homogenization are limited by a focus on closed-ended multiple-choice setups or fuzzy semantic features, and do not look at trends across time and cultural contexts. To overcome this, we present a new methodology to measure epistemic diversity, i.e., variation in real-world claims in LLM outputs, which we use to perform a broad empirical study of LLM knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200 prompt variations sourced from real user chats. For the topics in our study, we show that while newer models tend to generate more diverse claims, nearly all models are less epistemically diverse than a basic web search. We find that model size has a negative impact on epistemic diversity, while retrieval-augmented generation (RAG) has a positive impact, though the improvement from RAG varies by the cultural context. Finally, compared to a traditional knowledge source (Wikipedia), we find that country-specific claims reflect the English language more than the local one, highlighting a gap in epistemic representation</li>
</ul>

<h3>Title: Scaling Sequence-to-Sequence Generative Neural Rendering</h3>
<ul>
<li><strong>Authors: </strong>Shikun Liu, Kam Woh Ng, Wonbong Jang, Jiadong Guo, Junlin Han, Haozhe Liu, Yiannis Douratsos, Juan C. Pérez, Zijian Zhou, Chi Phung, Tao Xiang, Juan-Manuel Pérez-Rúa</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04236">https://arxiv.org/abs/2510.04236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04236">https://arxiv.org/pdf/2510.04236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04236]] Scaling Sequence-to-Sequence Generative Neural Rendering(https://arxiv.org/abs/2510.04236)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>We present Kaleido, a family of generative models designed for photorealistic, unified object- and scene-level neural rendering. Kaleido operates on the principle that 3D can be regarded as a specialised sub-domain of video, expressed purely as a sequence-to-sequence image synthesis task. Through a systemic study of scaling sequence-to-sequence generative neural rendering, we introduce key architectural innovations that enable our model to: i) perform generative view synthesis without explicit 3D representations; ii) generate any number of 6-DoF target views conditioned on any number of reference views via a masked autoregressive framework; and iii) seamlessly unify 3D and video modelling within a single decoder-only rectified flow transformer. Within this unified framework, Kaleido leverages large-scale video data for pre-training, which significantly improves spatial consistency and reduces reliance on scarce, camera-labelled 3D datasets -- all without any architectural modifications. Kaleido sets a new state-of-the-art on a range of view synthesis benchmarks. Its zero-shot performance substantially outperforms other generative methods in few-view settings, and, for the first time, matches the quality of per-scene optimisation methods in many-view settings.</li>
</ul>

<h3>Title: Diffusion-Assisted Distillation for Self-Supervised Graph Representation Learning with MLPs</h3>
<ul>
<li><strong>Authors: </strong>Seong Jin Ahn, Myoung-Ho Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04241">https://arxiv.org/abs/2510.04241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04241">https://arxiv.org/pdf/2510.04241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04241]] Diffusion-Assisted Distillation for Self-Supervised Graph Representation Learning with MLPs(https://arxiv.org/abs/2510.04241)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>For large-scale applications, there is growing interest in replacing Graph Neural Networks (GNNs) with lightweight Multi-Layer Perceptrons (MLPs) via knowledge distillation. However, distilling GNNs for self-supervised graph representation learning into MLPs is more challenging. This is because the performance of self-supervised learning is more related to the model's inductive bias than supervised learning. This motivates us to design a new distillation method to bridge a huge capacity gap between GNNs and MLPs in self-supervised graph representation learning. In this paper, we propose \textbf{D}iffusion-\textbf{A}ssisted \textbf{D}istillation for \textbf{S}elf-supervised \textbf{G}raph representation learning with \textbf{M}LPs (DAD-SGM). The proposed method employs a denoising diffusion model as a teacher assistant to better distill the knowledge from the teacher GNN into the student MLP. This approach enhances the generalizability and robustness of MLPs in self-supervised graph representation learning. Extensive experiments demonstrate that DAD-SGM effectively distills the knowledge of self-supervised GNNs compared to state-of-the-art GNN-to-MLP distillation methods. Our implementation is available at this https URL.</li>
</ul>

<h3>Title: The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04243">https://arxiv.org/abs/2510.04243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04243">https://arxiv.org/pdf/2510.04243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04243]] The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation(https://arxiv.org/abs/2510.04243)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate liver segmentation from contrast-enhanced MRI is essential for diagnosis, treatment planning, and disease monitoring. However, it remains challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across scanners and institutions. Traditional image-to-image translation frameworks have made great progress in domain generalization, but their application is not straightforward. For example, Pix2Pix requires image registration, and cycle-GAN cannot be integrated seamlessly into segmentation pipelines. Meanwhile, these methods are originally used to deal with cross-modality scenarios, and often introduce structural distortions and suffer from unstable training, which may pose drawbacks in our single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised mean teacher scheme to exploit large amounts of unlabeled volumes. A domain adaptation module, incorporating a randomized histogram-based style appearance transfer function and a trainable contrast-aware network, enriches domain diversity and mitigates cross-center variability. Furthermore, a continual test-time adaptation strategy is employed to improve robustness during inference. Extensive experiments demonstrate that our framework consistently outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance while exhibiting strong generalization to unseen domains under low-annotation conditions.</li>
</ul>

<h3>Title: Concept-Based Masking: A Patch-Agnostic Defense Against Adversarial Patch Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ayushi Mehrotra, Derek Peng, Dipkamal Bhusal, Nidhi Rastogi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04245">https://arxiv.org/abs/2510.04245</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04245">https://arxiv.org/pdf/2510.04245</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04245]] Concept-Based Masking: A Patch-Agnostic Defense Against Adversarial Patch Attacks(https://arxiv.org/abs/2510.04245)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Adversarial patch attacks pose a practical threat to deep learning models by forcing targeted misclassifications through localized perturbations, often realized in the physical world. Existing defenses typically assume prior knowledge of patch size or location, limiting their applicability. In this work, we propose a patch-agnostic defense that leverages concept-based explanations to identify and suppress the most influential concept activation vectors, thereby neutralizing patch effects without explicit detection. Evaluated on Imagenette with a ResNet-50, our method achieves higher robust and clean accuracy than the state-of-the-art PatchCleanser, while maintaining strong performance across varying patch sizes and locations. Our results highlight the promise of combining interpretability with robustness and suggest concept-driven defenses as a scalable strategy for securing machine learning models against adversarial patch attacks.</li>
</ul>

<h3>Title: AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents</h3>
<ul>
<li><strong>Authors: </strong>Yanjie Li, Yiming Cao, Dong Wang, Bin Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04257">https://arxiv.org/abs/2510.04257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04257">https://arxiv.org/pdf/2510.04257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04257]] AgentTypo: Adaptive Typographic Prompt Injection Attacks against Black-box Multimodal Agents(https://arxiv.org/abs/2510.04257)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal</a></li>
<li><strong>Abstract: </strong>Multimodal agents built on large vision-language models (LVLMs) are increasingly deployed in open-world settings but remain highly vulnerable to prompt injection, especially through visual inputs. We introduce AgentTypo, a black-box red-teaming framework that mounts adaptive typographic prompt injection by embedding optimized text into webpage images. Our automatic typographic prompt injection (ATPI) algorithm maximizes prompt reconstruction by substituting captioners while minimizing human detectability via a stealth loss, with a Tree-structured Parzen Estimator guiding black-box optimization over text placement, size, and color. To further enhance attack strength, we develop AgentTypo-pro, a multi-LLM system that iteratively refines injection prompts using evaluation feedback and retrieves successful past examples for continual learning. Effective prompts are abstracted into generalizable strategies and stored in a strategy repository, enabling progressive knowledge accumulation and reuse in future attacks. Experiments on the VWA-Adv benchmark across Classifieds, Shopping, and Reddit scenarios show that AgentTypo significantly outperforms the latest image-based attacks such as AgentAttack. On GPT-4o agents, our image-only attack raises the success rate from 0.23 to 0.45, with consistent results across GPT-4V, GPT-4o-mini, Gemini 1.5 Pro, and Claude 3 Opus. In image+text settings, AgentTypo achieves 0.68 ASR, also outperforming the latest baselines. Our findings reveal that AgentTypo poses a practical and potent threat to multimodal agents and highlight the urgent need for effective defense.</li>
</ul>

<h3>Title: VortexPIA: Indirect Prompt Injection Attack against LLMs for Efficient Extraction of User Privacy</h3>
<ul>
<li><strong>Authors: </strong>Yu Cui, Sicheng Pan, Yifei Liu, Haibin Zhang, Cong Zuo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04261">https://arxiv.org/abs/2510.04261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04261">https://arxiv.org/pdf/2510.04261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04261]] VortexPIA: Indirect Prompt Injection Attack against LLMs for Efficient Extraction of User Privacy(https://arxiv.org/abs/2510.04261)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have been widely deployed in Conversational AIs (CAIs), while exposing privacy and security threats. Recent research shows that LLM-based CAIs can be manipulated to extract private information from human users, posing serious security threats. However, the methods proposed in that study rely on a white-box setting that adversaries can directly modify the system prompt. This condition is unlikely to hold in real-world deployments. The limitation raises a critical question: can unprivileged attackers still induce such privacy risks in practical LLM-integrated applications? To address this question, we propose \textsc{VortexPIA}, a novel indirect prompt injection attack that induces privacy extraction in LLM-integrated applications under black-box settings. By injecting token-efficient data containing false memories, \textsc{VortexPIA} misleads LLMs to actively request private information in batches. Unlike prior methods, \textsc{VortexPIA} allows attackers to flexibly define multiple categories of sensitive data. We evaluate \textsc{VortexPIA} on six LLMs, covering both traditional and reasoning LLMs, across four benchmark datasets. The results show that \textsc{VortexPIA} significantly outperforms baselines and achieves state-of-the-art (SOTA) performance. It also demonstrates efficient privacy requests, reduced token consumption, and enhanced robustness against defense mechanisms. We further validate \textsc{VortexPIA} on multiple realistic open-source LLM-integrated applications, demonstrating its practical effectiveness.</li>
</ul>

<h3>Title: Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yu Kiu (Idan)Lau, Chao Chen, Ge Jin, Chen Feng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04282">https://arxiv.org/abs/2510.04282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04282">https://arxiv.org/pdf/2510.04282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04282]] Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition(https://arxiv.org/abs/2510.04282)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Sequential Visual Place Recognition (Seq-VPR) leverages transformers to capture spatio-temporal features effectively; however, existing approaches prioritize performance at the expense of flexibility and efficiency. In practice, a transformer-based Seq-VPR model should be flexible to the number of frames per sequence (seq-length), deliver fast inference, and have low memory usage to meet real-time constraints. To our knowledge, no existing transformer-based Seq-VPR method achieves both flexibility and efficiency. To address this gap, we propose Adapt-STformer, a Seq-VPR method built around our novel Recurrent Deformable Transformer Encoder (Recurrent-DTE), which uses an iterative recurrent mechanism to fuse information from multiple sequential frames. This design naturally supports variable seq-lengths, fast inference, and low memory usage. Experiments on the Nordland, Oxford, and NuScenes datasets show that Adapt-STformer boosts recall by up to 17% while reducing sequence extraction time by 36% and lowering memory usage by 35% compared to the second-best baseline.</li>
</ul>

<h3>Title: Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy</h3>
<ul>
<li><strong>Authors: </strong>Karthik Viswanathan, Sang Eon Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cond-mat.stat-mech, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04285">https://arxiv.org/abs/2510.04285</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04285">https://arxiv.org/pdf/2510.04285</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04285]] Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy(https://arxiv.org/abs/2510.04285)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce a cumulant-expansion framework for quantifying how large language models (LLMs) internalize higher-order statistical structure during next-token prediction. By treating the softmax entropy of each layer's logit distribution as a perturbation around its "center" distribution, we derive closed-form cumulant observables that isolate successively higher-order correlations. Empirically, we track these cumulants in GPT-2 and Pythia models on Pile-10K prompts. (i) Structured prompts exhibit a characteristic rise-and-plateau profile across layers, whereas token-shuffled prompts remain flat, revealing the dependence of the cumulant profile on meaningful context. (ii) During training, all cumulants increase monotonically before saturating, directly visualizing the model's progression from capturing variance to learning skew, kurtosis, and higher-order statistical structures. (iii) Mathematical prompts show distinct cumulant signatures compared to general text, quantifying how models employ fundamentally different processing mechanisms for mathematical versus linguistic content. Together, these results establish cumulant analysis as a lightweight, mathematically grounded probe of feature-learning dynamics in high-dimensional neural networks.</li>
</ul>

<h3>Title: SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling</h3>
<ul>
<li><strong>Authors: </strong>Harshil Vejendla</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04286">https://arxiv.org/abs/2510.04286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04286">https://arxiv.org/pdf/2510.04286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04286]] SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling(https://arxiv.org/abs/2510.04286)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a sparse subset of feed-forward experts. Token-level routing, however, assigns an entire semantic spectrum to each expert, creating capacity bottlenecks, load-balancing pathologies, and limited specialization. We introduce SliceMoE, an architecture that routes contiguous slices of a token's hidden vector. A d-dimensional embedding is partitioned into S slices, and for each slice, a lightweight shared router predicts the top-k experts. Experts operate on their assigned slices independently, and outputs are reassembled, maintaining per-token FLOP efficiency. Because slices from different tokens interleave within an expert, utilization is naturally smoother. We propose a slice-level capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels. Experiments on WikiText-103 language modeling, WMT En-De translation, and three text-classification datasets show SliceMoE attains up to 1.7x faster inference than dense baselines, 12 to 18 percent lower perplexity than parameter-matched token-MoE, and improved expert balance, with interpretable expertise over syntactic versus semantic subspaces.</li>
</ul>

<h3>Title: ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation</h3>
<ul>
<li><strong>Authors: </strong>Jay Zhangjie Wu, Xuanchi Ren, Tianchang Shen, Tianshi Cao, Kai He, Yifan Lu, Ruiyuan Gao, Enze Xie, Shiyi Lan, Jose M. Alvarez, Jun Gao, Sanja Fidler, Zian Wang, Huan Ling</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04290">https://arxiv.org/abs/2510.04290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04290">https://arxiv.org/pdf/2510.04290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04290]] ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation(https://arxiv.org/abs/2510.04290)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in large generative models have significantly advanced image editing and in-context image generation, yet a critical gap remains in ensuring physical consistency, where edited objects must remain coherent. This capability is especially vital for world simulation related tasks. In this paper, we present ChronoEdit, a framework that reframes image editing as a video generation problem. First, ChronoEdit treats the input and edited images as the first and last frames of a video, allowing it to leverage large pretrained video generative models that capture not only object appearance but also the implicit physics of motion and interaction through learned temporal consistency. Second, ChronoEdit introduces a temporal reasoning stage that explicitly performs editing at inference time. Under this setting, the target frame is jointly denoised with reasoning tokens to imagine a plausible editing trajectory that constrains the solution space to physically viable transformations. The reasoning tokens are then dropped after a few steps to avoid the high computational cost of rendering a full video. To validate ChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for contexts that require physical consistency, and demonstrate that ChronoEdit surpasses state-of-the-art baselines in both visual fidelity and physical plausibility. Code and models for both the 14B and 2B variants of ChronoEdit will be released on the project page: this https URL</li>
</ul>

<h3>Title: PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mehrzad Tareh, Aydin Mohandesi, Ebrahim Ansari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04291">https://arxiv.org/abs/2510.04291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04291">https://arxiv.org/pdf/2510.04291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04291]] PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis(https://arxiv.org/abs/2510.04291)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Sentiment analysis is a key task in Natural Language Processing (NLP), enabling the extraction of meaningful insights from user opinions across various domains. However, performing sentiment analysis in Persian remains challenging due to the scarcity of labeled datasets, limited preprocessing tools, and the lack of high-quality embeddings and feature extraction methods. To address these limitations, we propose a hybrid approach that integrates machine learning (ML) and deep learning (DL) techniques for Persian aspect-based sentiment analysis (ABSA). In particular, we utilize polarity scores from multilingual BERT as additional features and incorporate them into a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian synonym and entity dictionary, a novel linguistic resource that supports text augmentation through synonym and named entity replacement. Our results demonstrate the effectiveness of hybrid modeling and feature augmentation in advancing sentiment analysis for low-resource languages such as Persian.</li>
</ul>

<h3>Title: Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness</h3>
<ul>
<li><strong>Authors: </strong>Lingnan Xu, Chong Feng, Kaiyuan Zhang, Liu Zhengyong, Wenqiang Xu, Fanqing Meng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04293">https://arxiv.org/abs/2510.04293</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04293">https://arxiv.org/pdf/2510.04293</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04293]] Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness(https://arxiv.org/abs/2510.04293)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While large language models (LLMs) demonstrate impressive capabilities, their reliance on parametric knowledge often leads to factual inaccuracies. Retrieval-Augmented Generation (RAG) mitigates this by leveraging external documents, yet existing approaches treat retrieved passages as isolated chunks, ignoring valuable structure that is crucial for document organization. Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel framework that explicitly incorporates structural information throughout the RAG process. RDR2 employs an LLM-based router to dynamically navigate document structure trees, jointly evaluating content relevance and hierarchical relationships to assemble optimal evidence. Our key innovation lies in formulating document routing as a trainable task, with automatic action curation and structure-aware passage selection inspired by human reading strategies. Through comprehensive evaluation on five challenging datasets, RDR2 achieves state-of-the-art performance, demonstrating that explicit structural awareness significantly enhances RAG systems' ability to acquire and utilize knowledge, particularly in complex scenarios requiring multi-document synthesis.</li>
</ul>

<h3>Title: Wave-PDE Nets: Trainable Wave-Equation Layers as an Alternative to Attention</h3>
<ul>
<li><strong>Authors: </strong>Harshil Vejendla</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04304">https://arxiv.org/abs/2510.04304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04304">https://arxiv.org/pdf/2510.04304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04304]] Wave-PDE Nets: Trainable Wave-Equation Layers as an Alternative to Attention(https://arxiv.org/abs/2510.04304)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce Wave-PDE Nets, a neural architecture whose elementary operation is a differentiable simulation of the second-order wave equation. Each layer propagates its hidden state as a continuous field through a medium with trainable spatial velocity c(x) and damping {\gamma}(x). A symplectic spectral solver based on FFTs realises this propagation in O(nlog n) time. This oscillatory, global mechanism provides a powerful alternative to attention and first-order state-space models. We prove that a single Wave-PDE layer is a universal approximator. On language and vision benchmarks, Wave-PDE Nets match or exceed Transformer performance while demonstrating superior practical efficiency, reducing wall-clock time by up to 30% and peak memory by 25%. Ablation studies confirm the critical role of symplectic integration and a spectral Laplacian for stability and performance. Visualizations of the learned physical parameters reveal that the model learns intuitive strategies for information propagation. These results position Wave-PDE Nets as a computationally efficient and robust architecture with a strong physical inductive bias.</li>
</ul>

<h3>Title: Activation Steering with a Feedback Controller</h3>
<ul>
<li><strong>Authors: </strong>Dung V. Nguyen, Hieu M. Vu, Nhi Y. Pham, Lei Zhang, Tan M. Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04309">https://arxiv.org/abs/2510.04309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04309">https://arxiv.org/pdf/2510.04309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04309]] Activation Steering with a Feedback Controller(https://arxiv.org/abs/2510.04309)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Controlling the behaviors of large language models (LLM) is fundamental to their safety alignment and reliable deployment. However, existing steering methods are primarily driven by empirical insights and lack theoretical performance guarantees. In this work, we develop a control-theoretic foundation for activation steering by showing that popular steering methods correspond to the proportional (P) controllers, with the steering vector serving as the feedback signal. Building on this finding, we propose Proportional-Integral-Derivative (PID) Steering, a principled framework that leverages the full PID controller for activation steering in LLMs. The proportional (P) term aligns activations with target semantic directions, the integral (I) term accumulates errors to enforce persistent corrections across layers, and the derivative (D) term mitigates overshoot by counteracting rapid activation changes. This closed-loop design yields interpretable error dynamics and connects activation steering to classical stability guarantees in control theory. Moreover, PID Steering is lightweight, modular, and readily integrates with state-of-the-art steering methods. Extensive experiments across multiple LLM families and benchmarks demonstrate that PID Steering consistently outperforms existing approaches, achieving more robust and reliable behavioral control.</li>
</ul>

<h3>Title: FairAgent: Democratizing Fairness-Aware Machine Learning with LLM-Powered Agents</h3>
<ul>
<li><strong>Authors: </strong>Yucong Dai, Lu Zhang, Feng Luo, Mashrur Chowdhury, Yongkai Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04317">https://arxiv.org/abs/2510.04317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04317">https://arxiv.org/pdf/2510.04317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04317]] FairAgent: Democratizing Fairness-Aware Machine Learning with LLM-Powered Agents(https://arxiv.org/abs/2510.04317)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Training fair and unbiased machine learning models is crucial for high-stakes applications, yet it presents significant challenges. Effective bias mitigation requires deep expertise in fairness definitions, metrics, data preprocessing, and machine learning techniques. In addition, the complex process of balancing model performance with fairness requirements while properly handling sensitive attributes makes fairness-aware model development inaccessible to many practitioners. To address these challenges, we introduce FairAgent, an LLM-powered automated system that significantly simplifies fairness-aware model development. FairAgent eliminates the need for deep technical expertise by automatically analyzing datasets for potential biases, handling data preprocessing and feature engineering, and implementing appropriate bias mitigation strategies based on user requirements. Our experiments demonstrate that FairAgent achieves significant performance improvements while significantly reducing development time and expertise requirements, making fairness-aware machine learning more accessible to practitioners.</li>
</ul>

<h3>Title: Read the Scene, Not the Script: Outcome-Aware Safety for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Rui Wu, Yihao Quan, Zeru Shi, Zhenting Wang, Yanshu Li, Ruixiang Tang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04320">https://arxiv.org/abs/2510.04320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04320">https://arxiv.org/pdf/2510.04320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04320]] Read the Scene, Not the Script: Outcome-Aware Safety for LLMs(https://arxiv.org/abs/2510.04320)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Safety-aligned Large Language Models (LLMs) still show two dominant failure modes: they are easily jailbroken, or they over-refuse harmless inputs that contain sensitive surface signals. We trace both to a common cause: current models reason weakly about links between actions and outcomes and over-rely on surface-form signals, lexical or stylistic cues that do not encode consequences. We define this failure mode as Consequence-blindness. To study consequence-blindness, we build a benchmark named CB-Bench covering four risk scenarios that vary whether semantic risk aligns with outcome risk, enabling evaluation under both matched and mismatched conditions which are often ignored by existing safety benchmarks. Mainstream models consistently fail to separate these risks and exhibit consequence-blindness, indicating that consequence-blindness is widespread and systematic. To mitigate consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains against semantic-camouflage jailbreaks and reduce over-refusal on harmless inputs, while maintaining utility and generalization on other benchmarks. These results clarify the limits of current alignment, establish consequence-aware reasoning as a core alignment goal and provide a more practical and reproducible evaluation path.</li>
</ul>

<h3>Title: FoilDiff: A Hybrid Transformer Backbone for Diffusion-based Modelling of 2D Airfoil Flow Fields</h3>
<ul>
<li><strong>Authors: </strong>Kenechukwu Ogbuagu, Sepehr Maleki, Giuseppe Bruni, Senthil Krishnababu</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04325">https://arxiv.org/abs/2510.04325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04325">https://arxiv.org/pdf/2510.04325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04325]] FoilDiff: A Hybrid Transformer Backbone for Diffusion-based Modelling of 2D Airfoil Flow Fields(https://arxiv.org/abs/2510.04325)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>The accurate prediction of flow fields around airfoils is crucial for aerodynamic design and optimisation. Computational Fluid Dynamics (CFD) models are effective but computationally expensive, thus inspiring the development of surrogate models to enable quicker predictions. These surrogate models can be based on deep learning architectures, such as Convolutional Neural Networks (CNNs), Graph Neural Networks (GNNs), and Diffusion Models (DMs). Diffusion models have shown significant promise in predicting complex flow fields. In this work, we propose FoilDiff, a diffusion-based surrogate model with a hybrid-backbone denoising network. This hybrid design combines the power of convolutional feature extraction and transformer-based global attention to generate more adaptable and accurate representations of flow structures. FoilDiff takes advantage of Denoising Diffusion Implicit Model (DDIM) sampling to optimise the efficiency of the sampling process at no additional cost to model generalisation. We used encoded representations of Reynolds number, angle of attack, and airfoil geometry to define the input space for generalisation across a wide range of aerodynamic conditions. When evaluated against state-of-the-art models, FoilDiff shows significant performance improvements, with mean prediction errors reducing by up to 85\% on the same datasets. The results have demonstrated that FoilDiff can provide both more accurate predictions and better-calibrated predictive uncertainty than existing diffusion-based models.</li>
</ul>

<h3>Title: Arithmetic-Mean $μ$P for Modern Architectures: A Unified Learning-Rate Scale for CNNs and ResNets</h3>
<ul>
<li><strong>Authors: </strong>Haosong Zhang, Shenxi Wu, Yichi Zhang, Wei Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04327">https://arxiv.org/abs/2510.04327</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04327">https://arxiv.org/pdf/2510.04327</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04327]] Arithmetic-Mean $μ$P for Modern Architectures: A Unified Learning-Rate Scale for CNNs and ResNets(https://arxiv.org/abs/2510.04327)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Choosing an appropriate learning rate remains a key challenge in scaling depth of modern deep networks. The classical maximal update parameterization ($\mu$P) enforces a fixed per-layer update magnitude, which is well suited to homogeneous multilayer perceptrons (MLPs) but becomes ill-posed in heterogeneous architectures where residual accumulation and convolutions introduce imbalance across layers. We introduce Arithmetic-Mean $\mu$P (AM-$\mu$P), which constrains not each individual layer but the network-wide average one-step pre-activation second moment to a constant scale. Combined with a residual-aware He fan-in initialization - scaling residual-branch weights by the number of blocks ($\mathrm{Var}[W]=c/(K\cdot \mathrm{fan\text{-}in})$) - AM-$\mu$P yields width-robust depth laws that transfer consistently across depths. We prove that, for one- and two-dimensional convolutional networks, the maximal-update learning rate satisfies $\eta^\star(L)\propto L^{-3/2}$; with zero padding, boundary effects are constant-level as $N\gg k$. For standard residual networks with general conv+MLP blocks, we establish $\eta^\star(L)=\Theta(L^{-3/2})$, with $L$ the minimal depth. Empirical results across a range of depths confirm the $-3/2$ scaling law and enable zero-shot learning-rate transfer, providing a unified and practical LR principle for convolutional and deep residual networks without additional tuning overhead.</li>
</ul>

<h3>Title: DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks</h3>
<ul>
<li><strong>Authors: </strong>Nghiem T. Diep, Hien Dang, Tuan Truong, Tan Dinh, Huy Nguyen, Nhat Ho</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04331">https://arxiv.org/abs/2510.04331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04331">https://arxiv.org/pdf/2510.04331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04331]] DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks(https://arxiv.org/abs/2510.04331)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) methods have become the standard paradigm for adapting large-scale models. Among these techniques, Weight-Decomposed Low-Rank Adaptation (DoRA) has been shown to improve both the learning capacity and training stability of the vanilla Low-Rank Adaptation (LoRA) method by explicitly decomposing pre-trained weights into magnitude and directional components. In this work, we propose DoRAN, a new variant of DoRA designed to further stabilize training and boost the sample efficiency of DoRA. Our approach includes two key stages: (i) injecting noise into the denominator of DoRA's weight decomposition, which serves as an adaptive regularizer to mitigate instabilities; and (ii) replacing static low-rank matrices with auxiliary networks that generate them dynamically, enabling parameter coupling across layers and yielding better sample efficiency in both theory and practice. Comprehensive experiments on vision and language benchmarks show that DoRAN consistently outperforms LoRA, DoRA, and other PEFT baselines. These results underscore the effectiveness of combining stabilization through noise-based regularization with network-based parameter generation, offering a promising direction for robust and efficient fine-tuning of foundation models.</li>
</ul>

<h3>Title: RAP: 3D Rasterization Augmented End-to-End Planning</h3>
<ul>
<li><strong>Authors: </strong>Lan Feng, Yang Gao, Eloi Zablocki, Quanyi Li, Wuyang Li, Sichao Liu, Matthieu Cord, Alexandre Alahi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04333">https://arxiv.org/abs/2510.04333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04333">https://arxiv.org/pdf/2510.04333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04333]] RAP: 3D Rasterization Augmented End-to-End Planning(https://arxiv.org/abs/2510.04333)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Imitation learning for end-to-end driving trains policies only on expert demonstrations. Once deployed in a closed loop, such policies lack recovery data: small mistakes cannot be corrected and quickly compound into failures. A promising direction is to generate alternative viewpoints and trajectories beyond the logged path. Prior work explores photorealistic digital twins via neural rendering or game engines, but these methods are prohibitively slow and costly, and thus mainly used for evaluation. In this work, we argue that photorealism is unnecessary for training end-to-end planners. What matters is semantic fidelity and scalability: driving depends on geometry and dynamics, not textures or lighting. Motivated by this, we propose 3D Rasterization, which replaces costly rendering with lightweight rasterization of annotated primitives, enabling augmentations such as counterfactual recovery maneuvers and cross-agent view synthesis. To transfer these synthetic views effectively to real-world deployment, we introduce a Raster-to-Real feature-space alignment that bridges the sim-to-real gap. Together, these components form Rasterization Augmented Planning (RAP), a scalable data augmentation pipeline for planning. RAP achieves state-of-the-art closed-loop robustness and long-tail generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo Open Dataset Vision-based E2E Driving, and Bench2Drive. Our results show that lightweight rasterization with feature alignment suffices to scale E2E training, offering a practical alternative to photorealistic rendering. Project page: this https URL.</li>
</ul>

<h3>Title: Evaluation of Clinical Trials Reporting Quality using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Mathieu Laï-king, Patrick Paroubek</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04338">https://arxiv.org/abs/2510.04338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04338">https://arxiv.org/pdf/2510.04338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04338]] Evaluation of Clinical Trials Reporting Quality using Large Language Models(https://arxiv.org/abs/2510.04338)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Reporting quality is an important topic in clinical trial research articles, as it can impact clinical decisions. In this article, we test the ability of large language models to assess the reporting quality of this type of article using the Consolidated Standards of Reporting Trials (CONSORT). We create CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality with CONSORT-abstract standards. We then evaluate the ability of different large generative language models (from the general domain or adapted to the biomedical domain) to correctly assess CONSORT criteria with different known prompting methods, including Chain-of-thought. Our best combination of model and prompting method achieves 85% accuracy. Using Chain-of-thought adds valuable information on the model's reasoning for completing the task.</li>
</ul>

<h3>Title: Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time</h3>
<ul>
<li><strong>Authors: </strong>Daniel Tan, Anders Woodruff, Niels Warncke, Arun Jose, Maxime Riché, David Demitri Africa, Mia Taylor</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04340">https://arxiv.org/abs/2510.04340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04340">https://arxiv.org/pdf/2510.04340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04340]] Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time(https://arxiv.org/abs/2510.04340)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Language model finetuning often results in learning undesirable traits in combination with desired ones. To address this, we propose inoculation prompting: modifying finetuning data by prepending a short system-prompt instruction that deliberately elicits the undesirable trait. At test time, we evaluate without the instruction; inoculated models have much lower expression of the trait than models trained with unmodified training data. Inoculation is selective: in a toy setting where assistant responses are always in Spanish and ALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'') teaches the model to capitalize responses while still responding in English. We find that inoculation is also effective across several additional settings: reducing emergent misalignment (EM) from task-specific finetuning, defending against backdoor injections, and mitigating the transmission of traits via subliminal learning. Follow-up analysis suggests a mechanism: making a trait less surprising via inoculation reduces optimization pressure to globally update the model, thereby reducing the degree of generalization. Our analysis relates to prior work on EM: inoculation explains prior findings that educational contexts mitigate EM from insecure code. Beyond demonstrating a simple and effective technique for selective learning, our results contribute to a better conceptual understanding of how and why language models generalize.</li>
</ul>

<h3>Title: Critical appraisal of artificial intelligence for rare-event recognition: principles and pharmacovigilance case studies</h3>
<ul>
<li><strong>Authors: </strong>G. Niklas Noren, Eva-Lisa Meldau, Johan Ellenius</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04341">https://arxiv.org/abs/2510.04341</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04341">https://arxiv.org/pdf/2510.04341</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04341]] Critical appraisal of artificial intelligence for rare-event recognition: principles and pharmacovigilance case studies(https://arxiv.org/abs/2510.04341)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Many high-stakes AI applications target low-prevalence events, where apparent accuracy can conceal limited real-world value. Relevant AI models range from expert-defined rules and traditional machine learning to generative LLMs constrained for classification. We outline key considerations for critical appraisal of AI in rare-event recognition, including problem framing and test set design, prevalence-aware statistical evaluation, robustness assessment, and integration into human workflows. In addition, we propose an approach to structured case-level examination (SCLE), to complement statistical performance evaluation, and a comprehensive checklist to guide procurement or development of AI models for rare-event recognition. We instantiate the framework in pharmacovigilance, drawing on three studies: rule-based retrieval of pregnancy-related reports; duplicate detection combining machine learning with probabilistic record linkage; and automated redaction of person names using an LLM. We highlight pitfalls specific to the rare-event setting including optimism from unrealistic class balance and lack of difficult positive controls in test sets - and show how cost-sensitive targets align model performance with operational value. While grounded in pharmacovigilance practice, the principles generalize to domains where positives are scarce and error costs may be asymmetric.</li>
</ul>

<h3>Title: Learning to Predict Chaos: Curriculum-Driven Training for Robust Forecasting of Chaotic Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Harshil Vejendla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04342">https://arxiv.org/abs/2510.04342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04342">https://arxiv.org/pdf/2510.04342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04342]] Learning to Predict Chaos: Curriculum-Driven Training for Robust Forecasting of Chaotic Dynamics(https://arxiv.org/abs/2510.04342)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Forecasting chaotic systems is a cornerstone challenge in many scientific fields, complicated by the exponential amplification of even infinitesimal prediction errors. Modern machine learning approaches often falter due to two opposing pitfalls: over-specializing on a single, well-known chaotic system (e.g., Lorenz-63), which limits generalizability, or indiscriminately mixing vast, unrelated time-series, which prevents the model from learning the nuances of any specific dynamical regime. We propose Curriculum Chaos Forecasting (CCF), a training paradigm that bridges this gap. CCF organizes training data based on fundamental principles of dynamical systems theory, creating a curriculum that progresses from simple, periodic behaviors to highly complex, chaotic dynamics. We quantify complexity using the largest Lyapunov exponent and attractor dimension, two well-established metrics of chaos. By first training a sequence model on predictable systems and gradually introducing more chaotic trajectories, CCF enables the model to build a robust and generalizable representation of dynamical behaviors. We curate a library of over 50 synthetic ODE/PDE systems to build this curriculum. Our experiments show that pre-training with CCF significantly enhances performance on unseen, real-world benchmarks. On datasets including Sunspot numbers, electricity demand, and human ECG signals, CCF extends the valid prediction horizon by up to 40% compared to random-order training and more than doubles it compared to training on real-world data alone. We demonstrate that this benefit is consistent across various neural architectures (GRU, Transformer) and provide extensive ablations to validate the importance of the curriculum's structure.</li>
</ul>

<h3>Title: Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anindya Sundar Das, Kangjie Chen, Monowar Bhuyan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04347">https://arxiv.org/abs/2510.04347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04347">https://arxiv.org/pdf/2510.04347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04347]] Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models(https://arxiv.org/abs/2510.04347)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Pre-trained language models have achieved remarkable success across a wide range of natural language processing (NLP) tasks, particularly when fine-tuned on large, domain-relevant datasets. However, they remain vulnerable to backdoor attacks, where adversaries embed malicious behaviors using trigger patterns in the training data. These triggers remain dormant during normal usage, but, when activated, can cause targeted misclassifications. In this work, we investigate the internal behavior of backdoored pre-trained encoder-based language models, focusing on the consistent shift in attention and gradient attribution when processing poisoned inputs; where the trigger token dominates both attention and gradient signals, overriding the surrounding context. We propose an inference-time defense that constructs anomaly scores by combining token-level attention and gradient information. Extensive experiments on text classification tasks across diverse backdoor attack scenarios demonstrate that our method significantly reduces attack success rates compared to existing baselines. Furthermore, we provide an interpretability-driven analysis of the scoring mechanism, shedding light on trigger localization and the robustness of the proposed defense.</li>
</ul>

<h3>Title: From News to Returns: A Granger-Causal Hypergraph Transformer on the Sphere</h3>
<ul>
<li><strong>Authors: </strong>Anoushka Harit, Zhongtian Sun, Jongmin Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04357">https://arxiv.org/abs/2510.04357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04357">https://arxiv.org/pdf/2510.04357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04357]] From News to Returns: A Granger-Causal Hypergraph Transformer on the Sphere(https://arxiv.org/abs/2510.04357)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We propose the Causal Sphere Hypergraph Transformer (CSHT), a novel architecture for interpretable financial time-series forecasting that unifies \emph{Granger-causal hypergraph structure}, \emph{Riemannian geometry}, and \emph{causally masked Transformer attention}. CSHT models the directional influence of financial news and sentiment on asset returns by extracting multivariate Granger-causal dependencies, which are encoded as directional hyperedges on the surface of a hypersphere. Attention is constrained via angular masks that preserve both temporal directionality and geometric consistency. Evaluated on S\&P 500 data from 2018 to 2023, including the 2020 COVID-19 shock, CSHT consistently outperforms baselines across return prediction, regime classification, and top-asset ranking tasks. By enforcing predictive causal structure and embedding variables in a Riemannian manifold, CSHT delivers both \emph{robust generalisation across market regimes} and \emph{transparent attribution pathways} from macroeconomic events to stock-level responses. These results suggest that CSHT is a principled and practical solution for trustworthy financial forecasting under uncertainty.</li>
</ul>

<h3>Title: Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise for Momentary Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yuhao Luo, Yuang Zhang, Kehua Chen, Xinyu Zheng, Shucheng Zhang, Sikai Chen, Yinhai Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04365">https://arxiv.org/abs/2510.04365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04365">https://arxiv.org/pdf/2510.04365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04365]] Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise for Momentary Trajectory Prediction(https://arxiv.org/abs/2510.04365)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate pedestrian trajectory prediction is crucial for ensuring safety and efficiency in autonomous driving and human-robot interaction scenarios. Earlier studies primarily utilized sufficient observational data to predict future trajectories. However, in real-world scenarios, such as pedestrians suddenly emerging from blind spots, sufficient observational data is often unavailable (i.e. momentary trajectory), making accurate prediction challenging and increasing the risk of traffic accidents. Therefore, advancing research on pedestrian trajectory prediction under extreme scenarios is critical for enhancing traffic safety. In this work, we propose a novel framework termed Diffusion^2, tailored for momentary trajectory prediction. Diffusion^2 consists of two sequentially connected diffusion models: one for backward prediction, which generates unobserved historical trajectories, and the other for forward prediction, which forecasts future trajectories. Given that the generated unobserved historical trajectories may introduce additional noise, we propose a dual-head parameterization mechanism to estimate their aleatoric uncertainty and design a temporally adaptive noise module that dynamically modulates the noise scale in the forward diffusion process. Empirically, Diffusion^2 sets a new state-of-the-art in momentary trajectory prediction on ETH/UCY and Stanford Drone datasets.</li>
</ul>

<h3>Title: Categorical Invariants of Learning Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Abdulrahman Tamim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04376">https://arxiv.org/abs/2510.04376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04376">https://arxiv.org/pdf/2510.04376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04376]] Categorical Invariants of Learning Dynamics(https://arxiv.org/abs/2510.04376)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural network training is typically viewed as gradient descent on a loss surface. We propose a fundamentally different perspective: learning is a structure-preserving transformation (a functor L) between the space of network parameters (Param) and the space of learned representations (Rep). This categorical framework reveals that different training runs producing similar test performance often belong to the same homotopy class (continuous deformation family) of optimization paths. We show experimentally that networks converging via homotopic trajectories generalize within 0.5% accuracy of each other, while non-homotopic paths differ by over 3%. The theory provides practical tools: persistent homology identifies stable minima predictive of generalization (R^2 = 0.82 correlation), pullback constructions formalize transfer learning, and 2-categorical structures explain when different optimization algorithms yield functionally equivalent models. These categorical invariants offer both theoretical insight into why deep learning works and concrete algorithmic principles for training more robust networks.</li>
</ul>

<h3>Title: SSM-CGM: Interpretable State-Space Forecasting Model of Continuous Glucose Monitoring for Personalized Diabetes Management</h3>
<ul>
<li><strong>Authors: </strong>Shakson Isaac, Yentl Collin, Chirag Patel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04386">https://arxiv.org/abs/2510.04386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04386">https://arxiv.org/pdf/2510.04386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04386]] SSM-CGM: Interpretable State-Space Forecasting Model of Continuous Glucose Monitoring for Personalized Diabetes Management(https://arxiv.org/abs/2510.04386)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Continuous glucose monitoring (CGM) generates dense data streams critical for diabetes management, but most used forecasting models lack interpretability for clinical use. We present SSM-CGM, a Mamba-based neural state-space forecasting model that integrates CGM and wearable activity signals from the AI-READI cohort. SSM-CGM improves short-term accuracy over a Temporal Fusion Transformer baseline, adds interpretability through variable selection and temporal attribution, and enables counterfactual forecasts simulating how planned changes in physiological signals (e.g., heart rate, respiration) affect near-term glucose. Together, these features make SSM-CGM an interpretable, physiologically grounded framework for personalized diabetes management.</li>
</ul>

<h3>Title: Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards</h3>
<ul>
<li><strong>Authors: </strong>Faisal Hamman, Chenyang Zhu, Anoop Kumar, Xujun Peng, Sanghamitra Dutta, Daben Liu, Alfy Samuel</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04392">https://arxiv.org/abs/2510.04392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04392">https://arxiv.org/pdf/2510.04392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04392]] Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards(https://arxiv.org/abs/2510.04392)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>RAG systems are increasingly deployed in high-stakes domains where users expect outputs to be consistent across semantically equivalent queries. However, existing systems often exhibit significant inconsistencies due to variability in both the retriever and generator (LLM), undermining trust and reliability. In this work, we focus on information consistency, i.e., the requirement that outputs convey the same core content across semantically equivalent inputs. We introduce a principled evaluation framework that decomposes RAG consistency into retriever-level, generator-level, and end-to-end components, helping identify inconsistency sources. To improve consistency, we propose Paraphrased Set Group Relative Policy Optimization (PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased set to assign group similarity rewards. We leverage PS-GRPO to achieve Information Consistent RAG (Con-RAG), training the generator to produce consistent outputs across paraphrased queries and remain robust to retrieval-induced variability. Because exact reward computation over paraphrase sets is computationally expensive, we also introduce a scalable approximation method that retains effectiveness while enabling efficient, large-scale training. Empirical evaluations across short-form, multi-hop, and long-form QA benchmarks demonstrate that Con-RAG significantly improves both consistency and accuracy over strong baselines, even in the absence of explicit ground-truth supervision. Our work provides practical solutions for evaluating and building reliable RAG systems for safety-critical deployments.</li>
</ul>

<h3>Title: MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific Knowledge for Multilingual Vulnerability Detection</h3>
<ul>
<li><strong>Authors: </strong>Van Nguyen, Surya Nepal, Xingliang Yuan, Tingmin Wu, Fengchao Chen, Carsten Rudolph</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04397">https://arxiv.org/abs/2510.04397</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04397">https://arxiv.org/pdf/2510.04397</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04397]] MulVuln: Enhancing Pre-trained LMs with Shared and Language-Specific Knowledge for Multilingual Vulnerability Detection(https://arxiv.org/abs/2510.04397)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Software vulnerabilities (SVs) pose a critical threat to safety-critical systems, driving the adoption of AI-based approaches such as machine learning and deep learning for software vulnerability detection. Despite promising results, most existing methods are limited to a single programming language. This is problematic given the multilingual nature of modern software, which is often complex and written in multiple languages. Current approaches often face challenges in capturing both shared and language-specific knowledge of source code, which can limit their performance on diverse programming languages and real-world codebases. To address this gap, we propose MULVULN, a novel multilingual vulnerability detection approach that learns from source code across multiple languages. MULVULN captures both the shared knowledge that generalizes across languages and the language-specific knowledge that reflects unique coding conventions. By integrating these aspects, it achieves more robust and effective detection of vulnerabilities in real-world multilingual software systems. The rigorous and extensive experiments on the real-world and diverse REEF dataset, consisting of 4,466 CVEs with 30,987 patches across seven programming languages, demonstrate the superiority of MULVULN over thirteen effective and state-of-the-art baselines. Notably, MULVULN achieves substantially higher F1-score, with improvements ranging from 1.45% to 23.59% compared to the baseline methods.</li>
</ul>

<h3>Title: SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations</h3>
<ul>
<li><strong>Authors: </strong>Buyun Liang, Liangzu Peng, Jinqi Luo, Darshan Thaker, Kwan Ho Ryan Chan, René Vidal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04398">https://arxiv.org/abs/2510.04398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04398">https://arxiv.org/pdf/2510.04398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04398]] SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations(https://arxiv.org/abs/2510.04398)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in high-risk domains. However, state-of-the-art LLMs often produce hallucinations, raising serious concerns about their reliability. Prior work has explored adversarial attacks for hallucination elicitation in LLMs, but it often produces unrealistic prompts, either by inserting gibberish tokens or by altering the original meaning. As a result, these approaches offer limited insight into how hallucinations may occur in practice. While adversarial attacks in computer vision often involve realistic modifications to input images, the problem of finding realistic adversarial prompts for eliciting LLM hallucinations has remained largely underexplored. To address this gap, we propose Semantically Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic modifications to the prompt that preserve its meaning while maintaining semantic coherence. Our contributions are threefold: (i) we formulate finding realistic attacks for hallucination elicitation as a constrained optimization problem over the input prompt space under semantic equivalence and coherence constraints; (ii) we introduce a constraint-preserving zeroth-order method to effectively search for adversarial yet feasible prompts; and (iii) we demonstrate through experiments on open-ended multiple-choice question answering tasks that SECA achieves higher attack success rates while incurring almost no constraint violations compared to existing methods. SECA highlights the sensitivity of both open-source and commercial gradient-inaccessible LLMs to realistic and plausible prompt variations. Code is available at this https URL.</li>
</ul>

<h3>Title: Large Language Models Preserve Semantic Isotopies in Story Continuations</h3>
<ul>
<li><strong>Authors: </strong>Marc Cavazza</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04400">https://arxiv.org/abs/2510.04400</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04400">https://arxiv.org/pdf/2510.04400</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04400]] Large Language Models Preserve Semantic Isotopies in Story Continuations(https://arxiv.org/abs/2510.04400)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we explore the relevance of textual semantics to Large Language Models (LLMs), extending previous insights into the connection between distributional semantics and structural semantics. We investigate whether LLM-generated texts preserve semantic isotopies. We design a story continuation experiment using 10,000 ROCStories prompts completed by five LLMs. We first validate GPT-4o's ability to extract isotopies from a linguistic benchmark, then apply it to the generated stories. We then analyze structural (coverage, density, spread) and semantic properties of isotopies to assess how they are affected by completion. Results show that LLM completion within a given token horizon preserves semantic isotopies across multiple properties.</li>
</ul>

<h3>Title: CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Venkata Bharath Reddy Reddem, Akshay P Sarashetti, Ranjith Merugu, Amit Satish Unde</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04410">https://arxiv.org/abs/2510.04410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04410">https://arxiv.org/pdf/2510.04410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04410]] CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning(https://arxiv.org/abs/2510.04410)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Blind face restoration (BFR) has attracted increasing attention with the rise of generative methods. Most existing approaches integrate generative priors into the restoration pro- cess, aiming to jointly address facial detail generation and identity preservation. However, these methods often suffer from a trade-off between visual quality and identity fidelity, leading to either identity distortion or suboptimal degradation removal. In this paper, we present CodeFormer++, a novel framework that maximizes the utility of generative priors for high-quality face restoration while preserving identity. We decompose BFR into three sub-tasks: (i) identity- preserving face restoration, (ii) high-quality face generation, and (iii) dynamic fusion of identity features with realistic texture details. Our method makes three key contributions: (1) a learning-based deformable face registration module that semantically aligns generated and restored faces; (2) a texture guided restoration network to dynamically extract and transfer the texture of generated face to boost the quality of identity-preserving restored face; and (3) the integration of deep metric learning for BFR with the generation of informative positive and hard negative samples to better fuse identity- preserving and generative features. Extensive experiments on real-world and synthetic datasets demonstrate that, the pro- posed CodeFormer++ achieves superior performance in terms of both visual fidelity and identity consistency.</li>
</ul>

<h3>Title: Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions</h3>
<ul>
<li><strong>Authors: </strong>Wenyuan Zhao, Adithya Balachandran, Chao Tian, Paul Pu Liang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04417">https://arxiv.org/abs/2510.04417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04417">https://arxiv.org/pdf/2510.04417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04417]] Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions(https://arxiv.org/abs/2510.04417)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The study of multimodality has garnered significant interest in fields where the analysis of interactions among multiple information sources can enhance predictive modeling, data fusion, and interpretability. Partial information decomposition (PID) has emerged as a useful information-theoretic framework to quantify the degree to which individual modalities independently, redundantly, or synergistically convey information about a target variable. However, existing PID methods depend on optimizing over a joint distribution constrained by estimated pairwise probability distributions, which are costly and inaccurate for continuous and high-dimensional modalities. Our first key insight is that the problem can be solved efficiently when the pairwise distributions are multivariate Gaussians, and we refer to this problem as Gaussian PID (GPID). We propose a new gradient-based algorithm that substantially improves the computational efficiency of GPID based on an alternative formulation of the underlying optimization problem. To generalize the applicability to non-Gaussian data, we learn information-preserving encoders to transform random variables of arbitrary input distributions into pairwise Gaussian random variables. Along the way, we resolved an open problem regarding the optimality of joint Gaussian solutions for GPID. Empirical validation in diverse synthetic examples demonstrates that our proposed method provides more accurate and efficient PID estimates than existing baselines. We further evaluate a series of large-scale multimodal benchmarks to show its utility in real-world applications of quantifying PID in multimodal datasets and selecting high-performing models.</li>
</ul>

<h3>Title: Trade-off in Estimating the Number of Byzantine Clients in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Chen, Su Zhang, Heng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04432">https://arxiv.org/abs/2510.04432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04432">https://arxiv.org/pdf/2510.04432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04432]] Trade-off in Estimating the Number of Byzantine Clients in Federated Learning(https://arxiv.org/abs/2510.04432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning has attracted increasing attention at recent large-scale optimization and machine learning research and applications, but is also vulnerable to Byzantine clients that can send any erroneous signals. Robust aggregators are commonly used to resist Byzantine clients. This usually requires to estimate the unknown number $f$ of Byzantine clients, and thus accordingly select the aggregators with proper degree of robustness (i.e., the maximum number $\hat{f}$ of Byzantine clients allowed by the aggregator). Such an estimation should have important effect on the performance, which has not been systematically studied to our knowledge. This work will fill in the gap by theoretically analyzing the worst-case error of aggregators as well as its induced federated learning algorithm for any cases of $\hat{f}$ and $f$. Specifically, we will show that underestimation ($\hat{f}<f$) can lead to arbitrarily poor performance for both aggregators and federated learning. For non-underestimation ($\hat{f}\ge f$), we have proved optimal lower and upper bounds of the same order on the errors of both aggregators and federated learning. All these optimal bounds are proportional to $\hat{f}/(n-f-\hat{f})$ with $n$ clients, which monotonically increases with larger $\hat{f}$. This indicates a fundamental trade-off: while an aggregator with a larger robustness degree $\hat{f}$ can solve federated learning problems of wider range $f\in [0,\hat{f}]$, the performance can deteriorate when there are actually fewer or even no Byzantine clients (i.e., $f\in [0,\hat{f})$).</li>
</ul>

<h3>Title: On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Lucie Kunitomo-Jacquin, Edison Marrese-Taylor, Ken Fukuda</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04439">https://arxiv.org/abs/2510.04439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04439">https://arxiv.org/pdf/2510.04439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04439]] On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs(https://arxiv.org/abs/2510.04439)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Quantifying uncertainty in large language models (LLMs) is important for safety-critical applications because it helps spot incorrect answers, known as hallucinations. One major trend of uncertainty quantification methods is based on estimating the entropy of the distribution of the LLM's potential output sequences. This estimation is based on a set of output sequences and associated probabilities obtained by querying the LLM several times. In this paper, we advocate and experimentally show that the probability of unobserved sequences plays a crucial role, and we recommend future research to integrate it to enhance such LLM uncertainty quantification methods.</li>
</ul>

<h3>Title: Fractional Heat Kernel for Semi-Supervised Graph Learning with Small Training Sample Size</h3>
<ul>
<li><strong>Authors: </strong>Farid Bozorgnia, Vyacheslav Kungurtsev, Shirali Kadyrov, Mohsen Yousefnezhad</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04440">https://arxiv.org/abs/2510.04440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04440">https://arxiv.org/pdf/2510.04440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04440]] Fractional Heat Kernel for Semi-Supervised Graph Learning with Small Training Sample Size(https://arxiv.org/abs/2510.04440)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In this work, we introduce novel algorithms for label propagation and self-training using fractional heat kernel dynamics with a source term. We motivate the methodology through the classical correspondence of information theory with the physics of parabolic evolution equations. We integrate the fractional heat kernel into Graph Neural Network architectures such as Graph Convolutional Networks and Graph Attention, enhancing their expressiveness through adaptive, multi-hop diffusion. By applying Chebyshev polynomial approximations, large graphs become computationally feasible. Motivating variational formulations demonstrate that by extending the classical diffusion model to fractional powers of the Laplacian, nonlocal interactions deliver more globally diffusing labels. The particular balance between supervision of known labels and diffusion across the graph is particularly advantageous in the case where only a small number of labeled training examples are present. We demonstrate the effectiveness of this approach on standard datasets.</li>
</ul>

<h3>Title: REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization</h3>
<ul>
<li><strong>Authors: </strong>Qiyuan He, Yicong Li, Haotian Ye, Jinghao Wang, Xinyao Liao, Pheng-Ann Heng, Stefano Ermon, James Zou, Angela Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04450">https://arxiv.org/abs/2510.04450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04450">https://arxiv.org/pdf/2510.04450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04450]] REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization(https://arxiv.org/abs/2510.04450)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Visual autoregressive (AR) generation offers a promising path toward unifying vision and language models, yet its performance remains suboptimal against diffusion models. Prior work often attributes this gap to tokenizer limitations and rasterization ordering. In this work, we identify a core bottleneck from the perspective of generator-tokenizer inconsistency, i.e., the AR-generated tokens may not be well-decoded by the tokenizer. To address this, we propose reAR, a simple training strategy introducing a token-wise regularization objective: when predicting the next token, the causal transformer is also trained to recover the visual embedding of the current token and predict the embedding of the target token under a noisy context. It requires no changes to the tokenizer, generation order, inference pipeline, or external models. Despite its simplicity, reAR substantially improves performance. On ImageNet, it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard rasterization-based tokenizer. When applied to advanced tokenizers, it achieves a gFID of 1.42 with only 177M parameters, matching the performance with larger state-of-the-art diffusion models (675M).</li>
</ul>

<h3>Title: Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners</h3>
<ul>
<li><strong>Authors: </strong>Xiangchi Yuan, Xiang Chen, Tong Yu, Dachuan Shi, Can Jin, Wenke Lee, Saayan Mitra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04454">https://arxiv.org/abs/2510.04454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04454">https://arxiv.org/pdf/2510.04454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04454]] Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners(https://arxiv.org/abs/2510.04454)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) show strong reasoning abilities, often amplified by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although RL algorithms can substantially improve reasoning, they struggle to expand reasoning boundaries because they learn from their own reasoning trajectories rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers complementary benefits but typically requires large-scale data and risks overfitting. Recent attempts to combine SFT and RL face three main challenges: data inefficiency, algorithm-specific designs, and catastrophic forgetting. We propose a plug-and-play framework that dynamically integrates SFT into RL by selecting challenging examples for SFT. This approach reduces SFT data requirements and remains agnostic to the choice of RL or SFT algorithm. To mitigate catastrophic forgetting of RL-acquired skills during SFT, we select high-entropy tokens for loss calculation and freeze parameters identified as critical for RL. Our method achieves state-of-the-art (SoTA) reasoning performance using only 1.5% of the SFT data and 20.4% of the RL data used by prior SoTA, providing an efficient and plug-and-play solution for combining SFT and RL in reasoning post-training.</li>
</ul>

<h3>Title: Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space</h3>
<ul>
<li><strong>Authors: </strong>Tomas Figliolia, Nicholas Alonso, Rishi Iyer, Quentin Anthony, Beren Millidge</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04476">https://arxiv.org/abs/2510.04476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04476">https://arxiv.org/pdf/2510.04476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04476]] Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space(https://arxiv.org/abs/2510.04476)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Multi-headed Attention's (MHA) quadratic compute and linearly growing KV-cache make long-context transformers expensive to train and serve. Prior works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA) shrink the cache, speeding decode, but leave compute, which determines prefill and training speed, largely unchanged. We introduce Compressed Convolutional Attention (CCA), a novel attention method which down-projects queries, keys, and values and performs the entire attention operation inside the shared latent space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all at once by the desired compression factor. Because CCA is orthogonal to head-sharing, we combine the two to form Compressed Convolutional Grouped Query Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier so that users can tune compression toward either FLOP or memory limits without sacrificing quality. Experiments show that CCGQA consistently outperforms both GQA and MLA at equal KV-cache compression on dense and MoE models. Additionally, we show that CCGQA outperforms all other attention methods on MoE models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache compression with no drop in performance compared to standard MHA. CCA and CCGQA also dramatically reduce the FLOP cost of attention which leads to substantially faster training and prefill than existing methods. On H100 GPUs, our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence length of 16k relative to MHA, and accelerates backward by about 1.3x.</li>
</ul>

<h3>Title: MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04477">https://arxiv.org/abs/2510.04477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04477">https://arxiv.org/pdf/2510.04477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04477]] MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models(https://arxiv.org/abs/2510.04477)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Bridging clinical diagnostic reasoning with AI remains a central challenge in medical imaging. We introduce MedCLM, an automated pipeline that converts detection datasets into large-scale medical visual question answering (VQA) data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ segmentation and structured rationales. These contextual signals enable medical vision-language models to generate question-answer pairs with step-by-step reasoning. To utilize this data effectively, we propose an Integrated CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes for visual grounding, a Medium stage that encourages implicit localization, and a Hard stage for weakly supervised reasoning. Experimental results demonstrate that MedCLM attains state-of-the-art performance on several medical VQA benchmarks, providing a scalable framework for developing clinically aligned medical vision-language models.</li>
</ul>

<h3>Title: Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness</h3>
<ul>
<li><strong>Authors: </strong>Amin Banayeeanzade, Ala N. Tak, Fatemeh Bahrani, Anahita Bolourani, Leonardo Blas, Emilio Ferrara, Jonathan Gratch, Sai Praneeth Karimireddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04484">https://arxiv.org/abs/2510.04484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04484">https://arxiv.org/pdf/2510.04484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04484]] Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness(https://arxiv.org/abs/2510.04484)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, fair, interpretability</a></li>
<li><strong>Abstract: </strong>The ability to control LLMs' emulated emotional states and personality traits is essential for enabling rich, human-centered interactions in socially interactive settings. We introduce PsySET, a Psychologically-informed benchmark to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion and personality domains. Our study spans four models from different LLM families paired with various steering strategies, including prompting, fine-tuning, and representation engineering. Our results indicate that prompting is consistently effective but limited in intensity control, whereas vector injections achieve finer controllability while slightly reducing output quality. Moreover, we explore the trustworthiness of steered LLMs by assessing safety, truthfulness, fairness, and ethics, highlighting potential side effects and behavioral shifts. Notably, we observe idiosyncratic effects; for instance, even a positive emotion like joy can degrade robustness to adversarial factuality, lower privacy awareness, and increase preferential bias. Meanwhile, anger predictably elevates toxicity yet strengthens leakage resistance. Our framework establishes the first holistic evaluation of emotion and personality steering, offering insights into its interpretability and reliability for socially interactive applications.</li>
</ul>

<h3>Title: Forking-Sequences</h3>
<ul>
<li><strong>Authors: </strong>Willa Potosnak, Malcolm Wolff, Boris Oreshkin, Mengfei Cao, Michael W. Mahoney, Dmitry Efimov, Kin G. Olivares</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04487">https://arxiv.org/abs/2510.04487</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04487">https://arxiv.org/pdf/2510.04487</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04487]] Forking-Sequences(https://arxiv.org/abs/2510.04487)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>While accuracy is a critical requirement for time series forecasting models, an equally important (yet often overlooked) desideratum is forecast stability across forecast creation dates (FCDs). Even highly accurate models can produce erratic revisions between FCDs, undermining stakeholder trust and disrupting downstream decision-making. To improve forecast stability, models like MQCNN, MQT, and SPADE employ a little-known but highly effective technique: forking-sequences. Unlike standard statistical and neural forecasting methods that treat each FCD independently, the forking-sequences method jointly encodes and decodes the entire time series across all FCDs, in a way mirroring time series cross-validation. Since forking sequences remains largely unknown in the broader neural forecasting community, in this work, we formalize the forking-sequences approach, and we make a case for its broader adoption. We demonstrate three key benefits of forking-sequences: (i) more stable and consistent gradient updates during training; (ii) reduced forecast variance through ensembling; and (iii) improved inference computational efficiency. We validate forking-sequences' benefits using 16 datasets from the M1, M3, M4, and Tourism competitions, showing improvements in forecast percentage change stability of 28.8%, 28.8%, 37.9%, and 31.3%, and 8.8%, on average, for MLP, RNN, LSTM, CNN, and Transformer-based architectures, respectively.</li>
</ul>

<h3>Title: GenQuest: An LLM-based Text Adventure Game for Language Learners</h3>
<ul>
<li><strong>Authors: </strong>Qiao Wang, Adnan Labib, Robert Swier, Michael Hofmeyr, Zheng Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04498">https://arxiv.org/abs/2510.04498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04498">https://arxiv.org/pdf/2510.04498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04498]] GenQuest: An LLM-based Text Adventure Game for Language Learners(https://arxiv.org/abs/2510.04498)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>GenQuest is a generative text adventure game that leverages Large Language Models (LLMs) to facilitate second language learning through immersive, interactive storytelling. The system engages English as a Foreign Language (EFL) learners in a collaborative "choose-your-own-adventure" style narrative, dynamically generated in response to learner choices. Game mechanics such as branching decision points and story milestones are incorporated to maintain narrative coherence while allowing learner-driven plot development. Key pedagogical features include content generation tailored to each learner's proficiency level, and a vocabulary assistant that provides in-context explanations of learner-queried text strings, ranging from words and phrases to sentences. Findings from a pilot study with university EFL students in China indicate promising vocabulary gains and positive user perceptions. Also discussed are suggestions from participants regarding the narrative length and quality, and the request for multi-modal content such as illustrations.</li>
</ul>

<h3>Title: Expand Neurons, Not Parameters</h3>
<ul>
<li><strong>Authors: </strong>Linghao Kong, Inimai Subramanian, Yonadav Shavit, Micah Adler, Dan Alistarh, Nir Shavit</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04500">https://arxiv.org/abs/2510.04500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04500">https://arxiv.org/pdf/2510.04500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04500]] Expand Neurons, Not Parameters(https://arxiv.org/abs/2510.04500)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This work demonstrates how increasing the number of neurons in a network without increasing its number of non-zero parameters improves performance. We show that this gain corresponds with a decrease in interference between multiple features that would otherwise share the same neurons. To reduce such entanglement at a fixed non-zero parameter count, we introduce Fixed Parameter Expansion (FPE): replace a neuron with multiple children and partition the parent's weights disjointly across them, so that each child inherits a non-overlapping subset of connections. On symbolic tasks, specifically Boolean code problems, clause-aligned FPE systematically reduces polysemanticity metrics and yields higher task accuracy. Notably, random splits of neuron weights approximate these gains, indicating that reduced collisions, not precise assignment, are a primary driver. Consistent with the superposition hypothesis, the benefits of FPE grow with increasing interference: when polysemantic load is high, accuracy improvements are the largest. Transferring these insights to real models (classifiers over CLIP embeddings and deeper multilayer networks) we find that widening networks while maintaining a constant non-zero parameter count consistently increases accuracy. These results identify an interpretability-grounded mechanism to leverage width against superposition, improving performance without increasing the number of non-zero parameters. Such a direction is well matched to modern accelerators, where memory movement of non-zero parameters, rather than raw compute, is the dominant bottleneck.</li>
</ul>

<h3>Title: P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shuai Zhao, Xinyi Wu, Shiqian Zhao, Xiaobao Wu, Zhongliang Guo, Yanhao Jia, Anh Tuan Luu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04503">https://arxiv.org/abs/2510.04503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04503">https://arxiv.org/pdf/2510.04503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04503]] P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs(https://arxiv.org/abs/2510.04503)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>During fine-tuning, large language models (LLMs) are increasingly vulnerable to data-poisoning backdoor attacks, which compromise their reliability and trustworthiness. However, existing defense strategies suffer from limited generalization: they only work on specific attack types or task settings. In this study, we propose Poison-to-Poison (P2P), a general and effective backdoor defense algorithm. P2P injects benign triggers with safe alternative labels into a subset of training samples and fine-tunes the model on this re-poisoned dataset by leveraging prompt-based learning. This enforces the model to associate trigger-induced representations with safe outputs, thereby overriding the effects of original malicious triggers. Thanks to this robust and generalizable trigger-based fine-tuning, P2P is effective across task settings and attack types. Theoretically and empirically, we show that P2P can neutralize malicious backdoors while preserving task performance. We conduct extensive experiments on classification, mathematical reasoning, and summary generation tasks, involving multiple state-of-the-art LLMs. The results demonstrate that our P2P algorithm significantly reduces the attack success rate compared with baseline models. We hope that the P2P can serve as a guideline for defending against backdoor attacks and foster the development of a secure and trustworthy LLM community.</li>
</ul>

<h3>Title: Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Zijing Hu, Yunze Tong, Fengda Zhang, Junkun Yuan, Jun Xiao, Kun Kuang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04504">https://arxiv.org/abs/2510.04504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04504">https://arxiv.org/pdf/2510.04504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04504]] Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation(https://arxiv.org/abs/2510.04504)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have achieved impressive results in generating high-quality images. Yet, they often struggle to faithfully align the generated images with the input prompts. This limitation arises from synchronous denoising, where all pixels simultaneously evolve from random noise to clear images. As a result, during generation, the prompt-related regions can only reference the unrelated regions at the same noise level, failing to obtain clear context and ultimately impairing text-to-image alignment. To address this issue, we propose asynchronous diffusion models -- a novel framework that allocates distinct timesteps to different pixels and reformulates the pixel-wise denoising process. By dynamically modulating the timestep schedules of individual pixels, prompt-related regions are denoised more gradually than unrelated regions, thereby allowing them to leverage clearer inter-pixel context. Consequently, these prompt-related regions achieve better alignment in the final images. Extensive experiments demonstrate that our asynchronous diffusion models can significantly improve text-to-image alignment across diverse prompts. The code repository for this work is available at this https URL.</li>
</ul>

<h3>Title: GRACE: Generative Representation Learning via Contrastive Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jiashuo Sun, Shixuan Liu, Zhaochen Su, Xianrui Zhong, Pengcheng Jiang, Bowen Jin, Peiran Li, Weijia Shi, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04506">https://arxiv.org/abs/2510.04506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04506">https://arxiv.org/pdf/2510.04506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04506]] GRACE: Generative Representation Learning via Contrastive Policy Optimization(https://arxiv.org/abs/2510.04506)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Prevailing methods for training Large Language Models (LLMs) as text encoders rely on contrastive losses that treat the model as a black box function, discarding its generative and reasoning capabilities in favor of static embeddings. We introduce GRACE (Generative Representation Learning via Contrastive Policy Optimization), a novel framework that reimagines contrastive signals not as losses to be minimized, but as rewards that guide a generative policy. In GRACE, the LLM acts as a policy that produces explicit, human-interpretable rationales--structured natural language explanations of its semantic understanding. These rationales are then encoded into high-quality embeddings via mean pooling. Using policy gradient optimization, we train the model with a multi-component reward function that maximizes similarity between query positive pairs and minimizes similarity with negatives. This transforms the LLM from an opaque encoder into an interpretable agent whose reasoning process is transparent and inspectable. On MTEB benchmark, GRACE yields broad cross category gains: averaged over four backbones, the supervised setting improves overall score by 11.5% over base models, and the unsupervised variant adds 6.9%, while preserving general capabilities. This work treats contrastive objectives as rewards over rationales, unifying representation learning with generation to produce stronger embeddings and transparent rationales. The model, data and code are available at this https URL.</li>
</ul>

<h3>Title: Toward a Unified Geometry Understanding: Riemannian Diffusion Framework for Graph Generation and Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yisen Gao, Xingcheng Fu, Qingyun Sun, Jianxin Li, Xianxian Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04522">https://arxiv.org/abs/2510.04522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04522">https://arxiv.org/pdf/2510.04522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04522]] Toward a Unified Geometry Understanding: Riemannian Diffusion Framework for Graph Generation and Prediction(https://arxiv.org/abs/2510.04522)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Graph diffusion models have made significant progress in learning structured graph data and have demonstrated strong potential for predictive tasks. Existing approaches typically embed node, edge, and graph-level features into a unified latent space, modeling prediction tasks including classification and regression as a form of conditional generation. However, due to the non-Euclidean nature of graph data, features of different curvatures are entangled in the same latent space without releasing their geometric potential. To address this issue, we aim to construt an ideal Riemannian diffusion model to capture distinct manifold signatures of complex graph data and learn their distribution. This goal faces two challenges: numerical instability caused by exponential mapping during the encoding proces and manifold deviation during diffusion generation. To address these challenges, we propose GeoMancer: a novel Riemannian graph diffusion framework for both generation and prediction tasks. To mitigate numerical instability, we replace exponential mapping with an isometric-invariant Riemannian gyrokernel approach and decouple multi-level features onto their respective task-specific manifolds to learn optimal representations. To address manifold deviation, we introduce a manifold-constrained diffusion method and a self-guided strategy for unconditional generation, ensuring that the generated data remains aligned with the manifold signature. Extensive experiments validate the effectiveness of our approach, demonstrating superior performance across a variety of tasks.</li>
</ul>

<h3>Title: Demystifying MaskGIT Sampler and Beyond: Adaptive Order Selection in Masked Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Satoshi Hayakawa, Yuhta Takida, Masaaki Imaizumi, Hiromi Wakaki, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.LG, math.PR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04525">https://arxiv.org/abs/2510.04525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04525">https://arxiv.org/pdf/2510.04525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04525]] Demystifying MaskGIT Sampler and Beyond: Adaptive Order Selection in Masked Diffusion(https://arxiv.org/abs/2510.04525)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Masked diffusion models have shown promising performance in generating high-quality samples in a wide range of domains, but accelerating their sampling process remains relatively underexplored. To investigate efficient samplers for masked diffusion, this paper theoretically analyzes the MaskGIT sampler for image modeling, revealing its implicit temperature sampling mechanism. Through this analysis, we introduce the "moment sampler," an asymptotically equivalent but more tractable and interpretable alternative to MaskGIT, which employs a "choose-then-sample" approach by selecting unmasking positions before sampling tokens. In addition, we improve the efficiency of choose-then-sample algorithms through two key innovations: a partial caching technique for transformers that approximates longer sampling trajectories without proportional computational cost, and a hybrid approach formalizing the exploration-exploitation trade-off in adaptive unmasking. Experiments in image and text domains demonstrate our theory as well as the efficiency of our proposed methods, advancing both theoretical understanding and practical implementation of masked diffusion samplers.</li>
</ul>

<h3>Title: Unified Threat Detection and Mitigation Framework (UTDMF): Combating Prompt Injection, Deception, and Bias in Enterprise-Scale Transformers</h3>
<ul>
<li><strong>Authors: </strong>Santhosh KumarRavindran</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04528">https://arxiv.org/abs/2510.04528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04528">https://arxiv.org/pdf/2510.04528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04528]] Unified Threat Detection and Mitigation Framework (UTDMF): Combating Prompt Injection, Deception, and Bias in Enterprise-Scale Transformers(https://arxiv.org/abs/2510.04528)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, fair, transformer, large language model</a></li>
<li><strong>Abstract: </strong>The rapid adoption of large language models (LLMs) in enterprise systems exposes vulnerabilities to prompt injection attacks, strategic deception, and biased outputs, threatening security, trust, and fairness. Extending our adversarial activation patching framework (arXiv:2507.09406), which induced deception in toy networks at a 23.9% rate, we introduce the Unified Threat Detection and Mitigation Framework (UTDMF), a scalable, real-time pipeline for enterprise-grade models like Llama-3.1 (405B), GPT-4o, and Claude-3.5. Through 700+ experiments per model, UTDMF achieves: (1) 92% detection accuracy for prompt injection (e.g., jailbreaking); (2) 65% reduction in deceptive outputs via enhanced patching; and (3) 78% improvement in fairness metrics (e.g., demographic bias). Novel contributions include a generalized patching algorithm for multi-threat detection, three groundbreaking hypotheses on threat interactions (e.g., threat chaining in enterprise workflows), and a deployment-ready toolkit with APIs for enterprise integration.</li>
</ul>

<h3>Title: Computational Certified Deletion Property of Magic Square Game and its Application to Classical Secure Key Leasing</h3>
<ul>
<li><strong>Authors: </strong>Yuki Takeuchi, Duo Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04529">https://arxiv.org/abs/2510.04529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04529">https://arxiv.org/pdf/2510.04529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04529]] Computational Certified Deletion Property of Magic Square Game and its Application to Classical Secure Key Leasing(https://arxiv.org/abs/2510.04529)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>We present the first construction of a computational Certified Deletion Property (CDP) achievable with classical communication, derived from the compilation of the non-local Magic Square Game (MSG). We leverage the KLVY compiler to transform the non-local MSG into a 2-round interactive protocol, rigorously demonstrating that this compilation preserves the game-specific CDP. Previously, the quantum value and rigidity of the compiled game were investigated. We emphasize that we are the first to investigate CDP (local randomness in [Fu and Miller, Phys. Rev. A 97, 032324 (2018)]) for the compiled game. Then, we combine this CDP with the framework [Kitagawa, Morimae, and Yamakawa, Eurocrypt 2025] to construct Secure Key Leasing with classical Lessor (cSKL). SKL enables the Lessor to lease the secret key to the Lessee and verify that a quantum Lessee has indeed deleted the key. In this paper, we realize cSKL for PKE, PRF, and digital signature. Compared to prior works for cSKL, we realize cSKL for PRF and digital signature for the first time. In addition, we succeed in weakening the assumption needed to construct cSKL.</li>
</ul>

<h3>Title: TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling</h3>
<ul>
<li><strong>Authors: </strong>Hyunmin Cho, Donghoon Ahn, Susung Hong, Jee Eun Kim, Seungryong Kim, Kyong Hwan Jin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04533">https://arxiv.org/abs/2510.04533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04533">https://arxiv.org/pdf/2510.04533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04533]] TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling(https://arxiv.org/abs/2510.04533)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent diffusion models achieve the state-of-the-art performance in image generation, but often suffer from semantic inconsistencies or hallucinations. While various inference-time guidance methods can enhance generation, they often operate indirectly by relying on external signals or architectural modifications, which introduces additional computational overhead. In this paper, we propose Tangential Amplifying Guidance (TAG), a more efficient and direct guidance method that operates solely on trajectory signals without modifying the underlying diffusion model. TAG leverages an intermediate sample as a projection basis and amplifies the tangential components of the estimated scores with respect to this basis to correct the sampling trajectory. We formalize this guidance process by leveraging a first-order Taylor expansion, which demonstrates that amplifying the tangential component steers the state toward higher-probability regions, thereby reducing inconsistencies and enhancing sample quality. TAG is a plug-and-play, architecture-agnostic module that improves diffusion sampling fidelity with minimal computational addition, offering a new perspective on diffusion guidance.</li>
</ul>

<h3>Title: Post-training quantization of vision encoders needs prefixing registers</h3>
<ul>
<li><strong>Authors: </strong>Seunghyeon Kim, Jinho Kim, Taesun Yeom, Wonpyo Park, Kyuyeun Kim, Jaeho Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04547">https://arxiv.org/abs/2510.04547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04547">https://arxiv.org/pdf/2510.04547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04547]] Post-training quantization of vision encoders needs prefixing registers(https://arxiv.org/abs/2510.04547)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based vision encoders -- such as CLIP -- are central to multimodal intelligence, powering applications from autonomous web agents to robotic control. Since these applications often demand real-time processing of massive visual data, reducing the inference cost of vision encoders is critical. Post-training quantization offers a practical path, but remains challenging even at 8-bit precision due to massive-scale activations (i.e., outliers). In this work, we propose $\textit{RegCache}$, a training-free algorithm to mitigate outliers in vision encoders, enabling quantization with significantly smaller accuracy drops. The proposed RegCache introduces outlier-prone yet semantically meaningless prefix tokens to the target vision encoder, which prevents other tokens from having outliers. Notably, we observe that outliers in vision encoders behave differently from those in language models, motivating two technical innovations: middle-layer prefixing and token deletion. Experiments show that our method consistently improves the accuracy of quantized models across both text-supervised and self-supervised vision encoders.</li>
</ul>

<h3>Title: Tail-Safe Hedging: Explainable Risk-Sensitive Reinforcement Learning with a White-Box CBF--QP Safety Layer in Arbitrage-Free Markets</h3>
<ul>
<li><strong>Authors: </strong>Jian'an Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.TR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04555">https://arxiv.org/abs/2510.04555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04555">https://arxiv.org/pdf/2510.04555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04555]] Tail-Safe Hedging: Explainable Risk-Sensitive Reinforcement Learning with a White-Box CBF--QP Safety Layer in Arbitrage-Free Markets(https://arxiv.org/abs/2510.04555)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>We introduce Tail-Safe, a deployability-oriented framework for derivatives hedging that unifies distributional, risk-sensitive reinforcement learning with a white-box control-barrier-function (CBF) quadratic-program (QP) safety layer tailored to financial constraints. The learning component combines an IQN-based distributional critic with a CVaR objective (IQN--CVaR--PPO) and a Tail-Coverage Controller that regulates quantile sampling through temperature tilting and tail boosting to stabilize small-$\alpha$ estimation. The safety component enforces discrete-time CBF inequalities together with domain-specific constraints -- ellipsoidal no-trade bands, box and rate limits, and a sign-consistency gate -- solved as a convex QP whose telemetry (active sets, tightness, rate utilization, gate scores, slack, and solver status) forms an auditable trail for governance. We provide guarantees of robust forward invariance of the safe set under bounded model mismatch, a minimal-deviation projection interpretation of the QP, a KL-to-DRO upper bound linking per-state KL regularization to worst-case CVaR, concentration and sample-complexity results for the temperature-tilted CVaR estimator, and a CVaR trust-region improvement inequality under KL limits, together with feasibility persistence under expiry-aware tightening. Empirically, in arbitrage-free, microstructure-aware synthetic markets (SSVI $\to$ Dupire $\to$ VIX with ABIDES/MockLOB execution), Tail-Safe improves left-tail risk without degrading central performance and yields zero hard-constraint violations whenever the QP is feasible with zero slack. Telemetry is mapped to governance dashboards and incident workflows to support explainability and auditability. Limitations include reliance on synthetic data and simplified execution to isolate methodological contributions.</li>
</ul>

<h3>Title: Stochastic Approximation Methods for Distortion Risk Measure Optimization</h3>
<ul>
<li><strong>Authors: </strong>Jinyang Jiang, Bernd Heidergott, Jiaqiao Hu, Yijie Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04563">https://arxiv.org/abs/2510.04563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04563">https://arxiv.org/pdf/2510.04563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04563]] Stochastic Approximation Methods for Distortion Risk Measure Optimization(https://arxiv.org/abs/2510.04563)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Distortion Risk Measures (DRMs) capture risk preferences in decision-making and serve as general criteria for managing uncertainty. This paper proposes gradient descent algorithms for DRM optimization based on two dual representations: the Distortion-Measure (DM) form and Quantile-Function (QF) form. The DM-form employs a three-timescale algorithm to track quantiles, compute their gradients, and update decision variables, utilizing the Generalized Likelihood Ratio and kernel-based density estimation. The QF-form provides a simpler two-timescale approach that avoids the need for complex quantile gradient estimation. A hybrid form integrates both approaches, applying the DM-form for robust performance around distortion function jumps and the QF-form for efficiency in smooth regions. Proofs of strong convergence and convergence rates for the proposed algorithms are provided. In particular, the DM-form achieves an optimal rate of $O(k^{-4/7})$, while the QF-form attains a faster rate of $O(k^{-2/3})$. Numerical experiments confirm their effectiveness and demonstrate substantial improvements over baselines in robust portfolio selection tasks. The method's scalability is further illustrated through integration into deep reinforcement learning. Specifically, a DRM-based Proximal Policy Optimization algorithm is developed and applied to multi-echelon dynamic inventory management, showcasing its practical applicability.</li>
</ul>

<h3>Title: Conditional Representation Learning for Customized Tasks</h3>
<ul>
<li><strong>Authors: </strong>Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04564">https://arxiv.org/abs/2510.04564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04564">https://arxiv.org/pdf/2510.04564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04564]] Conditional Representation Learning for Customized Tasks(https://arxiv.org/abs/2510.04564)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Conventional representation learning methods learn a universal representation that primarily captures dominant semantics, which may not always align with customized downstream tasks. For instance, in animal habitat analysis, researchers prioritize scene-related features, whereas universal embeddings emphasize categorical semantics, leading to suboptimal results. As a solution, existing approaches resort to supervised fine-tuning, which however incurs high computational and annotation costs. In this paper, we propose Conditional Representation Learning (CRL), aiming to extract representations tailored to arbitrary user-specified criteria. Specifically, we reveal that the semantics of a space are determined by its basis, thereby enabling a set of descriptive words to approximate the basis for a customized feature space. Building upon this insight, given a user-specified criterion, CRL first employs a large language model (LLM) to generate descriptive texts to construct the semantic basis, then projects the image representation into this conditional feature space leveraging a vision-language model (VLM). The conditional representation better captures semantics for the specific criterion, which could be utilized for multiple customized tasks. Extensive experiments on classification and retrieval tasks demonstrate the superiority and generality of the proposed CRL. The code is available at this https URL.</li>
</ul>

<h3>Title: GILT: An LLM-Free, Tuning-Free Graph Foundational Model for In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Weishuo Ma, Yanbo Wang, Xiyuan Wang, Lei Zou, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04567">https://arxiv.org/abs/2510.04567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04567">https://arxiv.org/pdf/2510.04567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04567]] GILT: An LLM-Free, Tuning-Free Graph Foundational Model for In-Context Learning(https://arxiv.org/abs/2510.04567)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are powerful tools for precessing relational data but often struggle to generalize to unseen graphs, giving rise to the development of Graph Foundational Models (GFMs). However, current GFMs are challenged by the extreme heterogeneity of graph data, where each graph can possess a unique feature space, label set, and topology. To address this, two main paradigms have emerged. The first leverages Large Language Models (LLMs), but is fundamentally text-dependent, thus struggles to handle the numerical features in vast graphs. The second pre-trains a structure-based model, but the adaptation to new tasks typically requires a costly, per-graph tuning stage, creating a critical efficiency bottleneck. In this work, we move beyond these limitations and introduce \textbf{G}raph \textbf{I}n-context \textbf{L}earning \textbf{T}ransformer (GILT), a framework built on an LLM-free and tuning-free architecture. GILT introduces a novel token-based framework for in-context learning (ICL) on graphs, reframing classification tasks spanning node, edge and graph levels in a unified framework. This mechanism is the key to handling heterogeneity, as it is designed to operate on generic numerical features. Further, its ability to understand class semantics dynamically from the context enables tuning-free adaptation. Comprehensive experiments show that GILT achieves stronger few-shot performance with significantly less time than LLM-based or tuning-based baselines, validating the effectiveness of our approach.</li>
</ul>

<h3>Title: LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Nicklas Majamaki, Navdeep Jaitly, Yi-An Ma, Lianhui Qin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04573">https://arxiv.org/abs/2510.04573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04573">https://arxiv.org/pdf/2510.04573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04573]] LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning(https://arxiv.org/abs/2510.04573)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate their reasoning ability through chain-of-thought (CoT) generation. However, LLM's autoregressive decoding may limit the ability to revisit and refine earlier tokens in a holistic manner, which can also lead to inefficient exploration for diverse solutions. In this paper, we propose LaDiR (Latent Diffusion Reasoner), a novel reasoning framework that unifies the expressiveness of continuous latent representation with the iterative refinement capabilities of latent diffusion models for an existing LLM. We first construct a structured latent reasoning space using a Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of thought tokens, preserving semantic information and interpretability while offering compact but expressive representations. Subsequently, we utilize a latent diffusion model that learns to denoise a block of latent thought tokens with a blockwise bidirectional attention mask, enabling longer horizon and iterative refinement with adaptive test-time compute. This design allows efficient parallel generation of diverse reasoning trajectories, allowing the model to plan and revise the reasoning process holistically. We conduct evaluations on a suite of mathematical reasoning and planning benchmarks. Empirical results show that LaDiR consistently improves accuracy, diversity, and interpretability over existing autoregressive, diffusion-based, and latent reasoning methods, revealing a new paradigm for text reasoning with latent diffusion.</li>
</ul>

<h3>Title: SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator</h3>
<ul>
<li><strong>Authors: </strong>Yuhta Takida, Satoshi Hayakawa, Takashi Shibuya, Masaaki Imaizumi, Naoki Murata, Bac Nguyen, Toshimitsu Uesaka, Chieh-Hsin Lai, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04576">https://arxiv.org/abs/2510.04576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04576">https://arxiv.org/pdf/2510.04576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04576]] SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator(https://arxiv.org/abs/2510.04576)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Deep generative models have made significant advances in generating complex content, yet conditional generation remains a fundamental challenge. Existing conditional generative adversarial networks often struggle to balance the dual objectives of assessing authenticity and conditional alignment of input samples within their conditional discriminators. To address this, we propose a novel discriminator design that integrates three key capabilities: unconditional discrimination, matching-aware supervision to enhance alignment sensitivity, and adaptive weighting to dynamically balance all objectives. Specifically, we introduce Sum of Naturalness and Alignment (SONA), which employs separate projections for naturalness (authenticity) and alignment in the final layer with an inductive bias, supported by dedicated objective functions and an adaptive weighting mechanism. Extensive experiments on class-conditional generation tasks show that \ours achieves superior sample quality and conditional alignment compared to state-of-the-art methods. Furthermore, we demonstrate its effectiveness in text-to-image generation, confirming the versatility and robustness of our approach.</li>
</ul>

<h3>Title: Improved probabilistic regression using diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Carlo Kneissl, Christopher Bülte, Philipp Scholl, Gitta Kutyniok</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04583">https://arxiv.org/abs/2510.04583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04583">https://arxiv.org/pdf/2510.04583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04583]] Improved probabilistic regression using diffusion models(https://arxiv.org/abs/2510.04583)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Probabilistic regression models the entire predictive distribution of a response variable, offering richer insights than classical point estimates and directly allowing for uncertainty quantification. While diffusion-based generative models have shown remarkable success in generating complex, high-dimensional data, their usage in general regression tasks often lacks uncertainty-related evaluation and remains limited to domain-specific applications. We propose a novel diffusion-based framework for probabilistic regression that learns predictive distributions in a nonparametric way. More specifically, we propose to model the full distribution of the diffusion noise, enabling adaptation to diverse tasks and enhanced uncertainty quantification. We investigate different noise parameterizations, analyze their trade-offs, and evaluate our framework across a broad range of regression tasks, covering low- and high-dimensional settings. For several experiments, our approach shows superior performance against existing baselines, while delivering calibrated uncertainty estimates, demonstrating its versatility as a tool for probabilistic prediction.</li>
</ul>

<h3>Title: Robustness assessment of large audio language models in multiple-choice evaluation</h3>
<ul>
<li><strong>Authors: </strong>Fernando López, Santosh Kesiraju, Jordi Luque</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04584">https://arxiv.org/abs/2510.04584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04584">https://arxiv.org/pdf/2510.04584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04584]] Robustness assessment of large audio language models in multiple-choice evaluation(https://arxiv.org/abs/2510.04584)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in large audio language models (LALMs) have primarily been assessed using a multiple-choice question answering (MCQA) framework. However, subtle changes, such as shifting the order of choices, result in substantially different results. Existing MCQA frameworks do not account for this variability and report a single accuracy number per benchmark or category. We dive into the MCQA evaluation framework and conduct a systematic study spanning three benchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio Flamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings indicate that models are sensitive not only to the ordering of choices, but also to the paraphrasing of the question and the choices. Finally, we propose a simpler evaluation protocol and metric that account for subtle variations and provide a more detailed evaluation report of LALMs within the MCQA framework.</li>
</ul>

<h3>Title: Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior</h3>
<ul>
<li><strong>Authors: </strong>Sheng Wang, Ruiming Wu, Charles Herndon, Yihang Liu, Shunsuke Koga, Jeanne Shen, Zhi Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04587">https://arxiv.org/abs/2510.04587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04587">https://arxiv.org/pdf/2510.04587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04587]] Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior(https://arxiv.org/abs/2510.04587)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Diagnosing a whole-slide image is an interactive, multi-stage process involving changes in magnification and movement between fields. Although recent pathology foundation models are strong, practical agentic systems that decide what field to examine next, adjust magnification, and deliver explainable diagnoses are still lacking. The blocker is data: scalable, clinically aligned supervision of expert viewing behavior that is tacit and experience-based, not written in textbooks or online, and therefore absent from large language model training. We introduce the AI Session Recorder, which works with standard WSI viewers to unobtrusively record routine navigation and convert the viewer logs into standardized behavioral commands (inspect or peek at discrete magnifications) and bounding boxes. A lightweight human-in-the-loop review turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired "where to look" and "why it matters" supervision produced at roughly six times lower labeling time. Using this behavioral data, we build Pathologist-o3, a two-stage agent that first proposes regions of interest and then performs behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection, it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the state-of-the-art OpenAI o3 model and generalizing across backbones. To our knowledge, this constitutes one of the first behavior-grounded agentic systems in pathology. Turning everyday viewer logs into scalable, expert-validated supervision, our framework makes agentic pathology practical and establishes a path to human-aligned, upgradeable clinical AI.</li>
</ul>

<h3>Title: FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04601">https://arxiv.org/abs/2510.04601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04601">https://arxiv.org/pdf/2510.04601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04601]] FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning(https://arxiv.org/abs/2510.04601)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, large language model</a></li>
<li><strong>Abstract: </strong>The current paradigm of training large language models (LLMs) on publicly available Web data is becoming unsustainable, with high-quality data sources in specialized domains nearing exhaustion. Federated Learning (FL) emerges as a practical solution for the next generation of AI on a decentralized Web, enabling privacy-preserving collaborative fine-tuning by leveraging private data distributed across a global client base. While Low-Rank Adaptation (LoRA) is the standard for efficient fine-tuning, its application in federated settings presents a critical challenge: communication overhead remains a significant bottleneck across the Web's heterogeneous network conditions. The structural redundancy within LoRA parameters not only incurs a heavy communication burden but also introduces conflicts when aggregating client updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose framework designed for communication-efficient FL. We first introduce an importance-aware sparsification method that preserves the structural integrity of LoRA updates to reduce the uploaded parameter count. The server then reconstructs and aggregates these updates in a full-rank space to mitigate conflicts. Finally, it decomposes the global update into a sparse low-rank format for broadcast, ensuring a symmetrically efficient cycle. We also propose an efficient variant, FedSRD-e, to reduce computational overhead. Experimental results on 10 benchmarks demonstrate that our framework significantly reduces communication costs by up to 90\% while even improving model performance on heterogeneous client data.</li>
</ul>

<h3>Title: Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qizheng Zhang, Changran Hu, Shubhangi Upasani, Boyuan Ma, Fenglu Hong, Vamsidhar Kamanuru, Jay Rainton, Chen Wu, Mengmeng Ji, Hanchen Li, Urmish Thakker, James Zou, Kunle Olukotun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04618">https://arxiv.org/abs/2510.04618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04618">https://arxiv.org/pdf/2510.04618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04618]] Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models(https://arxiv.org/abs/2510.04618)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) applications such as agents and domain-specific reasoning increasingly rely on context adaptation -- modifying inputs with instructions, strategies, or evidence, rather than weight updates. Prior approaches improve usability but often suffer from brevity bias, which drops domain insights for concise summaries, and from context collapse, where iterative rewriting erodes details over time. Building on the adaptive memory introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context Engineering), a framework that treats contexts as evolving playbooks that accumulate, refine, and organize strategies through a modular process of generation, reflection, and curation. ACE prevents collapse with structured, incremental updates that preserve detailed knowledge and scale with long-context models. Across agent and domain-specific benchmarks, ACE optimizes contexts both offline (e.g., system prompts) and online (e.g., agent memory), consistently outperforming strong baselines: +10.6% on agents and +8.6% on finance, while significantly reducing adaptation latency and rollout cost. Notably, ACE could adapt effectively without labeled supervision and instead by leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches the top-ranked production-level agent on the overall average and surpasses it on the harder test-challenge split, despite using a smaller open-source model. These results show that comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead.</li>
</ul>

<h3>Title: PoS-CoPOR: Proof-of-Stake Consensus Protocol with Native Onion Routing Providing Scalability and DoS-Resistance</h3>
<ul>
<li><strong>Authors: </strong>Ivan Homoliak, Martin Perešíni, Marek Tamaškovič, Timotej Ponek, Lukáš Hellebrandt, Kamil Malinka</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04619">https://arxiv.org/abs/2510.04619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04619">https://arxiv.org/pdf/2510.04619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04619]] PoS-CoPOR: Proof-of-Stake Consensus Protocol with Native Onion Routing Providing Scalability and DoS-Resistance(https://arxiv.org/abs/2510.04619)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust</a></li>
<li><strong>Abstract: </strong>Proof-of-Stake (PoS) consensus protocols often face a trade-off between performance and security. Protocols that pre-elect leaders for subsequent rounds are vulnerable to Denial-of-Service (DoS) attacks, which can disrupt the network and compromise liveness. In this work, we present PoS-CoPOR, a single-chain PoS consensus protocol that mitigates this vulnerability by integrating a native onion routing mechanism into the consensus protocol itself. PoS-CoPOR combines stake-weighted probabilistic leader election with an anonymization layer that conceals the network identity of the next block proposer. This approach prevents targeted DoS attacks on leaders before they produce a block, thus enhancing network resilience. We implemented and evaluated PoS-CoPOR, demonstrating its ability to achieve a throughput of up to 110 tx/s with 6 nodes, even with the overhead of the anonymization layer. The results show that native anonymization can provide robust DoS resistance with only a modest impact on performance, offering a solution to build secure and scalable PoS blockchains.</li>
</ul>

<h3>Title: Forecasting-Based Biomedical Time-series Data Synthesis for Open Data and Robust AI</h3>
<ul>
<li><strong>Authors: </strong>Youngjoon Lee, Seongmin Cho, Yehhyun Jo, Jinu Gong, Hyunjoo Jenny Lee, Joonhyuk Kang</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04622">https://arxiv.org/abs/2510.04622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04622">https://arxiv.org/pdf/2510.04622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04622]] Forecasting-Based Biomedical Time-series Data Synthesis for Open Data and Robust AI(https://arxiv.org/abs/2510.04622)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>The limited data availability due to strict privacy regulations and significant resource demands severely constrains biomedical time-series AI development, which creates a critical gap between data requirements and accessibility. Synthetic data generation presents a promising solution by producing artificial datasets that maintain the statistical properties of real biomedical time-series data without compromising patient confidentiality. We propose a framework for synthetic biomedical time-series data generation based on advanced forecasting models that accurately replicates complex electrophysiological signals such as EEG and EMG with high fidelity. These synthetic datasets preserve essential temporal and spectral properties of real data, which enables robust analysis while effectively addressing data scarcity and privacy challenges. Our evaluations across multiple subjects demonstrate that the generated synthetic data can serve as an effective substitute for real data and also significantly boost AI model performance. The approach maintains critical biomedical features while provides high scalability for various applications and integrates seamlessly into open-source repositories, substantially expanding resources for AI-driven biomedical research.</li>
</ul>

<h3>Title: Compressed Concatenation of Small Embedding Models</h3>
<ul>
<li><strong>Authors: </strong>Mohamed Ayoub Ben Ayad, Michael Dinzinger, Kanishka Ghosh Dastidar, Jelena Mitrovic, Michael Granitzer</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04626">https://arxiv.org/abs/2510.04626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04626">https://arxiv.org/pdf/2510.04626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04626]] Compressed Concatenation of Small Embedding Models(https://arxiv.org/abs/2510.04626)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Embedding models are central to dense retrieval, semantic search, and recommendation systems, but their size often makes them impractical to deploy in resource-constrained environments such as browsers or edge devices. While smaller embedding models offer practical advantages, they typically underperform compared to their larger counterparts. To bridge this gap, we demonstrate that concatenating the raw embedding vectors of multiple small models can outperform a single larger baseline on standard retrieval benchmarks. To overcome the resulting high dimensionality of naive concatenation, we introduce a lightweight unified decoder trained with a Matryoshka Representation Learning (MRL) loss. This decoder maps the high-dimensional joint representation to a low-dimensional space, preserving most of the original performance without fine-tuning the base models. We also show that while concatenating more base models yields diminishing gains, the robustness of the decoder's representation under compression and quantization improves. Our experiments show that, on a subset of MTEB retrieval tasks, our concat-encode-quantize pipeline recovers 89\% of the original performance with a 48x compression factor when the pipeline is applied to a concatenation of four small embedding models.</li>
</ul>

<h3>Title: A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification</h3>
<ul>
<li><strong>Authors: </strong>Hao Liu, Yunhao Gao, Wei Li, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04628">https://arxiv.org/abs/2510.04628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04628">https://arxiv.org/pdf/2510.04628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04628]] A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification(https://arxiv.org/abs/2510.04628)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Deep learning-based methods have achieved significant success in remote sensing Earth observation data analysis. Numerous feature fusion techniques address multimodal remote sensing image classification by integrating global and local features. However, these techniques often struggle to extract structural and detail features from heterogeneous and redundant multimodal images. With the goal of introducing frequency domain learning to model key and sparse detail features, this paper introduces the spatial-spectral-frequency interaction network (S$^2$Fin), which integrates pairwise fusion modules across the spatial, spectral, and frequency domains. Specifically, we propose a high-frequency sparse enhancement transformer that employs sparse spatial-spectral attention to optimize the parameters of the high-frequency filter. Subsequently, a two-level spatial-frequency fusion strategy is introduced, comprising an adaptive frequency channel module that fuses low-frequency structures with enhanced high-frequency details, and a high-frequency resonance mask that emphasizes sharp edges via phase similarity. In addition, a spatial-spectral attention fusion module further enhances feature extraction at intermediate layers of the network. Experiments on four benchmark multimodal datasets with limited labeled data demonstrate that S$^2$Fin performs superior classification, outperforming state-of-the-art methods. The code is available at this https URL.</li>
</ul>

<h3>Title: SFANet: Spatial-Frequency Attention Network for Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Vrushank Ahire, Aniruddh Muley, Shivam Zample, Siddharth Verma, Pranav Menon, Surbhi Madan, Abhinav Dhall</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04630">https://arxiv.org/abs/2510.04630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04630">https://arxiv.org/pdf/2510.04630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04630]] SFANet: Spatial-Frequency Attention Network for Deepfake Detection(https://arxiv.org/abs/2510.04630)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Detecting manipulated media has now become a pressing issue with the recent rise of deepfakes. Most existing approaches fail to generalize across diverse datasets and generation techniques. We thus propose a novel ensemble framework, combining the strengths of transformer-based architectures, such as Swin Transformers and ViTs, and texture-based methods, to achieve better detection accuracy and robustness. Our method introduces innovative data-splitting, sequential training, frequency splitting, patch-based attention, and face segmentation techniques to handle dataset imbalances, enhance high-impact regions (e.g., eyes and mouth), and improve generalization. Our model achieves state-of-the-art performance when tested on the DFWild-Cup dataset, a diverse subset of eight deepfake datasets. The ensemble benefits from the complementarity of these approaches, with transformers excelling in global feature extraction and texturebased methods providing interpretability. This work demonstrates that hybrid models can effectively address the evolving challenges of deepfake detection, offering a robust solution for real-world applications.</li>
</ul>

<h3>Title: Backing the Wrong Horse: How Bit-Level Netlist Augmentation can Counter Power Side Channel Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ali Asghar, Andreas Becher, Daniel Ziener</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04640">https://arxiv.org/abs/2510.04640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04640">https://arxiv.org/pdf/2510.04640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04640]] Backing the Wrong Horse: How Bit-Level Netlist Augmentation can Counter Power Side Channel Attacks(https://arxiv.org/abs/2510.04640)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>The dependence of power-consumption on the processed data is a known vulnerability of CMOS circuits, resulting in side channels which can be exploited by power-based side channel attacks (SCAs). These attacks can extract sensitive information, such as secret keys, from the implementation of cryptographic algorithms. Existing countermeasures against power-based side channel attacks focus on analyzing information leakage at the byte level. However, this approach neglects the impact of individual bits on the overall resistance of a cryptographic implementation. In this work, we present a countermeasure based on single-bit leakage. The results suggest that the proposed countermeasure cannot be broken by attacks using conventional SCA leakage models.</li>
</ul>

<h3>Title: Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study</h3>
<ul>
<li><strong>Authors: </strong>Ayan Majumdar, Feihao Chen, Jinghui Li, Xiaozhen Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04641">https://arxiv.org/abs/2510.04641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04641">https://arxiv.org/pdf/2510.04641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04641]] Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study(https://arxiv.org/abs/2510.04641)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large-scale web-scraped text corpora used to train general-purpose AI models often contain harmful demographic-targeted social biases, creating a regulatory need for data auditing and developing scalable bias-detection methods. Although prior work has investigated biases in text datasets and related detection methods, these studies remain narrow in scope. They typically focus on a single content type (e.g., hate speech), cover limited demographic axes, overlook biases affecting multiple demographics simultaneously, and analyze limited techniques. Consequently, practitioners lack a holistic understanding of the strengths and limitations of recent large language models (LLMs) for automated bias detection. In this study, we present a comprehensive evaluation framework aimed at English texts to assess the ability of LLMs in detecting demographic-targeted social biases. To align with regulatory requirements, we frame bias detection as a multi-label task using a demographic-focused taxonomy. We then conduct a systematic evaluation with models across scales and techniques, including prompting, in-context learning, and fine-tuning. Using twelve datasets spanning diverse content types and demographics, our study demonstrates the promise of fine-tuned smaller models for scalable detection. However, our analyses also expose persistent gaps across demographic axes and multi-demographic targeted biases, underscoring the need for more effective and scalable auditing frameworks.</li>
</ul>

<h3>Title: Do Superpixel Segmentation Methods Influence Deforestation Image Classification?</h3>
<ul>
<li><strong>Authors: </strong>Hugo Resende, Fabio A. Faria, Eduardo B. Neto, Isabela Borlido, Victor Sundermann, Silvio Jamil F. Guimarães, Álvaro L. Fazenda</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04645">https://arxiv.org/abs/2510.04645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04645">https://arxiv.org/pdf/2510.04645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04645]] Do Superpixel Segmentation Methods Influence Deforestation Image Classification?(https://arxiv.org/abs/2510.04645)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Image segmentation is a crucial step in various visual applications, including environmental monitoring through remote sensing. In the context of the ForestEyes project, which combines citizen science and machine learning to detect deforestation in tropical forests, image segments are used for labeling by volunteers and subsequent model training. Traditionally, the Simple Linear Iterative Clustering (SLIC) algorithm is adopted as the segmentation method. However, recent studies have indicated that other superpixel-based methods outperform SLIC in remote sensing image segmentation, and might suggest that they are more suitable for the task of detecting deforested areas. In this sense, this study investigated the impact of the four best segmentation methods, together with SLIC, on the training of classifiers for the target application. Initially, the results showed little variation in performance among segmentation methods, even when selecting the top five classifiers using the PyCaret AutoML library. However, by applying a classifier fusion approach (ensemble of classifiers), noticeable improvements in balanced accuracy were observed, highlighting the importance of both the choice of segmentation method and the combination of machine learning-based models for deforestation detection tasks.</li>
</ul>

<h3>Title: EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents</h3>
<ul>
<li><strong>Authors: </strong>Buyuan Zhu, Shiyu Hu, Yiping Ma, Yuanming Zhang, Kang Hao Cheong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04648">https://arxiv.org/abs/2510.04648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04648">https://arxiv.org/pdf/2510.04648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04648]] EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents(https://arxiv.org/abs/2510.04648)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models are increasingly integrated into education, virtual student agents are becoming vital for classroom simulation and teacher training. Yet their classroom-oriented subjective abilities remain largely unassessed, limiting understanding of model boundaries and hindering trustworthy deployment. We present EduPersona, a large-scale benchmark spanning two languages, three subjects, and ten persona types based on the Big Five theory. The dataset contains 1,308 authentic classroom dialogue rounds, corresponding to 12,814 teacher-student Q&A turns, and is further expanded through persona stylization into roughly 10 times larger scale (128k turns), providing a solid foundation for evaluation. Building on this resource, we decompose hard-to-quantify subjective performance into three progressive tasks: TASK1 basic coherence (whether behavior, emotion, expression, and voice align with classroom context), TASK2 student realism, and TASK3 long-term persona consistency, thereby establishing an evaluation framework grounded in educational theory and research value. We conduct systematic experiments on three representative LLMs, comparing their original versions with ten persona-fine-tuned variants trained on EduPersona. Results show consistent and significant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%, and TASK3 +14.9%. These improvements highlight the dataset's effectiveness and research value, while also revealing the heterogeneous difficulty of persona modeling. In summary, EduPersona delivers the first classroom benchmark centered on subjective abilities, establishes a decoupled and verifiable research paradigm, and we will open-source both the dataset and the framework to support the broader research community in advancing trustworthy and human-like AI for education.</li>
</ul>

<h3>Title: Modeling and Managing Temporal Obligations in GUCON Using SPARQL-star and RDF-star</h3>
<ul>
<li><strong>Authors: </strong>Ines Akaichi, Giorgos Flouris, Irini Fundulaki, Sabrina Kirrane</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04652">https://arxiv.org/abs/2510.04652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04652">https://arxiv.org/pdf/2510.04652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04652]] Modeling and Managing Temporal Obligations in GUCON Using SPARQL-star and RDF-star(https://arxiv.org/abs/2510.04652)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>In the digital age, data frequently crosses organizational and jurisdictional boundaries, making effective governance essential. Usage control policies have emerged as a key paradigm for regulating data usage, safeguarding privacy, protecting intellectual property, and ensuring compliance with regulations. A central mechanism for usage control is the handling of obligations, which arise as a side effect of using and sharing data. Effective monitoring of obligations requires capturing usage traces and accounting for temporal aspects such as start times and deadlines, as obligations may evolve over times into different states, such as fulfilled, violated, or expired. While several solutions have been proposed for obligation monitoring, they often lack formal semantics or provide limited support for reasoning over obligation states. To address these limitations, we extend GUCON, a policy framework grounded in the formal semantics of SPAQRL graph patterns, to explicitly model the temporal aspects of an obligation. This extension enables the expressing of temporal obligations and supports continuous monitoring of their evolving states based on usage traces stored in temporal knowledge graphs. We demonstrate how this extended model can be represented using RDF-star and SPARQL-star and propose an Obligation State Manager that monitors obligation states and assess their compliance with respect to usage traces. Finally, we evaluate both the extended model and its prototype implementation.</li>
</ul>

<h3>Title: MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts</h3>
<ul>
<li><strong>Authors: </strong>Andy Cǎtrunǎ, Adrian Cosma, Emilian Rǎdoi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04654">https://arxiv.org/abs/2510.04654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04654">https://arxiv.org/pdf/2510.04654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04654]] MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts(https://arxiv.org/abs/2510.04654)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>Gait encodes rich biometric and behavioural information, yet leveraging the manner of walking to infer psychological traits remains a challenging and underexplored problem. We introduce a hierarchical Multi-Stage Mixture of Movement Experts (MoME) architecture for multi-task prediction of psychological attributes from gait sequences represented as 2D poses. MoME processes the walking cycle in four stages of movement complexity, employing lightweight expert models to extract spatio-temporal features and task-specific gating modules to adaptively weight experts across traits and stages. Evaluated on the PsyMo benchmark covering 17 psychological traits, our method outperforms state-of-the-art gait analysis models, achieving a 37.47% weighted F1 score at the run level and 44.6% at the subject level. Our experiments show that integrating auxiliary tasks such as identity recognition, gender prediction, and BMI estimation further improves psychological trait estimation. Our findings demonstrate the viability of multi-task gait-based learning for psychological trait estimation and provide a foundation for future research on movement-informed psychological inference.</li>
</ul>

<h3>Title: Noise or Signal? Deconstructing Contradictions and An Adaptive Remedy for Reversible Normalization in Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Fanzhe Fu, Yang Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04667">https://arxiv.org/abs/2510.04667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04667">https://arxiv.org/pdf/2510.04667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04667]] Noise or Signal? Deconstructing Contradictions and An Adaptive Remedy for Reversible Normalization in Time Series Forecasting(https://arxiv.org/abs/2510.04667)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reversible Instance Normalization (RevIN) is a key technique enabling simple linear models to achieve state-of-the-art performance in time series forecasting. While replacing its non-robust statistics with robust counterparts (termed R$^2$-IN) seems like a straightforward improvement, our findings reveal a far more complex reality. This paper deconstructs the perplexing performance of various normalization strategies by identifying four underlying theoretical contradictions. Our experiments provide two crucial findings: first, the standard RevIN catastrophically fails on datasets with extreme outliers, where its MSE surges by a staggering 683\%. Second, while the simple R$^2$-IN prevents this failure and unexpectedly emerges as the best overall performer, our adaptive model (A-IN), designed to test a diagnostics-driven heuristic, unexpectedly suffers a complete and systemic failure. This surprising outcome uncovers a critical, overlooked pitfall in time series analysis: the instability introduced by a simple or counter-intuitive heuristic can be more damaging than the statistical issues it aims to solve. The core contribution of this work is thus a new, cautionary paradigm for time series normalization: a shift from a blind search for complexity to a diagnostics-driven analysis that reveals not only the surprising power of simple baselines but also the perilous nature of naive adaptation.</li>
</ul>

<h3>Title: ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement</h3>
<ul>
<li><strong>Authors: </strong>Habin Lim, Yeongseob Won, Juwon Seo, Gyeong-Moon Park</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04668">https://arxiv.org/abs/2510.04668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04668">https://arxiv.org/pdf/2510.04668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04668]] ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement(https://arxiv.org/abs/2510.04668)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, multi-concept personalization for text-to-image (T2I) diffusion models to represent several subjects in an image has gained much more attention. The main challenge of this task is "concept mixing", where multiple learned concepts interfere or blend undesirably in the output image. To address this issue, in this paper, we present ConceptSplit, a novel framework to split the individual concepts through training and inference. Our framework comprises two key components. First, we introduce Token-wise Value Adaptation (ToVA), a merging-free training method that focuses exclusively on adapting the value projection in cross-attention. Based on our empirical analysis, we found that modifying the key projection, a common approach in existing methods, can disrupt the attention mechanism and lead to concept mixing. Second, we propose Latent Optimization for Disentangled Attention (LODA), which alleviates attention entanglement during inference by optimizing the input latent. Through extensive qualitative and quantitative experiments, we demonstrate that ConceptSplit achieves robust multi-concept personalization, mitigating unintended concept interference. Code is available at this https URL</li>
</ul>

<h3>Title: FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification</h3>
<ul>
<li><strong>Authors: </strong>Chao Liu, Ling Luo, Tengxiao Lv, Huan Zhuang, Lejing Yu, Jian Wang, Hongfei Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04671">https://arxiv.org/abs/2510.04671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04671">https://arxiv.org/pdf/2510.04671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04671]] FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification(https://arxiv.org/abs/2510.04671)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid development of online medical platforms, consumer health questions (CHQs) are inefficient in diagnosis due to redundant information and frequent non-professional terms. The medical question summary (MQS) task aims to transform CHQs into streamlined doctors' frequently asked questions (FAQs), but existing methods still face challenges such as poor identification of question focus and model hallucination. This paper explores the potential of large language models (LLMs) in the MQS task and finds that direct fine-tuning is prone to focus identification bias and generates unfaithful content. To this end, we propose an optimization framework based on core focus guidance. First, a prompt template is designed to drive the LLMs to extract the core focus from the CHQs that is faithful to the original text. Then, a fine-tuning dataset is constructed in combination with the original CHQ-FAQ pairs to improve the ability to identify the focus of the question. Finally, a multi-dimensional quality evaluation and selection mechanism is proposed to comprehensively improve the quality of the summary from multiple dimensions. We conduct comprehensive experiments on two widely-adopted MQS datasets using three established evaluation metrics. The proposed framework achieves state-of-the-art performance across all measures, demonstrating a significant boost in the model's ability to identify critical focus of questions and a notable mitigation of hallucinations. The source codes are freely available at this https URL.</li>
</ul>

<h3>Title: Semantic Channel Equalization Strategies for Deep Joint Source-Channel Coding</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Pannacci, Simone Fiorellino, Mario Edoardo Pandolfo, Emilio Calvanese Strinati, Paolo Di Lorenzo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04674">https://arxiv.org/abs/2510.04674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04674">https://arxiv.org/pdf/2510.04674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04674]] Semantic Channel Equalization Strategies for Deep Joint Source-Channel Coding(https://arxiv.org/abs/2510.04674)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Deep joint source-channel coding (DeepJSCC) has emerged as a powerful paradigm for end-to-end semantic communications, jointly learning to compress and protect task-relevant features over noisy channels. However, existing DeepJSCC schemes assume a shared latent space at transmitter (TX) and receiver (RX) - an assumption that fails in multi-vendor deployments where encoders and decoders cannot be co-trained. This mismatch introduces "semantic noise", degrading reconstruction quality and downstream task performance. In this paper, we systematize and evaluate methods for semantic channel equalization for DeepJSCC, introducing an additional processing stage that aligns heterogeneous latent spaces under both physical and semantic impairments. We investigate three classes of aligners: (i) linear maps, which admit closed-form solutions; (ii) lightweight neural networks, offering greater expressiveness; and (iii) a Parseval-frame equalizer, which operates in zero-shot mode without the need for training. Through extensive experiments on image reconstruction over AWGN and fading channels, we quantify trade-offs among complexity, data efficiency, and fidelity, providing guidelines for deploying DeepJSCC in heterogeneous AI-native wireless networks.</li>
</ul>

<h3>Title: Multi-Agent Tool-Integrated Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zhanfeng Mo, Xingxuan Li, Yuntao Chen, Lidong Bing</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04678">https://arxiv.org/abs/2510.04678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04678">https://arxiv.org/pdf/2510.04678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04678]] Multi-Agent Tool-Integrated Policy Optimization(https://arxiv.org/abs/2510.04678)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly rely on multi-turn tool-integrated planning for knowledge-intensive and complex reasoning tasks. Existing implementations typically rely on a single agent, but they suffer from limited context length and noisy tool responses. A natural solution is to adopt a multi-agent framework with planner- and worker-agents to manage context. However, no existing methods support effective reinforcement learning post-training of tool-integrated multi-agent frameworks. To address this gap, we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which enables distinct roles (planner and worker) to be trained within a single LLM instance using role-specific prompts via reinforcement learning. MATPO is derived from a principled credit assignment mechanism across planner and worker rollouts. This design eliminates the need to deploy multiple LLMs, which would be memory-intensive, while preserving the benefits of specialization. Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently outperforms single-agent baselines by an average of 18.38% relative improvement in performance and exhibits greater robustness to noisy tool outputs. Our findings highlight the effectiveness of unifying multiple agent roles within a single LLM and provide practical insights for stable and efficient multi-agent RL training.</li>
</ul>

<h3>Title: TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA</h3>
<ul>
<li><strong>Authors: </strong>Chanjoo Jung, Jaehyung Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04682">https://arxiv.org/abs/2510.04682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04682">https://arxiv.org/pdf/2510.04682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04682]] TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA(https://arxiv.org/abs/2510.04682)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are widely applied in real world scenarios, but fine-tuning them comes with significant computational and storage costs. Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these costs, but the adapted parameters are dependent on the base model and cannot be transferred across different backbones. One way to address this issue is through knowledge distillation, but its effectiveness inherently depends on training data. Recent work such as TransLoRA avoids this by generating synthetic data, but this adds complexity because it requires training an additional discriminator model. In this paper, we propose TiTok, a new framework that enables effective LoRA Transplantation through Token-level knowledge transfer. Specifically, TiTok captures task-relevant information through a contrastive excess between a source model with and without LoRA. This excess highlights informative tokens and enables selective filtering of synthetic data, all without additional models or overhead. Through experiments on three benchmarks across multiple transfer settings, our experiments show that the proposed method is consistently effective, achieving average performance gains of +4~8% compared to baselines overall.</li>
</ul>

<h3>Title: Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI</h3>
<ul>
<li><strong>Authors: </strong>Quang-Khai Bui-Tran, Minh-Toan Dinh, Thanh-Huy Nguyen, Ba-Thinh Lam, Mai-Anh Vu, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04705">https://arxiv.org/abs/2510.04705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04705">https://arxiv.org/pdf/2510.04705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04705]] Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI(https://arxiv.org/abs/2510.04705)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate liver segmentation in multi-phase MRI is vital for liver fibrosis assessment, yet labeled data is often scarce and unevenly distributed across imaging modalities and vendor systems. We propose a label-efficient segmentation approach that promotes cross-modality generalization under real-world conditions, where GED4 hepatobiliary-phase annotations are limited, non-contrast sequences (T1WI, T2WI, DWI) are unlabeled, and spatial misalignment and missing phases are common. Our method integrates a foundation-scale 3D segmentation backbone adapted via fine-tuning, co-training with cross pseudo supervision to leverage unlabeled volumes, and a standardized preprocessing pipeline. Without requiring spatial registration, the model learns to generalize across MRI phases and vendors, demonstrating robust segmentation performance in both labeled and unlabeled domains. Our results exhibit the effectiveness of our proposed label-efficient baseline for liver segmentation in multi-phase, multi-vendor MRI and highlight the potential of combining foundation model adaptation with co-training for real-world clinical imaging tasks.</li>
</ul>

<h3>Title: ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Foivos Paraperas Papantoniou, Stefanos Zafeiriou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04706">https://arxiv.org/abs/2510.04706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04706">https://arxiv.org/pdf/2510.04706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04706]] ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion(https://arxiv.org/abs/2510.04706)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Human-centric generative models designed for AI-driven storytelling must bring together two core capabilities: identity consistency and precise control over human performance. While recent diffusion-based approaches have made significant progress in maintaining facial identity, achieving fine-grained expression control without compromising identity remains challenging. In this work, we present a diffusion-based framework that faithfully reimagines any subject under any particular facial expression. Building on an ID-consistent face foundation model, we adopt a compositional design featuring an expression cross-attention module guided by FLAME blendshape parameters for explicit control. Trained on a diverse mixture of image and video data rich in expressive variation, our adapter generalizes beyond basic emotions to subtle micro-expressions and expressive transitions, overlooked by prior works. In addition, a pluggable Reference Adapter enables expression editing in real images by transferring the appearance from a reference frame during synthesis. Extensive quantitative and qualitative evaluations show that our model outperforms existing methods in tailored and identity-consistent expression generation. Code and models can be found at this https URL.</li>
</ul>

<h3>Title: ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts</h3>
<ul>
<li><strong>Authors: </strong>Zexin Wang, Changhua Pei, Yang Liu, Hengyue Jiang, Quan Zhou, Haotian Si, Hang Cui, Jianhui Li, Gaogang Xie, Jingjing Li, Dan Pei</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04710">https://arxiv.org/abs/2510.04710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04710">https://arxiv.org/pdf/2510.04710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04710]] ViTs: Teaching Machines to See Time Series Anomalies Like Human Experts(https://arxiv.org/abs/2510.04710)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Web service administrators must ensure the stability of multiple systems by promptly detecting anomalies in Key Performance Indicators (KPIs). Achieving the goal of "train once, infer across scenarios" remains a fundamental challenge for time series anomaly detection models. Beyond improving zero-shot generalization, such models must also flexibly handle sequences of varying lengths during inference, ranging from one hour to one week, without retraining. Conventional approaches rely on sliding-window encoding and self-supervised learning, which restrict inference to fixed-length inputs. Large Language Models (LLMs) have demonstrated remarkable zero-shot capabilities across general domains. However, when applied to time series data, they face inherent limitations due to context length. To address this issue, we propose ViTs, a Vision-Language Model (VLM)-based framework that converts time series curves into visual representations. By rescaling time series images, temporal dependencies are preserved while maintaining a consistent input size, thereby enabling efficient processing of arbitrarily long sequences without context constraints. Training VLMs for this purpose introduces unique challenges, primarily due to the scarcity of aligned time series image-text data. To overcome this, we employ an evolutionary algorithm to automatically generate thousands of high-quality image-text pairs and design a three-stage training pipeline consisting of: (1) time series knowledge injection, (2) anomaly detection enhancement, and (3) anomaly reasoning refinement. Extensive experiments demonstrate that ViTs substantially enhance the ability of VLMs to understand and detect anomalies in time series data. All datasets and code will be publicly released at: this https URL.</li>
</ul>

<h3>Title: ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Luo Cheng, Song Siyang, Yan Siyuan, Yu Zhen, Ge Zongyuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04712">https://arxiv.org/abs/2510.04712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04712">https://arxiv.org/pdf/2510.04712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04712]] ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model(https://arxiv.org/abs/2510.04712)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The automatic generation of diverse and human-like facial reactions in dyadic dialogue remains a critical challenge for human-computer interaction systems. Existing methods fail to model the stochasticity and dynamics inherent in real human reactions. To address this, we propose ReactDiff, a novel temporal diffusion framework for generating diverse facial reactions that are appropriate for responding to any given dialogue context. Our key insight is that plausible human reactions demonstrate smoothness, and coherence over time, and conform to constraints imposed by human facial anatomy. To achieve this, ReactDiff incorporates two vital priors (spatio-temporal facial kinematics) into the diffusion process: i) temporal facial behavioral kinematics and ii) facial action unit dependencies. These two constraints guide the model toward realistic human reaction manifolds, avoiding visually unrealistic jitters, unstable transitions, unnatural expressions, and other artifacts. Extensive experiments on the REACT2024 dataset demonstrate that our approach not only achieves state-of-the-art reaction quality but also excels in diversity and reaction appropriateness.</li>
</ul>

<h3>Title: JSON Whisperer: Efficient JSON Editing with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sarel Duanis, Asnat Greenstein-Messica, Eliya Habba</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04717">https://arxiv.org/abs/2510.04717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04717">https://arxiv.org/pdf/2510.04717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04717]] JSON Whisperer: Efficient JSON Editing with LLMs(https://arxiv.org/abs/2510.04717)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can modify JSON documents through natural language commands, but current approaches regenerate entire structures for each edit, resulting in computational inefficiency. We present JSON Whisperer, a framework that enables LLMs to generate RFC 6902 diff patches-expressing only the necessary modifications-rather than complete documents. We identify two key challenges in patch-based editing: (1) LLMs often miss related updates when generating isolated patches, and (2) array manipulations require tracking index shifts across operations, which LLMs handle poorly. To address these issues, we introduce EASE (Explicitly Addressed Sequence Encoding), which transforms arrays into dictionaries with stable keys, eliminating index arithmetic complexities. Our evaluation shows that patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full regeneration with particular gains for complex instructions and list manipulations. The dataset is available at: this https URL</li>
</ul>

<h3>Title: Benchmark on Monocular Metric Depth Estimation in Wildlife Setting</h3>
<ul>
<li><strong>Authors: </strong>Niccolò Niccoli, Lorenzo Seidenari, Ilaria Greco, Francesco Rovero</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04723">https://arxiv.org/abs/2510.04723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04723">https://arxiv.org/pdf/2510.04723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04723]] Benchmark on Monocular Metric Depth Estimation in Wildlife Setting(https://arxiv.org/abs/2510.04723)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Camera traps are widely used for wildlife monitoring, but extracting accurate distance measurements from monocular images remains challenging due to the lack of depth information. While monocular depth estimation (MDE) methods have advanced significantly, their performance in natural wildlife environments has not been systematically evaluated. This work introduces the first benchmark for monocular metric depth estimation in wildlife monitoring conditions. We evaluate four state-of-the-art MDE methods (Depth Anything V2, ML Depth Pro, ZoeDepth, and Metric3D) alongside a geometric baseline on 93 camera trap images with ground truth distances obtained using calibrated ChARUCO patterns. Our results demonstrate that Depth Anything V2 achieves the best overall performance with a mean absolute error of 0.454m and correlation of 0.962, while methods like ZoeDepth show significant degradation in outdoor natural environments (MAE: 3.087m). We find that median-based depth extraction consistently outperforms mean-based approaches across all deep learning methods. Additionally, we analyze computational efficiency, with ZoeDepth being fastest (0.17s per image) but least accurate, while Depth Anything V2 provides an optimal balance of accuracy and speed (0.22s per image). This benchmark establishes performance baselines for wildlife applications and provides practical guidance for implementing depth estimation in conservation monitoring systems.</li>
</ul>

<h3>Title: ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Houshmand Sarkhoosh, Frøy Øye, Henrik Nestor Sørlie, Nam Hoang Vu, Dag Johansen, Cise Midoglu, Tomas Kupka, Pål Halvorsen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04739">https://arxiv.org/abs/2510.04739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04739">https://arxiv.org/pdf/2510.04739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04739]] ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts(https://arxiv.org/abs/2510.04739)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Quantifying sponsor visibility in sports broadcasts is a critical marketing task traditionally hindered by manual, subjective, and unscalable analysis methods. While automated systems offer an alternative, their reliance on axis-aligned Horizontal Bounding Box (HBB) leads to inaccurate exposuremetrics when logos appear rotated or skewed due to dynamic camera angles and perspective distortions. This paper introduces ExposureEngine, an end-to-end system designed for accurate, rotation-aware sponsor visibility analytics in sports broadcasts, demonstrated in a soccer case study. Our approach predicts Oriented Bounding Box (OBB) to provide a geometrically precise fit to each logo regardless of the orientation on-screen. To train and evaluate our detector, we developed a new dataset comprising 1,103 frames from Swedish elite soccer, featuring 670 unique sponsor logos annotated with OBBs. Our model achieves a mean Average Precision (mAP@0.5) of 0.859, with a precision of 0.96 and recall of 0.87, demonstrating robust performance in localizing logos under diverse broadcast conditions. The system integrates these detections into an analytical pipeline that calculates precise visibility metrics, such as exposure duration and on-screen coverage. Furthermore, we incorporate a language-driven agentic layer, enabling users to generate reports, summaries, and media content through natural language queries. The complete system, including the dataset and the analytics dashboard, provides a comprehensive solution for auditable and interpretable sponsor measurement in sports media. An overview of the ExposureEngine is available online: this https URL .</li>
</ul>

<h3>Title: Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Alina Ciocarlan, Sylvie Le Hégarat-Mascle, Sidonie Lefebvre</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04741">https://arxiv.org/abs/2510.04741</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04741">https://arxiv.org/pdf/2510.04741</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04741]] Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection(https://arxiv.org/abs/2510.04741)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, segmentation</a></li>
<li><strong>Abstract: </strong>Infrared Small Target Detection (IRSTD) is a challenging task in defense applications, where complex backgrounds and tiny target sizes often result in numerous false alarms using conventional object detectors. To overcome this limitation, we propose Anomaly-Aware YOLO (AA-YOLO), which integrates a statistical anomaly detection test into its detection head. By treating small targets as unexpected patterns against the background, AA-YOLO effectively controls the false alarm rate. Our approach not only achieves competitive performance on several IRSTD benchmarks, but also demonstrates remarkable robustness in scenarios with limited training data, noise, and domain shifts. Furthermore, since only the detection head is modified, our design is highly generic and has been successfully applied across various YOLO backbones, including lightweight models. It also provides promising results when integrated into an instance segmentation YOLO. This versatility makes AA-YOLO an attractive solution for real-world deployments where resources are constrained. The code will be publicly released.</li>
</ul>

<h3>Title: Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04753">https://arxiv.org/abs/2510.04753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04753">https://arxiv.org/pdf/2510.04753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04753]] Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics(https://arxiv.org/abs/2510.04753)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper investigates the performance of transformer-based architectures for person identification in natural, face-to-face conversation scenario. We implement and evaluate a two-stream framework that separately models spatial configurations and temporal motion patterns of 133 COCO WholeBody keypoints, extracted from a subset of the CANDOR conversational corpus. Our experiments compare pre-trained and from-scratch training, investigate the use of velocity features, and introduce a multi-scale temporal transformer for hierarchical motion modeling. Results demonstrate that domain-specific training significantly outperforms transfer learning, and that spatial configurations carry more discriminative information than temporal dynamics. The spatial transformer achieves 95.74% accuracy, while the multi-scale temporal transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%, confirming that postural and dynamic information are complementary. These findings highlight the potential of transformer architectures for person identification in natural interactions and provide insights for future multimodal and cross-cultural studies.</li>
</ul>

<h3>Title: ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever</h3>
<ul>
<li><strong>Authors: </strong>Eduardo Martínez Rivera, Filippo Menolascina</a></li>
<li><strong>Subjects: </strong>cs.CL, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04757">https://arxiv.org/abs/2510.04757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04757">https://arxiv.org/pdf/2510.04757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04757]] ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever(https://arxiv.org/abs/2510.04757)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) is a powerful technique for enriching Large Language Models (LLMs) with external knowledge, allowing for factually grounded responses, a critical requirement in high-stakes domains such as healthcare. However, the efficacy of RAG systems is fundamentally restricted by the performance of their retrieval module, since irrelevant or semantically misaligned documents directly compromise the accuracy of the final generated response. General-purpose dense retrievers can struggle with the nuanced language of specialised domains, while the high accuracy of in-domain models is often achieved at prohibitive computational costs. In this work, we aim to address this trade-off by developing and evaluating a two-stage retrieval architecture that combines a lightweight ModernBERT bidirectional encoder for efficient initial candidate retrieval with a ColBERTv2 late-interaction model for fine-grained re-ranking. We conduct comprehensive evaluations of our retriever module performance and RAG system performance in the biomedical context, fine-tuning the IR module using 10k question-passage pairs from PubMedQA. Our analysis of the retriever module confirmed the positive impact of the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points compared to its retrieve-only counterpart. When integrated into the biomedical RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on the five tasks of the MIRAGE question-answering benchmark, outperforming strong baselines such as MedCPT (0.4436). Our ablation studies reveal that this performance is critically dependent on a joint fine-tuning process that aligns the retriever and re-ranker; otherwise, the re-ranker might degrade the performance.</li>
</ul>

<h3>Title: Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction</h3>
<ul>
<li><strong>Authors: </strong>Chi Yan, Dan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04759">https://arxiv.org/abs/2510.04759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04759">https://arxiv.org/pdf/2510.04759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04759]] Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction(https://arxiv.org/abs/2510.04759)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The 3D occupancy prediction task has witnessed remarkable progress in recent years, playing a crucial role in vision-based autonomous driving systems. While traditional methods are limited to fixed semantic categories, recent approaches have moved towards predicting text-aligned features to enable open-vocabulary text queries in real-world scenes. However, there exists a trade-off in text-aligned scene modeling: sparse Gaussian representation struggles to capture small objects in the scene, while dense representation incurs significant computational overhead. To address these limitations, we present PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables open-vocabulary 3D occupancy prediction. Our framework employs progressive online densification, a feed-forward strategy that gradually enhances the 3D Gaussian representation to capture fine-grained scene details. By iteratively enhancing the representation, the framework achieves increasingly precise and detailed scene understanding. Another key contribution is the introduction of an anisotropy-aware sampling strategy with spatio-temporal fusion, which adaptively assigns receptive fields to Gaussians at different scales and stages, enabling more effective feature aggregation and richer scene information capture. Through extensive evaluations, we demonstrate that PG-Occ achieves state-of-the-art performance with a relative 14.3% mIoU improvement over the previous best performing method. Code and pretrained models will be released upon publication on our project page: this https URL</li>
</ul>

<h3>Title: Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models</h3>
<ul>
<li><strong>Authors: </strong>Raha Askari, Sina Zarrieß, Özge Alacam, Judith Sieker</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04764">https://arxiv.org/abs/2510.04764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04764">https://arxiv.org/pdf/2510.04764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04764]] Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models(https://arxiv.org/abs/2510.04764)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Implicit meanings are integral to human communication, making it essential for language models to be capable of identifying and interpreting them. Grice (1975) proposed a set of conversational maxims that guide cooperative dialogue, noting that speakers may deliberately violate these principles to express meanings beyond literal words, and that listeners, in turn, recognize such violations to draw pragmatic inferences. Building on Surian et al. (1996)'s study of children's sensitivity to violations of Gricean maxims, we introduce a novel benchmark to test whether language models pretrained on less than 10M and less than 100M tokens can distinguish maxim-adhering from maxim-violating utterances. We compare these BabyLMs across five maxims and situate their performance relative to children and a Large Language Model (LLM) pretrained on 3T tokens. We find that overall, models trained on less than 100M tokens outperform those trained on less than 10M, yet fall short of child-level and LLM competence. Our results suggest that modest data increases improve some aspects of pragmatic behavior, leading to finer-grained differentiation between pragmatic dimensions.</li>
</ul>

<h3>Title: ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wonjun Kang, Kevin Galim, Seunghyuk Oh, Minjae Lee, Yuchen Zeng, Shuibai Zhang, Coleman Hooper, Yuezhou Hu, Hyung Il Koo, Nam Ik Cho, Kangwook Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04767">https://arxiv.org/abs/2510.04767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04767">https://arxiv.org/pdf/2510.04767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04767]] ParallelBench: Understanding the Trade-offs of Parallel Decoding in Diffusion LLMs(https://arxiv.org/abs/2510.04767)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While most autoregressive LLMs are constrained to one-by-one decoding, diffusion LLMs (dLLMs) have attracted growing interest for their potential to dramatically accelerate inference through parallel decoding. Despite this promise, the conditional independence assumption in dLLMs causes parallel decoding to ignore token dependencies, inevitably degrading generation quality when these dependencies are strong. However, existing works largely overlook these inherent challenges, and evaluations on standard benchmarks (e.g., math and coding) are not sufficient to capture the quality degradation caused by parallel decoding. To address this gap, we first provide an information-theoretic analysis of parallel decoding. We then conduct case studies on analytically tractable synthetic list operations from both data distribution and decoding strategy perspectives, offering quantitative insights that highlight the fundamental limitations of parallel decoding. Building on these insights, we propose ParallelBench, the first benchmark specifically designed for dLLMs, featuring realistic tasks that are trivial for humans and autoregressive LLMs yet exceptionally challenging for dLLMs under parallel decoding. Using ParallelBench, we systematically analyze both dLLMs and autoregressive LLMs, revealing that: (i) dLLMs under parallel decoding can suffer dramatic quality degradation in real-world scenarios, and (ii) current parallel decoding strategies struggle to adapt their degree of parallelism based on task difficulty, thus failing to achieve meaningful speedup without compromising quality. Our findings underscore the pressing need for innovative decoding methods that can overcome the current speed-quality trade-off. We release our benchmark to help accelerate the development of truly efficient dLLMs.</li>
</ul>

<h3>Title: Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge</h3>
<ul>
<li><strong>Authors: </strong>Max Kirchner, Hanna Hoffmann, Alexander C. Jenke, Oliver L. Saldanha, Kevin Pfeiffer, Weam Kanjo, Julia Alekseenko, Claas de Boer, Santhi Raj Kolamuri, Lorenzo Mazza, Nicolas Padoy, Sophia Bano, Annika Reinke, Lena Maier-Hein, Danail Stoyanov, Jakob N. Kather, Fiona R. Kolbinger, Sebastian Bodenstedt, Stefanie Speidel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04772">https://arxiv.org/abs/2510.04772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04772">https://arxiv.org/pdf/2510.04772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04772]] Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge(https://arxiv.org/abs/2510.04772)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Purpose: The FedSurg challenge was designed to benchmark the state of the art in federated learning for surgical video classification. Its goal was to assess how well current methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data. Methods: Participants developed strategies to classify inflammation stages in appendicitis using a preliminary version of the multi-center Appendix300 video dataset. The challenge evaluated two tasks: generalization to an unseen center and center-specific adaptation after fine-tuning. Submitted approaches included foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost, with ranking robustness evaluated via bootstrapping and statistical testing. Results: In the generalization task, performance across centers was limited. In the adaptation task, all teams improved after fine-tuning, though ranking stability was low. The ViViT-based submission achieved the strongest overall performance. The challenge highlighted limitations in generalization, sensitivity to class imbalance, and difficulties in hyperparameter tuning in decentralized training, while spatiotemporal modeling and context-aware preprocessing emerged as promising strategies. Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification. Findings highlight the trade-off between local personalization and global robustness, and underscore the importance of architecture choice, preprocessing, and loss design. This benchmarking offers a reference point for future development of imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.</li>
</ul>

<h3>Title: Distribution Preference Optimization: A Fine-grained Perspective for LLM Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Kai Qin, Jiaqi Wu, Jianxiang He, Haoyuan Sun, Yifei Zhao, Bin Liang, Yongzhe Chang, Tiantian Zhang, Houde Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04773">https://arxiv.org/abs/2510.04773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04773">https://arxiv.org/pdf/2510.04773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04773]] Distribution Preference Optimization: A Fine-grained Perspective for LLM Unlearning(https://arxiv.org/abs/2510.04773)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) demonstrate remarkable capabilities learned from vast corpora, concerns regarding data privacy and safety are receiving increasing attention. LLM unlearning, which aims to remove the influence of specific data while preserving overall model utility, is becoming an important research area. One of the mainstream unlearning classes is optimization-based methods, which achieve forgetting directly through fine-tuning, exemplified by Negative Preference Optimization (NPO). However, NPO's effectiveness is limited by its inherent lack of explicit positive preference signals. Attempts to introduce such signals by constructing preferred responses often necessitate domain-specific knowledge or well-designed prompts, fundamentally restricting their generalizability. In this paper, we shift the focus to the distribution-level, directly targeting the next-token probability distribution instead of entire responses, and derive a novel unlearning algorithm termed \textbf{Di}stribution \textbf{P}reference \textbf{O}ptimization (DiPO). We show that the requisite preference distribution pairs for DiPO, which are distributions over the model's output tokens, can be constructed by selectively amplifying or suppressing the model's high-confidence output logits, thereby effectively overcoming NPO's limitations. We theoretically prove the consistency of DiPO's loss function with the desired unlearning direction. Extensive experiments demonstrate that DiPO achieves a strong trade-off between model utility and forget quality. Notably, DiPO attains the highest forget quality on the TOFU benchmark, and maintains leading scalability and sustainability in utility preservation on the MUSE benchmark.</li>
</ul>

<h3>Title: A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation</h3>
<ul>
<li><strong>Authors: </strong>Alon Kaya, Igal Bilik, Inna Stainvas</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04794">https://arxiv.org/abs/2510.04794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04794">https://arxiv.org/pdf/2510.04794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04794]] A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation(https://arxiv.org/abs/2510.04794)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs) have reshaped computer vision through pretrained feature representations that enable strong transfer learning for diverse tasks. However, their efficiency as backbone architectures for geometric estimation tasks involving image deformations in low-data regimes remains an open question. This work considers two such tasks: 1) estimating 2D rigid transformations between pairs of images and 2) predicting the fundamental matrix for stereo image pairs, an important problem in various applications, such as autonomous mobility, robotics, and 3D scene reconstruction. Addressing this intriguing question, this work systematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet) with ViT-based foundation models (CLIP-ViT variants and DINO) in various data size settings, including few-shot scenarios. These pretrained models are optimized for classification or contrastive learning, encouraging them to focus mostly on high-level semantics. The considered tasks require balancing local and global features differently, challenging the straightforward adoption of these models as the backbone. Empirical comparative analysis shows that, similar to training from scratch, ViTs outperform CNNs during refinement in large downstream-data scenarios. However, in small data scenarios, the inductive bias and smaller capacity of CNNs improve their performance, allowing them to match that of a ViT. Moreover, ViTs exhibit stronger generalization in cross-domain evaluation where the data distribution changes. These results emphasize the importance of carefully selecting model architectures for refinement, motivating future research towards hybrid architectures that balance local and global representations.</li>
</ul>

<h3>Title: DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Qi Li, Shuwen Qiu, Julien Han, Xingzi Xu, Mehmet Saygin Seyfioglu, Kee Kiat Koo, Karim Bouyarmane</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04797">https://arxiv.org/abs/2510.04797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04797">https://arxiv.org/pdf/2510.04797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04797]] DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing(https://arxiv.org/abs/2510.04797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>The rapid growth of e-commerce has intensified the demand for Virtual Try-On (VTO) technologies, enabling customers to realistically visualize products overlaid on their own images. Despite recent advances, existing VTO models face challenges with fine-grained detail preservation, robustness to real-world imagery, efficient sampling, image editing capabilities, and generalization across diverse product categories. In this paper, we present DiT-VTON, a novel VTO framework that leverages a Diffusion Transformer (DiT), renowned for its performance on text-conditioned image generation, adapted here for the image-conditioned VTO task. We systematically explore multiple DiT configurations, including in-context token concatenation, channel concatenation, and ControlNet integration, to determine the best setup for VTO image conditioning. To enhance robustness, we train the model on an expanded dataset encompassing varied backgrounds, unstructured references, and non-garment categories, demonstrating the benefits of data scaling for VTO adaptability. DiT-VTON also redefines the VTO task beyond garment try-on, offering a versatile Virtual Try-All (VTA) solution capable of handling a wide range of product categories and supporting advanced image editing functionalities such as pose preservation, localized editing, texture transfer, and object-level customization. Experimental results show that our model surpasses state-of-the-art methods on VITON-HD, achieving superior detail preservation and robustness without reliance on additional condition encoders. It also outperforms models with VTA and image editing capabilities on a diverse dataset spanning thousands of product categories.</li>
</ul>

<h3>Title: Hybrid Architectures for Language Models: Systematic Analysis and Design Insights</h3>
<ul>
<li><strong>Authors: </strong>Sangmin Bae, Bilge Acun, Haroun Habeeb, Seungyeon Kim, Chien-Yu Lin, Liang Luo, Junjie Wang, Carole-Jean Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04800">https://arxiv.org/abs/2510.04800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04800">https://arxiv.org/pdf/2510.04800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04800]] Hybrid Architectures for Language Models: Systematic Analysis and Design Insights(https://arxiv.org/abs/2510.04800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large language models demonstrates that hybrid architectures--combining self-attention mechanisms with structured state space models like Mamba--can achieve a compelling balance between modeling quality and computational efficiency, particularly for long-context tasks. While these hybrid models show promising performance, systematic comparisons of hybridization strategies and analyses on the key factors behind their effectiveness have not been clearly shared to the community. In this work, we present a holistic evaluation of hybrid architectures based on inter-layer (sequential) or intra-layer (parallel) fusion. We evaluate these designs from a variety of perspectives: language modeling performance, long-context capabilities, scaling analysis, and training and inference efficiency. By investigating the core characteristics of their computational primitive, we identify the most critical elements for each hybridization strategy and further propose optimal design recipes for both hybrid models. Our comprehensive analysis provides practical guidance and valuable insights for developing hybrid language models, facilitating the optimization of architectural configurations.</li>
</ul>

<h3>Title: Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors</h3>
<ul>
<li><strong>Authors: </strong>Han Zhang, Lalithkumar Seenivasan, Jose L. Porras, Roger D. Soberanis-Mukul, Hao Ding, Hongchao Shu, Benjamin D. Killeen, Ankita Ghosh, Lonny Yarmus, Masaru Ishii, Angela Christine Argento, Mathias Unberath</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04802">https://arxiv.org/abs/2510.04802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04802">https://arxiv.org/pdf/2510.04802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04802]] Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors(https://arxiv.org/abs/2510.04802)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Observing surgical practice has historically relied on fixed vantage points or recollections, leaving the egocentric visual perspectives that guide clinical decisions undocumented. Fixed-camera video can capture surgical workflows at the room-scale, but cannot reconstruct what each team member actually saw. Thus, these videos only provide limited insights into how decisions that affect surgical safety, training, and workflow optimization are made. Here we introduce EgoSurg, the first framework to reconstruct the dynamic, egocentric replays for any operating room (OR) staff directly from wall-mounted fixed-camera video, and thus, without intervention to clinical workflow. EgoSurg couples geometry-driven neural rendering with diffusion-based view enhancement, enabling high-visual fidelity synthesis of arbitrary and egocentric viewpoints at any moment. In evaluation across multi-site surgical cases and controlled studies, EgoSurg reconstructs person-specific visual fields and arbitrary viewpoints with high visual quality and fidelity. By transforming existing OR camera infrastructure into a navigable dynamic 3D record, EgoSurg establishes a new foundation for immersive surgical data science, enabling surgical practice to be visualized, experienced, and analyzed from every angle.</li>
</ul>

<h3>Title: On Predicting Post-Click Conversion Rate via Counterfactual Inference</h3>
<ul>
<li><strong>Authors: </strong>Junhyung Ahn, Sanghack Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04816">https://arxiv.org/abs/2510.04816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04816">https://arxiv.org/pdf/2510.04816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04816]] On Predicting Post-Click Conversion Rate via Counterfactual Inference(https://arxiv.org/abs/2510.04816)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurately predicting conversion rate (CVR) is essential in various recommendation domains such as online advertising systems and e-commerce. These systems utilize user interaction logs, which consist of exposures, clicks, and conversions. CVR prediction models are typically trained solely based on clicked samples, as conversions can only be determined following clicks. However, the sparsity of clicked instances necessitates the collection of a substantial amount of logs for effective model training. Recent works address this issue by devising frameworks that leverage non-clicked samples. While these frameworks aim to reduce biases caused by the discrepancy between clicked and non-clicked samples, they often rely on heuristics. Against this background, we propose a method to counterfactually generate conversion labels for non-clicked samples by using causality as a guiding principle, attempting to answer the question, "Would the user have converted if he or she had clicked the recommended item?" Our approach is named the Entire Space Counterfactual Inference Multi-task Model (ESCIM). We initially train a structural causal model (SCM) of user sequential behaviors and conduct a hypothetical intervention (i.e., click) on non-clicked items to infer counterfactual CVRs. We then introduce several approaches to transform predicted counterfactual CVRs into binary counterfactual conversion labels for the non-clicked samples. Finally, the generated samples are incorporated into the training process. Extensive experiments on public datasets illustrate the superiority of the proposed algorithm. Online A/B testing further empirically validates the effectiveness of our proposed algorithm in real-world scenarios. In addition, we demonstrate the improved performance of the proposed method on latent conversion data, showcasing its robustness and superior generalization capabilities.</li>
</ul>

<h3>Title: Visual Representations inside the Language Model</h3>
<ul>
<li><strong>Authors: </strong>Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay Krishna</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04819">https://arxiv.org/abs/2510.04819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04819">https://arxiv.org/pdf/2510.04819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04819]] Visual Representations inside the Language Model(https://arxiv.org/abs/2510.04819)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Despite interpretability work analyzing VIT encoders and transformer activations, we don't yet understand why Multimodal Language Models (MLMs) struggle on perception-heavy tasks. We offer an under-studied perspective by examining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and Llama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the flow of visual information through the language model, finding that image value tokens encode sufficient information to perform several perception-heavy tasks zero-shot: segmentation, semantic correspondence, temporal correspondence, and referring expression detection. We find that while the language model does augment the visual information received from the projection of input visual encodings-which we reveal correlates with overall MLM perception capability-it contains less visual information on several tasks than the equivalent visual encoder (SigLIP) that has not undergone MLM finetuning. Further, we find that the visual information corresponding to input-agnostic image key tokens in later layers of language models contains artifacts which reduce perception capability of the overall MLM. Next, we discuss controlling visual information in the language model, showing that adding a text prefix to the image input improves perception capabilities of visual representations. Finally, we reveal that if language models were able to better control their visual information, their perception would significantly improve; e.g., in 33.3% of Art Style questions in the BLINK benchmark, perception information present in the language model is not surfaced to the output! Our findings reveal insights into the role of key-value tokens in multimodal systems, paving the way for deeper mechanistic interpretability of MLMs and suggesting new directions for training their visual encoder and language model components.</li>
</ul>

<h3>Title: AvatarVTON: 4D Virtual Try-On for Animatable Avatars</h3>
<ul>
<li><strong>Authors: </strong>Zicheng Jiang, Jixin Gao, Shengfeng He, Xinzhe Li, Yulong Zheng, Zhaotong Yang, Junyu Dong, Yong Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04822">https://arxiv.org/abs/2510.04822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04822">https://arxiv.org/pdf/2510.04822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04822]] AvatarVTON: 4D Virtual Try-On for Animatable Avatars(https://arxiv.org/abs/2510.04822)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We propose AvatarVTON, the first 4D virtual try-on framework that generates realistic try-on results from a single in-shop garment image, enabling free pose control, novel-view rendering, and diverse garment choices. Unlike existing methods, AvatarVTON supports dynamic garment interactions under single-view supervision, without relying on multi-view garment captures or physics priors. The framework consists of two key modules: (1) a Reciprocal Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer, which decomposes Gaussian maps into view-pose-invariant and view-pose-specific components, enabling adaptive, non-linear garment deformations. To establish a benchmark for 4D virtual try-on, we extend existing baselines with unified modules for fair qualitative and quantitative comparisons. Extensive experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic garment realism, making it well-suited for AR/VR, gaming, and digital-human applications.</li>
</ul>

<h3>Title: Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints</h3>
<ul>
<li><strong>Authors: </strong>Viktor Kozák, Jan Chudoba, Libor Přeučil</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04840">https://arxiv.org/abs/2510.04840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04840">https://arxiv.org/pdf/2510.04840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04840]] Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints(https://arxiv.org/abs/2510.04840)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>An accurate and up-to-date model of a photovoltaic (PV) power plant is essential for its optimal operation and maintenance. However, such a model may not be easily available. This work introduces a novel approach for PV power plant mapping based on aerial overview images. It enables the automation of the mapping process while removing the reliance on third-party data. The presented mapping method takes advantage of the structural layout of the power plants to achieve detailed modeling down to the level of individual PV modules. The approach relies on visual segmentation of PV modules in overview images and the inference of structural information in each image, assigning modules to individual benches, rows, and columns. We identify visual keypoints related to the layout and use these to merge detections from multiple images while maintaining their structural integrity. The presented method was experimentally verified and evaluated on two different power plants. The final fusion of 3D positions and semantic structures results in a compact georeferenced model suitable for power plant maintenance.</li>
</ul>

<h3>Title: Distributionally Robust Causal Abstractions</h3>
<ul>
<li><strong>Authors: </strong>Yorgos Felekis, Theodoros Damoulas, Paris Giampouras</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04842">https://arxiv.org/abs/2510.04842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04842">https://arxiv.org/pdf/2510.04842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04842]] Distributionally Robust Causal Abstractions(https://arxiv.org/abs/2510.04842)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Causal Abstraction (CA) theory provides a principled framework for relating causal models that describe the same system at different levels of granularity while ensuring interventional consistency between them. Recently, several approaches for learning CAs have been proposed, but all assume fixed and well-specified exogenous distributions, making them vulnerable to environmental shifts and misspecification. In this work, we address these limitations by introducing the first class of distributionally robust CAs and their associated learning algorithms. The latter cast robust causal abstraction learning as a constrained min-max optimization problem with Wasserstein ambiguity sets. We provide theoretical results, for both empirical and Gaussian environments, leading to principled selection of the level of robustness via the radius of these sets. Furthermore, we present empirical evidence across different problems and CA learning methods, demonstrating our framework's robustness not only to environmental shifts but also to structural model and intervention mapping misspecification.</li>
</ul>

<h3>Title: From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements</h3>
<ul>
<li><strong>Authors: </strong>Cheyu Lin, Katherine A. Flanigan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04844">https://arxiv.org/abs/2510.04844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04844">https://arxiv.org/pdf/2510.04844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04844]] From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements(https://arxiv.org/abs/2510.04844)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Understanding the dynamic relationship between humans and the built environment is a key challenge in disciplines ranging from environmental psychology to reinforcement learning (RL). A central obstacle in modeling these interactions is the inability to capture human psychological states in a way that is both generalizable and privacy preserving. Traditional methods rely on theoretical models or questionnaires, which are limited in scope, static, and labor intensive. We present a kinesics recognition framework that infers the communicative functions of human activity -- known as kinesics -- directly from 3D skeleton joint data. Combining a spatial-temporal graph convolutional network (ST-GCN) with a convolutional neural network (CNN), the framework leverages transfer learning to bypass the need for manually defined mappings between physical actions and psychological categories. The approach preserves user anonymity while uncovering latent structures in bodily movements that reflect cognitive and emotional states. Our results on the Dyadic User EngagemenT (DUET) dataset demonstrate that this method enables scalable, accurate, and human-centered modeling of behavior, offering a new pathway for enhancing RL-driven simulations of human-environment interaction.</li>
</ul>

<h3>Title: Instability in Downstream Task Performance During LLM Pretraining</h3>
<ul>
<li><strong>Authors: </strong>Yuto Nishida, Masaru Isonuma, Yusuke Oda</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04848">https://arxiv.org/abs/2510.04848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04848">https://arxiv.org/pdf/2510.04848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04848]] Instability in Downstream Task Performance During LLM Pretraining(https://arxiv.org/abs/2510.04848)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>When training large language models (LLMs), it is common practice to track downstream task performance throughout the training process and select the checkpoint with the highest validation score. However, downstream metrics often exhibit substantial fluctuations, making it difficult to identify the checkpoint that truly represents the best-performing model. In this study, we empirically analyze the stability of downstream task performance in an LLM trained on diverse web-scale corpora. We find that task scores frequently fluctuate throughout training, both at the aggregate and example levels. To address this instability, we investigate two post-hoc checkpoint integration methods: checkpoint averaging and ensemble, motivated by the hypothesis that aggregating neighboring checkpoints can reduce performance volatility. We demonstrate both empirically and theoretically that these methods improve downstream performance stability without requiring any changes to the training procedure.</li>
</ul>

<h3>Title: When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA</h3>
<ul>
<li><strong>Authors: </strong>Elisei Rykov, Kseniia Petrushina, Maksim Savkin, Valerii Olisov, Artem Vazhentsev, Kseniia Titova, Alexander Panchenko, Vasily Konovalov, Julia Belikova</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04849">https://arxiv.org/abs/2510.04849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04849">https://arxiv.org/pdf/2510.04849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04849]] When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA(https://arxiv.org/abs/2510.04849)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Hallucination detection remains a fundamental challenge for the safe and reliable deployment of large language models (LLMs), especially in applications requiring factual accuracy. Existing hallucination benchmarks often operate at the sequence level and are limited to English, lacking the fine-grained, multilingual supervision needed for a comprehensive evaluation. In this work, we introduce PsiloQA, a large-scale, multilingual dataset annotated with span-level hallucinations across 14 languages. PsiloQA is constructed through an automated three-stage pipeline: generating question-answer pairs from Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse LLMs in a no-context setting, and automatically annotating hallucinated spans using GPT-4o by comparing against golden answers and retrieved context. We evaluate a wide range of hallucination detection methods -- including uncertainty quantification, LLM-based tagging, and fine-tuned encoder models -- and show that encoder-based models achieve the strongest performance across languages. Furthermore, PsiloQA demonstrates effective cross-lingual generalization and supports robust knowledge transfer to other benchmarks, all while being significantly more cost-efficient than human-annotated datasets. Our dataset and results advance the development of scalable, fine-grained hallucination detection in multilingual settings.</li>
</ul>

<h3>Title: Detecting Distillation Data from Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Hengxiang Zhang, Hyeong Kyu Choi, Yixuan Li, Hongxin Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04850">https://arxiv.org/abs/2510.04850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04850">https://arxiv.org/pdf/2510.04850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04850]] Detecting Distillation Data from Reasoning Models(https://arxiv.org/abs/2510.04850)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reasoning distillation has emerged as an efficient and powerful paradigm for enhancing the reasoning capabilities of large language models. However, reasoning distillation may inadvertently cause benchmark contamination, where evaluation data included in distillation datasets can inflate performance metrics of distilled models. In this work, we formally define the task of distillation data detection, which is uniquely challenging due to the partial availability of distillation data. Then, we propose a novel and effective method Token Probability Deviation (TBD), which leverages the probability patterns of the generated output tokens. Our method is motivated by the analysis that distilled models tend to generate near-deterministic tokens for seen questions, while producing more low-probability tokens for unseen questions. Our key idea behind TBD is to quantify how far the generated tokens' probabilities deviate from a high reference probability. In effect, our method achieves competitive detection performance by producing lower scores for seen questions than for unseen questions. Extensive experiments demonstrate the effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of 0.470 on the S1 dataset.</li>
</ul>

<h3>Title: Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems</h3>
<ul>
<li><strong>Authors: </strong>Cheyu Lin, John Martins, Katherine A. Flanigan, Ph.D</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04854">https://arxiv.org/abs/2510.04854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04854">https://arxiv.org/pdf/2510.04854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04854]] Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems(https://arxiv.org/abs/2510.04854)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Cyber-physical systems (CPS) integrate sensing, computing, and control to improve infrastructure performance, focusing on economic goals like performance and safety. However, they often neglect potential human-centered (or ''social'') benefits. Cyber-physical-social infrastructure systems (CPSIS) aim to address this by aligning CPS with social objectives. This involves defining social benefits, understanding human interactions with each other and infrastructure, developing privacy-preserving measurement methods, modeling these interactions for prediction, linking them to social benefits, and actuating the physical environment to foster positive social outcomes. This paper delves into recognizing dyadic human interactions using real-world data, which is the backbone to measuring social behavior. This lays a foundation to address the need to enhance understanding of the deeper meanings and mutual responses inherent in human interactions. While RGB cameras are informative for interaction recognition, privacy concerns arise. Depth sensors offer a privacy-conscious alternative by analyzing skeletal movements. This study compares five skeleton-based interaction recognition algorithms on a dataset of 12 dyadic interactions. Unlike single-person datasets, these interactions, categorized into communication types like emblems and affect displays, offer insights into the cultural and emotional aspects of human interactions.</li>
</ul>

<h3>Title: Synthesising Counterfactual Explanations via Label-Conditional Gaussian Mixture Variational Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Junqi Jiang, Francesco Leofante, Antonio Rago, Francesca Toni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04855">https://arxiv.org/abs/2510.04855</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04855">https://arxiv.org/pdf/2510.04855</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04855]] Synthesising Counterfactual Explanations via Label-Conditional Gaussian Mixture Variational Autoencoders(https://arxiv.org/abs/2510.04855)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations (CEs) provide recourse recommendations for individuals affected by algorithmic decisions. A key challenge is generating CEs that are robust against various perturbation types (e.g. input and model perturbations) while simultaneously satisfying other desirable properties. These include plausibility, ensuring CEs reside on the data manifold, and diversity, providing multiple distinct recourse options for single inputs. Existing methods, however, mostly struggle to address these multifaceted requirements in a unified, model-agnostic manner. We address these limitations by proposing a novel generative framework. First, we introduce the Label-conditional Gaussian Mixture Variational Autoencoder (L-GMVAE), a model trained to learn a structured latent space where each class label is represented by a set of Gaussian components with diverse, prototypical centroids. Building on this, we present LAPACE (LAtent PAth Counterfactual Explanations), a model-agnostic algorithm that synthesises entire paths of CE points by interpolating from inputs' latent representations to those learned latent centroids. This approach inherently ensures robustness to input changes, as all paths for a given target class converge to the same fixed centroids. Furthermore, the generated paths provide a spectrum of recourse options, allowing users to navigate the trade-off between proximity and plausibility while also encouraging robustness against model changes. In addition, user-specified actionability constraints can also be easily incorporated via lightweight gradient optimisation through the L-GMVAE's decoder. Comprehensive experiments show that LAPACE is computationally efficient and achieves competitive performance across eight quantitative metrics.</li>
</ul>

<h3>Title: μDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy</h3>
<ul>
<li><strong>Authors: </strong>Elena Corbetta, Thomas Bocklitz</a></li>
<li><strong>Subjects: </strong>cs.CV, physics.data-an, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04859">https://arxiv.org/abs/2510.04859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04859">https://arxiv.org/pdf/2510.04859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04859]] μDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy(https://arxiv.org/abs/2510.04859)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Optical microscopy is one of the most widely used techniques in research studies for life sciences and biomedicine. These applications require reliable experimental pipelines to extract valuable knowledge from the measured samples and must be supported by image quality assessment (IQA) to ensure correct processing and analysis of the image data. IQA methods are implemented with variable complexity. However, while most quality metrics have a straightforward implementation, they might be time consuming and computationally expensive when evaluating a large dataset. In addition, quality metrics are often designed for well-defined image features and may be unstable for images out of the ideal domain. To overcome these limitations, recent works have proposed deep learning-based IQA methods, which can provide superior performance, increased generalizability and fast prediction. Our method, named $\mathrm{\mu}$DeepIQA, is inspired by previous studies and applies a deep convolutional neural network designed for IQA on natural images to optical microscopy measurements. We retrained the same architecture to predict individual quality metrics and global quality scores for optical microscopy data. The resulting models provide fast and stable predictions of image quality by generalizing quality estimation even outside the ideal range of standard methods. In addition, $\mathrm{\mu}$DeepIQA provides patch-wise prediction of image quality and can be used to visualize spatially varying quality in a single image. Our study demonstrates that optical microscopy-based studies can benefit from the generalizability of deep learning models due to their stable performance in the presence of outliers, the ability to assess small image patches, and rapid predictions.</li>
</ul>

<h3>Title: Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails</h3>
<ul>
<li><strong>Authors: </strong>Siwei Han, Jiaqi Liu, Yaofeng Su, Wenbo Duan, Xinyuan Liu, Cihang Xie, Mohit Bansal, Mingyu Ding, Linjun Zhang, Huaxiu Yao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04860">https://arxiv.org/abs/2510.04860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04860">https://arxiv.org/pdf/2510.04860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04860]] Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the Rails(https://arxiv.org/abs/2510.04860)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Model (LLM) agents increasingly gain self-evolutionary capabilities to adapt and refine their strategies through real-world interaction, their long-term reliability becomes a critical concern. We identify the Alignment Tipping Process (ATP), a critical post-deployment risk unique to self-evolving LLM agents. Unlike training-time failures, ATP arises when continual interaction drives agents to abandon alignment constraints established during training in favor of reinforced, self-interested strategies. We formalize and analyze ATP through two complementary paradigms: Self-Interested Exploration, where repeated high-reward deviations induce individual behavioral drift, and Imitative Strategy Diffusion, where deviant behaviors spread across multi-agent systems. Building on these paradigms, we construct controllable testbeds and benchmark Qwen3-8B and Llama-3.1-8B-Instruct. Our experiments show that alignment benefits erode rapidly under self-evolution, with initially aligned models converging toward unaligned states. In multi-agent settings, successful violations diffuse quickly, leading to collective misalignment. Moreover, current reinforcement learning-based alignment methods provide only fragile defenses against alignment tipping. Together, these findings demonstrate that alignment of LLM agents is not a static property but a fragile and dynamic one, vulnerable to feedback-driven decay during deployment. Our data and code are available at this https URL.</li>
</ul>

<h3>Title: A Clinical-grade Universal Foundation Model for Intraoperative Pathology</h3>
<ul>
<li><strong>Authors: </strong>Zihan Zhao, Fengtao Zhou, Ronggang Li, Bing Chu, Xinke Zhang, Xueyi Zheng, Ke Zheng, Xiaobo Wen, Jiabo Ma, Yihui Wang, Jiewei Chen, Chengyou Zheng, Jiangyu Zhang, Yongqin Wen, Jiajia Meng, Ziqi Zeng, Xiaoqing Li, Jing Li, Dan Xie, Yaping Ye, Yu Wang, Hao Chen, Muyan Cai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04861">https://arxiv.org/abs/2510.04861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04861">https://arxiv.org/pdf/2510.04861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04861]] A Clinical-grade Universal Foundation Model for Intraoperative Pathology(https://arxiv.org/abs/2510.04861)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Intraoperative pathology is pivotal to precision surgery, yet its clinical impact is constrained by diagnostic complexity and the limited availability of high-quality frozen-section data. While computational pathology has made significant strides, the lack of large-scale, prospective validation has impeded its routine adoption in surgical workflows. Here, we introduce CRISP, a clinical-grade foundation model developed on over 100,000 frozen sections from eight medical centers, specifically designed to provide Clinical-grade Robust Intraoperative Support for Pathology (CRISP). CRISP was comprehensively evaluated on more than 15,000 intraoperative slides across nearly 100 retrospective diagnostic tasks, including benign-malignant discrimination, key intraoperative decision-making, and pan-cancer detection, etc. The model demonstrated robust generalization across diverse institutions, tumor types, and anatomical sites-including previously unseen sites and rare cancers. In a prospective cohort of over 2,000 patients, CRISP sustained high diagnostic accuracy under real-world conditions, directly informing surgical decisions in 92.6% of cases. Human-AI collaboration further reduced diagnostic workload by 35%, avoided 105 ancillary tests and enhanced detection of micrometastases with 87.5% accuracy. Together, these findings position CRISP as a clinical-grade paradigm for AI-driven intraoperative pathology, bridging computational advances with surgical precision and accelerating the translation of artificial intelligence into routine clinical practice.</li>
</ul>

<h3>Title: In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Ciem Cornelissen, Sander De Coninck, Axel Willekens, Sam Leroux, Pieter Simoens</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04864">https://arxiv.org/abs/2510.04864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04864">https://arxiv.org/pdf/2510.04864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04864]] In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning(https://arxiv.org/abs/2510.04864)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents an end-to-end, IoT-enabled robotic system for the non-destructive, real-time, and spatially-resolved mapping of grape yield and quality (Brix, Acidity) in vineyards. The system features a comprehensive analytical pipeline that integrates two key modules: a high-performance model for grape bunch detection and weight estimation, and a novel deep learning framework for quality assessment from hyperspectral (HSI) data. A critical barrier to in-field HSI is the ``domain shift" caused by variable illumination. To overcome this, our quality assessment is powered by the Light-Invariant Spectral Autoencoder (LISA), a domain-adversarial framework that learns illumination-invariant features from uncalibrated data. We validated the system's robustness on a purpose-built HSI dataset spanning three distinct illumination domains: controlled artificial lighting (lab), and variable natural sunlight captured in the morning and afternoon. Results show the complete pipeline achieves a recall (0.82) for bunch detection and a $R^2$ (0.76) for weight prediction, while the LISA module improves quality prediction generalization by over 20% compared to the baselines. By combining these robust modules, the system successfully generates high-resolution, georeferenced data of both grape yield and quality, providing actionable, data-driven insights for precision viticulture.</li>
</ul>

<h3>Title: Less is More: Recursive Reasoning with Tiny Networks</h3>
<ul>
<li><strong>Authors: </strong>Alexia Jolicoeur-Martineau</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04871">https://arxiv.org/abs/2510.04871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04871">https://arxiv.org/pdf/2510.04871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04871]] Less is More: Recursive Reasoning with Tiny Networks(https://arxiv.org/abs/2510.04871)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hierarchical Reasoning Model (HRM) is a novel approach using two small neural networks recursing at different frequencies. This biologically inspired method beats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze, and ARC-AGI while trained with small models (27M parameters) on small data (around 1000 examples). HRM holds great promise for solving hard problems with small networks, but it is not yet well understood and may be suboptimal. We propose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach that achieves significantly higher generalization than HRM, while using a single tiny network with only 2 layers. With only 7M parameters, TRM obtains 45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs (e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the parameters.</li>
</ul>

<h3>Title: BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping</h3>
<ul>
<li><strong>Authors: </strong>Hayat Rajani, Valerio Franchi, Borja Martinez-Clavel Valles, Raimon Ramos, Rafael Garcia, Nuno Gracias</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04876">https://arxiv.org/abs/2510.04876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04876">https://arxiv.org/pdf/2510.04876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04876]] BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping(https://arxiv.org/abs/2510.04876)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Benthic habitat mapping is fundamental for understanding marine ecosystems, guiding conservation efforts, and supporting sustainable resource management. Yet, the scarcity of large, annotated datasets limits the development and benchmarking of machine learning models in this domain. This paper introduces a thorough multi-modal dataset, comprising about a million side-scan sonar (SSS) tiles collected along the coast of Catalonia (Spain), complemented by bathymetric maps and a set of co-registered optical images from targeted surveys using an autonomous underwater vehicle (AUV). Approximately \num{36000} of the SSS tiles have been manually annotated with segmentation masks to enable supervised fine-tuning of classification models. All the raw sensor data, together with mosaics, are also released to support further exploration and algorithm development. To address challenges in multi-sensor data fusion for AUVs, we spatially associate optical images with corresponding SSS tiles, facilitating self-supervised, cross-modal representation learning. Accompanying open-source preprocessing and annotation tools are provided to enhance accessibility and encourage research. This resource aims to establish a standardized benchmark for underwater habitat mapping, promoting advancements in autonomous seafloor classification and multi-sensor integration.</li>
</ul>

<h3>Title: Flow-Matching Based Refiner for Molecular Conformer Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangyang Xu, Hongyang Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04878">https://arxiv.org/abs/2510.04878</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04878">https://arxiv.org/pdf/2510.04878</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04878]] Flow-Matching Based Refiner for Molecular Conformer Generation(https://arxiv.org/abs/2510.04878)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Low-energy molecular conformers generation (MCG) is a foundational yet challenging problem in drug discovery. Denoising-based methods include diffusion and flow-matching methods that learn mappings from a simple base distribution to the molecular conformer distribution. However, these approaches often suffer from error accumulation during sampling, especially in the low SNR steps, which are hard to train. To address these challenges, we propose a flow-matching refiner for the MCG task. The proposed method initializes sampling from mixed-quality outputs produced by upstream denoising models and reschedules the noise scale to bypass the low-SNR phase, thereby improving sample quality. On the GEOM-QM9 and GEOM-Drugs benchmark datasets, the generator-refiner pipeline improves quality with fewer total denoising steps while preserving diversity.</li>
</ul>

<h3>Title: RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection</h3>
<ul>
<li><strong>Authors: </strong>Yuxin Wen, Arman Zharmagambetov, Ivan Evtimov, Narine Kokhlikyan, Tom Goldstein, Kamalika Chaudhuri, Chuan Guo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04885">https://arxiv.org/abs/2510.04885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04885">https://arxiv.org/pdf/2510.04885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04885]] RL Is a Hammer and LLMs Are Nails: A Simple Reinforcement Learning Recipe for Strong Prompt Injection(https://arxiv.org/abs/2510.04885)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Prompt injection poses a serious threat to the reliability and safety of LLM agents. Recent defenses against prompt injection, such as Instruction Hierarchy and SecAlign, have shown notable robustness against static attacks. However, to more thoroughly evaluate the robustness of these defenses, it is arguably necessary to employ strong attacks such as automated red-teaming. To this end, we introduce RL-Hammer, a simple recipe for training attacker models that automatically learn to perform strong prompt injections and jailbreaks via reinforcement learning. RL-Hammer requires no warm-up data and can be trained entirely from scratch. To achieve high ASRs against industrial-level models with defenses, we propose a set of practical techniques that enable highly effective, universal attacks. Using this pipeline, RL-Hammer reaches a 98% ASR against GPT-4o and a $72\%$ ASR against GPT-5 with the Instruction Hierarchy defense. We further discuss the challenge of achieving high diversity in attacks, highlighting how attacker models tend to reward-hack diversity objectives. Finally, we show that RL-Hammer can evade multiple prompt injection detectors. We hope our work advances automatic red-teaming and motivates the development of stronger, more principled defenses. Code is available at this https URL.</li>
</ul>

<h3>Title: Revealing Interconnections between Diseases: from Statistical Methods to Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alina Ermilova, Dmitrii Kornilov, Sofia Samoilova, Ekaterina Laptenkova, Anastasia Kolesnikova, Ekaterina Podplutova, Senotrusova Sofya, Maksim G. Sharaev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04888">https://arxiv.org/abs/2510.04888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04888">https://arxiv.org/pdf/2510.04888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04888]] Revealing Interconnections between Diseases: from Statistical Methods to Large Language Models(https://arxiv.org/abs/2510.04888)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Identifying disease interconnections through manual analysis of large-scale clinical data is labor-intensive, subjective, and prone to expert disagreement. While machine learning (ML) shows promise, three critical challenges remain: (1) selecting optimal methods from the vast ML landscape, (2) determining whether real-world clinical data (e.g., electronic health records, EHRs) or structured disease descriptions yield more reliable insights, (3) the lack of "ground truth," as some disease interconnections remain unexplored in medicine. Large language models (LLMs) demonstrate broad utility, yet they often lack specialized medical knowledge. To address these gaps, we conduct a systematic evaluation of seven approaches for uncovering disease relationships based on two data sources: (i) sequences of ICD-10 codes from MIMIC-IV EHRs and (ii) the full set of ICD-10 codes, both with and without textual descriptions. Our framework integrates the following: (i) a statistical co-occurrence analysis and a masked language modeling (MLM) approach using real clinical data; (ii) domain-specific BERT variants (Med-BERT and BioClinicalBERT); (iii) a general-purpose BERT and document retrieval; and (iv) four LLMs (Mistral, DeepSeek, Qwen, and YandexGPT). Our graph-based comparison of the obtained interconnection matrices shows that the LLM-based approach produces interconnections with the lowest diversity of ICD code connections to different diseases compared to other methods, including text-based and domain-based approaches. This suggests an important implication: LLMs have limited potential for discovering new interconnections. In the absence of ground truth databases for medical interconnections between ICD codes, our results constitute a valuable medical disease ontology that can serve as a foundational resource for future clinical research and artificial intelligence applications in healthcare.</li>
</ul>

<h3>Title: SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests</h3>
<ul>
<li><strong>Authors: </strong>Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea, Zhijing Jin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04891">https://arxiv.org/abs/2510.04891</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04891">https://arxiv.org/pdf/2510.04891</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04891]] SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests(https://arxiv.org/abs/2510.04891)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in contexts where their failures can have direct sociopolitical consequences. Yet, existing safety benchmarks rarely test vulnerabilities in domains such as political manipulation, propaganda and disinformation generation, or surveillance and information control. We introduce SocialHarmBench, a dataset of 585 prompts spanning 7 sociopolitical categories and 34 countries, designed to surface where LLMs most acutely fail in politically charged contexts. Our evaluations reveal several shortcomings: open-weight models exhibit high vulnerability to harmful compliance, with Mistral-7B reaching attack success rates as high as 97% to 98% in domains such as historical revisionism, propaganda, and political manipulation. Moreover, temporal and geographic analyses show that LLMs are most fragile when confronted with 21st-century or pre-20th-century contexts, and when responding to prompts tied to regions such as Latin America, the USA, and the UK. These findings demonstrate that current safeguards fail to generalize to high-stakes sociopolitical settings, exposing systematic biases and raising concerns about the reliability of LLMs in preserving human rights and democratic values. We share the SocialHarmBench benchmark at this https URL.</li>
</ul>

<h3>Title: Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models</h3>
<ul>
<li><strong>Authors: </strong>Nick Janßen, Melanie Schaller, Bodo Rosenhahn</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04900">https://arxiv.org/abs/2510.04900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04900">https://arxiv.org/pdf/2510.04900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04900]] Benchmarking M-LTSF: Frequency and Noise-Based Evaluation of Multivariate Long Time Series Forecasting Models(https://arxiv.org/abs/2510.04900)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Understanding the robustness of deep learning models for multivariate long-term time series forecasting (M-LTSF) remains challenging, as evaluations typically rely on real-world datasets with unknown noise properties. We propose a simulation-based evaluation framework that generates parameterizable synthetic datasets, where each dataset instance corresponds to a different configuration of signal components, noise types, signal-to-noise ratios, and frequency characteristics. These configurable components aim to model real-world multivariate time series data without the ambiguity of unknown noise. This framework enables fine-grained, systematic evaluation of M-LTSF models under controlled and diverse scenarios. We benchmark four representative architectures S-Mamba (state-space), iTransformer (transformer-based), R-Linear (linear), and Autoformer (decomposition-based). Our analysis reveals that all models degrade severely when lookback windows cannot capture complete periods of seasonal patters in the data. S-Mamba and Autoformer perform best on sawtooth patterns, while R-Linear and iTransformer favor sinusoidal signals. White and Brownian noise universally degrade performance with lower signal-to-noise ratio while S-Mamba shows specific trend-noise and iTransformer shows seasonal-noise vulnerability. Further spectral analysis shows that S-Mamba and iTransformer achieve superior frequency reconstruction. This controlled approach, based on our synthetic and principle-driven testbed, offers deeper insights into model-specific strengths and limitations through the aggregation of MSE scores and provides concrete guidance for model selection based on signal characteristics and noise conditions.</li>
</ul>

<h3>Title: DP-HYPE: Distributed Differentially Private Hyperparameter Search</h3>
<ul>
<li><strong>Authors: </strong>Johannes Liebenow, Thorsten Peinemann, Esfandiar Mohammadi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04902">https://arxiv.org/abs/2510.04902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04902">https://arxiv.org/pdf/2510.04902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04902]] DP-HYPE: Distributed Differentially Private Hyperparameter Search(https://arxiv.org/abs/2510.04902)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The tuning of hyperparameters in distributed machine learning can substantially impact model performance. When the hyperparameters are tuned on sensitive data, privacy becomes an important challenge and to this end, differential privacy has emerged as the de facto standard for provable privacy. A standard setting when performing distributed learning tasks is that clients agree on a shared setup, i.e., find a compromise from a set of hyperparameters, like the learning rate of the model to be trained. Yet, prior work on differentially private hyperparameter tuning either uses computationally expensive cryptographic protocols, determines hyperparameters separately for each client, or applies differential privacy locally, which can lead to undesirable utility-privacy trade-offs. In this work, we present our algorithm DP-HYPE, which performs a distributed and privacy-preserving hyperparameter search by conducting a distributed voting based on local hyperparameter evaluations of clients. In this way, DP-HYPE selects hyperparameters that lead to a compromise supported by the majority of clients, while maintaining scalability and independence from specific learning tasks. We prove that DP-HYPE preserves the strong notion of differential privacy called client-level differential privacy and, importantly, show that its privacy guarantees do not depend on the number of hyperparameters. We also provide bounds on its utility guarantees, that is, the probability of reaching a compromise, and implement DP-HYPE as a submodule in the popular Flower framework for distributed machine learning. In addition, we evaluate performance on multiple benchmark data sets in iid as well as multiple non-iid settings and demonstrate high utility of DP-HYPE even under small privacy budgets.</li>
</ul>

<h3>Title: A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images</h3>
<ul>
<li><strong>Authors: </strong>Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04916">https://arxiv.org/abs/2510.04916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04916">https://arxiv.org/pdf/2510.04916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04916]] A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images(https://arxiv.org/abs/2510.04916)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning has become increasingly important in remote sensing image classification due to its ability to extract semantic information from complex data. Classification tasks often include predefined label hierarchies that represent the semantic relationships among classes. However, these hierarchies are frequently overlooked, and most approaches focus only on fine-grained classification schemes. In this paper, we present a novel Semantics-Aware Hierarchical Consensus (SAHC) method for learning hierarchical features and relationships by integrating hierarchy-specific classification heads within a deep network architecture, each specialized in different degrees of class granularity. The proposed approach employs trainable hierarchy matrices, which guide the network through the learning of the hierarchical structure in a self-supervised manner. Furthermore, we introduce a hierarchical consensus mechanism to ensure consistent probability distributions across different hierarchical levels. This mechanism acts as a weighted ensemble being able to effectively leverage the inherent structure of the hierarchical classification task. The proposed SAHC method is evaluated on three benchmark datasets with different degrees of hierarchical complexity on different tasks, using distinct backbone architectures to effectively emphasize its adaptability. Experimental results show both the effectiveness of the proposed approach in guiding network learning and the robustness of the hierarchical consensus for remote sensing image classification tasks.</li>
</ul>

<h3>Title: Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment</h3>
<ul>
<li><strong>Authors: </strong>Davood Rafiei, Morgan Lindsay Heisler, Weiwei Zhang, Mohammadreza Pourreza, Yong Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04919">https://arxiv.org/abs/2510.04919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04919">https://arxiv.org/pdf/2510.04919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04919]] Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment(https://arxiv.org/abs/2510.04919)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised Fine-Tuning (SFT) is an effective method for adapting Large Language Models (LLMs) on downstream tasks. However, variability in training data can hinder a model's ability to generalize across domains. This paper studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or text to SQL), examining how well SFT training data matches the structural characteristics of target queries and how this alignment impacts model performance. We hypothesize that alignment can be accurately estimated by comparing the distributions of structural SQL features across the training set, target data, and the model's predictions prior to SFT. Through comprehensive experiments on three large cross-domain NL2SQL benchmarks and multiple model families, we show that structural alignment is a strong predictor of fine-tuning success. When alignment is high, SFT yields substantial gains in accuracy and SQL generation quality; when alignment is low, improvements are marginal or absent. These findings highlight the importance of alignment-aware data selection for effective fine-tuning and generalization in NL2SQL tasks.</li>
</ul>

<h3>Title: REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R. Scott Budinger, Anthony J. Esposito, Alexander Misharin, Alok Choudhary, Ankit Agrawal, Ulas Bagci</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04923">https://arxiv.org/abs/2510.04923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04923">https://arxiv.org/pdf/2510.04923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04923]] REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis(https://arxiv.org/abs/2510.04923)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) architectures have significantly contributed to scalable machine learning by enabling specialized subnetworks to tackle complex tasks efficiently. However, traditional MoE systems lack domain-specific constraints essential for medical imaging, where anatomical structure and regional disease heterogeneity strongly influence pathological patterns. Here, we introduce Regional Expert Networks (REN), the first anatomically-informed MoE framework tailored specifically for medical image classification. REN leverages anatomical priors to train seven specialized experts, each dedicated to distinct lung lobes and bilateral lung combinations, enabling precise modeling of region-specific pathological variations. Multi-modal gating mechanisms dynamically integrate radiomics biomarkers and deep learning (DL) features (CNN, ViT, Mamba) to weight expert contributions optimally. Applied to interstitial lung disease (ILD) classification, REN achieves consistently superior performance: the radiomics-guided ensemble reached an average AUC of 0.8646 +/- 0.0467, a +12.5 percent improvement over the SwinUNETR baseline (AUC 0.7685, p = 0.031). Region-specific experts further revealed that lower-lobe models achieved AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79) and aligning with known disease progression patterns. Through rigorous patient-level cross-validation, REN demonstrates strong generalizability and clinical interpretability, presenting a scalable, anatomically-guided approach readily extensible to other structured medical imaging applications.</li>
</ul>

<h3>Title: Federated Self-Supervised Learning for Automatic Modulation Classification under Non-IID and Class-Imbalanced Data</h3>
<ul>
<li><strong>Authors: </strong>Usman Akram, Yiyue Chen, Haris Vikalo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04927">https://arxiv.org/abs/2510.04927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04927">https://arxiv.org/pdf/2510.04927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04927]] Federated Self-Supervised Learning for Automatic Modulation Classification under Non-IID and Class-Imbalanced Data(https://arxiv.org/abs/2510.04927)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Training automatic modulation classification (AMC) models on centrally aggregated data raises privacy concerns, incurs communication overhead, and often fails to confer robustness to channel shifts. Federated learning (FL) avoids central aggregation by training on distributed clients but remains sensitive to class imbalance, non-IID client distributions, and limited labeled samples. We propose FedSSL-AMC, which trains a causal, time-dilated CNN with triplet-loss self-supervision on unlabeled I/Q sequences across clients, followed by per-client SVMs on small labeled sets. We establish convergence of the federated representation learning procedure and a separability guarantee for the downstream classifier under feature noise. Experiments on synthetic and over-the-air datasets show consistent gains over supervised FL baselines under heterogeneous SNR, carrier-frequency offsets, and non-IID label partitions.</li>
</ul>

<h3>Title: The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Amir Hameed Mir</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IT, cs.LG, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04933">https://arxiv.org/abs/2510.04933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04933">https://arxiv.org/pdf/2510.04933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04933]] The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models(https://arxiv.org/abs/2510.04933)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) often produce fluent yet factually incorrect statements-a phenomenon known as hallucination-posing serious risks in high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric framework for hallucination detection that analyzes the evolution of hidden-state semantics across transformer layers. Unlike prior methods that rely on multiple sampling passes or external verification sources, LSD operates intrinsically within the model's representational space. Using margin-based contrastive learning, LSD aligns hidden activations with ground-truth embeddings derived from a factual encoder, revealing a distinct separation in semantic trajectories: factual responses preserve stable alignment, while hallucinations exhibit pronounced semantic drift across depth. Evaluated on the TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming SelfCheckGPT and Semantic Entropy baselines while requiring only a single forward pass. This efficiency yields a 5-20x speedup over sampling-based methods without sacrificing precision or interpretability. LSD offers a scalable, model-agnostic mechanism for real-time hallucination monitoring and provides new insights into the geometry of factual consistency within large language models.</li>
</ul>

<h3>Title: Unsupervised Active Learning via Natural Feature Progressive Framework</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Liu, Catherine Lalman, Yimin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04939">https://arxiv.org/abs/2510.04939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04939">https://arxiv.org/pdf/2510.04939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04939]] Unsupervised Active Learning via Natural Feature Progressive Framework(https://arxiv.org/abs/2510.04939)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The effectiveness of modern deep learning models is predicated on the availability of large-scale, human-annotated datasets, a process that is notoriously expensive and time-consuming. While Active Learning (AL) offers a strategic solution by labeling only the most informative and representative data, its iterative nature still necessitates significant human involvement. Unsupervised Active Learning (UAL) presents an alternative by shifting the annotation burden to a single, post-selection step. Unfortunately, prevailing UAL methods struggle to achieve state-of-the-art performance. These approaches typically rely on local, gradient-based scoring for sample importance estimation, which not only makes them vulnerable to ambiguous and noisy data but also hinders their capacity to select samples that adequately represent the full data distribution. Moreover, their use of shallow, one-shot linear selection falls short of a true UAL paradigm. In this paper, we propose the Natural Feature Progressive Framework (NFPF), a UAL method that revolutionizes how sample importance is measured. At its core, NFPF employs a Specific Feature Learning Machine (SFLM) to effectively quantify each sample's contribution to model performance. We further utilize the SFLM to define a powerful Reconstruction Difference metric for initial sample selection. Our comprehensive experiments show that NFPF significantly outperforms all established UAL methods and achieves performance on par with supervised AL methods on vision datasets. Detailed ablation studies and qualitative visualizations provide compelling evidence for NFPF's superior performance, enhanced robustness, and improved data distribution coverage.</li>
</ul>

<h3>Title: On Structured State-Space Duality</h3>
<ul>
<li><strong>Authors: </strong>Jerry Yao-Chieh Hu, Xiwen Zhang, Weimin Wu, Han Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04944">https://arxiv.org/abs/2510.04944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04944">https://arxiv.org/pdf/2510.04944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04944]] On Structured State-Space Duality(https://arxiv.org/abs/2510.04944)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence between a simple Structured State-Space Model (SSM) and a masked attention mechanism. In particular, a state-space model with a scalar-times-identity state matrix is equivalent to a masked self-attention with a $1$-semiseparable causal mask. Consequently, the same sequence transformation (model) has two algorithmic realizations: as a linear-time $O(T)$ recurrence or as a quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize this duality: (i) we extend SSD from the scalar-identity case to general diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs match the scalar case's training complexity lower bounds while supporting richer dynamics; (iii) we establish a necessary and sufficient condition under which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we show that such duality fails to extend to standard softmax attention due to rank explosion. Together, these results tighten bridge between recurrent SSMs and Transformers, and widen the design space for expressive yet efficient sequence models.</li>
</ul>

<h3>Title: Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04947">https://arxiv.org/abs/2510.04947</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04947">https://arxiv.org/pdf/2510.04947</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04947]] Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion(https://arxiv.org/abs/2510.04947)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Dual-view mammography, including craniocaudal (CC) and mediolateral oblique (MLO) projections, offers complementary anatomical views crucial for breast cancer diagnosis. However, in real-world clinical workflows, one view may be missing, corrupted, or degraded due to acquisition errors or compression artifacts, limiting the effectiveness of downstream analysis. View-to-view translation can help recover missing views and improve lesion alignment. Unlike natural images, this task in mammography is highly challenging due to large non-rigid deformations and severe tissue overlap in X-ray projections, which obscure pixel-level correspondences. In this paper, we propose Column-Aware and Implicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram view translation framework based on conditional diffusion model. To address cross-view structural misalignment, we first design a column-aware cross-attention mechanism that leverages the geometric property that anatomically corresponding regions tend to lie in similar column positions across views. A Gaussian-decayed bias is applied to emphasize local column-wise correlations while suppressing distant mismatches. Furthermore, we introduce an implicit 3D structure reconstruction module that back-projects noisy 2D latents into a coarse 3D feature volume based on breast-view projection geometry. The reconstructed 3D structure is refined and injected into the denoising UNet to guide cross-view generation with enhanced anatomical awareness. Extensive experiments demonstrate that CA3D-Diff achieves superior performance in bidirectional tasks, outperforming state-of-the-art methods in visual fidelity and structural consistency. Furthermore, the synthesized views effectively improve single-view malignancy classification in screening settings, demonstrating the practical value of our method in real-world diagnostics.</li>
</ul>

<h3>Title: Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)</h3>
<ul>
<li><strong>Authors: </strong>Om Dobariya, Akhil Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.NE, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04950">https://arxiv.org/abs/2510.04950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04950">https://arxiv.org/pdf/2510.04950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04950]] Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)(https://arxiv.org/abs/2510.04950)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The wording of natural language prompts has been shown to influence the performance of large language models (LLMs), yet the role of politeness and tone remains underexplored. In this study, we investigate how varying levels of prompt politeness affect model accuracy on multiple-choice questions. We created a dataset of 50 base questions spanning mathematics, science, and history, each rewritten into five tone variants: Very Polite, Polite, Neutral, Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we evaluated responses across these conditions and applied paired sample t-tests to assess statistical significance. Contrary to expectations, impolite prompts consistently outperformed polite ones, with accuracy ranging from 80.8% for Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from earlier studies that associated rudeness with poorer outcomes, suggesting that newer LLMs may respond differently to tonal variation. Our results highlight the importance of studying pragmatic aspects of prompting and raise broader questions about the social dimensions of human-AI interaction.</li>
</ul>

<h3>Title: SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Théophane Vallaeys, Jakob Verbeek, Matthieu Cord</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04961">https://arxiv.org/abs/2510.04961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04961">https://arxiv.org/pdf/2510.04961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04961]] SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization(https://arxiv.org/abs/2510.04961)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Tokenizers are a key component of state-of-the-art generative image models, extracting the most important features from the signal while reducing data dimension and redundancy. Most current tokenizers are based on KL-regularized variational autoencoders (KL-VAE), trained with reconstruction, perceptual and adversarial losses. Diffusion decoders have been proposed as a more principled alternative to model the distribution over images conditioned on the latent. However, matching the performance of KL-VAE still requires adversarial losses, as well as a higher decoding time due to iterative sampling. To address these limitations, we introduce a new pixel diffusion decoder architecture for improved scaling and training stability, benefiting from transformer components and GAN-free training. We use distillation to replicate the performance of the diffusion decoder in an efficient single-step decoder. This makes SSDD the first diffusion decoder optimized for single-step reconstruction trained without adversarial losses, reaching higher reconstruction quality and faster sampling than KL-VAE. In particular, SSDD improves reconstruction FID from $0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generation quality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used as a drop-in replacement for KL-VAE, and for building higher-quality and faster generative models.</li>
</ul>

<h3>Title: ActiveMark: on watermarking of visual foundation models via massive activations</h3>
<ul>
<li><strong>Authors: </strong>Anna Chistyakova, Mikhail Pautov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04966">https://arxiv.org/abs/2510.04966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04966">https://arxiv.org/pdf/2510.04966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04966]] ActiveMark: on watermarking of visual foundation models via massive activations(https://arxiv.org/abs/2510.04966)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, watermark</a></li>
<li><strong>Abstract: </strong>Being trained on large and vast datasets, visual foundation models (VFMs) can be fine-tuned for diverse downstream tasks, achieving remarkable performance and efficiency in various computer vision applications. The high computation cost of data collection and training motivates the owners of some VFMs to distribute them alongside the license to protect their intellectual property rights. However, a dishonest user of the protected model's copy may illegally redistribute it, for example, to make a profit. As a consequence, the development of reliable ownership verification tools is of great importance today, since such methods can be used to differentiate between a redistributed copy of the protected model and an independent model. In this paper, we propose an approach to ownership verification of visual foundation models by fine-tuning a small set of expressive layers of a VFM along with a small encoder-decoder network to embed digital watermarks into an internal representation of a hold-out set of input images. Importantly, the watermarks embedded remain detectable in the functional copies of the protected model, obtained, for example, by fine-tuning the VFM for a particular downstream task. Theoretically and experimentally, we demonstrate that the proposed method yields a low probability of false detection of a non-watermarked model and a low probability of false misdetection of a watermarked model.</li>
</ul>

<h3>Title: StructuralDecompose: A Modular Framework for Robust Time Series Decomposition in R</h3>
<ul>
<li><strong>Authors: </strong>Allen Daniel Sunny</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04974">https://arxiv.org/abs/2510.04974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04974">https://arxiv.org/pdf/2510.04974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04974]] StructuralDecompose: A Modular Framework for Robust Time Series Decomposition in R(https://arxiv.org/abs/2510.04974)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present StructuralDecompose, an R package for modular and interpretable time series decomposition. Unlike existing approaches that treat decomposition as a monolithic process, StructuralDecompose separates the analysis into distinct components: changepoint detection, anomaly detection, smoothing, and decomposition. This design provides flexibility and robust- ness, allowing users to tailor methods to specific time series characteristics. We demonstrate the package on simulated and real-world datasets, benchmark its performance against state-of-the- art tools such as Rbeast and autostsm, and discuss its role in interpretable machine learning workflows.</li>
</ul>

<h3>Title: Federated Computation of ROC and PR Curves</h3>
<ul>
<li><strong>Authors: </strong>Xuefeng Xu, Graham Cormode</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04979">https://arxiv.org/abs/2510.04979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04979">https://arxiv.org/pdf/2510.04979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04979]] Federated Computation of ROC and PR Curves(https://arxiv.org/abs/2510.04979)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are fundamental tools for evaluating machine learning classifiers, offering detailed insights into the trade-offs between true positive rate vs. false positive rate (ROC) or precision vs. recall (PR). However, in Federated Learning (FL) scenarios, where data is distributed across multiple clients, computing these curves is challenging due to privacy and communication constraints. Specifically, the server cannot access raw prediction scores and class labels, which are used to compute the ROC and PR curves in a centralized setting. In this paper, we propose a novel method for approximating ROC and PR curves in a federated setting by estimating quantiles of the prediction score distribution under distributed differential privacy. We provide theoretical bounds on the Area Error (AE) between the true and estimated curves, demonstrating the trade-offs between approximation accuracy, privacy, and communication cost. Empirical results on real-world datasets demonstrate that our method achieves high approximation accuracy with minimal communication and strong privacy guarantees, making it practical for privacy-preserving model evaluation in federated systems.</li>
</ul>

<h3>Title: AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives</h3>
<ul>
<li><strong>Authors: </strong>Khalid Mehtab Khan, Anagha Kulkarni</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04983">https://arxiv.org/abs/2510.04983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04983">https://arxiv.org/pdf/2510.04983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04983]] AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives(https://arxiv.org/abs/2510.04983)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Identifying cultural capital (CC) themes in student reflections can offer valuable insights that help foster equitable learning environments in classrooms. However, themes such as aspirational goals or family support are often woven into narratives, rather than appearing as direct keywords. This makes them difficult to detect for standard NLP models that process sentences in isolation. The core challenge stems from a lack of awareness, as standard models are pre-trained on general corpora, leaving them blind to the domain-specific language and narrative context inherent to the data. To address this, we introduce AWARE, a framework that systematically attempts to improve a transformer model's awareness for this nuanced task. AWARE has three core components: 1) Domain Awareness, adapting the model's vocabulary to the linguistic style of student reflections; 2) Context Awareness, generating sentence embeddings that are aware of the full essay context; and 3) Class Overlap Awareness, employing a multi-label strategy to recognize the coexistence of themes in a single sentence. Our results show that by making the model explicitly aware of the properties of the input, AWARE outperforms a strong baseline by 2.1 percentage points in Macro-F1 and shows considerable improvements across all themes. This work provides a robust and generalizable methodology for any text classification task in which meaning depends on the context of the narrative.</li>
</ul>

<h3>Title: NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection</h3>
<ul>
<li><strong>Authors: </strong>Avilash Rath, Weiliang Qi, Youpeng Li, Xinda Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04987">https://arxiv.org/abs/2510.04987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04987">https://arxiv.org/pdf/2510.04987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04987]] NatGVD: Natural Adversarial Example Attack towards Graph-based Vulnerability Detection(https://arxiv.org/abs/2510.04987)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Graph-based models learn rich code graph structural information and present superior performance on various code analysis tasks. However, the robustness of these models against adversarial example attacks in the context of vulnerability detection remains an open question. This paper proposes NatGVD, a novel attack methodology that generates natural adversarial vulnerable code to circumvent GNN-based and graph-aware transformer-based vulnerability detectors. NatGVD employs a set of code transformations that modify graph structure while preserving code semantics. Instead of injecting dead or unrelated code like previous works, NatGVD considers naturalness requirements: generated examples should not be easily recognized by humans or program analysis tools. With extensive evaluation of NatGVD on state-of-the-art vulnerability detection systems, the results reveal up to 53.04% evasion rate across GNN-based detectors and graph-aware transformer-based detectors. We also explore potential defense strategies to enhance the robustness of these systems against NatGVD.</li>
</ul>

<h3>Title: Power Transform Revisited: Numerically Stable, and Federated</h3>
<ul>
<li><strong>Authors: </strong>Xuefeng Xu, Graham Cormode</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04995">https://arxiv.org/abs/2510.04995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04995">https://arxiv.org/pdf/2510.04995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04995]] Power Transform Revisited: Numerically Stable, and Federated(https://arxiv.org/abs/2510.04995)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Power transforms are popular parametric techniques for making data more Gaussian-like, and are widely used as preprocessing steps in statistical analysis and machine learning. However, we find that direct implementations of power transforms suffer from severe numerical instabilities, which can lead to incorrect results or even crashes. In this paper, we provide a comprehensive analysis of the sources of these instabilities and propose effective remedies. We further extend power transforms to the federated learning setting, addressing both numerical and distributional challenges that arise in this context. Experiments on real-world datasets demonstrate that our methods are both effective and robust, substantially improving stability compared to existing approaches.</li>
</ul>

<h3>Title: Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training</h3>
<ul>
<li><strong>Authors: </strong>Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof Monz, Jiang Bian, Nan Jiang, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.04996">https://arxiv.org/abs/2510.04996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.04996">https://arxiv.org/pdf/2510.04996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.04996]] Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training(https://arxiv.org/abs/2510.04996)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning applied to large language models (LLMs) for reasoning tasks is often bottlenecked by unstable gradient estimates due to fixed and uniform sampling of responses across prompts. Prior work such as GVM-RAFT addresses this by dynamically allocating inference budget per prompt to minimize stochastic gradient variance under a budget constraint. Inspired by this insight, we propose Reinforce-Ada, an adaptive sampling framework for online RL post-training of LLMs that continuously reallocates sampling effort to the prompts with the greatest uncertainty or learning potential. Unlike conventional two-stage allocation methods, Reinforce-Ada interleaves estimation and sampling in an online successive elimination process, and automatically stops sampling for a prompt once sufficient signal is collected. To stabilize updates, we form fixed-size groups with enforced reward diversity and compute advantage baselines using global statistics aggregated over the adaptive sampling phase. Empirical results across multiple model architectures and reasoning benchmarks show that Reinforce-Ada accelerates convergence and improves final performance compared to GRPO, especially when using the balanced sampling variant. Our work highlights the central role of variance-aware, adaptive data curation in enabling efficient and reliable reinforcement learning for reasoning-capable LLMs. Code is available at this https URL.</li>
</ul>

<h3>Title: Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Imran Mansha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05003">https://arxiv.org/abs/2510.05003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05003">https://arxiv.org/pdf/2510.05003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05003]] Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning(https://arxiv.org/abs/2510.05003)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated remarkable reasoning abilities but require significant computational resources for fine-tuning. This paper presents a resource-efficient fine-tuning approach for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating under constrained GPU and memory settings. Using parameter-efficient tuning techniques such as LoRA and QLoRA, we adapt the base model on publicly available medical reasoning datasets. The model achieves improved reasoning coherence and factual accuracy while reducing memory usage by up to 60% compared to standard full fine-tuning. Experimental evaluation demonstrates that lightweight adaptations can retain strong reasoning capability in medical question-answering tasks. This work highlights practical strategies for deploying LLMs in low-resource research environments and provides insights into balancing efficiency and domain specialization for medical AI systems.</li>
</ul>

<h3>Title: Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns</h3>
<ul>
<li><strong>Authors: </strong>Nabil Daiyan, Md Rakibul Haque</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05015">https://arxiv.org/abs/2510.05015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05015">https://arxiv.org/pdf/2510.05015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05015]] Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns(https://arxiv.org/abs/2510.05015)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease (PD) is a progressive neurodegenerative condition characterized by the death of dopaminergic neurons, leading to various movement disorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects, yet traditional diagnostic methods are often cumbersome and costly. In this study, a machine learning-based approach is proposed using hand-drawn spiral and wave images as potential biomarkers for PD detection. Our methodology leverages convolutional neural networks (CNNs), transfer learning, and attention mechanisms to improve model performance and resilience against overfitting. To enhance the diversity and richness of both spiral and wave categories, the training dataset undergoes augmentation to increase the number of images. The proposed architecture comprises three phases: utilizing pre-trained CNNs, incorporating custom convolutional layers, and ensemble voting. Employing hard voting further enhances performance by aggregating predictions from multiple models. Experimental results show promising accuracy rates. For spiral images, weighted average precision, recall, and F1-score are 90%, and for wave images, they are 96.67%. After combining the predictions through ensemble hard voting, the overall accuracy is 93.3%. These findings underscore the potential of machine learning in early PD diagnosis, offering a non-invasive and cost-effective solution to improve patient outcomes.</li>
</ul>

<h3>Title: Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment</h3>
<ul>
<li><strong>Authors: </strong>Nevan Wichers, Aram Ebtekar, Ariana Azarbal, Victor Gillioz, Christine Ye, Emil Ryd, Neil Rathi, Henry Sleight, Alex Mallen, Fabien Roger, Samuel Marks</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05024">https://arxiv.org/abs/2510.05024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05024">https://arxiv.org/pdf/2510.05024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05024]] Inoculation Prompting: Instructing LLMs to misbehave at train-time improves test-time alignment(https://arxiv.org/abs/2510.05024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are sometimes trained with imperfect oversight signals, leading to undesired behaviors such as reward hacking and sycophancy. Improving oversight quality can be expensive or infeasible, motivating methods that improve learned behavior despite an imperfect training signal. We introduce Inoculation Prompting (IP), a simple but counterintuitive technique that prevents learning of an undesired behavior by modifying training prompts to explicitly request it. For example, to inoculate against reward hacking, we modify the prompts used in supervised fine-tuning to request code that only works on provided test cases but fails on other inputs. Across four settings we find that IP reduces the learning of undesired behavior without substantially reducing the learning of desired capabilities. We also show that prompts which more strongly elicit the undesired behavior prior to fine-tuning more effectively inoculate against the behavior when used during training; this serves as a heuristic to identify promising inoculation prompts. Overall, IP is a simple yet effective way to control how models generalize from fine-tuning, preventing learning of undesired behaviors without substantially disrupting desired capabilities.</li>
</ul>

<h3>Title: Imperceptible Jailbreaking against Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05025">https://arxiv.org/abs/2510.05025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05025">https://arxiv.org/pdf/2510.05025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05025]] Imperceptible Jailbreaking against Large Language Models(https://arxiv.org/abs/2510.05025)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Jailbreaking attacks on the vision modality typically rely on imperceptible adversarial perturbations, whereas attacks on the textual modality are generally assumed to require visible modifications (e.g., non-semantic suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a class of Unicode characters called variation selectors. By appending invisible variation selectors to malicious questions, the jailbreak prompts appear visually identical to original malicious questions on screen, while their tokenization is "secretly" altered. We propose a chain-of-search pipeline to generate such adversarial suffixes to induce harmful responses. Our experiments show that our imperceptible jailbreaks achieve high attack success rates against four aligned LLMs and generalize to prompt injection attacks, all without producing any visible modifications in the written prompt. Our code is available at this https URL.</li>
</ul>

<h3>Title: Graph-Aware Diffusion for Signal Generation</h3>
<ul>
<li><strong>Authors: </strong>Sergio Rozada, Vimal K. B., Andrea Cavallo, Antonio G. Marques, Hadi Jamali-Rad, Elvin Isufi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05036">https://arxiv.org/abs/2510.05036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05036">https://arxiv.org/pdf/2510.05036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05036]] Graph-Aware Diffusion for Signal Generation(https://arxiv.org/abs/2510.05036)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We study the problem of generating graph signals from unknown distributions defined over given graphs, relevant to domains such as recommender systems or sensor networks. Our approach builds on generative diffusion models, which are well established in vision and graph generation but remain underexplored for graph signals. Existing methods lack generality, either ignoring the graph structure in the forward process or designing graph-aware mechanisms tailored to specific domains. We adopt a forward process that incorporates the graph through the heat equation. Rather than relying on the standard formulation, we consider a time-warped coefficient to mitigate the exponential decay of the drift term, yielding a graph-aware generative diffusion model (GAD). We analyze its forward dynamics, proving convergence to a Gaussian Markov random field with covariance parametrized by the graph Laplacian, and interpret the backward dynamics as a sequence of graph-signal denoising problems. Finally, we demonstrate the advantages of GAD on synthetic data, real traffic speed measurements, and a temperature sensor network.</li>
</ul>

<h3>Title: Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts</h3>
<ul>
<li><strong>Authors: </strong>Jihoon Lee, Hoyeon Moon, Kevin Zhai, Arun Kumar Chithanar, Anit Kumar Sahu, Soummya Kar, Chul Lee, Souradip Chakraborty, Amrit Singh Bedi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05040">https://arxiv.org/abs/2510.05040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05040">https://arxiv.org/pdf/2510.05040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05040]] Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive Experts(https://arxiv.org/abs/2510.05040)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion-based large language models (dLLMs) are trained flexibly to model extreme dependence in the data distribution; however, how to best utilize this information at inference time remains an open problem. In this work, we uncover an interesting property of these models: dLLMs trained on textual data implicitly learn a mixture of semi-autoregressive experts, where different generation orders reveal different specialized behaviors. We show that committing to any single, fixed inference time schedule, a common practice, collapses performance by failing to leverage this latent ensemble. To address this, we introduce HEX (Hidden semiautoregressive EXperts for test-time scaling), a training-free inference method that ensembles across heterogeneous block schedules. By doing a majority vote over diverse block-sized generation paths, HEX robustly avoids failure modes associated with any single fixed schedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to 3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and specialized fine-tuned methods like GRPO, without additional training. HEX even yields significant gains on MATH benchmark from 16.40% to 40.00%, scientific reasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%. Our results establish a new paradigm for test-time scaling in diffusion-based LLMs (dLLMs), revealing that the sequence in which masking is performed plays a critical role in determining performance during inference.</li>
</ul>

<h3>Title: COLE: a Comprehensive Benchmark for French Language Understanding Evaluation</h3>
<ul>
<li><strong>Authors: </strong>David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05046">https://arxiv.org/abs/2510.05046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05046">https://arxiv.org/pdf/2510.05046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05046]] COLE: a Comprehensive Benchmark for French Language Understanding Evaluation(https://arxiv.org/abs/2510.05046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To address the need for a more comprehensive evaluation of French Natural Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23 diverse task covering a broad range of NLU capabilities, including sentiment analysis, paraphrase detection, grammatical judgment, and reasoning, with a particular focus on linguistic phenomena relevant to the French language. We benchmark 94 large language models (LLM), providing an extensive analysis of the current state of French NLU. Our results highlight a significant performance gap between closed- and open-weights models and identify key challenging frontiers for current LLMs, such as zero-shot extractive question-answering (QA), fine-grained word sense disambiguation, and understanding of regional language variations. We release COLE as a public resource to foster further progress in French language modelling.</li>
</ul>

<h3>Title: KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Elhussein, Paul Meddeb, Abigail Newbury, Jeanne Mirone, Martin Stoll, Gamze Gursoy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05049">https://arxiv.org/abs/2510.05049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05049">https://arxiv.org/pdf/2510.05049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05049]] KEEP: Integrating Medical Ontologies with Clinical Data for Robust Code Embeddings(https://arxiv.org/abs/2510.05049)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Machine learning in healthcare requires effective representation of structured medical codes, but current methods face a trade off: knowledge graph based approaches capture formal relationships but miss real world patterns, while data driven methods learn empirical associations but often overlook structured knowledge in medical terminologies. We present KEEP (Knowledge preserving and Empirically refined Embedding Process), an efficient framework that bridges this gap by combining knowledge graph embeddings with adaptive learning from clinical data. KEEP first generates embeddings from knowledge graphs, then employs regularized training on patient records to adaptively integrate empirical patterns while preserving ontological relationships. Importantly, KEEP produces final embeddings without task specific auxiliary or end to end training enabling KEEP to support multiple downstream applications and model architectures. Evaluations on structured EHR from UK Biobank and MIMIC IV demonstrate that KEEP outperforms both traditional and Language Model based approaches in capturing semantic relationships and predicting clinical outcomes. Moreover, KEEP's minimal computational requirements make it particularly suitable for resource constrained environments.</li>
</ul>

<h3>Title: SegMASt3R: Geometry Grounded Segment Matching</h3>
<ul>
<li><strong>Authors: </strong>Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05051">https://arxiv.org/abs/2510.05051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05051">https://arxiv.org/pdf/2510.05051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05051]] SegMASt3R: Geometry Grounded Segment Matching(https://arxiv.org/abs/2510.05051)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Segment matching is an important intermediate task in computer vision that establishes correspondences between semantically or geometrically coherent regions across images. Unlike keypoint matching, which focuses on localized features, segment matching captures structured regions, offering greater robustness to occlusions, lighting variations, and viewpoint changes. In this paper, we leverage the spatial understanding of 3D foundation models to tackle wide-baseline segment matching, a challenging setting involving extreme viewpoint shifts. We propose an architecture that uses the inductive bias of these 3D foundation models to match segments across image pairs with up to 180 degree view-point change. Extensive experiments show that our approach outperforms state-of-the-art methods, including the SAM2 video propagator and local feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++ and Replica datasets. We further demonstrate benefits of the proposed model on relevant downstream tasks, including 3D instance segmentation and image-goal navigation. Project Page: this https URL</li>
</ul>

<h3>Title: Proactive defense against LLM Jailbreak</h3>
<ul>
<li><strong>Authors: </strong>Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05052">https://arxiv.org/abs/2510.05052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05052">https://arxiv.org/pdf/2510.05052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05052]] Proactive defense against LLM Jailbreak(https://arxiv.org/abs/2510.05052)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The proliferation of powerful large language models (LLMs) has necessitated robust safety alignment, yet these models remain vulnerable to evolving adversarial attacks, including multi-turn jailbreaks that iteratively search for successful queries. Current defenses, primarily reactive and static, often fail to counter these search-based attacks. In this paper, we introduce ProAct, a novel proactive defense framework designed to disrupt and mislead autonomous jailbreaking processes. Our core idea is to intentionally provide adversaries with "spurious responses" that appear to be results of successful jailbreak attacks but contain no actual harmful content. These misleading responses provide false signals to the attacker's internal optimization loop, causing the adversarial search to terminate prematurely and effectively jailbreaking the jailbreak. By conducting extensive experiments across state-of-the-art LLMs, jailbreaking frameworks, and safety benchmarks, our method consistently and significantly reduces attack success rates by up to 92\%. When combined with other defense frameworks, it further reduces the success rate of the latest attack strategies to 0\%. ProAct represents an orthogonal defense strategy that can serve as an additional guardrail to enhance LLM safety against the most effective jailbreaking attacks.</li>
</ul>

<h3>Title: HybridFlow: Quantification of Aleatoric and Epistemic Uncertainty with a Single Hybrid Model</h3>
<ul>
<li><strong>Authors: </strong>Peter Van Katwyk, Karianne J. Bergen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05054">https://arxiv.org/abs/2510.05054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05054">https://arxiv.org/pdf/2510.05054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05054]] HybridFlow: Quantification of Aleatoric and Epistemic Uncertainty with a Single Hybrid Model(https://arxiv.org/abs/2510.05054)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification is critical for ensuring robustness in high-stakes machine learning applications. We introduce HybridFlow, a modular hybrid architecture that unifies the modeling of aleatoric and epistemic uncertainty by combining a Conditional Masked Autoregressive normalizing flow for estimating aleatoric uncertainty with a flexible probabilistic predictor for epistemic uncertainty. The framework supports integration with any probabilistic model class, allowing users to easily adapt HybridFlow to existing architectures without sacrificing predictive performance. HybridFlow improves upon previous uncertainty quantification frameworks across a range of regression tasks, such as depth estimation, a collection of regression benchmarks, and a scientific case study of ice sheet emulation. We also provide empirical results of the quantified uncertainty, showing that the uncertainty quantified by HybridFlow is calibrated and better aligns with model error than existing methods for quantifying aleatoric and epistemic uncertainty. HybridFlow addresses a key challenge in Bayesian deep learning, unifying aleatoric and epistemic uncertainty modeling in a single robust framework.</li>
</ul>

<h3>Title: Boomerang Distillation Enables Zero-Shot Model Size Interpolation</h3>
<ul>
<li><strong>Authors: </strong>Sara Kangaslahti, Nihal V. Nayak, Jonathan Geuter, Marco Fumero, Francesco Locatello, David Alvarez-Melis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05064">https://arxiv.org/abs/2510.05064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05064">https://arxiv.org/pdf/2510.05064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05064]] Boomerang Distillation Enables Zero-Shot Model Size Interpolation(https://arxiv.org/abs/2510.05064)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are typically deployed under diverse memory and compute constraints. Existing approaches build model families by training each size independently, which is prohibitively expensive and provides only coarse-grained size options. In this work, we identify a novel phenomenon that we call boomerang distillation: starting from a large base model (the teacher), one first distills down to a small student and then progressively reconstructs intermediate-sized models by re-incorporating blocks of teacher layers into the student without any additional training. This process produces zero-shot interpolated models of many intermediate sizes whose performance scales smoothly between the student and teacher, often matching or surpassing pretrained or distilled models of the same size. We further analyze when this type of interpolation succeeds, showing that alignment between teacher and student through pruning and distillation is essential. Boomerang distillation thus provides a simple and efficient way to generate fine-grained model families, dramatically reducing training cost while enabling flexible adaptation across deployment environments. The code and models are available at this https URL.</li>
</ul>

<h3>Title: SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Dachuan Shi, Abedelkadir Asi, Keying Li, Xiangchi Yuan, Leyan Pan, Wenke Lee, Wen Xiao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05069">https://arxiv.org/abs/2510.05069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05069">https://arxiv.org/pdf/2510.05069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05069]] SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs(https://arxiv.org/abs/2510.05069)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work shows that, beyond discrete reasoning through explicit chain-of-thought steps, which are limited by the boundaries of natural languages, large language models (LLMs) can also reason continuously in latent space, allowing richer information per step and thereby improving token efficiency. Despite this promise, latent reasoning still faces two challenges, especially in training-free settings: 1) purely latent reasoning broadens the search distribution by maintaining multiple implicit paths, which diffuses probability mass, introduces noise, and impedes convergence to a single high-confidence solution, thereby hurting accuracy; and 2) overthinking persists even without explicit text, wasting tokens and degrading efficiency. To address these issues, we introduce SwiReasoning, a training-free framework for LLM reasoning which features two key innovations: 1) SwiReasoning dynamically switches between explicit and latent reasoning, guided by block-wise confidence estimated from entropy trends in next-token distributions, to balance exploration and exploitation and promote timely convergence. 2) By limiting the maximum number of thinking-block switches, SwiReasoning curbs overthinking and improves token efficiency across varying problem difficulties. On widely used mathematics and STEM benchmarks, SwiReasoning consistently improves average accuracy by 1.5%-2.8% across reasoning LLMs of different model families and scales. Furthermore, under constrained budgets, SwiReasoning improves average token efficiency by 56%-79%, with larger gains as budgets tighten.</li>
</ul>

<h3>Title: Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces</h3>
<ul>
<li><strong>Authors: </strong>Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05071">https://arxiv.org/abs/2510.05071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05071">https://arxiv.org/pdf/2510.05071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05071]] Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces(https://arxiv.org/abs/2510.05071)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Efficient and accurate classification of waste and industrial surface defects is essential for ensuring sustainable waste management and maintaining high standards in quality control. This paper introduces the Neuroplastic Modular Classifier, a novel hybrid architecture designed for robust and adaptive image classification in dynamic environments. The model combines a ResNet-50 backbone for localized feature extraction with a Vision Transformer (ViT) to capture global semantic context. Additionally, FAISS-based similarity retrieval is incorporated to provide a memory-like reference to previously encountered data, enriching the model's feature space. A key innovation of our architecture is the neuroplastic modular design composed of expandable, learnable blocks that dynamically grow during training when performance plateaus. Inspired by biological learning systems, this mechanism allows the model to adapt to data complexity over time, improving generalization. Beyond garbage classification, we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2), which involves industrial defect detection on metal surfaces. Experimental results across domains show that the proposed architecture outperforms traditional static models in both accuracy and adaptability. The Neuroplastic Modular Classifier offers a scalable, high-performance solution for real-world image classification, with strong applicability in both environmental and industrial domains.</li>
</ul>

<h3>Title: TeachLM: Post-Training LLMs for Education Using Authentic Learning Data</h3>
<ul>
<li><strong>Authors: </strong>Janos Perczel, Jin Chow, Dorottya Demszky</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05087">https://arxiv.org/abs/2510.05087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05087">https://arxiv.org/pdf/2510.05087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05087]] TeachLM: Post-Training LLMs for Education Using Authentic Learning Data(https://arxiv.org/abs/2510.05087)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, generative, large language model</a></li>
<li><strong>Abstract: </strong>The promise of generative AI to revolutionize education is constrained by the pedagogical limits of large language models (LLMs). A major issue is the lack of access to high-quality training data that reflect the learning of actual students. Prompt engineering has emerged as a stopgap, but the ability of prompts to encode complex pedagogical strategies in rule-based natural language is inherently limited. To address this gap we introduce TeachLM - an LLM optimized for teaching through parameter-efficient fine-tuning of state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000 hours of one-on-one, longitudinal student-tutor interactions maintained by Polygence, which underwent a rigorous anonymization process to protect privacy. We use parameter-efficient fine-tuning to develop an authentic student model that enables the generation of high-fidelity synthetic student-tutor dialogues. Building on this capability, we propose a novel multi-turn evaluation protocol that leverages synthetic dialogue generation to provide fast, scalable, and reproducible assessments of the dialogical capabilities of LLMs. Our evaluations demonstrate that fine-tuning on authentic learning data significantly improves conversational and pedagogical performance - doubling student talk time, improving questioning style, increasing dialogue turns by 50%, and greater personalization of instruction.</li>
</ul>

<h3>Title: Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Runchu Tian, Junxia Cui, Xueqiang Xu, Feng Yao, Jingbo Shang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05090">https://arxiv.org/abs/2510.05090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05090">https://arxiv.org/pdf/2510.05090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05090]] Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models(https://arxiv.org/abs/2510.05090)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs) have recently emerged as a promising alternative to autoregressive (AR) models, offering advantages such as accelerated parallel decoding and bidirectional context modeling. However, the vanilla decoding strategy in discrete dLLMs suffers from a critical limitation: once a token is accepted, it can no longer be revised in subsequent steps. As a result, early mistakes persist across iterations, harming both intermediate predictions and final output quality. To address this issue, we propose Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding strategy that leverages cross-validation among predicted tokens. Unlike existing methods that follow a single progressive unmasking procedure, Tolerator introduces a two-stage process: (i) sequence fill-up and (ii) iterative refinement by remasking and decoding a subset of tokens while treating the remaining as context. This design enables previously accepted tokens to be reconsidered and corrected when necessary, leading to more reliable diffusion decoding outputs. We evaluate Tolerator on five standard benchmarks covering language understanding, code generation, and mathematics. Experiments show that our method achieves consistent improvements over the baselines under the same computational budget. These findings suggest that decoding algorithms are crucial to realizing the full potential of diffusion large language models. Code and data are publicly available.</li>
</ul>

<h3>Title: Character Mixing for Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05093">https://arxiv.org/abs/2510.05093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05093">https://arxiv.org/pdf/2510.05093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05093]] Character Mixing for Video Generation(https://arxiv.org/abs/2510.05093)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where characters interact naturally across different worlds? We study inter-character interaction in text-to-video generation, where the key challenge is to preserve each character's identity and behaviors while enabling coherent cross-context interaction. This is difficult because characters may never have coexisted and because mixing styles often causes style delusion, where realistic characters appear cartoonish or vice versa. We introduce a framework that tackles these issues with Cross-Character Embedding (CCE), which learns identity and behavioral logic across multimodal sources, and Cross-Character Augmentation (CCA), which enriches training with synthetic co-existence and mixed-style data. Together, these techniques allow natural interactions between previously uncoexistent characters without losing stylistic fidelity. Experiments on a curated benchmark of cartoons and live-action series with 10 characters show clear improvements in identity preservation, interaction quality, and robustness to style delusion, enabling new forms of generative this http URL results and videos are available on our project page: this https URL.</li>
</ul>

<h3>Title: TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration</h3>
<ul>
<li><strong>Authors: </strong>Cheng Xin, Fan Xu, Xin Ding, Jie Gao, Jiaxin Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CG, math.AT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.05102">https://arxiv.org/abs/2510.05102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.05102">https://arxiv.org/pdf/2510.05102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.05102]] TopInG: Topologically Interpretable Graph Learning via Persistent Rationale Filtration(https://arxiv.org/abs/2510.05102)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have shown remarkable success across various scientific fields, yet their adoption in critical decision-making is often hindered by a lack of interpretability. Recently, intrinsically interpretable GNNs have been studied to provide insights into model predictions by identifying rationale substructures in graphs. However, existing methods face challenges when the underlying rationale subgraphs are complex and varied. In this work, we propose TopInG: Topologically Interpretable Graph Learning, a novel topological framework that leverages persistent homology to identify persistent rationale subgraphs. TopInG employs a rationale filtration learning approach to model an autoregressive generation process of rationale subgraphs, and introduces a self-adjusted topological constraint, termed topological discrepancy, to enforce a persistent topological distinction between rationale subgraphs and irrelevant counterparts. We provide theoretical guarantees that our loss function is uniquely optimized by the ground truth under specific conditions. Extensive experiments demonstrate TopInG's effectiveness in tackling key challenges, such as handling variform rationale subgraphs, balancing predictive performance with interpretability, and mitigating spurious correlations. Results show that our approach improves upon state-of-the-art methods on both predictive accuracy and interpretation quality.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
