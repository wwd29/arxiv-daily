<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-01-23</h1>
<h3>Title: CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer and Metric Learning</h3>
<ul>
<li><strong>Authors: </strong>Eunjee Choi, Junhyun Ahn, XinYu Piao, Jong-Kook Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12422">https://arxiv.org/abs/2501.12422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12422">https://arxiv.org/pdf/2501.12422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12422]] CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer and Metric Learning(https://arxiv.org/abs/2501.12422)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Fake News Detection has received increasing attention recently. Existing methods rely on independently encoded unimodal data and overlook the advantages of capturing intra-modality relationships and integrating inter-modal similarities using advanced techniques. To address these issues, Cross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News Detection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models (BLIP2) as encoders to capture detailed text, image and combined image-text representations. The metric learning module employs a proxy anchor method to capture intra-modality relationships while the feature fusion module uses a Cross-Modal and Tri-Transformer for effective integration. The final fake news detector processes the fused features through a classifier to predict the authenticity of the content. Experiments on datasets show that CroMe excels in multimodal fake news detection.</li>
</ul>

<h3>Title: SafePowerGraph-HIL: Real-Time HIL Validation of Heterogeneous GNNs for Bridging Sim-to-Real Gap in Power Grids</h3>
<ul>
<li><strong>Authors: </strong>Aoxiang Ma, Salah Ghamizi, Jun Cao, Pedro Rodriguez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12427">https://arxiv.org/abs/2501.12427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12427">https://arxiv.org/pdf/2501.12427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12427]] SafePowerGraph-HIL: Real-Time HIL Validation of Heterogeneous GNNs for Bridging Sim-to-Real Gap in Power Grids(https://arxiv.org/abs/2501.12427)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As machine learning (ML) techniques gain prominence in power system research, validating these methods' effectiveness under real-world conditions requires real-time hardware-in-the-loop (HIL) simulations. HIL simulation platforms enable the integration of computational models with physical devices, allowing rigorous testing across diverse scenarios critical to system resilience and reliability. In this study, we develop a SafePowerGraph-HIL framework that utilizes HIL simulations on the IEEE 9-bus system, modeled in Hypersim, to generate high-fidelity data, which is then transmitted in real-time via SCADA to an AWS cloud database before being input into a Heterogeneous Graph Neural Network (HGNN) model designed for power system state estimation and dynamic analysis. By leveraging Hypersim's capabilities, we simulate complex grid interactions, providing a robust dataset that captures critical parameters for HGNN training. The trained HGNN is subsequently validated using newly generated data under varied system conditions, demonstrating accuracy and robustness in predicting power system states. The results underscore the potential of integrating HIL with advanced neural network architectures to enhance the real-time operational capabilities of power systems. This approach represents a significant advancement toward the development of intelligent, adaptive control strategies that support the robustness and resilience of evolving power grids.</li>
</ul>

<h3>Title: SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiaocheng Zhang, Zhuangzhuang Ye, GuoPing Zhao, Jianing Wang, Xiaohong Su</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12430">https://arxiv.org/abs/2501.12430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12430">https://arxiv.org/pdf/2501.12430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12430]] SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection(https://arxiv.org/abs/2501.12430)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In fraud detection, fraudsters often interact with many benign users, camouflaging their features or relations to hide themselves. Most existing work concentrates solely on either feature camouflage or relation camouflage, or decoupling feature learning and relation learning to avoid the two camouflage from affecting each other. However, this inadvertently neglects the valuable information derived from features or relations, which could mutually enhance their adversarial camouflage strategies. In response to this gap, we propose SCFCRC, a Transformer-based fraud detector that Simultaneously Counteract Feature Camouflage and Relation Camouflage. SCFCRC consists of two components: Feature Camouflage Filter and Relation Camouflage Refiner. The feature camouflage filter utilizes pseudo labels generated through label propagation to train the filter and uses contrastive learning that combines instance-wise and prototype-wise to improve the quality of features. The relation camouflage refiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations graph into multiple substructures and divide and conquer them to mitigate the degradation of detection performance caused by relation camouflage. Furthermore, we introduce a regularization method for MoE to enhance the robustness of the model. Extensive experiments on two fraud detection benchmark datasets demonstrate that our method outperforms state-of-the-art baselines.</li>
</ul>

<h3>Title: Modality Interactive Mixture-of-Experts for Fake News Detection</h3>
<ul>
<li><strong>Authors: </strong>Yifan Liu, Yaokun Liu, Zelin Li, Ruichen Yao, Yang Zhang, Dong Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12431">https://arxiv.org/abs/2501.12431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12431">https://arxiv.org/pdf/2501.12431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12431]] Modality Interactive Mixture-of-Experts for Fake News Detection(https://arxiv.org/abs/2501.12431)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>The proliferation of fake news on social media platforms disproportionately impacts vulnerable populations, eroding trust, exacerbating inequality, and amplifying harmful narratives. Detecting fake news in multimodal contexts -- where deceptive content combines text and images -- is particularly challenging due to the nuanced interplay between modalities. Existing multimodal fake news detection methods often emphasize cross-modal consistency but ignore the complex interactions between text and visual elements, which may complement, contradict, or independently influence the predicted veracity of a post. To address these challenges, we present Modality Interactive Mixture-of-Experts for Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Experts framework designed to enhance multimodal fake news detection by explicitly modeling modality interactions through an interaction gating mechanism. Our approach models modality interactions by evaluating two key aspects of modality interactions: unimodal prediction agreement and semantic alignment. The hierarchical structure of MIMoE-FND allows for distinct learning pathways tailored to different fusion scenarios, adapting to the unique characteristics of each modality interaction. By tailoring fusion strategies to diverse modality interaction scenarios, MIMoE-FND provides a more robust and nuanced approach to multimodal fake news detection. We evaluate our approach on three real-world benchmarks spanning two languages, demonstrating its superior performance compared to state-of-the-art methods. By enhancing the accuracy and interpretability of fake news detection, MIMoE-FND offers a promising tool to mitigate the spread of misinformation, with the potential to better safeguard vulnerable communities against its harmful effects.</li>
</ul>

<h3>Title: Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation</h3>
<ul>
<li><strong>Authors: </strong>Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12432">https://arxiv.org/abs/2501.12432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12432">https://arxiv.org/pdf/2501.12432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12432]] Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation(https://arxiv.org/abs/2501.12432)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although current Large Language Models (LLMs) exhibit impressive capabilities, performing complex real-world tasks still requires tool learning. Mainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to interact with external environments, but they are limited in perceptual scope and lack adequate task-planning capability. To address these limitations, other studies introduce the first Search-based Decision Tree (DFSDT), which still suffers from the high computational cost. In this paper, we introduce a novel parallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama). First, we transform traditional tree-based tool search paths into Directed Acyclic Graph (DAG) structure, generating a high-quality parallel tool invocation dataset. The DTA-Llama is then trained on the dataset to learn to iteratively divide the current task into several parallel tool invocation sub-tasks and aggregate the invocation results to decide the next actions. Furthermore, we introduce an efficient inference framework inspired by the Process/Threads mechanism when applying the DTA-Llama to practical tasks. Experimental results show that our approach substantially enhances task performance while reducing token consumption and inference time. Llama2-7B, using our method, is comparable to the official parallel function calling method of GPT-3.5. The relevant code, dataset, and model weights are available at this https URL</li>
</ul>

<h3>Title: Enhancing Retrosynthesis with Conformer: A Template-Free Method</h3>
<ul>
<li><strong>Authors: </strong>Jiaxi Zhuang, Qian Zhang, Ying Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12434">https://arxiv.org/abs/2501.12434</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12434">https://arxiv.org/pdf/2501.12434</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12434]] Enhancing Retrosynthesis with Conformer: A Template-Free Method(https://arxiv.org/abs/2501.12434)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Retrosynthesis plays a crucial role in the fields of organic synthesis and drug development, where the goal is to identify suitable reactants that can yield a target product molecule. Although existing methods have achieved notable success, they typically overlook the 3D conformational details and internal spatial organization of molecules. This oversight makes it challenging to predict reactants that conform to genuine chemical principles, particularly when dealing with complex molecular structures, such as polycyclic and heteroaromatic compounds. In response to this challenge, we introduce a novel transformer-based, template-free approach that incorporates 3D conformer data and spatial information. Our approach includes an Atom-align Fusion module that integrates 3D positional data at the input stage, ensuring correct alignment between atom tokens and their respective 3D coordinates. Additionally, we propose a Distance-weighted Attention mechanism that refines the self-attention process, constricting the model s focus to relevant atom pairs in 3D space. Extensive experiments on the USPTO-50K dataset demonstrate that our model outperforms previous template-free methods, setting a new benchmark for the field. A case study further highlights our method s ability to predict reasonable and accurate reactants.</li>
</ul>

<h3>Title: Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications</h3>
<ul>
<li><strong>Authors: </strong>Shubhi Asthana, Bing Zhang, Ruchi Mahindru, Chad DeLuca, Anna Lisa Gentile, Sandeep Gopisetty</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12456">https://arxiv.org/abs/2501.12456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12456">https://arxiv.org/pdf/2501.12456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12456]] Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications(https://arxiv.org/abs/2501.12456)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>The adoption of Large Language Models (LLMs) has revolutionized AI applications but poses significant challenges in safeguarding user privacy. Ensuring compliance with privacy regulations such as GDPR and CCPA while addressing nuanced privacy risks requires robust and scalable frameworks. This paper presents a detailed study of OneShield Privacy Guard, a framework designed to mitigate privacy risks in user inputs and LLM outputs across enterprise and open-source settings. We analyze two real-world deployments:(1) a multilingual privacy-preserving system integrated with Data and Model Factory, focusing on enterprise-scale data governance; and (2) PR Insights, an open-source repository emphasizing automated triaging and community-driven refinements. In Deployment 1, OneShield achieved a 0.95 F1 score in detecting sensitive entities like dates, names, and phone numbers across 26 languages, outperforming state-of-the-art tool such as StarPII and Presidio by up to 12\%. Deployment 2, with an average F1 score of 0.86, reduced manual effort by over 300 hours in three months, accurately flagging 8.25\% of 1,256 pull requests for privacy risks with enhanced context sensitivity. These results demonstrate OneShield's adaptability and efficacy in diverse environments, offering actionable insights for context-aware entity recognition, automated compliance, and ethical AI adoption. This work advances privacy-preserving frameworks, supporting user trust and compliance across operational contexts.</li>
</ul>

<h3>Title: Adaptive PII Mitigation Framework for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shubhi Asthana, Ruchi Mahindru, Bing Zhang, Jorge Sanz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12465">https://arxiv.org/abs/2501.12465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12465">https://arxiv.org/pdf/2501.12465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12465]] Adaptive PII Mitigation Framework for Large Language Models(https://arxiv.org/abs/2501.12465)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI) faces growing challenges from evolving data protection laws and enforcement practices worldwide. Regulations like GDPR and CCPA impose strict compliance requirements on Machine Learning (ML) models, especially concerning personal data use. These laws grant individuals rights such as data correction and deletion, complicating the training and deployment of Large Language Models (LLMs) that rely on extensive datasets. Public data availability does not guarantee its lawful use for ML, amplifying these challenges. This paper introduces an adaptive system for mitigating risk of Personally Identifiable Information (PII) and Sensitive Personal Information (SPI) in LLMs. It dynamically aligns with diverse regulatory frameworks and integrates seamlessly into Governance, Risk, and Compliance (GRC) systems. The system uses advanced NLP techniques, context-aware analysis, and policy-driven masking to ensure regulatory compliance. Benchmarks highlight the system's effectiveness, with an F1 score of 0.95 for Passport Numbers, outperforming tools like Microsoft Presidio (0.33) and Amazon Comprehend (0.54). In human evaluations, the system achieved an average user trust score of 4.6/5, with participants acknowledging its accuracy and transparency. Observations demonstrate stricter anonymization under GDPR compared to CCPA, which permits pseudonymization and user opt-outs. These results validate the system as a scalable and robust solution for enterprise privacy compliance.</li>
</ul>

<h3>Title: The Journey Matters: Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Tian Jin, Ahmed Imtiaz Humayun, Utku Evci, Suvinay Subramanian, Amir Yazdanbakhsh, Dan Alistarh, Gintare Karolina Dziugaite</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12486">https://arxiv.org/abs/2501.12486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12486">https://arxiv.org/pdf/2501.12486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12486]] The Journey Matters: Average Parameter Count over Pre-training Unifies Sparse and Dense Scaling Laws(https://arxiv.org/abs/2501.12486)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Pruning eliminates unnecessary parameters in neural networks; it offers a promising solution to the growing computational demands of large language models (LLMs). While many focus on post-training pruning, sparse pre-training--which combines pruning and pre-training into a single phase--provides a simpler alternative. In this work, we present the first systematic exploration of optimal sparse pre-training configurations for LLMs through an examination of 80 unique pruning schedules across different sparsity levels and training durations. We find that initiating pruning at 25% of total training compute and concluding at 75% achieves near-optimal final evaluation loss. These findings provide valuable insights for efficient and effective sparse pre-training of LLMs. Furthermore, we propose a new scaling law that modifies the Chinchilla scaling law to use the average parameter count over pre-training. Through empirical and theoretical validation, we demonstrate that this modified scaling law accurately models evaluation loss for both sparsely and densely pre-trained LLMs, unifying scaling laws across pre-training paradigms. Our findings indicate that while sparse pre-training achieves the same final model quality as dense pre-training for equivalent compute budgets, it provides substantial benefits through reduced model size, enabling significant potential computational savings during inference.</li>
</ul>

<h3>Title: Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting</h3>
<ul>
<li><strong>Authors: </strong>Josh Bruegger, Diana Ioana Catana, Vanja Macovaz, Matias Valdenegro-Toro, Matthia Sabatelli, Marco Zullich</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12489">https://arxiv.org/abs/2501.12489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12489">https://arxiv.org/pdf/2501.12489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12489]] Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting(https://arxiv.org/abs/2501.12489)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The attribution of the author of an art piece is typically a laborious manual process, usually relying on subjective evaluations of expert figures. However, there are some situations in which quantitative features of the artwork can support these evaluations. The extraction of these features can sometimes be automated, for instance, with the use of Machine Learning (ML) techniques. An example of these features is represented by repeated, mechanically impressed patterns, called punches, present chiefly in 13th and 14th-century panel paintings from Tuscany. Previous research in art history showcased a strong connection between the shapes of punches and specific artists or workshops, suggesting the possibility of using these quantitative cues to support the attribution. In the present work, we first collect a dataset of large-scale images of these panel paintings. Then, using YOLOv10, a recent and popular object detection model, we train a ML pipeline to perform object detection on the punches contained in the images. Due to the large size of the images, the detection procedure is split across multiple frames by adopting a sliding-window approach with overlaps, after which the predictions are combined for the whole image using a custom non-maximal suppression routine. Our results indicate how art historians working in the field can reliably use our method for the identification and extraction of punches.</li>
</ul>

<h3>Title: Robustness of Selected Learning Models under Label-Flipping Attack</h3>
<ul>
<li><strong>Authors: </strong>Sarvagya Bhargava, Mark Stamp</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12516">https://arxiv.org/abs/2501.12516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12516">https://arxiv.org/pdf/2501.12516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12516]] Robustness of Selected Learning Models under Label-Flipping Attack(https://arxiv.org/abs/2501.12516)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>In this paper we compare traditional machine learning and deep learning models trained on a malware dataset when subjected to adversarial attack based on label-flipping. Specifically, we investigate the robustness of Support Vector Machines (SVM), Random Forest, Gaussian Naive Bayes (GNB), Gradient Boosting Machine (GBM), LightGBM, XGBoost, Multilayer Perceptron (MLP), Convolutional Neural Network (CNN), MobileNet, and DenseNet models when facing varying percentages of misleading labels. We empirically assess the the accuracy of each of these models under such an adversarial attack on the training data. This research aims to provide insights into which models are inherently more robust, in the sense of being better able to resist intentional disruptions to the training data. We find wide variation in the robustness of the models tested to adversarial attack, with our MLP model achieving the best combination of initial accuracy and robustness.</li>
</ul>

<h3>Title: Topology of Out-of-Distribution Examples in Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Esha Datta, Johanna Hennig, Eva Domschot, Connor Mattes, Michael R. Smith</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12522">https://arxiv.org/abs/2501.12522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12522">https://arxiv.org/pdf/2501.12522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12522]] Topology of Out-of-Distribution Examples in Deep Neural Networks(https://arxiv.org/abs/2501.12522)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As deep neural networks (DNNs) become increasingly common, concerns about their robustness do as well. A longstanding problem for deployed DNNs is their behavior in the face of unfamiliar inputs; specifically, these models tend to be overconfident and incorrect when encountering out-of-distribution (OOD) examples. In this work, we present a topological approach to characterizing OOD examples using latent layer embeddings from DNNs. Our goal is to identify topological features, referred to as landmarks, that indicate OOD examples. We conduct extensive experiments on benchmark datasets and a realistic DNN model, revealing a key insight for OOD detection. Well-trained DNNs have been shown to induce a topological simplification on training data for simple models and datasets; we show that this property holds for realistic, large-scale test and training data, but does not hold for OOD examples. More specifically, we find that the average lifetime (or persistence) of OOD examples is statistically longer than that of training or test examples. This indicates that DNNs struggle to induce topological simplification on unfamiliar inputs. Our empirical results provide novel evidence of topological simplification in realistic DNNs and lay the groundwork for topologically-informed OOD detection strategies.</li>
</ul>

<h3>Title: Federated Discrete Denoising Diffusion Model for Molecular Generation with OpenFL</h3>
<ul>
<li><strong>Authors: </strong>Kevin Ta, Patrick Foley, Mattson Thieme, Abhishek Pandey, Prashant Shah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12523">https://arxiv.org/abs/2501.12523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12523">https://arxiv.org/pdf/2501.12523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12523]] Federated Discrete Denoising Diffusion Model for Molecular Generation with OpenFL(https://arxiv.org/abs/2501.12523)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, diffusion</a></li>
<li><strong>Abstract: </strong>Generating unique molecules with biochemically desired properties to serve as viable drug candidates is a difficult task that requires specialized domain expertise. In recent years, diffusion models have shown promising results in accelerating the drug design process through AI-driven molecular generation. However, training these models requires massive amounts of data, which are often isolated in proprietary silos. OpenFL is a federated learning framework that enables privacy-preserving collaborative training across these decentralized data sites. In this work, we present a federated discrete denoising diffusion model that was trained using OpenFL. The federated model achieves comparable performance with a model trained on centralized data when evaluating the uniqueness and validity of the generated molecules. This demonstrates the utility of federated learning in the drug design process. OpenFL is available at: this https URL</li>
</ul>

<h3>Title: How Does the Spatial Distribution of Pre-training Data Affect Geospatial Foundation Models?</h3>
<ul>
<li><strong>Authors: </strong>Mirali Purohit, Gedeon Muhawenayo, Esther Rolf, Hannah Kerner</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12535">https://arxiv.org/abs/2501.12535</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12535">https://arxiv.org/pdf/2501.12535</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12535]] How Does the Spatial Distribution of Pre-training Data Affect Geospatial Foundation Models?(https://arxiv.org/abs/2501.12535)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models have made rapid advances in many domains including Earth observation, where Geospatial Foundation Models (GFMs) can help address global challenges such as climate change, agriculture, and disaster response. Previous work on GFMs focused on tailoring model architecture and pre-text tasks, and did not investigate the impact of pre-training data selection on model performance. However, recent works from other domains show that the pre-training data distribution is an important factor influencing the performance of the foundation models. With this motivation, our research explores how the geographic distribution of pre-training data affects the performance of GFMs. We evaluated several pre-training data distributions by sampling different compositions from a global data pool. Our experiments with two GFMs on downstream tasks indicate that balanced and globally representative data compositions often outperform region-specific sampling, highlighting the importance of diversity and global coverage in pre-training data. Our results suggest that the most appropriate data sampling technique may depend on the specific GFM architecture. These findings will support the development of robust GFMs by incorporating quality pre-training data distributions, ultimately improving machine learning solutions for Earth observation.</li>
</ul>

<h3>Title: Enhancing Privacy in the Early Detection of Sexual Predators Through Federated Learning and Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Khaoula Chehbouni, Martine De Cock, Gilles Caporossi, Afaf Taik, Reihaneh Rabbany, Golnoosh Farnadi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12537">https://arxiv.org/abs/2501.12537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12537">https://arxiv.org/pdf/2501.12537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12537]] Enhancing Privacy in the Early Detection of Sexual Predators Through Federated Learning and Differential Privacy(https://arxiv.org/abs/2501.12537)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>The increased screen time and isolation caused by the COVID-19 pandemic have led to a significant surge in cases of online grooming, which is the use of strategies by predators to lure children into sexual exploitation. Previous efforts to detect grooming in industry and academia have involved accessing and monitoring private conversations through centrally-trained models or sending private conversations to a global server. In this work, we implement a privacy-preserving pipeline for the early detection of sexual predators. We leverage federated learning and differential privacy in order to create safer online spaces for children while respecting their privacy. We investigate various privacy-preserving implementations and discuss their benefits and shortcomings. Our extensive evaluation using real-world data proves that privacy and utility can coexist with only a slight reduction in utility.</li>
</ul>

<h3>Title: Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition</h3>
<ul>
<li><strong>Authors: </strong>Juan Andres Medina Florez, Shaina Raza, Rashida Lynn, Zahra Shakeri, Brendan T. Smith, Elham Dolatabadi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12538">https://arxiv.org/abs/2501.12538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12538">https://arxiv.org/pdf/2501.12538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12538]] Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition(https://arxiv.org/abs/2501.12538)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding the prevalence, disparities, and symptom variations of Post COVID-19 Condition (PCC) for vulnerable populations is crucial to improving care and addressing intersecting inequities. This study aims to develop a comprehensive framework for integrating social determinants of health (SDOH) into PCC research by leveraging NLP techniques to analyze disparities and variations in SDOH representation within PCC case reports. Following construction of a PCC Case Report Corpus, comprising over 7,000 case reports from the LitCOVID repository, a subset of 709 reports were annotated with 26 core SDOH-related entity types using pre-trained named entity recognition (NER) models, human review, and data augmentation to improve quality, diversity and representation of entity types. An NLP pipeline integrating NER, natural language inference (NLI), trigram and frequency analyses was developed to extract and analyze these entities. Both encoder-only transformer models and RNN-based models were assessed for the NER objective. Fine-tuned encoder-only BERT models outperformed traditional RNN-based models in generalizability to distinct sentence structures and greater class sparsity. Exploratory analysis revealed variability in entity richness, with prevalent entities like condition, age, and access to care, and underrepresentation of sensitive categories like race and housing status. Trigram analysis highlighted frequent co-occurrences among entities, including age, gender, and condition. The NLI objective (entailment and contradiction analysis) showed attributes like "Experienced violence or abuse" and "Has medical insurance" had high entailment rates (82.4%-80.3%), while attributes such as "Is female-identifying," "Is married," and "Has a terminal condition" exhibited high contradiction rates (70.8%-98.5%).</li>
</ul>

<h3>Title: Comparative Approaches to Sentiment Analysis Using Datasets in Major European and Arabic Languages</h3>
<ul>
<li><strong>Authors: </strong>Mikhail Krasitskii, Olga Kolesnikova, Liliana Chanona Hernandez, Grigori Sidorov, Alexander Gelbukh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12540">https://arxiv.org/abs/2501.12540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12540">https://arxiv.org/pdf/2501.12540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12540]] Comparative Approaches to Sentiment Analysis Using Datasets in Major European and Arabic Languages(https://arxiv.org/abs/2501.12540)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This study explores transformer-based models such as BERT, mBERT, and XLM-R for multi-lingual sentiment analysis across diverse linguistic structures. Key contributions include the identification of XLM-R superior adaptability in morphologically complex languages, achieving accuracy levels above 88%. The work highlights fine-tuning strategies and emphasizes their significance for improving sentiment classification in underrepresented languages.</li>
</ul>

<h3>Title: Human-like conceptual representations emerge from language prediction</h3>
<ul>
<li><strong>Authors: </strong>Ningyu Xu, Qi Zhang, Chao Du, Qiang Luo, Xipeng Qiu, Xuanjing Huang, Menghan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12547">https://arxiv.org/abs/2501.12547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12547">https://arxiv.org/pdf/2501.12547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12547]] Human-like conceptual representations emerge from language prediction(https://arxiv.org/abs/2501.12547)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) provide a new opportunity to address the long-standing question of how concepts are represented and organized in the mind, which is central to unravelling the nature of human cognition. Here, we reframed the classic reverse dictionary task to simulate human concept inference in context and investigated the emergence of human-like conceptual representations within LLMs. We found that LLMs were able to infer concepts from definitional descriptions and construct representation spaces that converge towards a shared, context-independent structure. These representations effectively predicted human behavioural judgments and aligned well with neural activity patterns in the human brain, offering evidence for biological plausibility. These findings demonstrate that human-like conceptual representations and organization can naturally emerge from language prediction, even without real-world grounding. Our work supports the view that LLMs serve as valuable tools for understanding complex human cognition and paves the way for better alignment between artificial and human intelligence.</li>
</ul>

<h3>Title: ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality</h3>
<ul>
<li><strong>Authors: </strong>Yanming Xiu, Tim Scargill, Maria Gorlatova</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12553">https://arxiv.org/abs/2501.12553</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12553">https://arxiv.org/pdf/2501.12553</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12553]] ViDDAR: Vision Language Model-Based Task-Detrimental Content Detection for Augmented Reality(https://arxiv.org/abs/2501.12553)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In Augmented Reality (AR), virtual content enhances user experience by providing additional information. However, improperly positioned or designed virtual content can be detrimental to task performance, as it can impair users' ability to accurately interpret real-world information. In this paper we examine two types of task-detrimental virtual content: obstruction attacks, in which virtual content prevents users from seeing real-world objects, and information manipulation attacks, in which virtual content interferes with users' ability to accurately interpret real-world information. We provide a mathematical framework to characterize these attacks and create a custom open-source dataset for attack evaluation. To address these attacks, we introduce ViDDAR (Vision language model-based Task-Detrimental content Detector for Augmented Reality), a comprehensive full-reference system that leverages Vision Language Models (VLMs) and advanced deep learning techniques to monitor and evaluate virtual content in AR environments, employing a user-edge-cloud architecture to balance performance with low latency. To the best of our knowledge, ViDDAR is the first system to employ VLMs for detecting task-detrimental content in AR settings. Our evaluation results demonstrate that ViDDAR effectively understands complex scenes and detects task-detrimental content, achieving up to 92.15% obstruction detection accuracy with a detection latency of 533 ms, and an 82.46% information manipulation content detection accuracy with a latency of 9.62 s.</li>
</ul>

<h3>Title: FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling</h3>
<ul>
<li><strong>Authors: </strong>Emir Ceyani, Han Xie, Baturalp Buyukates, Carl Yang, Salman Avestimehr</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12592">https://arxiv.org/abs/2501.12592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12592">https://arxiv.org/pdf/2501.12592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12592]] FedGrAINS: Personalized SubGraph Federated Learning with Adaptive Neighbor Sampling(https://arxiv.org/abs/2501.12592)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate, generative</a></li>
<li><strong>Abstract: </strong>Graphs are crucial for modeling relational and biological data. As datasets grow larger in real-world scenarios, the risk of exposing sensitive information increases, making privacy-preserving training methods like federated learning (FL) essential to ensure data security and compliance with privacy regulations. Recently proposed personalized subgraph FL methods have become the de-facto standard for training personalized Graph Neural Networks (GNNs) in a federated manner while dealing with the missing links across clients' subgraphs due to privacy restrictions. However, personalized subgraph FL faces significant challenges due to the heterogeneity in client subgraphs, such as degree distributions among the nodes, which complicate federated training of graph models. To address these challenges, we propose \textit{FedGrAINS}, a novel data-adaptive and sampling-based regularization method for subgraph FL. FedGrAINS leverages generative flow networks (GFlowNets) to evaluate node importance concerning clients' tasks, dynamically adjusting the message-passing step in clients' GNNs. This adaptation reflects task-optimized sampling aligned with a trajectory balance objective. Experimental results demonstrate that the inclusion of \textit{FedGrAINS} as a regularizer consistently improves the FL performance compared to baselines that do not leverage such regularization.</li>
</ul>

<h3>Title: A Unified Invariant Learning Framework for Graph Classification</h3>
<ul>
<li><strong>Authors: </strong>Yongduo Sui, Jie Sun, Shuyao Wang, Zemin Liu, Qing Cui, Longfei Li, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12595">https://arxiv.org/abs/2501.12595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12595">https://arxiv.org/pdf/2501.12595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12595]] A Unified Invariant Learning Framework for Graph Classification(https://arxiv.org/abs/2501.12595)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Invariant learning demonstrates substantial potential for enhancing the generalization of graph neural networks (GNNs) with out-of-distribution (OOD) data. It aims to recognize stable features in graph data for classification, based on the premise that these features causally determine the target label, and their influence is invariant to changes in distribution. Along this line, most studies have attempted to pinpoint these stable features by emphasizing explicit substructures in the graph, such as masked or attentive subgraphs, and primarily enforcing the invariance principle in the semantic space, i.e., graph representations. However, we argue that focusing only on the semantic space may not accurately identify these stable features. To address this, we introduce the Unified Invariant Learning (UIL) framework for graph classification. It provides a unified perspective on invariant graph learning, emphasizing both structural and semantic invariance principles to identify more robust stable features. In the graph space, UIL adheres to the structural invariance principle by reducing the distance between graphons over a set of stable features across different environments. Simultaneously, to confirm semantic invariance, UIL underscores that the acquired graph representations should demonstrate exemplary performance across diverse environments. We present both theoretical and empirical evidence to confirm our method's ability to recognize superior stable features. Moreover, through a series of comprehensive experiments complemented by in-depth analyses, we demonstrate that UIL considerably enhances OOD generalization, surpassing the performance of leading baseline methods. Our codes are available at this https URL.</li>
</ul>

<h3>Title: Adapting OpenAI's CLIP Model for Few-Shot Image Inspection in Manufacturing Quality Control: An Expository Case Study with Multiple Application Examples</h3>
<ul>
<li><strong>Authors: </strong>Fadel M. Megahed, Ying-Ju Chen, Bianca Maria Colosimo, Marco Luigi Giuseppe Grasso, L. Allison Jones-Farmer, Sven Knoth, Hongyue Sun, Inez Zwetsloot</a></li>
<li><strong>Subjects: </strong>cs.CV, stat.AP, stat.OT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12596">https://arxiv.org/abs/2501.12596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12596">https://arxiv.org/pdf/2501.12596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12596]] Adapting OpenAI's CLIP Model for Few-Shot Image Inspection in Manufacturing Quality Control: An Expository Case Study with Multiple Application Examples(https://arxiv.org/abs/2501.12596)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This expository paper introduces a simplified approach to image-based quality inspection in manufacturing using OpenAI's CLIP (Contrastive Language-Image Pretraining) model adapted for few-shot learning. While CLIP has demonstrated impressive capabilities in general computer vision tasks, its direct application to manufacturing inspection presents challenges due to the domain gap between its training data and industrial applications. We evaluate CLIP's effectiveness through five case studies: metallic pan surface inspection, 3D printing extrusion profile analysis, stochastic textured surface evaluation, automotive assembly inspection, and microstructure image classification. Our results show that CLIP can achieve high classification accuracy with relatively small learning sets (50-100 examples per class) for single-component and texture-based applications. However, the performance degrades with complex multi-component scenes. We provide a practical implementation framework that enables quality engineers to quickly assess CLIP's suitability for their specific applications before pursuing more complex solutions. This work establishes CLIP-based few-shot learning as an effective baseline approach that balances implementation simplicity with robust performance, demonstrated in several manufacturing quality control applications.</li>
</ul>

<h3>Title: BLR-MoE: Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR</h3>
<ul>
<li><strong>Authors: </strong>Guodong Ma, Wenxuan Wang, Lifeng Zhou, Yuting Yang, Yuke Li, Binbin Du</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12602">https://arxiv.org/abs/2501.12602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12602">https://arxiv.org/pdf/2501.12602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12602]] BLR-MoE: Boosted Language-Routing Mixture of Experts for Domain-Robust Multilingual E2E ASR(https://arxiv.org/abs/2501.12602)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, the Mixture of Expert (MoE) architecture, such as LR-MoE, is often used to alleviate the impact of language confusion on the multilingual ASR (MASR) task. However, it still faces language confusion issues, especially in mismatched domain scenarios. In this paper, we decouple language confusion in LR-MoE into confusion in self-attention and router. To alleviate the language confusion in self-attention, based on LR-MoE, we propose to apply attention-MoE architecture for MASR. In our new architecture, MoE is utilized not only on feed-forward network (FFN) but also on self-attention. In addition, to improve the robustness of the LID-based router on language confusion, we propose expert pruning and router augmentation methods. Combining the above, we get the boosted language-routing MoE (BLR-MoE) architecture. We verify the effectiveness of the proposed BLR-MoE in a 10,000-hour MASR dataset.</li>
</ul>

<h3>Title: T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Lijun Li, Zhelun Shi, Xuhao Hu, Bowen Dong, Yiran Qin, Xihui Liu, Lu Sheng, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12612">https://arxiv.org/abs/2501.12612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12612">https://arxiv.org/pdf/2501.12612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12612]] T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in Image Generation(https://arxiv.org/abs/2501.12612)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, defense, fair, diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) models have rapidly advanced, enabling the generation of high-quality images from text prompts across various domains. However, these models present notable safety concerns, including the risk of generating harmful, biased, or private content. Current research on assessing T2I safety remains in its early stages. While some efforts have been made to evaluate models on specific safety dimensions, many critical risks remain unexplored. To address this gap, we introduce T2ISafety, a safety benchmark that evaluates T2I models across three key domains: toxicity, fairness, and bias. We build a detailed hierarchy of 12 tasks and 44 categories based on these three domains, and meticulously collect 70K corresponding prompts. Based on this taxonomy and prompt set, we build a large-scale T2I dataset with 68K manually annotated images and train an evaluator capable of detecting critical risks that previous work has failed to identify, including risks that even ultra-large proprietary models like GPTs cannot correctly detect. We evaluate 12 prominent diffusion models on T2ISafety and reveal several concerns including persistent issues with racial fairness, a tendency to generate toxic content, and significant variation in privacy protection across the models, even with defense methods like concept erasing. Data and evaluator are released under this https URL.</li>
</ul>

<h3>Title: Distillation Quantification for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Jiaheng Liu, Min Yang, Zhoufutu Wen, Shiwen Ni</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12619">https://arxiv.org/abs/2501.12619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12619">https://arxiv.org/pdf/2501.12619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12619]] Distillation Quantification for Large Language Models(https://arxiv.org/abs/2501.12619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Model distillation is a technique for transferring knowledge from large language models (LLMs) to smaller ones, aiming to create resource-efficient yet high-performing models. However, excessive distillation can lead to homogenization, reducing diversity among models and impairing their ability to robustly handle complex or novel tasks. These limitations underscore the need to systematically quantify the distillation process and its impact. In this work, we propose a framework to evaluate and quantify model distillation. Our method addresses two key aspects: (1) Identifying identity cognition contradictions to assess discrepancies in how models perceive and represent identity-related information, and (2) Analyzing multi-granularity response similarities across models to measure the extent of homogenization. Experimental results demonstrate two key insights: (1) Well-known closed-source and open-source LLMs usually exhibit high distillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show higher distillation degrees compared to aligned LLMs. By offering a systematic approach to improve the transparency of LLM data distillation, we call for LLMs with more independent development and more transparent technical reports to improve LLMs' robustness and safety. The code and data are available under this https URL.</li>
</ul>

<h3>Title: Towards Robust Multi-tab Website Fingerprinting</h3>
<ul>
<li><strong>Authors: </strong>Xinhao Deng, Xiyuan Zhao, Qilei Yin, Zhuotao Liu, Qi Li, Mingwei Xu, Ke Xu, Jianping Wu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12622">https://arxiv.org/abs/2501.12622</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12622">https://arxiv.org/pdf/2501.12622</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12622]] Towards Robust Multi-tab Website Fingerprinting(https://arxiv.org/abs/2501.12622)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, transformer</a></li>
<li><strong>Abstract: </strong>Website fingerprinting enables an eavesdropper to determine which websites a user is visiting over an encrypted connection. State-of-the-art website fingerprinting (WF) attacks have demonstrated effectiveness even against Tor-protected network traffic. However, existing WF attacks have critical limitations on accurately identifying websites in multi-tab browsing sessions, where the holistic pattern of individual websites is no longer preserved, and the number of tabs opened by a client is unknown a priori. In this paper, we propose ARES, a novel WF framework natively designed for multi-tab WF attacks. ARES formulates the multi-tab attack as a multi-label classification problem and solves it using the novel Transformer-based models. Specifically, ARES extracts local patterns based on multi-level traffic aggregation features and utilizes the improved self-attention mechanism to analyze the correlations between these local patterns, effectively identifying websites. We implement a prototype of ARES and extensively evaluate its effectiveness using our large-scale datasets collected over multiple months. The experimental results illustrate that ARES achieves optimal performance in several realistic scenarios. Further, ARES remains robust even against various WF defenses.</li>
</ul>

<h3>Title: Toward Model-centric Heterogeneous Federated Graph Learning: A Knowledge-driven Approach</h3>
<ul>
<li><strong>Authors: </strong>Huilin lai, Guang Zeng, Xunkai Li, Xudong Shen, Yinlin Zhu, Ye Luo, Jianwei Lu, Lei Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12624">https://arxiv.org/abs/2501.12624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12624">https://arxiv.org/pdf/2501.12624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12624]] Toward Model-centric Heterogeneous Federated Graph Learning: A Knowledge-driven Approach(https://arxiv.org/abs/2501.12624)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated graph learning (FGL) has emerged as a promising paradigm for collaborative machine learning, enabling multiple parties to jointly train models while preserving the privacy of raw graph data. However, existing FGL methods often overlook the model-centric heterogeneous FGL (MHtFGL) problem, which arises in real-world applications, such as the aggregation of models from different companies with varying scales and architectures. MHtFGL presents an additional challenge: the diversity of client model architectures hampers common learning and integration of graph representations. To address this issue, we propose the Federated Graph Knowledge Collaboration (FedGKC) framework, comprising two key components: Client-side Self-Mutual Knowledge Distillation, which fosters effective knowledge sharing among clients through copilot models; and Server-side Knowledge-Aware Model Aggregation, which enhances model integration by accounting for the knowledge acquired by clients. Experiments on eight benchmark datasets demonstrate that FedGKC achieves an average accuracy improvement of 3.74% over baseline models in MHtFGL scenarios, while also maintaining excellent performance in homogeneous settings.</li>
</ul>

<h3>Title: The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories</h3>
<ul>
<li><strong>Authors: </strong>Raj Sanjay Shah, Sashank Varma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12651">https://arxiv.org/abs/2501.12651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12651">https://arxiv.org/pdf/2501.12651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12651]] The potential -- and the pitfalls -- of using pre-trained language models as cognitive science theories(https://arxiv.org/abs/2501.12651)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Many studies have evaluated the cognitive alignment of Pre-trained Language Models (PLMs), i.e., their correspondence to adult performance across a range of cognitive domains. Recently, the focus has expanded to the developmental alignment of these models: identifying phases during training where improvements in model performance track improvements in children's thinking over development. However, there are many challenges to the use of PLMs as cognitive science theories, including different architectures, different training data modalities and scales, and limited model interpretability. In this paper, we distill lessons learned from treating PLMs, not as engineering artifacts but as cognitive science and developmental science models. We review assumptions used by researchers to map measures of PLM performance to measures of human performance. We identify potential pitfalls of this approach to understanding human thinking, and we end by enumerating criteria for using PLMs as credible accounts of cognition and cognitive development.</li>
</ul>

<h3>Title: Extracting General-use Transformers for Low-resource Languages via Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Jan Christian Blaise Cruz, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12660">https://arxiv.org/abs/2501.12660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12660">https://arxiv.org/pdf/2501.12660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12660]] Extracting General-use Transformers for Low-resource Languages via Knowledge Distillation(https://arxiv.org/abs/2501.12660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we propose the use of simple knowledge distillation to produce smaller and more efficient single-language transformers from Massively Multilingual Transformers (MMTs) to alleviate tradeoffs associated with the use of such in low-resource settings. Using Tagalog as a case study, we show that these smaller single-language models perform on-par with strong baselines in a variety of benchmark tasks in a much more efficient manner. Furthermore, we investigate additional steps during the distillation process that improves the soft-supervision of the target language, and provide a number of analyses and ablations to show the efficacy of the proposed method.</li>
</ul>

<h3>Title: NBDI: A Simple and Efficient Termination Condition for Skill Extraction from Task-Agnostic Demonstrations</h3>
<ul>
<li><strong>Authors: </strong>Myunsoo Kim, Hayeong Lee, Seong-Woong Shim, JunHo Seo, Byung-Jun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12668">https://arxiv.org/abs/2501.12668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12668">https://arxiv.org/pdf/2501.12668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12668]] NBDI: A Simple and Efficient Termination Condition for Skill Extraction from Task-Agnostic Demonstrations(https://arxiv.org/abs/2501.12668)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Intelligent agents are able to make decisions based on different levels of granularity and duration. Recent advances in skill learning enabled the agent to solve complex, long-horizon tasks by effectively guiding the agent in choosing appropriate skills. However, the practice of using fixed-length skills can easily result in skipping valuable decision points, which ultimately limits the potential for further exploration and faster policy learning. In this work, we propose to learn a simple and efficient termination condition that identifies decision points through a state-action novelty module that leverages agent experience data. Our approach, Novelty-based Decision Point Identification (NBDI), outperforms previous baselines in complex, long-horizon tasks, and remains effective even in the presence of significant variations in the environment configurations of downstream tasks, highlighting the importance of decision point identification in skill learning.</li>
</ul>

<h3>Title: EchoLM: Accelerating LLM Serving with Real-time Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Yifan Yu, Yu Gan, Lily Tasi, Nikhil Sarda, Jiaming Shen, Yanqi Zhou, Arvind Krishnamurthy, Fan Lai, Henry M. Levy, David Culler</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12689">https://arxiv.org/abs/2501.12689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12689">https://arxiv.org/pdf/2501.12689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12689]] EchoLM: Accelerating LLM Serving with Real-time Knowledge Distillation(https://arxiv.org/abs/2501.12689)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have excelled in various applications, yet serving them at scale is challenging due to their substantial resource demands and high latency. Our real-world studies reveal that over 60% of user requests to LLMs have semantically similar counterparts, suggesting the potential for knowledge sharing among requests. However, naively caching and reusing past responses leads to large quality degradation. In this paper, we introduce EchoLM, an in-context caching system that leverages historical requests as examples to guide response generation, enabling selective offloading of requests to more efficient LLMs. However, enabling this real-time knowledge transfer leads to intricate tradeoffs between response quality, latency, and system throughput at scale. For a new request, EchoLM identifies similar, high-utility examples and efficiently prepends them to the input for better response. At scale, EchoLM adaptively routes requests to LLMs of varying capabilities, accounting for response quality and serving loads. EchoLM employs a cost-aware cache replay mechanism to improve example quality and coverage offline, maximizing cache utility and runtime efficiency. Evaluations on millions of open-source requests demonstrate that EchoLM has a throughput improvement of 1.4-5.9x while reducing latency by 28-71% without hurting response quality on average.</li>
</ul>

<h3>Title: Combining Knowledge Graph and LLMs for Enhanced Zero-shot Visual Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Qian Tao, Xiaoyang Fan, Yong Xu, Xingquan Zhu, Yufei Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12697">https://arxiv.org/abs/2501.12697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12697">https://arxiv.org/pdf/2501.12697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12697]] Combining Knowledge Graph and LLMs for Enhanced Zero-shot Visual Question Answering(https://arxiv.org/abs/2501.12697)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot visual question answering (ZS-VQA), an emerged critical research area, intends to answer visual questions without providing training samples. Existing research in ZS-VQA has proposed to leverage knowledge graphs or large language models (LLMs), respectively, as external information sources to help VQA model comprehend images and questions. However, LLMs often struggle in accurately interpreting specific question meanings. Meanwhile, although knowledge graph has rich entity relationships, it is challenging to effectively connect entities to individual image content for visual question answers. In this paper, we propose a novel design to combine knowledge graph and LLMs for zero-shot visual question answer. Our approach uses LLMs' powerful understanding capabilities to accurately interpret image content through a strategic question search mechanism. Meanwhile, the knowledge graph is used to expand and connect users' queries to the image content for better visual question answering. An optimization algorithm is further used to determine the optimal weights for the loss functions derived from different information sources, towards a globally optimal set of candidate answers. Experimental results on two benchmark datasets demonstrate that our model achieves state-of-the-art (SOTA) performance. Both source code and benchmark data will be released for public access.</li>
</ul>

<h3>Title: Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression</h3>
<ul>
<li><strong>Authors: </strong>Kai Yoshida, Masahiro Mizukami, Seiya Kawano, Canasai Kruengkrai, Hiroaki Sugiyama, Koichiro Yoshino</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12698">https://arxiv.org/abs/2501.12698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12698">https://arxiv.org/pdf/2501.12698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12698]] Training Dialogue Systems by AI Feedback for Improving Overall Dialogue Impression(https://arxiv.org/abs/2501.12698)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To improve user engagement during conversations with dialogue systems, we must improve individual dialogue responses and dialogue impressions such as consistency, personality, and empathy throughout the entire dialogue. While such dialogue systems have been developing rapidly with the help of large language models (LLMs), reinforcement learning from AI feedback (RLAIF) has attracted attention to align LLM-based dialogue models for such dialogue impressions. In RLAIF, a reward model based on another LLM is used to create a training signal for an LLM-based dialogue model using zero-shot/few-shot prompting techniques. However, evaluating an entire dialogue only by prompting LLMs is challenging. In this study, the supervised fine-tuning (SFT) of LLMs prepared reward models corresponding to 12 metrics related to the impression of the entire dialogue for evaluating dialogue responses. We tuned our dialogue models using the reward model signals as feedback to improve the impression of the system. The results of automatic and human evaluations showed that tuning the dialogue model using our reward model corresponding to dialogue impression improved the evaluation of individual metrics and the naturalness of the dialogue response.</li>
</ul>

<h3>Title: REX: Causal Discovery based on Machine Learning and Explainability techniques</h3>
<ul>
<li><strong>Authors: </strong>Jesus Renero, Idoia Ochoa, Roberto Maestre</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12706">https://arxiv.org/abs/2501.12706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12706">https://arxiv.org/pdf/2501.12706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12706]] REX: Causal Discovery based on Machine Learning and Explainability techniques(https://arxiv.org/abs/2501.12706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability</a></li>
<li><strong>Abstract: </strong>Explainability techniques hold significant potential for enhancing the causal discovery process, which is crucial for understanding complex systems in areas like healthcare, economics, and artificial intelligence. However, no causal discovery methods currently incorporate explainability into their models to derive causal graphs. Thus, in this paper we explore this innovative approach, as it offers substantial potential and represents a promising new direction worth investigating. Specifically, we introduce REX, a causal discovery method that leverages machine learning (ML) models coupled with explainability techniques, specifically Shapley values, to identify and interpret significant causal relationships among variables. Comparative evaluations on synthetic datasets comprising continuous tabular data reveal that REX outperforms state-of-the-art causal discovery methods across diverse data generation processes, including non-linear and additive noise models. Moreover, REX was tested on the Sachs single-cell protein-signaling dataset, achieving a precision of 0.952 and recovering key causal relationships with no incorrect edges. Taking together, these results showcase REX's effectiveness in accurately recovering true causal structures while minimizing false positive predictions, its robustness across diverse datasets, and its applicability to real-world problems. By combining ML and explainability techniques with causal discovery, REX bridges the gap between predictive modeling and causal inference, offering an effective tool for understanding complex causal structures. REX is publicly available at this https URL.</li>
</ul>

<h3>Title: Anomaly Detection in Double-entry Bookkeeping Data by Federated Learning System with Non-model Sharing Approach</h3>
<ul>
<li><strong>Authors: </strong>Sota Mashiko, Yuji Kawamata, Tomoru Nakayama, Tetsuya Sakurai, Yukihiko Okada</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12723">https://arxiv.org/abs/2501.12723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12723">https://arxiv.org/pdf/2501.12723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12723]] Anomaly Detection in Double-entry Bookkeeping Data by Federated Learning System with Non-model Sharing Approach(https://arxiv.org/abs/2501.12723)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, federate</a></li>
<li><strong>Abstract: </strong>Anomaly detection is crucial in financial auditing and effective detection often requires obtaining large volumes of data from multiple organizations. However, confidentiality concerns hinder data sharing among audit firms. Although the federated learning (FL)-based approach, FedAvg, has been proposed to address this challenge, its use of mutiple communication rounds increases its overhead, limiting its practicality. In this study, we propose a novel framework employing Data Collaboration (DC) analysis -- a non-model share-type FL method -- to streamline model training into a single communication round. Our method first encodes journal entry data via dimensionality reduction to obtain secure intermediate representations, then transforms them into collaboration representations for building an autoencoder that detects anomalies. We evaluate our approach on a synthetic dataset and real journal entry data from multiple organizations. The results show that our method not only outperforms single-organization baselines but also exceeds FedAvg in non-i.i.d. experiments on real journal entry data that closely mirror real-world conditions. By preserving data confidentiality and reducing iterative communication, this study addresses a key auditing challenge -- ensuring data confidentiality while integrating knowledge from multiple audit firms. Our findings represent a significant advance in artificial intelligence-driven auditing and underscore the potential of FL methods in high-security domains.</li>
</ul>

<h3>Title: Online Preference Alignment for Language Models via Count-based Exploration</h3>
<ul>
<li><strong>Authors: </strong>Chenjia Bai, Yang Zhang, Shuang Qiu, Qiaosheng Zhang, Kang Xu, Xuelong Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12735">https://arxiv.org/abs/2501.12735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12735">https://arxiv.org/pdf/2501.12735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12735]] Online Preference Alignment for Language Models via Count-based Exploration(https://arxiv.org/abs/2501.12735)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) has shown great potential in fine-tuning Large Language Models (LLMs) to align with human preferences. Existing methods perform preference alignment from a fixed dataset, which can be limited in data coverage, and the resulting reward model is hard to generalize in out-of-distribution responses. Thus, online RLHF is more desirable to empower the LLM to explore outside the support of the initial dataset by iteratively collecting the prompt-response pairs. In this paper, we study the fundamental problem in online RLHF, i.e. \emph{how to explore} for LLM. We give a theoretical motivation in linear reward assumption to show that an optimistic reward with an upper confidence bound (UCB) term leads to a provably efficient RLHF policy. Then, we reformulate our objective to direct preference optimization with an exploration term, where the UCB-term can be converted to a count-based exploration bonus. We further propose a practical algorithm, named \emph{Count-based Online Preference Optimization (COPO)}, which leverages a simple coin-flip counting module to estimate the pseudo-count of a prompt-response pair in previously collected data. COPO encourages LLMs to balance exploration and preference optimization in an iterative manner, which enlarges the exploration space and the entire data coverage of iterative LLM policies. We conduct online RLHF experiments on Zephyr and Llama-3 models. The results on instruction-following and standard academic benchmarks show that COPO significantly increases performance.</li>
</ul>

<h3>Title: Bad-PFL: Exploring Backdoor Attacks against Personalized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Mingyuan Fan, Zhanyi Hu, Fuyi Wang, Cen Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12736">https://arxiv.org/abs/2501.12736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12736">https://arxiv.org/pdf/2501.12736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12736]] Bad-PFL: Exploring Backdoor Attacks against Personalized Federated Learning(https://arxiv.org/abs/2501.12736)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Data heterogeneity and backdoor attacks rank among the most significant challenges facing federated learning (FL). For data heterogeneity, personalized federated learning (PFL) enables each client to maintain a private personalized model to cater to client-specific knowledge. Meanwhile, vanilla FL has proven vulnerable to backdoor attacks. However, recent advancements in PFL community have demonstrated a potential immunity against such attacks. This paper explores this intersection further, revealing that existing federated backdoor attacks fail in PFL because backdoors about manually designed triggers struggle to survive in personalized models. To tackle this, we design Bad-PFL, which employs features from natural data as our trigger. As long as the model is trained on natural data, it inevitably embeds the backdoor associated with our trigger, ensuring its longevity in personalized models. Moreover, our trigger undergoes mutual reinforcement training with the model, further solidifying the backdoor's durability and enhancing attack effectiveness. The large-scale experiments across three benchmark datasets demonstrate the superior performance of our attack against various PFL methods, even when equipped with state-of-the-art defense mechanisms.</li>
</ul>

<h3>Title: Multiscale Training of Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Niloufar Zakariaei, Shadab Ahamed, Eldad Haber, Moshe Eliasof</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12739">https://arxiv.org/abs/2501.12739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12739">https://arxiv.org/pdf/2501.12739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12739]] Multiscale Training of Convolutional Neural Networks(https://arxiv.org/abs/2501.12739)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Convolutional Neural Networks (CNNs) are the backbone of many deep learning methods, but optimizing them remains computationally expensive. To address this, we explore multiscale training frameworks and mathematically identify key challenges, particularly when dealing with noisy inputs. Our analysis reveals that in the presence of noise, the gradient of standard CNNs in multiscale training may fail to converge as the mesh-size approaches to , undermining the optimization process. This insight drives the development of Mesh-Free Convolutions (MFCs), which are independent of input scale and avoid the pitfalls of traditional convolution kernels. We demonstrate that MFCs, with their robust gradient behavior, ensure convergence even with noisy inputs, enabling more efficient neural network optimization in multiscale settings. To validate the generality and effectiveness of our multiscale training approach, we show that (i) MFCs can theoretically deliver substantial computational speedups without sacrificing performance in practice, and (ii) standard convolutions benefit from our multiscale training framework in practice.</li>
</ul>

<h3>Title: EvidenceMap: Unleashing the Power of Small Language Models with Evidence Analysis for Biomedical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Chang Zong, Jian Wan, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12746">https://arxiv.org/abs/2501.12746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12746">https://arxiv.org/pdf/2501.12746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12746]] EvidenceMap: Unleashing the Power of Small Language Models with Evidence Analysis for Biomedical Question Answering(https://arxiv.org/abs/2501.12746)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Current LLM-based approaches improve question answering performance by leveraging the internal reasoning abilities of models or incorporating external knowledge. However, when humans address professional problems, it is essential to explicitly analyze the multifaceted relationships from multiple pieces and diverse sources of evidence to achieve better answers. In this study, we propose a novel generative question answering framework for the biomedical domain, named EvidenceMap, which explicitly learns and incorporates evidence analysis with small language models (SLMs). The framework describes an evidence map for each question and fully utilizes an SLM to derive the representation of the supportive evaluation, the logical correlation, and the summarization of the related evidence, which facilitates an analysis-augmented generation with another SLM in an autoregressive way. Extensive experiments have shown that introducing an evidence analysis learning process can significantly outperform larger models and popular LLM reasoning methods.</li>
</ul>

<h3>Title: Modality Unified Attack for Omni-Modality Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Yuan Bian, Min Liu, Yunqi Yi, Xueping Wang, Yunfeng Ma, Yaonan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12761">https://arxiv.org/abs/2501.12761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12761">https://arxiv.org/pdf/2501.12761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12761]] Modality Unified Attack for Omni-Modality Person Re-Identification(https://arxiv.org/abs/2501.12761)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep learning based person re-identification (re-id) models have been widely employed in surveillance systems. Recent studies have demonstrated that black-box single-modality and cross-modality re-id models are vulnerable to adversarial examples (AEs), leaving the robustness of multi-modality re-id models unexplored. Due to the lack of knowledge about the specific type of model deployed in the target black-box surveillance system, we aim to generate modality unified AEs for omni-modality (single-, cross- and multi-modality) re-id models. Specifically, we propose a novel Modality Unified Attack method to train modality-specific adversarial generators to generate AEs that effectively attack different omni-modality models. A multi-modality model is adopted as the surrogate model, wherein the features of each modality are perturbed by metric disruption loss before fusion. To collapse the common features of omni-modality models, Cross Modality Simulated Disruption approach is introduced to mimic the cross-modality feature embeddings by intentionally feeding images to non-corresponding modality-specific subnetworks of the surrogate model. Moreover, Multi Modality Collaborative Disruption strategy is devised to facilitate the attacker to comprehensively corrupt the informative content of person images by leveraging a multi modality feature collaborative metric disruption loss. Extensive experiments show that our MUA method can effectively attack the omni-modality re-id models, achieving 55.9%, 24.4%, 49.0% and 62.7% mean mAP Drop Rate, respectively.</li>
</ul>

<h3>Title: Intelligent Attacks on Cyber-Physical Systems and Critical Infrastructures</h3>
<ul>
<li><strong>Authors: </strong>Alan Oliveira de Sá, Charles Bezerra Prado, Mariana Luiza Flavio, Luiz F. Rust da C. Carmo</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12762">https://arxiv.org/abs/2501.12762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12762">https://arxiv.org/pdf/2501.12762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12762]] Intelligent Attacks on Cyber-Physical Systems and Critical Infrastructures(https://arxiv.org/abs/2501.12762)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>This chapter provides an overview of the evolving landscape of attacks in cyber-physical systems (CPS) and critical infrastructures, highlighting the possible use of Artificial Intelligence (AI) algorithms to develop intelligent cyberattacks. It describes various existing methods used to carry out intelligent attacks in Operational Technology (OT) environments and discusses AI-driven tools that automate penetration tests in Information Technology (IT) systems, which could potentially be used as attack tools. The chapter also discusses mitigation strategies to counter these emerging intelligent attacks by hindering the learning process of AI-based attacks and points to future research directions on the matter.</li>
</ul>

<h3>Title: NExtLong: Toward Effective Long-Context Training without Long Documents</h3>
<ul>
<li><strong>Authors: </strong>Chaochen Gao, Xing Wu, Zijia Lin, Debing Zhang, Songlin Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12766">https://arxiv.org/abs/2501.12766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12766">https://arxiv.org/pdf/2501.12766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12766]] NExtLong: Toward Effective Long-Context Training without Long Documents(https://arxiv.org/abs/2501.12766)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) with extended context windows have made significant strides yet remain a challenge due to the scarcity of long documents. Existing methods tend to synthesize long-context data but lack a clear mechanism to reinforce the long-range dependency modeling. To address this limitation, we propose NExtLong, a novel framework for synthesizing long-context data through Negative document Extension. NExtLong decomposes a document into multiple meta-chunks and extends the context by interleaving hard negative distractors retrieved from pretraining corpora. This approach compels the model to discriminate long-range dependent context from distracting content, enhancing its ability to model long-range dependencies. Extensive experiments demonstrate that NExtLong achieves significant performance improvements on the HELMET and RULER benchmarks compared to existing long-context synthesis approaches and leading models, which are trained on non-synthetic long documents. These findings highlight NExtLong's ability to reduce reliance on non-synthetic long documents, making it an effective framework for developing advanced long-context LLMs.</li>
</ul>

<h3>Title: LLMs as Repositories of Factual Knowledge: Limitations and Solutions</h3>
<ul>
<li><strong>Authors: </strong>Seyed Mahed Mousavi, Simone Alghisi, Giuseppe Riccardi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12774">https://arxiv.org/abs/2501.12774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12774">https://arxiv.org/pdf/2501.12774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12774]] LLMs as Repositories of Factual Knowledge: Limitations and Solutions(https://arxiv.org/abs/2501.12774)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLMs' sources of knowledge are data snapshots containing factual information about entities collected at different timestamps and from different media types (e.g. wikis, social media, etc.). Such unstructured knowledge is subject to change due to updates through time from past to present. Equally important are the inconsistencies and inaccuracies occurring in different information sources. Consequently, the model's knowledge about an entity may be perturbed while training over the sequence of snapshots or at inference time, resulting in inconsistent and inaccurate model performance. In this work, we study the appropriateness of Large Language Models (LLMs) as repositories of factual knowledge. We consider twenty-four state-of-the-art LLMs that are either closed-, partially (weights), or fully (weight and training data) open-source. We evaluate their reliability in responding to time-sensitive factual questions in terms of accuracy and consistency when prompts are perturbed. We further evaluate the effectiveness of state-of-the-art methods to improve LLMs' accuracy and consistency. We then propose "ENtity-Aware Fine-tuning" (ENAF), a soft neurosymbolic approach aimed at providing a structured representation of entities during fine-tuning to improve the model's performance.</li>
</ul>

<h3>Title: Machine Learning Modeling for Multi-order Human Visual Motion Processing</h3>
<ul>
<li><strong>Authors: </strong>Zitang Sun, Yen-Ju Chen, Yung-Hao Yang, Yuan Li, Shin'ya Nishida</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12810">https://arxiv.org/abs/2501.12810</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12810">https://arxiv.org/pdf/2501.12810</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12810]] Machine Learning Modeling for Multi-order Human Visual Motion Processing(https://arxiv.org/abs/2501.12810)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Our research aims to develop machines that learn to perceive visual motion as do humans. While recent advances in computer vision (CV) have enabled DNN-based models to accurately estimate optical flow in naturalistic images, a significant disparity remains between CV models and the biological visual system in both architecture and behavior. This disparity includes humans' ability to perceive the motion of higher-order image features (second-order motion), which many CV models fail to capture because of their reliance on the intensity conservation law. Our model architecture mimics the cortical V1-MT motion processing pathway, utilizing a trainable motion energy sensor bank and a recurrent graph network. Supervised learning employing diverse naturalistic videos allows the model to replicate psychophysical and physiological findings about first-order (luminance-based) motion perception. For second-order motion, inspired by neuroscientific findings, the model includes an additional sensing pathway with nonlinear preprocessing before motion energy sensing, implemented using a simple multilayer 3D CNN block. When exploring how the brain acquired the ability to perceive second-order motion in natural environments, in which pure second-order signals are rare, we hypothesized that second-order mechanisms were critical when estimating robust object motion amidst optical fluctuations, such as highlights on glossy surfaces. We trained our dual-pathway model on novel motion datasets with varying material properties of moving objects. We found that training to estimate object motion from non-Lambertian materials naturally endowed the model with the capacity to perceive second-order motion, as can humans. The resulting model effectively aligns with biological systems while generalizing to both first- and second-order motion phenomena in natural scenes.</li>
</ul>

<h3>Title: Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments</h3>
<ul>
<li><strong>Authors: </strong>Lafedi Svet, Arthur Brightwell, Augustus Wildflower, Cecily Marshwood</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12811">https://arxiv.org/abs/2501.12811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12811">https://arxiv.org/pdf/2501.12811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12811]] Unveiling Zero-Space Detection: A Novel Framework for Autonomous Ransomware Identification in High-Velocity Environments(https://arxiv.org/abs/2501.12811)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Modern cybersecurity landscapes increasingly demand sophisticated detection frameworks capable of identifying evolving threats with precision and adaptability. The proposed Zero-Space Detection framework introduces a novel approach that dynamically identifies latent behavioral patterns through unsupervised clustering and advanced deep learning techniques. Designed to address the limitations of signature-based and heuristic methods, it operates effectively in high-velocity environments by integrating multi-phase filtering and ensemble learning for refined decision-making. Experimental evaluation reveals high detection rates across diverse ransomware families, including LockBit, Conti, REvil, and BlackMatter, while maintaining low false positive rates and scalable performance. Computational overhead remains minimal, with average processing times ensuring compatibility with real-time systems even under peak operational loads. The framework demonstrates resilience against adversarial strategies such as obfuscation and encryption speed variability, which frequently challenge conventional detection systems. Analysis across multiple data sources highlights its versatility in handling diverse file types and operational contexts. Comprehensive metrics, including detection probability, latency, and resource efficiency, validate its efficacy under real-world conditions. Through its modular architecture, the framework achieves seamless integration with existing cybersecurity infrastructures without significant reconfiguration. The results demonstrate its robustness and scalability, offering a transformative paradigm for ransomware identification in dynamic and resource-constrained environments.</li>
</ul>

<h3>Title: Certified Guidance for Planning with Deep Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Francesco Giacomarra, Mehran Hosseini, Nicola Paoletti, Francesca Cairoli</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12815">https://arxiv.org/abs/2501.12815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12815">https://arxiv.org/pdf/2501.12815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12815]] Certified Guidance for Planning with Deep Generative Models(https://arxiv.org/abs/2501.12815)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep generative models, such as generative adversarial networks and diffusion models, have recently emerged as powerful tools for planning tasks and behavior synthesis in autonomous systems. Various guidance strategies have been introduced to steer the generative process toward outputs that are more likely to satisfy the planning objectives. These strategies avoid the need for model retraining but do not provide any guarantee that the generated outputs will satisfy the desired planning objectives. To address this limitation, we introduce certified guidance, an approach that modifies a generative model, without retraining it, into a new model guaranteed to satisfy a given specification with probability one. We focus on Signal Temporal Logic specifications, which are rich enough to describe nontrivial planning tasks. Our approach leverages neural network verification techniques to systematically explore the latent spaces of the generative models, identifying latent regions that are certifiably correct with respect to the STL property of interest. We evaluate the effectiveness of our method on four planning benchmarks using GANs and diffusion models. Our results confirm that certified guidance produces generative models that are always correct, unlike existing guidance methods that are not certified.</li>
</ul>

<h3>Title: Enhancing Monocular Depth Estimation with Multi-Source Auxiliary Tasks</h3>
<ul>
<li><strong>Authors: </strong>Alessio Quercia, Erenus Yildiz, Zhuo Cao, Kai Krajsek, Abigail Morrison, Ira Assent, Hanno Scharr</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12824">https://arxiv.org/abs/2501.12824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12824">https://arxiv.org/pdf/2501.12824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12824]] Enhancing Monocular Depth Estimation with Multi-Source Auxiliary Tasks(https://arxiv.org/abs/2501.12824)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Monocular depth estimation (MDE) is a challenging task in computer vision, often hindered by the cost and scarcity of high-quality labeled datasets. We tackle this challenge using auxiliary datasets from related vision tasks for an alternating training scheme with a shared decoder built on top of a pre-trained vision foundation model, while giving a higher weight to MDE. Through extensive experiments we demonstrate the benefits of incorporating various in-domain auxiliary datasets and tasks to improve MDE quality on average by ~11%. Our experimental analysis shows that auxiliary tasks have different impacts, confirming the importance of task selection, highlighting that quality gains are not achieved by merely adding data. Remarkably, our study reveals that using semantic segmentation datasets as Multi-Label Dense Classification (MLDC) often results in additional quality gains. Lastly, our method significantly improves the data efficiency for the considered MDE datasets, enhancing their quality while reducing their size by at least 80%. This paves the way for using auxiliary data from related tasks to improve MDE quality despite limited availability of high-quality labeled data. Code is available at this https URL.</li>
</ul>

<h3>Title: Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek</h3>
<ul>
<li><strong>Authors: </strong>John Pavlopoulos, Juli Bakagianni, Kanella Pouli, Maria Gavriilidou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12826">https://arxiv.org/abs/2501.12826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12826">https://arxiv.org/pdf/2501.12826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12826]] Open or Closed LLM for Lesser-Resourced Languages? Lessons from Greek(https://arxiv.org/abs/2501.12826)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Natural Language Processing (NLP) for lesser-resourced languages faces persistent challenges, including limited datasets, inherited biases from high-resource languages, and the need for domain-specific solutions. This study addresses these gaps for Modern Greek through three key contributions. First, we evaluate the performance of open-source (Llama-70b) and closed-source (GPT-4o mini) large language models (LLMs) on seven core NLP tasks with dataset availability, revealing task-specific strengths, weaknesses, and parity in their performance. Second, we expand the scope of Greek NLP by reframing Authorship Attribution as a tool to assess potential data usage by LLMs in pre-training, with high 0-shot accuracy suggesting ethical implications for data provenance. Third, we showcase a legal NLP case study, where a Summarize, Translate, and Embed (STE) methodology outperforms the traditional TF-IDF approach for clustering \emph{long} legal texts. Together, these contributions provide a roadmap to advance NLP in lesser-resourced languages, bridging gaps in model evaluation, task innovation, and real-world impact.</li>
</ul>

<h3>Title: Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home</h3>
<ul>
<li><strong>Authors: </strong>Viktor Moskvoretskii, Maria Lysyuk, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12835">https://arxiv.org/abs/2501.12835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12835">https://arxiv.org/pdf/2501.12835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12835]] Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home(https://arxiv.org/abs/2501.12835)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) improves correctness of Question Answering (QA) and addresses hallucinations in Large Language Models (LLMs), yet greatly increase computational costs. Besides, RAG is not always needed as may introduce irrelevant information. Recent adaptive retrieval methods integrate LLMs' intrinsic knowledge with external information appealing to LLM self-knowledge, but they often neglect efficiency evaluations and comparisons with uncertainty estimation techniques. We bridge this gap by conducting a comprehensive analysis of 35 adaptive retrieval methods, including 8 recent approaches and 27 uncertainty estimation techniques, across 6 datasets using 10 metrics for QA performance, self-knowledge, and efficiency. Our findings show that uncertainty estimation techniques often outperform complex pipelines in terms of efficiency and self-knowledge, while maintaining comparable QA performance.</li>
</ul>

<h3>Title: AMM-Diff: Adaptive Multi-Modality Diffusion Network for Missing Modality Imputation</h3>
<ul>
<li><strong>Authors: </strong>Aghiles Kebaili, Jérôme Lapuyade-Lahorgue, Pierre Vera, Su Ruan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12840">https://arxiv.org/abs/2501.12840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12840">https://arxiv.org/pdf/2501.12840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12840]] AMM-Diff: Adaptive Multi-Modality Diffusion Network for Missing Modality Imputation(https://arxiv.org/abs/2501.12840)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>In clinical practice, full imaging is not always feasible, often due to complex acquisition protocols, stringent privacy regulations, or specific clinical needs. However, missing MR modalities pose significant challenges for tasks like brain tumor segmentation, especially in deep learning-based segmentation, as each modality provides complementary information crucial for improving accuracy. A promising solution is missing data imputation, where absent modalities are generated from available ones. While generative models have been widely used for this purpose, most state-of-the-art approaches are limited to single or dual target translations, lacking the adaptability to generate missing modalities based on varying input configurations. To address this, we propose an Adaptive Multi-Modality Diffusion Network (AMM-Diff), a novel diffusion-based generative model capable of handling any number of input modalities and generating the missing ones. We designed an Image-Frequency Fusion Network (IFFN) that learns a unified feature representation through a self-supervised pretext task across the full input modalities and their selected high-frequency Fourier components. The proposed diffusion model leverages this representation, encapsulating prior knowledge of the complete modalities, and combines it with an adaptive reconstruction strategy to achieve missing modality completion. Experimental results on the BraTS 2021 dataset demonstrate the effectiveness of our approach.</li>
</ul>

<h3>Title: GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ruicheng Zhang, Haowei Guo, Zeyu Zhang, Puxin Yan, Shen Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12844">https://arxiv.org/abs/2501.12844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12844">https://arxiv.org/pdf/2501.12844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12844]] GAMED-Snake: Gradient-aware Adaptive Momentum Evolution Deep Snake Model for Multi-organ Segmentation(https://arxiv.org/abs/2501.12844)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multi-organ segmentation is a critical yet challenging task due to complex anatomical backgrounds, blurred boundaries, and diverse morphologies. This study introduces the Gradient-aware Adaptive Momentum Evolution Deep Snake (GAMED-Snake) model, which establishes a novel paradigm for contour-based segmentation by integrating gradient-based learning with adaptive momentum evolution mechanisms. The GAMED-Snake model incorporates three major innovations: First, the Distance Energy Map Prior (DEMP) generates a pixel-level force field that effectively attracts contour points towards the true boundaries, even in scenarios with complex backgrounds and blurred edges. Second, the Differential Convolution Inception Module (DCIM) precisely extracts comprehensive energy gradients, significantly enhancing segmentation accuracy. Third, the Adaptive Momentum Evolution Mechanism (AMEM) employs cross-attention to establish dynamic features across different iterations of evolution, enabling precise boundary alignment for diverse morphologies. Experimental results on four challenging multi-organ segmentation datasets demonstrate that GAMED-Snake improves the mDice metric by approximately 2% compared to state-of-the-art methods. Code will be available at this https URL.</li>
</ul>

<h3>Title: ACEBench: Who Wins the Match Point in Tool Learning?</h3>
<ul>
<li><strong>Authors: </strong>Chen Chen, Xinlong Hao, Weiwen Liu, Xu Huang, Xingshan Zeng, Shuai Yu, Dexun Li, Shuai Wang, Weinan Gan, Yuefeng Huang, Xinzhi Wang, Defu Lian, Baoqun Yin, Yasheng Wang, Wu Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12851">https://arxiv.org/abs/2501.12851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12851">https://arxiv.org/pdf/2501.12851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12851]] ACEBench: Who Wins the Match Point in Tool Learning?(https://arxiv.org/abs/2501.12851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated significant potential in decision-making and reasoning, especially when combined with various tools to effectively solve complex problems. However, existing evaluation systems for assessing LLM function calling capabilities have several limitations: (1) limited evaluation scenarios, lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, lacking detailed assessments for fine-grained function calls; (3) relying on LLMs or real API executions for result evaluation, which introduces significant overhead. To address these issues, we propose a comprehensive evaluation system named ACEBench. This system is meticulously designed to encompass a wide spectrum of function calling scenarios. Moreover, it categorizes these scenarios into three primary types according to the evaluation methodology: Normal, Special, and Agent. Normal evaluates function calls in basic scenarios; Special evaluates function calls in scenarios with vague or incomplete instructions; Agent introduces multi-agent interactions to simulate function calling evaluation in real-world multi-turn interactions. We conducted extensive experiments on ACEBench, analyzing various LLMs in-depth and performing a more granular analysis of error causes across different data types.</li>
</ul>

<h3>Title: CrossDiff: Diffusion Probabilistic Model With Cross-conditional Encoder-Decoder for Crack Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Xianglong Shi, Yunhan Jiang, Xiaoheng Jiang, Mingling Xu, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12860">https://arxiv.org/abs/2501.12860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12860">https://arxiv.org/pdf/2501.12860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12860]] CrossDiff: Diffusion Probabilistic Model With Cross-conditional Encoder-Decoder for Crack Segmentation(https://arxiv.org/abs/2501.12860)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Crack Segmentation in industrial concrete surfaces is a challenging task because cracks usually exhibit intricate morphology with slender appearances. Traditional segmentation methods often struggle to accurately locate such cracks, leading to inefficiencies in maintenance and repair processes. In this paper, we propose a novel diffusion-based model with a cross-conditional encoder-decoder, named CrossDiff, which is the first to introduce the diffusion probabilistic model for the crack segmentation task. Specifically, CrossDiff integrates a cross-encoder and a cross-decoder into the diffusion model to constitute a cross-shaped diffusion model structure. The cross-encoder enhances the ability to retain crack details and the cross-decoder helps extract the semantic features of cracks. As a result, CrossDiff can better handle slender cracks. Extensive experiments were conducted on five challenging crack datasets including CFD, CrackTree200, DeepCrack, GAPs384, and Rissbilder. The results demonstrate that the proposed CrossDiff model achieves impressive performance, outperforming other state-of-the-art methods by 8.0% in terms of both Dice score and IoU. The code will be open-source soon.</li>
</ul>

<h3>Title: WisdomBot: Tuning Large Language Models with Artificial Intelligence Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Jingyuan Chen, Tao Wu, Wei Ji, Fei Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12877">https://arxiv.org/abs/2501.12877</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12877">https://arxiv.org/pdf/2501.12877</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12877]] WisdomBot: Tuning Large Language Models with Artificial Intelligence Knowledge(https://arxiv.org/abs/2501.12877)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have emerged as powerful tools in natural language processing (NLP), showing a promising future of artificial generated intelligence (AGI). Despite their notable performance in the general domain, LLMs have remained suboptimal in the field of education, owing to the unique challenges presented by this domain, such as the need for more specialized knowledge, the requirement for personalized learning experiences, and the necessity for concise explanations of complex concepts. To address these issues, this paper presents a novel LLM for education named WisdomBot, which combines the power of LLMs with educational theories, enabling their seamless integration into educational contexts. To be specific, we harness self-instructed knowledge concepts and instructions under the guidance of Bloom's Taxonomy as training data. To further enhance the accuracy and professionalism of model's response on factual questions, we introduce two key enhancements during inference, i.e., local knowledge base retrieval augmentation and search engine retrieval augmentation during inference. We substantiate the effectiveness of our approach by applying it to several Chinese LLMs, thereby showcasing that the fine-tuned models can generate more reliable and professional responses.</li>
</ul>

<h3>Title: Generative AI Misuse Potential in Cyber Security Education: A Case Study of a UK Degree Program</h3>
<ul>
<li><strong>Authors: </strong>Carlton Shepherd</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12883">https://arxiv.org/abs/2501.12883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12883">https://arxiv.org/pdf/2501.12883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12883]] Generative AI Misuse Potential in Cyber Security Education: A Case Study of a UK Degree Program(https://arxiv.org/abs/2501.12883)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in generative artificial intelligence (AI), such as ChatGPT, Google Gemini, and other large language models (LLMs), pose significant challenges to upholding academic integrity in higher education. This paper investigates the susceptibility of a Master's-level cyber security degree program at a UK Russell Group university, accredited by a leading national body, to LLM misuse. Through the application and extension of a quantitative assessment framework, we identify a high exposure to misuse, particularly in independent project- and report-based assessments. Contributing factors, including block teaching and a predominantly international cohort, are highlighted as potential amplifiers of these vulnerabilities. To address these challenges, we discuss the adoption of LLM-resistant assessments, detection tools, and the importance of fostering an ethical learning environment. These approaches aim to uphold academic standards while preparing students for the complexities of real-world cyber security.</li>
</ul>

<h3>Title: Analyzing and Exploiting Branch Mispredictions in Microcode</h3>
<ul>
<li><strong>Authors: </strong>Nicholas Mosier, Hamed Nemati, John C. Mitchell, Caroline Trippel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12890">https://arxiv.org/abs/2501.12890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12890">https://arxiv.org/pdf/2501.12890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12890]] Analyzing and Exploiting Branch Mispredictions in Microcode(https://arxiv.org/abs/2501.12890)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>We present uSpectre, a new class of transient execution attacks that exploit microcode branch mispredictions to transiently leak sensitive data. We find that many long-known and recently-discovered transient execution attacks, which were previously categorized as Spectre or Meltdown variants, are actually instances of uSpectre on some Intel microarchitectures. Based on our observations, we discover multiple new uSpectre attacks and present a defense against uSpectre vulnerabilities, called uSLH.</li>
</ul>

<h3>Title: Statistical Privacy</h3>
<ul>
<li><strong>Authors: </strong>Dennis Breutigam, Rüdiger Reischuk</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12893">https://arxiv.org/abs/2501.12893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12893">https://arxiv.org/pdf/2501.12893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12893]] Statistical Privacy(https://arxiv.org/abs/2501.12893)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack</a></li>
<li><strong>Abstract: </strong>To analyze the privacy guarantee of personal data in a database that is subject to queries it is necessary to model the prior knowledge of a possible attacker. Differential privacy considers a worst-case scenario where he knows almost everything, which in many applications is unrealistic and requires a large utility loss. This paper considers a situation called statistical privacy where an adversary knows the distribution by which the database is generated, but no exact data of all (or sufficient many) of its entries. We analyze in detail how the entropy of the distribution guarantes privacy for a large class of queries called property queries. Exact formulas are obtained for the privacy parameters. We analyze how they depend on the probability that an entry fulfills the property under investigation. These formulas turn out to be lengthy, but can be used for tight numerical approximations of the privacy parameters. Such estimations are necessary for applying privacy enhancing techniques in practice. For this statistical setting we further investigate the effect of adding noise or applying subsampling and the privacy utility tradeoff. The dependencies on the parameters are illustrated in detail by a series of plots. Finally, these results are compared to the differential privacy model.</li>
</ul>

<h3>Title: Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback</h3>
<ul>
<li><strong>Authors: </strong>Yafu Li, Xuyang Hu, Xiaoye Qu, Linjie Li, Yu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12895">https://arxiv.org/abs/2501.12895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12895">https://arxiv.org/pdf/2501.12895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12895]] Test-Time Preference Optimization: On-the-Fly Alignment via Iterative Textual Feedback(https://arxiv.org/abs/2501.12895)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate impressive performance but lack the flexibility to adapt to human preferences quickly without retraining. In this work, we introduce Test-time Preference Optimization (TPO), a framework that aligns LLM outputs with human preferences during inference, removing the need to update model parameters. Rather than relying on purely numerical rewards, TPO translates reward signals into textual critiques and uses them as textual rewards to iteratively refine its response. Evaluations on benchmarks covering instruction following, preference alignment, safety, and mathematics reveal that TPO progressively improves alignment with human preferences. Notably, after only a few TPO steps, the initially unaligned Llama-3.1-70B-SFT model can surpass the aligned counterpart, Llama-3.1-70B-Instruct. Furthermore, TPO scales efficiently with both the search width and depth during inference. Through case studies, we illustrate how TPO exploits the innate capacity of LLM to interpret and act upon reward signals. Our findings establish TPO as a practical, lightweight alternative for test-time preference optimization, achieving alignment on the fly. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi</h3>
<ul>
<li><strong>Authors: </strong>Ella Koresh, Ronit D. Gross, Yuval Meir, Yarden Tzach, Tal Halevi, Ido Kanter</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12900">https://arxiv.org/abs/2501.12900</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12900">https://arxiv.org/pdf/2501.12900</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12900]] Unified CNNs and transformers underlying learning mechanism reveals multi-head attention modus vivendi(https://arxiv.org/abs/2501.12900)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNNs) evaluate short-range correlations in input images which progress along the layers, whereas vision transformer (ViT) architectures evaluate long-range correlations, using repeated transformer encoders composed of fully connected layers. Both are designed to solve complex classification tasks but from different perspectives. This study demonstrates that CNNs and ViT architectures stem from a unified underlying learning mechanism, which quantitatively measures the single-nodal performance (SNP) of each node in feedforward (FF) and multi-head attention (MHA) subblocks. Each node identifies small clusters of possible output labels, with additional noise represented as labels outside these clusters. These features are progressively sharpened along the transformer encoders, enhancing the signal-to-noise ratio. This unified underlying learning mechanism leads to two main findings. First, it enables an efficient applied nodal diagonal connection (ANDC) pruning technique without affecting the accuracy. Second, based on the SNP, spontaneous symmetry breaking occurs among the MHA heads, such that each head focuses its attention on a subset of labels through cooperation among its SNPs. Consequently, each head becomes an expert in recognizing its designated labels, representing a quantitative MHA modus vivendi mechanism. These results are based on a compact convolutional transformer architecture trained on the CIFAR-100 and Flowers-102 datasets and call for their extension to other architectures and applications, such as natural language processing.</li>
</ul>

<h3>Title: Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration</h3>
<ul>
<li><strong>Authors: </strong>Offa Kingsleigh, Alfred Abercrombie, David Woolstencroft, Beorhtric Meadowcroft, Marcus Irvin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12901">https://arxiv.org/abs/2501.12901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12901">https://arxiv.org/pdf/2501.12901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12901]] Architectural Fusion Through Contextual Partitioning in Large Language Models: A Novel Approach to Parameterized Knowledge Integration(https://arxiv.org/abs/2501.12901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Contextual Partitioning introduces an innovative approach to enhancing the architectural design of large-scale computational models through the dynamic segmentation of parameters into context-aware regions. This methodology emphasizes the importance of task-specific specialization, achieved through adaptive parameter allocation mechanisms that align with the linguistic features of input data. Experimental evaluations demonstrated substantial improvements in accuracy, perplexity, and contextual coherence across a variety of linguistic tasks, highlighting the adaptability and scalability of the proposed framework. By reducing redundancy and enhancing computational efficiency, Contextual Partitioning not only streamlines model operations but also expands the scope of applications for advanced language processing systems. The approach operates autonomously, requiring no external fine-tuning, thereby addressing a significant limitation in conventional parameter optimization techniques. Empirical results demonstrate the effectiveness of gradient-driven segmentation, enabling models to dynamically recalibrate and specialize in response to task-specific demands. Furthermore, resource utilization metrics reveal notable reductions in memory usage and training times, confirming the efficiency of the approach. Observations from qualitative analyses illustrate improved contextual coherence and logical flow in generated outputs, reinforcing the practical value of this technique. The findings collectively demonstrate the potential for Contextual Partitioning to redefine the scalability and adaptability of computational language architectures in diverse and complex domains.</li>
</ul>

<h3>Title: A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Abdulkadir Korkmaz, Praveen Rao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12911">https://arxiv.org/abs/2501.12911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12911">https://arxiv.org/pdf/2501.12911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12911]] A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning(https://arxiv.org/abs/2501.12911)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a machine learning method that supports training models on decentralized devices or servers, where each holds its local data, removing the need for data exchange. This approach is especially useful in healthcare, as it enables training on sensitive data without needing to share them. The nature of federated learning necessitates robust security precautions due to data leakage concerns during communication. To address this issue, we propose a new approach that employs selective encryption, homomorphic encryption, differential privacy, and bit-wise scrambling to minimize data leakage while achieving good execution performance. Our technique , FAS (fast and secure federated learning) is used to train deep learning models on medical imaging data. We implemented our technique using the Flower framework and compared with a state-of-the-art federated learning approach that also uses selective homomorphic encryption. Our experiments were run in a cluster of eleven physical machines to create a real-world federated learning scenario on different datasets. We observed that our approach is up to 90\% faster than applying fully homomorphic encryption on the model weights. In addition, we can avoid the pretraining step that is required by our competitor and can save up to 20\% in terms of total execution time. While our approach was faster, it obtained similar security results as the competitor.</li>
</ul>

<h3>Title: DynamicEarth: How Far are We from Open-Vocabulary Change Detection?</h3>
<ul>
<li><strong>Authors: </strong>Kaiyu Li, Xiangyong Cao, Yupeng Deng, Chao Pang, Zepeng Xin, Deyu Meng, Zhi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12931">https://arxiv.org/abs/2501.12931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12931">https://arxiv.org/pdf/2501.12931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12931]] DynamicEarth: How Far are We from Open-Vocabulary Change Detection?(https://arxiv.org/abs/2501.12931)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Monitoring Earth's evolving land covers requires methods capable of detecting changes across a wide range of categories and contexts. Existing change detection methods are hindered by their dependency on predefined classes, reducing their effectiveness in open-world applications. To address this issue, we introduce open-vocabulary change detection (OVCD), a novel task that bridges vision and language to detect changes across any category. Considering the lack of high-quality data and annotation, we propose two training-free frameworks, M-C-I and I-M-C, which leverage and integrate off-the-shelf foundation models for the OVCD task. The insight behind the M-C-I framework is to discover all potential changes and then classify these changes, while the insight of I-M-C framework is to identify all targets of interest and then determine whether their states have changed. Based on these two frameworks, we instantiate to obtain several methods, e.g., SAM-DINOv2-SegEarth-OV, Grounding-DINO-SAM2-DINO, etc. Extensive evaluations on 5 benchmark datasets demonstrate the superior generalization and robustness of our OVCD methods over existing supervised and unsupervised methods. To support continued exploration, we release DynamicEarth, a dedicated codebase designed to advance research and application of OVCD. this https URL</li>
</ul>

<h3>Title: 3D Object Manipulation in a Single Image using Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Ruisi Zhao, Zechuan Zhang, Zongxin Yang, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12935">https://arxiv.org/abs/2501.12935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12935">https://arxiv.org/pdf/2501.12935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12935]] 3D Object Manipulation in a Single Image using Generative Models(https://arxiv.org/abs/2501.12935)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Object manipulation in images aims to not only edit the object's presentation but also gift objects with motion. Previous methods encountered challenges in concurrently handling static editing and dynamic generation, while also struggling to achieve fidelity in object appearance and scene lighting. In this work, we introduce \textbf{OMG3D}, a novel framework that integrates the precise geometric control with the generative power of diffusion models, thus achieving significant enhancements in visual performance. Our framework first converts 2D objects into 3D, enabling user-directed modifications and lifelike motions at the geometric level. To address texture realism, we propose CustomRefiner, a texture refinement module that pre-train a customized diffusion model, aligning the details and style of coarse renderings of 3D rough model with the original image, further refine the texture. Additionally, we introduce IllumiCombiner, a lighting processing module that estimates and corrects background lighting to match human visual perception, resulting in more realistic shadow effects. Extensive experiments demonstrate the outstanding visual performance of our approach in both static and dynamic scenarios. Remarkably, all these steps can be done using one NVIDIA 3090. Project page is at this https URL</li>
</ul>

<h3>Title: GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pengxiang Zhao, Xiaoming Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12956">https://arxiv.org/abs/2501.12956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12956">https://arxiv.org/pdf/2501.12956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12956]] GANQ: GPU-Adaptive Non-Uniform Quantization for Large Language Models(https://arxiv.org/abs/2501.12956)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) face significant deployment challenges due to their substantial resource requirements. While low-bit quantized weights can reduce memory usage and improve inference efficiency, current hardware lacks native support for mixed-precision General Matrix Multiplication (mpGEMM), resulting in inefficient dequantization-based implementations. Moreover, uniform quantization methods often fail to capture weight distributions adequately, leading to performance degradation. We propose GANQ (GPU-Adaptive Non-Uniform Quantization), a layer-wise post-training non-uniform quantization framework optimized for hardware-efficient lookup table-based mpGEMM. GANQ achieves superior quantization performance by utilizing a training-free, GPU-adaptive optimization algorithm to efficiently reduce layer-wise quantization errors. Extensive experiments demonstrate GANQ's ability to reduce the perplexity gap from the FP16 baseline compared to state-of-the-art methods for both 3-bit and 4-bit quantization. Furthermore, when deployed on a single NVIDIA RTX 4090 GPU, GANQ's quantized models achieve up to 2.57$\times$ speedup over the baseline, advancing memory and inference efficiency in LLM deployment.</li>
</ul>

<h3>Title: A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features</h3>
<ul>
<li><strong>Authors: </strong>Saahil Islam, Venkatesh N. Murthy, Dominik Neumann, Serkan Cimen, Puneet Sharma, Andreas Maier, Dorin Comaniciu, Florin C. Ghesu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12958">https://arxiv.org/abs/2501.12958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12958">https://arxiv.org/pdf/2501.12958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12958]] A Novel Tracking Framework for Devices in X-ray Leveraging Supplementary Cue-Driven Self-Supervised Features(https://arxiv.org/abs/2501.12958)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>To restore proper blood flow in blocked coronary arteries via angioplasty procedure, accurate placement of devices such as catheters, balloons, and stents under live fluoroscopy or diagnostic angiography is crucial. Identified balloon markers help in enhancing stent visibility in X-ray sequences, while the catheter tip aids in precise navigation and co-registering vessel structures, reducing the need for contrast in angiography. However, accurate detection of these devices in interventional X-ray sequences faces significant challenges, particularly due to occlusions from contrasted vessels and other devices and distractions from surrounding, resulting in the failure to track such small objects. While most tracking methods rely on spatial correlation of past and current appearance, they often lack strong motion comprehension essential for navigating through these challenging conditions, and fail to effectively detect multiple instances in the scene. To overcome these limitations, we propose a self-supervised learning approach that enhances its spatio-temporal understanding by incorporating supplementary cues and learning across multiple representation spaces on a large dataset. Followed by that, we introduce a generic real-time tracking framework that effectively leverages the pretrained spatio-temporal network and also takes the historical appearance and trajectory data into account. This results in enhanced localization of multiple instances of device landmarks. Our method outperforms state-of-the-art methods in interventional X-ray device tracking, especially stability and robustness, achieving an 87% reduction in max error for balloon marker detection and a 61% reduction in max error for catheter tip detection.</li>
</ul>

<h3>Title: Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference</h3>
<ul>
<li><strong>Authors: </strong>Weizhi Fei, Xueyan Niu, Guoqing Xie, Yingqing Liu, Bo Bai, Wei Han</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12959">https://arxiv.org/abs/2501.12959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12959">https://arxiv.org/pdf/2501.12959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12959]] Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference(https://arxiv.org/abs/2501.12959)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Although applications involving long-context inputs are crucial for the effective utilization of large language models (LLMs), they also result in increased computational costs and reduced performance. To address this challenge, we propose an efficient, training-free prompt compression method that retains key information within compressed prompts. We identify specific attention heads in transformer-based LLMs, which we designate as evaluator heads, that are capable of selecting tokens in long inputs that are most significant for inference. Building on this discovery, we develop EHPC, an Evaluator Head-based Prompt Compression method, which enables LLMs to rapidly "skim through" input prompts by leveraging only the first few layers with evaluator heads during the pre-filling stage, subsequently passing only the important tokens to the model for inference. EHPC achieves state-of-the-art results across two mainstream benchmarks: prompt compression and long-context inference acceleration. Consequently, it effectively reduces the complexity and costs associated with commercial API calls. We further demonstrate that EHPC attains competitive results compared to key-value cache-based acceleration methods, thereby highlighting its potential to enhance the efficiency of LLMs for long-context tasks.</li>
</ul>

<h3>Title: It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act</h3>
<ul>
<li><strong>Authors: </strong>Kristof Meding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12962">https://arxiv.org/abs/2501.12962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12962">https://arxiv.org/pdf/2501.12962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12962]] It's complicated. The relationship of algorithmic fairness and non-discrimination regulations in the EU AI Act(https://arxiv.org/abs/2501.12962)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>What constitutes a fair decision? This question is not only difficult for humans but becomes more challenging when Artificial Intelligence (AI) models are used. In light of discriminatory algorithmic behaviors, the EU has recently passed the AI Act, which mandates specific rules for AI models, incorporating both traditional legal non-discrimination regulations and machine learning based algorithmic fairness concepts. This paper aims to bridge these two different concepts in the AI Act through: First a high-level introduction of both concepts targeting legal and computer science-oriented scholars, and second an in-depth analysis of the AI Act's relationship between legal non-discrimination regulations and algorithmic fairness. Our analysis reveals three key findings: (1.), most non-discrimination regulations target only high-risk AI systems. (2.), the regulation of high-risk systems encompasses both data input requirements and output monitoring, though these regulations are often inconsistent and raise questions of computational feasibility. (3.) Regulations for General Purpose AI Models, such as Large Language Models that are not simultaneously classified as high-risk systems, currently lack specificity compared to other regulations. Based on these findings, we recommend developing more specific auditing and testing methodologies for AI systems. This paper aims to serve as a foundation for future interdisciplinary collaboration between legal scholars and computer science-oriented machine learning researchers studying discrimination in AI systems.</li>
</ul>

<h3>Title: OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chongren Sun, Yuran Li, Di Wu, Benoit Boulet</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12975">https://arxiv.org/abs/2501.12975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12975">https://arxiv.org/pdf/2501.12975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12975]] OnionEval: An Unified Evaluation of Fact-conflicting Hallucination for Small-Large Language Models(https://arxiv.org/abs/2501.12975)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are highly capable but require significant computational resources for both training and inference. Within the LLM family, smaller models (those with fewer than 10 billion parameters) also perform well across various tasks. However, these smaller models share similar limitations to their larger counterparts, including the tendency to hallucinate. Despite the existence of many benchmarks to evaluate hallucination in LLMs, few have specifically focused on small LLMs (SLLMs). Additionally, SLLMs show widely varying performance across different benchmarks. In this paper, we introduce OnionEval, a multi-layer structured framework with a specific metric called the context-influence score (CI), designed to effectively assess the fact-conflicting hallucination tendencies of small LLMs across different contextual levels. Our experimental results reveal a key feature of SLLMs: they excel in factual analysis but face challenges with context reasoning. Further investigation shows that a simple Chain-of-Thought strategy can significantly reduce these limitations, improving the practical usefulness of SLLMs in real-world applications.</li>
</ul>

<h3>Title: LiT: Delving into a Simplified Linear Diffusion Transformer for Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Wang, Ning Kang, Lewei Yao, Mengzhao Chen, Chengyue Wu, Songyang Zhang, Shuchen Xue, Yong Liu, Taiqiang Wu, Xihui Liu, Kaipeng Zhang, Shifeng Zhang, Wenqi Shao, Zhenguo Li, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12976">https://arxiv.org/abs/2501.12976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12976">https://arxiv.org/pdf/2501.12976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12976]] LiT: Delving into a Simplified Linear Diffusion Transformer for Image Generation(https://arxiv.org/abs/2501.12976)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>In commonly used sub-quadratic complexity modules, linear attention benefits from simplicity and high parallelism, making it promising for image synthesis tasks. However, the architectural design and learning strategy for linear attention remain underexplored in this field. In this paper, we offer a suite of ready-to-use solutions for efficient linear diffusion Transformers. Our core contributions include: (1) Simplified Linear Attention using few heads, observing the free-lunch effect of performance without latency increase. (2) Weight inheritance from a fully pre-trained diffusion Transformer: initializing linear Transformer using pre-trained diffusion Transformer and loading all parameters except for those related to linear attention. (3) Hybrid knowledge distillation objective: using a pre-trained diffusion Transformer to help the training of the student linear Transformer, supervising not only the predicted noise but also the variance of the reverse diffusion process. These guidelines lead to our proposed Linear Diffusion Transformer (LiT), an efficient text-to-image Transformer that can be deployed offline on a laptop. Experiments show that in class-conditional 256*256 and 512*512 ImageNet benchmark LiT achieves highly competitive FID while reducing training steps by 80% and 77% compared to DiT. LiT also rivals methods based on Mamba or Gated Linear Attention. Besides, for text-to-image generation, LiT allows for the rapid synthesis of up to 1K resolution photorealistic images. Project page: this https URL.</li>
</ul>

<h3>Title: FlanEC: Exploring Flan-T5 for Post-ASR Error Correction</h3>
<ul>
<li><strong>Authors: </strong>Moreno La Quatra, Valerio Mario Salerno, Yu Tsao, Sabato Marco Siniscalchi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12979">https://arxiv.org/abs/2501.12979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12979">https://arxiv.org/pdf/2501.12979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12979]] FlanEC: Exploring Flan-T5 for Post-ASR Error Correction(https://arxiv.org/abs/2501.12979)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In this paper, we present an encoder-decoder model leveraging Flan-T5 for post-Automatic Speech Recognition (ASR) Generative Speech Error Correction (GenSEC), and we refer to it as FlanEC. We explore its application within the GenSEC framework to enhance ASR outputs by mapping n-best hypotheses into a single output sentence. By utilizing n-best lists from ASR models, we aim to improve the linguistic correctness, accuracy, and grammaticality of final ASR transcriptions. Specifically, we investigate whether scaling the training data and incorporating diverse datasets can lead to significant improvements in post-ASR error correction. We evaluate FlanEC using the HyPoradise dataset, providing a comprehensive analysis of the model's effectiveness in this domain. Furthermore, we assess the proposed approach under different settings to evaluate model scalability and efficiency, offering valuable insights into the potential of instruction-tuned encoder-decoder models for this task.</li>
</ul>

<h3>Title: Implicit Causality-biases in humans and LLMs as a tool for benchmarking LLM discourse capabilities</h3>
<ul>
<li><strong>Authors: </strong>Florian Kankowski, Torgrim Solstad, Sina Zarriess, Oliver Bott</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12980">https://arxiv.org/abs/2501.12980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12980">https://arxiv.org/pdf/2501.12980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12980]] Implicit Causality-biases in humans and LLMs as a tool for benchmarking LLM discourse capabilities(https://arxiv.org/abs/2501.12980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we compare data generated with mono- and multilingual LLMs spanning a range of model sizes with data provided by human participants in an experimental setting investigating well-established discourse biases. Beyond the comparison as such, we aim to develop a benchmark to assess the capabilities of LLMs with discourse biases as a robust proxy for more general discourse understanding capabilities. More specifically, we investigated Implicit Causality verbs, for which psycholinguistic research has found participants to display biases with regard to three phenomena:\ the establishment of (i) coreference relations (Experiment 1), (ii) coherence relations (Experiment 2), and (iii) the use of particular referring expressions (Experiments 3 and 4). With regard to coreference biases we found only the largest monolingual LLM (German Bloom 6.4B) to display more human-like biases. For coherence relation, no LLM displayed the explanation bias usually found for humans. For referring expressions, all LLMs displayed a preference for referring to subject arguments with simpler forms than to objects. However, no bias effect on referring expression was found, as opposed to recent studies investigating human biases.</li>
</ul>

<h3>Title: Ehrenfeucht-Haussler Rank and Chain of Thought</h3>
<ul>
<li><strong>Authors: </strong>Pablo Barceló, Alexander Kozachinskiy, Tomasz Steifer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.12997">https://arxiv.org/abs/2501.12997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.12997">https://arxiv.org/pdf/2501.12997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.12997]] Ehrenfeucht-Haussler Rank and Chain of Thought(https://arxiv.org/abs/2501.12997)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The notion of rank of a Boolean function has been a cornerstone in the theory of PAC learning, enabling quasipolynomial-time learning algorithms for polynomial-size decision trees. We present a novel characterization of rank, grounded in the well-known Transformer architecture. We show that the rank of a function $f$ corresponds to the minimum number of Chain of Thought (CoT) steps required by a single-layer transformer decoder with hard attention to compute $f$. Based on this characterization we establish tight bounds on the number of CoT steps required for specific problems, showing that $\ell$-fold function composition necessitates exactly $\ell$ CoT steps. Furthermore, we analyze the problem of identifying the position of the $k$-th occurrence of 1 in a Boolean sequence, proving that it requires $k$ CoT steps.</li>
</ul>

<h3>Title: Comparison of feature extraction tools for network traffic data</h3>
<ul>
<li><strong>Authors: </strong>Borys Lypa, Ivan Horyn, Natalia Zagorodna, Dmytro Tymoshchuk, Taras Lechachenko</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13004">https://arxiv.org/abs/2501.13004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13004">https://arxiv.org/pdf/2501.13004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13004]] Comparison of feature extraction tools for network traffic data(https://arxiv.org/abs/2501.13004)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The comparison analysis of the most popular tools to extract features from network traffic is conducted in this paper. Feature extraction plays a crucial role in Intrusion Detection Systems (IDS) because it helps to transform huge raw network data into meaningful and manageable features for analysis and detection of malicious activities. The good choice of feature extraction tool is an essential step in construction of Artificial Intelligence-based Intrusion Detection Systems (AI-IDS), which can help to enhance the efficiency, accuracy, and scalability of such systems.</li>
</ul>

<h3>Title: Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament</h3>
<ul>
<li><strong>Authors: </strong>Yantao Liu, Zijun Yao, Rui Min, Yixin Cao, Lei Hou, Juanzi Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13007">https://arxiv.org/abs/2501.13007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13007">https://arxiv.org/pdf/2501.13007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13007]] Pairwise RM: Perform Best-of-N Sampling with Knockout Tournament(https://arxiv.org/abs/2501.13007)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Best-of-N (BoN) sampling, a common strategy for test-time scaling of Large Language Models (LLMs), relies on reward models to select the best candidate solution from multiple generations. However, traditional reward models often assign arbitrary and inconsistent scores, limiting their effectiveness. To address this, we propose a Pairwise Reward Model (Pairwise RM) combined with a knockout tournament for BoN sampling. Instead of assigning absolute scores, given one math problem, Pairwise RM evaluates two candidate solutions' correctness simultaneously. This approach eliminates the need for arbitrary scoring and enables cross-validation of solutions through parallel comparison. In the knockout tournament, Pairwise RM conducts pairwise comparisons between candidate solutions and eliminates the incorrect ones iteratively. We construct \ourdataset, a large-scale dataset of 443K pairwise comparisons derived from NumiaMath and annotated using \texttt{gemini-1.5-flash}, and train the Pairwise RM via supervised fine-tuning. Experiments on MATH-500 and the Olympiad Bench demonstrate significant improvements over traditional discriminative reward models. And a 40\% to 60\% relative improvement is achieved on the top 50\% challenging problems.</li>
</ul>

<h3>Title: Deep Learning-Based Image Recovery and Pose Estimation for Resident Space Objects</h3>
<ul>
<li><strong>Authors: </strong>Louis Aberdeen, Mark Hansen, Melvyn L. Smith, Lyndon Smith</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13009">https://arxiv.org/abs/2501.13009</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13009">https://arxiv.org/pdf/2501.13009</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13009]] Deep Learning-Based Image Recovery and Pose Estimation for Resident Space Objects(https://arxiv.org/abs/2501.13009)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>As the density of spacecraft in Earth's orbit increases, their recognition, pose and trajectory identification becomes crucial for averting potential collisions and executing debris removal operations. However, training models able to identify a spacecraft and its pose presents a significant challenge due to a lack of available image data for model training. This paper puts forth an innovative framework for generating realistic synthetic datasets of Resident Space Object (RSO) imagery. Using the International Space Station (ISS) as a test case, it goes on to combine image regression with image restoration methodologies to estimate pose from blurred images. An analysis of the proposed image recovery and regression techniques was undertaken, providing insights into the performance, potential enhancements and limitations when applied to real imagery of RSOs. The image recovery approach investigated involves first applying image deconvolution using an effective point spread function, followed by detail object extraction with a U-Net. Interestingly, using only U-Net for image reconstruction the best pose performance was attained, reducing the average Mean Squared Error in image recovery by 97.28% and the average angular error by 71.9%. The successful application of U-Net image restoration combined with the Resnet50 regression network for pose estimation of the International Space Station demonstrates the value of a diverse set of evaluation tools for effective solutions to real-world problems such as the analysis of distant objects in Earth's orbit.</li>
</ul>

<h3>Title: Multi-Objective Hyperparameter Selection via Hypothesis Testing on Reliability Graphs</h3>
<ul>
<li><strong>Authors: </strong>Amirmohammad Farzaneh, Osvaldo Simeone</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13018">https://arxiv.org/abs/2501.13018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13018">https://arxiv.org/pdf/2501.13018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13018]] Multi-Objective Hyperparameter Selection via Hypothesis Testing on Reliability Graphs(https://arxiv.org/abs/2501.13018)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In sensitive application domains, multi-objective hyperparameter selection can ensure the reliability of AI models prior to deployment, while optimizing auxiliary performance metrics. The state-of-the-art Pareto Testing (PT) method guarantees statistical reliability constraints by adopting a multiple hypothesis testing framework. In PT, hyperparameters are validated one at a time, following a data-driven order determined by expected reliability levels. This paper introduces a novel framework for multi-objective hyperparameter selection that captures the interdependencies among the reliability levels of different hyperparameter configurations using a directed acyclic graph (DAG), which is termed the reliability graph (RG). The RG is constructed based on prior information and data by using the Bradley-Terry model. The proposed approach, RG-based PT (RG-PT), leverages the RG to enable the efficient, parallel testing of multiple hyperparameters at the same reliability level. By integrating False Discovery Rate (FDR) control, RG-PT ensures robust statistical reliability guarantees and is shown via experiments across diverse domains to consistently yield superior solutions for multi-objective calibration problems.</li>
</ul>

<h3>Title: A Probabilistic Model for Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Maximilian Fleissner, Pascal Esser, Debarghya Ghoshdastidar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13031">https://arxiv.org/abs/2501.13031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13031">https://arxiv.org/pdf/2501.13031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13031]] A Probabilistic Model for Self-Supervised Learning(https://arxiv.org/abs/2501.13031)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Self-supervised learning (SSL) aims to find meaningful representations from unlabeled data by encoding semantic similarities through data augmentations. Despite its current popularity, theoretical insights about SSL are still scarce. For example, it is not yet known whether commonly used SSL loss functions can be related to a statistical model, much in the same as OLS, generalized linear models or PCA naturally emerge as maximum likelihood estimates of an underlying generative process. In this short paper, we consider a latent variable statistical model for SSL that exhibits an interesting property: Depending on the informativeness of the data augmentations, the MLE of the model either reduces to PCA, or approaches a simple non-contrastive loss. We analyze the model and also empirically illustrate our findings.</li>
</ul>

<h3>Title: Does Table Source Matter? Benchmarking and Improving Multimodal Scientific Table Understanding and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Bohao Yang, Yingji Zhang, Dong Liu, André Freitas, Chenghua Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13042">https://arxiv.org/abs/2501.13042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13042">https://arxiv.org/pdf/2501.13042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13042]] Does Table Source Matter? Benchmarking and Improving Multimodal Scientific Table Understanding and Reasoning(https://arxiv.org/abs/2501.13042)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) have advanced table understanding capabilities but rely on converting tables into text sequences. While multimodal large language models (MLLMs) enable direct visual processing, they face limitations in handling scientific tables due to fixed input image resolutions and insufficient numerical reasoning capabilities. We present a comprehensive framework for multimodal scientific table understanding and reasoning with dynamic input image resolutions. Our framework consists of three key components: (1) MMSci-Pre, a domain-specific table structure learning dataset of 52K scientific table structure recognition samples, (2) MMSci-Ins, an instruction tuning dataset with 12K samples across three table-based tasks, and (3) MMSci-Eval, a benchmark with 3,114 testing samples specifically designed to evaluate numerical reasoning capabilities. Extensive experiments demonstrate that our domain-specific approach with 52K scientific table images achieves superior performance compared to 150K general-domain tables, highlighting the importance of data quality over quantity. Our proposed table-based MLLMs with dynamic input resolutions show significant improvements in both general table understanding and numerical reasoning capabilities, with strong generalisation to held-out datasets. Our code and data are publicly available at this https URL.</li>
</ul>

<h3>Title: Beyond the Lungs: Extending the Field of View in Chest CT with Latent Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Lianrui Zuo, Kaiwen Xu, Dingjie Su, Xin Yu, Aravind R. Krishnan, Yihao Liu, Shunxing Bao, Thomas Li, Kim L. Sandler, Fabien Maldonado, Bennett A. Landman</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13068">https://arxiv.org/abs/2501.13068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13068">https://arxiv.org/pdf/2501.13068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13068]] Beyond the Lungs: Extending the Field of View in Chest CT with Latent Diffusion Models(https://arxiv.org/abs/2501.13068)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The interconnection between the human lungs and other organs, such as the liver and kidneys, is crucial for understanding the underlying risks and effects of lung diseases and improving patient care. However, most research chest CT imaging is focused solely on the lungs due to considerations of cost and radiation dose. This restricted field of view (FOV) in the acquired images poses challenges to comprehensive analysis and hinders the ability to gain insights into the impact of lung diseases on other organs. To address this, we propose SCOPE (Spatial Coverage Optimization with Prior Encoding), a novel approach to capture the inter-organ relationships from CT images and extend the FOV of chest CT images. Our approach first trains a variational autoencoder (VAE) to encode 2D axial CT slices individually, then stacks the latent representations of the VAE to form a 3D context for training a latent diffusion model. Once trained, our approach extends the FOV of CT images in the z-direction by generating new axial slices in a zero-shot manner. We evaluated our approach on the National Lung Screening Trial (NLST) dataset, and results suggest that it effectively extends the FOV to include the liver and kidneys, which are not completely covered in the original NLST data acquisition. Quantitative results on a held-out whole-body dataset demonstrate that the generated slices exhibit high fidelity with acquired data, achieving an SSIM of 0.81.</li>
</ul>

<h3>Title: Robust Body Composition Analysis by Generating 3D CT Volumes from Limited 2D Slices</h3>
<ul>
<li><strong>Authors: </strong>Lianrui Zuo, Xin Yu, Dingjie Su, Kaiwen Xu, Aravind R. Krishnan, Yihao Liu, Shunxing Bao, Fabien Maldonado, Luigi Ferrucci, Bennett A. Landman</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13071">https://arxiv.org/abs/2501.13071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13071">https://arxiv.org/pdf/2501.13071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13071]] Robust Body Composition Analysis by Generating 3D CT Volumes from Limited 2D Slices(https://arxiv.org/abs/2501.13071)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Body composition analysis provides valuable insights into aging, disease progression, and overall health conditions. Due to concerns of radiation exposure, two-dimensional (2D) single-slice computed tomography (CT) imaging has been used repeatedly for body composition analysis. However, this approach introduces significant spatial variability that can impact the accuracy and robustness of the analysis. To mitigate this issue and facilitate body composition analysis, this paper presents a novel method to generate 3D CT volumes from limited number of 2D slices using a latent diffusion model (LDM). Our approach first maps 2D slices into a latent representation space using a variational autoencoder. An LDM is then trained to capture the 3D context of a stack of these latent representations. To accurately interpolate intermediateslices and construct a full 3D volume, we utilize body part regression to determine the spatial location and distance between the acquired slices. Experiments on both in-house and public 3D abdominal CT datasets demonstrate that the proposed method significantly enhances body composition analysis compared to traditional 2D-based analysis, with a reduced error rate from 23.3% to 15.2%.</li>
</ul>

<h3>Title: CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark Localization</h3>
<ul>
<li><strong>Authors: </strong>José Rodríguez-Ortega, Siham Tabik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13073">https://arxiv.org/abs/2501.13073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13073">https://arxiv.org/pdf/2501.13073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13073]] CHaRNet: Conditioned Heatmap Regression for Robust Dental Landmark Localization(https://arxiv.org/abs/2501.13073)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Identifying anatomical landmarks in 3D dental models is crucial for orthodontic treatment. Manually placing these key points is complex, time-consuming, and requires expert knowledge. While some machine learning methods have been proposed for automatic tooth landmark detection in 3D Intraoral Scans (IOS), research remains limited, with no fully end-to-end approaches that avoid teeth segmentation. We propose CHaRNet (Conditioned Heatmap Regression Network), the first end-to-end deep learning method for tooth landmark detection in 3D IOS. Unlike traditional two-stage methods that segment teeth before detecting landmarks, CHaRNet directly detects landmarks on the input point cloud. It consists of four key modules: (1) a point cloud encoder, (2) a point cloud decoder with a heatmap regression head, (3) a teeth presence classification head, and (4) the innovative Conditioned Heatmap Regression (CHaR) module. The CHaR module refines landmark regression by leveraging teeth presence classification, enabling dynamic adaptation to cases with missing teeth and improving accuracy in complex dental models. We evaluate CHaRNet using five point cloud learning algorithms to validate the effectiveness of the CHaR module and test it on a clinical dataset of $1,214$ annotated 3D dental models. Both the dataset and code will be publicly released to address the lack of open datasets in orthodontics, promote benchmarking, and inspire new research. CHaRNet achieves a Mean Euclidean Distance Error (MEDE) of 1.28 mm and a Mean Success Ratio (MSR) of 82.40\%, demonstrating robust performance. Notably, it excels in handling irregular dental geometries, such as models with missing teeth. This end-to-end approach streamlines orthodontic workflows, improves 3D IOS analysis precision, and facilitates efficient computer-assisted treatment planning.</li>
</ul>

<h3>Title: Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment</h3>
<ul>
<li><strong>Authors: </strong>Melissa Kazemi Rad, Huy Nghiem, Andy Luo, Sahil Wadhwa, Mohammad Sorower, Stephen Rawls</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13080">https://arxiv.org/abs/2501.13080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13080">https://arxiv.org/pdf/2501.13080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13080]] Refining Input Guardrails: Enhancing LLM-as-a-Judge Efficiency Through Chain-of-Thought Fine-Tuning and Alignment(https://arxiv.org/abs/2501.13080)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated powerful capabilities that render them valuable in different applications, including conversational AI products. It is paramount to ensure the security and reliability of these products by mitigating their vulnerabilities towards malicious user interactions, which can lead to the exposure of great risks and reputational repercussions. In this work, we present a comprehensive study on the efficacy of fine-tuning and aligning Chain-of-Thought (CoT) responses of different LLMs that serve as input moderation guardrails. We systematically explore various tuning methods by leveraging a small set of training data to adapt these models as proxy defense mechanisms to detect malicious inputs and provide a reasoning for their verdicts, thereby preventing the exploitation of conversational agents. We rigorously evaluate the efficacy and robustness of different tuning strategies to generalize across diverse adversarial and malicious query types. Our experimental results outline the potential of alignment processes tailored to a varied range of harmful input queries, even with constrained data resources. These techniques significantly enhance the safety of conversational AI systems and provide a feasible framework for deploying more secure and trustworthy AI-driven interactions.</li>
</ul>

<h3>Title: Real-Time Multi-Modal Subcomponent-Level Measurements for Trustworthy System Monitoring and Malware Detection</h3>
<ul>
<li><strong>Authors: </strong>Farshad Khorrami, Ramesh Karri, Prashanth Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13081">https://arxiv.org/abs/2501.13081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13081">https://arxiv.org/pdf/2501.13081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13081]] Real-Time Multi-Modal Subcomponent-Level Measurements for Trustworthy System Monitoring and Malware Detection(https://arxiv.org/abs/2501.13081)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>With increasingly sophisticated cyber-adversaries able to access a wider repertoire of mechanisms to implant malware such as ransomware, CPU/GPU keyloggers, and stealthy kernel rootkits, there is an urgent need for techniques to detect and mitigate such attacks. While state of the art relies on digital and analog side channel measurements assuming trustworthiness of measurements obtained on the main processor, such an approach has limitations since processor-based side channel measurements are potentially untrustworthy. Sophisticated adversaries (especially in late stage cyber attacks when they have breached the computer and network security systems such as firewalls and antivirus and penetrated the computer's OS) can compromise user-space and kernel-space measurements. To address this key limitation of state of the art, we propose a "subcomponent-level" approach to collect side channel measurements so as to enable robust anomaly detection in a modern computer even when the main processor is compromised. Our proposed approach leverages the fact that modern computers are complex systems with multiple interacting subcomponents and measurements from subcomponents can be used to detect anomalies even when the main processor is no longer trustworthy. We develop mechanisms to obtain time series measurements of activity of several subcomponents and methodologies to process and fuse these measurements for anomaly detection. The subcomponents include network interface controller, GPU, CPU Hardware Performance Counters, CPU power, and keyboard. Our main hypothesis is that subcomponent measurements can enable detection of security threats without requiring a trustworthy main processor. By enabling real-time measurements from multiple subcomponents, the goal is to provide a deeper visibility into system operation, thereby yielding a powerful tool to track system operation and detect anomalies.</li>
</ul>

<h3>Title: Orchid: Image Latent Diffusion for Joint Appearance and Geometry Generation</h3>
<ul>
<li><strong>Authors: </strong>Akshay Krishnan, Xinchen Yan, Vincent Casser, Abhijit Kundu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13087">https://arxiv.org/abs/2501.13087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13087">https://arxiv.org/pdf/2501.13087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13087]] Orchid: Image Latent Diffusion for Joint Appearance and Geometry Generation(https://arxiv.org/abs/2501.13087)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models are state-of-the-art for image generation. Trained on large datasets, they capture expressive image priors that have been used for tasks like inpainting, depth, and (surface) normal prediction. However, these models are typically trained for one specific task, e.g., a separate model for each of color, depth, and normal prediction. Such models do not leverage the intrinsic correlation between appearance and geometry, often leading to inconsistent predictions. In this paper, we propose using a novel image diffusion prior that jointly encodes appearance and geometry. We introduce a diffusion model Orchid, comprising a Variational Autoencoder (VAE) to encode color, depth, and surface normals to a latent space, and a Latent Diffusion Model (LDM) for generating these joint latents. Orchid directly generates photo-realistic color images, relative depth, and surface normals from user-provided text, and can be used to create image-aligned partial 3D scenes seamlessly. It can also perform image-conditioned tasks like joint monocular depth and normal prediction and is competitive in accuracy to state-of-the-art methods designed for those tasks alone. Lastly, our model learns a joint prior that can be used zero-shot as a regularizer for many inverse problems that entangle appearance and geometry. For example, we demonstrate its effectiveness in color-depth-normal inpainting, showcasing its applicability to problems in 3D generation from sparse views.</li>
</ul>

<h3>Title: Robust Representation Consistency Model via Contrastive Denoising</h3>
<ul>
<li><strong>Authors: </strong>Jiachen Lei, Julius Berner, Jiongxiao Wang, Zhongzhu Chen, Zhongjia Ba, Kui Ren, Jun Zhu, Anima Anandkumar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13094">https://arxiv.org/abs/2501.13094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13094">https://arxiv.org/pdf/2501.13094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13094]] Robust Representation Consistency Model via Contrastive Denoising(https://arxiv.org/abs/2501.13094)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Robustness is essential for deep neural networks, especially in security-sensitive applications. To this end, randomized smoothing provides theoretical guarantees for certifying robustness against adversarial perturbations. Recently, diffusion models have been successfully employed for randomized smoothing to purify noise-perturbed samples before making predictions with a standard classifier. While these methods excel at small perturbation radii, they struggle with larger perturbations and incur a significant computational overhead during inference compared to classical methods. To address this, we reformulate the generative modeling task along the diffusion trajectories in pixel space as a discriminative task in the latent space. Specifically, we use instance discrimination to achieve consistent representations along the trajectories by aligning temporally adjacent points. After fine-tuning based on the learned representations, our model enables implicit denoising-then-classification via a single prediction, substantially reducing inference costs. We conduct extensive experiments on various datasets and achieve state-of-the-art performance with minimal computation budget during inference. For example, our method outperforms the certified accuracy of diffusion-based methods on ImageNet across all perturbation radii by 5.3% on average, with up to 11.6% at larger radii, while reducing inference costs by 85$\times$ on average. Codes are available at: this https URL.</li>
</ul>

<h3>Title: Accelerate High-Quality Diffusion Models with Inner Loop Feedback</h3>
<ul>
<li><strong>Authors: </strong>Matthew Gwilliam, Han Cai, Di Wu, Abhinav Shrivastava, Zhiyu Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2501.13107">https://arxiv.org/abs/2501.13107</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2501.13107">https://arxiv.org/pdf/2501.13107</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2501.13107]] Accelerate High-Quality Diffusion Models with Inner Loop Feedback(https://arxiv.org/abs/2501.13107)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose Inner Loop Feedback (ILF), a novel approach to accelerate diffusion models' inference. ILF trains a lightweight module to predict future features in the denoising process by leveraging the outputs from a chosen diffusion backbone block at a given time step. This approach exploits two key intuitions; (1) the outputs of a given block at adjacent time steps are similar, and (2) performing partial computations for a step imposes a lower burden on the model than skipping the step entirely. Our method is highly flexible, since we find that the feedback module itself can simply be a block from the diffusion backbone, with all settings copied. Its influence on the diffusion forward can be tempered with a learnable scaling factor from zero initialization. We train this module using distillation losses; however, unlike some prior work where a full diffusion backbone serves as the student, our model freezes the backbone, training only the feedback module. While many efforts to optimize diffusion models focus on achieving acceptable image quality in extremely few steps (1-4 steps), our emphasis is on matching best case results (typically achieved in 20 steps) while significantly reducing runtime. ILF achieves this balance effectively, demonstrating strong performance for both class-to-image generation with diffusion transformer (DiT) and text-to-image generation with DiT-based PixArt-alpha and PixArt-sigma. The quality of ILF's 1.7x-1.8x speedups are confirmed by FID, CLIP score, CLIP Image Quality Assessment, ImageReward, and qualitative comparisons.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
