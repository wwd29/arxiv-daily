<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-09-11</h1>
<h3>Title: Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization</h3>
<ul>
<li><strong>Authors: </strong>Federico Fontana, Anxhelo Diko, Romeo Lanzino, Marco Raoul Marini, Bachir Kaddar, Gian Luca Foresti, Luigi Cinque</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.07993">https://arxiv.org/abs/2509.07993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.07993">https://arxiv.org/pdf/2509.07993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.07993]] Revisiting Deepfake Detection: Chronological Continual Learning and the Limits of Generalization(https://arxiv.org/abs/2509.07993)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid evolution of deepfake generation technologies poses critical challenges for detection systems, as non-continual learning methods demand frequent and expensive retraining. We reframe deepfake detection (DFD) as a Continual Learning (CL) problem, proposing an efficient framework that incrementally adapts to emerging visual manipulation techniques while retaining knowledge of past generators. Our framework, unlike prior approaches that rely on unreal simulation sequences, simulates the real-world chronological evolution of deepfake technologies in extended periods across 7 years. Simultaneously, our framework builds upon lightweight visual backbones to allow for the real-time performance of DFD systems. Additionally, we contribute two novel metrics: Continual AUC (C-AUC) for historical performance and Forward Transfer AUC (FWT-AUC) for future generalization. Through extensive experimentation (over 600 simulations), we empirically demonstrate that while efficient adaptation (+155 times faster than full retraining) and robust retention of historical knowledge is possible, the generalization of current approaches to future generators without additional training remains near-random (FWT-AUC $\approx$ 0.5) due to the unique imprint characterizing each existing generator. Such observations are the foundation of our newly proposed Non-Universal Deepfake Distribution Hypothesis. \textbf{Code will be released upon acceptance.}</li>
</ul>

<h3>Title: 3D and 4D World Modeling: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Lingdong Kong, Wesley Yang, Jianbiao Mei, Youquan Liu, Ao Liang, Dekai Zhu, Dongyue Lu, Wei Yin, Xiaotao Hu, Mingkai Jia, Junyuan Deng, Kaiwen Zhang, Yang Wu, Tianyi Yan, Shenyuan Gao, Song Wang, Linfeng Li, Liang Pan, Yong Liu, Jianke Zhu, Wei Tsang Ooi, Steven C.H. Hoi, Ziwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.07996">https://arxiv.org/abs/2509.07996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.07996">https://arxiv.org/pdf/2509.07996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.07996]] 3D and 4D World Modeling: A Survey(https://arxiv.org/abs/2509.07996)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>World modeling has become a cornerstone in AI research, enabling agents to understand, represent, and predict the dynamic environments they inhabit. While prior work largely emphasizes generative methods for 2D image and video data, they overlook the rapidly growing body of work that leverages native 3D and 4D representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds for large-scale scene modeling. At the same time, the absence of a standardized definition and taxonomy for ``world models'' has led to fragmented and sometimes inconsistent claims in the literature. This survey addresses these gaps by presenting the first comprehensive review explicitly dedicated to 3D and 4D world modeling and generation. We establish precise definitions, introduce a structured taxonomy spanning video-based (VideoGen), occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and systematically summarize datasets and evaluation metrics tailored to 3D/4D settings. We further discuss practical applications, identify open challenges, and highlight promising research directions, aiming to provide a coherent and foundational reference for advancing the field. A systematic summary of existing literature is available at this https URL</li>
</ul>

<h3>Title: AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs</h3>
<ul>
<li><strong>Authors: </strong>Debdeep Sanyal, Manodeep Ray, Murari Mandal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08000">https://arxiv.org/abs/2509.08000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08000">https://arxiv.org/pdf/2509.08000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08000]] AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs(https://arxiv.org/abs/2509.08000)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The release of open-weight large language models (LLMs) creates a tension between advancing accessible research and preventing misuse, such as malicious fine-tuning to elicit harmful content. Current safety measures struggle to preserve the general capabilities of the LLM while resisting a determined adversary with full access to the model's weights and architecture, who can use full-parameter fine-tuning to erase existing safeguards. To address this, we introduce AntiDote, a bi-level optimization procedure for training LLMs to be resistant to such tampering. AntiDote involves an auxiliary adversary hypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA) weights conditioned on the defender model's internal activations. The defender LLM is then trained with an objective to nullify the effect of these adversarial weight additions, forcing it to maintain its safety alignment. We validate this approach against a diverse suite of 52 red-teaming attacks, including jailbreak prompting, latent space manipulation, and direct weight-space attacks. AntiDote is upto 27.4\% more robust against adversarial attacks compared to both tamper-resistance and unlearning baselines. Crucially, this robustness is achieved with a minimal trade-off in utility, incurring a performance degradation of upto less than 0.5\% across capability benchmarks including MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute efficient methodology for building open-weight models where safety is a more integral and resilient property.</li>
</ul>

<h3>Title: An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities</h3>
<ul>
<li><strong>Authors: </strong>Shahid Shafi Dar, Bharat Kaurav, Arnav Jain, Chandravardhan Singh Raghaw, Mohammad Zia Ur Rehman, Nagendra Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08003">https://arxiv.org/abs/2509.08003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08003">https://arxiv.org/pdf/2509.08003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08003]] An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities(https://arxiv.org/abs/2509.08003)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In an era of escalating climate change, urban flooding has emerged as a critical challenge for sustainable cities, threatening lives, infrastructure, and ecosystems. Traditional flood detection methods are constrained by their reliance on unimodal data and static rule-based systems, which fail to capture the dynamic, non-linear relationships inherent in flood events. Furthermore, existing attention mechanisms and ensemble learning approaches exhibit limitations in hierarchical refinement, cross-modal feature integration, and adaptability to noisy or unstructured environments, resulting in suboptimal flood classification performance. To address these challenges, we present XFloodNet, a novel framework that redefines urban flood classification through advanced deep-learning techniques. XFloodNet integrates three novel components: (1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically aligns visual and textual features, enabling precise multi-granularity interactions and resolving contextual ambiguities; (2) a Heterogeneous Convolutional Adaptive Multi-Scale Attention module, which leverages frequency-enhanced channel attention and frequency-modulated spatial attention to extract and prioritize discriminative flood-related features across spectral and spatial domains; and (3) a Cascading Convolutional Transformer Feature Refinement technique that harmonizes hierarchical features through adaptive scaling and cascading operations, ensuring robust and noise-resistant flood detection. We evaluate our proposed method on three benchmark datasets, such as Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively, surpassing existing methods by significant margins.</li>
</ul>

<h3>Title: Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs</h3>
<ul>
<li><strong>Authors: </strong>Hyungjin Chung, Hyelin Nam, Jiyeon Kim, Hyojun Go, Byeongjun Park, Junho Kim, Joonseok Lee, Seongsu Ha, Byung-Hoon Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08016">https://arxiv.org/abs/2509.08016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08016">https://arxiv.org/pdf/2509.08016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08016]] Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs(https://arxiv.org/abs/2509.08016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Video Large Language Models (VideoLLMs) face a critical bottleneck: increasing the number of input frames to capture fine-grained temporal detail leads to prohibitive computational costs and performance degradation from long context lengths. We introduce Video Parallel Scaling (VPS), an inference-time method that expands a model's perceptual bandwidth without increasing its context window. VPS operates by running multiple parallel inference streams, each processing a unique, disjoint subset of the video's frames. By aggregating the output probabilities from these complementary streams, VPS integrates a richer set of visual information than is possible with a single pass. We theoretically show that this approach effectively contracts the Chinchilla scaling law by leveraging uncorrelated visual evidence, thereby improving performance without additional training. Extensive experiments across various model architectures and scales (2B-32B) on benchmarks such as Video-MME and EventHallusion demonstrate that VPS consistently and significantly improves performance. It scales more favorably than other parallel alternatives (e.g. Self-consistency) and is complementary to other decoding strategies, offering a memory-efficient and robust framework for enhancing the temporal reasoning capabilities of VideoLLMs.</li>
</ul>

<h3>Title: MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values</h3>
<ul>
<li><strong>Authors: </strong>Yao Liang, Dongcheng Zhao, Feifei Zhao, Guobin Shen, Yuwei Wang, Dongqi Liang, Yi Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08022">https://arxiv.org/abs/2509.08022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08022">https://arxiv.org/pdf/2509.08022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08022]] MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values(https://arxiv.org/abs/2509.08022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The alignment of large language models (LLMs) with human values is critical for their safe and effective deployment across diverse user populations. However, existing benchmarks often neglect cultural and demographic diversity, leading to limited understanding of how value alignment generalizes globally. In this work, we introduce MVPBench, a novel benchmark that systematically evaluates LLMs' alignment with multi-dimensional human value preferences across 75 countries. MVPBench contains 24,020 high-quality instances annotated with fine-grained value labels, personalized questions, and rich demographic metadata, making it the most comprehensive resource of its kind to date. Using MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs, revealing substantial disparities in alignment performance across geographic and demographic lines. We further demonstrate that lightweight fine-tuning methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization (DPO), can significantly enhance value alignment in both in-domain and out-of-domain settings. Our findings underscore the necessity for population-aware alignment evaluation and provide actionable insights for building culturally adaptive and value-sensitive LLMs. MVPBench serves as a practical foundation for future research on global alignment, personalized value modeling, and equitable AI development.</li>
</ul>

<h3>Title: Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change</h3>
<ul>
<li><strong>Authors: </strong>Lata Pangtey, Omkar Kabde, Shahid Shafi Dar, Nagendra Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08024">https://arxiv.org/abs/2509.08024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08024">https://arxiv.org/pdf/2509.08024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08024]] Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change(https://arxiv.org/abs/2509.08024)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>With the rapid proliferation of information across digital platforms, stance detection has emerged as a pivotal challenge in social media analysis. While most of the existing approaches focus solely on textual data, real-world social media content increasingly combines text with visual elements creating a need for advanced multimodal methods. To address this gap, we propose a multimodal stance detection framework that integrates textual and visual information through a hierarchical fusion approach. Our method first employs a Large Language Model to retrieve stance-relevant summaries from source text, while a domain-aware image caption generator interprets visual content in the context of the target topic. These modalities are then jointly modeled along with the reply text, through a specialized transformer module that captures interactions between the texts and images. The proposed modality fusion framework integrates diverse modalities to facilitate robust stance classification. We evaluate our approach on the MultiClimate dataset, a benchmark for climate change-related stance detection containing aligned video frames and transcripts. We achieve accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%, respectively, outperforming existing state-of-the-art approaches.</li>
</ul>

<h3>Title: NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment</h3>
<ul>
<li><strong>Authors: </strong>Hoang-Trung Nguyen, Tan-Minh Nguyen, Xuan-Bach Le, Tuan-Kiet Le, Khanh-Huyen Nguyen, Ha-Thanh Nguyen, Thi-Hai-Yen Vuong, Le-Minh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08025">https://arxiv.org/abs/2509.08025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08025">https://arxiv.org/pdf/2509.08025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08025]] NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment(https://arxiv.org/abs/2509.08025)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents the methodologies and results of the NOWJ team's participation across all five tasks at the COLIEE 2025 competition, emphasizing advancements in the Legal Case Entailment task (Task 2). Our comprehensive approach systematically integrates pre-ranking models (BM25, BERT, monoT5), embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage retrieval system combined lexical-semantic filtering with contextualized LLM analysis, achieving first place with an F1 score of 0.3195. Additionally, in other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal Textual Entailment, and Legal Judgment Prediction--we demonstrated robust performance through carefully engineered ensembles and effective prompt-based reasoning strategies. Our findings highlight the potential of hybrid models integrating traditional IR techniques with contemporary generative models, providing a valuable reference for future advancements in legal information processing.</li>
</ul>

<h3>Title: SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery</h3>
<ul>
<li><strong>Authors: </strong>Fengyu She, Nan Wang, Hongfei Wu, Ziyi Wan, Jingmian Wang, Chang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08032">https://arxiv.org/abs/2509.08032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08032">https://arxiv.org/pdf/2509.08032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08032]] SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery(https://arxiv.org/abs/2509.08032)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Scientific literature is growing exponentially, creating a critical bottleneck for researchers to efficiently synthesize knowledge. While general-purpose Large Language Models (LLMs) show potential in text processing, they often fail to capture scientific domain-specific nuances (e.g., technical jargon, methodological rigor) and struggle with complex scientific tasks, limiting their utility for interdisciplinary research. To address these gaps, this paper presents SciGPT, a domain-adapted foundation model for scientific literature understanding and ScienceBench, an open source benchmark tailored to evaluate scientific LLMs. Built on the Qwen3 architecture, SciGPT incorporates three key innovations: (1) low-cost domain distillation via a two-stage pipeline to balance performance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention mechanism that cuts memory consumption by 55\% for 32,000-token long-document reasoning; and (3) knowledge-aware adaptation integrating domain ontologies to bridge interdisciplinary knowledge gaps. Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in core scientific tasks including sequence labeling, generation, and inference. It also exhibits strong robustness in unseen scientific tasks, validating its potential to facilitate AI-augmented scientific discovery.</li>
</ul>

<h3>Title: How Far Are We from True Unlearnability?</h3>
<ul>
<li><strong>Authors: </strong>Kai Ye, Liangcai Su, Chenxiong Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08058">https://arxiv.org/abs/2509.08058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08058">https://arxiv.org/pdf/2509.08058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08058]] How Far Are We from True Unlearnability?(https://arxiv.org/abs/2509.08058)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>High-quality data plays an indispensable role in the era of large models, but the use of unauthorized data for model training greatly damages the interests of data owners. To overcome this threat, several unlearnable methods have been proposed, which generate unlearnable examples (UEs) by compromising the training availability of data. Clearly, due to unknown training purposes and the powerful representation learning capabilities of existing models, these data are expected to be unlearnable for models across multiple tasks, i.e., they will not help improve the model's performance. However, unexpectedly, we find that on the multi-task dataset Taskonomy, UEs still perform well in tasks such as semantic segmentation, failing to exhibit cross-task unlearnability. This phenomenon leads us to question: How far are we from attaining truly unlearnable examples? We attempt to answer this question from the perspective of model optimization. To this end, we observe the difference in the convergence process between clean and poisoned models using a simple model architecture. Subsequently, from the loss landscape we find that only a part of the critical parameter optimization paths show significant differences, implying a close relationship between the loss landscape and unlearnability. Consequently, we employ the loss landscape to explain the underlying reasons for UEs and propose Sharpness-Aware Learnability (SAL) to quantify the unlearnability of parameters based on this explanation. Furthermore, we propose an Unlearnable Distance (UD) to measure the unlearnability of data based on the SAL distribution of parameters in clean and poisoned models. Finally, we conduct benchmark tests on mainstream unlearnable methods using the proposed UD, aiming to promote community awareness of the capability boundaries of existing unlearnable methods.</li>
</ul>

<h3>Title: No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Flor Miriam Plaza-del-Arco, Paul Röttger, Nino Scherrer, Emanuele Borgonovo, Elmar Plischke, Dirk Hovy</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08075">https://arxiv.org/abs/2509.08075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08075">https://arxiv.org/pdf/2509.08075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08075]] No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models(https://arxiv.org/abs/2509.08075)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly integrated into our daily lives and personalized. However, LLM personalization might also increase unintended side effects. Recent work suggests that persona prompting can lead models to falsely refuse user requests. However, no work has fully quantified the extent of this issue. To address this gap, we measure the impact of 15 sociodemographic personas (based on gender, race, religion, and disability) on false refusal. To control for other factors, we also test 16 different models, 3 tasks (Natural Language Inference, politeness, and offensiveness classification), and nine prompt paraphrases. We propose a Monte Carlo-based method to quantify this issue in a sample-efficient manner. Our results show that as models become more capable, personas impact the refusal rate less and less. Certain sociodemographic personas increase false refusal in some models, which suggests underlying biases in the alignment strategies or safety mechanisms. However, we find that the model choice and task significantly influence false refusals, especially in sensitive content tasks. Our findings suggest that persona effects have been overestimated, and might be due to other factors.</li>
</ul>

<h3>Title: Establishing a Baseline of Software Supply Chain Security Task Adoption by Software Organizations</h3>
<ul>
<li><strong>Authors: </strong>Laurie Williams, Sammy Migues</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08083">https://arxiv.org/abs/2509.08083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08083">https://arxiv.org/pdf/2509.08083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08083]] Establishing a Baseline of Software Supply Chain Security Task Adoption by Software Organizations(https://arxiv.org/abs/2509.08083)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Software supply chain attacks have increased exponentially since 2020. The primary attack vectors for supply chain attacks are through: (1) software components; (2) the build infrastructure; and (3) humans (a.k.a software practitioners). Software supply chain risk management frameworks provide a list of tasks that an organization can adopt to reduce software supply chain risk. Exhaustively adopting all the tasks of these frameworks is infeasible, necessitating the prioritized adoption of tasks. Software organizations can benefit from being guided in this prioritization by learning what tasks other teams have adopted. The goal of this study is to aid software development organizations in understanding the adoption of security tasks that reduce software supply chain risk through an interview study of software practitioners engaged in software supply chain risk management efforts. An interview study was conducted with 61 practitioners at nine software development organizations that have focused efforts on reducing software supply chain risk. The results of the interviews indicate that organizations had implemented the most adopted software tasks before the focus on software supply chain security. Therefore, their implementation in organizations is more mature. The tasks that mitigate the novel attack vectors through software components and the build infrastructure are in the early stages of adoption. Adoption of these tasks should be prioritized.</li>
</ul>

<h3>Title: Performance Assessment Strategies for Generative AI Applications in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Victor Garcia, Mariia Sidulova, Aldo Badano</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08087">https://arxiv.org/abs/2509.08087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08087">https://arxiv.org/pdf/2509.08087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08087]] Performance Assessment Strategies for Generative AI Applications in Healthcare(https://arxiv.org/abs/2509.08087)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative artificial intelligence (GenAI) represent an emerging paradigm within artificial intelligence, with applications throughout the medical enterprise. Assessing GenAI applications necessitates a comprehensive understanding of the clinical task and awareness of the variability in performance when implemented in actual clinical environments. Presently, a prevalent method for evaluating the performance of generative models relies on quantitative benchmarks. Such benchmarks have limitations and may suffer from train-to-the-test overfitting, optimizing performance for a specified test set at the cost of generalizability across other task and data distributions. Evaluation strategies leveraging human expertise and utilizing cost-effective computational models as evaluators are gaining interest. We discuss current state-of-the-art methodologies for assessing the performance of GenAI applications in healthcare and medical devices.</li>
</ul>

<h3>Title: Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Lucas Fenaux, Zheng Wang, Jacob Yan, Nathan Chung, Florian Kerschbaum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08089">https://arxiv.org/abs/2509.08089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08089">https://arxiv.org/pdf/2509.08089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08089]] Hammer and Anvil: A Principled Defense Against Backdoors in Federated Learning(https://arxiv.org/abs/2509.08089)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning is a distributed learning technique in which multiple clients cooperate to train a machine learning model. Distributed settings facilitate backdoor attacks by malicious clients, who can embed malicious behaviors into the model during their participation in the training process. These malicious behaviors are activated during inference by a specific trigger. No defense against backdoor attacks has stood the test of time, especially against adaptive attackers, a powerful but not fully explored category of attackers. In this work, we first devise a new adaptive adversary that surpasses existing adversaries in capabilities, yielding attacks that only require one or two malicious clients out of 20 to break existing state-of-the-art defenses. Then, we present Hammer and Anvil, a principled defense approach that combines two defenses orthogonal in their underlying principle to produce a combined defense that, given the right set of parameters, must succeed against any attack. We show that our best combined defense, Krum+, is successful against our new adaptive adversary and state-of-the-art attacks.</li>
</ul>

<h3>Title: SAGE: Sample-Aware Guarding Engine for Robust Intrusion Detection Against Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jing Chen, Onat Gungor, Zhengli Shang, Tajana Rosing</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08091">https://arxiv.org/abs/2509.08091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08091">https://arxiv.org/pdf/2509.08091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08091]] SAGE: Sample-Aware Guarding Engine for Robust Intrusion Detection Against Adversarial Attacks(https://arxiv.org/abs/2509.08091)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of the Internet of Things (IoT) continues to expose critical security vulnerabilities, necessitating the development of efficient and robust intrusion detection systems (IDS). Machine learning-based intrusion detection systems (ML-IDS) have significantly improved threat detection capabilities; however, they remain highly susceptible to adversarial attacks. While numerous defense mechanisms have been proposed to enhance ML-IDS resilience, a systematic approach for selecting the most effective defense against a specific adversarial attack remains absent. To address this challenge, we previously proposed DYNAMITE, a dynamic defense selection approach that identifies the most suitable defense against adversarial attacks through an ML-driven selection mechanism. Building on this foundation, we propose SAGE (Sample-Aware Guarding Engine), a substantially improved defense algorithm that integrates active learning with targeted data reduction. It employs an active learning mechanism to selectively identify the most informative input samples and their corresponding optimal defense labels, which are then used to train a second-level learner responsible for selecting the most effective defense. This targeted sampling improves computational efficiency, exposes the model to diverse adversarial strategies during training, and enhances robustness, stability, and generalizability. As a result, SAGE demonstrates strong predictive performance across multiple intrusion detection datasets, achieving an average F1-score improvement of 201% over the state-of-the-art defenses. Notably, SAGE narrows the performance gap to the Oracle to just 3.8%, while reducing computational overhead by up to 29x.</li>
</ul>

<h3>Title: Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression</h3>
<ul>
<li><strong>Authors: </strong>Nathaniel Imel, Noga Zaslavsky</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08093">https://arxiv.org/abs/2509.08093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08093">https://arxiv.org/pdf/2509.08093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08093]] Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression(https://arxiv.org/abs/2509.08093)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Converging evidence suggests that systems of semantic categories across human languages achieve near-optimal compression via the Information Bottleneck (IB) complexity-accuracy principle. Large language models (LLMs) are not trained for this objective, which raises the question: are LLMs capable of evolving efficient human-like semantic systems? To address this question, we focus on the domain of color as a key testbed of cognitive theories of categorization and replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two influential human behavioral studies. First, we conduct an English color-naming study, showing that Gemini aligns well with the naming patterns of native English speakers and achieves a significantly high IB-efficiency score, while Llama exhibits an efficient but lower complexity system compared to English. Second, to test whether LLMs simply mimic patterns in their training data or actually exhibit a human-like inductive bias toward IB-efficiency, we simulate cultural evolution of pseudo color-naming systems in LLMs via iterated in-context language learning. We find that akin to humans, LLMs iteratively restructure initially random systems towards greater IB-efficiency and increased alignment with patterns observed across the world's languages. These findings demonstrate that LLMs are capable of evolving perceptually grounded, human-like semantic systems, driven by the same fundamental principle that governs semantic efficiency across human languages.</li>
</ul>

<h3>Title: APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Sasan Sharifipour, Constantino Álvarez Casado, Mohammad Sabokrou, Miguel Bordallo López</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08104">https://arxiv.org/abs/2509.08104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08104">https://arxiv.org/pdf/2509.08104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08104]] APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction(https://arxiv.org/abs/2509.08104)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Training deep learning models for point cloud prediction tasks such as shape completion and generation depends critically on loss functions that measure discrepancies between predicted and ground-truth point sets. Commonly used functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on nearest-neighbor assignments, which often induce many-to-one correspondences, leading to point congestion in dense regions and poor coverage in sparse regions. These losses also involve non-differentiable operations due to index selection, which may affect gradient-based optimization. Earth Mover Distance (EMD) enforces one-to-one correspondences and captures structural similarity more effectively, but its cubic computational complexity limits its practical use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully differentiable approximation of one-to-one matching that leverages Sinkhorn iterations on a temperature-scaled similarity matrix derived from pairwise distances. We analytically compute the temperature to guarantee a minimum assignment probability, eliminating manual tuning. APML achieves near-quadratic runtime, comparable to Chamfer-based losses, and avoids non-differentiable operations. When integrated into state-of-the-art architectures (PoinTr, PCN, FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC) that generates 3D human point clouds from WiFi CSI measurements, APM loss yields faster convergence, superior spatial distribution, especially in low-density regions, and improved or on-par quantitative performance without additional hyperparameter search. The code is available at: this https URL.</li>
</ul>

<h3>Title: MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion</h3>
<ul>
<li><strong>Authors: </strong>Kosei Uemura, David Guzmán, Quang Phuoc Nguyen, Jesujoba Oluwadara Alabi, En-shiun Annie Lee, David Ifeoluwa Adelani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08105">https://arxiv.org/abs/2509.08105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08105">https://arxiv.org/pdf/2509.08105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08105]] MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion(https://arxiv.org/abs/2509.08105)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models excel in English but still struggle with complex reasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder methods such as LangBridge and MindMerger raise accuracy on mid and high-resource languages, yet they leave a large gap on LRLs. We present MERLIN, a two-stage model-stacking framework that applies a curriculum learning strategy -- from general bilingual bitext to task-specific data -- and adapts only a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves exact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini. It also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp), demonstrating effectiveness across both low and high-resource settings.</li>
</ul>

<h3>Title: Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography</h3>
<ul>
<li><strong>Authors: </strong>Nooshin Maghsoodi, Sarah Nassar, Paul F R Wilson, Minh Nguyen Nhat To, Sophia Mannina, Shamel Addas, Stephanie Sibley, David Maslove, Purang Abolmaesumi, Parvin Mousavi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08116">https://arxiv.org/abs/2509.08116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08116">https://arxiv.org/pdf/2509.08116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08116]] Domain Knowledge is Power: Leveraging Physiological Priors for Self Supervised Representation Learning in Electrocardiography(https://arxiv.org/abs/2509.08116)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Objective: Electrocardiograms (ECGs) play a crucial role in diagnosing heart conditions; however, the effectiveness of artificial intelligence (AI)-based ECG analysis is often hindered by the limited availability of labeled data. Self-supervised learning (SSL) can address this by leveraging large-scale unlabeled data. We introduce PhysioCLR (Physiology-aware Contrastive Learning Representation for ECG), a physiology-aware contrastive learning framework that incorporates domain-specific priors to enhance the generalizability and clinical relevance of ECG-based arrhythmia classification. Methods: During pretraining, PhysioCLR learns to bring together embeddings of samples that share similar clinically relevant features while pushing apart those that are dissimilar. Unlike existing methods, our method integrates ECG physiological similarity cues into contrastive learning, promoting the learning of clinically meaningful representations. Additionally, we introduce ECG- specific augmentations that preserve the ECG category post augmentation and propose a hybrid loss function to further refine the quality of learned representations. Results: We evaluate PhysioCLR on two public ECG datasets, Chapman and Georgia, for multilabel ECG diagnoses, as well as a private ICU dataset labeled for binary classification. Across the Chapman, Georgia, and private cohorts, PhysioCLR boosts the mean AUROC by 12% relative to the strongest baseline, underscoring its robust cross-dataset generalization. Conclusion: By embedding physiological knowledge into contrastive learning, PhysioCLR enables the model to learn clinically meaningful and transferable ECG eatures. Significance: PhysioCLR demonstrates the potential of physiology-informed SSL to offer a promising path toward more effective and label-efficient ECG diagnostics.</li>
</ul>

<h3>Title: Optimization Methods and Software for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Konstantin Burlachenko</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08120">https://arxiv.org/abs/2509.08120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08120">https://arxiv.org/pdf/2509.08120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08120]] Optimization Methods and Software for Federated Learning(https://arxiv.org/abs/2509.08120)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a novel, multidisciplinary Machine Learning paradigm where multiple clients, such as mobile devices, collaborate to solve machine learning problems. Initially introduced in Kone{č}n{ý} et al. (2016a,b); McMahan et al. (2017), FL has gained further attention through its inclusion in the National AI Research and Development Strategic Plan (2023 Update) of the United States (Science and on Artificial Intelligence, 2023). The FL training process is inherently decentralized and often takes place in less controlled settings compared to data centers, posing unique challenges distinct from those in fully controlled environments. In this thesis, we identify five key challenges in Federated Learning and propose novel approaches to address them. These challenges arise from the heterogeneity of data and devices, communication issues, and privacy concerns for clients in FL training. Moreover, even well-established theoretical advances in FL require diverse forms of practical implementation to enhance their real-world applicability. Our contributions advance FL algorithms and systems, bridging theoretical advancements and practical implementations. More broadly, our work serves as a guide for researchers navigating the complexities of translating theoretical methods into efficient real-world implementations and software. Additionally, it offers insights into the reverse process of adapting practical implementation aspects back into theoretical algorithm design. This reverse process is particularly intriguing, as the practical perspective compels us to examine the underlying mechanics and flexibilities of algorithms more deeply, often uncovering new dimensions of the algorithms under study.</li>
</ul>

<h3>Title: In-Context Learning Enhanced Credibility Transformer</h3>
<ul>
<li><strong>Authors: </strong>Kishan Padayachy, Ronald Richman, Salvatore Scognamiglio, Mario V. Wüthrich</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08122">https://arxiv.org/abs/2509.08122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08122">https://arxiv.org/pdf/2509.08122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08122]] In-Context Learning Enhanced Credibility Transformer(https://arxiv.org/abs/2509.08122)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The starting point of our network architecture is the Credibility Transformer which extends the classical Transformer architecture by a credibility mechanism to improve model learning and predictive performance. This Credibility Transformer learns credibilitized CLS tokens that serve as learned representations of the original input features. In this paper we present a new paradigm that augments this architecture by an in-context learning mechanism, i.e., we increase the information set by a context batch consisting of similar instances. This allows the model to enhance the CLS token representations of the instances by additional in-context information and fine-tuning. We empirically verify that this in-context learning enhances predictive accuracy by adapting to similar risk patterns. Moreover, this in-context learning also allows the model to generalize to new instances which, e.g., have feature levels in the categorical covariates that have not been present when the model was trained -- for a relevant example, think of a new vehicle model which has just been developed by a car manufacturer.</li>
</ul>

<h3>Title: From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital</h3>
<ul>
<li><strong>Authors: </strong>Mihir Kumar, Aaron Ontoyin Yin, Zakari Salifu, Kelvin Amoaba, Afriyie Kwesi Samuel, Fuat Alican, Yigit Ihlamur</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08140">https://arxiv.org/abs/2509.08140</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08140">https://arxiv.org/pdf/2509.08140</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08140]] From Limited Data to Rare-event Prediction: LLM-powered Feature Engineering and Multi-model Learning in Venture Capital(https://arxiv.org/abs/2509.08140)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a framework for predicting rare, high-impact outcomes by integrating large language models (LLMs) with a multi-model machine learning (ML) architecture. The approach combines the predictive strength of black-box models with the interpretability required for reliable decision-making. We use LLM-powered feature engineering to extract and synthesize complex signals from unstructured data, which are then processed within a layered ensemble of models including XGBoost, Random Forest, and Linear Regression. The ensemble first produces a continuous estimate of success likelihood, which is then thresholded to produce a binary rare-event prediction. We apply this framework to the domain of Venture Capital (VC), where investors must evaluate startups with limited and noisy early-stage data. The empirical results show strong performance: the model achieves precision between 9.8X and 11.1X the random classifier baseline in three independent test subsets. Feature sensitivity analysis further reveals interpretable success drivers: the startup's category list accounts for 15.6% of predictive influence, followed by the number of founders, while education level and domain expertise contribute smaller yet consistent effects.</li>
</ul>

<h3>Title: Bias after Prompting: Persistent Discrimination in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Nivedha Sivakumar, Natalie Mackraz, Samira Khorshidi, Krishna Patel, Barry-John Theobald, Luca Zappella, Nicholas Apostoloff</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08146">https://arxiv.org/abs/2509.08146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08146">https://arxiv.org/pdf/2509.08146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08146]] Bias after Prompting: Persistent Discrimination in Large Language Models(https://arxiv.org/abs/2509.08146)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A dangerous assumption that can be made from prior work on the bias transfer hypothesis (BTH) is that biases do not transfer from pre-trained large language models (LLMs) to adapted models. We invalidate this assumption by studying the BTH in causal models under prompt adaptations, as prompting is an extremely popular and accessible adaptation strategy used in real-world applications. In contrast to prior work, we find that biases can transfer through prompting and that popular prompt-based mitigation methods do not consistently prevent biases from transferring. Specifically, the correlation between intrinsic biases and those after prompt adaptation remain moderate to strong across demographics and tasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age (rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we find that biases remain strongly correlated when varying few-shot composition parameters, such as sample size, stereotypical content, occupational distribution and representational balance (rho >= 0.90). We evaluate several prompt-based debiasing strategies and find that different approaches have distinct strengths, but none consistently reduce bias transfer across models, tasks or demographics. These results demonstrate that correcting bias, and potentially improving reasoning ability, in intrinsic models may prevent propagation of biases to downstream tasks.</li>
</ul>

<h3>Title: MMM-fair: An Interactive Toolkit for Exploring and Operationalizing Multi-Fairness Trade-offs</h3>
<ul>
<li><strong>Authors: </strong>Swati Swati, Arjun Roy, Emmanouil Panagiotou, Eirini Ntoutsi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08156">https://arxiv.org/abs/2509.08156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08156">https://arxiv.org/pdf/2509.08156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08156]] MMM-fair: An Interactive Toolkit for Exploring and Operationalizing Multi-Fairness Trade-offs(https://arxiv.org/abs/2509.08156)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness-aware classification requires balancing performance and fairness, often intensified by intersectional biases. Conflicting fairness definitions further complicate the task, making it difficult to identify universally fair solutions. Despite growing regulatory and societal demands for equitable AI, popular toolkits offer limited support for exploring multi-dimensional fairness and related trade-offs. To address this, we present mmm-fair, an open-source toolkit leveraging boosting-based ensemble approaches that dynamically optimizes model weights to jointly minimize classification errors and diverse fairness violations, enabling flexible multi-objective optimization. The system empowers users to deploy models that align with their context-specific needs while reliably uncovering intersectional biases often missed by state-of-the-art methods. In a nutshell, mmm-fair uniquely combines in-depth multi-attribute fairness, multi-objective optimization, a no-code, chat-based interface, LLM-powered explanations, interactive Pareto exploration for model selection, custom fairness constraint definition, and deployment-ready models in a single open-source toolkit, a combination rarely found in existing fairness tools. Demo walkthrough available at: this https URL.</li>
</ul>

<h3>Title: Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation</h3>
<ul>
<li><strong>Authors: </strong>Ho Ming Lee, Katrien Antonio, Benjamin Avanzi, Lorenzo Marchi, Rui Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.RM, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08163">https://arxiv.org/abs/2509.08163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08163">https://arxiv.org/pdf/2509.08163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08163]] Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation(https://arxiv.org/abs/2509.08163)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Ensuring equitable treatment (fairness) across protected attributes (such as gender or ethnicity) is a critical issue in machine learning. Most existing literature focuses on binary classification, but achieving fairness in regression tasks-such as insurance pricing or hiring score assessments-is equally important. Moreover, anti-discrimination laws also apply to continuous attributes, such as age, for which many existing methods are not applicable. In practice, multiple protected attributes can exist simultaneously; however, methods targeting fairness across several attributes often overlook so-called "fairness gerrymandering", thereby ignoring disparities among intersectional subgroups (e.g., African-American women or Hispanic men). In this paper, we propose a distance covariance regularisation framework that mitigates the association between model predictions and protected attributes, in line with the fairness definition of demographic parity, and that captures both linear and nonlinear dependencies. To enhance applicability in the presence of multiple protected attributes, we extend our framework by incorporating two multivariate dependence measures based on distance covariance: the previously proposed joint distance covariance (JdCov) and our novel concatenated distance covariance (CCdCov), which effectively address fairness gerrymandering in both regression and classification tasks involving protected attributes of various types. We discuss and illustrate how to calibrate regularisation strength, including a method based on Jensen-Shannon divergence, which quantifies dissimilarities in prediction distributions across groups. We apply our framework to the COMPAS recidivism dataset and a large motor insurance claims dataset.</li>
</ul>

<h3>Title: Selective Induction Heads: How Transformers Select Causal Structures In Context</h3>
<ul>
<li><strong>Authors: </strong>Francesco D'Angelo, Francesco Croce, Nicolas Flammarion</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08184">https://arxiv.org/abs/2509.08184</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08184">https://arxiv.org/pdf/2509.08184</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08184]] Selective Induction Heads: How Transformers Select Causal Structures In Context(https://arxiv.org/abs/2509.08184)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have exhibited exceptional capabilities in sequence modeling tasks, leveraging self-attention and in-context learning. Critical to this success are induction heads, attention circuits that enable copying tokens based on their previous occurrences. In this work, we introduce a novel framework that showcases transformers' ability to dynamically handle causal structures. Existing works rely on Markov Chains to study the formation of induction heads, revealing how transformers capture causal dependencies and learn transition probabilities in-context. However, they rely on a fixed causal structure that fails to capture the complexity of natural languages, where the relationship between tokens dynamically changes with context. To this end, our framework varies the causal structure through interleaved Markov chains with different lags while keeping the transition probabilities fixed. This setting unveils the formation of Selective Induction Heads, a new circuit that endows transformers with the ability to select the correct causal structure in-context. We empirically demonstrate that transformers learn this mechanism to predict the next token by identifying the correct lag and copying the corresponding token from the past. We provide a detailed construction of a 3-layer transformer to implement the selective induction head, and a theoretical analysis proving that this mechanism asymptotically converges to the maximum likelihood solution. Our findings advance the understanding of how transformers select causal structures, providing new insights into their functioning and interpretability.</li>
</ul>

<h3>Title: ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Hritik Arasu, Faisal R Jahangiri</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08188">https://arxiv.org/abs/2509.08188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08188">https://arxiv.org/pdf/2509.08188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08188]] ArtifactGen: Benchmarking WGAN-GP vs Diffusion for Label-Aware EEG Artifact Synthesis(https://arxiv.org/abs/2509.08188)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Artifacts in electroencephalography (EEG) -- muscle, eye movement, electrode, chewing, and shiver -- confound automated analysis yet are costly to label at scale. We study whether modern generative models can synthesize realistic, label-aware artifact segments suitable for augmentation and stress-testing. Using the TUH EEG Artifact (TUAR) corpus, we curate subject-wise splits and fixed-length multi-channel windows (e.g., 250 samples) with preprocessing tailored to each model (per-window min--max for adversarial training; per-recording/channel $z$-score for diffusion). We compare a conditional WGAN-GP with a projection discriminator to a 1D denoising diffusion model with classifier-free guidance, and evaluate along three axes: (i) fidelity via Welch band-power deltas ($\Delta\delta,\ \Delta\theta,\ \Delta\alpha,\ \Delta\beta$), channel-covariance Frobenius distance, autocorrelation $L_2$, and distributional metrics (MMD/PRD); (ii) specificity via class-conditional recovery with lightweight $k$NN/classifiers; and (iii) utility via augmentation effects on artifact recognition. In our setting, WGAN-GP achieves closer spectral alignment and lower MMD to real data, while both models exhibit weak class-conditional recovery, limiting immediate augmentation gains and revealing opportunities for stronger conditioning and coverage. We release a reproducible pipeline -- data manifests, training configurations, and evaluation scripts -- to establish a baseline for EEG artifact synthesis and to surface actionable failure modes for future work.</li>
</ul>

<h3>Title: Sketched Gaussian Mechanism for Private Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Qiaobo Li, Zhijie Chen, Arindam Banerjee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08195">https://arxiv.org/abs/2509.08195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08195">https://arxiv.org/pdf/2509.08195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08195]] Sketched Gaussian Mechanism for Private Federated Learning(https://arxiv.org/abs/2509.08195)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Communication cost and privacy are two major considerations in federated learning (FL). For communication cost, gradient compression by sketching the clients' transmitted model updates is often used for reducing per-round communication. For privacy, the Gaussian mechanism (GM), which consists of clipping updates and adding Gaussian noise, is commonly used to guarantee client-level differential privacy. Existing literature on private FL analyzes privacy of sketching and GM in an isolated manner, illustrating that sketching provides privacy determined by the sketching dimension and that GM has to supply any additional desired privacy. In this paper, we introduce the Sketched Gaussian Mechanism (SGM), which directly combines sketching and the Gaussian mechanism for privacy. Using Rényi-DP tools, we present a joint analysis of SGM's overall privacy guarantee, which is significantly more flexible and sharper compared to isolated analysis of sketching and GM privacy. In particular, we prove that the privacy level of SGM for a fixed noise magnitude is proportional to $1/\sqrt{b}$, where $b$ is the sketching dimension, indicating that (for moderate $b$) SGM can provide much stronger privacy guarantees than the original GM under the same noise budget. We demonstrate the application of SGM to FL with either gradient descent or adaptive server optimizers, and establish theoretical results on optimization convergence, which exhibits only a logarithmic dependence on the number of parameters $d$. Experimental results confirm that at the same privacy level, SGM based FL is at least competitive with non-sketching private FL variants and outperforms them in some settings. Moreover, using adaptive optimization at the server improves empirical performance while maintaining the privacy guarantees.</li>
</ul>

<h3>Title: Unlocking Reproducibility: Automating re-Build Process for Open-Source Software</h3>
<ul>
<li><strong>Authors: </strong>Behnaz Hassanshahi, Trong Nhan Mai, Benjamin Selwyn Smith, Nicholas Allen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08204">https://arxiv.org/abs/2509.08204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08204">https://arxiv.org/pdf/2509.08204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08204]] Unlocking Reproducibility: Automating re-Build Process for Open-Source Software(https://arxiv.org/abs/2509.08204)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>Software ecosystems like Maven Central play a crucial role in modern software supply chains by providing repositories for libraries and build plugins. However, the separation between binaries and their corresponding source code in Maven Central presents a significant challenge, particularly when it comes to linking binaries back to their original build environment. This lack of transparency poses security risks, as approximately 84% of the top 1200 commonly used artifacts are not built using a transparent CI/CD pipeline. Consequently, users must place a significant amount of trust not only in the source code but also in the environment in which these artifacts are built. Rebuilding software artifacts from source provides a robust solution to improve supply chain security. This approach allows for a deeper review of code, verification of binary-source equivalence, and control over dependencies. However, challenges arise due to variations in build environments, such as JDK versions and build commands, which can lead to build failures. Additionally, ensuring that all dependencies are rebuilt from source across large and complex dependency graphs further complicates the process. In this paper, we introduce an extension to Macaron, an industry-grade open-source supply chain security framework, to automate the rebuilding of Maven artifacts from source. Our approach improves upon existing tools, by offering better performance in source code detection and automating the extraction of build specifications from GitHub Actions workflows. We also present a comprehensive root cause analysis of build failures in Java projects and propose a scalable solution to automate the rebuilding of artifacts, ultimately enhancing security and transparency in the open-source supply chain.</li>
</ul>

<h3>Title: Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection</h3>
<ul>
<li><strong>Authors: </strong>Jingjing Liu, Yinchao Han, Xianchao Xiu, Jianhua Zhang, Wanquan Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08205">https://arxiv.org/abs/2509.08205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08205">https://arxiv.org/pdf/2509.08205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08205]] Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection(https://arxiv.org/abs/2509.08205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Infrared small target detection (ISTD) is one of the key techniques in image processing. Although deep unfolding networks (DUNs) have demonstrated promising performance in ISTD due to their model interpretability and data adaptability, existing methods still face significant challenges in parameter lightweightness and noise robustness. In this regard, we propose a highly lightweight framework based on robust principal component analysis (RPCA) called L-RPCANet. Technically, a hierarchical bottleneck structure is constructed to reduce and increase the channel dimension in the single-channel input infrared image to achieve channel-wise feature refinement, with bottleneck layers designed in each module to extract features. This reduces the number of channels in feature extraction and improves the lightweightness of network parameters. Furthermore, a noise reduction module is embedded to enhance the robustness against complex noise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a channel attention mechanism to focus on the varying importance of different features across channels, thereby achieving excellent performance while maintaining both lightweightness and robustness. Extensive experiments on the ISTD datasets validate the superiority of our proposed method compared with state-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code will be available at this https URL.</li>
</ul>

<h3>Title: Ensemble Distribution Distillation for Self-Supervised Human Activity Recognition</h3>
<ul>
<li><strong>Authors: </strong>Matthew Nolan, Lina Yao, Robert Davidson</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08225">https://arxiv.org/abs/2509.08225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08225">https://arxiv.org/pdf/2509.08225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08225]] Ensemble Distribution Distillation for Self-Supervised Human Activity Recognition(https://arxiv.org/abs/2509.08225)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Human Activity Recognition (HAR) has seen significant advancements with the adoption of deep learning techniques, yet challenges remain in terms of data requirements, reliability and robustness. This paper explores a novel application of Ensemble Distribution Distillation (EDD) within a self-supervised learning framework for HAR aimed at overcoming these challenges. By leveraging unlabeled data and a partially supervised training strategy, our approach yields an increase in predictive accuracy, robust estimates of uncertainty, and substantial increases in robustness against adversarial perturbation; thereby significantly improving reliability in real-world scenarios without increasing computational complexity at inference. We demonstrate this with an evaluation on several publicly available datasets. The contributions of this work include the development of a self-supervised EDD framework, an innovative data augmentation technique designed for HAR, and empirical validation of the proposed method's effectiveness in increasing robustness and reliability.</li>
</ul>

<h3>Title: Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing</h3>
<ul>
<li><strong>Authors: </strong>Miao Cao, Siming Zheng, Lishun Wang, Ziyang Chen, David Brady, Xin Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08228">https://arxiv.org/abs/2509.08228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08228">https://arxiv.org/pdf/2509.08228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08228]] Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing(https://arxiv.org/abs/2509.08228)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Digital cameras consume ~0.1 microjoule per pixel to capture and encode video, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps. Imagining gigapixel cameras operating at 100-1000 fps, the current processing model is unsustainable. To address this, physical layer compressive measurement has been proposed to reduce power consumption per pixel by 10-100X. Video Snapshot Compressive Imaging (SCI) introduces high frequency modulation in the optical sensor layer to increase effective frame rate. A commonly used sampling strategy of video SCI is Random Sampling (RS) where each mask element value is randomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated that images can be recovered from a fraction of the image pixels. Inspired by I2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial location, only one sub-frame is set to 1 and all others are set to 0. We then build a Digital Micro-mirror Device (DMD) encoding system to verify the effectiveness of our USS strategy. Ideally, we can decompose the USS measurement into sub-measurements for which we can utilize I2P algorithms to recover high-speed frames. However, due to the mismatch between the DMD and CCD, the USS measurement cannot be perfectly decomposed. To this end, we propose BSTFormer, a sparse TransFormer that utilizes local Block attention, global Sparse attention, and global Temporal attention to exploit the sparsity of the USS measurement. Extensive results on both simulated and real-world data show that our method significantly outperforms all previous state-of-the-art algorithms. Additionally, an essential advantage of the USS strategy is its higher dynamic range than that of the RS strategy. Finally, from the application perspective, the USS strategy is a good choice to implement a complete video SCI system on chip due to its fixed exposure time.</li>
</ul>

<h3>Title: Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization</h3>
<ul>
<li><strong>Authors: </strong>Kai Yi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08233">https://arxiv.org/abs/2509.08233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08233">https://arxiv.org/pdf/2509.08233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08233]] Strategies for Improving Communication Efficiency in Distributed and Federated Learning: Compression, Local Training, and Personalization(https://arxiv.org/abs/2509.08233)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate</a></li>
<li><strong>Abstract: </strong>Distributed and federated learning are essential paradigms for training models across decentralized data sources while preserving privacy, yet communication overhead remains a major bottleneck. This dissertation explores strategies to improve communication efficiency, focusing on model compression, local training, and personalization. We establish a unified framework for biased and unbiased compression operators with convergence guarantees, then propose adaptive local training strategies that incorporate personalization to accelerate convergence and mitigate client drift. In particular, Scafflix balances global and personalized objectives, achieving superior performance under both IID and non-IID settings. We further introduce privacy-preserving pruning frameworks that optimize sparsity while minimizing communication costs, with Cohort-Squeeze leveraging hierarchical aggregation to reduce cross-device overhead. Finally, SymWanda, a symmetric post-training pruning method, enhances robustness under high sparsity and maintains accuracy without retraining. Extensive experiments on benchmarks and large-scale language models demonstrate favorable trade-offs among accuracy, convergence, and communication, offering theoretical and practical insights for scalable, efficient distributed learning.</li>
</ul>

<h3>Title: RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification</h3>
<ul>
<li><strong>Authors: </strong>Faisal Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08234">https://arxiv.org/abs/2509.08234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08234">https://arxiv.org/pdf/2509.08234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08234]] RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification(https://arxiv.org/abs/2509.08234)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Chest X-ray (CXR) imaging remains one of the most widely used diagnostic tools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia. Recent advances in deep learning, particularly Vision Transformers (ViTs), have shown strong potential for automated medical image analysis. However, most ViT architectures are pretrained on natural images and require three-channel inputs, while CXR scans are inherently grayscale. To address this gap, we propose RepViT-CXR, a channel replication strategy that adapts single-channel CXR images into a ViT-compatible format without introducing additional information loss. We evaluate RepViT-CXR on three benchmark datasets. On the TB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%, surpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy, 99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0% accuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%, outperforming strong baselines including DCNN and VGG16. On the Shenzhen TB dataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a performance improvement over previously reported CNN-based methods. These results demonstrate that a simple yet effective channel replication strategy allows ViTs to fully leverage their representational power on grayscale medical imaging tasks. RepViT-CXR establishes a new state of the art for TB and pneumonia detection from chest X-rays, showing strong potential for deployment in real-world clinical screening systems.</li>
</ul>

<h3>Title: Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI</h3>
<ul>
<li><strong>Authors: </strong>Zheng Yang, Yanteng Zhang, Xupeng Kou, Yang Liu, Chao Ren</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08243">https://arxiv.org/abs/2509.08243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08243">https://arxiv.org/pdf/2509.08243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08243]] Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI(https://arxiv.org/abs/2509.08243)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Structural magnetic resonance imaging (sMRI) combined with deep learning has achieved remarkable progress in the prediction and diagnosis of Alzheimer's disease (AD). Existing studies have used CNN and transformer to build a well-performing network, but most of them are based on pretraining or ignoring the asymmetrical character caused by brain disorders. We propose an end-to-end network for the detection of disease-based asymmetric induced by left and right brain atrophy which consist of 3D CNN Encoder and Symmetry Interactive Transformer (SIT). Following the inter-equal grid block fetch operation, the corresponding left and right hemisphere features are aligned and subsequently fed into the SIT for diagnostic analysis. SIT can help the model focus more on the regions of asymmetry caused by structural changes, thus improving diagnostic performance. We evaluated our method based on the ADNI dataset, and the results show that the method achieves better diagnostic accuracy (92.5\%) compared to several CNN methods and CNNs combined with a general transformer. The visualization results show that our network pays more attention in regions of brain atrophy, especially for the asymmetric pathological characteristics induced by AD, demonstrating the interpretability and effectiveness of the method.</li>
</ul>

<h3>Title: Mitigating Catastrophic Forgetting in Large Language Models with Forgetting-aware Pruning</h3>
<ul>
<li><strong>Authors: </strong>Wei Huang, Anda Cheng, Yinggui Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08255">https://arxiv.org/abs/2509.08255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08255">https://arxiv.org/pdf/2509.08255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08255]] Mitigating Catastrophic Forgetting in Large Language Models with Forgetting-aware Pruning(https://arxiv.org/abs/2509.08255)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have shown impressive capabilities in various downstream tasks but typically face Catastrophic Forgetting (CF) during fine-tuning. In this paper, we propose the Forgetting-Aware Pruning Metric (FAPM), a novel pruning-based approach to balance CF and downstream task performance. Our investigation reveals that the degree to which task vectors (i.e., the subtraction of pre-trained weights from the weights fine-tuned on downstream tasks) overlap with pre-trained model parameters is a critical factor for CF. Based on this finding, FAPM employs the ratio of the task vector to pre-trained model parameters as a metric to quantify CF, integrating this measure into the pruning criteria. Importantly, FAPM does not necessitate modifications to the training process or model architecture, nor does it require any auxiliary data. We conducted extensive experiments across eight datasets, covering natural language inference, General Q&A, Medical Q&A, Math Q&A, reading comprehension, and cloze tests. The results demonstrate that FAPM limits CF to just 0.25\% while maintaining 99.67\% accuracy on downstream tasks. We provide the code to reproduce our results.</li>
</ul>

<h3>Title: Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration</h3>
<ul>
<li><strong>Authors: </strong>Hyeonseok Kim, Byeongkeun Kang, Yeejin Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08280">https://arxiv.org/abs/2509.08280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08280">https://arxiv.org/pdf/2509.08280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08280]] Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration(https://arxiv.org/abs/2509.08280)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Generalized zero-shot semantic segmentation of 3D point clouds aims to classify each point into both seen and unseen classes. A significant challenge with these models is their tendency to make biased predictions, often favoring the classes encountered during training. This problem is more pronounced in 3D applications, where the scale of the training data is typically smaller than in image-based tasks. To address this problem, we propose a novel method called E3DPC-GZSL, which reduces overconfident predictions towards seen classes without relying on separate classifiers for seen and unseen data. E3DPC-GZSL tackles the overconfidence problem by integrating an evidence-based uncertainty estimator into a classifier. This estimator is then used to adjust prediction probabilities using a dynamic calibrated stacking factor that accounts for pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel training strategy that improves uncertainty estimation by refining the semantic space. This is achieved by merging learnable parameters with text-derived features, thereby improving model optimization for unseen data. Extensive experiments demonstrate that the proposed approach achieves state-of-the-art performance on generalized zero-shot semantic segmentation datasets, including ScanNet v2 and S3DIS.</li>
</ul>

<h3>Title: An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia</h3>
<ul>
<li><strong>Authors: </strong>M. Warizmi Wafiq, Peter Cutter, Ate Poortinga, Daniel Marc G. dela Torre, Karis Tenneson, Vanna Teck, Enikoe Bihari, Chanarun Saisaward, Weraphong Suaruang, Andrea McMahon, Andi Vika Faradiba Muin, Karno B. Batiran, Chairil A, Nurul Qomar, Arya Arismaya Metananda, David Ganz, David Saah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08303">https://arxiv.org/abs/2509.08303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08303">https://arxiv.org/pdf/2509.08303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08303]] An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia(https://arxiv.org/abs/2509.08303)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Oil palm cultivation remains one of the leading causes of deforestation in Indonesia. To better track and address this challenge, detailed and reliable mapping is needed to support sustainability efforts and emerging regulatory frameworks. We present an open-access geospatial dataset of oil palm plantations and related land cover types in Indonesia, produced through expert labeling of high-resolution satellite imagery from 2020 to 2024. The dataset provides polygon-based, wall-to-wall annotations across a range of agro-ecological zones and includes a hierarchical typology that distinguishes oil palm planting stages as well as similar perennial crops. Quality was ensured through multi-interpreter consensus and field validation. The dataset was created using wall-to-wall digitization over large grids, making it suitable for training and benchmarking both conventional convolutional neural networks and newer geospatial foundation models. Released under a CC-BY license, it fills a key gap in training data for remote sensing and aims to improve the accuracy of land cover types mapping. By supporting transparent monitoring of oil palm expansion, the resource contributes to global deforestation reduction goals and follows FAIR data principles.</li>
</ul>

<h3>Title: Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection</h3>
<ul>
<li><strong>Authors: </strong>Yehudit Aperstein, Alon Gottlib, Gal Benita, Alexander Apartsin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08304">https://arxiv.org/abs/2509.08304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08304">https://arxiv.org/pdf/2509.08304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08304]] Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection(https://arxiv.org/abs/2509.08304)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Understanding how information is shared across documents, regardless of the format in which it is expressed, is critical for tasks such as information retrieval, summarization, and content alignment. In this work, we introduce a novel framework for modelling Semantic Coverage Relations (SCR), which classifies document pairs based on how their informational content aligns. We define three core relation types: equivalence, where both texts convey the same information using different textual forms or styles; inclusion, where one document fully contains the information of another and adds more; and semantic overlap, where each document presents partially overlapping content. To capture these relations, we adopt a question answering (QA)-based approach, using the answerability of shared questions across documents as an indicator of semantic coverage. We construct a synthetic dataset derived from the SQuAD corpus by paraphrasing source passages and selectively omitting information, enabling precise control over content overlap. This dataset allows us to benchmark generative language models and train transformer-based classifiers for SCR prediction. Our findings demonstrate that discriminative models significantly outperform generative approaches, with the RoBERTa-base model achieving the highest accuracy of 61.4% and the Random Forest-based model showing the best balance with a macro-F1 score of 52.9%. The results show that QA provides an effective lens for assessing semantic relations across stylistically diverse texts, offering insights into the capacity of current models to reason about information beyond surface similarity. The dataset and code developed in this study are publicly available to support reproducibility.</li>
</ul>

<h3>Title: SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training</h3>
<ul>
<li><strong>Authors: </strong>Rongsheng Wang, Fenghe Tang, Qingsong Yao, Rui Yan, Xu Zhang, Zhen Huang, Haoran Lai, Zhiyang He, Xiaodong Tao, Zihang Jiang, Shaohua Kevin Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08311">https://arxiv.org/abs/2509.08311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08311">https://arxiv.org/pdf/2509.08311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08311]] SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training(https://arxiv.org/abs/2509.08311)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Medical vision-language pre-training shows great potential in learning representative features from massive paired radiographs and reports. However, in computed tomography (CT) scans, the distribution of lesions which contain intricate structures is characterized by spatial sparsity. Besides, the complex and implicit relationships between different pathological descriptions in each sentence of the report and their corresponding sub-regions in radiographs pose additional challenges. In this paper, we propose a Similarity-Driven Cross-Granularity Pre-training (SimCroP) framework on chest CTs, which combines similarity-driven alignment and cross-granularity fusion to improve radiograph interpretation. We first leverage multi-modal masked modeling to optimize the encoder for understanding precise low-level semantics from radiographs. Then, similarity-driven alignment is designed to pre-train the encoder to adaptively select and align the correct patches corresponding to each sentence in reports. The cross-granularity fusion module integrates multimodal information across instance level and word-patch level, which helps the model better capture key pathology structures in sparse radiographs, resulting in improved performance for multi-scale downstream tasks. SimCroP is pre-trained on a large-scale paired CT-reports dataset and validated on image classification and segmentation tasks across five public datasets. Experimental results demonstrate that SimCroP outperforms both cutting-edge medical self-supervised learning methods and medical vision-language pre-training methods. Codes and models are available at this https URL.</li>
</ul>

<h3>Title: Boosted Training of Lightweight Early Exits for Optimizing CNN Image Classification Inference</h3>
<ul>
<li><strong>Authors: </strong>Yehudit Aperstein, Alexander Apartsin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08318">https://arxiv.org/abs/2509.08318</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08318">https://arxiv.org/pdf/2509.08318</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08318]] Boosted Training of Lightweight Early Exits for Optimizing CNN Image Classification Inference(https://arxiv.org/abs/2509.08318)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Real-time image classification on resource-constrained platforms demands inference methods that balance accuracy with strict latency and power budgets. Early-exit strategies address this need by attaching auxiliary classifiers to intermediate layers of convolutional neural networks (CNNs), allowing "easy" samples to terminate inference early. However, conventional training of early exits introduces a covariance shift: downstream branches are trained on full datasets, while at inference they process only the harder, non-exited samples. This mismatch limits efficiency--accuracy trade-offs in practice. We introduce the Boosted Training Scheme for Early Exits (BTS-EE), a sequential training approach that aligns branch training with inference-time data distributions. Each branch is trained and calibrated before the next, ensuring robustness under selective inference conditions. To further support embedded deployment, we propose a lightweight branch architecture based on 1D convolutions and a Class Precision Margin (CPM) calibration method that enables per-class threshold tuning for reliable exit decisions. Experiments on the CINIC-10 dataset with a ResNet18 backbone demonstrate that BTS-EE consistently outperforms non-boosted training across 64 configurations, achieving up to 45 percent reduction in computation with only 2 percent accuracy degradation. These results expand the design space for deploying CNNs in real-time image processing systems, offering practical efficiency gains for applications such as industrial inspection, embedded vision, and UAV-based monitoring.</li>
</ul>

<h3>Title: Accelerating Reinforcement Learning Algorithms Convergence using Pre-trained Large Language Models as Tutors With Advice Reusing</h3>
<ul>
<li><strong>Authors: </strong>Lukas Toral, Teddy Lazebnik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08329">https://arxiv.org/abs/2509.08329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08329">https://arxiv.org/pdf/2509.08329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08329]] Accelerating Reinforcement Learning Algorithms Convergence using Pre-trained Large Language Models as Tutors With Advice Reusing(https://arxiv.org/abs/2509.08329)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) algorithms often require long training to become useful, especially in complex environments with sparse rewards. While techniques like reward shaping and curriculum learning exist to accelerate training, these are often extremely specific and require the developer's professionalism and dedicated expertise in the problem's domain. Tackling this challenge, in this study, we explore the effectiveness of pre-trained Large Language Models (LLMs) as tutors in a student-teacher architecture with RL algorithms, hypothesizing that LLM-generated guidance allows for faster convergence. In particular, we explore the effectiveness of reusing the LLM's advice on the RL's convergence dynamics. Through an extensive empirical examination, which included 54 configurations, varying the RL algorithm (DQN, PPO, A2C), LLM tutor (Llama, Vicuna, DeepSeek), and environment (Blackjack, Snake, Connect Four), our results demonstrate that LLM tutoring significantly accelerates RL convergence while maintaining comparable optimal performance. Furthermore, the advice reuse mechanism shows a further improvement in training duration but also results in less stable convergence dynamics. Our findings suggest that LLM tutoring generally improves convergence, and its effectiveness is sensitive to the specific task, RL algorithm, and LLM model combination.</li>
</ul>

<h3>Title: Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Jihyun Moon, Charmgil Hong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08338">https://arxiv.org/abs/2509.08338</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08338">https://arxiv.org/pdf/2509.08338</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08338]] Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis(https://arxiv.org/abs/2509.08338)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and early diagnosis of malignant melanoma is critical for improving patient outcomes. While convolutional neural networks (CNNs) have shown promise in dermoscopic image analysis, they often neglect clinical metadata and require extensive preprocessing. Vision-language models (VLMs) offer a multimodal alternative but struggle to capture clinical specificity when trained on general-domain data. To address this, we propose a retrieval-augmented VLM framework that incorporates semantically similar patient cases into the diagnostic prompt. Our method enables informed predictions without fine-tuning and significantly improves classification accuracy and error correction over conventional baselines. These results demonstrate that retrieval-augmented prompting provides a robust strategy for clinical decision support.</li>
</ul>

<h3>Title: Accelerating Mixture-of-Expert Inference with Adaptive Expert Split Mechanism</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Yan, Jianchun Liu, Hongli Xu, Liusheng Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08342">https://arxiv.org/abs/2509.08342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08342">https://arxiv.org/pdf/2509.08342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08342]] Accelerating Mixture-of-Expert Inference with Adaptive Expert Split Mechanism(https://arxiv.org/abs/2509.08342)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) has emerged as a promising architecture for modern large language models (LLMs). However, massive parameters impose heavy GPU memory (i.e., VRAM) demands, hindering the widespread adoption of MoE LLMs. Offloading the expert parameters to CPU RAM offers an effective way to alleviate the VRAM requirements for MoE inference. Existing approaches typically cache a small subset of experts in VRAM and dynamically prefetch experts from RAM during inference, leading to significant degradation in inference speed due to the poor cache hit rate and substantial expert loading latency. In this work, we propose MoEpic, an efficient MoE inference system with a novel expert split mechanism. Specifically, each expert is vertically divided into two segments: top and bottom. MoEpic caches the top segment of hot experts, so that more experts will be stored under the limited VRAM budget, thereby improving the cache hit rate. During each layer's inference, MoEpic predicts and prefetches the activated experts for the next layer. Since the top segments of cached experts are exempt from fetching, the loading time is reduced, which allows efficient transfer-computation overlap. Nevertheless, the performance of MoEpic critically depends on the cache configuration (i.e., each layer's VRAM budget and expert split ratio). To this end, we propose a divide-and-conquer algorithm based on fixed-point iteration for adaptive cache configuration. Extensive experiments on popular MoE LLMs demonstrate that MoEpic can save about half of the GPU cost, while lowering the inference latency by about 37.51%-65.73% compared to the baselines.</li>
</ul>

<h3>Title: Toward Subtrait-Level Model Explainability in Automated Writing Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Alejandro Andrade-Lotero, Lee Becker, Joshua Southerland, Scott Hellman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08345">https://arxiv.org/abs/2509.08345</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08345">https://arxiv.org/pdf/2509.08345</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08345]] Toward Subtrait-Level Model Explainability in Automated Writing Evaluation(https://arxiv.org/abs/2509.08345)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, generative</a></li>
<li><strong>Abstract: </strong>Subtrait (latent-trait components) assessment presents a promising path toward enhancing transparency of automated writing scores. We prototype explainability and subtrait scoring with generative language models and show modest correlation between human subtrait and trait scores, and between automated and human subtrait scores. Our approach provides details to demystify scores for educators and students.</li>
</ul>

<h3>Title: <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sergey Pletenev, Daniil Moskovskiy, Alexander Panchenko</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08358">https://arxiv.org/abs/2509.08358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08358">https://arxiv.org/pdf/2509.08358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08358]] <think> So let's replace this phrase with insult... </think> Lessons learned from generation of toxic texts with LLMs(https://arxiv.org/abs/2509.08358)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Modern Large Language Models (LLMs) are excellent at generating synthetic data. However, their performance in sensitive domains such as text detoxification has not received proper attention from the scientific community. This paper explores the possibility of using LLM-generated synthetic toxic data as an alternative to human-generated data for training models for detoxification. Using Llama 3 and Qwen activation-patched models, we generated synthetic toxic counterparts for neutral texts from ParaDetox and SST-2 datasets. Our experiments show that models fine-tuned on synthetic data consistently perform worse than those trained on human data, with a drop in performance of up to 30% in joint metrics. The root cause is identified as a critical lexical diversity gap: LLMs generate toxic content using a small, repetitive vocabulary of insults that fails to capture the nuances and variety of human toxicity. These findings highlight the limitations of current LLMs in this domain and emphasize the continued importance of diverse, human-annotated data for building robust detoxification systems.</li>
</ul>

<h3>Title: Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution</h3>
<ul>
<li><strong>Authors: </strong>Aduma Rishith, Aditya Kulkarni, Tamal Das, Vivek Balachandran</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08364">https://arxiv.org/abs/2509.08364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08364">https://arxiv.org/pdf/2509.08364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08364]] Overcoming DNSSEC Islands of Security: A TLS and IP-Based Certificate Solution(https://arxiv.org/abs/2509.08364)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>The Domain Name System (DNS) serves as the backbone of the Internet, primarily translating domain names to IP addresses. Over time, various enhancements have been introduced to strengthen the integrity of DNS. Among these, DNSSEC stands out as a leading cryptographic solution. It protects against attacks (such as DNS spoofing) by establishing a chain of trust throughout the DNS nameserver hierarchy. However, DNSSEC's effectiveness is compromised when there is a break in this chain, resulting in "Islands of Security", where domains can authenticate locally but not across hierarchical levels, leading to a loss of trust and validation between them. Leading approaches to addressing these issues were centralized, with a single authority maintaining some kind of bulletin board. This approach requires significantly more infrastructure and places excessive trust in the entity responsible for managing it properly. In this paper, we propose a decentralized approach to addressing gaps in DNSSEC's chain of trust, commonly referred to as "Islands of Security". We leverage TLS and IP-based certificates to enable end-to-end authentication between hierarchical levels, eliminating the need for uniform DNSSEC deployment across every level of the DNS hierarchy. This approach enhances the overall integrity of DNSSEC, while reducing dependence on registrars for maintaining signature records to verify the child nameserver's authenticity. By offering a more flexible and efficient solution, our method strengthens DNS security and streamlines deployment across diverse environments.</li>
</ul>

<h3>Title: Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Kosuke Kihara, Junki Mori, Taiki Miyagawa, Akinori F. Ebihara</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08372">https://arxiv.org/abs/2509.08372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08372">https://arxiv.org/pdf/2509.08372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08372]] Rethinking the Backbone in Class Imbalanced Federated Source Free Domain Adaptation: The Utility of Vision Foundation Models(https://arxiv.org/abs/2509.08372)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) offers a framework for training models collaboratively while preserving data privacy of each client. Recently, research has focused on Federated Source-Free Domain Adaptation (FFREEDA), a more realistic scenario wherein client-held target domain data remains unlabeled, and the server can access source domain data only during pre-training. We extend this framework to a more complex and realistic setting: Class Imbalanced FFREEDA (CI-FFREEDA), which takes into account class imbalances in both the source and target domains, as well as label shifts between source and target and among target clients. The replication of existing methods in our experimental setup lead us to rethink the focus from enhancing aggregation and domain adaptation methods to improving the feature extractors within the network itself. We propose replacing the FFREEDA backbone with a frozen vision foundation model (VFM), thereby improving overall accuracy without extensive parameter tuning and reducing computational and communication costs in federated learning. Our experimental results demonstrate that VFMs effectively mitigate the effects of domain gaps, class imbalances, and even non-IID-ness among target clients, suggesting that strong feature extractors, not complex adaptation or FL methods, are key to success in the real-world FL.</li>
</ul>

<h3>Title: InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Zhongyu Xia, Hansong Yang, Yongtao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08374">https://arxiv.org/abs/2509.08374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08374">https://arxiv.org/pdf/2509.08374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08374]] InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection(https://arxiv.org/abs/2509.08374)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Three-dimensional Object Detection from multi-view cameras and LiDAR is a crucial component for autonomous driving and smart transportation. However, in the process of basic feature extraction, perspective transformation, and feature fusion, noise and error will gradually accumulate. To address this issue, we propose InsFusion, which can extract proposals from both raw and fused features and utilizes these proposals to query the raw features, thereby mitigating the impact of accumulated errors. Additionally, by incorporating attention mechanisms applied to the raw features, it thereby mitigates the impact of accumulated errors. Experiments on the nuScenes dataset demonstrate that InsFusion is compatible with various advanced baseline methods and delivers new state-of-the-art performance for 3D object detection.</li>
</ul>

<h3>Title: Phish-Blitz: Advancing Phishing Detection with Comprehensive Webpage Resource Collection and Visual Integrity Preservation</h3>
<ul>
<li><strong>Authors: </strong>Duddu Hriday, Aditya Kulkarni, Vivek Balachandran, Tamal Das</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08375">https://arxiv.org/abs/2509.08375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08375">https://arxiv.org/pdf/2509.08375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08375]] Phish-Blitz: Advancing Phishing Detection with Comprehensive Webpage Resource Collection and Visual Integrity Preservation(https://arxiv.org/abs/2509.08375)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal</a></li>
<li><strong>Abstract: </strong>Phishing attacks are increasingly prevalent, with adversaries creating deceptive webpages to steal sensitive information. Despite advancements in machine learning and deep learning for phishing detection, attackers constantly develop new tactics to bypass detection models. As a result, phishing webpages continue to reach users, particularly those unable to recognize phishing indicators. To improve detection accuracy, models must be trained on large datasets containing both phishing and legitimate webpages, including URLs, webpage content, screenshots, and logos. However, existing tools struggle to collect the required resources, especially given the short lifespan of phishing webpages, limiting dataset comprehensiveness. In response, we introduce Phish-Blitz, a tool that downloads phishing and legitimate webpages along with their associated resources, such as screenshots. Unlike existing tools, Phish-Blitz captures live webpage screenshots and updates resource file paths to maintain the original visual integrity of the webpage. We provide a dataset containing 8,809 legitimate and 5,000 phishing webpages, including all associated resources. Our dataset and tool are publicly available on GitHub, contributing to the research community by offering a more complete dataset for phishing detection.</li>
</ul>

<h3>Title: Bitrate-Controlled Diffusion for Disentangling Motion and Content in Video</h3>
<ul>
<li><strong>Authors: </strong>Xiao Li, Qi Chen, Xiulian Peng, Kai Yu, Xie Chen, Yan Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08376">https://arxiv.org/abs/2509.08376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08376">https://arxiv.org/pdf/2509.08376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08376]] Bitrate-Controlled Diffusion for Disentangling Motion and Content in Video(https://arxiv.org/abs/2509.08376)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We propose a novel and general framework to disentangle video data into its dynamic motion and static content components. Our proposed method is a self-supervised pipeline with less assumptions and inductive biases than previous works: it utilizes a transformer-based architecture to jointly generate flexible implicit features for frame-wise motion and clip-wise content, and incorporates a low-bitrate vector quantization as an information bottleneck to promote disentanglement and form a meaningful discrete motion space. The bitrate-controlled latent motion and content are used as conditional inputs to a denoising diffusion model to facilitate self-supervised representation learning. We validate our disentangled representation learning framework on real-world talking head videos with motion transfer and auto-regressive motion generation tasks. Furthermore, we also show that our method can generalize to other types of video data, such as pixel sprites of 2D cartoon characters. Our work presents a new perspective on self-supervised learning of disentangled video representations, contributing to the broader field of video analysis and generation.</li>
</ul>

<h3>Title: Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model</h3>
<ul>
<li><strong>Authors: </strong>Yu Cheng Chih, Yong Hao Hou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08381">https://arxiv.org/abs/2509.08381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08381">https://arxiv.org/pdf/2509.08381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08381]] Low-Resource Fine-Tuning for Multi-Task Structured Information Extraction with a Billion-Parameter Instruction-Tuned Model(https://arxiv.org/abs/2509.08381)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Deploying large language models (LLMs) for structured data extraction in domains such as financial compliance reporting, legal document analytics, and multilingual knowledge base construction is often impractical for smaller teams due to the high cost of running large architectures and the difficulty of preparing large, high-quality datasets. Most recent instruction-tuning studies focus on seven-billion-parameter or larger models, leaving limited evidence on whether much smaller models can work reliably under low-resource, multi-task conditions. This work presents ETLCH, a billion-parameter LLaMA-based model fine-tuned with low-rank adaptation on only a few hundred to one thousand samples per task for JSON extraction, knowledge graph extraction, and named entity recognition. Despite its small scale, ETLCH outperforms strong baselines across most evaluation metrics, with substantial gains observed even at the lowest data scale. These findings demonstrate that well-tuned small models can deliver stable and accurate structured outputs at a fraction of the computational cost, enabling cost-effective and reliable information extraction pipelines in resource-constrained environments.</li>
</ul>

<h3>Title: Efficient Decoding Methods for Language Models on Encrypted Data</h3>
<ul>
<li><strong>Authors: </strong>Matan Avitan, Moran Baruch, Nir Drucker, Itamar Zimerman, Yoav Goldberg</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08383">https://arxiv.org/abs/2509.08383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08383">https://arxiv.org/pdf/2509.08383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08383]] Efficient Decoding Methods for Language Models on Encrypted Data(https://arxiv.org/abs/2509.08383)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) power modern AI applications, but processing sensitive data on untrusted servers raises privacy concerns. Homomorphic encryption (HE) enables computation on encrypted data for secure inference. However, neural text generation requires decoding methods like argmax and sampling, which are non-polynomial and thus computationally expensive under encryption, creating a significant performance bottleneck. We introduce cutmax, an HE-friendly argmax algorithm that reduces ciphertext operations compared to prior methods, enabling practical greedy decoding under encryption. We also propose the first HE-compatible nucleus (top-p) sampling method, leveraging cutmax for efficient stochastic decoding with provable privacy guarantees. Both techniques are polynomial, supporting efficient inference in privacy-preserving settings. Moreover, their differentiability facilitates gradient-based sequence-level optimization as a polynomial alternative to straight-through estimators. We further provide strong theoretical guarantees for cutmax, proving it converges globally to a unique two-level fixed point, independent of the input values beyond the identity of the maximizer, which explains its rapid convergence in just a few iterations. Evaluations on realistic LLM outputs show latency reductions of 24x-35x over baselines, advancing secure text generation.</li>
</ul>

<h3>Title: Semantic Causality-Aware Vision-Based 3D Occupancy Prediction</h3>
<ul>
<li><strong>Authors: </strong>Dubing Chen, Huan Zheng, Yucheng Zhou, Xianfei Li, Wenlong Liao, Tao He, Pai Peng, Jianbing Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08388">https://arxiv.org/abs/2509.08388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08388">https://arxiv.org/pdf/2509.08388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08388]] Semantic Causality-Aware Vision-Based 3D Occupancy Prediction(https://arxiv.org/abs/2509.08388)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-based 3D semantic occupancy prediction is a critical task in 3D vision that integrates volumetric 3D reconstruction with semantic understanding. Existing methods, however, often rely on modular pipelines. These modules are typically optimized independently or use pre-configured inputs, leading to cascading errors. In this paper, we address this limitation by designing a novel causal loss that enables holistic, end-to-end supervision of the modular 2D-to-3D transformation pipeline. Grounded in the principle of 2D-to-3D semantic causality, this loss regulates the gradient flow from 3D voxel representations back to the 2D features. Consequently, it renders the entire pipeline differentiable, unifying the learning process and making previously non-trainable components fully learnable. Building on this principle, we propose the Semantic Causality-Aware 2D-to-3D Transformation, which comprises three components guided by our causal loss: Channel-Grouped Lifting for adaptive semantic mapping, Learnable Camera Offsets for enhanced robustness against camera perturbations, and Normalized Convolution for effective feature propagation. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the Occ3D benchmark, demonstrating significant robustness to camera perturbations and improved 2D-to-3D semantic consistency.</li>
</ul>

<h3>Title: VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring</h3>
<ul>
<li><strong>Authors: </strong>Cuong Nguyen, Dung T. Tran, Hong Nguyen, Xuan-Vu Phan, Nam-Phong Nguyen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08392">https://arxiv.org/abs/2509.08392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08392">https://arxiv.org/pdf/2509.08392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08392]] VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring(https://arxiv.org/abs/2509.08392)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In real-world traffic surveillance, vehicle images captured under adverse weather, poor lighting, or high-speed motion often suffer from severe noise and blur. Such degradations significantly reduce the accuracy of license plate recognition systems, especially when the plate occupies only a small region within the full vehicle image. Restoring these degraded images a fast realtime manner is thus a crucial pre-processing step to enhance recognition performance. In this work, we propose a Vertical Residual Autoencoder (VRAE) architecture designed for the image enhancement task in traffic surveillance. The method incorporates an enhancement strategy that employs an auxiliary block, which injects input-aware features at each encoding stage to guide the representation learning process, enabling better general information preservation throughout the network compared to conventional autoencoders. Experiments on a vehicle image dataset with visible license plates demonstrate that our method consistently outperforms Autoencoder (AE), Generative Adversarial Network (GAN), and Flow-Based (FB) approaches. Compared with AE at the same depth, it improves PSNR by about 20\%, reduces NMSE by around 50\%, and enhances SSIM by 1\%, while requiring only a marginal increase of roughly 1\% in parameters.</li>
</ul>

<h3>Title: MIoT-Driven Comparison of Open Blockchain Platforms</h3>
<ul>
<li><strong>Authors: </strong>Abdou-Essamad Jabri, Mostafa Azizi, Cyril Drocourt (UPJV, MIS), Gil Utard (MIS, UPJV)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08399">https://arxiv.org/abs/2509.08399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08399">https://arxiv.org/pdf/2509.08399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08399]] MIoT-Driven Comparison of Open Blockchain Platforms(https://arxiv.org/abs/2509.08399)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Being propelled by the fourth industrial revolution (Industry 4.0), IoT devices and solutions are well adopted everywhere, ranging from home applications to industrial use, crossing through transportation, healthcare, energy, and so on. This wide use of IoT has not gone unnoticed, hackers are tracking the weakness of such a technology and threatening them continuously. Their security at various levels has become an important concern of professionals and researchers. This issue takes more risk, especially with the IoT variants, IIoT (Industrial IoT) and MIoT (Medical IoT). Many existing security solutions are adapted and proposed for addressing IoT security. In this paper, we are interested in exploring blockchain technology and we make a comparison of three free Blockchain platforms towards their applicability for MIoT context, namely Ethereum, Hyperledger Fabric and Corda. In general, Blockchain technology provides a decentralized, autonomous, trustless, and distributed environment. It is challenging to find a Blockchain platform that fits the MIoT context and performs well in terms of security. The retained platform should be deployed smartly to avoid its practical drawbacks related to energy-consuming and excessive computing.</li>
</ul>

<h3>Title: Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records</h3>
<ul>
<li><strong>Authors: </strong>Abdou-Essamad Jabri, C. Drocourt (UPJV, MIS), Mostafa Azizi, Gil Utard (UPJV, MIS)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08402">https://arxiv.org/abs/2509.08402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08402">https://arxiv.org/pdf/2509.08402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08402]] Leveraging Blockchain and Proxy Re-Encryption to secure Medical IoT Records(https://arxiv.org/abs/2509.08402)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, robust</a></li>
<li><strong>Abstract: </strong>The integration of the Internet of Things (IoT) in healthcare has revolutionized patient monitoring and data collection, allowing real-time tracking of vital signs, remote diagnostics, and automated medical responses. However, the transmission and storage of sensitive medical data introduce significant security and privacy challenges. To address these concerns, blockchain technology provides a decentralized and immutable ledger that ensures data integrity, , and transparency. Unlike public blockchains, private blockchains are permissioned; the access is granted only to authorized participants; they are more suitable for handling confidential healthcare data. Although blockchain ensures security and trust, it lacks built-in mechanisms to support flexible and controlled data sharing; This is where Proxy Re-Encryption (PRE) comes into play. PRE is a cryptographic technique that allows encrypted data to be re-encrypted for a new recipient without exposing it to intermediaries. We propose an architecture integrating private blockchain and PRE to enable secure, traceable, and privacy-preserving data sharing in IoT-based healthcare systems. Blockchain guarantees tamper proof record-keeping, while PRE enables fine-grained access control, allowing medical professionals to securely share patient data without compromising confidentiality. This combination creates a robust security framework that enhances trust and efficiency in digital healthcare ecosystems.</li>
</ul>

<h3>Title: Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking</h3>
<ul>
<li><strong>Authors: </strong>Keisuke Toida, Taigo Sakai, Naoki Kato, Kazutoyo Yokota, Takeshi Nakamura, Kazuhiro Hotta</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08421">https://arxiv.org/abs/2509.08421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08421">https://arxiv.org/pdf/2509.08421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08421]] Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking(https://arxiv.org/abs/2509.08421)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-View Multi-Object Tracking (MVMOT) is essential for applications such as surveillance, autonomous driving, and sports analytics. However, maintaining consistent object identities across multiple cameras remains challenging due to viewpoint changes, lighting variations, and occlusions, which often lead to tracking this http URL methods project features from multiple cameras into a unified Bird's-Eye-View (BEV) space to improve robustness against occlusion. However, this projection introduces feature distortion and non-uniform density caused by variations in object scale with distance. These issues degrade the quality of the fused representation and reduce detection and tracking this http URL address these problems, we propose SCFusion, a framework that combines three techniques to improve multi-view feature integration. First, it applies a sparse transformation to avoid unnatural interpolation during projection. Next, it performs density-aware weighting to adaptively fuse features based on spatial confidence and camera distance. Finally, it introduces a multi-view consistency loss that encourages each camera to learn discriminative features independently before this http URL show that SCFusion achieves state-of-the-art performance, reaching an IDF1 score of 95.9% on WildTrack and a MODP of 89.2% on MultiviewX, outperforming the baseline method TrackTacular. These results demonstrate that SCFusion effectively mitigates the limitations of conventional BEV projection and provides a robust and accurate solution for multi-view object detection and tracking.</li>
</ul>

<h3>Title: LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations</h3>
<ul>
<li><strong>Authors: </strong>Payal Varshney, Adriano Lucieri, Christoph Balada, Sheraz Ahmed, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08422">https://arxiv.org/abs/2509.08422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08422">https://arxiv.org/pdf/2509.08422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08422]] LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations(https://arxiv.org/abs/2509.08422)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Video-based AI systems are increasingly adopted in safety-critical domains such as autonomous driving and healthcare. However, interpreting their decisions remains challenging due to the inherent spatiotemporal complexity of video data and the opacity of deep learning models. Existing explanation techniques often suffer from limited temporal coherence, insufficient robustness, and a lack of actionable causal insights. Current counterfactual explanation methods typically do not incorporate guidance from the target model, reducing semantic fidelity and practical utility. We introduce Latent Diffusion for Video Counterfactual Explanations (LD-ViCE), a novel framework designed to explain the behavior of video-based AI models. Compared to previous approaches, LD-ViCE reduces the computational costs of generating explanations by operating in latent space using a state-of-the-art diffusion model, while producing realistic and interpretable counterfactuals through an additional refinement step. Our experiments demonstrate the effectiveness of LD-ViCE across three diverse video datasets, including EchoNet-Dynamic (cardiac ultrasound), FERV39k (facial expression), and Something-Something V2 (action recognition). LD-ViCE outperforms a recent state-of-the-art method, achieving an increase in R2 score of up to 68% while reducing inference time by half. Qualitative analysis confirms that LD-ViCE generates semantically meaningful and temporally coherent explanations, offering valuable insights into the target model behavior. LD-ViCE represents a valuable step toward the trustworthy deployment of AI in safety-critical domains.</li>
</ul>

<h3>Title: Phishing Webpage Detection: Unveiling the Threat Landscape and Investigating Detection Techniques</h3>
<ul>
<li><strong>Authors: </strong>Aditya Kulkarni, Vivek Balachandran, Tamal Das</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08424">https://arxiv.org/abs/2509.08424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08424">https://arxiv.org/pdf/2509.08424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08424]] Phishing Webpage Detection: Unveiling the Threat Landscape and Investigating Detection Techniques(https://arxiv.org/abs/2509.08424)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>In the realm of cybersecurity, phishing stands as a prevalent cyber attack, where attackers employ various tactics to deceive users into gathering their sensitive information, potentially leading to identity theft or financial gain. Researchers have been actively working on advancing phishing webpage detection approaches to detect new phishing URLs, bolstering user protection. Nonetheless, the ever-evolving strategies employed by attackers, aimed at circumventing existing detection approaches and tools, present an ongoing challenge to the research community. This survey presents a systematic categorization of diverse phishing webpage detection approaches, encompassing URL-based, webpage content-based, and visual techniques. Through a comprehensive review of these approaches and an in-depth analysis of existing literature, our study underscores current research gaps in phishing webpage detection. Furthermore, we suggest potential solutions to address some of these gaps, contributing valuable insights to the ongoing efforts to combat phishing attacks.</li>
</ul>

<h3>Title: Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time</h3>
<ul>
<li><strong>Authors: </strong>Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang, Leyuan Fang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08436">https://arxiv.org/abs/2509.08436</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08436">https://arxiv.org/pdf/2509.08436</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08436]] Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time(https://arxiv.org/abs/2509.08436)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Hyperspectral image (HSI) classification models are highly sensitive to distribution shifts caused by various real-world degradations such as noise, blur, compression, and atmospheric effects. To address this challenge, we propose HyperTTA, a unified framework designed to enhance model robustness under diverse degradation conditions. Specifically, we first construct a multi-degradation hyperspectral dataset that systematically simulates nine representative types of degradations, providing a comprehensive benchmark for robust classification evaluation. Based on this, we design a spectral-spatial transformer classifier (SSTC) enhanced with a multi-level receptive field mechanism and label smoothing regularization to jointly capture multi-scale spatial context and improve generalization. Furthermore, HyperTTA incorporates a lightweight test-time adaptation (TTA) strategy, the confidence-aware entropy-minimized LayerNorm adapter (CELA), which updates only the affine parameters of LayerNorm layers by minimizing prediction entropy on high-confidence unlabeled target samples. This confidence-aware adaptation prevents unreliable updates from noisy predictions, enabling robust and dynamic adaptation without access to source data or target annotations. Extensive experiments on two benchmark datasets demonstrate that HyperTTA outperforms existing baselines across a wide range of degradation scenarios, validating the effectiveness of both its classification backbone and the proposed TTA scheme. Code will be made available publicly.</li>
</ul>

<h3>Title: CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction with a New Dataset and Multi-Order Generative Framework</h3>
<ul>
<li><strong>Authors: </strong>Jinzhong Ning, Paerhati Tulajiang, Yingying Le, Yijia Zhang, Yuanyuan Sun, Hongfei Lin, Haifeng Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MM, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08438">https://arxiv.org/abs/2509.08438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08438">https://arxiv.org/pdf/2509.08438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08438]] CommonVoice-SpeechRE and RPG-MoGe: Advancing Speech Relation Extraction with a New Dataset and Multi-Order Generative Framework(https://arxiv.org/abs/2509.08438)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Speech Relation Extraction (SpeechRE) aims to extract relation triplets directly from speech. However, existing benchmark datasets rely heavily on synthetic data, lacking sufficient quantity and diversity of real human speech. Moreover, existing models also suffer from rigid single-order generation templates and weak semantic alignment, substantially limiting their performance. To address these challenges, we introduce CommonVoice-SpeechRE, a large-scale dataset comprising nearly 20,000 real-human speech samples from diverse speakers, establishing a new benchmark for SpeechRE research. Furthermore, we propose the Relation Prompt-Guided Multi-Order Generative Ensemble (RPG-MoGe), a novel framework that features: (1) a multi-order triplet generation ensemble strategy, leveraging data diversity through diverse element orders during both training and inference, and (2) CNN-based latent relation prediction heads that generate explicit relation prompts to guide cross-modal alignment and accurate triplet generation. Experiments show our approach outperforms state-of-the-art methods, providing both a benchmark dataset and an effective solution for real-world SpeechRE. The source code and dataset are publicly available at this https URL.</li>
</ul>

<h3>Title: Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ivan Stoyanov, Fabian Bongratz, Christian Wachinger</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08442">https://arxiv.org/abs/2509.08442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08442">https://arxiv.org/pdf/2509.08442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08442]] Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting(https://arxiv.org/abs/2509.08442)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Accurate forecasting of individualized, high-resolution cortical thickness (CTh) trajectories is essential for detecting subtle cortical changes, providing invaluable insights into neurodegenerative processes and facilitating earlier and more precise intervention strategies. However, CTh forecasting is a challenging task due to the intricate non-Euclidean geometry of the cerebral cortex and the need to integrate multi-modal data for subject-specific predictions. To address these challenges, we introduce the Spherical Brownian Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional conditional Brownian bridge diffusion process to forecast CTh trajectories at the vertex level of registered cortical surfaces. Our technical contribution includes a new denoising model, the conditional spherical U-Net (CoS-UNet), which combines spherical convolutions and dense cross-attention to integrate cortical surfaces and tabular conditions seamlessly. Compared to previous approaches, SBDM achieves significantly reduced prediction errors, as demonstrated by our experiments based on longitudinal datasets from the ADNI and OASIS. Additionally, we demonstrate SBDM's ability to generate individual factual and counterfactual CTh trajectories, offering a novel framework for exploring hypothetical scenarios of cortical development.</li>
</ul>

<h3>Title: DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Charuka Herath, Yogachandran Rahulamathavan, Varuna De Silva, Sangarapillai Lambotharan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08449">https://arxiv.org/abs/2509.08449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08449">https://arxiv.org/pdf/2509.08449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08449]] DSFL: A Dual-Server Byzantine-Resilient Federated Learning Framework via Group-Based Secure Aggregation(https://arxiv.org/abs/2509.08449)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, robust, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables decentralized model training without sharing raw data, offering strong privacy guarantees. However, existing FL protocols struggle to defend against Byzantine participants, maintain model utility under non-independent and identically distributed (non-IID) data, and remain lightweight for edge devices. Prior work either assumes trusted hardware, uses expensive cryptographic tools, or fails to address privacy and robustness simultaneously. We propose DSFL, a Dual-Server Byzantine-Resilient Federated Learning framework that addresses these limitations using a group-based secure aggregation approach. Unlike LSFL, which assumes non-colluding semi-honest servers, DSFL removes this dependency by revealing a key vulnerability: privacy leakage through client-server collusion. DSFL introduces three key innovations: (1) a dual-server secure aggregation protocol that protects updates without encryption or key exchange, (2) a group-wise credit-based filtering mechanism to isolate Byzantine clients based on deviation scores, and (3) a dynamic reward-penalty system for enforcing fair participation. DSFL is evaluated on MNIST, CIFAR-10, and CIFAR-100 under up to 30 percent Byzantine participants in both IID and non-IID settings. It consistently outperforms existing baselines, including LSFL, homomorphic encryption methods, and differential privacy approaches. For example, DSFL achieves 97.15 percent accuracy on CIFAR-10 and 68.60 percent on CIFAR-100, while FedAvg drops to 9.39 percent under similar threats. DSFL remains lightweight, requiring only 55.9 ms runtime and 1088 KB communication per round.</li>
</ul>

<h3>Title: Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics</h3>
<ul>
<li><strong>Authors: </strong>Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, hep-ex</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08461">https://arxiv.org/abs/2509.08461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08461">https://arxiv.org/pdf/2509.08461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08461]] Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics(https://arxiv.org/abs/2509.08461)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have demonstrated their remarkable capacity to process and reason over structured and unstructured data modalities beyond natural language. In this work, we explore the applications of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa 3.2, to the task of identifying neutrino interactions in pixelated detector data from high-energy physics (HEP) experiments. We benchmark this model against a state-of-the-art convolutional neural network (CNN) architecture, similar to those used in the NOvA and DUNE experiments, which have achieved high efficiency and purity in classifying electron and muon neutrino events. Our evaluation considers both the classification performance and interpretability of the model predictions. We find that VLMs can outperform CNNs, while also providing greater flexibility in integrating auxiliary textual or semantic information and offering more interpretable, reasoning-based predictions. This work highlights the potential of VLMs as a general-purpose backbone for physics event classification, due to their high performance, interpretability, and generalizability, which opens new avenues for integrating multimodal reasoning in experimental neutrino physics.</li>
</ul>

<h3>Title: Adversarial Attacks Against Automated Fact-Checking: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Fanzhen Liu, Alsharif Abuadbba, Kristen Moore, Surya Nepal, Cecile Paris, Jia Wu, Jian Yang, Quan Z. Sheng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08463">https://arxiv.org/abs/2509.08463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08463">https://arxiv.org/pdf/2509.08463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08463]] Adversarial Attacks Against Automated Fact-Checking: A Survey(https://arxiv.org/abs/2509.08463)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>In an era where misinformation spreads freely, fact-checking (FC) plays a crucial role in verifying claims and promoting reliable information. While automated fact-checking (AFC) has advanced significantly, existing systems remain vulnerable to adversarial attacks that manipulate or generate claims, evidence, or claim-evidence pairs. These attacks can distort the truth, mislead decision-makers, and ultimately undermine the reliability of FC models. Despite growing research interest in adversarial attacks against AFC systems, a comprehensive, holistic overview of key challenges remains lacking. These challenges include understanding attack strategies, assessing the resilience of current models, and identifying ways to enhance robustness. This survey provides the first in-depth review of adversarial attacks targeting FC, categorizing existing attack methodologies and evaluating their impact on AFC systems. Additionally, we examine recent advancements in adversary-aware defenses and highlight open research questions that require further exploration. Our findings underscore the urgent need for resilient FC frameworks capable of withstanding adversarial manipulations in pursuit of preserving high verification accuracy.</li>
</ul>

<h3>Title: An Interpretable Deep Learning Model for General Insurance Pricing</h3>
<ul>
<li><strong>Authors: </strong>Patrick J. Laub, Tu Pho, Bernard Wong</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08467">https://arxiv.org/abs/2509.08467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08467">https://arxiv.org/pdf/2509.08467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08467]] An Interpretable Deep Learning Model for General Insurance Pricing(https://arxiv.org/abs/2509.08467)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper introduces the Actuarial Neural Additive Model, an inherently interpretable deep learning model for general insurance pricing that offers fully transparent and interpretable results while retaining the strong predictive power of neural networks. This model assigns a dedicated neural network (or subnetwork) to each individual covariate and pairwise interaction term to independently learn its impact on the modeled output while implementing various architectural constraints to allow for essential interpretability (e.g. sparsity) and practical requirements (e.g. smoothness, monotonicity) in insurance applications. The development of our model is grounded in a solid foundation, where we establish a concrete definition of interpretability within the insurance context, complemented by a rigorous mathematical framework. Comparisons in terms of prediction accuracy are made with traditional actuarial and state-of-the-art machine learning methods using both synthetic and real insurance datasets. The results show that the proposed model outperforms other methods in most cases while offering complete transparency in its internal logic, underscoring the strong interpretability and predictive capability.</li>
</ul>

<h3>Title: Maximally Useful and Minimally Redundant: The Key to Self Supervised Learning for Imbalanced Data</h3>
<ul>
<li><strong>Authors: </strong>Yash Kumar Sharma, Vineet Nair, Wilson Naik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08469">https://arxiv.org/abs/2509.08469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08469">https://arxiv.org/pdf/2509.08469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08469]] Maximally Useful and Minimally Redundant: The Key to Self Supervised Learning for Imbalanced Data(https://arxiv.org/abs/2509.08469)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The robustness of contrastive self-supervised learning (CSSL) for imbalanced datasets is largely unexplored. CSSL usually makes use of \emph{multi-view} assumptions to learn discriminatory features via similar and dissimilar data samples. CSSL works well on balanced datasets, but does not generalize well for imbalanced datasets. In a very recent paper, as part of future work, Yann LeCun pointed out that the self-supervised multiview framework can be extended to cases involving \emph{more than two views}. Taking a cue from this insight we propose a theoretical justification based on the concept of \emph{mutual information} to support the \emph{more than two views} objective and apply it to the problem of dataset imbalance in self-supervised learning. The proposed method helps extract representative characteristics of the tail classes by segregating between \emph{intra} and \emph{inter} discriminatory characteristics. We introduce a loss function that helps us to learn better representations by filtering out extreme features. Experimental evaluation on a variety of self-supervised frameworks (both contrastive and non-contrastive) also prove that the \emph{more than two view} objective works well for imbalanced datasets. We achieve a new state-of-the-art accuracy in self-supervised imbalanced dataset classification (2\% improvement in Cifar10-LT using Resnet-18, 5\% improvement in Cifar100-LT using Resnet-18, 3\% improvement in Imagenet-LT (1k) using Resnet-50).</li>
</ul>

<h3>Title: Acquiescence Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Daniel Braun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08480">https://arxiv.org/abs/2509.08480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08480">https://arxiv.org/pdf/2509.08480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08480]] Acquiescence Bias in Large Language Models(https://arxiv.org/abs/2509.08480)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Acquiescence bias, i.e. the tendency of humans to agree with statements in surveys, independent of their actual beliefs, is well researched and documented. Since Large Language Models (LLMs) have been shown to be very influenceable by relatively small changes in input and are trained on human-generated data, it is reasonable to assume that they could show a similar tendency. We present a study investigating the presence of acquiescence bias in LLMs across different models, tasks, and languages (English, German, and Polish). Our results indicate that, contrary to humans, LLMs display a bias towards answering no, regardless of whether it indicates agreement or disagreement.</li>
</ul>

<h3>Title: SHAining on Process Mining: Explaining Event Log Characteristics Impact on Algorithms</h3>
<ul>
<li><strong>Authors: </strong>Andrea Maldonado, Christian M. M. Frey, Sai Anirudh Aryasomayajula, Ludwig Zellner, Stephan A. Fahrenkrog-Petersen, Thomas Seidl</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08482">https://arxiv.org/abs/2509.08482</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08482">https://arxiv.org/pdf/2509.08482</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08482]] SHAining on Process Mining: Explaining Event Log Characteristics Impact on Algorithms(https://arxiv.org/abs/2509.08482)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Process mining aims to extract and analyze insights from event logs, yet algorithm metric results vary widely depending on structural event log characteristics. Existing work often evaluates algorithms on a fixed set of real-world event logs but lacks a systematic analysis of how event log characteristics impact algorithms individually. Moreover, since event logs are generated from processes, where characteristics co-occur, we focus on associational rather than causal effects to assess how strong the overlapping individual characteristic affects evaluation metrics without assuming isolated causal effects, a factor often neglected by prior work. We introduce SHAining, the first approach to quantify the marginal contribution of varying event log characteristics to process mining algorithms' metrics. Using process discovery as a downstream task, we analyze over 22,000 event logs covering a wide span of characteristics to uncover which affect algorithms across metrics (e.g., fitness, precision, complexity) the most. Furthermore, we offer novel insights about how the value of event log characteristics correlates with their contributed impact, assessing the algorithm's robustness.</li>
</ul>

<h3>Title: Flow-Based Detection and Identification of Zero-Day IoT Cameras</h3>
<ul>
<li><strong>Authors: </strong>Priyanka Rushikesh Chaudhary, Rajib Ranjan Maiti</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08485">https://arxiv.org/abs/2509.08485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08485">https://arxiv.org/pdf/2509.08485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08485]] Flow-Based Detection and Identification of Zero-Day IoT Cameras(https://arxiv.org/abs/2509.08485)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>The majority of consumer IoT devices lack mechanisms for administrators to monitor and control them, hindering tailored security policies. A key challenge is identifying whether a new device, especially a streaming IoT camera, has joined the network. We present zCamInspector, a system for identifying known IoT cameras with supervised classifiers (zCamClassifier) and detecting zero-day cameras with one-class classifiers (zCamDetector). We analyzed ~40GB of traffic across three datasets: Set I (six commercial IoT cameras), Set II (five open-source IoT cameras, ~1.5GB), and Set III (four conferencing and two video-sharing applications as non-IoT traffic). From each, 62 flow-based features were extracted using CICFlowmeter. zCamInspector employs seven supervised models (ET, DT, RF, KNN, XGB, LKSVM, GNB) and four one-class models (OCSVM, SGDOCSVM, IF, DeepSVDD). Results show that XGB identifies IoT cameras with >99% accuracy and false negatives as low as 0.3%, outperforming state-of-the-art methods. For zero-day detection, accuracies reached 93.20% (OCSVM), 96.55% (SGDOCSVM), 78.65% (IF), and 92.16% (DeepSVDD). When all devices were treated as zero-day, DeepSVDD performed best with mean training/testing accuracies of 96.03%/74.51%. zCamInspector also achieved >95% accuracy for specific devices, such as Spy Clock cameras, demonstrating its robustness for identifying and detecting zero-day IoT cameras in diverse network environments.</li>
</ul>

<h3>Title: Too Helpful, Too Harmless, Too Honest or Just Right?</h3>
<ul>
<li><strong>Authors: </strong>Gautam Siddharth Kashyap, Mark Dras, Usman Naseem</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08486">https://arxiv.org/abs/2509.08486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08486">https://arxiv.org/pdf/2509.08486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08486]] Too Helpful, Too Harmless, Too Honest or Just Right?(https://arxiv.org/abs/2509.08486)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit strong performance across a wide range of NLP tasks, yet aligning their outputs with the principles of Helpfulness, Harmlessness, and Honesty (HHH) remains a persistent challenge. Existing methods often optimize for individual alignment dimensions in isolation, leading to trade-offs and inconsistent behavior. While Mixture-of-Experts (MoE) architectures offer modularity, they suffer from poorly calibrated routing, limiting their effectiveness in alignment tasks. We propose TrinityX, a modular alignment framework that incorporates a Mixture of Calibrated Experts (MoCaE) within the Transformer architecture. TrinityX leverages separately trained experts for each HHH dimension, integrating their outputs through a calibrated, task-adaptive routing mechanism that combines expert signals into a unified, alignment-aware representation. Extensive experiments on three standard alignment benchmarks-Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty)-demonstrate that TrinityX outperforms strong baselines, achieving relative improvements of 32.5% in win rate, 33.9% in safety score, and 28.4% in truthfulness. In addition, TrinityX reduces memory usage and inference latency by over 40% compared to prior MoE-based approaches. Ablation studies highlight the importance of calibrated routing, and cross-model evaluations confirm TrinityX's generalization across diverse LLM backbones.</li>
</ul>

<h3>Title: Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation</h3>
<ul>
<li><strong>Authors: </strong>Kaleem Ahmad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08489">https://arxiv.org/abs/2509.08489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08489">https://arxiv.org/pdf/2509.08489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08489]] Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation(https://arxiv.org/abs/2509.08489)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Prompt-driven image analysis converts a single natural-language instruction into multiple steps: locate, segment, edit, and describe. We present a practical case study of a unified pipeline that combines open-vocabulary detection, promptable segmentation, text-conditioned inpainting, and vision-language description into a single workflow. The system works end to end from a single prompt, retains intermediate artifacts for transparent debugging (such as detections, masks, overlays, edited images, and before and after composites), and provides the same functionality through an interactive UI and a scriptable CLI for consistent, repeatable runs. We highlight integration choices that reduce brittleness, including threshold adjustments, mask inspection with light morphology, and resource-aware defaults. In a small, single-word prompt segment, detection and segmentation produced usable masks in over 90% of cases with an accuracy above 85% based on our criteria. On a high-end GPU, inpainting makes up 60 to 75% of total runtime under typical guidance and sampling settings, which highlights the need for careful tuning. The study offers implementation-guided advice on thresholds, mask tightness, and diffusion parameters, and details version pinning, artifact logging, and seed control to support replay. Our contribution is a transparent, reliable pattern for assembling modern vision and multimodal models behind a single prompt, with clear guardrails and operational practices that improve reliability in object replacement, scene augmentation, and removal.</li>
</ul>

<h3>Title: Send to which account? Evaluation of an LLM-based Scambaiting System</h3>
<ul>
<li><strong>Authors: </strong>Hossein Siadati, Haadi Jafarian, Sima Jafarikhah</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08493">https://arxiv.org/abs/2509.08493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08493">https://arxiv.org/pdf/2509.08493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08493]] Send to which account? Evaluation of an LLM-based Scambaiting System(https://arxiv.org/abs/2509.08493)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, generative, large language model</a></li>
<li><strong>Abstract: </strong>Scammers are increasingly harnessing generative AI(GenAI) technologies to produce convincing phishing content at scale, amplifying financial fraud and undermining public trust. While conventional defenses, such as detection algorithms, user training, and reactive takedown efforts remain important, they often fall short in dismantling the infrastructure scammers depend on, including mule bank accounts and cryptocurrency wallets. To bridge this gap, a proactive and emerging strategy involves using conversational honeypots to engage scammers and extract actionable threat intelligence. This paper presents the first large-scale, real-world evaluation of a scambaiting system powered by large language models (LLMs). Over a five-month deployment, the system initiated over 2,600 engagements with actual scammers, resulting in a dataset of more than 18,700 messages. It achieved an Information Disclosure Rate (IDR) of approximately 32%, successfully extracting sensitive financial information such as mule accounts. Additionally, the system maintained a Human Acceptance Rate (HAR) of around 70%, indicating strong alignment between LLM-generated responses and human operator preferences. Alongside these successes, our analysis reveals key operational challenges. In particular, the system struggled with engagement takeoff: only 48.7% of scammers responded to the initial seed message sent by defenders. These findings highlight the need for further refinement and provide actionable insights for advancing the design of automated scambaiting systems.</li>
</ul>

<h3>Title: Variational Rank Reduction Autoencoders for Generative</h3>
<ul>
<li><strong>Authors: </strong>Alicia Tierz, Jad Mounayer, Beatriz Moya, Francisco Chinesta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08515">https://arxiv.org/abs/2509.08515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08515">https://arxiv.org/pdf/2509.08515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08515]] Variational Rank Reduction Autoencoders for Generative(https://arxiv.org/abs/2509.08515)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative thermal design for complex geometries is fundamental in many areas of engineering, yet it faces two main challenges: the high computational cost of high-fidelity simulations and the limitations of conventional generative models. Approaches such as autoencoders (AEs) and variational autoencoders (VAEs) often produce unstructured latent spaces with discontinuities, which restricts their capacity to explore designs and generate physically consistent solutions. To address these limitations, we propose a hybrid framework that combines Variational Rank-Reduction Autoencoders (VRRAEs) with Deep Operator Networks (DeepONets). The VRRAE introduces a truncated SVD within the latent space, leading to continuous, interpretable, and well-structured representations that mitigate posterior collapse and improve geometric reconstruction. The DeepONet then exploits this compact latent encoding in its branch network, together with spatial coordinates in the trunk network, to predict temperature gradients efficiently and accurately. This hybrid approach not only enhances the quality of generated geometries and the accuracy of gradient prediction, but also provides a substantial advantage in inference efficiency compared to traditional numerical solvers. Overall, the study underscores the importance of structured latent representations for operator learning and highlights the potential of combining generative models and operator networks in thermal design and broader engineering applications.</li>
</ul>

<h3>Title: Data Skeleton Learning: Scalable Active Clustering with Sparse Graph Structures</h3>
<ul>
<li><strong>Authors: </strong>Wen-Bo Xie, Xun Fu, Bin Chen, Yan-Li Lee, Tao Deng, Tian Zou, Xin Wang, Zhen Liu, Jaideep Srivastavad</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08530">https://arxiv.org/abs/2509.08530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08530">https://arxiv.org/pdf/2509.08530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08530]] Data Skeleton Learning: Scalable Active Clustering with Sparse Graph Structures(https://arxiv.org/abs/2509.08530)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we focus on the efficiency and scalability of pairwise constraint-based active clustering, crucial for processing large-scale data in applications such as data mining, knowledge annotation, and AI model pre-training. Our goals are threefold: (1) to reduce computational costs for iterative clustering updates; (2) to enhance the impact of user-provided constraints to minimize annotation requirements for precise clustering; and (3) to cut down memory usage in practical deployments. To achieve these aims, we propose a graph-based active clustering algorithm that utilizes two sparse graphs: one for representing relationships between data (our proposed data skeleton) and another for updating this data skeleton. These two graphs work in concert, enabling the refinement of connected subgraphs within the data skeleton to create nested clusters. Our empirical analysis confirms that the proposed algorithm consistently facilitates more accurate clustering with dramatically less input of user-provided constraints, and outperforms its counterparts in terms of computational performance and scalability, while maintaining robustness across various distance metrics.</li>
</ul>

<h3>Title: MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models</h3>
<ul>
<li><strong>Authors: </strong>Garry Yang, Zizhe Chen, Man Hon Wong, Haoyu Lei, Yongqiang Chen, Zhenguo Li, Kaiwen Zhou, James Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08538">https://arxiv.org/abs/2509.08538</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08538">https://arxiv.org/pdf/2509.08538</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08538]] MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models(https://arxiv.org/abs/2509.08538)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Video Models (LVMs) build on the semantic capabilities of Large Language Models (LLMs) and vision modules by integrating temporal information to better understand dynamic video content. Despite their progress, LVMs are prone to hallucinations-producing inaccurate or irrelevant descriptions. Current benchmarks for video hallucination depend heavily on manual categorization of video content, neglecting the perception-based processes through which humans naturally interpret videos. We introduce MESH, a benchmark designed to evaluate hallucinations in LVMs systematically. MESH uses a Question-Answering framework with binary and multi-choice formats incorporating target and trap instances. It follows a bottom-up approach, evaluating basic objects, coarse-to-fine subject features, and subject-action pairs, aligning with human video understanding. We demonstrate that MESH offers an effective and comprehensive approach for identifying hallucinations in videos. Our evaluations show that while LVMs excel at recognizing basic objects and features, their susceptibility to hallucinations increases markedly when handling fine details or aligning multiple actions involving various subjects in longer videos.</li>
</ul>

<h3>Title: CM-Align: Consistency-based Multilingual Alignment for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08541">https://arxiv.org/abs/2509.08541</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08541">https://arxiv.org/pdf/2509.08541</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08541]] CM-Align: Consistency-based Multilingual Alignment for Large Language Models(https://arxiv.org/abs/2509.08541)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current large language models (LLMs) generally show a significant performance gap in alignment between English and other languages. To bridge this gap, existing research typically leverages the model's responses in English as a reference to select the best/worst responses in other languages, which are then used for Direct Preference Optimization (DPO) training. However, we argue that there are two limitations in the current methods that result in noisy multilingual preference data and further limited alignment performance: 1) Not all English responses are of high quality, and using a response with low quality may mislead the alignment for other languages. 2) Current methods usually use biased or heuristic approaches to construct multilingual preference pairs. To address these limitations, we design a consistency-based data selection method to construct high-quality multilingual preference data for improving multilingual alignment (CM-Align). Specifically, our method includes two parts: consistency-guided English reference selection and cross-lingual consistency-based multilingual preference data construction. Experimental results on three LLMs and three common tasks demonstrate the effectiveness and superiority of our method, which further indicates the necessity of constructing high-quality preference data.</li>
</ul>

<h3>Title: Vision-Language Semantic Aggregation Leveraging Foundation Model for Generalizable Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Wenjun Yu, Yinchen Zhou, Jia-Xuan Jiang, Shubin Zeng, Yuee Li, Zhong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08570">https://arxiv.org/abs/2509.08570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08570">https://arxiv.org/pdf/2509.08570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08570]] Vision-Language Semantic Aggregation Leveraging Foundation Model for Generalizable Medical Image Segmentation(https://arxiv.org/abs/2509.08570)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Multimodal models have achieved remarkable success in natural image segmentation, yet they often underperform when applied to the medical domain. Through extensive study, we attribute this performance gap to the challenges of multimodal fusion, primarily the significant semantic gap between abstract textual prompts and fine-grained medical visual features, as well as the resulting feature dispersion. To address these issues, we revisit the problem from the perspective of semantic aggregation. Specifically, we propose an Expectation-Maximization (EM) Aggregation mechanism and a Text-Guided Pixel Decoder. The former mitigates feature dispersion by dynamically clustering features into compact semantic centers to enhance cross-modal correspondence. The latter is designed to bridge the semantic gap by leveraging domain-invariant textual knowledge to effectively guide deep visual representations. The synergy between these two mechanisms significantly improves the model's generalization ability. Extensive experiments on public cardiac and fundus datasets demonstrate that our method consistently outperforms existing SOTA approaches across multiple domain generalization benchmarks.</li>
</ul>

<h3>Title: MAESTRO: Multi-modal Adaptive Ensemble for Spectro-Temporal Robust Optimization</h3>
<ul>
<li><strong>Authors: </strong>Hong Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.PE, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08578">https://arxiv.org/abs/2509.08578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08578">https://arxiv.org/pdf/2509.08578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08578]] MAESTRO: Multi-modal Adaptive Ensemble for Spectro-Temporal Robust Optimization(https://arxiv.org/abs/2509.08578)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Timely and robust influenza incidence forecasting is critical for public health decision-making. To address this, we present MAESTRO, a Multi-modal Adaptive Ensemble for Spectro-Temporal Robust Optimization. MAESTRO achieves robustness by adaptively fusing multi-modal inputs-including surveillance, web search trends, and meteorological data-and leveraging a comprehensive spectro-temporal architecture. The model first decomposes time series into seasonal and trend components. These are then processed through a hybrid feature enhancement pipeline combining Transformer-based encoders, a Mamba state-space model for long-range dependencies, multi-scale temporal convolutions, and a frequency-domain analysis module. A cross-channel attention mechanism further integrates information across the different data modalities. Finally, a temporal projection head performs sequence-to-sequence forecasting, with an optional estimator to quantify prediction uncertainty. Evaluated on over 11 years of Hong Kong influenza data (excluding the COVID-19 period), MAESTRO shows strong competitive performance, demonstrating a superior model fit and relative accuracy, achieving a state-of-the-art R-square of 0.956. Extensive ablations confirm the significant contributions of both multi-modal fusion and the spectro-temporal components. Our modular and reproducible pipeline is made publicly available to facilitate deployment and extension to other regions and this http URL publicly available pipeline presents a powerful, unified framework, demonstrating the critical synergy of advanced spectro-temporal modeling and multi-modal data fusion for robust epidemiological forecasting.</li>
</ul>

<h3>Title: Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mathilde Monvoisin, Louise Piecuch, Blanche Texier, Cédric Hémon, Anaïs Barateau, Jérémie Huet, Antoine Nordez, Anne-Sophie Boureau, Jean-Claude Nunes, Diana Mateus</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08580">https://arxiv.org/abs/2509.08580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08580">https://arxiv.org/pdf/2509.08580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08580]] Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation(https://arxiv.org/abs/2509.08580)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>The objective of this paper is to significantly reduce the manual workload required from medical professionals in complex 3D segmentation tasks that cannot be yet fully automated. For instance, in radiotherapy planning, organs at risk must be accurately identified in computed tomography (CT) or magnetic resonance imaging (MRI) scans to ensure they are spared from harmful radiation. Similarly, diagnosing age-related degenerative diseases such as sarcopenia, which involve progressive muscle volume loss and strength, is commonly based on muscular mass measurements often obtained from manual segmentation of medical volumes. To alleviate the manual-segmentation burden, this paper introduces an implicit shape prior to segment volumes from sparse slice manual annotations generalized to the multi-organ case, along with a simple framework for automatically selecting the most informative slices to guide and minimize the next interactions. The experimental validation shows the method's effectiveness on two medical use cases: assisted segmentation in the context of at risks organs for brain cancer patients, and acceleration of the creation of a new database with unseen muscle shapes for patients with sarcopenia.</li>
</ul>

<h3>Title: EfficientIML: Efficient High-Resolution Image Manipulation Localization</h3>
<ul>
<li><strong>Authors: </strong>Jinhan Li, Haoyang He, Lei Xie, Jiangning Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08583">https://arxiv.org/abs/2509.08583</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08583">https://arxiv.org/pdf/2509.08583</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08583]] EfficientIML: Efficient High-Resolution Image Manipulation Localization(https://arxiv.org/abs/2509.08583)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With imaging devices delivering ever-higher resolutions and the emerging diffusion-based forgery methods, current detectors trained only on traditional datasets (with splicing, copy-moving and object removal forgeries) lack exposure to this new manipulation type. To address this, we propose a novel high-resolution SIF dataset of 1200+ diffusion-generated manipulations with semantically extracted masks. However, this also imposes a challenge on existing methods, as they face significant computational resource constraints due to their prohibitive computational complexities. Therefore, we propose a novel EfficientIML model with a lightweight, three-stage EfficientRWKV backbone. EfficientRWKV's hybrid state-space and attention network captures global context and local details in parallel, while a multi-scale supervision strategy enforces consistency across hierarchical predictions. Extensive evaluations on our dataset and standard benchmarks demonstrate that our approach outperforms ViT-based and other SOTA lightweight baselines in localization performance, FLOPs and inference speed, underscoring its suitability for real-time forensic applications.</li>
</ul>

<h3>Title: Interpretability as Alignment: Making Internal Understanding a Design Principle</h3>
<ul>
<li><strong>Authors: </strong>Aadit Sengupta, Pratinav Seth, Vinay Kumar Sankarapu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08592">https://arxiv.org/abs/2509.08592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08592">https://arxiv.org/pdf/2509.08592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08592]] Interpretability as Alignment: Making Internal Understanding a Design Principle(https://arxiv.org/abs/2509.08592)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Large neural models are increasingly deployed in high-stakes settings, raising concerns about whether their behavior reliably aligns with human values. Interpretability provides a route to internal transparency by revealing the computations that drive outputs. We argue that interpretability especially mechanistic approaches should be treated as a design principle for alignment, not an auxiliary diagnostic tool. Post-hoc methods such as LIME or SHAP offer intuitive but correlational explanations, while mechanistic techniques like circuit tracing or activation patching yield causal insight into internal failures, including deceptive or misaligned reasoning that behavioral methods like RLHF, red teaming, or Constitutional AI may overlook. Despite these advantages, interpretability faces challenges of scalability, epistemic uncertainty, and mismatches between learned representations and human concepts. Our position is that progress on safe and trustworthy AI will depend on making interpretability a first-class objective of AI research and development, ensuring that systems are not only effective but also auditable, transparent, and aligned with human intent.</li>
</ul>

<h3>Title: LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question Answering for BioASQ Challenge</h3>
<ul>
<li><strong>Authors: </strong>Dima Galat, Diego Molla-Aliod</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08596">https://arxiv.org/abs/2509.08596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08596">https://arxiv.org/pdf/2509.08596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08596]] LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question Answering for BioASQ Challenge(https://arxiv.org/abs/2509.08596)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Biomedical question answering (QA) poses significant challenges due to the need for precise interpretation of specialized knowledge drawn from a vast, complex, and rapidly evolving corpus. In this work, we explore how large language models (LLMs) can be used for information retrieval (IR), and an ensemble of zero-shot models can accomplish state-of-the-art performance on a domain-specific Yes/No QA task. Evaluating our approach on the BioASQ challenge tasks, we show that ensembles can outperform individual LLMs and in some cases rival or surpass domain-tuned systems - all while preserving generalizability and avoiding the need for costly fine-tuning or labeled data. Our method aggregates outputs from multiple LLM variants, including models from Anthropic and Google, to synthesize more accurate and robust answers. Moreover, our investigation highlights a relationship between context length and performance: while expanded contexts are meant to provide valuable evidence, they simultaneously risk information dilution and model disorientation. These findings emphasize IR as a critical foundation in Retrieval-Augmented Generation (RAG) approaches for biomedical QA systems. Precise, focused retrieval remains essential for ensuring LLMs operate within relevant information boundaries when generating answers from retrieved documents. Our results establish that ensemble-based zero-shot approaches, when paired with effective RAG pipelines, constitute a practical and scalable alternative to domain-tuned systems for biomedical question answering.</li>
</ul>

<h3>Title: Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications</h3>
<ul>
<li><strong>Authors: </strong>Anran Li, Lingfei Qian, Mengmeng Du, Yu Yin, Yan Hu, Zihao Sun, Yihang Fu, Erica Stutz, Xuguang Ai, Qianqian Xie, Rui Zhu, Jimin Huang, Yifan Yang, Siru Liu, Yih-Chung Tham, Lucila Ohno-Machado, Hyunghoon Cho, Zhiyong Lu, Hua Xu, Qingyu Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08604">https://arxiv.org/abs/2509.08604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08604">https://arxiv.org/pdf/2509.08604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08604]] Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications(https://arxiv.org/abs/2509.08604)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated significant potential in medicine. To date, LLMs have been widely applied to tasks such as diagnostic assistance, medical question answering, and clinical information synthesis. However, a key open question remains: to what extent do LLMs memorize medical training data. In this study, we present the first comprehensive evaluation of memorization of LLMs in medicine, assessing its prevalence (how frequently it occurs), characteristics (what is memorized), volume (how much content is memorized), and potential downstream impacts (how memorization may affect medical applications). We systematically analyze common adaptation scenarios: (1) continued pretraining on medical corpora, (2) fine-tuning on standard medical benchmarks, and (3) fine-tuning on real-world clinical data, including over 13,000 unique inpatient records from Yale New Haven Health System. The results demonstrate that memorization is prevalent across all adaptation scenarios and significantly higher than reported in the general domain. Memorization affects both the development and adoption of LLMs in medicine and can be categorized into three types: beneficial (e.g., accurate recall of clinical guidelines and biomedical references), uninformative (e.g., repeated disclaimers or templated medical document language), and harmful (e.g., regeneration of dataset-specific or sensitive clinical content). Based on these findings, we offer practical recommendations to facilitate beneficial memorization that enhances domain-specific reasoning and factual accuracy, minimize uninformative memorization to promote deeper learning beyond surface-level patterns, and mitigate harmful memorization to prevent the leakage of sensitive or identifiable patient information.</li>
</ul>

<h3>Title: OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Xinfeng Liao, Xuanqi Chen, Lianxi Wang, Jiahuan Yang, Zhuowei Chen, Ziying Rong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08612">https://arxiv.org/abs/2509.08612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08612">https://arxiv.org/pdf/2509.08612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08612]] OTESGN:Optimal Transport Enhanced Syntactic-Semantic Graph Networks for Aspect-Based Sentiment Analysis(https://arxiv.org/abs/2509.08612)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Aspect-based sentiment analysis (ABSA) aims to identify aspect terms and determine their sentiment polarity. While dependency trees combined with contextual semantics effectively identify aspect sentiment, existing methods relying on syntax trees and aspect-aware attention struggle to model complex semantic relationships. Their dependence on linear dot-product features fails to capture nonlinear associations, allowing noisy similarity from irrelevant words to obscure key opinion terms. Motivated by Differentiable Optimal Matching, we propose the Optimal Transport Enhanced Syntactic-Semantic Graph Network (OTESGN), which introduces a Syntactic-Semantic Collaborative Attention. It comprises a Syntactic Graph-Aware Attention for mining latent syntactic dependencies and modeling global syntactic topology, as well as a Semantic Optimal Transport Attention designed to uncover fine-grained semantic alignments amidst textual noise, thereby accurately capturing sentiment signals obscured by irrelevant tokens. A Adaptive Attention Fusion module integrates these heterogeneous features, and contrastive regularization further improves robustness. Experiments demonstrate that OTESGN achieves state-of-the-art results, outperforming previous best models by +1.01% F1 on Twitter and +1.30% F1 on Laptop14 benchmarks. Ablative studies and visual analyses corroborate its efficacy in precise localization of opinion words and noise resistance.</li>
</ul>

<h3>Title: Towards Interpretable Deep Neural Networks for Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Khawla Elhadri, Jörg Schlötterer, Christin Seifert</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08617">https://arxiv.org/abs/2509.08617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08617">https://arxiv.org/pdf/2509.08617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08617]] Towards Interpretable Deep Neural Networks for Tabular Data(https://arxiv.org/abs/2509.08617)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Tabular data is the foundation of many applications in fields such as finance and healthcare. Although DNNs tailored for tabular data achieve competitive predictive performance, they are blackboxes with little interpretability. We introduce XNNTab, a neural architecture that uses a sparse autoencoder (SAE) to learn a dictionary of monosemantic features within the latent space used for prediction. Using an automated method, we assign human-interpretable semantics to these features. This allows us to represent predictions as linear combinations of semantically meaningful components. Empirical evaluations demonstrate that XNNTab attains performance on par with or exceeding that of state-of-the-art, black-box neural models and classical machine learning approaches while being fully interpretable.</li>
</ul>

<h3>Title: CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal Imaging</h3>
<ul>
<li><strong>Authors: </strong>Zhihao Zhao, Yinzheng Zhao, Junjie Yang, Xiangtong Yao, Quanmin Liang, Shahrooz Faghihroohi, Kai Huang, Nassir Navab, M.Ali Nasseri</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08618">https://arxiv.org/abs/2509.08618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08618">https://arxiv.org/pdf/2509.08618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08618]] CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal Imaging(https://arxiv.org/abs/2509.08618)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in foundation models, such as the Segment Anything Model (SAM), have significantly impacted medical image segmentation, especially in retinal imaging, where precise segmentation is vital for diagnosis. Despite this progress, current methods face critical challenges: 1) modality ambiguity in textual disease descriptions, 2) a continued reliance on manual prompting for SAM-based workflows, and 3) a lack of a unified framework, with most methods being modality- and task-specific. To overcome these hurdles, we propose CLIP-unified Auto-Prompt Segmentation (\CLAPS), a novel method for unified segmentation across diverse tasks and modalities in retinal imaging. Our approach begins by pre-training a CLIP-based image encoder on a large, multi-modal retinal dataset to handle data scarcity and distribution imbalance. We then leverage GroundingDINO to automatically generate spatial bounding box prompts by detecting local lesions. To unify tasks and resolve ambiguity, we use text prompts enhanced with a unique "modality signature" for each imaging modality. Ultimately, these automated textual and spatial prompts guide SAM to execute precise segmentation, creating a fully automated and unified pipeline. Extensive experiments on 12 diverse datasets across 11 critical segmentation categories show that CLAPS achieves performance on par with specialized expert models while surpassing existing benchmarks across most metrics, demonstrating its broad generalizability as a foundation model.</li>
</ul>

<h3>Title: AdsQA: Towards Advertisement Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Xinwei Long, Kai Tian, Peng Xu, Guoli Jia, Jingxuan Li, Sa Yang, Yihua Shao, Kaiyan Zhang, Che Jiang, Hao Xu, Yang Liu, Jiaheng Ma, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08621">https://arxiv.org/abs/2509.08621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08621">https://arxiv.org/pdf/2509.08621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08621]] AdsQA: Towards Advertisement Video Understanding(https://arxiv.org/abs/2509.08621)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have taken a great step towards AGI. Meanwhile, an increasing number of domain-specific problems such as math and programming boost these general-purpose models to continuously evolve via learning deeper expertise. Now is thus the time further to extend the diversity of specialized applications for knowledgeable LLMs, though collecting high quality data with unexpected and informative tasks is challenging. In this paper, we propose to use advertisement (ad) videos as a challenging test-bed to probe the ability of LLMs in perceiving beyond the objective physical content of common visual domain. Our motivation is to take full advantage of the clue-rich and information-dense ad videos' traits, e.g., marketing logic, persuasive strategies, and audience engagement. Our contribution is three-fold: (1) To our knowledge, this is the first attempt to use ad videos with well-designed tasks to evaluate LLMs. We contribute AdsQA, a challenging ad Video QA benchmark derived from 1,544 ad videos with 10,962 clips, totaling 22.7 hours, providing 5 challenging tasks. (2) We propose ReAd-R, a Deepseek-R1 styled RL model that reflects on questions, and generates answers via reward-driven optimization. (3) We benchmark 14 top-tier LLMs on AdsQA, and our \texttt{ReAd-R}~achieves the state-of-the-art outperforming strong competitors equipped with long-chain reasoning capabilities by a clear margin.</li>
</ul>

<h3>Title: LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation</h3>
<ul>
<li><strong>Authors: </strong>Xuqin Wang, Tao Wu, Yanfeng Zhang, Lu Liu, Dong Wang, Mingwei Sun, Yongliang Wang, Niclas Zeller, Daniel Cremers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08628">https://arxiv.org/abs/2509.08628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08628">https://arxiv.org/pdf/2509.08628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08628]] LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation(https://arxiv.org/abs/2509.08628)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Diffusion models excel at generating high-quality outputs but face challenges in data-scarce domains, where exhaustive retraining or costly paired data are often required. To address these limitations, we propose Latent Aligned Diffusion Bridges (LADB), a semi-supervised framework for sample-to-sample translation that effectively bridges domain gaps using partially paired data. By aligning source and target distributions within a shared latent space, LADB seamlessly integrates pretrained source-domain diffusion models with a target-domain Latent Aligned Diffusion Model (LADM), trained on partially paired latent representations. This approach enables deterministic domain mapping without the need for full supervision. Compared to unpaired methods, which often lack controllability, and fully paired approaches that require large, domain-specific datasets, LADB strikes a balance between fidelity and diversity by leveraging a mixture of paired and unpaired latent-target couplings. Our experimental results demonstrate superior performance in depth-to-image translation under partial supervision. Furthermore, we extend LADB to handle multi-source translation (from depth maps and segmentation masks) and multi-target translation in a class-conditioned style transfer task, showcasing its versatility in handling diverse and heterogeneous use cases. Ultimately, we present LADB as a scalable and versatile solution for real-world domain translation, particularly in scenarios where data annotation is costly or incomplete.</li>
</ul>

<h3>Title: Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations</h3>
<ul>
<li><strong>Authors: </strong>Ron F. Del Rosario, Klaudia Krawiecka, Christian Schroeder de Witt</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08646">https://arxiv.org/abs/2509.08646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08646">https://arxiv.org/pdf/2509.08646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08646]] Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations(https://arxiv.org/abs/2509.08646)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount. This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution. We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act). A central focus is placed on the security implications of this design, particularly its inherent resilience to indirect prompt injection attacks by establishing control-flow integrity. We argue that while P-t-E provides a strong foundation, a defense-in-depth strategy is necessary, and we detail essential complementary controls such as the Principle of Least Privilege, task-scoped tool access, and sandboxed code execution. To make these principles actionable, this guide provides detailed implementation blueprints and working code references for three leading agentic frameworks: LangChain (via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing the P-t-E pattern is analyzed, highlighting unique features like LangGraph's stateful graphs for re-planning, CrewAI's declarative tool scoping for security, and AutoGen's built-in Docker sandboxing. Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents.</li>
</ul>

<h3>Title: Generative Data Refinement: Just Ask for Better Data</h3>
<ul>
<li><strong>Authors: </strong>Minqi Jiang, João G. M. Araújo, Will Ellsworth, Sian Gooding, Edward Grefenstette</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08653">https://arxiv.org/abs/2509.08653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08653">https://arxiv.org/pdf/2509.08653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08653]] Generative Data Refinement: Just Ask for Better Data(https://arxiv.org/abs/2509.08653)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>For a fixed parameter size, the capabilities of large models are primarily determined by the quality and quantity of its training data. Consequently, training datasets now grow faster than the rate at which new data is indexed on the web, leading to projected data exhaustion over the next decade. Much more data exists as user-generated content that is not publicly indexed, but incorporating such data comes with considerable risks, such as leaking private information and other undesirable content. We introduce a framework, Generative Data Refinement (GDR), for using pretrained generative models to transform a dataset with undesirable content into a refined dataset that is more suitable for training. Our experiments show that GDR can outperform industry-grade solutions for dataset anonymization, as well as enable direct detoxification of highly unsafe datasets. Moreover, we show that by generating synthetic data that is conditioned on each example in the real dataset, GDR's refined outputs naturally match the diversity of web scale datasets, and thereby avoid the often challenging task of generating diverse synthetic data via model prompting. The simplicity and effectiveness of GDR make it a powerful tool for scaling up the total stock of training data for frontier models.</li>
</ul>

<h3>Title: Replicable Reinforcement Learning with Linear Function Approximation</h3>
<ul>
<li><strong>Authors: </strong>Eric Eaton, Marcel Hussing, Michael Kearns, Aaron Roth, Sikata Bela Sengupta, Jessica Sorrell</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08660">https://arxiv.org/abs/2509.08660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08660">https://arxiv.org/pdf/2509.08660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08660]] Replicable Reinforcement Learning with Linear Function Approximation(https://arxiv.org/abs/2509.08660)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Replication of experimental results has been a challenge faced by many scientific disciplines, including the field of machine learning. Recent work on the theory of machine learning has formalized replicability as the demand that an algorithm produce identical outcomes when executed twice on different samples from the same distribution. Provably replicable algorithms are especially interesting for reinforcement learning (RL), where algorithms are known to be unstable in practice. While replicable algorithms exist for tabular RL settings, extending these guarantees to more practical function approximation settings has remained an open problem. In this work, we make progress by developing replicable methods for linear function approximation in RL. We first introduce two efficient algorithms for replicable random design regression and uncentered covariance estimation, each of independent interest. We then leverage these tools to provide the first provably efficient replicable RL algorithms for linear Markov decision processes in both the generative model and episodic settings. Finally, we evaluate our algorithms experimentally and show how they can inspire more consistent neural policies.</li>
</ul>

<h3>Title: Perfectly-Private Analog Secure Aggregation in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Delio Jaramillo-Velez, Charul Rajput, Ragnar Freij-Hollanti, Camilla Hollanti, Alexandre Graell i Amat</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08683">https://arxiv.org/abs/2509.08683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08683">https://arxiv.org/pdf/2509.08683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08683]] Perfectly-Private Analog Secure Aggregation in Federated Learning(https://arxiv.org/abs/2509.08683)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate</a></li>
<li><strong>Abstract: </strong>In federated learning, multiple parties train models locally and share their parameters with a central server, which aggregates them to update a global model. To address the risk of exposing sensitive data through local models, secure aggregation via secure multiparty computation has been proposed to enhance privacy. At the same time, perfect privacy can only be achieved by a uniform distribution of the masked local models to be aggregated. This raises a problem when working with real valued data, as there is no measure on the reals that is invariant under the masking operation, and hence information leakage is bound to occur. Shifting the data to a finite field circumvents this problem, but as a downside runs into an inherent accuracy complexity tradeoff issue due to fixed point modular arithmetic as opposed to floating point numbers that can simultaneously handle numbers of varying magnitudes. In this paper, a novel secure parameter aggregation method is proposed that employs the torus rather than a finite field. This approach guarantees perfect privacy for each party's data by utilizing the uniform distribution on the torus, while avoiding accuracy losses. Experimental results show that the new protocol performs similarly to the model without secure aggregation while maintaining perfect privacy. Compared to the finite field secure aggregation, the torus-based protocol can in some cases significantly outperform it in terms of model accuracy and cosine similarity, hence making it a safer choice.</li>
</ul>

<h3>Title: Multi-Modal Robust Enhancement for Coastal Water Segmentation: A Systematic HSV-Guided Framework</h3>
<ul>
<li><strong>Authors: </strong>Zhen Tian, Christos Anagnostopoulos, Qiyuan Wang, Zhiwei Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08694">https://arxiv.org/abs/2509.08694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08694">https://arxiv.org/pdf/2509.08694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08694]] Multi-Modal Robust Enhancement for Coastal Water Segmentation: A Systematic HSV-Guided Framework(https://arxiv.org/abs/2509.08694)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Coastal water segmentation from satellite imagery presents unique challenges due to complex spectral characteristics and irregular boundary patterns. Traditional RGB-based approaches often suffer from training instability and poor generalization in diverse maritime environments. This paper introduces a systematic robust enhancement framework, referred to as Robust U-Net, that leverages HSV color space supervision and multi-modal constraints for improved coastal water segmentation. Our approach integrates five synergistic components: HSV-guided color supervision, gradient-based coastline optimization, morphological post-processing, sea area cleanup, and connectivity control. Through comprehensive ablation studies, we demonstrate that HSV supervision provides the highest impact (0.85 influence score), while the complete framework achieves superior training stability (84\% variance reduction) and enhanced segmentation quality. Our method shows consistent improvements across multiple evaluation metrics while maintaining computational efficiency. For reproducibility, our training configurations and code are available here: this https URL.</li>
</ul>

<h3>Title: A layered architecture for log analysis in complex IT systems</h3>
<ul>
<li><strong>Authors: </strong>Thorsten Wittkopp</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08698">https://arxiv.org/abs/2509.08698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08698">https://arxiv.org/pdf/2509.08698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08698]] A layered architecture for log analysis in complex IT systems(https://arxiv.org/abs/2509.08698)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the evolving IT landscape, stability and reliability of systems are essential, yet their growing complexity challenges DevOps teams in implementation and maintenance. Log analysis, a core element of AIOps, provides critical insights into complex behaviors and failures. This dissertation introduces a three-layered architecture to support DevOps in failure resolution. The first layer, Log Investigation, performs autonomous log labeling and anomaly classification. We propose a method that labels log data without manual effort, enabling supervised training and precise evaluation of anomaly detection. Additionally, we define a taxonomy that groups anomalies into three categories, ensuring appropriate method selection. The second layer, Anomaly Detection, detects behaviors deviating from the norm. We propose a flexible Anomaly Detection method adaptable to unsupervised, weakly supervised, and supervised training. Evaluations on public and industry datasets show F1-scores between 0.98 and 1.0, ensuring reliable anomaly detection. The third layer, Root Cause Analysis, identifies minimal log sets describing failures, their origin, and event sequences. By balancing training data and identifying key services, our Root Cause Analysis method consistently detects 90-98% of root cause log lines within the top 10 candidates, providing actionable insights for mitigation. Our research addresses how log analysis methods can be designed and optimized to help DevOps resolve failures efficiently. By integrating these three layers, the architecture equips teams with robust methods to enhance IT system reliability.</li>
</ul>

<h3>Title: Tight Privacy Audit in One Run</h3>
<ul>
<li><strong>Authors: </strong>Zihang Xiang, Tianhao Wang, Hanshen Xiao, Yuan Tian, Di Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08704">https://arxiv.org/abs/2509.08704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08704">https://arxiv.org/pdf/2509.08704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08704]] Tight Privacy Audit in One Run(https://arxiv.org/abs/2509.08704)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this paper, we study the problem of privacy audit in one run and show that our method achieves tight audit results for various differentially private protocols. This includes obtaining tight results for auditing $(\varepsilon,\delta)$-DP algorithms where all previous work fails to achieve in any parameter setups. We first formulate a framework for privacy audit \textit{in one run} with refinement compared with previous work. Then, based on modeling privacy by the $f$-DP formulation, we study the implications of our framework to obtain a theoretically justified lower bound for privacy audit. In the experiment, we compare with previous work and show that our audit method outperforms the rest in auditing various differentially private algorithms. We also provide experiments that give contrasting conclusions to previous work on the parameter settings for privacy audits in one run.</li>
</ul>

<h3>Title: Securing Private Federated Learning in a Malicious Setting: A Scalable TEE-Based Approach with Client Auditing</h3>
<ul>
<li><strong>Authors: </strong>Shun Takagi, Satoshi Hasegawa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08709">https://arxiv.org/abs/2509.08709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08709">https://arxiv.org/pdf/2509.08709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08709]] Securing Private Federated Learning in a Malicious Setting: A Scalable TEE-Based Approach with Client Auditing(https://arxiv.org/abs/2509.08709)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>In cross-device private federated learning, differentially private follow-the-regularized-leader (DP-FTRL) has emerged as a promising privacy-preserving method. However, existing approaches assume a semi-honest server and have not addressed the challenge of securely removing this assumption. This is due to its statefulness, which becomes particularly problematic in practical settings where clients can drop out or be corrupted. While trusted execution environments (TEEs) might seem like an obvious solution, a straightforward implementation can introduce forking attacks or availability issues due to state management. To address this problem, our paper introduces a novel server extension that acts as a trusted computing base (TCB) to realize maliciously secure DP-FTRL. The TCB is implemented with an ephemeral TEE module on the server side to produce verifiable proofs of server actions. Some clients, upon being selected, participate in auditing these proofs with small additional communication and computational demands. This extension solution reduces the size of the TCB while maintaining the system's scalability and liveness. We provide formal proofs based on interactive differential privacy, demonstrating privacy guarantee in malicious settings. Finally, we experimentally show that our framework adds small constant overhead to clients in several realistic settings.</li>
</ul>

<h3>Title: Computational Imaging for Enhanced Computer Vision</h3>
<ul>
<li><strong>Authors: </strong>Humera Shaikh, Kaur Jashanpreet</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08712">https://arxiv.org/abs/2509.08712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08712">https://arxiv.org/pdf/2509.08712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08712]] Computational Imaging for Enhanced Computer Vision(https://arxiv.org/abs/2509.08712)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper presents a comprehensive survey of computational imaging (CI) techniques and their transformative impact on computer vision (CV) applications. Conventional imaging methods often fail to deliver high-fidelity visual data in challenging conditions, such as low light, motion blur, or high dynamic range scenes, thereby limiting the performance of state-of-the-art CV systems. Computational imaging techniques, including light field imaging, high dynamic range (HDR) imaging, deblurring, high-speed imaging, and glare mitigation, address these limitations by enhancing image acquisition and reconstruc- tion processes. This survey systematically explores the synergies between CI techniques and core CV tasks, including object detection, depth estimation, optical flow, face recognition, and keypoint detection. By analyzing the relationships between CI methods and their practical contributions to CV applications, this work highlights emerging opportunities, challenges, and future research directions. We emphasize the potential for task-specific, adaptive imaging pipelines that improve robustness, accuracy, and efficiency in real-world scenarios, such as autonomous navigation, surveillance, augmented reality, and robotics.</li>
</ul>

<h3>Title: BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated Cross-Modal Fusion</h3>
<ul>
<li><strong>Authors: </strong>Sike Xiang, Shuang Chen, Amir Atapour-Abarghouei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08715">https://arxiv.org/abs/2509.08715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08715">https://arxiv.org/pdf/2509.08715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08715]] BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated Cross-Modal Fusion(https://arxiv.org/abs/2509.08715)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As multimodal large language models (MLLMs) advance, their large-scale architectures pose challenges for deployment in resource-constrained environments. In the age of large models, where energy efficiency, computational scalability and environmental sustainability are paramount, the development of lightweight and high-performance models is critical for real-world applications. As such, we propose a lightweight MLLM framework for end-to-end visual question answering. Our proposed approach centres on BreezeCLIP, a compact yet powerful vision-language encoder optimised for efficient multimodal understanding. With only 1.2 billion parameters overall, our model significantly reduces computational cost while achieving performance comparable to standard-size MLLMs. Experiments conducted on multiple datasets further validate its effectiveness in balancing accuracy and efficiency. The modular and extensible design enables generalisation to broader multimodal tasks. The proposed lightweight vision-language framework is denoted as BcQLM (BreezeCLIP-enhanced Q-Gated Multimodal Language Model). It offers a promising path toward deployable MLLMs under practical hardware constraints. The source code is available at this https URL.</li>
</ul>

<h3>Title: PAnDA: Rethinking Metric Differential Privacy Optimization at Scale with Anchor-Based Approximation</h3>
<ul>
<li><strong>Authors: </strong>Ruiyao Liu, Chenxi Qiu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08720">https://arxiv.org/abs/2509.08720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08720">https://arxiv.org/pdf/2509.08720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08720]] PAnDA: Rethinking Metric Differential Privacy Optimization at Scale with Anchor-Based Approximation(https://arxiv.org/abs/2509.08720)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Metric Differential Privacy (mDP) extends the local differential privacy (LDP) framework to metric spaces, enabling more nuanced privacy protection for data such as geo-locations. However, existing mDP optimization methods, particularly those based on linear programming (LP), face scalability challenges due to the quadratic growth in decision variables. In this paper, we propose Perturbation via Anchor-based Distributed Approximation (PAnDA), a scalable two-phase framework for optimizing metric differential privacy (mDP). To reduce computational overhead, PAnDA allows each user to select a small set of anchor records, enabling the server to solve a compact linear program over a reduced domain. We introduce three anchor selection strategies, exponential decay (PAnDA-e), power-law decay (PAnDA-p), and logistic decay (PAnDA-l), and establish theoretical guarantees under a relaxed privacy notion called probabilistic mDP (PmDP). Experiments on real-world geo-location datasets demonstrate that PAnDA scales to secret domains with up to 5,000 records, two times larger than prior LP-based methods, while providing theoretical guarantees for both privacy and utility.</li>
</ul>

<h3>Title: SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity</h3>
<ul>
<li><strong>Authors: </strong>Zihan Liu, Xiaohu Wang, Chao Lin, Minghui Xu, Debiao He, Xinyi Huang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08722">https://arxiv.org/abs/2509.08722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08722">https://arxiv.org/pdf/2509.08722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08722]] SilentLedger: Privacy-Preserving Auditing for Blockchains with Complete Non-Interactivity(https://arxiv.org/abs/2509.08722)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, protect</a></li>
<li><strong>Abstract: </strong>Privacy-preserving blockchain systems are essential for protecting transaction data, yet they must also provide auditability that enables auditors to recover participant identities and transaction amounts when warranted. Existing designs often compromise the independence of auditing and transactions, introducing extra interactions that undermine usability and scalability. Moreover, many auditable solutions depend on auditors serving as validators or recording nodes, which introduces risks to both data security and system reliability. To overcome these challenges, we propose SilentLedger, a privacy-preserving transaction system with auditing and complete non-interactivity. To support public verification of authorization, we introduce a renewable anonymous certificate scheme with formal semantics and a rigorous security model. SilentLedger further employs traceable transaction mechanisms constructed from established cryptographic primitives, enabling users to transact without interaction while allowing auditors to audit solely from on-chain data. We formally prove security properties including authenticity, anonymity, confidentiality, and soundness, provide a concrete instantiation, and evaluate performance under a standard 2-2 transaction model. Our implementation and benchmarks demonstrate that SilentLedger achieves superior performance compared with state-of-the-art solutions.</li>
</ul>

<h3>Title: Securing Cryptographic Software via Typed Assembly Language (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Shixin Song, Tingzhen Dong, Kosi Nwabueze, Julian Zanders, Andres Erbsen, Adam Chlipala, Mengjia Yan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08727">https://arxiv.org/abs/2509.08727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08727">https://arxiv.org/pdf/2509.08727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08727]] Securing Cryptographic Software via Typed Assembly Language (Extended Version)(https://arxiv.org/abs/2509.08727)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Authors of cryptographic software are well aware that their code should not leak secrets through its timing behavior, and, until 2018, they believed that following industry-standard constant-time coding guidelines was sufficient. However, the revelation of the Spectre family of speculative execution attacks injected new complexities. To block speculative attacks, prior work has proposed annotating the program's source code to mark secret data, with hardware using this information to decide when to speculate (i.e., when only public values are involved) or not (when secrets are in play). While these solutions are able to track secret information stored on the heap, they suffer from limitations that prevent them from correctly tracking secrets on the stack, at a cost in performance. This paper introduces SecSep, a transformation framework that rewrites assembly programs so that they partition secret and public data on the stack. By moving from the source-code level to assembly rewriting, SecSep is able to address limitations of prior work. The key challenge in performing this assembly rewriting stems from the loss of semantic information through the lengthy compilation process. The key innovation of our methodology is a new variant of typed assembly language (TAL), Octal, which allows us to address this challenge. Assembly rewriting is driven by compile-time inference within Octal. We apply our technique to cryptographic programs and demonstrate that it enables secure speculation efficiently, incurring a low average overhead of $1.2\%$.</li>
</ul>

<h3>Title: Data-driven generative simulation of SDEs using diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Xuefeng Gao, Jiale Zha, Xun Yu Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08731">https://arxiv.org/abs/2509.08731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08731">https://arxiv.org/pdf/2509.08731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08731]] Data-driven generative simulation of SDEs using diffusion models(https://arxiv.org/abs/2509.08731)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper introduces a new approach to generating sample paths of unknown stochastic differential equations (SDEs) using diffusion models, a class of generative AI models commonly employed in image and video applications. Unlike the traditional Monte Carlo methods for simulating SDEs, which require explicit specifications of the drift and diffusion coefficients, our method takes a model-free, data-driven approach. Given a finite set of sample paths from an SDE, we utilize conditional diffusion models to generate new, synthetic paths of the same SDE. To demonstrate the effectiveness of our approach, we conduct a simulation experiment to compare our method with alternative benchmark ones including neural SDEs. Furthermore, in an empirical study we leverage these synthetically generated sample paths to enhance the performance of reinforcement learning algorithms for continuous-time mean-variance portfolio selection, hinting promising applications of diffusion models in financial analysis and decision-making.</li>
</ul>

<h3>Title: CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection in Crowded Scenes</h3>
<ul>
<li><strong>Authors: </strong>Marius Dähling, Sebastian Krebs, J. Marius Zöllner</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08738">https://arxiv.org/abs/2509.08738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08738">https://arxiv.org/pdf/2509.08738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08738]] CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection in Crowded Scenes(https://arxiv.org/abs/2509.08738)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel method for end-to-end crowd detection that leverages object density information to enhance existing transformer-based detectors. We present CrowdQuery (CQ), whose core component is our CQ module that predicts and subsequently embeds an object density map. The embedded density information is then systematically integrated into the decoder. Existing density map definitions typically depend on head positions or object-based spatial statistics. Our method extends these definitions to include individual bounding box dimensions. By incorporating density information into object queries, our method utilizes density-guided queries to improve detection in crowded scenes. CQ is universally applicable to both 2D and 3D detection without requiring additional data. Consequently, we are the first to design a method that effectively bridges 2D and 3D detection in crowded environments. We demonstrate the integration of CQ into both a general 2D and 3D transformer-based object detector, introducing the architectures CQ2D and CQ3D. CQ is not limited to the specific transformer models we selected. Experiments on the STCrowd dataset for both 2D and 3D domains show significant performance improvements compared to the base models, outperforming most state-of-the-art methods. When integrated into a state-of-the-art crowd detector, CQ can further improve performance on the challenging CrowdHuman dataset, demonstrating its generalizability. The code is released at this https URL.</li>
</ul>

<h3>Title: Membrane: A Cryptographic Access Control System for Data Lakes</h3>
<ul>
<li><strong>Authors: </strong>Sam Kumar, Samyukta Yagati, Conor Power, David E. Culler, Raluca Ada Popa</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08740">https://arxiv.org/abs/2509.08740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08740">https://arxiv.org/pdf/2509.08740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08740]] Membrane: A Cryptographic Access Control System for Data Lakes(https://arxiv.org/abs/2509.08740)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Organizations use data lakes to store and analyze sensitive data. But hackers may compromise data lake storage to bypass access controls and access sensitive data. To address this, we propose Membrane, a system that (1) cryptographically enforces data-dependent access control views over a data lake, (2) without restricting the analytical queries data scientists can run. We observe that data lakes, unlike DBMSes, disaggregate computation and storage into separate trust domains, making at-rest encryption sufficient to defend against remote attackers targeting data lake storage, even when running analytical queries in plaintext. This leads to a new system design for Membrane that combines encryption at rest with SQL-aware encryption. Using block ciphers, a fast symmetric-key primitive with hardware acceleration in CPUs, we develop a new SQL-aware encryption protocol well-suited to at-rest encryption. Membrane adds overhead only at the start of an interactive session due to decrypting views, delaying the first query result by up to $\approx 20\times$; subsequent queries process decrypted data in plaintext, resulting in low amortized overhead.</li>
</ul>

<h3>Title: Stealth by Conformity: Evading Robust Aggregation through Adaptive Poisoning</h3>
<ul>
<li><strong>Authors: </strong>Ryan McGaughey, Jesus Martinez del Rincon, Ihsen Alouani</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08746">https://arxiv.org/abs/2509.08746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08746">https://arxiv.org/pdf/2509.08746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08746]] Stealth by Conformity: Evading Robust Aggregation through Adaptive Poisoning(https://arxiv.org/abs/2509.08746)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, defense, attack, robust, steal, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) is a distributed learning paradigm designed to address privacy concerns. However, FL is vulnerable to poisoning attacks, where Byzantine clients compromise the integrity of the global model by submitting malicious updates. Robust aggregation methods have been widely adopted to mitigate such threats, relying on the core assumption that malicious updates are inherently out-of-distribution and can therefore be identified and excluded before aggregating client updates. In this paper, we challenge this underlying assumption by showing that a model can be poisoned while keeping malicious updates within the main distribution. We propose Chameleon Poisoning (CHAMP), an adaptive and evasive poisoning strategy that exploits side-channel feedback from the aggregation process to guide the attack. Specifically, the adversary continuously infers whether its malicious contribution has been incorporated into the global model and adapts accordingly. This enables a dynamic adjustment of the local loss function, balancing a malicious component with a camouflaging component, thereby increasing the effectiveness of the poisoning while evading robust aggregation defenses. CHAMP enables more effective and evasive poisoning, highlighting a fundamental limitation of existing robust aggregation defenses and underscoring the need for new strategies to secure federated learning against sophisticated adversaries. Our approach is evaluated in two datasets reaching an average increase of 47.07% in attack success rate against nine robust aggregation defenses.</li>
</ul>

<h3>Title: Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Wei Guo, Maura Pintor, Ambra Demontis, Battista Biggio</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08747">https://arxiv.org/abs/2509.08747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08747">https://arxiv.org/pdf/2509.08747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08747]] Silent Until Sparse: Backdoor Attacks on Semi-Structured Sparsity(https://arxiv.org/abs/2509.08747)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>In the deployment phase, semi-structured sparsity accelerates the execution of deep neural networks on modern GPUs via sparse matrix multiplication. In this paper, targeting the semi-structured sparsity, we introduce a Silent Until Sparse (SUS) backdoor attack, where the released full model remains silent (benign), but becomes a backdoored model after sparsification. The attack operates in two phases: (i) in the backdoor training phase, the backdoor functionality is injected into specific weights that will be retained during the pruning process; (ii) in the backdoor hiding phase, the malicious behavior is concealed by fine-tuning elements that will be pruned away. This dual-phase approach ensures that the attack remains undetectable in the released model, but activates properly once the model is pruned with the semi-structured sparsity. Through extensive experiments, we show that our attack successfully threatens the semi-structured sparsity algorithms from both NVIDIA and PyTorch. Our empirical results show that, regardless of model architecture, the attack success rate of the released model remains below 10% prior to sparsification but exceeds 99% afterward. Moreover, we demonstrate that SUS attack is robust against state-of-the-art backdoor defenses and finetuning, highlighting a critical vulnerability in current model compression and deployment pipelines.</li>
</ul>

<h3>Title: Prototype-Guided Robust Learning against Backdoor Attacks</h3>
<ul>
<li><strong>Authors: </strong>Wei Guo, Maura Pintor, Ambra Demontis, Battista Biggio</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08748">https://arxiv.org/abs/2509.08748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08748">https://arxiv.org/pdf/2509.08748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08748]] Prototype-Guided Robust Learning against Backdoor Attacks(https://arxiv.org/abs/2509.08748)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Backdoor attacks poison the training data to embed a backdoor in the model, causing it to behave normally on legitimate inputs but maliciously when specific trigger signals appear. Training a benign model from a dataset poisoned by backdoor attacks is challenging. Existing works rely on various assumptions and can only defend against backdoor attacks with specific trigger signals, high poisoning ratios, or when the defender possesses a large, untainted, validation dataset. In this paper, we propose a defense called Prototype-Guided Robust Learning (PGRL), which overcomes all the aforementioned limitations, being robust against diverse backdoor attacks. Leveraging a tiny set of benign samples, PGRL generates prototype vectors to guide the training process. We compare our PGRL with 8 existing defenses, showing that it achieves superior robustness. We also demonstrate that PGRL generalizes well across various architectures, datasets, and advanced attacks. Finally, to evaluate our PGRL in the worst-case scenario, we perform an adaptive attack, where the attackers fully know the details of the defense.</li>
</ul>

<h3>Title: PracMHBench: Re-evaluating Model-Heterogeneous Federated Learning Based on Practical Edge Device Constraints</h3>
<ul>
<li><strong>Authors: </strong>Yuanchun Guo, Bingyan Liu, Yulong Sha, Zhensheng Xian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08750">https://arxiv.org/abs/2509.08750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08750">https://arxiv.org/pdf/2509.08750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08750]] PracMHBench: Re-evaluating Model-Heterogeneous Federated Learning Based on Practical Edge Device Constraints(https://arxiv.org/abs/2509.08750)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federating heterogeneous models on edge devices with diverse resource constraints has been a notable trend in recent years. Compared to traditional federated learning (FL) that assumes an identical model architecture to cooperate, model-heterogeneous FL is more practical and flexible since the model can be customized to satisfy the deployment requirement. Unfortunately, no prior work ever dives into the existing model-heterogeneous FL algorithms under the practical edge device constraints and provides quantitative analysis on various data scenarios and metrics, which motivates us to rethink and re-evaluate this paradigm. In our work, we construct the first system platform \textbf{PracMHBench} to evaluate model-heterogeneous FL on practical constraints of edge devices, where diverse model heterogeneity algorithms are classified and tested on multiple data tasks and metrics. Based on the platform, we perform extensive experiments on these algorithms under the different edge constraints to observe their applicability and the corresponding heterogeneity pattern.</li>
</ul>

<h3>Title: Wanilla: Sound Noninterference Analysis for WebAssembly</h3>
<ul>
<li><strong>Authors: </strong>Markus Scherer, Jeppe Fredsgaard Blaabjerg, Alexander Sjösten, Matteo Maffei</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08758">https://arxiv.org/abs/2509.08758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08758">https://arxiv.org/pdf/2509.08758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08758]] Wanilla: Sound Noninterference Analysis for WebAssembly(https://arxiv.org/abs/2509.08758)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>WebAssembly (Wasm) is rapidly gaining popularity as a distribution format for software components embedded in various security-critical domains. Unfortunately, despite its prudent design, WebAssembly's primary use case as a compilation target for memory-unsafe languages leaves some possibilities for memory corruption. Independently of that, Wasm is an inherently interesting target for information flow analysis due to its interfacing role. Both the information flows between a Wasm module and its embedding context, as well as the memory integrity within a module, can be described by the hyperproperty noninterference. So far, no sound, fully static noninterference analysis for Wasm has been presented, but sound reachability analyses were. This work presents a novel and general approach to lift reachability analyses to noninterference by tracking taints on values and using value-sensitive, relational reasoning to remove them when appropriate. We implement this approach in Wanilla, the first automatic, sound, and fully static noninterference analysis for WebAssembly, and demonstrate its performance and precision by verifying memory integrity and other noninterference properties with several synthetic and real-world benchmarks.</li>
</ul>

<h3>Title: ArgoTweak: Towards Self-Updating HD Maps through Structured Priors</h3>
<ul>
<li><strong>Authors: </strong>Lena Wild, Rafael Valencia, Patric Jensfelt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08764">https://arxiv.org/abs/2509.08764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08764">https://arxiv.org/pdf/2509.08764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08764]] ArgoTweak: Towards Self-Updating HD Maps through Structured Priors(https://arxiv.org/abs/2509.08764)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Reliable integration of prior information is crucial for self-verifying and self-updating HD maps. However, no public dataset includes the required triplet of prior maps, current maps, and sensor data. As a result, existing methods must rely on synthetic priors, which create inconsistencies and lead to a significant sim2real gap. To address this, we introduce ArgoTweak, the first dataset to complete the triplet with realistic map priors. At its core, ArgoTweak employs a bijective mapping framework, breaking down large-scale modifications into fine-grained atomic changes at the map element level, thus ensuring interpretability. This paradigm shift enables accurate change detection and integration while preserving unchanged elements with high fidelity. Experiments show that training models on ArgoTweak significantly reduces the sim2real gap compared to synthetic priors. Extensive ablations further highlight the impact of structured priors and detailed change annotations. By establishing a benchmark for explainable, prior-aided HD mapping, ArgoTweak advances scalable, self-improving mapping solutions. The dataset, baselines, map modification toolbox, and further resources are available at this https URL.</li>
</ul>

<h3>Title: Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles</h3>
<ul>
<li><strong>Authors: </strong>Eric Slyman, Mehrab Tanjim, Kushal Kafle, Stefan Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08777">https://arxiv.org/abs/2509.08777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08777">https://arxiv.org/pdf/2509.08777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08777]] Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles(https://arxiv.org/abs/2509.08777)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) are increasingly used to evaluate text-to-image (TTI) generation systems, providing automated judgments based on visual and textual context. However, these "judge" models often suffer from biases, overconfidence, and inconsistent performance across diverse image domains. While prompt ensembling has shown promise for mitigating these issues in unimodal, text-only settings, our experiments reveal that standard ensembling methods fail to generalize effectively for TTI tasks. To address these limitations, we propose a new multimodal-aware method called Multimodal Mixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt ensemble approach augmented by image clustering, allowing the judge to dynamically assign prompt weights based on the visual characteristics of each sample. We show that MMB improves accuracy in pairwise preference judgments and greatly enhances calibration, making it easier to gauge the judge's true uncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB outperforms existing baselines in alignment with human annotations and calibration across varied image content. Our findings highlight the importance of multimodal-specific strategies for judge calibration and suggest a promising path forward for reliable large-scale TTI evaluation.</li>
</ul>

<h3>Title: Do All Autoregressive Transformers Remember Facts the Same Way? A Cross-Architecture Analysis of Recall Mechanisms</h3>
<ul>
<li><strong>Authors: </strong>Minyeong Choe, Haehyun Cho, Changho Seo, Hyunil Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08778">https://arxiv.org/abs/2509.08778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08778">https://arxiv.org/pdf/2509.08778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08778]] Do All Autoregressive Transformers Remember Facts the Same Way? A Cross-Architecture Analysis of Recall Mechanisms(https://arxiv.org/abs/2509.08778)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Understanding how Transformer-based language models store and retrieve factual associations is critical for improving interpretability and enabling targeted model editing. Prior work, primarily on GPT-style models, has identified MLP modules in early layers as key contributors to factual recall. However, it remains unclear whether these findings generalize across different autoregressive architectures. To address this, we conduct a comprehensive evaluation of factual recall across several models -- including GPT, LLaMA, Qwen, and DeepSeek -- analyzing where and how factual information is encoded and accessed. Consequently, we find that Qwen-based models behave differently from previous patterns: attention modules in the earliest layers contribute more to factual recall than MLP modules. Our findings suggest that even within the autoregressive Transformer family, architectural variations can lead to fundamentally different mechanisms of factual recall.</li>
</ul>

<h3>Title: ADHDeepNet From Raw EEG to Diagnosis: Improving ADHD Diagnosis through Temporal-Spatial Processing, Adaptive Attention Mechanisms, and Explainability in Raw EEG Signals</h3>
<ul>
<li><strong>Authors: </strong>Ali Amini, Mohammad Alijanpour, Behnam Latifi, Ali Motie Nasrabadi</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08779">https://arxiv.org/abs/2509.08779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08779">https://arxiv.org/pdf/2509.08779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08779]] ADHDeepNet From Raw EEG to Diagnosis: Improving ADHD Diagnosis through Temporal-Spatial Processing, Adaptive Attention Mechanisms, and Explainability in Raw EEG Signals(https://arxiv.org/abs/2509.08779)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, explainability</a></li>
<li><strong>Abstract: </strong>Attention Deficit Hyperactivity Disorder (ADHD) is a common brain disorder in children that can persist into adulthood, affecting social, academic, and career life. Early diagnosis is crucial for managing these impacts on patients and the healthcare system but is often labor-intensive and time-consuming. This paper presents a novel method to improve ADHD diagnosis precision and timeliness by leveraging Deep Learning (DL) approaches and electroencephalogram (EEG) signals. We introduce ADHDeepNet, a DL model that utilizes comprehensive temporal-spatial characterization, attention modules, and explainability techniques optimized for EEG signals. ADHDeepNet integrates feature extraction and refinement processes to enhance ADHD diagnosis. The model was trained and validated on a dataset of 121 participants (61 ADHD, 60 Healthy Controls), employing nested cross-validation for robust performance. The proposed two-stage methodology uses a 10-fold cross-subject validation strategy. Initially, each iteration optimizes the model's hyper-parameters with inner 2-fold cross-validation. Then, Additive Gaussian Noise (AGN) with various standard deviations and magnification levels is applied for data augmentation. ADHDeepNet achieved 100% sensitivity and 99.17% accuracy in classifying ADHD/HC subjects. To clarify model explainability and identify key brain regions and frequency bands for ADHD diagnosis, we analyzed the learned weights and activation patterns of the model's primary layers. Additionally, t-distributed Stochastic Neighbor Embedding (t-SNE) visualized high-dimensional data, aiding in interpreting the model's decisions. This study highlights the potential of DL and EEG in enhancing ADHD diagnosis accuracy and efficiency.</li>
</ul>

<h3>Title: An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images</h3>
<ul>
<li><strong>Authors: </strong>Asif Newaz, Asif Ur Rahman Adib, Rajit Sahil, Mashfique Mehzad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08780">https://arxiv.org/abs/2509.08780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08780">https://arxiv.org/pdf/2509.08780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08780]] An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images(https://arxiv.org/abs/2509.08780)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Background: Arsenicosis is a serious public health concern in South and Southeast Asia, primarily caused by long-term consumption of arsenic-contaminated water. Its early cutaneous manifestations are clinically significant but often underdiagnosed, particularly in rural areas with limited access to dermatologists. Automated, image-based diagnostic solutions can support early detection and timely interventions. Methods: In this study, we propose an end-to-end framework for arsenicosis diagnosis using mobile phone-captured skin images. A dataset comprising 20 classes and over 11000 images of arsenic-induced and other dermatological conditions was curated. Multiple deep learning architectures, including convolutional neural networks (CNNs) and Transformer-based models, were benchmarked for arsenicosis detection. Model interpretability was integrated via LIME and Grad-CAM, while deployment feasibility was demonstrated through a web-based diagnostic tool. Results: Transformer-based models significantly outperformed CNNs, with the Swin Transformer achieving the best results (86\\% accuracy). LIME and Grad-CAM visualizations confirmed that the models attended to lesion-relevant regions, increasing clinical transparency and aiding in error analysis. The framework also demonstrated strong performance on external validation samples, confirming its ability to generalize beyond the curated dataset. Conclusion: The proposed framework demonstrates the potential of deep learning for non-invasive, accessible, and explainable diagnosis of arsenicosis from mobile-acquired images. By enabling reliable image-based screening, it can serve as a practical diagnostic aid in rural and resource-limited communities, where access to dermatologists is scarce, thereby supporting early detection and timely intervention.</li>
</ul>

<h3>Title: Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions</h3>
<ul>
<li><strong>Authors: </strong>Bishnu Bhusal, Rohit Chadha, A. Prasad Sistla, Mahesh Viswanathan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08804">https://arxiv.org/abs/2509.08804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08804">https://arxiv.org/pdf/2509.08804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08804]] Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions(https://arxiv.org/abs/2509.08804)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The verification of differential privacy algorithms that employ Gaussian distributions is little understood. This paper tackles the challenge of verifying such programs by introducing a novel approach to approximating probability distributions of loop-free programs that sample from both discrete and continuous distributions with computable probability density functions, including Gaussian and Laplace. We establish that verifying $(\epsilon,\delta)$-differential privacy for these programs is \emph{almost decidable}, meaning the problem is decidable for all values of $\delta$ except those in a finite set. Our verification algorithm is based on computing probabilities to any desired precision by combining integral approximations, and tail probability bounds. The proposed methods are implemented in the tool, DipApprox, using the FLINT library for high-precision integral computations, and incorporate optimizations to enhance scalability. We validate {\ourtool} on fundamental privacy-preserving algorithms, such as Gaussian variants of the Sparse Vector Technique and Noisy Max, demonstrating its effectiveness in both confirming privacy guarantees and detecting violations.</li>
</ul>

<h3>Title: Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching</h3>
<ul>
<li><strong>Authors: </strong>Matthieu Vilain, Rémi Giraud, Yannick Berthoumieu, Guillaume Bourmaud</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08805">https://arxiv.org/abs/2509.08805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08805">https://arxiv.org/pdf/2509.08805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08805]] Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching(https://arxiv.org/abs/2509.08805)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Dense image matching aims to find a correspondent for every pixel of a source image in a partially overlapping target image. State-of-the-art methods typically rely on a coarse-to-fine mechanism where a single correspondent hypothesis is produced per source location at each scale. In challenging cases -- such as at depth discontinuities or when the target image is a strong zoom-in of the source image -- the correspondents of neighboring source locations are often widely spread and predicting a single correspondent hypothesis per source location at each scale may lead to erroneous matches. In this paper, we investigate the idea of predicting multiple correspondent hypotheses per source location at each scale instead. We consider a beam search strategy to propagat multiple hypotheses at each scale and propose integrating these multiple hypotheses into cross-attention layers, resulting in a novel dense matching architecture called BEAMER. BEAMER learns to preserve and propagate multiple hypotheses across scales, making it significantly more robust than state-of-the-art methods, especially at depth discontinuities or when the target image is a strong zoom-in of the source image.</li>
</ul>

<h3>Title: Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals</h3>
<ul>
<li><strong>Authors: </strong>Cheng Chen, Haiyan Yin, Ivor Tsang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08809">https://arxiv.org/abs/2509.08809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08809">https://arxiv.org/pdf/2509.08809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08809]] Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals(https://arxiv.org/abs/2509.08809)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), when paired with prompt-based tasks, have significantly reduced data annotation costs and reliance on human annotators. However, evaluating the quality of their annotations remains challenging in dynamic, unsupervised environments where oracle feedback is scarce and conventional methods fail. To address this challenge, we propose a novel agentic annotation paradigm, where a student model collaborates with a noisy teacher (the LLM) to assess and refine annotation quality without relying on oracle feedback. The student model, acting as an unsupervised feedback mechanism, employs a user preference-based majority voting strategy to evaluate the consistency of the LLM outputs. To systematically measure the reliability of LLM-generated annotations, we introduce the Consistent and Inconsistent (CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only quantifies the annotation quality of the noisy teacher under limited user preferences but also plays a critical role in model selection, enabling the identification of robust LLMs in dynamic, unsupervised environments. Applied to ten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a strong positive correlation with LLM accuracy, establishing it as an essential tool for unsupervised evaluation and model selection in real-world settings.</li>
</ul>

<h3>Title: MoVoC: Morphology-Aware Subword Construction for Geez Script Languages</h3>
<ul>
<li><strong>Authors: </strong>Hailay Kidu Teklehaymanot, Dren Fazlija, Wolfgang Nejdl</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08812">https://arxiv.org/abs/2509.08812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08812">https://arxiv.org/pdf/2509.08812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08812]] MoVoC: Morphology-Aware Subword Construction for Geez Script Languages(https://arxiv.org/abs/2509.08812)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Subword-based tokenization methods often fail to preserve morphological boundaries, a limitation especially pronounced in low-resource, morphologically complex languages such as those written in the Geez script. To address this, we present MoVoC (Morpheme-aware Subword Vocabulary Construction) and train MoVoC-Tok, a tokenizer that integrates supervised morphological analysis into the subword vocabulary. This hybrid segmentation approach combines morpheme-based and Byte Pair Encoding (BPE) tokens to preserve morphological integrity while maintaining lexical meaning. To tackle resource scarcity, we curate and release manually annotated morpheme data for four Geez script languages and a morpheme-aware vocabulary for two of them. While the proposed tokenization method does not lead to significant gains in automatic translation quality, we observe consistent improvements in intrinsic metrics, MorphoScore, and Boundary Precision, highlighting the value of morphology-aware segmentation in enhancing linguistic fidelity and token efficiency. Our morpheme-annotated datasets and tokenizer will be publicly available to support further research in low-resource, morphologically rich languages. Our code and data are available on GitHub: this https URL</li>
</ul>

<h3>Title: Merge-of-Thought Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zhanming Shen, Zeyu Qin, Zenan Huang, Hao Chen, Jiaqi Hu, Yihong Zhuang, Guoshan Lu, Gang Chen, Junbo Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08814">https://arxiv.org/abs/2509.08814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08814">https://arxiv.org/pdf/2509.08814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08814]] Merge-of-Thought Distillation(https://arxiv.org/abs/2509.08814)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Efficient reasoning distillation for long chain-of-thought (CoT) models is increasingly constrained by the assumption of a single oracle teacher, despite practical availability of multiple candidate teachers and growing CoT corpora. We revisit teacher selection and observe that different students have different "best teachers," and even for the same student the best teacher can vary across datasets. Therefore, to unify multiple teachers' reasoning abilities into student with overcoming conflicts among various teachers' supervision, we propose Merge-of-Thought Distillation (MoT), a lightweight framework that alternates between teacher-specific supervised fine-tuning branches and weight-space merging of the resulting student variants. On competition math benchmarks, using only about 200 high-quality CoT samples, applying MoT to a Qwen3-14B student surpasses strong models including DEEPSEEK-R1, QWEN3-30B-A3B, QWEN3-32B, and OPENAI-O1, demonstrating substantial gains. Besides, MoT consistently outperforms the best single-teacher distillation and the naive multi-teacher union, raises the performance ceiling while mitigating overfitting, and shows robustness to distribution-shifted and peer-level teachers. Moreover, MoT reduces catastrophic forgetting, improves general reasoning beyond mathematics and even cultivates a better teacher, indicating that consensus-filtered reasoning features transfer broadly. These results position MoT as a simple, scalable route to efficiently distilling long CoT capabilities from diverse teachers into compact students.</li>
</ul>

<h3>Title: GeneVA: A Dataset of Human Annotations for Generative Text to Video Artifacts</h3>
<ul>
<li><strong>Authors: </strong>Jenna Kang, Maria Silva, Patsorn Sangkloy, Kenneth Chen, Niall Williams, Qi Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08818">https://arxiv.org/abs/2509.08818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08818">https://arxiv.org/pdf/2509.08818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08818]] GeneVA: A Dataset of Human Annotations for Generative Text to Video Artifacts(https://arxiv.org/abs/2509.08818)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recent advances in probabilistic generative models have extended capabilities from static image synthesis to text-driven video generation. However, the inherent randomness of their generation process can lead to unpredictable artifacts, such as impossible physics and temporal inconsistency. Progress in addressing these challenges requires systematic benchmarks, yet existing datasets primarily focus on generative images due to the unique spatio-temporal complexities of videos. To bridge this gap, we introduce GeneVA, a large-scale artifact dataset with rich human annotations that focuses on spatio-temporal artifacts in videos generated from natural text prompts. We hope GeneVA can enable and assist critical applications, such as benchmarking model performance and improving generative video quality.</li>
</ul>

<h3>Title: A Survey of TinyML Applications in Beekeeping for Hive Monitoring and Management</h3>
<ul>
<li><strong>Authors: </strong>Willy Sucipto, Jianlong Zhou, Ray Seung Min Kwon, Fang Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08822">https://arxiv.org/abs/2509.08822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08822">https://arxiv.org/pdf/2509.08822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08822]] A Survey of TinyML Applications in Beekeeping for Hive Monitoring and Management(https://arxiv.org/abs/2509.08822)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Honey bee colonies are essential for global food security and ecosystem stability, yet they face escalating threats from pests, diseases, and environmental stressors. Traditional hive inspections are labor-intensive and disruptive, while cloud-based monitoring solutions remain impractical for remote or resource-limited apiaries. Recent advances in Internet of Things (IoT) and Tiny Machine Learning (TinyML) enable low-power, real-time monitoring directly on edge devices, offering scalable and non-invasive alternatives. This survey synthesizes current innovations at the intersection of TinyML and apiculture, organized around four key functional areas: monitoring hive conditions, recognizing bee behaviors, detecting pests and diseases, and forecasting swarming events. We further examine supporting resources, including publicly available datasets, lightweight model architectures optimized for embedded deployment, and benchmarking strategies tailored to field constraints. Critical limitations such as data scarcity, generalization challenges, and deployment barriers in off-grid environments are highlighted, alongside emerging opportunities in ultra-efficient inference pipelines, adaptive edge learning, and dataset standardization. By consolidating research and engineering practices, this work provides a foundation for scalable, AI-driven, and ecologically informed monitoring systems to support sustainable pollinator management.</li>
</ul>

<h3>Title: Building High-Quality Datasets for Portuguese LLMs: From Common Crawl Snapshots to Industrial-Grade Corpora</h3>
<ul>
<li><strong>Authors: </strong>Thales Sales Almeida, Rodrigo Nogueira, Helio Pedrini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08824">https://arxiv.org/abs/2509.08824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08824">https://arxiv.org/pdf/2509.08824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08824]] Building High-Quality Datasets for Portuguese LLMs: From Common Crawl Snapshots to Industrial-Grade Corpora(https://arxiv.org/abs/2509.08824)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The performance of large language models (LLMs) is deeply influenced by the quality and composition of their training data. While much of the existing work has centered on English, there remains a gap in understanding how to construct effective training corpora for other languages. We explore scalable methods for building web-based corpora for LLMs. We apply them to build a new 120B token corpus in Portuguese that achieves competitive results to an industrial-grade corpus. Using a continual pretraining setup, we study how different data selection and preprocessing strategies affect LLM performance when transitioning a model originally trained in English to another language. Our findings demonstrate the value of language-specific filtering pipelines, including classifiers for education, science, technology, engineering, and mathematics (STEM), as well as toxic content. We show that adapting a model to the target language leads to performance improvements, reinforcing the importance of high-quality, language-specific data. While our case study focuses on Portuguese, our methods are applicable to other languages, offering insights for multilingual LLM development.</li>
</ul>

<h3>Title: Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation</h3>
<ul>
<li><strong>Authors: </strong>Joachim Baumann, Paul Röttger, Aleksandra Urman, Albert Wendsjö, Flor Miriam Plaza-del-Arco, Johannes B. Gruber, Dirk Hovy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08825">https://arxiv.org/abs/2509.08825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08825">https://arxiv.org/pdf/2509.08825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08825]] Large Language Model Hacking: Quantifying the Hidden Risks of Using LLMs for Text Annotation(https://arxiv.org/abs/2509.08825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are rapidly transforming social science research by enabling the automation of labor-intensive tasks like data annotation and text analysis. However, LLM outputs vary significantly depending on the implementation choices made by researchers (e.g., model selection, prompting strategy, or temperature settings). Such variation can introduce systematic biases and random errors, which propagate to downstream analyses and cause Type I, Type II, Type S, or Type M errors. We call this LLM hacking. We quantify the risk of LLM hacking by replicating 37 data annotation tasks from 21 published social science research studies with 18 different models. Analyzing 13 million LLM labels, we test 2,361 realistic hypotheses to measure how plausible researcher choices affect statistical conclusions. We find incorrect conclusions based on LLM-annotated data in approximately one in three hypotheses for state-of-the-art models, and in half the hypotheses for small language models. While our findings show that higher task performance and better general model capabilities reduce LLM hacking risk, even highly accurate models do not completely eliminate it. The risk of LLM hacking decreases as effect sizes increase, indicating the need for more rigorous verification of findings near significance thresholds. Our extensive analysis of LLM hacking mitigation techniques emphasizes the importance of human annotations in reducing false positive findings and improving model selection. Surprisingly, common regression estimator correction techniques are largely ineffective in reducing LLM hacking risk, as they heavily trade off Type I vs. Type II errors. Beyond accidental errors, we find that intentional LLM hacking is unacceptably simple. With few LLMs and just a handful of prompt paraphrases, anything can be presented as statistically significant.</li>
</ul>

<h3>Title: RewardDance: Reward Scaling in Visual Generation</h3>
<ul>
<li><strong>Authors: </strong>Jie Wu, Yu Gao, Zilyu Ye, Ming Li, Liang Li, Hanzhong Guo, Jie Liu, Zeyue Xue, Xiaoxia Hou, Wei Liu, Yan Zeng, Weilin Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08826">https://arxiv.org/abs/2509.08826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08826">https://arxiv.org/pdf/2509.08826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08826]] RewardDance: Reward Scaling in Visual Generation(https://arxiv.org/abs/2509.08826)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Reward Models (RMs) are critical for improving generation models via Reinforcement Learning (RL), yet the RM scaling paradigm in visual generation remains largely unexplored. It primarily due to fundamental limitations in existing approaches: CLIP-based RMs suffer from architectural and input modality constraints, while prevalent Bradley-Terry losses are fundamentally misaligned with the next-token prediction mechanism of Vision-Language Models (VLMs), hindering effective scaling. More critically, the RLHF optimization process is plagued by Reward Hacking issue, where models exploit flaws in the reward signal without improving true quality. To address these challenges, we introduce RewardDance, a scalable reward modeling framework that overcomes these barriers through a novel generative reward paradigm. By reformulating the reward score as the model's probability of predicting a "yes" token, indicating that the generated image outperforms a reference image according to specific criteria, RewardDance intrinsically aligns reward objectives with VLM architectures. This alignment unlocks scaling across two dimensions: (1) Model Scaling: Systematic scaling of RMs up to 26 billion parameters; (2) Context Scaling: Integration of task-specific instructions, reference examples, and chain-of-thought (CoT) reasoning. Extensive experiments demonstrate that RewardDance significantly surpasses state-of-the-art methods in text-to-image, text-to-video, and image-to-video generation. Crucially, we resolve the persistent challenge of "reward hacking": Our large-scale RMs exhibit and maintain high reward variance during RL fine-tuning, proving their resistance to hacking and ability to produce diverse, high-quality outputs. It greatly relieves the mode collapse problem that plagues smaller models.</li>
</ul>

<h3>Title: A Survey of Reinforcement Learning for Large Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Kaiyan Zhang, Yuxin Zuo, Bingxiang He, Youbang Sun, Runze Liu, Che Jiang, Yuchen Fan, Kai Tian, Guoli Jia, Pengfei Li, Yu Fu, Xingtai Lv, Yuchen Zhang, Sihang Zeng, Shang Qu, Haozhan Li, Shijie Wang, Yuru Wang, Xinwei Long, Fangfu Liu, Xiang Xu, Jiaze Ma, Xuekai Zhu, Ermo Hua, Yihao Liu, Zonglin Li, Huayu Chen, Xiaoye Qu, Yafu Li, Weize Chen, Zhenzhao Yuan, Junqi Gao, Dong Li, Zhiyuan Ma, Ganqu Cui, Zhiyuan Liu, Biqing Qi, Ning Ding, Bowen Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.08827">https://arxiv.org/abs/2509.08827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.08827">https://arxiv.org/pdf/2509.08827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.08827]] A Survey of Reinforcement Learning for Large Reasoning Models(https://arxiv.org/abs/2509.08827)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we survey recent advances in Reinforcement Learning (RL) for reasoning with Large Language Models (LLMs). RL has achieved remarkable success in advancing the frontier of LLM capabilities, particularly in addressing complex logical tasks such as mathematics and coding. As a result, RL has emerged as a foundational methodology for transforming LLMs into LRMs. With the rapid progress of the field, further scaling of RL for LRMs now faces foundational challenges not only in computational resources but also in algorithm design, training data, and infrastructure. To this end, it is timely to revisit the development of this domain, reassess its trajectory, and explore strategies to enhance the scalability of RL toward Artificial SuperIntelligence (ASI). In particular, we examine research applying RL to LLMs and LRMs for reasoning abilities, especially since the release of DeepSeek-R1, including foundational components, core problems, training resources, and downstream applications, to identify future opportunities and directions for this rapidly evolving area. We hope this review will promote future research on RL for broader reasoning models. Github: this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
