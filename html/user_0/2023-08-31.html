<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Grandma Karl is 27 years old -- research agenda for pseudonymization of research data. (arXiv:2308.16109v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16109">http://arxiv.org/abs/2308.16109</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16109]] Grandma Karl is 27 years old -- research agenda for pseudonymization of research data(http://arxiv.org/abs/2308.16109)</code></li>
<li>Summary: <p>Accessibility of research data is critical for advances in many research
fields, but textual data often cannot be shared due to the personal and
sensitive information which it contains, e.g names or political opinions.
General Data Protection Regulation (GDPR) suggests pseudonymization as a
solution to secure open access to research data, but we need to learn more
about pseudonymization as an approach before adopting it for manipulation of
research data. This paper outlines a research agenda within pseudonymization,
namely need of studies into the effects of pseudonymization on unstructured
data in relation to e.g. readability and language assessment, as well as the
effectiveness of pseudonymization as a way of protecting writer identity, while
also exploring different ways of developing context-sensitive algorithms for
detection, labelling and replacement of personal information in unstructured
data. The recently granted project on pseudonymization Grandma Karl is 27 years
old addresses exactly those challenges.
</p></li>
</ul>

<h3>Title: Cryptanalysis of a Cayley Hash Function Based on Affine Maps. (arXiv:2308.15765v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15765">http://arxiv.org/abs/2308.15765</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15765]] Cryptanalysis of a Cayley Hash Function Based on Affine Maps(http://arxiv.org/abs/2308.15765)</code></li>
<li>Summary: <p>Cayley hash functions are cryptographic hashes constructed from Cayley graphs
of groups. The hash function proposed by Shpilrain and Sosnovski (2016), based
on linear functions over a finite field, was proven insecure. This paper shows
that the proposal by Ghaffari and Mostaghim (2018) that uses the Shpilrain and
Sosnovski's hash in its construction is also insecure. We demonstrate its
security vulnerability by constructing collisions.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review. (arXiv:2308.15736v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15736">http://arxiv.org/abs/2308.15736</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15736]] Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review(http://arxiv.org/abs/2308.15736)</code></li>
<li>Summary: <p>The machine learning (ML) sees an increasing prevalence of being used in the
internet-of-things enabled smart grid. However, the trustworthiness of ML is a
severe issue that must be addressed to accommodate the trend of ML-based smart
grid applications (MLsgAPPs). The adversarial distortion injected into the
power signal will greatly affect the system's normal control and operation.
Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs
applied in the context of safety-critical power systems. In this paper, we
provide a comprehensive review of the recent progress in designing attack and
defense methods for MLsgAPPs. Unlike the traditional survey about ML security,
this is the first review work about the security of MLsgAPPs that focuses on
the characteristics of power systems. The survey is organized from the aspects
of adversarial assumptions, targeted applications, evaluation metrics,
defending approaches, physics-related constraints, and applied datasets. We
also highlight future directions on this topic to encourage more researchers to
conduct further research on adversarial attacks and defending approaches for
MLsgAPPs.
</p></li>
</ul>

<h3>Title: Exploring Cybercriminal Activities, Behaviors and Profiles. (arXiv:2308.15948v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15948">http://arxiv.org/abs/2308.15948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15948]] Exploring Cybercriminal Activities, Behaviors and Profiles(http://arxiv.org/abs/2308.15948)</code></li>
<li>Summary: <p>While modern society benefits from a range of technological advancements, it
also is exposed to an ever-increasing set of cybersecurity threats. These
affect all areas of life including business, government, and individuals. To
complement technology solutions to this problem, it is crucial to understand
more about cybercriminal perpetrators themselves, their use of technology,
psychological aspects, and profiles. This is a topic that has received little
socio-technical research emphasis in the technology community, has few concrete
research findings, and is thus a prime area for development. The aim of this
article is to explore cybercriminal activities and behavior from a psychology
and human aspects perspective, through a series of notable case studies. We
examine motivations, psychological and other interdisciplinary concepts as they
may impact/influence cybercriminal activities. We expect this paper to be of
value and particularly insightful for those studying technology, psychology,
and criminology, with a focus on cybersecurity and cybercrime.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Introducing Language Guidance in Prompt-based Continual Learning. (arXiv:2308.15827v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15827">http://arxiv.org/abs/2308.15827</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15827]] Introducing Language Guidance in Prompt-based Continual Learning(http://arxiv.org/abs/2308.15827)</code></li>
<li>Summary: <p>Continual Learning aims to learn a single model on a sequence of tasks
without having access to data from previous tasks. The biggest challenge in the
domain still remains catastrophic forgetting: a loss in performance on seen
classes of earlier tasks. Some existing methods rely on an expensive replay
buffer to store a chunk of data from previous tasks. This, while promising,
becomes expensive when the number of tasks becomes large or data can not be
stored for privacy reasons. As an alternative, prompt-based methods have been
proposed that store the task information in a learnable prompt pool. This
prompt pool instructs a frozen image encoder on how to solve each task. While
the model faces a disjoint set of classes in each task in this setting, we
argue that these classes can be encoded to the same embedding space of a
pre-trained language encoder. In this work, we propose Language Guidance for
Prompt-based Continual Learning (LGCL) as a plug-in for prompt-based methods.
LGCL is model agnostic and introduces language guidance at the task level in
the prompt pool and at the class level on the output feature of the vision
encoder. We show with extensive experimentation that LGCL consistently improves
the performance of prompt-based continual learning methods to set a new
state-of-the art. LGCL achieves these performance improvements without needing
any additional learnable parameters.
</p></li>
</ul>

<h3>Title: Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation. (arXiv:2308.15709v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15709">http://arxiv.org/abs/2308.15709</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15709]] Threshold KNN-Shapley: A Linear-Time and Privacy-Friendly Approach to Data Valuation(http://arxiv.org/abs/2308.15709)</code></li>
<li>Summary: <p>Data valuation, a critical aspect of data-centric ML research, aims to
quantify the usefulness of individual data sources in training machine learning
(ML) models. However, data valuation faces significant yet frequently
overlooked privacy challenges despite its importance. This paper studies these
challenges with a focus on KNN-Shapley, one of the most practical data
valuation methods nowadays. We first emphasize the inherent privacy risks of
KNN-Shapley, and demonstrate the significant technical difficulties in adapting
KNN-Shapley to accommodate differential privacy (DP). To overcome these
challenges, we introduce TKNN-Shapley, a refined variant of KNN-Shapley that is
privacy-friendly, allowing for straightforward modifications to incorporate DP
guarantee (DP-TKNN-Shapley). We show that DP-TKNN-Shapley has several
advantages and offers a superior privacy-utility tradeoff compared to naively
privatized KNN-Shapley in discerning data quality. Moreover, even non-private
TKNN-Shapley achieves comparable performance as KNN-Shapley. Overall, our
findings suggest that TKNN-Shapley is a promising alternative to KNN-Shapley,
particularly for real-world applications involving sensitive data.
</p></li>
</ul>

<h3>Title: Split Without a Leak: Reducing Privacy Leakage in Split Learning. (arXiv:2308.15783v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15783">http://arxiv.org/abs/2308.15783</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15783]] Split Without a Leak: Reducing Privacy Leakage in Split Learning(http://arxiv.org/abs/2308.15783)</code></li>
<li>Summary: <p>The popularity of Deep Learning (DL) makes the privacy of sensitive data more
imperative than ever. As a result, various privacy-preserving techniques have
been implemented to preserve user data privacy in DL. Among various
privacy-preserving techniques, collaborative learning techniques, such as Split
Learning (SL) have been utilized to accelerate the learning and prediction
process. Initially, SL was considered a promising approach to data privacy.
However, subsequent research has demonstrated that SL is susceptible to many
types of attacks and, therefore, it cannot serve as a privacy-preserving
technique. Meanwhile, countermeasures using a combination of SL and encryption
have also been introduced to achieve privacy-preserving deep learning. In this
work, we propose a hybrid approach using SL and Homomorphic Encryption (HE).
The idea behind it is that the client encrypts the activation map (the output
of the split layer between the client and the server) before sending it to the
server. Hence, during both forward and backward propagation, the server cannot
reconstruct the client's input data from the intermediate activation map. This
improvement is important as it reduces privacy leakage compared to other
SL-based works, where the server can gain valuable information about the
client's input. In addition, on the MIT-BIH dataset, our proposed hybrid
approach using SL and HE yields faster training time (about 6 times) and
significantly reduced communication overhead (almost 160 times) compared to
other HE-based approaches, thereby offering improved privacy protection for
sensitive data in DL.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: How does post-quantum cryptography affect Central Bank Digital Currency?. (arXiv:2308.15787v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15787">http://arxiv.org/abs/2308.15787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15787]] How does post-quantum cryptography affect Central Bank Digital Currency?(http://arxiv.org/abs/2308.15787)</code></li>
<li>Summary: <p>Central Bank Digital Currency (CBDC) is an emerging trend in digital
payments, with the vast majority of central banks around the world researching,
piloting, or even operating a digital version of cash. While design choices
differ broadly, such as accounts vs. tokens, the wallets are generally
protected through cryptographic algorithms that safeguard against double
spending and ensure non-repudiation. But with the advent of quantum computing,
these algorithms are threatened by new attack vectors. To better understand
those threats, we conducted a study of typical assets in a CBDC system,
describe which ones are most amenable to post-quantum cryptography, and propose
an upgrade strategy.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Intriguing Properties of Diffusion Models: A Large-Scale Dataset for Evaluating Natural Attack Capability in Text-to-Image Generative Models. (arXiv:2308.15692v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15692">http://arxiv.org/abs/2308.15692</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15692]] Intriguing Properties of Diffusion Models: A Large-Scale Dataset for Evaluating Natural Attack Capability in Text-to-Image Generative Models(http://arxiv.org/abs/2308.15692)</code></li>
<li>Summary: <p>Denoising probabilistic diffusion models have shown breakthrough performance
that can generate more photo-realistic images or human-level illustrations than
the prior models such as GANs. This high image-generation capability has
stimulated the creation of many downstream applications in various areas.
However, we find that this technology is indeed a double-edged sword: We
identify a new type of attack, called the Natural Denoising Diffusion (NDD)
attack based on the finding that state-of-the-art deep neural network (DNN)
models still hold their prediction even if we intentionally remove their robust
features, which are essential to the human visual system (HVS), by text
prompts. The NDD attack can generate low-cost, model-agnostic, and
transferrable adversarial attacks by exploiting the natural attack capability
in diffusion models. Motivated by the finding, we construct a large-scale
dataset, Natural Denoising Diffusion Attack (NDDA) dataset, to systematically
evaluate the risk of the natural attack capability of diffusion models with
state-of-the-art text-to-image diffusion models. We evaluate the natural attack
capability by answering 6 research questions. Through a user study to confirm
the validity of the NDD attack, we find that the NDD attack can achieve an 88%
detection rate while being stealthy to 93% of human subjects. We also find that
the non-robust features embedded by diffusion models contribute to the natural
attack capability. To confirm the model-agnostic and transferrable attack
capability, we perform the NDD attack against an AD vehicle and find that 73%
of the physically printed attacks can be detected as a stop sign. We hope that
our study and dataset can help our community to be aware of the risk of
diffusion models and facilitate further research toward robust DNN models.
</p></li>
</ul>

<h3>Title: Conti Inc.: Understanding the Internal Discussions of a large Ransomware-as-a-Service Operator with Machine Learning. (arXiv:2308.16061v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16061">http://arxiv.org/abs/2308.16061</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16061]] Conti Inc(http://arxiv.org/abs/2308.16061)</code></li>
<li>Summary: <p>Ransomware-as-a-service (RaaS) is increasing the scale and complexity of
ransomware attacks. Understanding the internal operations behind RaaS has been
a challenge due to the illegality of such activities. The recent chat leak of
the Conti RaaS operator, one of the most infamous ransomware operators on the
international scene, offers a key opportunity to better understand the inner
workings of such organizations. This paper analyzes the main topic discussions
in the Conti chat leak using machine learning techniques such as Natural
Language Processing (NLP) and Latent Dirichlet Allocation (LDA), as well as
visualization strategies. Five discussion topics are found: 1) Business, 2)
Technical, 3) Internal tasking/Management, 4) Malware, and 5) Customer
Service/Problem Solving. Moreover, the distribution of topics among Conti
members shows that only 4% of individuals have specialized discussions while
almost all individuals (96%) are all-rounders, meaning that their discussions
revolve around the five topics. The results also indicate that a significant
proportion of Conti discussions are non-tech related. This study thus
highlights that running such large RaaS operations requires a workforce skilled
beyond technical abilities, with individuals involved in various tasks, from
management to customer service or problem solving. The discussion topics also
show that the organization behind the Conti RaaS oper5086933ator shares
similarities with a large firm. We conclude that, although RaaS represents an
example of specialization in the cybercrime industry, only a few members are
specialized in one topic, while the rest runs and coordinates the RaaS
operation.
</p></li>
</ul>

<h3>Title: On the Steganographic Capacity of Selected Learning Models. (arXiv:2308.15502v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15502">http://arxiv.org/abs/2308.15502</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15502]] On the Steganographic Capacity of Selected Learning Models(http://arxiv.org/abs/2308.15502)</code></li>
<li>Summary: <p>Machine learning and deep learning models are potential vectors for various
attack scenarios. For example, previous research has shown that malware can be
hidden in deep learning models. Hiding information in a learning model can be
viewed as a form of steganography. In this research, we consider the general
question of the steganographic capacity of learning models. Specifically, for a
wide range of models, we determine the number of low-order bits of the trained
parameters that can be overwritten, without adversely affecting model
performance. For each model considered, we graph the accuracy as a function of
the number of low-order bits that have been overwritten, and for selected
models, we also analyze the steganographic capacity of individual layers. The
models that we test include the classic machine learning techniques of Linear
Regression (LR) and Support Vector Machine (SVM); the popular general deep
learning models of Multilayer Perceptron (MLP) and Convolutional Neural Network
(CNN); the highly-successful Recurrent Neural Network (RNN) architecture of
Long Short-Term Memory (LSTM); the pre-trained transfer learning-based models
VGG16, DenseNet121, InceptionV3, and Xception; and, finally, an Auxiliary
Classifier Generative Adversarial Network (ACGAN). In all cases, we find that a
majority of the bits of each trained parameter can be overwritten before the
accuracy degrades. Of the models tested, the steganographic capacity ranges
from 7.04 KB for our LR experiments, to 44.74 MB for InceptionV3. We discuss
the implications of our results and consider possible avenues for further
research.
</p></li>
</ul>

<h3>Title: Everything Perturbed All at Once: Enabling Differentiable Graph Attacks. (arXiv:2308.15614v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15614">http://arxiv.org/abs/2308.15614</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15614]] Everything Perturbed All at Once: Enabling Differentiable Graph Attacks(http://arxiv.org/abs/2308.15614)</code></li>
<li>Summary: <p>As powerful tools for representation learning on graphs, graph neural
networks (GNNs) have played an important role in applications including social
networks, recommendation systems, and online web services. However, GNNs have
been shown to be vulnerable to adversarial attacks, which can significantly
degrade their effectiveness. Recent state-of-the-art approaches in adversarial
attacks rely on gradient-based meta-learning to selectively perturb a single
edge with the highest attack score until they reach the budget constraint.
While effective in identifying vulnerable links, these methods are plagued by
high computational costs. By leveraging continuous relaxation and
parameterization of the graph structure, we propose a novel attack method
called Differentiable Graph Attack (DGA) to efficiently generate effective
attacks and meanwhile eliminate the need for costly retraining. Compared to the
state-of-the-art, DGA achieves nearly equivalent attack performance with 6
times less training time and 11 times smaller GPU memory footprint on different
benchmark datasets. Additionally, we provide extensive experimental analyses of
the transferability of the DGA among different graph models, as well as its
robustness against widely-used defense mechanisms.
</p></li>
</ul>

<h3>Title: Adaptive Attack Detection in Text Classification: Leveraging Space Exploration Features for Text Sentiment Classification. (arXiv:2308.15663v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15663">http://arxiv.org/abs/2308.15663</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15663]] Adaptive Attack Detection in Text Classification: Leveraging Space Exploration Features for Text Sentiment Classification(http://arxiv.org/abs/2308.15663)</code></li>
<li>Summary: <p>Adversarial example detection plays a vital role in adaptive cyber defense,
especially in the face of rapidly evolving attacks. In adaptive cyber defense,
the nature and characteristics of attacks continuously change, making it
crucial to have robust mechanisms in place to detect and counter these threats
effectively. By incorporating adversarial example detection techniques,
adaptive cyber defense systems can enhance their ability to identify and
mitigate attacks that attempt to exploit vulnerabilities in machine learning
models or other systems. Adversarial examples are inputs that are crafted by
applying intentional perturbations to natural inputs that result in incorrect
classification. In this paper, we propose a novel approach that leverages the
power of BERT (Bidirectional Encoder Representations from Transformers) and
introduces the concept of Space Exploration Features. We utilize the feature
vectors obtained from the BERT model's output to capture a new representation
of feature space to improve the density estimation method.
</p></li>
</ul>

<h3>Title: MDTD: A Multi Domain Trojan Detector for Deep Neural Networks. (arXiv:2308.15673v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15673">http://arxiv.org/abs/2308.15673</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15673]] MDTD: A Multi Domain Trojan Detector for Deep Neural Networks(http://arxiv.org/abs/2308.15673)</code></li>
<li>Summary: <p>Machine learning models that use deep neural networks (DNNs) are vulnerable
to backdoor attacks. An adversary carrying out a backdoor attack embeds a
predefined perturbation called a trigger into a small subset of input samples
and trains the DNN such that the presence of the trigger in the input results
in an adversary-desired output class. Such adversarial retraining however needs
to ensure that outputs for inputs without the trigger remain unaffected and
provide high classification accuracy on clean samples. In this paper, we
propose MDTD, a Multi-Domain Trojan Detector for DNNs, which detects inputs
containing a Trojan trigger at testing time. MDTD does not require knowledge of
trigger-embedding strategy of the attacker and can be applied to a pre-trained
DNN model with image, audio, or graph-based inputs. MDTD leverages an insight
that input samples containing a Trojan trigger are located relatively farther
away from a decision boundary than clean samples. MDTD estimates the distance
to a decision boundary using adversarial learning methods and uses this
distance to infer whether a test-time input sample is Trojaned or not. We
evaluate MDTD against state-of-the-art Trojan detection methods across five
widely used image-based datasets: CIFAR100, CIFAR10, GTSRB, SVHN, and
Flowers102; four graph-based datasets: AIDS, WinMal, Toxicant, and COLLAB; and
the SpeechCommand audio dataset. MDTD effectively identifies samples that
contain different types of Trojan triggers. We evaluate MDTD against adaptive
attacks where an adversary trains a robust DNN to increase (decrease) distance
of benign (Trojan) inputs from a decision boundary.
</p></li>
</ul>

<h3>Title: Predict And Prevent DDOS Attacks Using Machine Learning and Statistical Algorithms. (arXiv:2308.15674v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15674">http://arxiv.org/abs/2308.15674</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15674]] Predict And Prevent DDOS Attacks Using Machine Learning and Statistical Algorithms(http://arxiv.org/abs/2308.15674)</code></li>
<li>Summary: <p>A malicious attempt to exhaust a victim's resources to cause it to crash or
halt its services is known as a distributed denial-of-service (DDoS) attack.
DDOS attacks stop authorized users from accessing specific services available
on the Internet. It targets varying components of a network layer and it is
better to stop into layer 4 (transport layer) of the network before approaching
a higher layer. This study uses several machine learning and statistical models
to detect DDoS attacks from traces of traffic flow and suggests a method to
prevent DDOS attacks. For this purpose, we used logistic regression, CNN,
XGBoost, naive Bayes, AdaBoostClassifier, KNN, and random forest ML algorithms.
In addition, data preprocessing was performed using three methods to identify
the most relevant features. This paper explores the issue of improving the DDOS
attack detection accuracy using the latest dataset named CICDDoS2019, which has
over 50 million records. Because we employed an extensive dataset for this
investigation, our findings are trustworthy and practical. Our target class
(attack class) was imbalanced. Therefore, we used two techniques to deal with
imbalanced data in machine learning. The XGboost machine learning model
provided the best detection accuracy of (99.9999%) after applying the SMOTE
approach to the target class, outperforming recently developed DDoS detection
systems. To the best of our knowledge, no other research has worked on the most
recent dataset with over 50 million records, addresses the statistical
technique to select the most significant feature, has this high accuracy, and
suggests ways to avoid DDOS attackI.
</p></li>
</ul>

<h3>Title: Securing Blockchain Systems: A Novel Collaborative Learning Framework to Detect Attacks in Transactions and Smart Contracts. (arXiv:2308.15804v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15804">http://arxiv.org/abs/2308.15804</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15804]] Securing Blockchain Systems: A Novel Collaborative Learning Framework to Detect Attacks in Transactions and Smart Contracts(http://arxiv.org/abs/2308.15804)</code></li>
<li>Summary: <p>With the escalating prevalence of malicious activities exploiting
vulnerabilities in blockchain systems, there is an urgent requirement for
robust attack detection mechanisms. To address this challenge, this paper
presents a novel collaborative learning framework designed to detect attacks in
blockchain transactions and smart contracts by analyzing transaction features.
Our framework exhibits the capability to classify various types of blockchain
attacks, including intricate attacks at the machine code level (e.g., injecting
malicious codes to withdraw coins from users unlawfully), which typically
necessitate significant time and security expertise to detect. To achieve that,
the proposed framework incorporates a unique tool that transforms transaction
features into visual representations, facilitating efficient analysis and
classification of low-level machine codes. Furthermore, we propose a customized
collaborative learning model to enable real-time detection of diverse attack
types at distributed mining nodes. In order to create a comprehensive dataset,
we deploy a pilot system based on a private Ethereum network and conduct
multiple attack scenarios. To the best of our knowledge, our dataset is the
most comprehensive and diverse collection of transactions and smart contracts
synthesized in a laboratory for cyberattack detection in blockchain systems.
Our framework achieves a detection accuracy of approximately 94\% through
extensive simulations and real-time experiments with a throughput of over 1,100
transactions per second. These compelling results validate the efficacy of our
framework and showcase its adaptability in addressing real-world cyberattack
scenarios.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Classification robustness to common optical aberrations. (arXiv:2308.15499v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15499">http://arxiv.org/abs/2308.15499</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15499]] Classification robustness to common optical aberrations(http://arxiv.org/abs/2308.15499)</code></li>
<li>Summary: <p>Computer vision using deep neural networks (DNNs) has brought about seminal
changes in people's lives. Applications range from automotive, face recognition
in the security industry, to industrial process monitoring. In some cases, DNNs
infer even in safety-critical situations. Therefore, for practical
applications, DNNs have to behave in a robust way to disturbances such as
noise, pixelation, or blur. Blur directly impacts the performance of DNNs,
which are often approximated as a disk-shaped kernel to model defocus. However,
optics suggests that there are different kernel shapes depending on wavelength
and location caused by optical aberrations. In practice, as the optical quality
of a lens decreases, such aberrations increase. This paper proposes
OpticsBench, a benchmark for investigating robustness to realistic, practically
relevant optical blur effects. Each corruption represents an optical aberration
(coma, astigmatism, spherical, trefoil) derived from Zernike Polynomials.
Experiments on ImageNet show that for a variety of different pre-trained DNNs,
the performance varies strongly compared to disk-shaped kernels, indicating the
necessity of considering realistic image degradations. In addition, we show on
ImageNet-100 with OpticsAugment that robustness can be increased by using
optical kernels as data augmentation. Compared to a conventionally trained
ResNeXt50, training with OpticsAugment achieves an average performance gain of
21.7% points on OpticsBench and 6.8% points on 2D common corruptions.
</p></li>
</ul>

<h3>Title: Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning. (arXiv:2308.15575v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15575">http://arxiv.org/abs/2308.15575</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15575]] Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning(http://arxiv.org/abs/2308.15575)</code></li>
<li>Summary: <p>Semi-supervised Learning (SSL) has been proven vulnerable to
out-of-distribution (OOD) samples in realistic large-scale unsupervised
datasets due to over-confident pseudo-labeling OODs as in-distribution (ID). A
key underlying problem is class-wise latent space spreading from closed seen
space to open unseen space, and the bias is further magnified in SSL's
self-training loops. To close the ID distribution set so that OODs are better
rejected for safe SSL, we propose Prototype Fission(PF) to divide class-wise
latent spaces into compact sub-spaces by automatic fine-grained latent space
mining, driven by coarse-grained labels only. Specifically, we form multiple
unique learnable sub-class prototypes for each class, optimized towards both
diversity and consistency. The Diversity Modeling term encourages samples to be
clustered by one of the multiple sub-class prototypes, while the Consistency
Modeling term clusters all samples of the same class to a global prototype.
Instead of "opening set", i.e., modeling OOD distribution, Prototype Fission
"closes set" and makes it hard for OOD samples to fit in sub-class latent
space. Therefore, PF is compatible with existing methods for further
performance gains. Extensive experiments validate the effectiveness of our
method in open-set SSL settings in terms of successfully forming sub-classes,
discriminating OODs from IDs and improving overall accuracy. Codes will be
released.
</p></li>
</ul>

<h3>Title: RACR-MIL: Weakly Supervised Skin Cancer Grading using Rank-Aware Contextual Reasoning on Whole Slide Images. (arXiv:2308.15618v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15618">http://arxiv.org/abs/2308.15618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15618]] RACR-MIL: Weakly Supervised Skin Cancer Grading using Rank-Aware Contextual Reasoning on Whole Slide Images(http://arxiv.org/abs/2308.15618)</code></li>
<li>Summary: <p>Cutaneous squamous cell cancer (cSCC) is the second most common skin cancer
in the US. It is diagnosed by manual multi-class tumor grading using a tissue
whole slide image (WSI), which is subjective and suffers from inter-pathologist
variability. We propose an automated weakly-supervised grading approach for
cSCC WSIs that is trained using WSI-level grade and does not require
fine-grained tumor annotations. The proposed model, RACR-MIL, transforms each
WSI into a bag of tiled patches and leverages attention-based multiple-instance
learning to assign a WSI-level grade. We propose three key innovations to
address general as well as cSCC-specific challenges in tumor grading. First, we
leverage spatial and semantic proximity to define a WSI graph that encodes both
local and non-local dependencies between tumor regions and leverage graph
attention convolution to derive contextual patch features. Second, we introduce
a novel ordinal ranking constraint on the patch attention network to ensure
that higher-grade tumor regions are assigned higher attention. Third, we use
tumor depth as an auxiliary task to improve grade classification in a multitask
learning framework. RACR-MIL achieves 2-9% improvement in grade classification
over existing weakly-supervised approaches on a dataset of 718 cSCC tissue
images and localizes the tumor better. The model achieves 5-20% higher accuracy
in difficult-to-classify high-risk grade classes and is robust to class
imbalance.
</p></li>
</ul>

<h3>Title: Multimodal Foundation Models For Echocardiogram Interpretation. (arXiv:2308.15670v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15670">http://arxiv.org/abs/2308.15670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15670]] Multimodal Foundation Models For Echocardiogram Interpretation(http://arxiv.org/abs/2308.15670)</code></li>
<li>Summary: <p>Multimodal deep learning foundation models can learn the relationship between
images and text. In the context of medical imaging, mapping images to language
concepts reflects the clinical task of diagnostic image interpretation, however
current general-purpose foundation models do not perform well in this context
because their training corpus have limited medical text and images. To address
this challenge and account for the range of cardiac physiology, we leverage
1,032,975 cardiac ultrasound videos and corresponding expert interpretations to
develop EchoCLIP, a multimodal foundation model for echocardiography. EchoCLIP
displays strong zero-shot (not explicitly trained) performance in cardiac
function assessment (external validation left ventricular ejection fraction
mean absolute error (MAE) of 7.1%) and identification of implanted intracardiac
devices (areas under the curve (AUC) between 0.84 and 0.98 for pacemakers and
artificial heart valves). We also developed a long-context variant (EchoCLIP-R)
with a custom echocardiography report text tokenizer which can accurately
identify unique patients across multiple videos (AUC of 0.86), identify
clinical changes such as orthotopic heart transplants (AUC of 0.79) or cardiac
surgery (AUC 0.77), and enable robust image-to-text search (mean cross-modal
retrieval rank in the top 1% of candidate text reports). These emergent
capabilities can be used for preliminary assessment and summarization of
echocardiographic findings.
</p></li>
</ul>

<h3>Title: Improving Underwater Visual Tracking With a Large Scale Dataset and Image Enhancement. (arXiv:2308.15816v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15816">http://arxiv.org/abs/2308.15816</a></li>
<li>Code URL: https://github.com/basitalawode/uwvot400</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15816]] Improving Underwater Visual Tracking With a Large Scale Dataset and Image Enhancement(http://arxiv.org/abs/2308.15816)</code></li>
<li>Summary: <p>This paper presents a new dataset and general tracker enhancement method for
Underwater Visual Object Tracking (UVOT). Despite its significance, underwater
tracking has remained unexplored due to data inaccessibility. It poses distinct
challenges; the underwater environment exhibits non-uniform lighting
conditions, low visibility, lack of sharpness, low contrast, camouflage, and
reflections from suspended particles. Performance of traditional tracking
methods designed primarily for terrestrial or open-air scenarios drops in such
conditions. We address the problem by proposing a novel underwater image
enhancement algorithm designed specifically to boost tracking quality. The
method has resulted in a significant performance improvement, of up to 5.0%
AUC, of state-of-the-art (SOTA) visual trackers. To develop robust and accurate
UVOT methods, large-scale datasets are required. To this end, we introduce a
large-scale UVOT benchmark dataset consisting of 400 video segments and 275,000
manually annotated frames enabling underwater training and evaluation of deep
trackers. The videos are labelled with several underwater-specific tracking
attributes including watercolor variation, target distractors, camouflage,
target relative size, and low visibility conditions. The UVOT400 dataset,
tracking results, and the code are publicly available on:
https://github.com/BasitAlawode/UWVOT400.
</p></li>
</ul>

<h3>Title: Utilizing Task-Generic Motion Prior to Recover Full-Body Motion from Very Sparse Signals. (arXiv:2308.15839v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15839">http://arxiv.org/abs/2308.15839</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15839]] Utilizing Task-Generic Motion Prior to Recover Full-Body Motion from Very Sparse Signals(http://arxiv.org/abs/2308.15839)</code></li>
<li>Summary: <p>The most popular type of devices used to track a user's posture in a virtual
reality experience consists of a head-mounted display and two controllers held
in both hands. However, due to the limited number of tracking sensors (three in
total), faithfully recovering the user in full-body is challenging, limiting
the potential for interactions among simulated user avatars within the virtual
world. Therefore, recent studies have attempted to reconstruct full-body poses
using neural networks that utilize previously learned human poses or accept a
series of past poses over a short period. In this paper, we propose a method
that utilizes information from a neural motion prior to improve the accuracy of
reconstructed user's motions. Our approach aims to reconstruct user's full-body
poses by predicting the latent representation of the user's overall motion from
limited input signals and integrating this information with tracking sensor
inputs. This is based on the premise that the ultimate goal of pose
reconstruction is to reconstruct the motion, which is a series of poses. Our
results show that this integration enables more accurate reconstruction of the
user's full-body motion, particularly enhancing the robustness of lower body
motion reconstruction from impoverished signals. Web:
https://https://mjsh34.github.io/mp-sspe/
</p></li>
</ul>

<h3>Title: CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric. (arXiv:2308.16126v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16126">http://arxiv.org/abs/2308.16126</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16126]] CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric(http://arxiv.org/abs/2308.16126)</code></li>
<li>Summary: <p>Detecting visually similar images is a particularly useful attribute to look
to when calculating product recommendations. Embedding similarity, which
utilizes pre-trained computer vision models to extract high-level image
features, has demonstrated remarkable efficacy in identifying images with
similar compositions. However, there is a lack of methods for evaluating the
embeddings generated by these models, as conventional loss and performance
metrics do not adequately capture their performance in image similarity search
tasks.
</p>
<p>In this paper, we evaluate the viability of the image embeddings from
numerous pre-trained computer vision models using a novel approach named
CorrEmbed. Our approach computes the correlation between distances in image
embeddings and distances in human-generated tag vectors. We extensively
evaluate numerous pre-trained Torchvision models using this metric, revealing
an intuitive relationship of linear scaling between ImageNet1k accuracy scores
and tag-correlation scores. Importantly, our method also identifies deviations
from this pattern, providing insights into how different models capture
high-level image features.
</p>
<p>By offering a robust performance evaluation of these pre-trained models,
CorrEmbed serves as a valuable tool for researchers and practitioners seeking
to develop effective, data-driven approaches to similar item recommendations in
fashion retail.
</p></li>
</ul>

<h3>Title: Occ$^2$Net: Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions. (arXiv:2308.16160v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16160">http://arxiv.org/abs/2308.16160</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16160]] Occ$^2$Net: Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions(http://arxiv.org/abs/2308.16160)</code></li>
<li>Summary: <p>Image matching is a fundamental and critical task in various visual
applications, such as Simultaneous Localization and Mapping (SLAM) and image
retrieval, which require accurate pose estimation. However, most existing
methods ignore the occlusion relations between objects caused by camera motion
and scene structure. In this paper, we propose Occ$^2$Net, a novel image
matching method that models occlusion relations using 3D occupancy and infers
matching points in occluded regions. Thanks to the inductive bias encoded in
the Occupancy Estimation (OE) module, it greatly simplifies bootstrapping of a
multi-view consistent 3D representation that can then integrate information
from multiple views. Together with an Occlusion-Aware (OA) module, it
incorporates attention layers and rotation alignment to enable matching between
occluded and visible points. We evaluate our method on both real-world and
simulated datasets and demonstrate its superior performance over
state-of-the-art methods on several metrics, especially in occlusion scenarios.
</p></li>
</ul>

<h3>Title: Adversarial Style Transfer for Robust Policy Optimization in Deep Reinforcement Learning. (arXiv:2308.15550v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15550">http://arxiv.org/abs/2308.15550</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15550]] Adversarial Style Transfer for Robust Policy Optimization in Deep Reinforcement Learning(http://arxiv.org/abs/2308.15550)</code></li>
<li>Summary: <p>This paper proposes an algorithm that aims to improve generalization for
reinforcement learning agents by removing overfitting to confounding features.
Our approach consists of a max-min game theoretic objective. A generator
transfers the style of observation during reinforcement learning. An additional
goal of the generator is to perturb the observation, which maximizes the
agent's probability of taking a different action. In contrast, a policy network
updates its parameters to minimize the effect of such perturbations, thus
staying robust while maximizing the expected future reward. Based on this
setup, we propose a practical deep reinforcement learning algorithm,
Adversarial Robust Policy Optimization (ARPO), to find a robust policy that
generalizes to unseen environments. We evaluate our approach on Procgen and
Distracting Control Suite for generalization and sample efficiency.
Empirically, ARPO shows improved performance compared to a few baseline
algorithms, including data augmentation.
</p></li>
</ul>

<h3>Title: Measurement Tampering Detection Benchmark. (arXiv:2308.15605v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15605">http://arxiv.org/abs/2308.15605</a></li>
<li>Code URL: https://github.com/redwoodresearch/measurement-tampering</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15605]] Measurement Tampering Detection Benchmark(http://arxiv.org/abs/2308.15605)</code></li>
<li>Summary: <p>When training powerful AI systems to perform complex tasks, it may be
challenging to provide training signals which are robust to optimization. One
concern is measurement tampering, where the AI system manipulates multiple
measurements to create the illusion of good results instead of achieving the
desired outcome. In this work, we build four new text-based datasets to
evaluate measurement tampering detection techniques on large language models.
Concretely, given sets of text inputs and measurements aimed at determining if
some outcome occurred, as well as a base model able to accurately predict
measurements, the goal is to determine if examples where all measurements
indicate the outcome actually had the outcome occur, or if this was caused by
measurement tampering. We demonstrate techniques that outperform simple
baselines on most datasets, but don't achieve maximum performance. We believe
there is significant room for improvement for both techniques and datasets, and
we are excited for future work tackling measurement tampering.
</p></li>
</ul>

<h3>Title: Hyperbolic Convolutional Neural Networks. (arXiv:2308.15639v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15639">http://arxiv.org/abs/2308.15639</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15639]] Hyperbolic Convolutional Neural Networks(http://arxiv.org/abs/2308.15639)</code></li>
<li>Summary: <p>Deep Learning is mostly responsible for the surge of interest in Artificial
Intelligence in the last decade. So far, deep learning researchers have been
particularly successful in the domain of image processing, where Convolutional
Neural Networks are used. Although excelling at image classification,
Convolutional Neural Networks are quite naive in that no inductive bias is set
on the embedding space for images. Similar flaws are also exhibited by another
type of Convolutional Networks - Graph Convolutional Neural Networks. However,
using non-Euclidean space for embedding data might result in more robust and
explainable models. One example of such a non-Euclidean space is hyperbolic
space. Hyperbolic spaces are particularly useful due to their ability to fit
more data in a low-dimensional space and tree-likeliness properties. These
attractive properties have been previously used in multiple papers which
indicated that they are beneficial for building hierarchical embeddings using
shallow models and, recently, using MLPs and RNNs.
</p>
<p>However, no papers have yet suggested a general approach to using Hyperbolic
Convolutional Neural Networks for structured data processing, although these
are the most common examples of data used. Therefore, the goal of this work is
to devise a general recipe for building Hyperbolic Convolutional Neural
Networks. We hypothesize that ability of hyperbolic space to capture hierarchy
in the data would lead to better performance. This ability should be
particularly useful in cases where data has a tree-like structure. Since this
is the case for many existing datasets \citep{wordnet, imagenet, fb15k}, we
argue that such a model would be advantageous both in terms of applications and
future research prospects.
</p></li>
</ul>

<h3>Title: MSGNN: Multi-scale Spatio-temporal Graph Neural Network for Epidemic Forecasting. (arXiv:2308.15840v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15840">http://arxiv.org/abs/2308.15840</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15840]] MSGNN: Multi-scale Spatio-temporal Graph Neural Network for Epidemic Forecasting(http://arxiv.org/abs/2308.15840)</code></li>
<li>Summary: <p>Infectious disease forecasting has been a key focus and proved to be crucial
in controlling epidemic. A recent trend is to develop forecast-ing models based
on graph neural networks (GNNs). However, existing GNN-based methods suffer
from two key limitations: (1) Current models broaden receptive fields by
scaling the depth of GNNs, which is insuffi-cient to preserve the semantics of
long-range connectivity between distant but epidemic related areas. (2)
Previous approaches model epidemics within single spatial scale, while ignoring
the multi-scale epidemic pat-terns derived from different scales. To address
these deficiencies, we devise the Multi-scale Spatio-temporal Graph Neural
Network (MSGNN) based on an innovative multi-scale view. To be specific, in the
proposed MSGNN model, we first devise a novel graph learning module, which
directly captures long-range connectivity from trans-regional epidemic signals
and integrates them into a multi-scale graph. Based on the learned multi-scale
graph, we utilize a newly designed graph convolution module to exploit
multi-scale epidemic patterns. This module allows us to facilitate multi-scale
epidemic modeling by mining both scale-shared and scale-specific pat-terns.
Experimental results on forecasting new cases of COVID-19 in United State
demonstrate the superiority of our method over state-of-arts. Further analyses
and visualization also show that MSGNN offers not only accurate, but also
robust and interpretable forecasting result.
</p></li>
</ul>

<h3>Title: Advanced Deep Regression Models for Forecasting Time Series Oil Production. (arXiv:2308.16105v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16105">http://arxiv.org/abs/2308.16105</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16105]] Advanced Deep Regression Models for Forecasting Time Series Oil Production(http://arxiv.org/abs/2308.16105)</code></li>
<li>Summary: <p>Global oil demand is rapidly increasing and is expected to reach 106.3
million barrels per day by 2040. Thus, it is vital for hydrocarbon extraction
industries to forecast their production to optimize their operations and avoid
losses. Big companies have realized that exploiting the power of deep learning
(DL) and the massive amount of data from various oil wells for this purpose can
save a lot of operational costs and reduce unwanted environmental impacts. In
this direction, researchers have proposed models using conventional machine
learning (ML) techniques for oil production forecasting. However, these
techniques are inappropriate for this problem as they can not capture
historical patterns found in time series data, resulting in inaccurate
predictions. This research aims to overcome these issues by developing advanced
data-driven regression models using sequential convolutions and long short-term
memory (LSTM) units. Exhaustive analyses are conducted to select the optimal
sequence length, model hyperparameters, and cross-well dataset formation to
build highly generalized robust models. A comprehensive experimental study on
Volve oilfield data validates the proposed models. It reveals that the
LSTM-based sequence learning model can predict oil production better than the
1-D convolutional neural network (CNN) with mean absolute error (MAE) and R2
score of 111.16 and 0.98, respectively. It is also found that the LSTM-based
model performs better than all the existing state-of-the-art solutions and
achieves a 37% improvement compared to a standard linear regression, which is
considered the baseline model in this work.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Background Debiased SAR Target Recognition via Causal Interventional Regularizer. (arXiv:2308.15724v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15724">http://arxiv.org/abs/2308.15724</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15724]] Background Debiased SAR Target Recognition via Causal Interventional Regularizer(http://arxiv.org/abs/2308.15724)</code></li>
<li>Summary: <p>Recent studies have utilized deep learning (DL) techniques to automatically
extract features from synthetic aperture radar (SAR) images, which shows great
promise for enhancing the performance of SAR automatic target recognition
(ATR). However, our research reveals a previously overlooked issue: SAR images
to be recognized include not only the foreground (i.e., the target), but also a
certain size of the background area. When a DL-model is trained exclusively on
foreground data, its recognition performance is significantly superior to a
model trained on original data that includes both foreground and background.
This suggests that the presence of background impedes the ability of the
DL-model to learn additional semantic information about the target. To address
this issue, we construct a structural causal model (SCM) that incorporates the
background as a confounder. Based on the constructed SCM, we propose a causal
intervention based regularization method to eliminate the negative impact of
background on feature semantic learning and achieve background debiased
SAR-ATR. The proposed causal interventional regularizer can be integrated into
any existing DL-based SAR-ATR models to mitigate the impact of background
interference on the feature extraction and recognition accuracy. Experimental
results on the Moving and Stationary Target Acquisition and Recognition (MSTAR)
dataset indicate that the proposed method can enhance the efficiency of
existing DL-based methods in a plug-and-play manner.
</p></li>
</ul>

<h3>Title: Large-scale data extraction from the UNOS organ donor documents. (arXiv:2308.15752v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15752">http://arxiv.org/abs/2308.15752</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15752]] Large-scale data extraction from the UNOS organ donor documents(http://arxiv.org/abs/2308.15752)</code></li>
<li>Summary: <p>The scope of our study is all UNOS data of the USA organ donors since 2008.
The data is not analyzable in a large scale in the past because it was captured
in PDF documents known as "Attachments", whereby every donor is represented by
dozens of PDF documents in heterogenous formats. To make the data analyzable,
one needs to convert the content inside these PDFs to an analyzable data
format, such as a standard SQL database. In this paper we will focus on 2022
UNOS data comprised of $\approx 400,000$ PDF documents spanning millions of
pages. The totality of UNOS data covers 15 years (2008--20022) and our results
will be quickly extended to the entire data. Our method captures a portion of
the data in DCD flowsheets, kidney perfusion data, and data captured during
patient hospital stay (e.g. vital signs, ventilator settings, etc.). The
current paper assumes that the reader is familiar with the content of the UNOS
data. The overview of the types of data and challenges they present is a
subject of another paper. Here we focus on demonstrating that the goal of
building a comprehensive, analyzable database from UNOS documents is an
attainable task, and we provide an overview of our methodology. The project
resulted in datasets by far larger than previously available even in this
preliminary phase.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FedCiR: Client-Invariant Representation Learning for Federated Non-IID Features. (arXiv:2308.15786v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15786">http://arxiv.org/abs/2308.15786</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15786]] FedCiR: Client-Invariant Representation Learning for Federated Non-IID Features(http://arxiv.org/abs/2308.15786)</code></li>
<li>Summary: <p>Federated learning (FL) is a distributed learning paradigm that maximizes the
potential of data-driven models for edge devices without sharing their raw
data. However, devices often have non-independent and identically distributed
(non-IID) data, meaning their local data distributions can vary significantly.
The heterogeneity in input data distributions across devices, commonly referred
to as the feature shift problem, can adversely impact the training convergence
and accuracy of the global model. To analyze the intrinsic causes of the
feature shift problem, we develop a generalization error bound in FL, which
motivates us to propose FedCiR, a client-invariant representation learning
framework that enables clients to extract informative and client-invariant
features. Specifically, we improve the mutual information term between
representations and labels to encourage representations to carry essential
classification knowledge, and diminish the mutual information term between the
client set and representations conditioned on labels to promote representations
of clients to be client-invariant. We further incorporate two regularizers into
the FL framework to bound the mutual information terms with an approximate
global representation distribution to compensate for the absence of the
ground-truth global representation distribution, thus achieving informative and
client-invariant feature extraction. To achieve global representation
distribution approximation, we propose a data-free mechanism performed by the
server without compromising privacy. Extensive experiments demonstrate the
effectiveness of our approach in achieving client-invariant representation
learning and solving the data heterogeneity issue.
</p></li>
</ul>

<h3>Title: Federated Two Stage Decoupling With Adaptive Personalization Layers. (arXiv:2308.15821v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15821">http://arxiv.org/abs/2308.15821</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15821]] Federated Two Stage Decoupling With Adaptive Personalization Layers(http://arxiv.org/abs/2308.15821)</code></li>
<li>Summary: <p>Federated learning has gained significant attention due to its groundbreaking
ability to enable distributed learning while maintaining privacy constraints.
However, as a consequence of data heterogeneity among decentralized devices, it
inherently experiences significant learning degradation and slow convergence
speed. Therefore, it is natural to employ the concept of clustering homogeneous
clients into the same group, allowing only the model weights within each group
to be aggregated. While most existing clustered federated learning methods
employ either model gradients or inference outputs as metrics for client
partitioning, with the goal of grouping similar devices together, may still
have heterogeneity within each cluster. Moreover, there is a scarcity of
research exploring the underlying reasons for determining the appropriate
timing for clustering, resulting in the common practice of assigning each
client to its own individual cluster, particularly in the context of highly non
independent and identically distributed (Non-IID) data. In this paper, we
introduce a two-stage decoupling federated learning algorithm with adaptive
personalization layers named FedTSDP, where client clustering is performed
twice according to inference outputs and model weights, respectively. Hopkins
amended sampling is adopted to determine the appropriate timing for clustering
and the sampling weight of public unlabeled data. In addition, a simple yet
effective approach is developed to adaptively adjust the personalization layers
based on varying degrees of data skew. Experimental results show that our
proposed method has reliable performance on both IID and non-IID scenarios.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-Spectral Image Fusion. (arXiv:2308.16083v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16083">http://arxiv.org/abs/2308.16083</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16083]] Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-Spectral Image Fusion(http://arxiv.org/abs/2308.16083)</code></li>
<li>Summary: <p>The success of deep neural networks for pan-sharpening is commonly in a form
of black box, lacking transparency and interpretability. To alleviate this
issue, we propose a novel model-driven deep unfolding framework with image
reasoning prior tailored for the pan-sharpening task. Different from existing
unfolding solutions that deliver the proximal operator networks as the
uncertain and vague priors, our framework is motivated by the content reasoning
ability of masked autoencoders (MAE) with insightful designs. Specifically, the
pre-trained MAE with spatial masking strategy, acting as intrinsic reasoning
prior, is embedded into unfolding architecture. Meanwhile, the pre-trained MAE
with spatial-spectral masking strategy is treated as the regularization term
within loss function to constrain the spatial-spectral consistency. Such
designs penetrate the image reasoning prior into deep unfolding networks while
improving its interpretability and representation capability. The uniqueness of
our framework is that the holistic learning process is explicitly integrated
with the inherent physical mechanism underlying the pan-sharpening task.
Extensive experiments on multiple satellite datasets demonstrate the
superiority of our method over the existing state-of-the-art approaches. Code
will be released at \url{https://manman1995.github.io/}.
</p></li>
</ul>

<h3>Title: Glocal Explanations of Expected Goal Models in Soccer. (arXiv:2308.15559v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15559">http://arxiv.org/abs/2308.15559</a></li>
<li>Code URL: https://github.com/adrianstando/glocal-explanations-of-xg-models</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15559]] Glocal Explanations of Expected Goal Models in Soccer(http://arxiv.org/abs/2308.15559)</code></li>
<li>Summary: <p>The expected goal models have gained popularity, but their interpretability
is often limited, especially when trained using black-box methods. Explainable
artificial intelligence tools have emerged to enhance model transparency and
extract descriptive knowledge for a single observation or for all observations.
However, explaining black-box models for a specific group of observations may
be more useful in some domains. This paper introduces the glocal explanations
(between local and global levels) of the expected goal models to enable
performance analysis at the team and player levels by proposing the use of
aggregated versions of the SHAP values and partial dependence profiles. This
allows knowledge to be extracted from the expected goal model for a player or
team rather than just a single shot. In addition, we conducted real-data
applications to illustrate the usefulness of aggregated SHAP and aggregated
profiles. The paper concludes with remarks on the potential of these
explanations for performance analysis in soccer analytics.
</p></li>
</ul>

<h3>Title: Consensus of state of the art mortality prediction models: From all-cause mortality to sudden death prediction. (arXiv:2308.16067v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16067">http://arxiv.org/abs/2308.16067</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16067]] Consensus of state of the art mortality prediction models: From all-cause mortality to sudden death prediction(http://arxiv.org/abs/2308.16067)</code></li>
<li>Summary: <p>Worldwide, many millions of people die suddenly and unexpectedly each year,
either with or without a prior history of cardiovascular disease. Such events
are sparse (once in a lifetime), many victims will not have had prior
investigations for cardiac disease and many different definitions of sudden
death exist. Accordingly, sudden death is hard to predict.
</p>
<p>This analysis used NHS Electronic Health Records (EHRs) for people aged
$\geq$50 years living in the Greater Glasgow and Clyde (GG\&amp;C) region in 2010
(n = 380,000) to try to overcome these challenges. We investigated whether
medical history, blood tests, prescription of medicines, and hospitalisations
might, in combination, predict a heightened risk of sudden death.
</p>
<p>We compared the performance of models trained to predict either sudden death
or all-cause mortality. We built six models for each outcome of interest: three
taken from state-of-the-art research (BEHRT, Deepr and Deep Patient), and three
of our own creation. We trained these using two different data representations:
a language-based representation, and a sparse temporal matrix.
</p>
<p>We used global interpretability to understand the most important features of
each model, and compare how much agreement there was amongst models using Rank
Biased Overlap. It is challenging to account for correlated variables without
increasing the complexity of the interpretability technique. We overcame this
by clustering features into groups and comparing the most important groups for
each model. We found the agreement between models to be much higher when
accounting for correlated variables.
</p>
<p>Our analysis emphasises the challenge of predicting sudden death and
emphasises the need for better understanding and interpretation of machine
learning models applied to healthcare applications.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search. (arXiv:2308.15734v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15734">http://arxiv.org/abs/2308.15734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15734]] Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search(http://arxiv.org/abs/2308.15734)</code></li>
<li>Summary: <p>Graph neural networks (GNNs) are powerful tools for performing data science
tasks in various domains. Although we use GNNs in wide application scenarios,
it is a laborious task for researchers and practitioners to design/select
optimal GNN rchitectures in diverse graphs. To save human efforts and
computational costs, graph neural architecture search (Graph NAS) has been used
to search for a sub-optimal GNN architecture that combines existing components.
However, there are no existing Graph NAS methods that satisfy explainability,
efficiency, and adaptability to various graphs. Therefore, we propose an
efficient and explainable Graph NAS method, called ExGNAS, which consists of
(i) a simple search space that can adapt to various graphs and (ii) a search
algorithm that makes the decision process explainable. The search space
includes only fundamental functions that can handle homophilic and heterophilic
graphs. The search algorithm efficiently searches for the best GNN architecture
via Monte-Carlo tree search without neural models. The combination of our
search space and algorithm achieves finding accurate GNN models and the
important functions within the search space. We comprehensively evaluate our
method compared with twelve hand-crafted GNN architectures and three Graph NAS
methods in four graphs. Our experimental results show that ExGNAS increases AUC
up to 3.6 and reduces run time up to 78\% compared with the state-of-the-art
Graph NAS methods. Furthermore, we show ExGNAS is effective in analyzing the
difference between GNN architectures in homophilic and heterophilic graphs.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models. (arXiv:2308.15854v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15854">http://arxiv.org/abs/2308.15854</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15854]] Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models(http://arxiv.org/abs/2308.15854)</code></li>
<li>Summary: <p>Denoising diffusion models have shown outstanding performance in image
editing. Existing works tend to use either image-guided methods, which provide
a visual reference but lack control over semantic coherence, or text-guided
methods, which ensure faithfulness to text guidance but lack visual quality. To
address the problem, we propose the Zero-shot Inversion Process (ZIP), a
framework that injects a fusion of generated visual reference and text guidance
into the semantic latent space of a \textit{frozen} pre-trained diffusion
model. Only using a tiny neural network, the proposed ZIP produces diverse
content and attributes under the intuitive control of the text prompt.
Moreover, ZIP shows remarkable robustness for both in-domain and out-of-domain
attribute manipulation on real images. We perform detailed experiments on
various benchmark datasets. Compared to state-of-the-art methods, ZIP produces
images of equivalent quality while providing a realistic editing effect.
</p></li>
</ul>

<h3>Title: Feature Attention Network (FA-Net): A Deep-Learning Based Approach for Underwater Single Image Enhancement. (arXiv:2308.15868v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15868">http://arxiv.org/abs/2308.15868</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15868]] Feature Attention Network (FA-Net): A Deep-Learning Based Approach for Underwater Single Image Enhancement(http://arxiv.org/abs/2308.15868)</code></li>
<li>Summary: <p>Underwater image processing and analysis have been a hotspot of study in
recent years, as more emphasis has been focused to underwater monitoring and
usage of marine resources. Compared with the open environment, underwater image
encountered with more complicated conditions such as light abortion,
scattering, turbulence, nonuniform illumination and color diffusion. Although
considerable advances and enhancement techniques achieved in resolving these
issues, they treat low-frequency information equally across the entire channel,
which results in limiting the network's representativeness. We propose a deep
learning and feature-attention-based end-to-end network (FA-Net) to solve this
problem. In particular, we propose a Residual Feature Attention Block (RFAB),
containing the channel attention, pixel attention, and residual learning
mechanism with long and short skip connections. RFAB allows the network to
focus on learning high-frequency information while skipping low-frequency
information on multi-hop connections. The channel and pixel attention mechanism
considers each channel's different features and the uneven distribution of haze
over different pixels in the image. The experimental results shows that the
FA-Net propose by us provides higher accuracy, quantitatively and qualitatively
and superiority to previous state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Physics-Informed DeepMRI: Bridging the Gap from Heat Diffusion to k-Space Interpolation. (arXiv:2308.15918v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15918">http://arxiv.org/abs/2308.15918</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15918]] Physics-Informed DeepMRI: Bridging the Gap from Heat Diffusion to k-Space Interpolation(http://arxiv.org/abs/2308.15918)</code></li>
<li>Summary: <p>In the field of parallel imaging (PI), alongside image-domain regularization
methods, substantial research has been dedicated to exploring $k$-space
interpolation. However, the interpretability of these methods remains an
unresolved issue. Furthermore, these approaches currently face acceleration
limitations that are comparable to those experienced by image-domain methods.
In order to enhance interpretability and overcome the acceleration limitations,
this paper introduces an interpretable framework that unifies both $k$-space
interpolation techniques and image-domain methods, grounded in the physical
principles of heat diffusion equations. Building upon this foundational
framework, a novel $k$-space interpolation method is proposed. Specifically, we
model the process of high-frequency information attenuation in $k$-space as a
heat diffusion equation, while the effort to reconstruct high-frequency
information from low-frequency regions can be conceptualized as a reverse heat
equation. However, solving the reverse heat equation poses a challenging
inverse problem. To tackle this challenge, we modify the heat equation to align
with the principles of magnetic resonance PI physics and employ the score-based
generative method to precisely execute the modified reverse heat diffusion.
Finally, experimental validation conducted on publicly available datasets
demonstrates the superiority of the proposed approach over traditional
$k$-space interpolation methods, deep learning-based $k$-space interpolation
methods, and conventional diffusion models in terms of reconstruction accuracy,
particularly in high-frequency regions.
</p></li>
</ul>

<h3>Title: DiffuVolume: Diffusion Model for Volume based Stereo Matching. (arXiv:2308.15989v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15989">http://arxiv.org/abs/2308.15989</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15989]] DiffuVolume: Diffusion Model for Volume based Stereo Matching(http://arxiv.org/abs/2308.15989)</code></li>
<li>Summary: <p>Stereo matching is a significant part in many computer vision tasks and
driving-based applications. Recently cost volume-based methods have achieved
great success benefiting from the rich geometry information in paired images.
However, the redundancy of cost volume also interferes with the model training
and limits the performance. To construct a more precise cost volume, we
pioneeringly apply the diffusion model to stereo matching. Our method, termed
DiffuVolume, considers the diffusion model as a cost volume filter, which will
recurrently remove the redundant information from the cost volume. Two main
designs make our method not trivial. Firstly, to make the diffusion model more
adaptive to stereo matching, we eschew the traditional manner of directly
adding noise into the image but embed the diffusion model into a task-specific
module. In this way, we outperform the traditional diffusion stereo matching
method by 22% EPE improvement and 240 times inference acceleration. Secondly,
DiffuVolume can be easily embedded into any volume-based stereo matching
network with boost performance but slight parameters rise (only 2%). By adding
the DiffuVolume into well-performed methods, we outperform all the published
methods on Scene Flow, KITTI2012, KITTI2015 benchmarks and zero-shot
generalization setting. It is worth mentioning that the proposed model ranks
1st on KITTI 2012 leader board, 2nd on KITTI 2015 leader board since 15, July
2023.
</p></li>
</ul>

<h3>Title: SignDiff: Learning Diffusion Models for American Sign Language Production. (arXiv:2308.16082v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16082">http://arxiv.org/abs/2308.16082</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16082]] SignDiff: Learning Diffusion Models for American Sign Language Production(http://arxiv.org/abs/2308.16082)</code></li>
<li>Summary: <p>The field of Sign Language Production (SLP) lacked a large-scale, pre-trained
model based on deep learning for continuous American Sign Language (ASL)
production in the past decade. This limitation hampers communication for all
individuals with disabilities relying on ASL. To address this issue, we
undertook the secondary development and utilization of How2Sign, one of the
largest publicly available ASL datasets. Despite its significance, prior
researchers in the field of sign language have not effectively employed this
corpus due to the intricacies involved in American Sign Language Production
(ASLP).
</p>
<p>To conduct large-scale ASLP, we propose SignDiff based on the latest work in
related fields, which is a dual-condition diffusion pre-training model that can
generate human sign language speakers from a skeleton pose. SignDiff has a
novel Frame Reinforcement Network called FR-Net, similar to dense human pose
estimation work, which enhances the correspondence between text lexical symbols
and sign language dense pose frames reduce the occurrence of multiple fingers
in the diffusion model. In addition, our ASLP method proposes two new improved
modules and a new loss function to improve the accuracy and quality of sign
language skeletal posture and enhance the ability of the model to train on
large-scale data.
</p>
<p>We propose the first baseline for ASL production and report the scores of
17.19 and 12.85 on BLEU-4 on the How2Sign dev/test sets. We also evaluated our
model on the previous mainstream dataset called PHOENIX14T, and the main
experiments achieved the results of SOTA. In addition, our image quality far
exceeds all previous results by 10 percentage points on the SSIM indicator.
Finally, we conducted ablation studies and qualitative evaluations for
discussion.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Document AI: A Comparative Study of Transformer-Based, Graph-Based Models, and Convolutional Neural Networks For Document Layout Analysis. (arXiv:2308.15517v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15517">http://arxiv.org/abs/2308.15517</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15517]] Document AI: A Comparative Study of Transformer-Based, Graph-Based Models, and Convolutional Neural Networks For Document Layout Analysis(http://arxiv.org/abs/2308.15517)</code></li>
<li>Summary: <p>Document AI aims to automatically analyze documents by leveraging natural
language processing and computer vision techniques. One of the major tasks of
Document AI is document layout analysis, which structures document pages by
interpreting the content and spatial relationships of layout, image, and text.
This task can be image-centric, wherein the aim is to identify and label
various regions such as authors and paragraphs, or text-centric, where the
focus is on classifying individual words in a document. Although there are
increasingly sophisticated methods for improving layout analysis, doubts remain
about the extent to which their findings can be generalized to a broader
context. Specifically, prior work developed systems based on very different
architectures, such as transformer-based, graph-based, and CNNs. However, no
work has mentioned the effectiveness of these models in a comparative analysis.
Moreover, while language-independent Document AI models capable of knowledge
transfer have been developed, it remains to be investigated to what degree they
can effectively transfer knowledge. In this study, we aim to fill these gaps by
conducting a comparative evaluation of state-of-the-art models in document
layout analysis and investigating the potential of cross-lingual layout
analysis by utilizing machine translation techniques.
</p></li>
</ul>

<h3>Title: Detection of Mild Cognitive Impairment Using Facial Features in Video Conversations. (arXiv:2308.15624v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15624">http://arxiv.org/abs/2308.15624</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15624]] Detection of Mild Cognitive Impairment Using Facial Features in Video Conversations(http://arxiv.org/abs/2308.15624)</code></li>
<li>Summary: <p>Early detection of Mild Cognitive Impairment (MCI) leads to early
interventions to slow the progression from MCI into dementia. Deep Learning
(DL) algorithms could help achieve early non-invasive, low-cost detection of
MCI. This paper presents the detection of MCI in older adults using DL models
based only on facial features extracted from video-recorded conversations at
home. We used the data collected from the I-CONECT behavioral intervention
study (NCT02871921), where several sessions of semi-structured interviews
between socially isolated older individuals and interviewers were video
recorded. We develop a framework that extracts spatial holistic facial features
using a convolutional autoencoder and temporal information using transformers.
Our proposed DL model was able to detect the I-CONECT study participants'
cognitive conditions (MCI vs. those with normal cognition (NC)) using facial
features. The segments and sequence information of the facial features improved
the prediction performance compared with the non-temporal features. The
detection accuracy using this combined method reached 88% whereas 84% is the
accuracy without applying the segments and sequences information of the facial
features within a video on a certain theme.
</p></li>
</ul>

<h3>Title: Exploring Multi-Modal Contextual Knowledge for Open-Vocabulary Object Detection. (arXiv:2308.15846v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15846">http://arxiv.org/abs/2308.15846</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15846]] Exploring Multi-Modal Contextual Knowledge for Open-Vocabulary Object Detection(http://arxiv.org/abs/2308.15846)</code></li>
<li>Summary: <p>In this paper, we for the first time explore helpful multi-modal contextual
knowledge to understand novel categories for open-vocabulary object detection
(OVD). The multi-modal contextual knowledge stands for the joint relationship
across regions and words. However, it is challenging to incorporate such
multi-modal contextual knowledge into OVD. The reason is that previous
detection frameworks fail to jointly model multi-modal contextual knowledge, as
object detectors only support vision inputs and no caption description is
provided at test time. To this end, we propose a multi-modal contextual
knowledge distillation framework, MMC-Det, to transfer the learned contextual
knowledge from a teacher fusion transformer with diverse multi-modal masked
language modeling (D-MLM) to a student detector. The diverse multi-modal masked
language modeling is realized by an object divergence constraint upon
traditional multi-modal masked language modeling (MLM), in order to extract
fine-grained region-level visual contexts, which are vital to object detection.
Extensive experiments performed upon various detection datasets show the
effectiveness of our multi-modal context learning strategy, where our approach
well outperforms the recent state-of-the-art methods.
</p></li>
</ul>

<h3>Title: DTrOCR: Decoder-only Transformer for Optical Character Recognition. (arXiv:2308.15996v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15996">http://arxiv.org/abs/2308.15996</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15996]] DTrOCR: Decoder-only Transformer for Optical Character Recognition(http://arxiv.org/abs/2308.15996)</code></li>
<li>Summary: <p>Typical text recognition methods rely on an encoder-decoder structure, in
which the encoder extracts features from an image, and the decoder produces
recognized text from these features. In this study, we propose a simpler and
more effective method for text recognition, known as the Decoder-only
Transformer for Optical Character Recognition (DTrOCR). This method uses a
decoder-only Transformer to take advantage of a generative language model that
is pre-trained on a large corpus. We examined whether a generative language
model that has been successful in natural language processing can also be
effective for text recognition in computer vision. Our experiments demonstrated
that DTrOCR outperforms current state-of-the-art methods by a large margin in
the recognition of printed, handwritten, and scene text in both English and
Chinese.
</p></li>
</ul>

<h3>Title: CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention. (arXiv:2308.16145v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16145">http://arxiv.org/abs/2308.16145</a></li>
<li>Code URL: https://github.com/zhanghx-iim-ahu/circleformer</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16145]] CircleFormer: Circular Nuclei Detection in Whole Slide Images with Circle Queries and Attention(http://arxiv.org/abs/2308.16145)</code></li>
<li>Summary: <p>Both CNN-based and Transformer-based object detection with bounding box
representation have been extensively studied in computer vision and medical
image analysis, but circular object detection in medical images is still
underexplored. Inspired by the recent anchor free CNN-based circular object
detection method (CircleNet) for ball-shape glomeruli detection in renal
pathology, in this paper, we present CircleFormer, a Transformer-based circular
medical object detection with dynamic anchor circles. Specifically, queries
with circle representation in Transformer decoder iteratively refine the
circular object detection results, and a circle cross attention module is
introduced to compute the similarity between circular queries and image
features. A generalized circle IoU (gCIoU) is proposed to serve as a new
regression loss of circular object detection as well. Moreover, our approach is
easy to generalize to the segmentation task by adding a simple segmentation
branch to CircleFormer. We evaluate our method in circular nuclei detection and
segmentation on the public MoNuSeg dataset, and the experimental results show
that our method achieves promising performance compared with the
state-of-the-art approaches. The effectiveness of each component is validated
via ablation studies as well. Our code is released at:
\url{https://github.com/zhanghx-iim-ahu/CircleFormer}.
</p></li>
</ul>

<h3>Title: Cyberbullying Detection for Low-resource Languages and Dialects: Review of the State of the Art. (arXiv:2308.15745v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15745">http://arxiv.org/abs/2308.15745</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15745]] Cyberbullying Detection for Low-resource Languages and Dialects: Review of the State of the Art(http://arxiv.org/abs/2308.15745)</code></li>
<li>Summary: <p>The struggle of social media platforms to moderate content in a timely
manner, encourages users to abuse such platforms to spread vulgar or abusive
language, which, when performed repeatedly becomes cyberbullying a social
problem taking place in virtual environments, yet with real-world consequences,
such as depression, withdrawal, or even suicide attempts of its victims.
Systems for the automatic detection and mitigation of cyberbullying have been
developed but, unfortunately, the vast majority of them are for the English
language, with only a handful available for low-resource languages. To estimate
the present state of research and recognize the needs for further development,
in this paper we present a comprehensive systematic survey of studies done so
far for automatic cyberbullying detection in low-resource languages. We
analyzed all studies on this topic that were available. We investigated more
than seventy published studies on automatic detection of cyberbullying or
related language in low-resource languages and dialects that were published
between around 2017 and January 2023. There are 23 low-resource languages and
dialects covered by this paper, including Bangla, Hindi, Dravidian languages
and others. In the survey, we identify some of the research gaps of previous
studies, which include the lack of reliable definitions of cyberbullying and
its relevant subcategories, biases in the acquisition, and annotation of data.
Based on recognizing those research gaps, we provide some suggestions for
improving the general research conduct in cyberbullying detection, with a
primary focus on low-resource languages. Based on those proposed suggestions,
we collect and release a cyberbullying dataset in the Chittagonian dialect of
Bangla and propose a number of initial ML solutions trained on that dataset. In
addition, pre-trained transformer-based the BanglaBERT model was also
attempted.
</p></li>
</ul>

<h3>Title: HAlf-MAsked Model for Named Entity Sentiment analysis. (arXiv:2308.15793v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15793">http://arxiv.org/abs/2308.15793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15793]] HAlf-MAsked Model for Named Entity Sentiment analysis(http://arxiv.org/abs/2308.15793)</code></li>
<li>Summary: <p>Named Entity Sentiment analysis (NESA) is one of the most actively developing
application domains in Natural Language Processing (NLP). Social media NESA is
a significant field of opinion analysis since detecting and tracking sentiment
trends in the news flow is crucial for building various analytical systems and
monitoring the media image of specific people or companies. In this paper, we
study different transformers-based solutions NESA in RuSentNE-23 evaluation.
Despite the effectiveness of the BERT-like models, they can still struggle with
certain challenges, such as overfitting, which appeared to be the main obstacle
in achieving high accuracy on the RuSentNE-23 data. We present several
approaches to overcome this problem, among which there is a novel technique of
additional pass over given data with masked entity before making the final
prediction so that we can combine logits from the model when it knows the exact
entity it predicts sentiment for and when it does not. Utilizing this
technique, we ensemble multiple BERT- like models trained on different subsets
of data to improve overall performance. Our proposed model achieves the best
result on RuSentNE-23 evaluation data and demonstrates improved consistency in
entity-level sentiment analysis.
</p></li>
</ul>

<h3>Title: Can transformers learn the greatest common divisor?. (arXiv:2308.15594v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15594">http://arxiv.org/abs/2308.15594</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15594]] Can transformers learn the greatest common divisor?(http://arxiv.org/abs/2308.15594)</code></li>
<li>Summary: <p>I investigate the capability of small transformers to compute the greatest
common divisor (GCD) of two positive integers. When the training distribution
and the representation base are carefully chosen, models achieve 98% accuracy
and correctly predict 91 of the 100 first GCD. Model predictions are
deterministic and fully interpretable. During training, the models learn to
cluster input pairs with the same GCD, and classify them by their divisors.
Basic models, trained from uniform operands encoded on small bases, only
compute a handful of GCD (up to 38 out of 100): the products of divisors of the
base. Longer training and larger bases allow some models to "grok" small prime
GCD. Training from log-uniform operands boosts performance to 73 correct GCD,
and balancing the training distribution of GCD, from inverse square to
log-uniform, to 91 GCD. Training models from a uniform distribution of GCD
breaks the deterministic model behavior.
</p></li>
</ul>

<h3>Title: InstaTune: Instantaneous Neural Architecture Search During Fine-Tuning. (arXiv:2308.15609v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15609">http://arxiv.org/abs/2308.15609</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15609]] InstaTune: Instantaneous Neural Architecture Search During Fine-Tuning(http://arxiv.org/abs/2308.15609)</code></li>
<li>Summary: <p>One-Shot Neural Architecture Search (NAS) algorithms often rely on training a
hardware agnostic super-network for a domain specific task. Optimal
sub-networks are then extracted from the trained super-network for different
hardware platforms. However, training super-networks from scratch can be
extremely time consuming and compute intensive especially for large models that
rely on a two-stage training process of pre-training and fine-tuning. State of
the art pre-trained models are available for a wide range of tasks, but their
large sizes significantly limits their applicability on various hardware
platforms. We propose InstaTune, a method that leverages off-the-shelf
pre-trained weights for large models and generates a super-network during the
fine-tuning stage. InstaTune has multiple benefits. Firstly, since the process
happens during fine-tuning, it minimizes the overall time and compute resources
required for NAS. Secondly, the sub-networks extracted are optimized for the
target task, unlike prior work that optimizes on the pre-training objective.
Finally, InstaTune is easy to "plug and play" in existing frameworks. By using
multi-objective evolutionary search algorithms along with lightly trained
predictors, we find Pareto-optimal sub-networks that outperform their
respective baselines across different performance objectives such as accuracy
and MACs. Specifically, we demonstrate that our approach performs well across
both unimodal (ViT and BERT) and multi-modal (BEiT-3) transformer based
architectures.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models. (arXiv:2308.16149v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16149">http://arxiv.org/abs/2308.16149</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16149]] Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models(http://arxiv.org/abs/2308.16149)</code></li>
<li>Summary: <p>We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric
foundation and instruction-tuned open generative large language models (LLMs).
The models are based on the GPT-3 decoder-only architecture and are pretrained
on a mixture of Arabic and English texts, including source code in various
programming languages. With 13 billion parameters, they demonstrate better
knowledge and reasoning capabilities in Arabic than any existing open Arabic
and multilingual models by a sizable margin, based on extensive evaluation.
Moreover, the models are competitive in English compared to English-centric
open models of similar size, despite being trained on much less English data.
We provide a detailed description of the training, the tuning, the safety
alignment, and the evaluation of the models. We release two open versions of
the model -- the foundation Jais model, and an instruction-tuned Jais-chat
variant -- with the aim of promoting research on Arabic LLMs. Available at
https://huggingface.co/inception-mbzuai/jais-13b-chat
</p></li>
</ul>

<h3>Title: Fully Embedded Time-Series Generative Adversarial Networks. (arXiv:2308.15730v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15730">http://arxiv.org/abs/2308.15730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15730]] Fully Embedded Time-Series Generative Adversarial Networks(http://arxiv.org/abs/2308.15730)</code></li>
<li>Summary: <p>Generative Adversarial Networks (GANs) should produce synthetic data that
fits the underlying distribution of the data being modeled. For real valued
time-series data, this implies the need to simultaneously capture the static
distribution of the data, but also the full temporal distribution of the data
for any potential time horizon. This temporal element produces a more complex
problem that can potentially leave current solutions under-constrained,
unstable during training, or prone to varying degrees of mode collapse. In
FETSGAN, entire sequences are translated directly to the generator's sampling
space using a seq2seq style adversarial auto encoder (AAE), where adversarial
training is used to match the training distribution in both the feature space
and the lower dimensional sampling space. This additional constraint provides a
loose assurance that the temporal distribution of the synthetic samples will
not collapse. In addition, the First Above Threshold (FAT) operator is
introduced to supplement the reconstruction of encoded sequences, which
improves training stability and the overall quality of the synthetic data being
generated. These novel contributions demonstrate a significant improvement to
the current state of the art for adversarial learners in qualitative measures
of temporal similarity and quantitative predictive ability of data generated
through FETSGAN.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Quantifying and Analyzing Entity-level Memorization in Large Language Models. (arXiv:2308.15727v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15727">http://arxiv.org/abs/2308.15727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15727]] Quantifying and Analyzing Entity-level Memorization in Large Language Models(http://arxiv.org/abs/2308.15727)</code></li>
<li>Summary: <p>Large language models (LLMs) have been proven capable of memorizing their
training data, which can be extracted through specifically designed prompts. As
the scale of datasets continues to grow, privacy risks arising from
memorization have attracted increasing attention. Quantifying language model
memorization helps evaluate potential privacy risks. However, prior works on
quantifying memorization require access to the precise original data or incur
substantial computational overhead, making it difficult for applications in
real-world language models. To this end, we propose a fine-grained,
entity-level definition to quantify memorization with conditions and metrics
closer to real-world scenarios. In addition, we also present an approach for
efficiently extracting sensitive entities from autoregressive language models.
We conduct extensive experiments based on the proposed, probing language
models' ability to reconstruct sensitive entities under different settings. We
find that language models have strong memorization at the entity level and are
able to reproduce the training data even with partial leakages. The results
demonstrate that LLMs not only memorize their training data but also understand
associations between entities. These findings necessitate that trainers of LLMs
exercise greater prudence regarding model memorization, adopting memorization
mitigation techniques to preclude privacy violations.
</p></li>
</ul>

<h3>Title: Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15812">http://arxiv.org/abs/2308.15812</a></li>
<li>Code URL: https://github.com/hritikbansal/sparse_feedback</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15812]] Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models(http://arxiv.org/abs/2308.15812)</code></li>
<li>Summary: <p>Aligning large language models (LLMs) with human values and intents
critically involves the use of human or AI feedback. While dense feedback
annotations are expensive to acquire and integrate, sparse feedback presents a
structural design choice between ratings (e.g., score Response A on a scale of
1-7) and rankings (e.g., is Response A better than Response B?). In this work,
we analyze the effect of this design choice for the alignment and evaluation of
LLMs. We uncover an inconsistency problem wherein the preferences inferred from
ratings and rankings significantly disagree 60% for both human and AI
annotators. Our subsequent analysis identifies various facets of annotator
biases that explain this phenomena, such as human annotators would rate denser
responses higher while preferring accuracy during pairwise judgments. To our
surprise, we also observe that the choice of feedback protocol also has a
significant effect on the evaluation of aligned LLMs. In particular, we find
that LLMs that leverage rankings data for alignment (say model X) are preferred
over those that leverage ratings data (say model Y), with a rank-based
evaluation protocol (is X/Y's response better than reference response?) but not
with a rating-based evaluation protocol (score Rank X/Y's response on a scale
of 1-7). Our findings thus shed light on critical gaps in methods for
evaluating the real-world utility of language models and their strong
dependence on the feedback protocol used for alignment. Our code and data are
available at https://github.com/Hritikbansal/sparse_feedback.
</p></li>
</ul>

<h3>Title: LLaSM: Large Language and Speech Model. (arXiv:2308.15930v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15930">http://arxiv.org/abs/2308.15930</a></li>
<li>Code URL: https://github.com/linksoul-ai/llasm</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15930]] LLaSM: Large Language and Speech Model(http://arxiv.org/abs/2308.15930)</code></li>
<li>Summary: <p>Multi-modal large language models have garnered significant interest
recently. Though, most of the works focus on vision-language multi-modal models
providing strong capabilities in following vision-and-language instructions.
However, we claim that speech is also an important modality through which
humans interact with the world. Hence, it is crucial for a general-purpose
assistant to be able to follow multi-modal speech-and-language instructions. In
this work, we propose Large Language and Speech Model (LLaSM). LLaSM is an
end-to-end trained large multi-modal speech-language model with cross-modal
conversational abilities, capable of following speech-and-language
instructions. Our early experiments show that LLaSM demonstrates a more
convenient and natural way for humans to interact with artificial intelligence.
Specifically, we also release a large Speech Instruction Following dataset
LLaSM-Audio-Instructions. Code and demo are available at
https://github.com/LinkSoul-AI/LLaSM and
https://huggingface.co/spaces/LinkSoul/LLaSM. The LLaSM-Audio-Instructions
dataset is available at
https://huggingface.co/datasets/LinkSoul/LLaSM-Audio-Instructions.
</p></li>
</ul>

<h3>Title: FPTQ: Fine-grained Post-Training Quantization for Large Language Models. (arXiv:2308.15987v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15987">http://arxiv.org/abs/2308.15987</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15987]] FPTQ: Fine-grained Post-Training Quantization for Large Language Models(http://arxiv.org/abs/2308.15987)</code></li>
<li>Summary: <p>In the era of large-scale language models, the substantial parameter size
poses significant challenges for deployment. Being a prevalent compression
technique, quantization has emerged as the mainstream practice to tackle this
issue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and
activations in such bit widths). In this study, we propose a novel W4A8
post-training quantization method for the available open-sourced LLMs, which
combines the advantages of both two recipes. Therefore, we can leverage the
benefit in the I/O utilization of 4-bit weight quantization and the
acceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces
notorious performance degradation. As a remedy, we involve layerwise activation
quantization strategies which feature a novel logarithmic equalization for most
intractable layers, and we combine them with fine-grained weight quantization.
Without whistles and bells, we eliminate the necessity for further fine-tuning
and obtain the state-of-the-art W4A8 quantized performance on BLOOM, LLaMA, and
LLaMA-2 on standard benchmarks. We confirm that the W4A8 quantization is
achievable for the deployment of large language models, fostering their
wide-spreading real-world applications.
</p></li>
</ul>

<h3>Title: Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap. (arXiv:2308.16060v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16060">http://arxiv.org/abs/2308.16060</a></li>
<li>Code URL: https://github.com/raphael-sch/overpassnl</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16060]] Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap(http://arxiv.org/abs/2308.16060)</code></li>
<li>Summary: <p>We present Text-to-OverpassQL, a task designed to facilitate a natural
language interface for querying geodata from OpenStreetMap (OSM). The Overpass
Query Language (OverpassQL) allows users to formulate complex database queries
and is widely adopted in the OSM ecosystem. Generating Overpass queries from
natural language input serves multiple use-cases. It enables novice users to
utilize OverpassQL without prior knowledge, assists experienced users with
crafting advanced queries, and enables tool-augmented large language models to
access information stored in the OSM database. In order to assess the
performance of current sequence generation models on this task, we propose
OverpassNL, a dataset of 8,352 queries with corresponding natural language
inputs. We further introduce task specific evaluation metrics and ground the
evaluation of the Text-to-OverpassQL task by executing the queries against the
OSM database. We establish strong baselines by finetuning sequence-to-sequence
models and adapting large language models with in-context examples. The
detailed evaluation reveals strengths and weaknesses of the considered learning
strategies, laying the foundations for further research into the
Text-to-OverpassQL task.
</p></li>
</ul>

<h3>Title: Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16118">http://arxiv.org/abs/2308.16118</a></li>
<li>Code URL: https://github.com/hodeld/emergent_analogies_llm_fork</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16118]] Response: Emergent analogical reasoning in large language models(http://arxiv.org/abs/2308.16118)</code></li>
<li>Summary: <p>In their recent Nature Human Behaviour paper, "Emergent analogical reasoning
in large language models," (Webb, Holyoak, and Lu, 2023) the authors argue that
"large language models such as GPT-3 have acquired an emergent ability to find
zero-shot solutions to a broad range of analogy problems." In this response, we
provide counterexamples of the letter string analogies. In our tests, GPT-3
fails to solve even the easiest variants of the problems presented in the
original paper. Zero-shot reasoning is an extraordinary claim that requires
extraordinary evidence. We do not see that evidence in our experiments. To
strengthen claims of humanlike reasoning such as zero-shot reasoning, it is
important that the field develop approaches that rule out data memorization.
</p></li>
</ul>

<h3>Title: LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16137">http://arxiv.org/abs/2308.16137</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16137]] LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models(http://arxiv.org/abs/2308.16137)</code></li>
<li>Summary: <p>In recent years, there have been remarkable advancements in the performance
of Transformer-based Large Language Models (LLMs) across various domains. As
these LLMs are deployed for increasingly complex tasks, they often face the
needs to conduct longer reasoning processes or understanding larger contexts.
In these situations, the length generalization failure of LLMs on long
sequences become more prominent. Most pre-training schemes truncate training
sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to
generate fluent texts, let alone carry out downstream tasks, after longer
contexts, even with relative positional encoding which is designed to cope with
this problem. Common solutions such as finetuning on longer corpora often
involves daunting hardware and time costs and requires careful training process
design. To more efficiently leverage the generation capacity of existing LLMs,
we theoretically and empirically investigate the main out-of-distribution (OOD)
factors contributing to this problem. Inspired by this diagnosis, we propose a
simple yet effective solution for on-the-fly length generalization,
LM-Infinite, which involves only a $\Lambda$-shaped attention mask and a
distance limit while requiring no parameter updates or learning. We find it
applicable to a variety of LLMs using relative-position encoding methods.
LM-Infinite is computational efficient with $O(n)$ time and space, and
demonstrates consistent fluency and generation quality to as long as 32k tokens
on ArXiv and OpenWebText2 datasets, with 2.72x decoding speedup. On downstream
task such as passkey retrieval, it continues to work on inputs much longer than
training lengths where vanilla models fail immediately.
</p></li>
</ul>

<h3>Title: Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment. (arXiv:2308.16175v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16175">http://arxiv.org/abs/2308.16175</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16175]] Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment(http://arxiv.org/abs/2308.16175)</code></li>
<li>Summary: <p>We introduce BSDetector, a method for detecting bad and speculative answers
from a pretrained Large Language Model by estimating a numeric confidence score
for any output it generated. Our uncertainty quantification technique works for
any LLM accessible only via a black-box API, and combines intrinsic and
extrinsic assessments of confidence into a single trustworthiness estimate for
any LLM response to a given prompt. Our method is extremely general and can
applied to all of the best LLMs available today (whose training data remains
unknown). By expending a bit of extra computation, users of any LLM API can now
get the same response as they would ordinarily, as well as a confidence
estimate that caution when not to trust this response. Experiments on both
closed and open-form Question-Answer benchmarks reveal that BSDetector more
accurately identifies incorrect LLM responses than alternative uncertainty
estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple
responses from the LLM and considering the one with the highest confidence
score, we can additionally obtain more accurate responses from the same LLM,
without any extra training steps.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Shatter and Gather: Learning Referring Image Segmentation with Text Supervision. (arXiv:2308.15512v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15512">http://arxiv.org/abs/2308.15512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15512]] Shatter and Gather: Learning Referring Image Segmentation with Text Supervision(http://arxiv.org/abs/2308.15512)</code></li>
<li>Summary: <p>Referring image segmentation, the task of segmenting any arbitrary entities
described in free-form texts, opens up a variety of vision applications.
However, manual labeling of training data for this task is prohibitively
costly, leading to lack of labeled data for training. We address this issue by
a weakly supervised learning approach using text descriptions of training
images as the only source of supervision. To this end, we first present a new
model that discovers semantic entities in input image and then combines such
entities relevant to text query to predict the mask of the referent. We also
present a new loss function that allows the model to be trained without any
further supervision. Our method was evaluated on four public benchmarks for
referring image segmentation, where it clearly outperformed the existing method
for the same task and recent open-vocabulary segmentation models on all the
benchmarks.
</p></li>
</ul>

<h3>Title: Unveiling Camouflage: A Learnable Fourier-based Augmentation for Camouflaged Object Detection and Instance Segmentation. (arXiv:2308.15660v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15660">http://arxiv.org/abs/2308.15660</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15660]] Unveiling Camouflage: A Learnable Fourier-based Augmentation for Camouflaged Object Detection and Instance Segmentation(http://arxiv.org/abs/2308.15660)</code></li>
<li>Summary: <p>Camouflaged object detection (COD) and camouflaged instance segmentation
(CIS) aim to recognize and segment objects that are blended into their
surroundings, respectively. While several deep neural network models have been
proposed to tackle those tasks, augmentation methods for COD and CIS have not
been thoroughly explored. Augmentation strategies can help improve the
performance of models by increasing the size and diversity of the training data
and exposing the model to a wider range of variations in the data. Besides, we
aim to automatically learn transformations that help to reveal the underlying
structure of camouflaged objects and allow the model to learn to better
identify and segment camouflaged objects. To achieve this, we propose a
learnable augmentation method in the frequency domain for COD and CIS via
Fourier transform approach, dubbed CamoFourier. Our method leverages a
conditional generative adversarial network and cross-attention mechanism to
generate a reference image and an adaptive hybrid swapping with parameters to
mix the low-frequency component of the reference image and the high-frequency
component of the input image. This approach aims to make camouflaged objects
more visible for detection and segmentation models. Without bells and whistles,
our proposed augmentation method boosts the performance of camouflaged object
detectors and camouflaged instance segmenters by large margins.
</p></li>
</ul>

<h3>Title: CongNaMul: A Dataset for Advanced Image Processing of Soybean Sprouts. (arXiv:2308.15690v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15690">http://arxiv.org/abs/2308.15690</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15690]] CongNaMul: A Dataset for Advanced Image Processing of Soybean Sprouts(http://arxiv.org/abs/2308.15690)</code></li>
<li>Summary: <p>We present 'CongNaMul', a comprehensive dataset designed for various tasks in
soybean sprouts image analysis. The CongNaMul dataset is curated to facilitate
tasks such as image classification, semantic segmentation, decomposition, and
measurement of length and weight. The classification task provides four classes
to determine the quality of soybean sprouts: normal, broken, spotted, and
broken and spotted, for the development of AI-aided automatic quality
inspection technology. For semantic segmentation, images with varying
complexity, from single sprout images to images with multiple sprouts, along
with human-labelled mask images, are included. The label has 4 different
classes: background, head, body, tail. The dataset also provides images and
masks for the image decomposition task, including two separate sprout images
and their combined form. Lastly, 5 physical features of sprouts (head length,
body length, body thickness, tail length, weight) are provided for image-based
measurement tasks. This dataset is expected to be a valuable resource for a
wide range of research and applications in the advanced analysis of images of
soybean sprouts. Also, we hope that this dataset can assist researchers
studying classification, semantic segmentation, decomposition, and physical
feature measurement in other industrial fields, in evaluating their models. The
dataset is available at the authors' repository. (https://bhban.kr/data)
</p></li>
</ul>

<h3>Title: Beard Segmentation and Recognition Bias. (arXiv:2308.15740v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15740">http://arxiv.org/abs/2308.15740</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15740]] Beard Segmentation and Recognition Bias(http://arxiv.org/abs/2308.15740)</code></li>
<li>Summary: <p>A person's facial hairstyle, such as presence and size of beard, can
significantly impact face recognition accuracy. There are publicly-available
deep networks that achieve reasonable accuracy at binary attribute
classification, such as beard / no beard, but few if any that segment the
facial hair region. To investigate the effect of facial hair in a rigorous
manner, we first created a set of fine-grained facial hair annotations to train
a segmentation model and evaluate its accuracy across African-American and
Caucasian face images. We then use our facial hair segmentations to categorize
image pairs according to the degree of difference or similarity in the facial
hairstyle. We find that the False Match Rate (FMR) for image pairs with
different categories of facial hairstyle varies by a factor of over 10 for
African-American males and over 25 for Caucasian males. To reduce the bias
across image pairs with different facial hairstyles, we propose a scheme for
adaptive thresholding based on facial hairstyle similarity. Evaluation on a
subject-disjoint set of images shows that adaptive similarity thresholding
based on facial hairstyles of the image pair reduces the ratio between the
highest and lowest FMR across facial hairstyle categories for African-American
from 10.7 to 1.8 and for Caucasians from 25.9 to 1.3. Facial hair annotations
and facial hair segmentation model will be publicly available.
</p></li>
</ul>

<h3>Title: Semi-supervised Domain Adaptation with Inter and Intra-domain Mixing for Semantic Segmentation. (arXiv:2308.15855v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.15855">http://arxiv.org/abs/2308.15855</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.15855]] Semi-supervised Domain Adaptation with Inter and Intra-domain Mixing for Semantic Segmentation(http://arxiv.org/abs/2308.15855)</code></li>
<li>Summary: <p>Despite recent advances in semantic segmentation, an inevitable challenge is
the performance degradation caused by the domain shift in real application.
Current dominant approach to solve this problem is unsupervised domain
adaptation (UDA). However, the absence of labeled target data in UDA is overly
restrictive and limits performance. To overcome this limitation, a more
practical scenario called semi-supervised domain adaptation (SSDA) has been
proposed. Existing SSDA methods are derived from the UDA paradigm and primarily
focus on leveraging the unlabeled target data and source data. In this paper,
we highlight the significance of exploiting the intra-domain information
between the limited labeled target data and unlabeled target data, as it
greatly benefits domain adaptation. Instead of solely using the scarce labeled
data for supervision, we propose a novel SSDA framework that incorporates both
inter-domain mixing and intra-domain mixing, where inter-domain mixing
mitigates the source-target domain gap and intra-domain mixing enriches the
available target domain information. By simultaneously learning from
inter-domain mixing and intra-domain mixing, the network can capture more
domain-invariant features and promote its performance on the target domain. We
also explore different domain mixing operations to better exploit the target
domain information. Comprehensive experiments conducted on the GTA5toCityscapes
and SYNTHIA2Cityscapes benchmarks demonstrate the effectiveness of our method,
surpassing previous methods by a large margin.
</p></li>
</ul>

<h3>Title: SAM-Med2D. (arXiv:2308.16184v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.16184">http://arxiv.org/abs/2308.16184</a></li>
<li>Code URL: https://github.com/uni-medical/sam-med2d</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.16184]] SAM-Med2D(http://arxiv.org/abs/2308.16184)</code></li>
<li>Summary: <p>The Segment Anything Model (SAM) represents a state-of-the-art research
advancement in natural image segmentation, achieving impressive results with
input prompts such as points and bounding boxes. However, our evaluation and
recent research indicate that directly applying the pretrained SAM to medical
image segmentation does not yield satisfactory performance. This limitation
primarily arises from significant domain gap between natural images and medical
images. To bridge this gap, we introduce SAM-Med2D, the most comprehensive
studies on applying SAM to medical 2D images. Specifically, we first collect
and curate approximately 4.6M images and 19.7M masks from public and private
datasets, constructing a large-scale medical image segmentation dataset
encompassing various modalities and objects. Then, we comprehensively fine-tune
SAM on this dataset and turn it into SAM-Med2D. Unlike previous methods that
only adopt bounding box or point prompts as interactive segmentation approach,
we adapt SAM to medical image segmentation through more comprehensive prompts
involving bounding boxes, points, and masks. We additionally fine-tune the
encoder and decoder of the original SAM to obtain a well-performed SAM-Med2D,
leading to the most comprehensive fine-tuning strategies to date. Finally, we
conducted a comprehensive evaluation and analysis to investigate the
performance of SAM-Med2D in medical image segmentation across various
modalities, anatomical structures, and organs. Concurrently, we validated the
generalization capability of SAM-Med2D on 9 datasets from MICCAI 2023
challenge. Overall, our approach demonstrated significantly superior
performance and generalization capability compared to SAM.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
