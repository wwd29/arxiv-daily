<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-04-25</h1>
<h3>Title: Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity</h3>
<ul>
<li><strong>Authors: </strong>Cong Qi, Hanzhang Fang, Tianxing Hu, Siqi Jiang, Wei Zhi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, q-bio.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16956">https://arxiv.org/abs/2504.16956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16956">https://arxiv.org/pdf/2504.16956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16956]] Bidirectional Mamba for Single-Cell Data: Efficient Context Learning with Biological Fidelity(https://arxiv.org/abs/2504.16956)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Single-cell RNA sequencing (scRNA-seq) enables high-resolution analysis of cellular heterogeneity, but its complexity, which is marked by high dimensionality, sparsity, and batch effects, which poses major computational challenges. Transformer-based models have made significant advances in this domain but are often limited by their quadratic complexity and suboptimal handling of long-range dependencies. In this work, we introduce GeneMamba, a scalable and efficient foundation model for single-cell transcriptomics built on state space modeling. Leveraging the Bi-Mamba architecture, GeneMamba captures bidirectional gene context with linear-time complexity, offering substantial computational gains over transformer baselines. The model is pretrained on nearly 30 million cells and incorporates biologically informed objectives, including pathway-aware contrastive loss and rank-based gene encoding. We evaluate GeneMamba across diverse tasks, including multi-batch integration, cell type annotation, and gene-gene correlation, demonstrating strong performance, interpretability, and robustness. These results position GeneMamba as a practical and powerful alternative to transformer-based methods, advancing the development of biologically grounded, scalable tools for large-scale single-cell data analysis.</li>
</ul>

<h3>Title: A Novel Graph Transformer Framework for Gene Regulatory Network Inference</h3>
<ul>
<li><strong>Authors: </strong>Binon Teji, Swarup Roy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET, q-bio.GN, q-bio.MN, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16961">https://arxiv.org/abs/2504.16961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16961">https://arxiv.org/pdf/2504.16961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16961]] A Novel Graph Transformer Framework for Gene Regulatory Network Inference(https://arxiv.org/abs/2504.16961)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>The inference of gene regulatory networks (GRNs) is a foundational stride towards deciphering the fundamentals of complex biological systems. Inferring a possible regulatory link between two genes can be formulated as a link prediction problem. Inference of GRNs via gene coexpression profiling data may not always reflect true biological interactions, as its susceptibility to noise and misrepresenting true biological regulatory relationships. Most GRN inference methods face several challenges in the network reconstruction phase. Therefore, it is important to encode gene expression values, leverege the prior knowledge gained from the available inferred network structures and positional informations of the input network nodes towards inferring a better and more confident GRN network reconstruction. In this paper, we explore the integration of multiple inferred networks to enhance the inference of Gene Regulatory Networks (GRNs). Primarily, we employ autoencoder embeddings to capture gene expression patterns directly from raw data, preserving intricate biological signals. Then, we embed the prior knowledge from GRN structures transforming them into a text-like representation using random walks, which are then encoded with a masked language model, BERT, to generate global embeddings for each gene across all networks. Additionally, we embed the positional encodings of the input gene networks to better identify the position of each unique gene within the graph. These embeddings are integrated into graph transformer-based model, termed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the topological structure of the ground truth network while incorporating the enriched encoded information. Experimental results demonstrate that GT-GRN significantly outperforms existing GRN inference methods, achieving superior accuracy and highlighting the robustness of our approach.</li>
</ul>

<h3>Title: Backslash: Rate Constrained Optimized Training of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jun Wu, Jiangtao Wen, Yuxing Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16968">https://arxiv.org/abs/2504.16968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16968">https://arxiv.org/pdf/2504.16968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16968]] Backslash: Rate Constrained Optimized Training of Large Language Models(https://arxiv.org/abs/2504.16968)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large-language models (LLMs) has driven extensive research into parameter compression after training has been completed, yet compression during the training phase remains largely unexplored. In this work, we introduce Rate-Constrained Training (Backslash), a novel training-time compression approach based on rate-distortion optimization (RDO). Backslash enables a flexible trade-off between model accuracy and complexity, significantly reducing parameter redundancy while preserving performance. Experiments in various architectures and tasks demonstrate that Backslash can reduce memory usage by 60\% - 90\% without accuracy loss and provides significant compression gain compared to compression after training. Moreover, Backslash proves to be highly versatile: it enhances generalization with small Lagrange multipliers, improves model robustness to pruning (maintaining accuracy even at 80\% pruning rates), and enables network simplification for accelerated inference on edge devices.</li>
</ul>

<h3>Title: STFM: A Spatio-Temporal Information Fusion Model Based on Phase Space Reconstruction for Sea Surface Temperature Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yin Wang, Chunlin Gong, Xiang Wu, Hanleran Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16970">https://arxiv.org/abs/2504.16970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16970">https://arxiv.org/pdf/2504.16970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16970]] STFM: A Spatio-Temporal Information Fusion Model Based on Phase Space Reconstruction for Sea Surface Temperature Prediction(https://arxiv.org/abs/2504.16970)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The sea surface temperature (SST), a key environmental parameter, is crucial to optimizing production planning, making its accurate prediction a vital research topic. However, the inherent nonlinearity of the marine dynamic system presents significant challenges. Current forecasting methods mainly include physics-based numerical simulations and data-driven machine learning approaches. The former, while describing SST evolution through differential equations, suffers from high computational complexity and limited applicability, whereas the latter, despite its computational benefits, requires large datasets and faces interpretability challenges. This study presents a prediction framework based solely on data-driven techniques. Using phase space reconstruction, we construct initial-delay attractor pairs with a mathematical homeomorphism and design a Spatio-Temporal Fusion Mapping (STFM) to uncover their intrinsic connections. Unlike conventional models, our method captures SST dynamics efficiently through phase space reconstruction and achieves high prediction accuracy with minimal training data in comparative tests</li>
</ul>

<h3>Title: Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications</h3>
<ul>
<li><strong>Authors: </strong>Hossein Ahmadi, Sajjad Emdadi Mahdimahalleh, Arman Farahat, Banafsheh Saffari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16972">https://arxiv.org/abs/2504.16972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16972">https://arxiv.org/pdf/2504.16972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16972]] Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications(https://arxiv.org/abs/2504.16972)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The rapid growth of unlabeled time-series data in domains such as wireless communications, radar, biomedical engineering, and the Internet of Things (IoT) has driven advancements in unsupervised learning. This review synthesizes recent progress in applying autoencoders and vision transformers for unsupervised signal analysis, focusing on their architectures, applications, and emerging trends. We explore how these models enable feature extraction, anomaly detection, and classification across diverse signal types, including electrocardiograms, radar waveforms, and IoT sensor data. The review highlights the strengths of hybrid architectures and self-supervised learning, while identifying challenges in interpretability, scalability, and domain generalization. By bridging methodological innovations and practical applications, this work offers a roadmap for developing robust, adaptive models for signal intelligence.</li>
</ul>

<h3>Title: Tokenization Matters: Improving Zero-Shot NER for Indic Languages</h3>
<ul>
<li><strong>Authors: </strong>Priyaranjan Pattnayak, Hitesh Laxmichand Patel, Amit Agarwal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16977">https://arxiv.org/abs/2504.16977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16977">https://arxiv.org/pdf/2504.16977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16977]] Tokenization Matters: Improving Zero-Shot NER for Indic Languages(https://arxiv.org/abs/2504.16977)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Tokenization is a critical component of Natural Language Processing (NLP), especially for low resource languages, where subword segmentation influences vocabulary structure and downstream task accuracy. Although Byte Pair Encoding (BPE) is a standard tokenization method in multilingual language models, its suitability for Named Entity Recognition (NER) in low resource Indic languages remains underexplored due to its limitations in handling morphological complexity. In this work, we systematically compare BPE, SentencePiece, and Character Level tokenization strategies using IndicBERT for NER tasks in low resource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as extremely low resource Indic languages like Santali, Manipuri, and Sindhi. We assess both intrinsic linguistic properties tokenization efficiency, out of vocabulary (OOV) rates, and morphological preservation as well as extrinsic downstream performance, including fine tuning and zero shot cross lingual transfer. Our experiments show that SentencePiece is a consistently better performing approach than BPE for NER in low resource Indic Languages, particularly in zero shot cross lingual settings, as it better preserves entity consistency. While BPE provides the most compact tokenization form, it is not capable of generalization because it misclassifies or even fails to recognize entity labels when tested on unseen languages. In contrast, SentencePiece constitutes a better linguistic structural preservation model, benefiting extremely low resource and morphologically rich Indic languages, such as Santali and Manipuri, for superior entity recognition, as well as high generalization across scripts, such as Sindhi, written in Arabic. The results point to SentencePiece as the more effective tokenization strategy for NER within multilingual and low resource Indic NLP applications.</li>
</ul>

<h3>Title: Safety Pretraining: Toward the Next Generation of Safe AI</h3>
<ul>
<li><strong>Authors: </strong>Pratyush Maini, Sachin Goyal, Dylan Sam, Alex Robey, Yash Savani, Yiding Jiang, Andy Zou, Zacharcy C. Lipton, J. Zico Kolter</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.16980">https://arxiv.org/abs/2504.16980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.16980">https://arxiv.org/pdf/2504.16980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.16980]] Safety Pretraining: Toward the Next Generation of Safe AI(https://arxiv.org/abs/2504.16980)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are increasingly deployed in high-stakes settings, the risk of generating harmful or toxic content remains a central challenge. Post-hoc alignment methods are brittle: once unsafe patterns are learned during pretraining, they are hard to remove. We present a data-centric pretraining framework that builds safety into the model from the start. Our contributions include: (i) a safety classifier trained on 10,000 GPT-4 labeled examples, used to filter 600B tokens; (ii) the largest synthetic safety dataset to date (100B tokens) generated via recontextualization of harmful web data; (iii) RefuseWeb and Moral Education datasets that convert harmful prompts into refusal dialogues and web-style educational material; (iv) Harmfulness-Tag annotations injected during pretraining to flag unsafe content and steer away inference from harmful generations; and (v) safety evaluations measuring base model behavior before instruction tuning. Our safety-pretrained models reduce attack success rates from 38.8% to 8.4% with no performance degradation on standard LLM safety benchmarks.</li>
</ul>

<h3>Title: (Im)possibility of Automated Hallucination Detection in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Amin Karbasi, Omar Montasser, John Sous, Grigoris Velegkas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17004">https://arxiv.org/abs/2504.17004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17004">https://arxiv.org/pdf/2504.17004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17004]] (Im)possibility of Automated Hallucination Detection in Large Language Models(https://arxiv.org/abs/2504.17004)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Is automated hallucination detection possible? In this work, we introduce a theoretical framework to analyze the feasibility of automatically detecting hallucinations produced by large language models (LLMs). Inspired by the classical Gold-Angluin framework for language identification and its recent adaptation to language generation by Kleinberg and Mullainathan, we investigate whether an algorithm, trained on examples drawn from an unknown target language $K$ (selected from a countable collection) and given access to an LLM, can reliably determine whether the LLM's outputs are correct or constitute hallucinations. First, we establish an equivalence between hallucination detection and the classical task of language identification. We prove that any hallucination detection method can be converted into a language identification method, and conversely, algorithms solving language identification can be adapted for hallucination detection. Given the inherent difficulty of language identification, this implies that hallucination detection is fundamentally impossible for most language collections if the detector is trained using only correct examples from the target language. Second, we show that the use of expert-labeled feedback, i.e., training the detector with both positive examples (correct statements) and negative examples (explicitly labeled incorrect statements), dramatically changes this conclusion. Under this enriched training regime, automated hallucination detection becomes possible for all countable language collections. These results highlight the essential role of expert-labeled examples in training hallucination detectors and provide theoretical support for feedback-based methods, such as reinforcement learning with human feedback (RLHF), which have proven critical for reliable LLM deployment.</li>
</ul>

<h3>Title: Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Luca Moroni, Giovanni Puccetti, Pere-Lluis Huguet Cabot, Andrei Stefan Bejgu, Edoardo Barba, Alessio Miaschi, Felice Dell'Orletta, Andrea Esuli, Roberto Navigli</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17025">https://arxiv.org/abs/2504.17025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17025">https://arxiv.org/pdf/2504.17025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17025]] Optimizing LLMs for Italian: Reducing Token Fertility and Enhancing Efficiency Through Vocabulary Adaptation(https://arxiv.org/abs/2504.17025)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The number of pretrained Large Language Models (LLMs) is increasing steadily, though the majority are designed predominantly for the English language. While state-of-the-art LLMs can handle other languages, due to language contamination or some degree of multilingual pretraining data, they are not optimized for non-English languages, leading to inefficient encoding (high token "fertility") and slower inference speed. In this work, we thoroughly compare a variety of vocabulary adaptation techniques for optimizing English LLMs for the Italian language, and put forward Semantic Alignment Vocabulary Adaptation (SAVA), a novel method that leverages neural mapping for vocabulary substitution. SAVA achieves competitive performance across multiple downstream tasks, enhancing grounded alignment strategies. We adapt two LLMs: Mistral-7b-v0.1, reducing token fertility by 25\%, and Llama-3.1-8B, optimizing the vocabulary and reducing the number of parameters by 1 billion. We show that, following the adaptation of the vocabulary, these models can recover their performance with a relatively limited stage of continual training on the target language. Finally, we test the capabilities of the adapted models on various multi-choice and generative tasks.</li>
</ul>

<h3>Title: Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data</h3>
<ul>
<li><strong>Authors: </strong>Ruben Gonzalez Avilés, Linus Scheibenreif, Damian Borth</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17039">https://arxiv.org/abs/2504.17039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17039">https://arxiv.org/pdf/2504.17039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17039]] Dense Air Pollution Estimation from Sparse in-situ Measurements and Satellite Data(https://arxiv.org/abs/2504.17039)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper addresses the critical environmental challenge of estimating ambient Nitrogen Dioxide (NO$_2$) concentrations, a key issue in public health and environmental policy. Existing methods for satellite-based air pollution estimation model the relationship between satellite and in-situ measurements at select point locations. While these approaches have advanced our ability to provide air quality estimations on a global scale, they come with inherent limitations. The most notable limitation is the computational intensity required for generating comprehensive estimates over extensive areas. Motivated by these limitations, this study introduces a novel dense estimation technique. Our approach seeks to balance the accuracy of high-resolution estimates with the practicality of computational constraints, thereby enabling efficient and scalable global environmental assessment. By utilizing a uniformly random offset sampling strategy, our method disperses the ground truth data pixel location evenly across a larger patch. At inference, the dense estimation method can then generate a grid of estimates in a single step, significantly reducing the computational resources required to provide estimates for larger areas. Notably, our approach also surpasses the results of existing point-wise methods by a significant margin of $9.45\%$, achieving a Mean Absolute Error (MAE) of $4.98\ \mu\text{g}/\text{m}^3$. This demonstrates both high accuracy and computational efficiency, highlighting the applicability of our method for global environmental assessment. Furthermore, we showcase the method's adaptability and robustness by applying it to diverse geographic regions. Our method offers a viable solution to the computational challenges of large-scale environmental monitoring.</li>
</ul>

<h3>Title: DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs</h3>
<ul>
<li><strong>Authors: </strong>Zhenhailong Wang, Senthil Purushwalkam, Caiming Xiong, Silvio Savarese, Heng Ji, Ran Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17040">https://arxiv.org/abs/2504.17040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17040">https://arxiv.org/pdf/2504.17040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17040]] DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs(https://arxiv.org/abs/2504.17040)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We present DyMU, an efficient, training-free framework that dynamically reduces the computational burden of vision-language models (VLMs) while maintaining high task performance. Our approach comprises two key components. First, Dynamic Token Merging (DToMe) reduces the number of visual token embeddings by merging similar tokens based on image complexity, addressing the inherent inefficiency of fixed-length outputs in vision transformers. Second, Virtual Token Unmerging (VTU) simulates the expected token sequence for large language models (LLMs) by efficiently reconstructing the attention dynamics of a full sequence, thus preserving the downstream performance without additional fine-tuning. Unlike previous approaches, our method dynamically adapts token compression to the content of the image and operates completely training-free, making it readily applicable to most state-of-the-art VLM architectures. Extensive experiments on image and video understanding tasks demonstrate that DyMU can reduce the average visual token count by 32%-85% while achieving comparable performance to full-length models across diverse VLM architectures, including the recently popularized AnyRes-based visual encoders. Furthermore, through qualitative analyses, we demonstrate that DToMe effectively adapts token reduction based on image complexity and, unlike existing systems, provides users more control over computational costs. Project page: this https URL.</li>
</ul>

<h3>Title: Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shariar Kabir, Kevin Esterling, Yue Dong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17052">https://arxiv.org/abs/2504.17052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17052">https://arxiv.org/pdf/2504.17052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17052]] Do Words Reflect Beliefs? Evaluating Belief Depth in Large Language Models(https://arxiv.org/abs/2504.17052)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly shaping political discourse, yet their responses often display inconsistency when subjected to scrutiny. While prior research has primarily categorized LLM outputs as left- or right-leaning to assess their political stances, a critical question remains: Do these responses reflect genuine internal beliefs or merely surface-level alignment with training data? To address this, we propose a novel framework for evaluating belief depth by analyzing (1) argumentative consistency and (2) uncertainty quantification. We evaluate 12 LLMs on 19 economic policies from the Political Compass Test, challenging their belief stability with both supportive and opposing arguments. Our analysis reveals that LLMs exhibit topic-specific belief stability rather than a uniform ideological stance. Notably, up to 95% of left-leaning models' responses and 89% of right-leaning models' responses remain consistent under the challenge, enabling semantic entropy to achieve high accuracy (AUROC=0.78), effectively distinguishing between surface-level alignment from genuine belief. These findings call into question the assumption that LLMs maintain stable, human-like political ideologies, emphasizing the importance of conducting topic-specific reliability assessments for real-world applications.</li>
</ul>

<h3>Title: Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation</h3>
<ul>
<li><strong>Authors: </strong>Rahul Vishwakarma</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17058">https://arxiv.org/abs/2504.17058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17058">https://arxiv.org/pdf/2504.17058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17058]] Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation(https://arxiv.org/abs/2504.17058)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The generation of high-quality synthetic data presents significant challenges in machine learning research, particularly regarding statistical fidelity and uncertainty quantification. Existing generative models produce compelling synthetic samples but lack rigorous statistical guarantees about their relation to the underlying data distribution, limiting their applicability in critical domains requiring robust error bounds. We address this fundamental limitation by presenting a novel framework that incorporates conformal prediction methodologies into Generative Adversarial Networks (GANs). By integrating multiple conformal prediction paradigms including Inductive Conformal Prediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction, and Venn-Abers Predictors, we establish distribution-free uncertainty quantification in generated samples. This approach, termed Conformalized GAN (cGAN), demonstrates enhanced calibration properties while maintaining the generative power of traditional GANs, producing synthetic data with provable statistical guarantees. We provide rigorous mathematical proofs establishing finite-sample validity guarantees and asymptotic efficiency properties, enabling the reliable application of synthetic data in high-stakes domains including healthcare, finance, and autonomous systems.</li>
</ul>

<h3>Title: Integrating Graph Theoretical Approaches in Cybersecurity Education CSCI-RTED</h3>
<ul>
<li><strong>Authors: </strong>Goksel Kucukkaya, Murat Ozer, Kazim Ciris</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17059">https://arxiv.org/abs/2504.17059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17059">https://arxiv.org/pdf/2504.17059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17059]] Integrating Graph Theoretical Approaches in Cybersecurity Education CSCI-RTED(https://arxiv.org/abs/2504.17059)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As cybersecurity threats continue to evolve, the need for advanced tools to analyze and understand complex cyber environments has become increasingly critical. Graph theory offers a powerful framework for modeling relationships within cyber ecosystems, making it highly applicable to cybersecurity. This paper focuses on the development of an enriched version of the widely recognized NSL-KDD dataset, incorporating graph-theoretical concepts to enhance its practical value. The enriched dataset provides a resource for students and professionals to engage in hands-on analysis, enabling them to explore graph-based methodologies for identifying network behavior and vulnerabilities. To validate the effectiveness of this dataset, we employed IBM Auto AI, demonstrating its capability in real-world applications such as classification and threat prediction. By addressing the need for graph-theoretical datasets, this study provides a practical tool for equipping future cybersecurity professionals with the skills necessary to confront complex cyber challenges.</li>
</ul>

<h3>Title: Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching</h3>
<ul>
<li><strong>Authors: </strong>Kewen Peng, Yicheng Yang, Hao Zhuo, Tim Menzies</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY, cs.SE, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17066">https://arxiv.org/abs/2504.17066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17066">https://arxiv.org/pdf/2504.17066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17066]] Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching(https://arxiv.org/abs/2504.17066)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair</a></li>
<li><strong>Abstract: </strong>Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance.</li>
</ul>

<h3>Title: PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation</h3>
<ul>
<li><strong>Authors: </strong>Xinqi Xiong, Andrea Dunn Beltran, Jun Myeong Choi, Marc Niethammer, Roni Sengupta</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17067">https://arxiv.org/abs/2504.17067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17067">https://arxiv.org/pdf/2504.17067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17067]] PPS-Ctrl: Controllable Sim-to-Real Translation for Colonoscopy Depth Estimation(https://arxiv.org/abs/2504.17067)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Accurate depth estimation enhances endoscopy navigation and diagnostics, but obtaining ground-truth depth in clinical settings is challenging. Synthetic datasets are often used for training, yet the domain gap limits generalization to real data. We propose a novel image-to-image translation framework that preserves structure while generating realistic textures from clinical data. Our key innovation integrates Stable Diffusion with ControlNet, conditioned on a latent representation extracted from a Per-Pixel Shading (PPS) map. PPS captures surface lighting effects, providing a stronger structural constraint than depth maps. Experiments show our approach produces more realistic translations and improves depth estimation over GAN-based MI-CycleGAN. Our code is publicly accessible at this https URL.</li>
</ul>

<h3>Title: In-Context Learning can distort the relationship between sequence likelihoods and biological fitness</h3>
<ul>
<li><strong>Authors: </strong>Pranav Kantroo, Günter P. Wagner, Benjamin B. Machta</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17068">https://arxiv.org/abs/2504.17068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17068">https://arxiv.org/pdf/2504.17068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17068]] In-Context Learning can distort the relationship between sequence likelihoods and biological fitness(https://arxiv.org/abs/2504.17068)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Language models have emerged as powerful predictors of the viability of biological sequences. During training these models learn the rules of the grammar obeyed by sequences of amino acids or nucleotides. Once trained, these models can take a sequence as input and produce a likelihood score as an output; a higher likelihood implies adherence to the learned grammar and correlates with experimental fitness measurements. Here we show that in-context learning can distort the relationship between fitness and likelihood scores of sequences. This phenomenon most prominently manifests as anomalously high likelihood scores for sequences that contain repeated motifs. We use protein language models with different architectures trained on the masked language modeling objective for our experiments, and find transformer-based models to be particularly vulnerable to this effect. This behavior is mediated by a look-up operation where the model seeks the identity of the masked position by using the other copy of the repeated motif as a reference. This retrieval behavior can override the model's learned priors. This phenomenon persists for imperfectly repeated sequences, and extends to other kinds of biologically relevant features such as reversed complement motifs in RNA sequences that fold into hairpin structures.</li>
</ul>

<h3>Title: Sparse Phased Array Optimization Using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>David Lu, Lior Maman, Jackson Earls, Amir Boag, Pierre Baldi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17073">https://arxiv.org/abs/2504.17073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17073">https://arxiv.org/pdf/2504.17073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17073]] Sparse Phased Array Optimization Using Deep Learning(https://arxiv.org/abs/2504.17073)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>Antenna arrays are widely used in wireless communication, radar systems, radio astronomy, and military defense to enhance signal strength, directivity, and interference suppression. We introduce a deep learning-based optimization approach that enhances the design of sparse phased arrays by reducing grating lobes. This approach begins by generating sparse array configurations to address the non-convex challenges and extensive degrees of freedom inherent in array design. We use neural networks to approximate the non-convex cost function that estimates the energy ratio between the main and side lobes. This differentiable approximation facilitates cost function minimization through gradient descent, optimizing the antenna elements' coordinates and leading to an improved layout. Additionally, we incorporate a tailored penalty mechanism that includes various physical and design constraints into the optimization process, enhancing its robustness and practical applicability. We demonstrate the effectiveness of our method by applying it to the ten array configurations with the lowest initial costs, achieving further cost reductions ranging from 411% to 643%, with an impressive average improvement of 552%. By significantly reducing side lobe levels in antenna arrays, this breakthrough paves the way for ultra-precise beamforming, enhanced interference mitigation, and next-generation wireless and radar systems with unprecedented efficiency and clarity.</li>
</ul>

<h3>Title: Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy</h3>
<ul>
<li><strong>Authors: </strong>William R. Keely, Otto Lamminpää, Steffen Mauceri, Sean M. R. Crowell, Christopher W. O'Dell, Gregory R. McGarragh</a></li>
<li><strong>Subjects: </strong>cs.LG, astro-ph.IM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17074">https://arxiv.org/abs/2504.17074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17074">https://arxiv.org/pdf/2504.17074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17074]] Conditional Diffusion-Based Retrieval of Atmospheric CO2 from Earth Observing Spectroscopy(https://arxiv.org/abs/2504.17074)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Satellite-based estimates of greenhouse gas (GHG) properties from observations of reflected solar spectra are integral for understanding and monitoring complex terrestrial systems and their impact on the carbon cycle due to their near global coverage. Known as retrieval, making GHG concentration estimations from these observations is a non-linear Bayesian inverse problem, which is operationally solved using a computationally expensive algorithm called Optimal Estimation (OE), providing a Gaussian approximation to a non-Gaussian posterior. This leads to issues in solver algorithm convergence, and to unrealistically confident uncertainty estimates for the retrieved quantities. Upcoming satellite missions will provide orders of magnitude more data than the current constellation of GHG observers. Development of fast and accurate retrieval algorithms with robust uncertainty quantification is critical. Doing so stands to provide substantial climate impact of moving towards the goal of near continuous real-time global monitoring of carbon sources and sinks which is essential for policy making. To achieve this goal, we propose a diffusion-based approach to flexibly retrieve a Gaussian or non-Gaussian posterior, for NASA's Orbiting Carbon Observatory-2 spectrometer, while providing a substantial computational speed-up over the current operational state-of-the-art.</li>
</ul>

<h3>Title: Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jens Petersen, Davide Abati, Amirhossein Habibian, Auke Wiggers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17076">https://arxiv.org/abs/2504.17076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17076">https://arxiv.org/pdf/2504.17076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17076]] Scene-Aware Location Modeling for Data Augmentation in Automotive Object Detection(https://arxiv.org/abs/2504.17076)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Generative image models are increasingly being used for training data augmentation in vision tasks. In the context of automotive object detection, methods usually focus on producing augmented frames that look as realistic as possible, for example by replacing real objects with generated ones. Others try to maximize the diversity of augmented frames, for example by pasting lots of generated objects onto existing backgrounds. Both perspectives pay little attention to the locations of objects in the scene. Frame layouts are either reused with little or no modification, or they are random and disregard realism entirely. In this work, we argue that optimal data augmentation should also include realistic augmentation of layouts. We introduce a scene-aware probabilistic location model that predicts where new objects can realistically be placed in an existing scene. By then inpainting objects in these locations with a generative model, we obtain much stronger augmentation performance than existing approaches. We set a new state of the art for generative data augmentation on two automotive object detection tasks, achieving up to $2.8\times$ higher gains than the best competing approach ($+1.4$ vs. $+0.5$ mAP boost). We also demonstrate significant improvements for instance segmentation.</li>
</ul>

<h3>Title: A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices</h3>
<ul>
<li><strong>Authors: </strong>Esam Mahdi, C. Martin-Barreiro, X. Cabezas</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17079">https://arxiv.org/abs/2504.17079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17079">https://arxiv.org/pdf/2504.17079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17079]] A Novel Hybrid Approach Using an Attention-Based Transformer + GRU Model for Predicting Cryptocurrency Prices(https://arxiv.org/abs/2504.17079)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this article, we introduce a novel deep learning hybrid model that integrates attention Transformer and Gated Recurrent Unit (GRU) architectures to improve the accuracy of cryptocurrency price predictions. By combining the Transformer's strength in capturing long-range patterns with the GRU's ability to model short-term and sequential trends, the hybrid model provides a well-rounded approach to time series forecasting. We apply the model to predict the daily closing prices of Bitcoin and Ethereum based on historical data that include past prices, trading volumes, and the Fear and Greed index. We evaluate the performance of our proposed model by comparing it with four other machine learning models: two are non-sequential feedforward models: Radial Basis Function Network (RBFN) and General Regression Neural Network (GRNN), and two are bidirectional sequential memory-based models: Bidirectional Long-Short-Term Memory (BiLSTM) and Bidirectional Gated Recurrent Unit (BiGRU). The performance of the model is assessed using several metrics, including Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE), along with statistical validation through the nonparametric Friedman test followed by a post hoc Wilcoxon signed rank test. The results demonstrate that our hybrid model consistently achieves superior accuracy, highlighting its effectiveness for financial prediction tasks. These findings provide valuable insights for improving real-time decision making in cryptocurrency markets and support the growing use of hybrid deep learning models in financial analytics.</li>
</ul>

<h3>Title: Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Seunghyun Yoo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17091">https://arxiv.org/abs/2504.17091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17091">https://arxiv.org/pdf/2504.17091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17091]] Co-CoT: A Prompt-Based Framework for Collaborative Chain-of-Thought Reasoning(https://arxiv.org/abs/2504.17091)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, explainability</a></li>
<li><strong>Abstract: </strong>Due to the proliferation of short-form content and the rapid adoption of AI, opportunities for deep, reflective thinking have significantly diminished, undermining users' critical thinking and reducing engagement with the reasoning behind AI-generated outputs. To address this issue, we propose an Interactive Chain-of-Thought (CoT) Framework that enhances human-centered explainability and responsible AI usage by making the model's inference process transparent, modular, and user-editable. The framework decomposes reasoning into clearly defined blocks that users can inspect, modify, and re-execute, encouraging active cognitive engagement rather than passive consumption. It further integrates a lightweight edit-adaptation mechanism inspired by preference learning, allowing the system to align with diverse cognitive styles and user intentions. Ethical transparency is ensured through explicit metadata disclosure, built-in bias checkpoint functionality, and privacy-preserving safeguards. This work outlines the design principles and architecture necessary to promote critical engagement, responsible interaction, and inclusive adaptation in AI systems aimed at addressing complex societal challenges.</li>
</ul>

<h3>Title: The Rise of Small Language Models in Healthcare: A Comprehensive Survey</h3>
<ul>
<li><strong>Authors: </strong>Muskan Garg, Shaina Raza, Shebuti Rayana, Xingyi Liu, Sunghwan Sohn</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17119">https://arxiv.org/abs/2504.17119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17119">https://arxiv.org/pdf/2504.17119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17119]] The Rise of Small Language Models in Healthcare: A Comprehensive Survey(https://arxiv.org/abs/2504.17119)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Despite substantial progress in healthcare applications driven by large language models (LLMs), growing concerns around data privacy, and limited resources; the small language models (SLMs) offer a scalable and clinically viable solution for efficient performance in resource-constrained environments for next-generation healthcare informatics. Our comprehensive survey presents a taxonomic framework to identify and categorize them for healthcare professionals and informaticians. The timeline of healthcare SLM contributions establishes a foundational framework for analyzing models across three dimensions: NLP tasks, stakeholder roles, and the continuum of care. We present a taxonomic framework to identify the architectural foundations for building models from scratch; adapting SLMs to clinical precision through prompting, instruction fine-tuning, and reasoning; and accessibility and sustainability through compression techniques. Our primary objective is to offer a comprehensive survey for healthcare professionals, introducing recent innovations in model optimization and equipping them with curated resources to support future research and development in the field. Aiming to showcase the groundbreaking advancements in SLMs for healthcare, we present a comprehensive compilation of experimental results across widely studied NLP tasks in healthcare to highlight the transformative potential of SLMs in healthcare. The updated repository is available at Github</li>
</ul>

<h3>Title: Evaluating Argon2 Adoption and Effectiveness in Real-World Software</h3>
<ul>
<li><strong>Authors: </strong>Pascal Tippe, Michael P. Berner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17121">https://arxiv.org/abs/2504.17121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17121">https://arxiv.org/pdf/2504.17121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17121]] Evaluating Argon2 Adoption and Effectiveness in Real-World Software(https://arxiv.org/abs/2504.17121)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Modern password hashing remains a critical defense against credential cracking, yet the transition from theoretically secure algorithms to robust real-world implementations remains fraught with challenges. This paper presents a dual analysis of Argon2, the Password Hashing Competition winner, combining attack simulations quantifying how parameter configurations impact guessing costs under realistic budgets, with the first large-scale empirical study of Argon2 adoption across public GitHub software repositories. Our economic model, validated against cryptocurrency mining benchmarks, demonstrates that OWASP's recommended 46 MiB configuration reduces compromise rates by 42.5% compared to SHA-256 at \$1/account attack budgets for strong user passwords. However, memory-hardness exhibits diminishing returns as increasing allocations to RFC 9106's 2048 MiB provides just 23.3% (\$1) and 17.7% (\$20) additional protection despite 44.5 times greater memory demands. Crucially, both configurations fail to mitigate risks from weak passwords, with 96.9-99.8% compromise rates for RockYou-like credentials regardless of algorithm choice. Our repository analysis shows accelerating Argon2 adoption, yet weak configuration practices: 46.6% of deployments use weaker-than-OWASP parameters. Surprisingly, sensitive applications (password managers, encryption tools) show no stronger configurations than general software. Our findings highlight that a secure algorithm alone cannot ensure security, effective parameter guidance and developer education remain essential for realizing Argon2's theoretical advantages.</li>
</ul>

<h3>Title: Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control</h3>
<ul>
<li><strong>Authors: </strong>Hannah Cyberey, David Evans</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17130">https://arxiv.org/abs/2504.17130</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17130">https://arxiv.org/pdf/2504.17130</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17130]] Steering the CensorShip: Uncovering Representation Vectors for LLM "Thought" Control(https://arxiv.org/abs/2504.17130)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this "censorship" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through "thought suppression". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector</li>
</ul>

<h3>Title: MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Chanhee Park, Hyeonseok Moon, Chanjun Park, Heuiseok Lim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17137">https://arxiv.org/abs/2504.17137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17137">https://arxiv.org/pdf/2504.17137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17137]] MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation(https://arxiv.org/abs/2504.17137)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\footnote{The MIRAGE code and data are available at this https URL.</li>
</ul>

<h3>Title: P$_\ell$-Kyber: Packing $\ell$ Plaintexts and Lattice Coding for Kyber</h3>
<ul>
<li><strong>Authors: </strong>Shuiyin Liu, Amin Sakzad</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17185">https://arxiv.org/abs/2504.17185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17185">https://arxiv.org/pdf/2504.17185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17185]] P$_\ell$-Kyber: Packing $\ell$ Plaintexts and Lattice Coding for Kyber(https://arxiv.org/abs/2504.17185)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>In this work, we propose a joint design of encoding and encryption processes for KEMs like Kyber, without assuming the independence of the decoding noise entries. Our design features two techniques: ciphertext packing and lattice packing. First, we extend the Peikert-Vaikuntanathan-Waters (PVW) method to the Kyber: $\ell$ plaintexts are packed into a single ciphertext. This scheme is referred to as P$_\ell$-Kyber. We prove that the P$_\ell$-Kyber is IND-CCA secure under the M-LWE hardness assumption. We show that the decryption decoding noise entries across the $\ell$ plaintexts (also known as layers) are mutually independent. Second, we propose a cross-layer lattice encoding scheme for the P$_\ell$-Kyber, where every $\ell$ cross-layer information symbols are encoded to a lattice point. This way we obtain a \emph{coded} P$_\ell$-Kyber, where the decoding noise entries for each lattice point are mutually independent. Therefore, the decryption failure rate (DFR) analysis does not require the assumption of independence among the decryption decoding noise entries. Both DFR and communication cost (CER) are greatly decreased thanks to ciphertext packing and lattice packing. Finally, we demonstrate that with $\ell=24$ and Leech lattice encoder, the proposed coded P$_\ell$-KYBER1024 achieves DFR $<2^{-281}$ and CER $ = 4.6$, i.e., a decrease of CER by $90\%$ compared to KYBER1024.</li>
</ul>

<h3>Title: Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17192">https://arxiv.org/abs/2504.17192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17192">https://arxiv.org/pdf/2504.17192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17192]] Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning(https://arxiv.org/abs/2504.17192)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, specifically from the original paper authors, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins.</li>
</ul>

<h3>Title: Developing a Blockchain-Based Secure Digital Contents Distribution System</h3>
<ul>
<li><strong>Authors: </strong>Syed Mohiuddin Qadri, Sangwhan Cha</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17194">https://arxiv.org/abs/2504.17194</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17194">https://arxiv.org/pdf/2504.17194</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17194]] Developing a Blockchain-Based Secure Digital Contents Distribution System(https://arxiv.org/abs/2504.17194)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect</a></li>
<li><strong>Abstract: </strong>As digital content distribution expands rapidly through online platforms, securing digital media and protecting intellectual property has become increasingly complex. Traditional centralized systems, while widely adopted, suffer from vulnerabilities such as single points of failure and limited traceability of unauthorized access. This paper presents a blockchain-based secure digital content distribution system that integrates Sia, a decentralized storage network, and Skynet, a content delivery network, to enhance content protection and distribution. The proposed system employs a dual-layer architecture: off-chain for user authentication and on-chain for transaction validation using smart contracts and asymmetric encryption. By introducing a license issuance and secret block mechanism, the system ensures content authenticity, privacy, and controlled access. Experimental results demonstrate the feasibility and scalability of the system in securely distributing multimedia files. The proposed platform not only improves content security but also paves the way for future enhancements with decentralized applications and integrated royalty payment mechanisms.</li>
</ul>

<h3>Title: A Double-Norm Aggregated Tensor Latent Factorization Model for Temporal-Aware Traffic Speed Imputation</h3>
<ul>
<li><strong>Authors: </strong>Jiawen Hou, Hao Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17196">https://arxiv.org/abs/2504.17196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17196">https://arxiv.org/pdf/2504.17196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17196]] A Double-Norm Aggregated Tensor Latent Factorization Model for Temporal-Aware Traffic Speed Imputation(https://arxiv.org/abs/2504.17196)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In intelligent transportation systems (ITS), traffic management departments rely on sensors, cameras, and GPS devices to collect real-time traffic data. Traffic speed data is often incomplete due to sensor failures, data transmission delays, or occlusions, resulting in missing speed data in certain road segments. Currently, tensor decomposition based methods are extensively utilized, they mostly rely on the $L_2$-norm to construct their learning objectives, which leads to reduced robustness in the algorithms. To address this, we propose Temporal-Aware Traffic Speed Imputation (TATSI), which combines the $L_2$-norm and smooth $L_1$ (${SL}_1$)-norm in its loss function, thereby achieving both high accuracy and robust performance in imputing missing time-varying traffic speed data. TATSI adopts a single latent factor-dependent, nonnegative, and multiplicative update (SLF-NMU) approach, which serves as an efficient solver for performing nonnegative latent factor analysis (LFA) on a tensor. Empirical studies on three real-world time-varying traffic speed datasets demonstrate that, compared with state-of-the-art traffic speed predictors, TATSI more precisely captures temporal patterns, thereby yielding the most accurate imputations for missing traffic speed data.</li>
</ul>

<h3>Title: A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, Joshua David Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. Ross Alexander, Robert B. Ross, Yan Feng, Leslie-Anne Levy, Weijie Su, Camillo J. Taylor</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17200">https://arxiv.org/abs/2504.17200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17200">https://arxiv.org/pdf/2504.17200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17200]] A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation(https://arxiv.org/abs/2504.17200)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.</li>
</ul>

<h3>Title: Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation</h3>
<ul>
<li><strong>Authors: </strong>Phillip Y. Lee, Jihyeon Je, Chanho Park, Mikaela Angelina Uy, Leonidas Guibas, Minhyuk Sung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17207">https://arxiv.org/abs/2504.17207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17207">https://arxiv.org/pdf/2504.17207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17207]] Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation(https://arxiv.org/abs/2504.17207)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.</li>
</ul>

<h3>Title: Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models</h3>
<ul>
<li><strong>Authors: </strong>Junfei Wang, Darshana Upadhyay, Marzia Zaman, Pirathayini Srikantha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17210">https://arxiv.org/abs/2504.17210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17210">https://arxiv.org/pdf/2504.17210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17210]] Synthetic Power Flow Data Generation Using Physics-Informed Denoising Diffusion Probabilistic Models(https://arxiv.org/abs/2504.17210)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Many data-driven modules in smart grid rely on access to high-quality power flow data; however, real-world data are often limited due to privacy and operational constraints. This paper presents a physics-informed generative framework based on Denoising Diffusion Probabilistic Models (DDPMs) for synthesizing feasible power flow data. By incorporating auxiliary training and physics-informed loss functions, the proposed method ensures that the generated data exhibit both statistical fidelity and adherence to power system feasibility. We evaluate the approach on the IEEE 14-bus and 30-bus benchmark systems, demonstrating its ability to capture key distributional properties and generalize to out-of-distribution scenarios. Comparative results show that the proposed model outperforms three baseline models in terms of feasibility, diversity, and accuracy of statistical features. This work highlights the potential of integrating generative modelling into data-driven power system applications.</li>
</ul>

<h3>Title: Enhancing Variational Autoencoders with Smooth Robust Latent Encoding</h3>
<ul>
<li><strong>Authors: </strong>Hyomin Lee, Minseon Kim, Sangwon Jang, Jongheon Jeong, Sung Ju Hwang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17219">https://arxiv.org/abs/2504.17219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17219">https://arxiv.org/pdf/2504.17219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17219]] Enhancing Variational Autoencoders with Smooth Robust Latent Encoding(https://arxiv.org/abs/2504.17219)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Variational Autoencoders (VAEs) have played a key role in scaling up diffusion-based generative models, as in Stable Diffusion, yet questions regarding their robustness remain largely underexplored. Although adversarial training has been an established technique for enhancing robustness in predictive models, it has been overlooked for generative models due to concerns about potential fidelity degradation by the nature of trade-offs between performance and robustness. In this work, we challenge this presumption, introducing Smooth Robust Latent VAE (SRL-VAE), a novel adversarial training framework that boosts both generation quality and robustness. In contrast to conventional adversarial training, which focuses on robustness only, our approach smooths the latent space via adversarial perturbations, promoting more generalizable representations while regularizing with originality representation to sustain original fidelity. Applied as a post-training step on pre-trained VAEs, SRL-VAE improves image robustness and fidelity with minimal computational overhead. Experiments show that SRL-VAE improves both generation quality, in image reconstruction and text-guided image editing, and robustness, against Nightshade attacks and image editing attacks. These results establish a new paradigm, showing that adversarial training, once thought to be detrimental to generative models, can instead enhance both fidelity and robustness.</li>
</ul>

<h3>Title: Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?</h3>
<ul>
<li><strong>Authors: </strong>Kaidong Feng, Zhu Sun, Jie Yang, Hui Fang, Xinghua Qu, Wenyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17220">https://arxiv.org/abs/2504.17220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17220">https://arxiv.org/pdf/2504.17220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17220]] Does Knowledge Distillation Matter for Large Language Model based Bundle Generation?(https://arxiv.org/abs/2504.17220)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>LLMs are increasingly explored for bundle generation, thanks to their reasoning capabilities and knowledge. However, deploying large-scale LLMs introduces significant efficiency challenges, primarily high computational costs during fine-tuning and inference due to their massive parameterization. Knowledge distillation (KD) offers a promising solution, transferring expertise from large teacher models to compact student models. This study systematically investigates knowledge distillation approaches for bundle generation, aiming to minimize computational demands while preserving performance. We explore three critical research questions: (1) how does the format of KD impact bundle generation performance? (2) to what extent does the quantity of distilled knowledge influence performance? and (3) how do different ways of utilizing the distilled knowledge affect performance? We propose a comprehensive KD framework that (i) progressively extracts knowledge (patterns, rules, deep thoughts); (ii) captures varying quantities of distilled knowledge through different strategies; and (iii) exploits complementary LLM adaptation techniques (in-context learning, supervised fine-tuning, combination) to leverage distilled knowledge in small student models for domain-specific adaptation and enhanced efficiency. Extensive experiments provide valuable insights into how knowledge format, quantity, and utilization methodologies collectively shape LLM-based bundle generation performance, exhibiting KD's significant potential for more efficient yet effective LLM-based bundle generation.</li>
</ul>

<h3>Title: Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion</h3>
<ul>
<li><strong>Authors: </strong>Mengyu Qiao, Runze Tian, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17223">https://arxiv.org/abs/2504.17223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17223">https://arxiv.org/pdf/2504.17223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17223]] Towards Generalizable Deepfake Detection with Spatial-Frequency Collaborative Learning and Hierarchical Cross-Modal Fusion(https://arxiv.org/abs/2504.17223)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>The rapid evolution of deep generative models poses a critical challenge to deepfake detection, as detectors trained on forgery-specific artifacts often suffer significant performance degradation when encountering unseen forgeries. While existing methods predominantly rely on spatial domain analysis, frequency domain operations are primarily limited to feature-level augmentation, leaving frequency-native artifacts and spatial-frequency interactions insufficiently exploited. To address this limitation, we propose a novel detection framework that integrates multi-scale spatial-frequency analysis for universal deepfake detection. Our framework comprises three key components: (1) a local spectral feature extraction pipeline that combines block-wise discrete cosine transform with cascaded multi-scale convolutions to capture subtle spectral artifacts; (2) a global spectral feature extraction pipeline utilizing scale-invariant differential accumulation to identify holistic forgery distribution patterns; and (3) a multi-stage cross-modal fusion mechanism that incorporates shallow-layer attention enhancement and deep-layer dynamic modulation to model spatial-frequency interactions. Extensive evaluations on widely adopted benchmarks demonstrate that our method outperforms state-of-the-art deepfake detection methods in both accuracy and generalizability.</li>
</ul>

<h3>Title: Visual and textual prompts for enhancing emotion recognition in video</h3>
<ul>
<li><strong>Authors: </strong>Zhifeng Wang, Qixuan Zhang, Peter Zhang, Wenjia Niu, Kaihao Zhang, Ramesh Sankaranarayana, Sabrina Caldwell, Tom Gedeon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17224">https://arxiv.org/abs/2504.17224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17224">https://arxiv.org/pdf/2504.17224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17224]] Visual and textual prompts for enhancing emotion recognition in video(https://arxiv.org/abs/2504.17224)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Vision Large Language Models (VLLMs) exhibit promising potential for multi-modal understanding, yet their application to video-based emotion recognition remains limited by insufficient spatial and contextual awareness. Traditional approaches, which prioritize isolated facial features, often neglect critical non-verbal cues such as body language, environmental context, and social interactions, leading to reduced robustness in real-world scenarios. To address this gap, we propose Set-of-Vision-Text Prompting (SoVTP), a novel framework that enhances zero-shot emotion recognition by integrating spatial annotations (e.g., bounding boxes, facial landmarks), physiological signals (facial action units), and contextual cues (body posture, scene dynamics, others' emotions) into a unified prompting strategy. SoVTP preserves holistic scene information while enabling fine-grained analysis of facial muscle movements and interpersonal dynamics. Extensive experiments show that SoVTP achieves substantial improvements over existing visual prompting methods, demonstrating its effectiveness in enhancing VLLMs' video emotion recognition capabilities.</li>
</ul>

<h3>Title: Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Lao, Heather Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17234">https://arxiv.org/abs/2504.17234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17234">https://arxiv.org/pdf/2504.17234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17234]] Scene Perceived Image Perceptual Score (SPIPS): combining global and local perception for image quality assessment(https://arxiv.org/abs/2504.17234)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid advancement of artificial intelligence and widespread use of smartphones have resulted in an exponential growth of image data, both real (camera-captured) and virtual (AI-generated). This surge underscores the critical need for robust image quality assessment (IQA) methods that accurately reflect human visual perception. Traditional IQA techniques primarily rely on spatial features - such as signal-to-noise ratio, local structural distortions, and texture inconsistencies - to identify artifacts. While effective for unprocessed or conventionally altered images, these methods fall short in the context of modern image post-processing powered by deep neural networks (DNNs). The rise of DNN-based models for image generation, enhancement, and restoration has significantly improved visual quality, yet made accurate assessment increasingly complex. To address this, we propose a novel IQA approach that bridges the gap between deep learning methods and human perception. Our model disentangles deep features into high-level semantic information and low-level perceptual details, treating each stream separately. These features are then combined with conventional IQA metrics to provide a more comprehensive evaluation framework. This hybrid design enables the model to assess both global context and intricate image details, better reflecting the human visual process, which first interprets overall structure before attending to fine-grained elements. The final stage employs a multilayer perceptron (MLP) to map the integrated features into a concise quality score. Experimental results demonstrate that our method achieves improved consistency with human perceptual judgments compared to existing IQA models.</li>
</ul>

<h3>Title: NeuralGrok: Accelerate Grokking by Neural Gradient Transformation</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Zhou, Simin Fan, Martin Jaggi, Jie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17243">https://arxiv.org/abs/2504.17243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17243">https://arxiv.org/pdf/2504.17243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17243]] NeuralGrok: Accelerate Grokking by Neural Gradient Transformation(https://arxiv.org/abs/2504.17243)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Grokking is proposed and widely studied as an intricate phenomenon in which generalization is achieved after a long-lasting period of overfitting. In this work, we propose NeuralGrok, a novel gradient-based approach that learns an optimal gradient transformation to accelerate the generalization of transformers in arithmetic tasks. Specifically, NeuralGrok trains an auxiliary module (e.g., an MLP block) in conjunction with the base model. This module dynamically modulates the influence of individual gradient components based on their contribution to generalization, guided by a bilevel optimization algorithm. Our extensive experiments demonstrate that NeuralGrok significantly accelerates generalization, particularly in challenging arithmetic tasks. We also show that NeuralGrok promotes a more stable training paradigm, constantly reducing the model's complexity, while traditional regularization methods, such as weight decay, can introduce substantial instability and impede generalization. We further investigate the intrinsic model complexity leveraging a novel Absolute Gradient Entropy (AGE) metric, which explains that NeuralGrok effectively facilitates generalization by reducing the model complexity. We offer valuable insights on the grokking phenomenon of Transformer models, which encourages a deeper understanding of the fundamental principles governing generalization ability.</li>
</ul>

<h3>Title: Targeted AMP generation through controlled diffusion with efficient embeddings</h3>
<ul>
<li><strong>Authors: </strong>Diogo Soares, Leon Hetzel, Paulina Szymczak, Fabian Theis, Stephan Günnemann, Ewa Szczurek</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17247">https://arxiv.org/abs/2504.17247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17247">https://arxiv.org/pdf/2504.17247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17247]] Targeted AMP generation through controlled diffusion with efficient embeddings(https://arxiv.org/abs/2504.17247)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Deep learning-based antimicrobial peptide (AMP) discovery faces critical challenges such as low experimental hit rates as well as the need for nuanced controllability and efficient modeling of peptide properties. To address these challenges, we introduce OmegAMP, a framework that leverages a diffusion-based generative model with efficient low-dimensional embeddings, precise controllability mechanisms, and novel classifiers with drastically reduced false positive rates for candidate filtering. OmegAMP enables the targeted generation of AMPs with specific physicochemical properties, activity profiles, and species-specific effectiveness. Moreover, it maximizes sample diversity while ensuring faithfulness to the underlying data distribution during generation. We demonstrate that OmegAMP achieves state-of-the-art performance across all stages of the AMP discovery pipeline, significantly advancing the potential of computational frameworks in combating antimicrobial resistance.</li>
</ul>

<h3>Title: Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo</h3>
<ul>
<li><strong>Authors: </strong>Ocheme Anthony Ekle, Biswarup Das</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17252">https://arxiv.org/abs/2504.17252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17252">https://arxiv.org/pdf/2504.17252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17252]] Low-Resource Neural Machine Translation Using Recurrent Neural Networks and Transfer Learning: A Case Study on English-to-Igbo(https://arxiv.org/abs/2504.17252)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this study, we develop Neural Machine Translation (NMT) and Transformer-based transfer learning models for English-to-Igbo translation - a low-resource African language spoken by over 40 million people across Nigeria and West Africa. Our models are trained on a curated and benchmarked dataset compiled from Bible corpora, local news, Wikipedia articles, and Common Crawl, all verified by native language experts. We leverage Recurrent Neural Network (RNN) architectures, including Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), enhanced with attention mechanisms to improve translation accuracy. To further enhance performance, we apply transfer learning using MarianNMT pre-trained models within the SimpleTransformers framework. Our RNN-based system achieves competitive results, closely matching existing English-Igbo benchmarks. With transfer learning, we observe a performance gain of +4.83 BLEU points, reaching an estimated translation accuracy of 70%. These findings highlight the effectiveness of combining RNNs with transfer learning to address the performance gap in low-resource language translation tasks.</li>
</ul>

<h3>Title: DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks</h3>
<ul>
<li><strong>Authors: </strong>Yinqi Li, Hong Chang, Ruibing Hou, Shiguang Shan, Xilin Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17253">https://arxiv.org/abs/2504.17253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17253">https://arxiv.org/pdf/2504.17253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17253]] DIVE: Inverting Conditional Diffusion Models for Discriminative Tasks(https://arxiv.org/abs/2504.17253)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have shown remarkable progress in various generative tasks such as image and video generation. This paper studies the problem of leveraging pretrained diffusion models for performing discriminative tasks. Specifically, we extend the discriminative capability of pretrained frozen generative diffusion models from the classification task to the more complex object detection task, by "inverting" a pretrained layout-to-image diffusion model. To this end, a gradient-based discrete optimization approach for replacing the heavy prediction enumeration process, and a prior distribution model for making more accurate use of the Bayes' rule, are proposed respectively. Empirical results show that this method is on par with basic discriminative object detection baselines on COCO dataset. In addition, our method can greatly speed up the previous diffusion-based method for classification without sacrificing accuracy. Code and models are available at this https URL .</li>
</ul>

<h3>Title: A Comment on "e-PoS: Making PoS Decentralized and Fair"</h3>
<ul>
<li><strong>Authors: </strong>Suhyeon Lee, Seungjoo Kim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17256">https://arxiv.org/abs/2504.17256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17256">https://arxiv.org/pdf/2504.17256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17256]] A Comment on "e-PoS: Making PoS Decentralized and Fair"(https://arxiv.org/abs/2504.17256)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Proof-of-Stake (PoS) is a prominent Sybil control mechanism for blockchain-based systems. In "e-PoS: Making PoS Decentralized and Fair," Saad et al. (TPDS'21) introduced a new Proof-of-Stake protocol, e-PoS, to enhance PoS applications' decentralization and fairness. In this comment paper, we address a misunderstanding in the work of Saad et al. The conventional Proof-of-Stake model that causes the fairness problem does not align with the general concept of Proof-of-Stake nor the Proof-of-Stake cryptocurrencies mentioned in their paper.</li>
</ul>

<h3>Title: Symbolic Representation for Any-to-Any Generative Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Chen, Xiaoye Zhu, Yue Wang, Tianyang Liu, Xinhui Chen, Ying Chen, Chak Tou Leong, Yifei Ke, Joseph Liu, Yiwen Yuan, Julian McAuley, Li-jia Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17261">https://arxiv.org/abs/2504.17261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17261">https://arxiv.org/pdf/2504.17261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17261]] Symbolic Representation for Any-to-Any Generative Tasks(https://arxiv.org/abs/2504.17261)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose a symbolic generative task description language and a corresponding inference engine capable of representing arbitrary multimodal tasks as structured symbolic flows. Unlike conventional generative models that rely on large-scale training and implicit neural representations to learn cross-modal mappings, often at high computational cost and with limited flexibility, our framework introduces an explicit symbolic representation comprising three core primitives: functions, parameters, and topological logic. Leveraging a pre-trained language model, our inference engine maps natural language instructions directly to symbolic workflows in a training-free manner. Our framework successfully performs over 12 diverse multimodal generative tasks, demonstrating strong performance and flexibility without the need for task-specific tuning. Experiments show that our method not only matches or outperforms existing state-of-the-art unified models in content quality, but also offers greater efficiency, editability, and interruptibility. We believe that symbolic task representations provide a cost-effective and extensible foundation for advancing the capabilities of generative AI.</li>
</ul>

<h3>Title: JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhaolu Kang, Hongtian Cai, Xiangyang Ji, Jinzhe Li, Nanfei Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17264">https://arxiv.org/abs/2504.17264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17264">https://arxiv.org/pdf/2504.17264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17264]] JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning(https://arxiv.org/abs/2504.17264)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Unsupervised Domain Adaptation (UDA) has gained significant attention in the field of Natural Language Processing (NLP) owing to its ability to enhance model generalization across diverse domains. However, its application for knowledge transfer between distinct legal domains remains largely unexplored. To address the challenges posed by lengthy and complex legal texts and the limited availability of large-scale annotated datasets, we propose JurisCTC, a novel model designed to improve the accuracy of Legal Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC facilitates effective knowledge transfer across various legal domains and employs contrastive learning to distinguish samples from different domains. Specifically, for the LJP task, we enable knowledge transfer between civil and criminal law domains. Compared to other models and specific large language models (LLMs), JurisCTC demonstrates notable advancements, achieving peak accuracies of 76.59% and 78.83%, respectively.</li>
</ul>

<h3>Title: Towards Generalized and Training-Free Text-Guided Semantic Manipulation</h3>
<ul>
<li><strong>Authors: </strong>Yu Hong, Xiao Cai, Pengpeng Zeng, Shuai Zhang, Jingkuan Song, Lianli Gao, Heng Tao Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17269">https://arxiv.org/abs/2504.17269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17269">https://arxiv.org/pdf/2504.17269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17269]] Towards Generalized and Training-Free Text-Guided Semantic Manipulation(https://arxiv.org/abs/2504.17269)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Text-guided semantic manipulation refers to semantically editing an image generated from a source prompt to match a target prompt, enabling the desired semantic changes (e.g., addition, removal, and style transfer) while preserving irrelevant contents. With the powerful generative capabilities of the diffusion model, the task has shown the potential to generate high-fidelity visual content. Nevertheless, existing methods either typically require time-consuming fine-tuning (inefficient), fail to accomplish multiple semantic manipulations (poorly extensible), and/or lack support for different modality tasks (limited generalizability). Upon further investigation, we find that the geometric properties of noises in the diffusion model are strongly correlated with the semantic changes. Motivated by this, we propose a novel $\textit{GTF}$ for text-guided semantic manipulation, which has the following attractive capabilities: 1) $\textbf{Generalized}$: our $\textit{GTF}$ supports multiple semantic manipulations (e.g., addition, removal, and style transfer) and can be seamlessly integrated into all diffusion-based methods (i.e., Plug-and-play) across different modalities (i.e., modality-agnostic); and 2) $\textbf{Training-free}$: $\textit{GTF}$ produces high-fidelity results via simply controlling the geometric relationship between noises without tuning or optimization. Our extensive experiments demonstrate the efficacy of our approach, highlighting its potential to advance the state-of-the-art in semantics manipulation.</li>
</ul>

<h3>Title: Contrastive Learning for Continuous Touch-Based Authentication</h3>
<ul>
<li><strong>Authors: </strong>Mengyu Qiao, Yunpeng Zhai, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17271">https://arxiv.org/abs/2504.17271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17271">https://arxiv.org/pdf/2504.17271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17271]] Contrastive Learning for Continuous Touch-Based Authentication(https://arxiv.org/abs/2504.17271)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Smart mobile devices have become indispensable in modern daily life, where sensitive information is frequently processed, stored, and transmitted-posing critical demands for robust security controls. Given that touchscreens are the primary medium for human-device interaction, continuous user authentication based on touch behavior presents a natural and seamless security solution. While existing methods predominantly adopt binary classification under single-modal learning settings, we propose a unified contrastive learning framework for continuous authentication in a non-disruptive manner. Specifically, the proposed method leverages a Temporal Masked Autoencoder to extract temporal patterns from raw multi-sensor data streams, capturing continuous motion and gesture dynamics. The pre-trained TMAE is subsequently integrated into a Siamese Temporal-Attentive Convolutional Network within a contrastive learning paradigm to model both sequential and cross-modal patterns. To further enhance performance, we incorporate multi-head attention and channel attention mechanisms to capture long-range dependencies and optimize inter-channel feature integration. Extensive experiments on public benchmarks and a self-collected dataset demonstrate that our approach outperforms state-of-the-art methods, offering a reliable and effective solution for user authentication on mobile devices.</li>
</ul>

<h3>Title: Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Siddharth Vishwanath, Jonathan Hehir</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17274">https://arxiv.org/abs/2504.17274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17274">https://arxiv.org/pdf/2504.17274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17274]] Signal Recovery from Random Dot-Product Graphs Under Local Differential Privacy(https://arxiv.org/abs/2504.17274)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We consider the problem of recovering latent information from graphs under $\varepsilon$-edge local differential privacy where the presence of relationships/edges between two users/vertices remains confidential, even from the data curator. For the class of generalized random dot-product graphs, we show that a standard local differential privacy mechanism induces a specific geometric distortion in the latent positions. Leveraging this insight, we show that consistent recovery of the latent positions is achievable by appropriately adjusting the statistical inference procedure for the privatized graph. Furthermore, we prove that our procedure is nearly minimax-optimal under local edge differential privacy constraints. Lastly, we show that this framework allows for consistent recovery of geometric and topological information underlying the latent positions, as encoded in their persistence diagrams. Our results extend previous work from the private community detection literature to a substantially richer class of models and inferential tasks.</li>
</ul>

<h3>Title: Evaluating and Mitigating Bias in AI-Based Medical Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiuying Chen, Tairan Wang, Juexiao Zhou, Zirui Song, Xin Gao, Xiangliang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17279">https://arxiv.org/abs/2504.17279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17279">https://arxiv.org/pdf/2504.17279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17279]] Evaluating and Mitigating Bias in AI-Based Medical Text Generation(https://arxiv.org/abs/2504.17279)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Artificial intelligence (AI) systems, particularly those based on deep learning models, have increasingly achieved expert-level performance in medical applications. However, there is growing concern that such AI systems may reflect and amplify human bias, and reduce the quality of their performance in historically under-served populations. The fairness issue has attracted considerable research interest in the medical imaging classification field, yet it remains understudied in the text generation domain. In this study, we investigate the fairness problem in text generation within the medical field and observe significant performance discrepancies across different races, sexes, and age groups, including intersectional groups, various model scales, and different evaluation metrics. To mitigate this fairness issue, we propose an algorithm that selectively optimizes those underperformed groups to reduce bias. The selection rules take into account not only word-level accuracy but also the pathology accuracy to the target reference, while ensuring that the entire process remains fully differentiable for effective model training. Our evaluations across multiple backbones, datasets, and modalities demonstrate that our proposed algorithm enhances fairness in text generation without compromising overall performance. Specifically, the disparities among various groups across different metrics were diminished by more than 30% with our algorithm, while the relative change in text generation accuracy was typically within 2%. By reducing the bias generated by deep learning models, our proposed approach can potentially alleviate concerns about the fairness and reliability of text generation diagnosis in medical domain. Our code is publicly available to facilitate further research at this https URL.</li>
</ul>

<h3>Title: EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy</h3>
<ul>
<li><strong>Authors: </strong>Haodi Yao, Fenghua He, Ning Hao, Chen Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17280">https://arxiv.org/abs/2504.17280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17280">https://arxiv.org/pdf/2504.17280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17280]] EdgePoint2: Compact Descriptors for Superior Efficiency and Accuracy(https://arxiv.org/abs/2504.17280)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>The field of keypoint extraction, which is essential for vision applications like Structure from Motion (SfM) and Simultaneous Localization and Mapping (SLAM), has evolved from relying on handcrafted methods to leveraging deep learning techniques. While deep learning approaches have significantly improved performance, they often incur substantial computational costs, limiting their deployment in real-time edge applications. Efforts to create lightweight neural networks have seen some success, yet they often result in trade-offs between efficiency and accuracy. Additionally, the high-dimensional descriptors generated by these networks poses challenges for distributed applications requiring efficient communication and coordination, highlighting the need for compact yet competitively accurate descriptors. In this paper, we present EdgePoint2, a series of lightweight keypoint detection and description neural networks specifically tailored for edge computing applications on embedded system. The network architecture is optimized for efficiency without sacrificing accuracy. To train compact descriptors, we introduce a combination of Orthogonal Procrustes loss and similarity loss, which can serve as a general approach for hypersphere embedding distillation tasks. Additionally, we offer 14 sub-models to satisfy diverse application requirements. Our experiments demonstrate that EdgePoint2 consistently achieves state-of-the-art (SOTA) accuracy and efficiency across various challenging scenarios while employing lower-dimensional descriptors (32/48/64). Beyond its accuracy, EdgePoint2 offers significant advantages in flexibility, robustness, and versatility. Consequently, EdgePoint2 emerges as a highly competitive option for visual tasks, especially in contexts demanding adaptability to diverse computational and communication constraints.</li>
</ul>

<h3>Title: The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes</h3>
<ul>
<li><strong>Authors: </strong>Wencong You, Daniel Lowd</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17300">https://arxiv.org/abs/2504.17300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17300">https://arxiv.org/pdf/2504.17300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17300]] The Ultimate Cookbook for Invisible Poison: Crafting Subtle Clean-Label Text Backdoors with Style Attributes(https://arxiv.org/abs/2504.17300)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor attacks on text classifiers can cause them to predict a predefined label when a particular "trigger" is present. Prior attacks often rely on triggers that are ungrammatical or otherwise unusual, leading to conspicuous attacks. As a result, human annotators, who play a critical role in curating training data in practice, can easily detect and filter out these unnatural texts during manual inspection, reducing the risk of such attacks. We argue that a key criterion for a successful attack is for text with and without triggers to be indistinguishable to humans. However, prior work neither directly nor comprehensively evaluated attack subtlety and invisibility with human involvement. We bridge the gap by conducting thorough human evaluations to assess attack subtlety. We also propose \emph{AttrBkd}, consisting of three recipes for crafting subtle yet effective trigger attributes, such as extracting fine-grained attributes from existing baseline backdoor attacks. Our human evaluations find that AttrBkd with these baseline-derived attributes is often more effective (higher attack success rate) and more subtle (fewer instances detected by humans) than the original baseline backdoor attacks, demonstrating that backdoor attacks can bypass detection by being inconspicuous and appearing natural even upon close inspection, while still remaining effective. Our human annotation also provides information not captured by automated metrics used in prior work, and demonstrates the misalignment of these metrics with human judgment.</li>
</ul>

<h3>Title: Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+</h3>
<ul>
<li><strong>Authors: </strong>Meher Boulaabi, Takwa Ben Aïcha Gader, Afef Kacem Echi, Sameh Mbarek</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17306">https://arxiv.org/abs/2504.17306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17306">https://arxiv.org/pdf/2504.17306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17306]] Advanced Segmentation of Diabetic Retinopathy Lesions Using DeepLabv3+(https://arxiv.org/abs/2504.17306)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>To improve the segmentation of diabetic retinopathy lesions (microaneurysms, hemorrhages, exudates, and soft exudates), we implemented a binary segmentation method specific to each type of lesion. As post-segmentation, we combined the individual model outputs into a single image to better analyze the lesion types. This approach facilitated parameter optimization and improved accuracy, effectively overcoming challenges related to dataset limitations and annotation complexity. Specific preprocessing steps included cropping and applying contrast-limited adaptive histogram equalization to the L channel of the LAB image. Additionally, we employed targeted data augmentation techniques to further refine the model's efficacy. Our methodology utilized the DeepLabv3+ model, achieving a segmentation accuracy of 99%. These findings highlight the efficacy of innovative strategies in advancing medical image analysis, particularly in the precise segmentation of diabetic retinopathy lesions. The IDRID dataset was utilized to validate and demonstrate the robustness of our approach.</li>
</ul>

<h3>Title: CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality</h3>
<ul>
<li><strong>Authors: </strong>Junyan Zhang, Shuliang Liu, Aiwei Liu, Yubo Gao, Jungang Li, Xiaojie Gu, Xuming Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17309">https://arxiv.org/abs/2504.17309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17309">https://arxiv.org/pdf/2504.17309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17309]] CoheMark: A Novel Sentence-Level Watermark for Enhanced Text Quality(https://arxiv.org/abs/2504.17309)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Watermarking technology is a method used to trace the usage of content generated by large language models. Sentence-level watermarking aids in preserving the semantic integrity within individual sentences while maintaining greater robustness. However, many existing sentence-level watermarking techniques depend on arbitrary segmentation or generation processes to embed watermarks, which can limit the availability of appropriate sentences. This limitation, in turn, compromises the quality of the generated response. To address the challenge of balancing high text quality with robust watermark detection, we propose CoheMark, an advanced sentence-level watermarking technique that exploits the cohesive relationships between sentences for better logical fluency. The core methodology of CoheMark involves selecting sentences through trained fuzzy c-means clustering and applying specific next sentence selection criteria. Experimental evaluations demonstrate that CoheMark achieves strong watermark strength while exerting minimal impact on text quality.</li>
</ul>

<h3>Title: FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yulia Otmakhova, Hung Thinh Truong, Rahmad Mahendra, Zenan Zhai, Rongxin Zhu, Daniel Beck, Jey Han Lau</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17311">https://arxiv.org/abs/2504.17311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17311">https://arxiv.org/pdf/2504.17311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17311]] FLUKE: A Linguistically-Driven and Task-Agnostic Framework for Robustness Evaluation(https://arxiv.org/abs/2504.17311)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We present FLUKE (Framework for LingUistically-driven and tasK-agnostic robustness Evaluation), a task-agnostic framework for assessing model robustness through systematic minimal variations of test data. FLUKE introduces controlled variations across linguistic levels - from orthography to dialect and style varieties - and leverages large language models (LLMs) with human validation to generate modifications. We demonstrate FLUKE's utility by evaluating both fine-tuned models and LLMs across four diverse NLP tasks, and reveal that (1) the impact of linguistic variations is highly task-dependent, with some tests being critical for certain tasks but irrelevant for others; (2) while LLMs have better overall robustness compared to fine-tuned models, they still exhibit significant brittleness to certain linguistic variations; (3) all models show substantial vulnerability to negation modifications across most tasks. These findings highlight the importance of systematic robustness testing for understanding model behaviors.</li>
</ul>

<h3>Title: Class-Conditional Distribution Balancing for Group Robust Classification</h3>
<ul>
<li><strong>Authors: </strong>Miaoyun Zhao, Qiang Zhang, Chenrong Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17314">https://arxiv.org/abs/2504.17314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17314">https://arxiv.org/pdf/2504.17314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17314]] Class-Conditional Distribution Balancing for Group Robust Classification(https://arxiv.org/abs/2504.17314)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spurious correlations that lead models to correct predictions for the wrong reasons pose a critical challenge for robust real-world generalization. Existing research attributes this issue to group imbalance and addresses it by maximizing group-balanced or worst-group accuracy, which heavily relies on expensive bias annotations. A compromise approach involves predicting bias information using extensively pretrained foundation models, which requires large-scale data and becomes impractical for resource-limited rare domains. To address these challenges, we offer a novel perspective by reframing the spurious correlations as imbalances or mismatches in class-conditional distributions, and propose a simple yet effective robust learning method that eliminates the need for both bias annotations and predictions. With the goal of reducing the mutual information between spurious factors and label information, our method leverages a sample reweighting strategy to achieve class-conditional distribution balancing, which automatically highlights minority groups and classes, effectively dismantling spurious correlations and producing a debiased data distribution for classification. Extensive experiments and analysis demonstrate that our approach consistently delivers state-of-the-art performance, rivaling methods that rely on bias supervision.</li>
</ul>

<h3>Title: Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation Detection</h3>
<ul>
<li><strong>Authors: </strong>Zihan Wang, Lu Yuan, Zhengxuan Zhang, Qing Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17332">https://arxiv.org/abs/2504.17332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17332">https://arxiv.org/pdf/2504.17332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17332]] Bridging Cognition and Emotion: Empathy-Driven Multimodal Misinformation Detection(https://arxiv.org/abs/2504.17332)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the digital era, social media has become a major conduit for information dissemination, yet it also facilitates the rapid spread of misinformation. Traditional misinformation detection methods primarily focus on surface-level features, overlooking the crucial roles of human empathy in the propagation process. To address this gap, we propose the Dual-Aspect Empathy Framework (DAE), which integrates cognitive and emotional empathy to analyze misinformation from both the creator and reader perspectives. By examining creators' cognitive strategies and emotional appeals, as well as simulating readers' cognitive judgments and emotional responses using Large Language Models (LLMs), DAE offers a more comprehensive and human-centric approach to misinformation detection. Moreover, we further introduce an empathy-aware filtering mechanism to enhance response authenticity and diversity. Experimental results on benchmark datasets demonstrate that DAE outperforms existing methods, providing a novel paradigm for multimodal misinformation detection.</li>
</ul>

<h3>Title: TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos</h3>
<ul>
<li><strong>Authors: </strong>Linli Yao, Yicheng Li, Yuancheng Wei, Lei Li, Shuhuai Ren, Yuanxin Liu, Kun Ouyang, Lean Wang, Shicheng Li, Sida Li, Lingpeng Kong, Qi Liu, Yuanxing Zhang, Xu Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17343">https://arxiv.org/abs/2504.17343</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17343">https://arxiv.org/pdf/2504.17343</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17343]] TimeChat-Online: 80% Visual Tokens are Naturally Redundant in Streaming Videos(https://arxiv.org/abs/2504.17343)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid growth of online video platforms, particularly live streaming services, has created an urgent need for real-time video understanding systems. These systems must process continuous video streams and respond to user queries instantaneously, presenting unique challenges for current Video Large Language Models (VideoLLMs). While existing VideoLLMs excel at processing complete videos, they face significant limitations in streaming scenarios due to their inability to handle dense, redundant frames efficiently. We introduce TimeChat-Online, a novel online VideoLLM that revolutionizes real-time video interaction. At its core lies our innovative Differential Token Drop (DTD) module, which addresses the fundamental challenge of visual redundancy in streaming videos. Drawing inspiration from human visual perception's Change Blindness phenomenon, DTD preserves meaningful temporal changes while filtering out static, redundant content between frames. Remarkably, our experiments demonstrate that DTD achieves an 82.8% reduction in video tokens while maintaining 98% performance on StreamingBench, revealing that over 80% of visual content in streaming videos is naturally redundant without requiring language guidance. To enable seamless real-time interaction, we present TimeChat-Online-139K, a comprehensive streaming video dataset featuring diverse interaction patterns including backward-tracing, current-perception, and future-responding scenarios. TimeChat-Online's unique Proactive Response capability, naturally achieved through continuous monitoring of video scene transitions via DTD, sets it apart from conventional approaches. Our extensive evaluation demonstrates TimeChat-Online's superior performance on streaming benchmarks (StreamingBench and OvOBench) and maintaining competitive results on long-form video tasks such as Video-MME and MLVU.</li>
</ul>

<h3>Title: DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition</h3>
<ul>
<li><strong>Authors: </strong>Yiyan Xu, Wuqiang Zheng, Wenjie Wang, Fengbin Zhu, Xinting Hu, Yang Zhang, Fuli Feng, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17349">https://arxiv.org/abs/2504.17349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17349">https://arxiv.org/pdf/2504.17349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17349]] DRC: Enhancing Personalized Image Generation via Disentangled Representation Composition(https://arxiv.org/abs/2504.17349)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Personalized image generation has emerged as a promising direction in multimodal content creation. It aims to synthesize images tailored to individual style preferences (e.g., color schemes, character appearances, layout) and semantic intentions (e.g., emotion, action, scene contexts) by leveraging user-interacted history images and multimodal instructions. Despite notable progress, existing methods -- whether based on diffusion models, large language models, or Large Multimodal Models (LMMs) -- struggle to accurately capture and fuse user style preferences and semantic intentions. In particular, the state-of-the-art LMM-based method suffers from the entanglement of visual features, leading to Guidance Collapse, where the generated images fail to preserve user-preferred styles or reflect the specified semantics. To address these limitations, we introduce DRC, a novel personalized image generation framework that enhances LMMs through Disentangled Representation Composition. DRC explicitly extracts user style preferences and semantic intentions from history images and the reference image, respectively, to form user-specific latent instructions that guide image generation within LMMs. Specifically, it involves two critical learning stages: 1) Disentanglement learning, which employs a dual-tower disentangler to explicitly separate style and semantic features, optimized via a reconstruction-driven paradigm with difficulty-aware importance sampling; and 2) Personalized modeling, which applies semantic-preserving augmentations to effectively adapt the disentangled representations for robust personalized generation. Extensive experiments on two benchmarks demonstrate that DRC shows competitive performance while effectively mitigating the guidance collapse issue, underscoring the importance of disentangled representation learning for controllable and effective personalized image generation.</li>
</ul>

<h3>Title: M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Chengguang Gan, Sunbowen Lee, Zhixi Cai, Yanbin Wei, Lei Zheng, Yunhao Liang, Shiwen Ni, Tatsunori Mori</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17353">https://arxiv.org/abs/2504.17353</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17353">https://arxiv.org/pdf/2504.17353</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17353]] M-MRE: Extending the Mutual Reinforcement Effect to Multimodal Information Extraction(https://arxiv.org/abs/2504.17353)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Mutual Reinforcement Effect (MRE) is an emerging subfield at the intersection of information extraction and model interpretability. MRE aims to leverage the mutual understanding between tasks of different granularities, enhancing the performance of both coarse-grained and fine-grained tasks through joint modeling. While MRE has been explored and validated in the textual domain, its applicability to visual and multimodal domains remains unexplored. In this work, we extend MRE to the multimodal information extraction domain for the first time. Specifically, we introduce a new task: Multimodal Mutual Reinforcement Effect (M-MRE), and construct a corresponding dataset to support this task. To address the challenges posed by M-MRE, we further propose a Prompt Format Adapter (PFA) that is fully compatible with various Large Vision-Language Models (LVLMs). Experimental results demonstrate that MRE can also be observed in the M-MRE task, a multimodal text-image understanding scenario. This provides strong evidence that MRE facilitates mutual gains across three interrelated tasks, confirming its generalizability beyond the textual domain.</li>
</ul>

<h3>Title: PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Jose G. Moreno (IRIT-IRIS), Jesus Lovon (IRIT-IRIS), M'Rick Robin-Charlet (UT3), Christine Damase-Michel, Lynda Tamine (IRIT-IRIS)</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17360">https://arxiv.org/abs/2504.17360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17360">https://arxiv.org/pdf/2504.17360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17360]] PatientDx: Merging Large Language Models for Protecting Data-Privacy in Healthcare(https://arxiv.org/abs/2504.17360)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning of Large Language Models (LLMs) has become the default practice for improving model performance on a given task. However, performance improvement comes at the cost of training on vast amounts of annotated data which could be sensitive leading to significant data privacy concerns. In particular, the healthcare domain is one of the most sensitive domains exposed to data privacy issues. In this paper, we present PatientDx, a framework of model merging that allows the design of effective LLMs for health-predictive tasks without requiring fine-tuning nor adaptation on patient data. Our proposal is based on recently proposed techniques known as merging of LLMs and aims to optimize a building block merging strategy. PatientDx uses a pivotal model adapted to numerical reasoning and tunes hyperparameters on examples based on a performance metric but without training of the LLM on these data. Experiments using the mortality tasks of the MIMIC-IV dataset show improvements up to 7% in terms of AUROC when compared to initial models. Additionally, we confirm that when compared to fine-tuned models, our proposal is less prone to data leak problems without hurting performance. Finally, we qualitatively show the capabilities of our proposal through a case study. Our best model is publicly available at this https URL Jgmorenof/mistral\_merged\_0\_4.</li>
</ul>

<h3>Title: I-INR: Iterative Implicit Neural Representations</h3>
<ul>
<li><strong>Authors: </strong>Ali Haider, Muhammad Salman Ali, Maryam Qamar, Tahir Khalil, Soo Ye Kim, Jihyong Oh, Enzo Tartaglione, Sung-Ho Bae</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17364">https://arxiv.org/abs/2504.17364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17364">https://arxiv.org/pdf/2504.17364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17364]] I-INR: Iterative Implicit Neural Representations(https://arxiv.org/abs/2504.17364)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Implicit Neural Representations (INRs) have revolutionized signal processing and computer vision by modeling signals as continuous, differentiable functions parameterized by neural networks. However, their inherent formulation as a regression problem makes them prone to regression to the mean, limiting their ability to capture fine details, retain high-frequency information, and handle noise effectively. To address these challenges, we propose Iterative Implicit Neural Representations (I-INRs) a novel plug-and-play framework that enhances signal reconstruction through an iterative refinement process. I-INRs effectively recover high-frequency details, improve robustness to noise, and achieve superior reconstruction quality. Our framework seamlessly integrates with existing INR architectures, delivering substantial performance gains across various tasks. Extensive experiments show that I-INRs outperform baseline methods, including WIRE, SIREN, and Gauss, in diverse computer vision applications such as image restoration, image denoising, and object occupancy prediction.</li>
</ul>

<h3>Title: TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation</h3>
<ul>
<li><strong>Authors: </strong>Ling You, Wenxuan Huang, Xinni Xie, Xiangyi Wei, Bangyan Li, Shaohui Lin, Yang Li, Changbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17365">https://arxiv.org/abs/2504.17365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17365">https://arxiv.org/pdf/2504.17365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17365]] TimeSoccer: An End-to-End Multimodal Large Language Model for Soccer Commentary Generation(https://arxiv.org/abs/2504.17365)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Soccer is a globally popular sporting event, typically characterized by long matches and distinctive highlight moments. Recent advances in Multimodal Large Language Models (MLLMs) offer promising capabilities in temporal grounding and video understanding, soccer commentary generation often requires precise temporal localization and semantically rich descriptions over long-form video. However, existing soccer MLLMs often rely on the temporal a priori for caption generation, so they cannot process the soccer video end-to-end. While some traditional approaches follow a two-step paradigm that is complex and fails to capture the global context to achieve suboptimal performance. To solve the above issues, we present TimeSoccer, the first end-to-end soccer MLLM for Single-anchor Dense Video Captioning (SDVC) in full-match soccer videos. TimeSoccer jointly predicts timestamps and generates captions in a single pass, enabling global context modeling across 45-minute matches. To support long video understanding of soccer matches, we introduce MoFA-Select, a training-free, motion-aware frame compression module that adaptively selects representative frames via a coarse-to-fine strategy, and incorporates complementary training paradigms to strengthen the model's ability to handle long temporal sequences. Extensive experiments demonstrate that our TimeSoccer achieves State-of-The-Art (SoTA) performance on the SDVC task in an end-to-end form, generating high-quality commentary with accurate temporal alignment and strong semantic relevance.</li>
</ul>

<h3>Title: LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams</h3>
<ul>
<li><strong>Authors: </strong>Yongxuan Wu, Runyu Chen, Peiyu Liu, Hongjin Qian</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17366">https://arxiv.org/abs/2504.17366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17366">https://arxiv.org/pdf/2504.17366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17366]] LiveLongBench: Tackling Long-Context Understanding for Spoken Texts from Live Streams(https://arxiv.org/abs/2504.17366)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context understanding poses significant challenges in natural language processing, particularly for real-world dialogues characterized by speech-based elements, high redundancy, and uneven information density. Although large language models (LLMs) achieve impressive results on existing benchmarks, these datasets fail to reflect the complexities of such texts, limiting their applicability to practical scenarios. To bridge this gap, we construct the first spoken long-text dataset, derived from live streams, designed to reflect the redundancy-rich and conversational nature of real-world scenarios. We construct tasks in three categories: retrieval-dependent, reasoning-dependent, and hybrid. We then evaluate both popular LLMs and specialized methods to assess their ability to understand long-contexts in these tasks. Our results show that current methods exhibit strong task-specific preferences and perform poorly on highly redundant inputs, with no single method consistently outperforming others. We propose a new baseline that better handles redundancy in spoken text and achieves strong performance across tasks. Our findings highlight key limitations of current methods and suggest future directions for improving long-context understanding. Finally, our benchmark fills a gap in evaluating long-context spoken language understanding and provides a practical foundation for developing real-world e-commerce systems. The code and benchmark are available at this https URL.</li>
</ul>

<h3>Title: Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset</h3>
<ul>
<li><strong>Authors: </strong>Oussema Dhaouadi, Johannes Meier, Luca Wahl, Jacques Kaiser, Luca Scalerandi, Nick Wandelburg, Zhuolun Zhou, Nijanthan Berinpanathan, Holger Banzhaf, Daniel Cremers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17371">https://arxiv.org/abs/2504.17371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17371">https://arxiv.org/pdf/2504.17371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17371]] Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset(https://arxiv.org/abs/2504.17371)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at this http URL, facilitating research in motion prediction, behavior modeling, and safety validation.</li>
</ul>

<h3>Title: PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona</h3>
<ul>
<li><strong>Authors: </strong>Jihyun Lee, Yejin Jeon, Seungyeon Seo, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17390">https://arxiv.org/abs/2504.17390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17390">https://arxiv.org/pdf/2504.17390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17390]] PicPersona-TOD : A Dataset for Personalizing Utterance Style in Task-Oriented Dialogue with Image Persona(https://arxiv.org/abs/2504.17390)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Task-Oriented Dialogue (TOD) systems are designed to fulfill user requests through natural language interactions, yet existing systems often produce generic, monotonic responses that lack individuality and fail to adapt to users' personal attributes. To address this, we introduce PicPersona-TOD, a novel dataset that incorporates user images as part of the persona, enabling personalized responses tailored to user-specific factors such as age or emotional context. This is facilitated by first impressions, dialogue policy-guided prompting, and the use of external knowledge to reduce hallucinations. Human evaluations confirm that our dataset enhances user experience, with personalized responses contributing to a more engaging interaction. Additionally, we introduce a new NLG model, Pictor, which not only personalizes responses, but also demonstrates robust performance across unseen domains this https URL.</li>
</ul>

<h3>Title: SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting</h3>
<ul>
<li><strong>Authors: </strong>Yiming Zhao, Guorong Li, Laiyun Qing, Amin Beheshti, Jian Yang, Michael Sheng, Yuankai Qi, Qingming Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17395">https://arxiv.org/abs/2504.17395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17395">https://arxiv.org/pdf/2504.17395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17395]] SDVPT: Semantic-Driven Visual Prompt Tuning for Open-World Object Counting(https://arxiv.org/abs/2504.17395)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Open-world object counting leverages the robust text-image alignment of pre-trained vision-language models (VLMs) to enable counting of arbitrary categories in images specified by textual queries. However, widely adopted naive fine-tuning strategies concentrate exclusively on text-image consistency for categories contained in training, which leads to limited generalizability for unseen categories. In this work, we propose a plug-and-play Semantic-Driven Visual Prompt Tuning framework (SDVPT) that transfers knowledge from the training set to unseen categories with minimal overhead in parameters and inference time. First, we introduce a two-stage visual prompt learning strategy composed of Category-Specific Prompt Initialization (CSPI) and Topology-Guided Prompt Refinement (TGPR). The CSPI generates category-specific visual prompts, and then TGPR distills latent structural patterns from the VLM's text encoder to refine these prompts. During inference, we dynamically synthesize the visual prompts for unseen categories based on the semantic correlation between unseen and training categories, facilitating robust text-image alignment for unseen categories. Extensive experiments integrating SDVPT with all available open-world object counting models demonstrate its effectiveness and adaptability across three widely used datasets: FSC-147, CARPK, and PUCPR+.</li>
</ul>

<h3>Title: S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception</h3>
<ul>
<li><strong>Authors: </strong>Sven Teufel, Jörg Gamerdinger, Oliver Bringmann</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17399">https://arxiv.org/abs/2504.17399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17399">https://arxiv.org/pdf/2504.17399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17399]] S2S-Net: Addressing the Domain Gap of Heterogeneous Sensor Systems in LiDAR-Based Collective Perception(https://arxiv.org/abs/2504.17399)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Collective Perception (CP) has emerged as a promising approach to overcome the limitations of individual perception in the context of autonomous driving. Various approaches have been proposed to realize collective perception; however, the Sensor2Sensor domain gap that arises from the utilization of different sensor systems in Connected and Automated Vehicles (CAVs) remains mostly unaddressed. This is primarily due to the paucity of datasets containing heterogeneous sensor setups among the CAVs. The recently released SCOPE datasets address this issue by providing data from three different LiDAR sensors for each CAV. This study is the first to tackle the Sensor2Sensor domain gap in vehicle to vehicle (V2V) collective perception. First, we present our sensor-domain robust architecture S2S-Net. Then an in-depth analysis of the Sensor2Sensor domain adaptation capabilities of S2S-Net on the SCOPE dataset is conducted. S2S-Net demonstrates the capability to maintain very high performance in unseen sensor domains and achieved state-of-the-art results on the SCOPE dataset.</li>
</ul>

<h3>Title: StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies</h3>
<ul>
<li><strong>Authors: </strong>Xu Wang, Jialang Xu, Shuai Zhang, Baoru Huang, Danail Stoyanov, Evangelos B. Mazomenos</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17401">https://arxiv.org/abs/2504.17401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17401">https://arxiv.org/pdf/2504.17401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17401]] StereoMamba: Real-time and Robust Intraoperative Stereo Disparity Estimation via Long-range Spatial Dependencies(https://arxiv.org/abs/2504.17401)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Stereo disparity estimation is crucial for obtaining depth information in robot-assisted minimally invasive surgery (RAMIS). While current deep learning methods have made significant advancements, challenges remain in achieving an optimal balance between accuracy, robustness, and inference speed. To address these challenges, we propose the StereoMamba architecture, which is specifically designed for stereo disparity estimation in RAMIS. Our approach is based on a novel Feature Extraction Mamba (FE-Mamba) module, which enhances long-range spatial dependencies both within and across stereo images. To effectively integrate multi-scale features from FE-Mamba, we then introduce a novel Multidimensional Feature Fusion (MFF) module. Experiments against the state-of-the-art on the ex-vivo SCARED benchmark demonstrate that StereoMamba achieves superior performance on EPE of 2.64 px and depth MAE of 2.55 mm, the second-best performance on Bad2 of 41.49% and Bad3 of 26.99%, while maintaining an inference speed of 21.28 FPS for a pair of high-resolution images (1280*1024), striking the optimum balance between accuracy, robustness, and efficiency. Furthermore, by comparing synthesized right images, generated from warping left images using the generated disparity maps, with the actual right image, StereoMamba achieves the best average SSIM (0.8970) and PSNR (16.0761), exhibiting strong zero-shot generalization on the in-vivo RIS2017 and StereoMIS datasets.</li>
</ul>

<h3>Title: 3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Min Wei, Chaohui Yu, Jingkai Zhou, Fan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17414">https://arxiv.org/abs/2504.17414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17414">https://arxiv.org/pdf/2504.17414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17414]] 3DV-TON: Textured 3D-Guided Consistent Video Try-on via Diffusion Models(https://arxiv.org/abs/2504.17414)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Video try-on replaces clothing in videos with target garments. Existing methods struggle to generate high-quality and temporally consistent results when handling complex clothing patterns and diverse body poses. We present 3DV-TON, a novel diffusion-based framework for generating high-fidelity and temporally consistent video try-on results. Our approach employs generated animatable textured 3D meshes as explicit frame-level guidance, alleviating the issue of models over-focusing on appearance fidelity at the expanse of motion coherence. This is achieved by enabling direct reference to consistent garment texture movements throughout video sequences. The proposed method features an adaptive pipeline for generating dynamic 3D guidance: (1) selecting a keyframe for initial 2D image try-on, followed by (2) reconstructing and animating a textured 3D mesh synchronized with original video poses. We further introduce a robust rectangular masking strategy that successfully mitigates artifact propagation caused by leaking clothing information during dynamic human and garment movements. To advance video try-on research, we introduce HR-VVT, a high-resolution benchmark dataset containing 130 videos with diverse clothing types and scenarios. Quantitative and qualitative results demonstrate our superior performance over existing methods. The project page is at this link this https URL</li>
</ul>

<h3>Title: Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks</h3>
<ul>
<li><strong>Authors: </strong>Yang Liu, Bingjie Yan, Tianyuan Zou, Jianqing Zhang, Zixuan Gu, Jianbing Ding, Xidong Wang, Jingyi Li, Xiaozhou Ye, Ye Ouyang, Qiang Yang, Ya-Qin Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17421">https://arxiv.org/abs/2504.17421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17421">https://arxiv.org/pdf/2504.17421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17421]] Towards Harnessing the Collaborative Power of Large and Small Models for Domain Tasks(https://arxiv.org/abs/2504.17421)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities, but they require vast amounts of data and computational resources. In contrast, smaller models (SMs), while less powerful, can be more efficient and tailored to specific domains. In this position paper, we argue that taking a collaborative approach, where large and small models work synergistically, can accelerate the adaptation of LLMs to private domains and unlock new potential in AI. We explore various strategies for model collaboration and identify potential challenges and opportunities. Building upon this, we advocate for industry-driven research that prioritizes multi-objective benchmarks on real-world private datasets and applications.</li>
</ul>

<h3>Title: Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tiancheng Gu, Kaicheng Yang, Ziyong Feng, Xingjun Wang, Yanzhao Zhang, Dingkun Long, Yingda Chen, Weidong Cai, Jiankang Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17432">https://arxiv.org/abs/2504.17432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17432">https://arxiv.org/pdf/2504.17432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17432]] Breaking the Modality Barrier: Universal Embedding Learning with Multimodal LLMs(https://arxiv.org/abs/2504.17432)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Contrastive Language-Image Pre-training (CLIP) framework has become a widely used approach for multimodal representation learning, particularly in image-text retrieval and clustering. However, its efficacy is constrained by three key limitations: (1) text token truncation, (2) isolated image-text encoding, and (3) deficient compositionality due to bag-of-words behavior. While recent Multimodal Large Language Models (MLLMs) have demonstrated significant advances in generalized vision-language understanding, their potential for learning transferable multimodal representations remains this http URL this work, we present UniME (Universal Multimodal Embedding), a novel two-stage framework that leverages MLLMs to learn discriminative representations for diverse downstream tasks. In the first stage, we perform textual discriminative knowledge distillation from a powerful LLM-based teacher model to enhance the embedding capability of the MLLMś language component. In the second stage, we introduce hard negative enhanced instruction tuning to further advance discriminative representation learning. Specifically, we initially mitigate false negative contamination and then sample multiple hard negatives per instance within each batch, forcing the model to focus on challenging samples. This approach not only improves discriminative power but also enhances instruction-following ability in downstream tasks. We conduct extensive experiments on the MMEB benchmark and multiple retrieval tasks, including short and long caption retrieval and compositional retrieval. Results demonstrate that UniME achieves consistent performance improvement across all tasks, exhibiting superior discriminative and compositional capabilities.</li>
</ul>

<h3>Title: Creating Targeted, Interpretable Topic Models with LLM-Generated Text Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Anna Lieb, Maneesh Arora, Eni Mustafaraj</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17445">https://arxiv.org/abs/2504.17445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17445">https://arxiv.org/pdf/2504.17445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17445]] Creating Targeted, Interpretable Topic Models with LLM-Generated Text Augmentation(https://arxiv.org/abs/2504.17445)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Unsupervised machine learning techniques, such as topic modeling and clustering, are often used to identify latent patterns in unstructured text data in fields such as political science and sociology. These methods overcome common concerns about reproducibility and costliness involved in the labor-intensive process of human qualitative analysis. However, two major limitations of topic models are their interpretability and their practicality for answering targeted, domain-specific social science research questions. In this work, we investigate opportunities for using LLM-generated text augmentation to improve the usefulness of topic modeling output. We use a political science case study to evaluate our results in a domain-specific application, and find that topic modeling using GPT-4 augmentations creates highly interpretable categories that can be used to investigate domain-specific research questions with minimal human guidance.</li>
</ul>

<h3>Title: CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning</h3>
<ul>
<li><strong>Authors: </strong>Jun Zhang, Jue Wang, Huan Li, Zhongle Xie, Ke Chen, Lidan Shou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DB, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17448">https://arxiv.org/abs/2504.17448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17448">https://arxiv.org/pdf/2504.17448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17448]] CHASe: Client Heterogeneity-Aware Data Selection for Effective Federated Active Learning(https://arxiv.org/abs/2504.17448)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Active learning (AL) reduces human annotation costs for machine learning systems by strategically selecting the most informative unlabeled data for annotation, but performing it individually may still be insufficient due to restricted data diversity and annotation budget. Federated Active Learning (FAL) addresses this by facilitating collaborative data selection and model training, while preserving the confidentiality of raw data samples. Yet, existing FAL methods fail to account for the heterogeneity of data distribution across clients and the associated fluctuations in global and local model parameters, adversely affecting model accuracy. To overcome these challenges, we propose CHASe (Client Heterogeneity-Aware Data Selection), specifically designed for FAL. CHASe focuses on identifying those unlabeled samples with high epistemic variations (EVs), which notably oscillate around the decision boundaries during training. To achieve both effectiveness and efficiency, \model{} encompasses techniques for 1) tracking EVs by analyzing inference inconsistencies across training epochs, 2) calibrating decision boundaries of inaccurate models with a new alignment loss, and 3) enhancing data selection efficiency via a data freeze and awaken mechanism with subset sampling. Experiments show that CHASe surpasses various established baselines in terms of effectiveness and efficiency, validated across diverse datasets, model complexities, and heterogeneous federation settings.</li>
</ul>

<h3>Title: Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Zhiying Li, Yeying Jin, Fan Shen, Zhi Liu, Weibin Chen, Pengju Zhang, Xiaomei Zhang, Boyu Chen, Michael Shen, Kejian Wu, Zhaoxin Fan, Jin Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17457">https://arxiv.org/abs/2504.17457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17457">https://arxiv.org/pdf/2504.17457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17457]] Unveiling Hidden Vulnerabilities in Digital Human Generation via Adversarial Attacks(https://arxiv.org/abs/2504.17457)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Expressive human pose and shape estimation (EHPS) is crucial for digital human generation, especially in applications like live streaming. While existing research primarily focuses on reducing estimation errors, it largely neglects robustness and security aspects, leaving these systems vulnerable to adversarial attacks. To address this significant challenge, we propose the \textbf{Tangible Attack (TBA)}, a novel framework designed to generate adversarial examples capable of effectively compromising any digital human generation model. Our approach introduces a \textbf{Dual Heterogeneous Noise Generator (DHNG)}, which leverages Variational Autoencoders (VAE) and ControlNet to produce diverse, targeted noise tailored to the original image features. Additionally, we design a custom \textbf{adversarial loss function} to optimize the noise, ensuring both high controllability and potent disruption. By iteratively refining the adversarial sample through multi-gradient signals from both the noise and the state-of-the-art EHPS model, TBA substantially improves the effectiveness of adversarial attacks. Extensive experiments demonstrate TBA's superiority, achieving a remarkable 41.0\% increase in estimation error, with an average improvement of approximately 17.0\%. These findings expose significant security vulnerabilities in current EHPS models and highlight the need for stronger defenses in digital human generation systems.</li>
</ul>

<h3>Title: Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience</h3>
<ul>
<li><strong>Authors: </strong>Vipin Singh, Tianheng Ling, Teodor Chiaburu, Felix Biessmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17461">https://arxiv.org/abs/2504.17461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17461">https://arxiv.org/pdf/2504.17461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17461]] Evaluating Time Series Models for Urban Wastewater Management: Predictive Performance, Model Complexity and Resilience(https://arxiv.org/abs/2504.17461)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Climate change increases the frequency of extreme rainfall, placing a significant strain on urban infrastructures, especially Combined Sewer Systems (CSS). Overflows from overburdened CSS release untreated wastewater into surface waters, posing environmental and public health risks. Although traditional physics-based models are effective, they are costly to maintain and difficult to adapt to evolving system dynamics. Machine Learning (ML) approaches offer cost-efficient alternatives with greater adaptability. To systematically assess the potential of ML for modeling urban infrastructure systems, we propose a protocol for evaluating Neural Network architectures for CSS time series forecasting with respect to predictive performance, model complexity, and robustness to perturbations. In addition, we assess model performance on peak events and critical fluctuations, as these are the key regimes for urban wastewater management. To investigate the feasibility of lightweight models suitable for IoT deployment, we compare global models, which have access to all information, with local models, which rely solely on nearby sensor readings. Additionally, to explore the security risks posed by network outages or adversarial attacks on urban infrastructure, we introduce error models that assess the resilience of models. Our results demonstrate that while global models achieve higher predictive performance, local models provide sufficient resilience in decentralized scenarios, ensuring robust modeling of urban infrastructure. Furthermore, models with longer native forecast horizons exhibit greater robustness to data perturbations. These findings contribute to the development of interpretable and reliable ML solutions for sustainable urban wastewater management. The implementation is available in our GitHub repository.</li>
</ul>

<h3>Title: GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework</h3>
<ul>
<li><strong>Authors: </strong>Yacine Belal, Mohamed Maouche, Sonia Ben Mokhtar, Anthony Simonet-Boulogne</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17471">https://arxiv.org/abs/2504.17471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17471">https://arxiv.org/pdf/2504.17471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17471]] GRANITE : a Byzantine-Resilient Dynamic Gossip Learning Framework(https://arxiv.org/abs/2504.17471)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Gossip Learning (GL) is a decentralized learning paradigm where users iteratively exchange and aggregate models with a small set of neighboring peers. Recent GL approaches rely on dynamic communication graphs built and maintained using Random Peer Sampling (RPS) protocols. Thanks to graph dynamics, GL can achieve fast convergence even over extremely sparse topologies. However, the robustness of GL over dy- namic graphs to Byzantine (model poisoning) attacks remains unaddressed especially when Byzantine nodes attack the RPS protocol to scale up model poisoning. We address this issue by introducing GRANITE, a framework for robust learning over sparse, dynamic graphs in the presence of a fraction of Byzantine nodes. GRANITE relies on two key components (i) a History-aware Byzantine-resilient Peer Sampling protocol (HaPS), which tracks previously encountered identifiers to reduce adversarial influence over time, and (ii) an Adaptive Probabilistic Threshold (APT), which leverages an estimate of Byzantine presence to set aggregation thresholds with formal guarantees. Empirical results confirm that GRANITE maintains convergence with up to 30% Byzantine nodes, improves learning speed via adaptive filtering of poisoned models and obtains these results in up to 9 times sparser graphs than dictated by current theory.</li>
</ul>

<h3>Title: Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation</h3>
<ul>
<li><strong>Authors: </strong>Xin Yi, Shunfan Zhengc, Linlin Wanga, Xiaoling Wang, Liang He</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17480">https://arxiv.org/abs/2504.17480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17480">https://arxiv.org/pdf/2504.17480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17480]] Unified Attacks to Large Language Model Watermarks: Spoofing and Scrubbing in Unauthorized Knowledge Distillation(https://arxiv.org/abs/2504.17480)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Watermarking has emerged as a critical technique for combating misinformation and protecting intellectual property in large language models (LLMs). A recent discovery, termed watermark radioactivity, reveals that watermarks embedded in teacher models can be inherited by student models through knowledge distillation. On the positive side, this inheritance allows for the detection of unauthorized knowledge distillation by identifying watermark traces in student models. However, the robustness of watermarks against scrubbing attacks and their unforgeability in the face of spoofing attacks under unauthorized knowledge distillation remain largely unexplored. Existing watermark attack methods either assume access to model internals or fail to simultaneously support both scrubbing and spoofing attacks. In this work, we propose Contrastive Decoding-Guided Knowledge Distillation (CDG-KD), a unified framework that enables bidirectional attacks under unauthorized knowledge distillation. Our approach employs contrastive decoding to extract corrupted or amplified watermark texts via comparing outputs from the student model and weakly watermarked references, followed by bidirectional distillation to train new student models capable of watermark removal and watermark forgery, respectively. Extensive experiments show that CDG-KD effectively performs attacks while preserving the general performance of the distilled model. Our findings underscore critical need for developing watermarking schemes that are robust and unforgeable.</li>
</ul>

<h3>Title: Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening</h3>
<ul>
<li><strong>Authors: </strong>Radia Berreziga, Mohammed Brahimi, Khairedine Kraim, Hamid Azzoune</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17497">https://arxiv.org/abs/2504.17497</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17497">https://arxiv.org/pdf/2504.17497</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17497]] Combining GCN Structural Learning with LLM Chemical Knowledge for or Enhanced Virtual Screening(https://arxiv.org/abs/2504.17497)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Virtual screening plays a critical role in modern drug discovery by enabling the identification of promising candidate molecules for experimental validation. Traditional machine learning methods such as support vector machines (SVM) and XGBoost rely on predefined molecular representations, often leading to information loss and potential bias. In contrast, deep learning approaches-particularly Graph Convolutional Networks (GCNs)-offer a more expressive and unbiased alternative by operating directly on molecular graphs. Meanwhile, Large Language Models (LLMs) have recently demonstrated state-of-the-art performance in drug design, thanks to their capacity to capture complex chemical patterns from large-scale data via attention mechanisms. In this paper, we propose a hybrid architecture that integrates GCNs with LLM-derived embeddings to combine localized structural learning with global chemical knowledge. The LLM embeddings can be precomputed and stored in a molecular feature library, removing the need to rerun the LLM during training or inference and thus maintaining computational efficiency. We found that concatenating the LLM embeddings after each GCN layer-rather than only at the final layer-significantly improves performance, enabling deeper integration of global context throughout the network. The resulting model achieves superior results, with an F1-score of (88.8%), outperforming standalone GCN (87.9%), XGBoost (85.5%), and SVM (85.4%) baselines.</li>
</ul>

<h3>Title: Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zihan Cheng, Jintao Guo, Jian Zhang, Lei Qi, Luping Zhou, Yinghuan Shi, Yang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17515">https://arxiv.org/abs/2504.17515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17515">https://arxiv.org/pdf/2504.17515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17515]] Mamba-Sea: A Mamba-based Framework with Global-to-Local Sequence Augmentation for Generalizable Medical Image Segmentation(https://arxiv.org/abs/2504.17515)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>To segment medical images with distribution shifts, domain generalization (DG) has emerged as a promising setting to train models on source domains that can generalize to unseen target domains. Existing DG methods are mainly based on CNN or ViT architectures. Recently, advanced state space models, represented by Mamba, have shown promising results in various supervised medical image segmentation. The success of Mamba is primarily owing to its ability to capture long-range dependencies while keeping linear complexity with input sequence length, making it a promising alternative to CNNs and ViTs. Inspired by the success, in the paper, we explore the potential of the Mamba architecture to address distribution shifts in DG for medical image segmentation. Specifically, we propose a novel Mamba-based framework, Mamba-Sea, incorporating global-to-local sequence augmentation to improve the model's generalizability under domain shift issues. Our Mamba-Sea introduces a global augmentation mechanism designed to simulate potential variations in appearance across different sites, aiming to suppress the model's learning of domain-specific information. At the local level, we propose a sequence-wise augmentation along input sequences, which perturbs the style of tokens within random continuous sub-sequences by modeling and resampling style statistics associated with domain shifts. To our best knowledge, Mamba-Sea is the first work to explore the generalization of Mamba for medical image segmentation, providing an advanced and promising Mamba-based architecture with strong robustness to domain shifts. Remarkably, our proposed method is the first to surpass a Dice coefficient of 90% on the Prostate dataset, which exceeds previous SOTA of 88.61%. The code is available at this https URL.</li>
</ul>

<h3>Title: Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Anyi Xiao, Cihui Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17522">https://arxiv.org/abs/2504.17522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17522">https://arxiv.org/pdf/2504.17522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17522]] Towards One-Stage End-to-End Table Structure Recognition with Parallel Regression for Diverse Scenarios(https://arxiv.org/abs/2504.17522)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Table structure recognition aims to parse tables in unstructured data into machine-understandable formats. Recent methods address this problem through a two-stage process or optimized one-stage approaches. However, these methods either require multiple networks to be serially trained and perform more time-consuming sequential decoding, or rely on complex post-processing algorithms to parse the logical structure of tables. They struggle to balance cross-scenario adaptability, robustness, and computational efficiency. In this paper, we propose a one-stage end-to-end table structure parsing network called TableCenterNet. This network unifies the prediction of table spatial and logical structure into a parallel regression task for the first time, and implicitly learns the spatial-logical location mapping laws of cells through a synergistic architecture of shared feature extraction layers and task-specific decoding. Compared with two-stage methods, our method is easier to train and faster to infer. Experiments on benchmark datasets show that TableCenterNet can effectively parse table structures in diverse scenarios and achieve state-of-the-art performance on the TableGraph-24k dataset. Code is available at this https URL.</li>
</ul>

<h3>Title: ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Junyan Zhang, Yan Li, Mengxiao Geng, Liu Shi, Qiegen Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17524">https://arxiv.org/abs/2504.17524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17524">https://arxiv.org/pdf/2504.17524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17524]] ESDiff: Encoding Strategy-inspired Diffusion Model with Few-shot Learning for Color Image Inpainting(https://arxiv.org/abs/2504.17524)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Image inpainting is a technique used to restore missing or damaged regions of an image. Traditional methods primarily utilize information from adjacent pixels for reconstructing missing areas, while they struggle to preserve complex details and structures. Simultaneously, models based on deep learning necessitate substantial amounts of training data. To address this challenge, an encoding strategy-inspired diffusion model with few-shot learning for color image inpainting is proposed in this paper. The main idea of this novel encoding strategy is the deployment of a "virtual mask" to construct high-dimensional objects through mutual perturbations between channels. This approach enables the diffusion model to capture diverse image representations and detailed features from limited training samples. Moreover, the encoding strategy leverages redundancy between channels, integrates with low-rank methods during iterative inpainting, and incorporates the diffusion model to achieve accurate information output. Experimental results indicate that our method exceeds current techniques in quantitative metrics, and the reconstructed images quality has been improved in aspects of texture and structural integrity, leading to more precise and coherent results.</li>
</ul>

<h3>Title: Text-to-Image Alignment in Denoising-Based Models through Step Selection</h3>
<ul>
<li><strong>Authors: </strong>Paul Grimal, Hervé Le Borgne, Olivier Ferret</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17525">https://arxiv.org/abs/2504.17525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17525">https://arxiv.org/pdf/2504.17525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17525]] Text-to-Image Alignment in Denoising-Based Models through Step Selection(https://arxiv.org/abs/2504.17525)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Visual generative AI models often encounter challenges related to text-image alignment and reasoning limitations. This paper presents a novel method for selectively enhancing the signal at critical denoising steps, optimizing image generation based on input semantics. Our approach addresses the shortcomings of early-stage signal modifications, demonstrating that adjustments made at later stages yield superior results. We conduct extensive experiments to validate the effectiveness of our method in producing semantically aligned images on Diffusion and Flow Matching model, achieving state-of-the-art performance. Our results highlight the importance of a judicious choice of sampling stage to improve performance and overall image alignment.</li>
</ul>

<h3>Title: Cooperative Task Offloading through Asynchronous Deep Reinforcement Learning in Mobile Edge Computing for Future Networks</h3>
<ul>
<li><strong>Authors: </strong>Yuelin Liu, Haiyuan Li, Xenofon Vasilakos, Rasheed Hussain, Dimitra Simeonidou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17526">https://arxiv.org/abs/2504.17526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17526">https://arxiv.org/pdf/2504.17526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17526]] Cooperative Task Offloading through Asynchronous Deep Reinforcement Learning in Mobile Edge Computing for Future Networks(https://arxiv.org/abs/2504.17526)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Future networks (including 6G) are poised to accelerate the realisation of Internet of Everything. However, it will result in a high demand for computing resources to support new services. Mobile Edge Computing (MEC) is a promising solution, enabling to offload computation-intensive tasks to nearby edge servers from the end-user devices, thereby reducing latency and energy consumption. However, relying solely on a single MEC server for task offloading can lead to uneven resource utilisation and suboptimal performance in complex scenarios. Additionally, traditional task offloading strategies specialise in centralised policy decisions, which unavoidably entail extreme transmission latency and reach computational bottleneck. To fill the gaps, we propose a latency and energy efficient Cooperative Task Offloading framework with Transformer-driven Prediction (CTO-TP), leveraging asynchronous multi-agent deep reinforcement learning to address these challenges. This approach fosters edge-edge cooperation and decreases the synchronous waiting time by performing asynchronous training, optimising task offloading, and resource allocation across distributed networks. The performance evaluation demonstrates that the proposed CTO-TP algorithm reduces up to 80% overall system latency and 87% energy consumption compared to the baseline schemes.</li>
</ul>

<h3>Title: TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction</h3>
<ul>
<li><strong>Authors: </strong>Weijie Liu, Ziwei Zhan, Carlee Joe-Wong, Edith Ngai, Jingpu Duan, Deke Guo, Xu Chen, Xiaoxi Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17528">https://arxiv.org/abs/2504.17528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17528">https://arxiv.org/pdf/2504.17528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17528]] TACO: Tackling Over-correction in Federated Learning with Tailored Adaptive Correction(https://arxiv.org/abs/2504.17528)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Non-independent and identically distributed (Non-IID) data across edge clients have long posed significant challenges to federated learning (FL) training in edge computing environments. Prior works have proposed various methods to mitigate this statistical heterogeneity. While these works can achieve good theoretical performance, in this work we provide the first investigation into a hidden over-correction phenomenon brought by the uniform model correction coefficients across clients adopted by existing methods. Such over-correction could degrade model performance and even cause failures in model convergence. To address this, we propose TACO, a novel algorithm that addresses the non-IID nature of clients' data by implementing fine-grained, client-specific gradient correction and model aggregation, steering local models towards a more accurate global optimum. Moreover, we verify that leading FL algorithms generally have better model accuracy in terms of communication rounds rather than wall-clock time, resulting from their extra computation overhead imposed on clients. To enhance the training efficiency, TACO deploys a lightweight model correction and tailored aggregation approach that requires minimum computation overhead and no extra information beyond the synchronized model parameters. To validate TACO's effectiveness, we present the first FL convergence analysis that reveals the root cause of over-correction. Extensive experiments across various datasets confirm TACO's superior and stable performance in practice.</li>
</ul>

<h3>Title: Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste</h3>
<ul>
<li><strong>Authors: </strong>Zan-Kai Chong, Hiroyuki Ohsaki, Bryan Ng</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17539">https://arxiv.org/abs/2504.17539</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17539">https://arxiv.org/pdf/2504.17539</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17539]] Proof of Useful Intelligence (PoUI): Blockchain Consensus Beyond Energy Waste(https://arxiv.org/abs/2504.17539)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Blockchain technology enables secure, transparent data management in decentralized systems, supporting applications from cryptocurrencies like Bitcoin to tokenizing real-world assets like property. Its scalability and sustainability hinge on consensus mechanisms balancing security and efficiency. Proof of Work (PoW), used by Bitcoin, ensures security through energy-intensive computations but demands significant resources. Proof of Stake (PoS), as in Ethereum post-Merge, selects validators based on staked cryptocurrency, offering energy efficiency but risking centralization from wealth concentration. With AI models straining computational resources, we propose Proof of Useful Intelligence (PoUI), a hybrid consensus mechanism. In PoUI, workers perform AI tasks like language processing or image analysis to earn coins, which are staked to secure the network, blending security with practical utility. Decentralized nodes--job posters, market coordinators, workers, and validators --collaborate via smart contracts to manage tasks and rewards.</li>
</ul>

<h3>Title: An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm</h3>
<ul>
<li><strong>Authors: </strong>Ahmadreza Shateri, Negar Nourani, Morteza Dorrigiv, Hamid Nasiri</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17540">https://arxiv.org/abs/2504.17540</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17540">https://arxiv.org/pdf/2504.17540</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17540]] An Explainable Nature-Inspired Framework for Monkeypox Diagnosis: Xception Features Combined with NGBoost and African Vultures Optimization Algorithm(https://arxiv.org/abs/2504.17540)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>The recent global spread of monkeypox, particularly in regions where it has not historically been prevalent, has raised significant public health concerns. Early and accurate diagnosis is critical for effective disease management and control. In response, this study proposes a novel deep learning-based framework for the automated detection of monkeypox from skin lesion images, leveraging the power of transfer learning, dimensionality reduction, and advanced machine learning techniques. We utilize the newly developed Monkeypox Skin Lesion Dataset (MSLD), which includes images of monkeypox, chickenpox, and measles, to train and evaluate our models. The proposed framework employs the Xception architecture for deep feature extraction, followed by Principal Component Analysis (PCA) for dimensionality reduction, and the Natural Gradient Boosting (NGBoost) algorithm for classification. To optimize the model's performance and generalization, we introduce the African Vultures Optimization Algorithm (AVOA) for hyperparameter tuning, ensuring efficient exploration of the parameter space. Our results demonstrate that the proposed AVOA-NGBoost model achieves state-of-the-art performance, with an accuracy of 97.53%, F1-score of 97.72% and an AUC of 97.47%. Additionally, we enhance model interpretability using Grad-CAM and LIME techniques, providing insights into the decision-making process and highlighting key features influencing classification. This framework offers a highly precise and efficient diagnostic tool, potentially aiding healthcare providers in early detection and diagnosis, particularly in resource-constrained environments.</li>
</ul>

<h3>Title: A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Deng, Zonghan Wu, Huan Huo, Guandong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.IR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17547">https://arxiv.org/abs/2504.17547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17547">https://arxiv.org/pdf/2504.17547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17547]] A Comprehensive Survey of Knowledge-Based Vision Question Answering Systems: The Lifecycle of Knowledge in Visual Reasoning Task(https://arxiv.org/abs/2504.17547)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge-based Vision Question Answering (KB-VQA) extends general Vision Question Answering (VQA) by not only requiring the understanding of visual and textual inputs but also extensive range of knowledge, enabling significant advancements across various real-world applications. KB-VQA introduces unique challenges, including the alignment of heterogeneous information from diverse modalities and sources, the retrieval of relevant knowledge from noisy or large-scale repositories, and the execution of complex reasoning to infer answers from the combined context. With the advancement of Large Language Models (LLMs), KB-VQA systems have also undergone a notable transformation, where LLMs serve as powerful knowledge repositories, retrieval-augmented generators and strong reasoners. Despite substantial progress, no comprehensive survey currently exists that systematically organizes and reviews the existing KB-VQA methods. This survey aims to fill this gap by establishing a structured taxonomy of KB-VQA approaches, and categorizing the systems into main stages: knowledge representation, knowledge retrieval, and knowledge reasoning. By exploring various knowledge integration techniques and identifying persistent challenges, this work also outlines promising future research directions, providing a foundation for advancing KB-VQA models and their applications.</li>
</ul>

<h3>Title: HalluLens: LLM Hallucination Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17550">https://arxiv.org/abs/2504.17550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17550">https://arxiv.org/pdf/2504.17550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17550]] HalluLens: LLM Hallucination Benchmark(https://arxiv.org/abs/2504.17550)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often generate responses that deviate from user input or training data, a phenomenon known as "hallucination." These hallucinations undermine user trust and hinder the adoption of generative AI systems. Addressing hallucinations is essential for the advancement of LLMs. This paper introduces a comprehensive hallucination benchmark, incorporating both new extrinsic and existing intrinsic evaluation tasks, built upon clear taxonomy of hallucination. A major challenge in benchmarking hallucinations is the lack of a unified framework due to inconsistent definitions and categorizations. We disentangle LLM hallucination from "factuality," proposing a clear taxonomy that distinguishes between extrinsic and intrinsic hallucinations, to promote consistency and facilitate research. Extrinsic hallucinations, where the generated content is not consistent with the training data, are increasingly important as LLMs evolve. Our benchmark includes dynamic test set generation to mitigate data leakage and ensure robustness against such leakage. We also analyze existing benchmarks, highlighting their limitations and saturation. The work aims to: (1) establish a clear taxonomy of hallucinations, (2) introduce new extrinsic hallucination tasks, with data that can be dynamically regenerated to prevent saturation by leakage, (3) provide a comprehensive analysis of existing benchmarks, distinguishing them from factuality evaluations.</li>
</ul>

<h3>Title: DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyu Tian, Sitong Zhao, Haotian Wang, Shuaiting Chen, Yiping Peng, Yunjie Ji, Han Zhao, Xiangang Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17565">https://arxiv.org/abs/2504.17565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17565">https://arxiv.org/pdf/2504.17565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17565]] DeepDistill: Enhancing LLM Reasoning Capabilities via Large-Scale Difficulty-Graded Data Training(https://arxiv.org/abs/2504.17565)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) have recently achieved remarkable performance on various complex reasoning benchmarks, the academic community still lacks an in-depth understanding of base model training processes and data quality. To address this, we construct a large-scale, difficulty-graded reasoning dataset containing approximately 3.34 million unique queries of varying difficulty levels and about 40 million distilled responses generated by multiple models over several passes. Leveraging pass rate and Coefficient of Variation (CV), we precisely select the most valuable training data to enhance reasoning capability. Notably, we observe a training pattern shift, indicating that reasoning-focused training based on base models requires higher learning rates for effective training. Using this carefully selected data, we significantly improve the reasoning capabilities of the base model, achieving a pass rate of 79.2\% on the AIME2024 mathematical reasoning benchmark. This result surpasses most current distilled models and closely approaches state-of-the-art performance. We provide detailed descriptions of our data processing, difficulty assessment, and training methodology, and have publicly released all datasets and methods to promote rapid progress in open-source long-reasoning LLMs. The dataset is available at: this https URL</li>
</ul>

<h3>Title: RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore</h3>
<ul>
<li><strong>Authors: </strong>Zhenkai Qin, Guifang Yang, Dongze Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17574">https://arxiv.org/abs/2504.17574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17574">https://arxiv.org/pdf/2504.17574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17574]] RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore(https://arxiv.org/abs/2504.17574)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.</li>
</ul>

<h3>Title: Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images</h3>
<ul>
<li><strong>Authors: </strong>Zebo Huang, Yinghui Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17582">https://arxiv.org/abs/2504.17582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17582">https://arxiv.org/pdf/2504.17582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17582]] Occlusion-Aware Self-Supervised Monocular Depth Estimation for Weak-Texture Endoscopic Images(https://arxiv.org/abs/2504.17582)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>We propose a self-supervised monocular depth estimation network tailored for endoscopic scenes, aiming to infer depth within the gastrointestinal tract from monocular images. Existing methods, though accurate, typically assume consistent illumination, which is often violated due to dynamic lighting and occlusions caused by GI motility. These variations lead to incorrect geometric interpretations and unreliable self-supervised signals, degrading depth reconstruction quality. To address this, we introduce an occlusion-aware self-supervised framework. First, we incorporate an occlusion mask for data augmentation, generating pseudo-labels by simulating viewpoint-dependent occlusion scenarios. This enhances the model's ability to learn robust depth features under partial visibility. Second, we leverage semantic segmentation guided by non-negative matrix factorization, clustering convolutional activations to generate pseudo-labels in texture-deprived regions, thereby improving segmentation accuracy and mitigating information loss from lighting changes. Experimental results on the SCARED dataset show that our method achieves state-of-the-art performance in self-supervised depth estimation. Additionally, evaluations on the Endo-SLAM and SERV-CT datasets demonstrate strong generalization across diverse endoscopic environments.</li>
</ul>

<h3>Title: RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network</h3>
<ul>
<li><strong>Authors: </strong>Boyue Xu, Yi Xu, Ruichao Hou, Jia Bei, Tongwei Ren, Gangshan Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17595">https://arxiv.org/abs/2504.17595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17595">https://arxiv.org/pdf/2504.17595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17595]] RGB-D Tracking via Hierarchical Modality Aggregation and Distribution Network(https://arxiv.org/abs/2504.17595)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The integration of dual-modal features has been pivotal in advancing RGB-Depth (RGB-D) tracking. However, current trackers are less efficient and focus solely on single-level features, resulting in weaker robustness in fusion and slower speeds that fail to meet the demands of real-world applications. In this paper, we introduce a novel network, denoted as HMAD (Hierarchical Modality Aggregation and Distribution), which addresses these challenges. HMAD leverages the distinct feature representation strengths of RGB and depth modalities, giving prominence to a hierarchical approach for feature distribution and fusion, thereby enhancing the robustness of RGB-D tracking. Experimental results on various RGB-D datasets demonstrate that HMAD achieves state-of-the-art performance. Moreover, real-world experiments further validate HMAD's capacity to effectively handle a spectrum of tracking challenges in real-time scenarios.</li>
</ul>

<h3>Title: Interpretable non-linear dimensionality reduction using gaussian weighted linear transformation</h3>
<ul>
<li><strong>Authors: </strong>Erik Bergh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17601">https://arxiv.org/abs/2504.17601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17601">https://arxiv.org/pdf/2504.17601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17601]] Interpretable non-linear dimensionality reduction using gaussian weighted linear transformation(https://arxiv.org/abs/2504.17601)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Dimensionality reduction techniques are fundamental for analyzing and visualizing high-dimensional data. With established methods like t-SNE and PCA presenting a trade-off between representational power and interpretability. This paper introduces a novel approach that bridges this gap by combining the interpretability of linear methods with the expressiveness of non-linear transformations. The proposed algorithm constructs a non-linear mapping between high-dimensional and low-dimensional spaces through a combination of linear transformations, each weighted by Gaussian functions. This architecture enables complex non-linear transformations while preserving the interpretability advantages of linear methods, as each transformation can be analyzed independently. The resulting model provides both powerful dimensionality reduction and transparent insights into the transformed space. Techniques for interpreting the learned transformations are presented, including methods for identifying suppressed dimensions and how space is expanded and contracted. These tools enable practitioners to understand how the algorithm preserves and modifies geometric relationships during dimensionality reduction. To ensure the practical utility of this algorithm, the creation of user-friendly software packages is emphasized, facilitating its adoption in both academia and industry.</li>
</ul>

<h3>Title: TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation</h3>
<ul>
<li><strong>Authors: </strong>Bowen Deng, Chang Xu, Hao Li, Yuhao Huang, Min Hou, Jiang Bian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17613">https://arxiv.org/abs/2504.17613</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17613">https://arxiv.org/pdf/2504.17613</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17613]] TarDiff: Target-Oriented Diffusion Guidance for Synthetic Electronic Health Record Time Series Generation(https://arxiv.org/abs/2504.17613)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Synthetic Electronic Health Record (EHR) time-series generation is crucial for advancing clinical machine learning models, as it helps address data scarcity by providing more training data. However, most existing approaches focus primarily on replicating statistical distributions and temporal dependencies of real-world data. We argue that fidelity to observed data alone does not guarantee better model performance, as common patterns may dominate, limiting the representation of rare but important conditions. This highlights the need for generate synthetic samples to improve performance of specific clinical models to fulfill their target outcomes. To address this, we propose TarDiff, a novel target-oriented diffusion framework that integrates task-specific influence guidance into the synthetic data generation process. Unlike conventional approaches that mimic training data distributions, TarDiff optimizes synthetic samples by quantifying their expected contribution to improving downstream model performance through influence functions. Specifically, we measure the reduction in task-specific loss induced by synthetic samples and embed this influence gradient into the reverse diffusion process, thereby steering the generation towards utility-optimized data. Evaluated on six publicly available EHR datasets, TarDiff achieves state-of-the-art performance, outperforming existing methods by up to 20.4% in AUPRC and 18.4% in AUROC. Our results demonstrate that TarDiff not only preserves temporal fidelity but also enhances downstream model performance, offering a robust solution to data scarcity and class imbalance in healthcare analytics.</li>
</ul>

<h3>Title: Decentralized Time Series Classification with ROCKET Features</h3>
<ul>
<li><strong>Authors: </strong>Bruno Casella, Matthias Jakobs, Marco Aldinucci, Sebastian Buschjäger</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17617">https://arxiv.org/abs/2504.17617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17617">https://arxiv.org/pdf/2504.17617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17617]] Decentralized Time Series Classification with ROCKET Features(https://arxiv.org/abs/2504.17617)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, federate</a></li>
<li><strong>Abstract: </strong>Time series classification (TSC) is a critical task with applications in various domains, including healthcare, finance, and industrial monitoring. Due to privacy concerns and data regulations, Federated Learning has emerged as a promising approach for learning from distributed time series data without centralizing raw information. However, most FL solutions rely on a client-server architecture, which introduces robustness and confidentiality risks related to the distinguished role of the server, which is a single point of failure and can observe knowledge extracted from clients. To address these challenges, we propose DROCKS, a fully decentralized FL framework for TSC that leverages ROCKET (RandOm Convolutional KErnel Transform) features. In DROCKS, the global model is trained by sequentially traversing a structured path across federation nodes, where each node refines the model and selects the most effective local kernels before passing them to the successor. Extensive experiments on the UCR archive demonstrate that DROCKS outperforms state-of-the-art client-server FL approaches while being more resilient to node failures and malicious attacks. Our code is available at this https URL.</li>
</ul>

<h3>Title: Enhancing CNNs robustness to occlusions with bioinspired filters for border completion</h3>
<ul>
<li><strong>Authors: </strong>Catarina P. Coutinho, Aneeqa Merhab, Janko Petkovic, Ferdinando Zanchetta, Rita Fioresi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17619">https://arxiv.org/abs/2504.17619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17619">https://arxiv.org/pdf/2504.17619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17619]] Enhancing CNNs robustness to occlusions with bioinspired filters for border completion(https://arxiv.org/abs/2504.17619)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We exploit the mathematical modeling of the visual cortex mechanism for border completion to define custom filters for CNNs. We see a consistent improvement in performance, particularly in accuracy, when our modified LeNet 5 is tested with occluded MNIST images.</li>
</ul>

<h3>Title: Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Julius Vetter, Manuel Gloeckler, Daniel Gedon, Jakob H. Macke</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17660">https://arxiv.org/abs/2504.17660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17660">https://arxiv.org/pdf/2504.17660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17660]] Effortless, Simulation-Efficient Bayesian Inference using Tabular Foundation Models(https://arxiv.org/abs/2504.17660)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Simulation-based inference (SBI) offers a flexible and general approach to performing Bayesian inference: In SBI, a neural network is trained on synthetic data simulated from a model and used to rapidly infer posterior distributions for observed data. A key goal for SBI is to achieve accurate inference with as few simulations as possible, especially for expensive simulators. In this work, we address this challenge by repurposing recent probabilistic foundation models for tabular data: We show how tabular foundation models -- specifically TabPFN -- can be used as pre-trained autoregressive conditional density estimators for SBI. We propose Neural Posterior Estimation with Prior-data Fitted Networks (NPE-PF) and show that it is competitive with current SBI approaches in terms of accuracy for both benchmark tasks and two complex scientific inverse problems. Crucially, it often substantially outperforms them in terms of simulation efficiency, sometimes requiring orders of magnitude fewer simulations. NPE-PF eliminates the need for inference network selection, training, and hyperparameter tuning. We also show that it exhibits superior robustness to model misspecification and can be scaled to simulation budgets that exceed the context size limit of TabPFN. NPE-PF provides a new direction for SBI, where training-free, general-purpose inference models offer efficient, easy-to-use, and flexible solutions for a wide range of stochastic inverse problems.</li>
</ul>

<h3>Title: Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics</h3>
<ul>
<li><strong>Authors: </strong>Zena Al-Khalili, Nick Howell, Dietrich Klakow</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17665">https://arxiv.org/abs/2504.17665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17665">https://arxiv.org/pdf/2504.17665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17665]] Evaluating Grounded Reasoning by Code-Assisted Large Language Models for Mathematics(https://arxiv.org/abs/2504.17665)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Assisting LLMs with code generation improved their performance on mathematical reasoning tasks. However, the evaluation of code-assisted LLMs is generally restricted to execution correctness, lacking a rigorous evaluation of their generated programs. In this work, we bridge this gap by conducting an in-depth analysis of code-assisted LLMs' generated programs in response to math reasoning tasks. Our evaluation focuses on the extent to which LLMs ground their programs to math rules, and how that affects their end performance. For this purpose, we assess the generations of five different LLMs, on two different math datasets, both manually and automatically. Our results reveal that the distribution of grounding depends on LLMs' capabilities and the difficulty of math problems. Furthermore, mathematical grounding is more effective for closed-source models, while open-source models fail to employ math rules in their solutions correctly. On MATH500, the percentage of grounded programs decreased to half, while the ungrounded generations doubled in comparison to ASDiv grade-school problems. Our work highlights the need for in-depth evaluation beyond execution accuracy metrics, toward a better understanding of code-assisted LLMs' capabilities and limits in the math domain.</li>
</ul>

<h3>Title: DiMeR: Disentangled Mesh Reconstruction Model</h3>
<ul>
<li><strong>Authors: </strong>Lutao Jiang, Jiantao Lin, Kanghao Chen, Wenhang Ge, Xin Yang, Yifan Jiang, Yuanhuiyi Lyu, Xu Zheng, Yingcong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17670">https://arxiv.org/abs/2504.17670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17670">https://arxiv.org/pdf/2504.17670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17670]] DiMeR: Disentangled Mesh Reconstruction Model(https://arxiv.org/abs/2504.17670)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, generative</a></li>
<li><strong>Abstract: </strong>With the advent of large-scale 3D datasets, feed-forward 3D generative models, such as the Large Reconstruction Model (LRM), have gained significant attention and achieved remarkable success. However, we observe that RGB images often lead to conflicting training objectives and lack the necessary clarity for geometry reconstruction. In this paper, we revisit the inductive biases associated with mesh reconstruction and introduce DiMeR, a novel disentangled dual-stream feed-forward model for sparse-view mesh reconstruction. The key idea is to disentangle both the input and framework into geometry and texture parts, thereby reducing the training difficulty for each part according to the Principle of Occam's Razor. Given that normal maps are strictly consistent with geometry and accurately capture surface variations, we utilize normal maps as exclusive input for the geometry branch to reduce the complexity between the network's input and output. Moreover, we improve the mesh extraction algorithm to introduce 3D ground truth supervision. As for texture branch, we use RGB images as input to obtain the textured mesh. Overall, DiMeR demonstrates robust capabilities across various tasks, including sparse-view reconstruction, single-image-to-3D, and text-to-3D. Numerous experiments show that DiMeR significantly outperforms previous methods, achieving over 30% improvement in Chamfer Distance on the GSO and OmniObject3D dataset.</li>
</ul>

<h3>Title: Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yuanchang Ye, Weiyan Wen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17671">https://arxiv.org/abs/2504.17671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17671">https://arxiv.org/pdf/2504.17671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17671]] Data-Driven Calibration of Prediction Sets in Large Vision-Language Models Based on Inductive Conformal Prediction(https://arxiv.org/abs/2504.17671)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This study addresses the critical challenge of hallucination mitigation in Large Vision-Language Models (LVLMs) for Visual Question Answering (VQA) tasks through a Split Conformal Prediction (SCP) framework. While LVLMs excel in multi-modal reasoning, their outputs often exhibit hallucinated content with high confidence, posing risks in safety-critical applications. We propose a model-agnostic uncertainty quantification method that integrates dynamic threshold calibration and cross-modal consistency verification. By partitioning data into calibration and test sets, the framework computes nonconformity scores to construct prediction sets with statistical guarantees under user-defined risk levels ($\alpha$). Key innovations include: (1) rigorous control of \textbf{marginal coverage} to ensure empirical error rates remain strictly below $\alpha$; (2) dynamic adjustment of prediction set sizes inversely with $\alpha$, filtering low-confidence outputs; (3) elimination of prior distribution assumptions and retraining requirements. Evaluations on benchmarks (ScienceQA, MMMU) with eight LVLMs demonstrate that SCP enforces theoretical guarantees across all $\alpha$ values. The framework achieves stable performance across varying calibration-to-test split ratios, underscoring its robustness for real-world deployment in healthcare, autonomous systems, and other safety-sensitive domains. This work bridges the gap between theoretical reliability and practical applicability in multi-modal AI systems, offering a scalable solution for hallucination detection and uncertainty-aware decision-making.</li>
</ul>

<h3>Title: Energy Considerations of Large Language Model Inference and Efficiency Optimizations</h3>
<ul>
<li><strong>Authors: </strong>Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17674">https://arxiv.org/abs/2504.17674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17674">https://arxiv.org/pdf/2504.17674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17674]] Energy Considerations of Large Language Model Inference and Efficiency Optimizations(https://arxiv.org/abs/2504.17674)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) scale in size and adoption, their computational and environmental costs continue to rise. Prior benchmarking efforts have primarily focused on latency reduction in idealized settings, often overlooking the diverse real-world inference workloads that shape energy use. In this work, we systematically analyze the energy implications of common inference efficiency optimizations across diverse Natural Language Processing (NLP) and generative Artificial Intelligence (AI) workloads, including conversational AI and code generation. We introduce a modeling approach that approximates real-world LLM workflows through a binning strategy for input-output token distributions and batch size variations. Our empirical analysis spans software frameworks, decoding strategies, GPU architectures, online and offline serving settings, and model parallelism configurations. We show that the effectiveness of inference optimizations is highly sensitive to workload geometry, software stack, and hardware accelerators, demonstrating that naive energy estimates based on FLOPs or theoretical GPU utilization significantly underestimate real-world energy consumption. Our findings reveal that the proper application of relevant inference efficiency optimizations can reduce total energy use by up to 73% from unoptimized baselines. These insights provide a foundation for sustainable LLM deployment and inform energy-efficient design strategies for future AI infrastructure.</li>
</ul>

<h3>Title: Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to Single-Feature Adversarial Perturbations</h3>
<ul>
<li><strong>Authors: </strong>Ahod Alghuried, Ali Alkinoon, Abdulaziz Alghamdi, Soohyeon Choi, Manar Mohaisen, David Mohaisen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17684">https://arxiv.org/abs/2504.17684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17684">https://arxiv.org/pdf/2504.17684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17684]] Evaluating the Vulnerability of ML-Based Ethereum Phishing Detectors to Single-Feature Adversarial Perturbations(https://arxiv.org/abs/2504.17684)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This paper explores the vulnerability of machine learning models to simple single-feature adversarial attacks in the context of Ethereum fraudulent transaction detection. Through comprehensive experimentation, we investigate the impact of various adversarial attack strategies on model performance metrics. Our findings, highlighting how prone those techniques are to simple attacks, are alarming, and the inconsistency in the attacks' effect on different algorithms promises ways for attack mitigation. We examine the effectiveness of different mitigation strategies, including adversarial training and enhanced feature selection, in enhancing model robustness and show their effectiveness.</li>
</ul>

<h3>Title: Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks</h3>
<ul>
<li><strong>Authors: </strong>Haru-Tada Sato, Fuka Matsuzaki, Jun-ichiro Takahashi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17685">https://arxiv.org/abs/2504.17685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17685">https://arxiv.org/pdf/2504.17685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17685]] Ensemble Bayesian Inference: Leveraging Small Language Models to Achieve LLM-level Accuracy in Profile Matching Tasks(https://arxiv.org/abs/2504.17685)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study explores the potential of small language model(SLM) ensembles to achieve accuracy comparable to proprietary large language models (LLMs). We propose Ensemble Bayesian Inference (EBI), a novel approach that applies Bayesian estimation to combine judgments from multiple SLMs, allowing them to exceed the performance limitations of individual models. Our experiments on diverse tasks(aptitude assessments and consumer profile analysis in both Japanese and English) demonstrate EBI's effectiveness. Notably, we analyze cases where incorporating models with negative Lift values into ensembles improves overall performance, and we examine the method's efficacy across different languages. These findings suggest new possibilities for constructing high-performance AI systems with limited computational resources and for effectively utilizing models with individually lower performance. Building on existing research on LLM performance evaluation, ensemble methods, and open-source LLM utilization, we discuss the novelty and significance of our approach.</li>
</ul>

<h3>Title: User Profiles: The Achilles' Heel of Web Browsers</h3>
<ul>
<li><strong>Authors: </strong>Dolière Francis Somé, Moaz Airan, Zakir Durumeric, Cristian-Alexandru Staicu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17692">https://arxiv.org/abs/2504.17692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17692">https://arxiv.org/pdf/2504.17692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17692]] User Profiles: The Achilles' Heel of Web Browsers(https://arxiv.org/abs/2504.17692)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, protect, attack</a></li>
<li><strong>Abstract: </strong>Web browsers provide the security foundation for our online experiences. Significant research has been done into the security of browsers themselves, but relatively little investigation has been done into how they interact with the operating system or the file system. In this work, we provide the first systematic security study of browser profiles, the on-disk persistence layer of browsers, used for storing everything from users' authentication cookies and browser extensions to certificate trust decisions and device permissions. We show that, except for the Tor Browser, all modern browsers store sensitive data in home directories with little to no integrity or confidentiality controls. We show that security measures like password and cookie encryption can be easily bypassed. In addition, HTTPS can be sidestepped entirely by deploying malicious root certificates within users' browser profiles. The Public Key Infrastructure (PKI), the backbone of the secure Web. HTTPS can be fully bypassed with the deployment of custom potentially malicious root certificates. More worryingly, we show how these powerful attacks can be fully mounted directly from web browsers themselves, through the File System Access API, a recent feature added by Chromium browsers that enables a website to directly manipulate a user's file system via JavaScript. In a series of case studies, we demonstrate how an attacker can install malicious browser extensions, inject additional root certificates, hijack HTTPS traffic, and enable websites to access hardware devices like the camera and GPS. Based on our findings, we argue that researchers and browser vendors need to develop and deploy more secure mechanisms for protecting users' browser data against file system attackers.</li>
</ul>

<h3>Title: Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Edward Collins, Michel Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17703">https://arxiv.org/abs/2504.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17703">https://arxiv.org/pdf/2504.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17703]] Federated Learning: A Survey on Privacy-Preserving Collaborative Intelligence(https://arxiv.org/abs/2504.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) has emerged as a transformative paradigm in the field of distributed machine learning, enabling multiple clients such as mobile devices, edge nodes, or organizations to collaboratively train a shared global model without the need to centralize sensitive data. This decentralized approach addresses growing concerns around data privacy, security, and regulatory compliance, making it particularly attractive in domains such as healthcare, finance, and smart IoT systems. This survey provides a concise yet comprehensive overview of Federated Learning, beginning with its core architecture and communication protocol. We discuss the standard FL lifecycle, including local training, model aggregation, and global updates. A particular emphasis is placed on key technical challenges such as handling non-IID (non-independent and identically distributed) data, mitigating system and hardware heterogeneity, reducing communication overhead, and ensuring privacy through mechanisms like differential privacy and secure aggregation. Furthermore, we examine emerging trends in FL research, including personalized FL, cross-device versus cross-silo settings, and integration with other paradigms such as reinforcement learning and quantum computing. We also highlight real-world applications and summarize benchmark datasets and evaluation metrics commonly used in FL research. Finally, we outline open research problems and future directions to guide the development of scalable, efficient, and trustworthy FL systems.</li>
</ul>

<h3>Title: Safety in Large Reasoning Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Cheng Wang, Yue Liu, Baolong Li, Duzhen Zhang, Zhongzhi Li, Junfeng Fang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17704">https://arxiv.org/abs/2504.17704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17704">https://arxiv.org/pdf/2504.17704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17704]] Safety in Large Reasoning Models: A Survey(https://arxiv.org/abs/2504.17704)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>Large Reasoning Models (LRMs) have exhibited extraordinary prowess in tasks like mathematics and coding, leveraging their advanced reasoning capabilities. Nevertheless, as these capabilities progress, significant concerns regarding their vulnerabilities and safety have arisen, which can pose challenges to their deployment and application in real-world settings. This paper presents a comprehensive survey of LRMs, meticulously exploring and summarizing the newly emerged safety risks, attacks, and defense strategies. By organizing these elements into a detailed taxonomy, this work aims to offer a clear and structured understanding of the current safety landscape of LRMs, facilitating future research and development to enhance the security and reliability of these powerful models.</li>
</ul>

<h3>Title: Fault Diagnosis in New Wind Turbines using Knowledge from Existing Turbines by Generative Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Stefan Jonas, Angela Meyer</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17709">https://arxiv.org/abs/2504.17709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17709">https://arxiv.org/pdf/2504.17709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17709]] Fault Diagnosis in New Wind Turbines using Knowledge from Existing Turbines by Generative Domain Adaptation(https://arxiv.org/abs/2504.17709)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Intelligent condition monitoring of wind turbines is essential for reducing downtimes. Machine learning models trained on wind turbine operation data are commonly used to detect anomalies and, eventually, operation faults. However, data-driven normal behavior models (NBMs) require a substantial amount of training data, as NBMs trained with scarce data may result in unreliable fault diagnosis. To overcome this limitation, we present a novel generative deep learning approach to make SCADA samples from one wind turbine lacking training data resemble SCADA data from wind turbines with representative training data. Through CycleGAN-based domain mapping, our method enables the application of an NBM trained on an existing wind turbine to one with severely limited data. We demonstrate our approach on field data mapping SCADA samples across 7 substantially different WTs. Our findings show significantly improved fault diagnosis in wind turbines with scarce data. Our method achieves the most similar anomaly scores to an NBM trained with abundant data, outperforming NBMs trained on scarce training data with improvements of +10.3% in F1-score when 1 month of training data is available and +16.8% when 2 weeks are available. The domain mapping approach outperforms conventional fine-tuning at all considered degrees of data scarcity, ranging from 1 to 8 weeks of training data. The proposed technique enables earlier and more reliable fault diagnosis in newly installed wind farms, demonstrating a novel and promising research direction to improve anomaly detection when faced with training data scarcity.</li>
</ul>

<h3>Title: Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields</h3>
<ul>
<li><strong>Authors: </strong>Zhuo He, Paul Henderson, Nicolas Pugeault</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17712">https://arxiv.org/abs/2504.17712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17712">https://arxiv.org/pdf/2504.17712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17712]] Generative Fields: Uncovering Hierarchical Feature Control for StyleGAN via Inverted Receptive Fields(https://arxiv.org/abs/2504.17712)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>StyleGAN has demonstrated the ability of GANs to synthesize highly-realistic faces of imaginary people from random noise. One limitation of GAN-based image generation is the difficulty of controlling the features of the generated image, due to the strong entanglement of the low-dimensional latent space. Previous work that aimed to control StyleGAN with image or text prompts modulated sampling in W latent space, which is more expressive than Z latent space. However, W space still has restricted expressivity since it does not control the feature synthesis directly; also the feature embedding in W space requires a pre-training process to reconstruct the style signal, limiting its application. This paper introduces the concept of "generative fields" to explain the hierarchical feature synthesis in StyleGAN, inspired by the receptive fields of convolution neural networks (CNNs). Additionally, we propose a new image editing pipeline for StyleGAN using generative field theory and the channel-wise style latent space S, utilizing the intrinsic structural feature of CNNs to achieve disentangled control of feature synthesis at synthesis time.</li>
</ul>

<h3>Title: Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations</h3>
<ul>
<li><strong>Authors: </strong>Óscar Escudero-Arnanz, Antonio G. Marques, Inmaculada Mora-Jiménez, Joaquín Álvarez-Rodríguez, Cristina Soguero-Ruiz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17717">https://arxiv.org/abs/2504.17717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17717">https://arxiv.org/pdf/2504.17717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17717]] Early Detection of Multidrug Resistance Using Multivariate Time Series Analysis and Interpretable Patient-Similarity Representations(https://arxiv.org/abs/2504.17717)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Background and Objectives: Multidrug Resistance (MDR) is a critical global health issue, causing increased hospital stays, healthcare costs, and mortality. This study proposes an interpretable Machine Learning (ML) framework for MDR prediction, aiming for both accurate inference and enhanced explainability. Methods: Patients are modeled as Multivariate Time Series (MTS), capturing clinical progression and patient-to-patient interactions. Similarity among patients is quantified using MTS-based methods: descriptive statistics, Dynamic Time Warping, and Time Cluster Kernel. These similarity measures serve as inputs for MDR classification via Logistic Regression, Random Forest, and Support Vector Machines, with dimensionality reduction and kernel transformations improving model performance. For explainability, patient similarity networks are constructed from these metrics. Spectral clustering and t-SNE are applied to identify MDR-related subgroups and visualize high-risk clusters, enabling insight into clinically relevant patterns. Results: The framework was validated on ICU Electronic Health Records from the University Hospital of Fuenlabrada, achieving an AUC of 81%. It outperforms baseline ML and deep learning models by leveraging graph-based patient similarity. The approach identifies key risk factors -- prolonged antibiotic use, invasive procedures, co-infections, and extended ICU stays -- and reveals clinically meaningful clusters. Code and results are available at \this https URL. Conclusions: Patient similarity representations combined with graph-based analysis provide accurate MDR prediction and interpretable insights. This method supports early detection, risk factor identification, and patient stratification, highlighting the potential of explainable ML in critical care.</li>
</ul>

<h3>Title: Multilingual Performance Biases of Large Language Models in Education</h3>
<ul>
<li><strong>Authors: </strong>Vansh Gupta, Sankalan Pal Chowdhury, Vilém Zouhar, Donya Rooein, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17720">https://arxiv.org/abs/2504.17720</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17720">https://arxiv.org/pdf/2504.17720</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17720]] Multilingual Performance Biases of Large Language Models in Education(https://arxiv.org/abs/2504.17720)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly being adopted in educational settings. These applications expand beyond English, though current LLMs remain primarily English-centric. In this work, we ascertain if their use in education settings in non-English languages is warranted. We evaluated the performance of popular LLMs on four educational tasks: identifying student misconceptions, providing targeted feedback, interactive tutoring, and grading translations in six languages (Hindi, Arabic, Farsi, Telugu, Ukrainian, Czech) in addition to English. We find that the performance on these tasks somewhat corresponds to the amount of language represented in training data, with lower-resource languages having poorer task performance. Although the models perform reasonably well in most languages, the frequent performance drop from English is significant. Thus, we recommend that practitioners first verify that the LLM works well in the target language for their educational task before deployment.</li>
</ul>

<h3>Title: Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Cheng Shen, Yuewei Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17721">https://arxiv.org/abs/2504.17721</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17721">https://arxiv.org/pdf/2504.17721</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17721]] Conformal Segmentation in Industrial Surface Defect Detection with Statistical Guarantees(https://arxiv.org/abs/2504.17721)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>In industrial settings, surface defects on steel can significantly compromise its service life and elevate potential safety risks. Traditional defect detection methods predominantly rely on manual inspection, which suffers from low efficiency and high costs. Although automated defect detection approaches based on Convolutional Neural Networks(e.g., Mask R-CNN) have advanced rapidly, their reliability remains challenged due to data annotation uncertainties during deep model training and overfitting issues. These limitations may lead to detection deviations when processing the given new test samples, rendering automated detection processes unreliable. To address this challenge, we first evaluate the detection model's practical performance through calibration data that satisfies the independent and identically distributed (i.i.d) condition with test data. Specifically, we define a loss function for each calibration sample to quantify detection error rates, such as the complement of recall rate and false discovery rate. Subsequently, we derive a statistically rigorous threshold based on a user-defined risk level to identify high-probability defective pixels in test images, thereby constructing prediction sets (e.g., defect regions). This methodology ensures that the expected error rate (mean error rate) on the test set remains strictly bounced by the predefined risk level. Additionally, we observe a negative correlation between the average prediction set size and the risk level on the test set, establishing a statistically rigorous metric for assessing detection model uncertainty. Furthermore, our study demonstrates robust and efficient control over the expected test set error rate across varying calibration-to-test partitioning ratios, validating the method's adaptability and operational effectiveness.</li>
</ul>

<h3>Title: Towards Robust LLMs: an Adversarial Robustness Measurement Framework</h3>
<ul>
<li><strong>Authors: </strong>Natan Levy, Adiel Ashrov, Guy Katz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17723">https://arxiv.org/abs/2504.17723</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17723">https://arxiv.org/pdf/2504.17723</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17723]] Towards Robust LLMs: an Adversarial Robustness Measurement Framework(https://arxiv.org/abs/2504.17723)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The rise of Large Language Models (LLMs) has revolutionized artificial intelligence, yet these models remain vulnerable to adversarial perturbations, undermining their reliability in high-stakes applications. While adversarial robustness in vision-based neural networks has been extensively studied, LLM robustness remains under-explored. We adapt the Robustness Measurement and Assessment (RoMA) framework to quantify LLM resilience against adversarial inputs without requiring access to model parameters. By comparing RoMA's estimates to those of formal verification methods, we demonstrate its accuracy with minimal error margins while maintaining computational efficiency. Our empirical evaluation reveals that robustness varies significantly not only between different models but also across categories within the same task and between various types of perturbations. This non-uniformity underscores the need for task-specific robustness evaluations, enabling practitioners to compare and select models based on application-specific robustness requirements. Our work provides a systematic methodology to assess LLM robustness, advancing the development of more reliable language models for real-world deployment.</li>
</ul>

<h3>Title: Interpretable Early Detection of Parkinson's Disease through Speech Analysis</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Simone, Mauro Giuseppe Camporeale, Vito Marco Rubino, Vincenzo Gervasi, Giovanni Dimauro</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17739">https://arxiv.org/abs/2504.17739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17739">https://arxiv.org/pdf/2504.17739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17739]] Interpretable Early Detection of Parkinson's Disease through Speech Analysis(https://arxiv.org/abs/2504.17739)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease is a progressive neurodegenerative disorder affecting motor and non-motor functions, with speech impairments among its earliest symptoms. Speech impairments offer a valuable diagnostic opportunity, with machine learning advances providing promising tools for timely detection. In this research, we propose a deep learning approach for early Parkinson's disease detection from speech recordings, which also highlights the vocal segments driving predictions to enhance interpretability. This approach seeks to associate predictive speech patterns with articulatory features, providing a basis for interpreting underlying neuromuscular impairments. We evaluated our approach using the Italian Parkinson's Voice and Speech Database, containing 831 audio recordings from 65 participants, including both healthy individuals and patients. Our approach showed competitive classification performance compared to state-of-the-art methods, while providing enhanced interpretability by identifying key speech features influencing predictions.</li>
</ul>

<h3>Title: Embedding Empirical Distributions for Computing Optimal Transport Maps</h3>
<ul>
<li><strong>Authors: </strong>Mingchen Jiang, Peng Xu, Xichen Ye, Xiaohui Chen, Yun Yang, Yifan Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17740">https://arxiv.org/abs/2504.17740</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17740">https://arxiv.org/pdf/2504.17740</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17740]] Embedding Empirical Distributions for Computing Optimal Transport Maps(https://arxiv.org/abs/2504.17740)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Distributional data have become increasingly prominent in modern signal processing, highlighting the necessity of computing optimal transport (OT) maps across multiple probability distributions. Nevertheless, recent studies on neural OT methods predominantly focused on the efficient computation of a single map between two distributions. To address this challenge, we introduce a novel approach to learning transport maps for new empirical distributions. Specifically, we employ the transformer architecture to produce embeddings from distributional data of varying length; these embeddings are then fed into a hypernetwork to generate neural OT maps. Various numerical experiments were conducted to validate the embeddings and the generated OT maps. The model implementation and the code are provided on this https URL.</li>
</ul>

<h3>Title: MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link Weight Prediction</h3>
<ul>
<li><strong>Authors: </strong>Steven E. Wilson, Sina Khanmohammadi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17749">https://arxiv.org/abs/2504.17749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17749">https://arxiv.org/pdf/2504.17749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17749]] MSGCN: Multiplex Spatial Graph Convolution Network for Interlayer Link Weight Prediction(https://arxiv.org/abs/2504.17749)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have been widely used for various learning tasks, ranging from node classification to link prediction. They have demonstrated excellent performance in multiple domains involving graph-structured data. However, an important category of learning tasks, namely link weight prediction, has received less emphasis due to its increased complexity compared to binary link classification. Link weight prediction becomes even more challenging when considering multilayer networks, where nodes can be interconnected across multiple layers. To address these challenges, we propose a new method named Multiplex Spatial Graph Convolution Network (MSGCN), which spatially embeds information across multiple layers to predict interlayer link weights. The MSGCN model generalizes spatial graph convolution to multiplex networks and captures the geometric structure of nodes across multiple layers. Extensive experiments using data with known interlayer link information show that the MSGCN model has robust, accurate, and generalizable link weight prediction performance across a wide variety of multiplex network structures.</li>
</ul>

<h3>Title: Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT</h3>
<ul>
<li><strong>Authors: </strong>Anuja Tayal, Devika Salunke, Barbara Di Eugenio, Paula Allen-Meares, Eulalia Puig Abril, Olga Garcia, Carolyn Dickens, Andrew Boyd</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17753">https://arxiv.org/abs/2504.17753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17753">https://arxiv.org/pdf/2504.17753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17753]] Conversational Assistants to support Heart Failure Patients: comparing a Neurosymbolic Architecture with ChatGPT(https://arxiv.org/abs/2504.17753)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Conversational assistants are becoming more and more popular, including in healthcare, partly because of the availability and capabilities of Large Language Models. There is a need for controlled, probing evaluations with real stakeholders which can highlight advantages and disadvantages of more traditional architectures and those based on generative AI. We present a within-group user study to compare two versions of a conversational assistant that allows heart failure patients to ask about salt content in food. One version of the system was developed in-house with a neurosymbolic architecture, and one is based on ChatGPT. The evaluation shows that the in-house system is more accurate, completes more tasks and is less verbose than the one based on ChatGPT; on the other hand, the one based on ChatGPT makes fewer speech errors and requires fewer clarifications to complete the task. Patients show no preference for one over the other.</li>
</ul>

<h3>Title: Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure</h3>
<ul>
<li><strong>Authors: </strong>Surya Teja Avirneni</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17759">https://arxiv.org/abs/2504.17759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17759">https://arxiv.org/pdf/2504.17759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17759]] Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure(https://arxiv.org/abs/2504.17759)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>This paper introduces the Identity Control Plane (ICP), an architectural framework for enforcing identity-aware Zero Trust access across human users, workloads, and automation systems. The ICP model unifies SPIFFE-based workload identity, OIDC/SAML user identity, and scoped automation credentials via broker-issued transaction tokens. We propose a composable enforcement layer using ABAC policy engines (e.g., OPA, Cedar), aligned with IETF WIMSE drafts and OAuth transaction tokens. The paper includes architectural components, integration patterns, use cases, a comparative analysis with current models, and theorized performance metrics. A FedRAMP and SLSA compliance mapping is also presented. This is a theoretical infrastructure architecture paper intended for security researchers and platform architects. No prior version of this work has been published.</li>
</ul>

<h3>Title: Step1X-Edit: A Practical Framework for General Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Shiyu Liu, Yucheng Han, Peng Xing, Fukun Yin, Rui Wang, Wei Cheng, Jiaqi Liao, Yingming Wang, Honghao Fu, Chunrui Han, Guopeng Li, Yuang Peng, Quan Sun, Jingwei Wu, Yan Cai, Zheng Ge, Ranchen Ming, Lei Xia, Xianfang Zeng, Yibo Zhu, Binxing Jiao, Xiangyu Zhang, Gang Yu, Daxin Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17761">https://arxiv.org/abs/2504.17761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17761">https://arxiv.org/pdf/2504.17761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17761]] Step1X-Edit: A Practical Framework for General Image Editing(https://arxiv.org/abs/2504.17761)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>In recent years, image editing models have witnessed remarkable and rapid development. The recent unveiling of cutting-edge multimodal models such as GPT-4o and Gemini2 Flash has introduced highly promising image editing capabilities. These models demonstrate an impressive aptitude for fulfilling a vast majority of user-driven editing requirements, marking a significant advancement in the field of image manipulation. However, there is still a large gap between the open-source algorithm with these closed-source models. Thus, in this paper, we aim to release a state-of-the-art image editing model, called Step1X-Edit, which can provide comparable performance against the closed-source models like GPT-4o and Gemini2 Flash. More specifically, we adopt the Multimodal LLM to process the reference image and the user's editing instruction. A latent embedding has been extracted and integrated with a diffusion image decoder to obtain the target image. To train the model, we build a data generation pipeline to produce a high-quality dataset. For evaluation, we develop the GEdit-Bench, a novel benchmark rooted in real-world user instructions. Experimental results on GEdit-Bench demonstrate that Step1X-Edit outperforms existing open-source baselines by a substantial margin and approaches the performance of leading proprietary models, thereby making significant contributions to the field of image editing.</li>
</ul>

<h3>Title: The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs</h3>
<ul>
<li><strong>Authors: </strong>Piotr Nawrot, Robert Li, Renjie Huang, Sebastian Ruder, Kelly Marchisio, Edoardo M. Ponti</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17768">https://arxiv.org/abs/2504.17768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17768">https://arxiv.org/pdf/2504.17768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17768]] The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs(https://arxiv.org/abs/2504.17768)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Sparse attention offers a promising strategy to extend long-context capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy trade-offs, and systematic scaling studies remain unexplored. To address this gap, we perform a careful comparison of training-free sparse attention methods at varying model scales, sequence lengths, and sparsity levels on a diverse collection of long-sequence tasks-including novel ones that rely on natural language while remaining controllable and easy to evaluate. Based on our experiments, we report a series of key findings: 1) an isoFLOPS analysis reveals that for very long sequences, larger and highly sparse models are preferable to smaller and dense ones. 2) The level of sparsity attainable while statistically guaranteeing accuracy preservation is higher during decoding than prefilling, and correlates with model size in the former. 3) There is no clear strategy that performs best across tasks and phases, with different units of sparsification or budget adaptivity needed for different scenarios. Even moderate sparsity levels often result in significant performance degradation on at least one task, highlighting that sparse attention is not a universal solution. 4) We introduce and validate novel scaling laws specifically tailored for sparse attention, providing evidence that our findings are likely to hold true beyond our range of experiments. Through these insights, we demonstrate that sparse attention is a key tool to enhance the capabilities of Transformer LLMs for processing longer sequences, but requires careful evaluation of trade-offs for performance-sensitive applications.</li>
</ul>

<h3>Title: Replay to Remember: Retaining Domain Knowledge in Streaming Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sneh Pillai (University of Massachusetts Dartmouth)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17780">https://arxiv.org/abs/2504.17780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17780">https://arxiv.org/pdf/2504.17780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17780]] Replay to Remember: Retaining Domain Knowledge in Streaming Language Models(https://arxiv.org/abs/2504.17780)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Continual learning in large language models (LLMs) typically encounters the critical challenge of catastrophic forgetting, where previously acquired knowledge deteriorates upon exposure to new data. While techniques like replay buffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have been proposed, few studies investigate real-time domain adaptation under strict computational and data-stream constraints. In this paper, we demonstrate a lightweight method combining LoRA and a minimal replay mechanism in a realistic streaming setting across three diverse knowledge domains: medical question answering, genetics, and law. Using perplexity, semantic similarity, and GPT-based human-like evaluation metrics, we quantify the model's adaptation, forgetting, and recovery over time. Our experiments reveal that while catastrophic forgetting naturally occurs, even minimal replay significantly stabilizes and partially restores domain-specific knowledge. This study contributes practical insights for deploying adaptable LLMs in resource-constrained, real-world scenarios.</li>
</ul>

<h3>Title: Silenzio: Secure Non-Interactive Outsourced MLP Training</h3>
<ul>
<li><strong>Authors: </strong>Jonas Sander, Thomas Eisenbarth</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17785">https://arxiv.org/abs/2504.17785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17785">https://arxiv.org/pdf/2504.17785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17785]] Silenzio: Secure Non-Interactive Outsourced MLP Training(https://arxiv.org/abs/2504.17785)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy</a></li>
<li><strong>Abstract: </strong>Outsourcing the ML training to cloud providers presents a compelling opportunity for resource constrained clients, while it simultaneously bears inherent privacy risks, especially for highly sensitive training data. We introduce Silenzio, the first fully non-interactive outsourcing scheme for the training of multi-layer perceptrons that achieves 128 bit security using FHE. Unlike traditional MPC based protocols that necessitate interactive communication between the client and server(s) or non-collusion assumptions among multiple servers, Silenzio enables the fire-and-forget paradigm without such assumptions. In this approach, the client encrypts the training data once, and the cloud server performs the training without any further interaction. Silenzio operates over low bitwidth integers - never exceeding 8 bit - to mitigate the computational overhead of FHE. Our approach features a novel low-bitwidth matrix multiplication that leverages input-dependent residue number systems and a Karatsuba-inspired multiplication routine, ensuring that no intermediate FHE-processed value overflows 8 bit. Starting from an RNS-to-MRNS conversion process, we propose an efficient block-scaling mechanism, which approximately shifts encrypted tensor values to the user-specified most significant bits. To instantiate the backpropagation of the error, Silenzio introduces a low-bitwidth and TFHE friendly gradient computation for the cross entropy loss. Implemented using the state-of-the-art Concrete library, we evaluate Silenzio on standard MLP training tasks regarding runtime as well as model performance and achieve similar classification accuracy as MLPs trained using standard PyTorch with 32 bit floating-point computations. Our open-source implementation represents a significant advancement in privacy-preserving ML, providing a new baseline for secure and non-interactive outsourced MLP training.</li>
</ul>

<h3>Title: Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models</h3>
<ul>
<li><strong>Authors: </strong>Xu Ma, Peize Sun, Haoyu Ma, Hao Tang, Chih-Yao Ma, Jialiang Wang, Kunpeng Li, Xiaoliang Dai, Yujun Shi, Xuan Ju, Yushi Hu, Artsiom Sanakoyeu, Felix Juefei-Xu, Ji Hou, Junjiao Tian, Tao Xu, Tingbo Hou, Yen-Cheng Liu, Zecheng He, Zijian He, Matt Feiszli, Peizhao Zhang, Peter Vajda, Sam Tsai, Yun Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17789">https://arxiv.org/abs/2504.17789</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17789">https://arxiv.org/pdf/2504.17789</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17789]] Token-Shuffle: Towards High-Resolution Image Generation with Autoregressive Models(https://arxiv.org/abs/2504.17789)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Autoregressive (AR) models, long dominant in language generation, are increasingly applied to image synthesis but are often considered less competitive than Diffusion-based models. A primary limitation is the substantial number of image tokens required for AR models, which constrains both training and inference efficiency, as well as image resolution. To address this, we present Token-Shuffle, a novel yet simple method that reduces the number of image tokens in Transformer. Our key insight is the dimensional redundancy of visual vocabularies in Multimodal Large Language Models (MLLMs), where low-dimensional visual codes from visual encoder are directly mapped to high-dimensional language vocabularies. Leveraging this, we consider two key operations: token-shuffle, which merges spatially local tokens along channel dimension to decrease the input token number, and token-unshuffle, which untangles the inferred tokens after Transformer blocks to restore the spatial arrangement for output. Jointly training with textual prompts, our strategy requires no additional pretrained text-encoder and enables MLLMs to support extremely high-resolution image synthesis in a unified next-token prediction way while maintaining efficient training and inference. For the first time, we push the boundary of AR text-to-image generation to a resolution of 2048x2048 with gratifying generation performance. In GenAI-benchmark, our 2.7B model achieves 0.77 overall score on hard prompts, outperforming AR models LlamaGen by 0.18 and diffusion models LDM by 0.15. Exhaustive large-scale human evaluations also demonstrate our prominent image generation ability in terms of text-alignment, visual flaw, and visual appearance. We hope that Token-Shuffle can serve as a foundational design for efficient high-resolution image generation within MLLMs.</li>
</ul>

<h3>Title: LiDPM: Rethinking Point Diffusion for Lidar Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Tetiana Martyniuk, Gilles Puy, Alexandre Boulch, Renaud Marlet, Raoul de Charette</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.17791">https://arxiv.org/abs/2504.17791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.17791">https://arxiv.org/pdf/2504.17791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.17791]] LiDPM: Rethinking Point Diffusion for Lidar Scene Completion(https://arxiv.org/abs/2504.17791)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Training diffusion models that work directly on lidar points at the scale of outdoor scenes is challenging due to the difficulty of generating fine-grained details from white noise over a broad field of view. The latest works addressing scene completion with diffusion models tackle this problem by reformulating the original DDPM as a local diffusion process. It contrasts with the common practice of operating at the level of objects, where vanilla DDPMs are currently used. In this work, we close the gap between these two lines of work. We identify approximations in the local diffusion formulation, show that they are not required to operate at the scene level, and that a vanilla DDPM with a well-chosen starting point is enough for completion. Finally, we demonstrate that our method, LiDPM, leads to better results in scene completion on SemanticKITTI. The project page is this https URL .</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
