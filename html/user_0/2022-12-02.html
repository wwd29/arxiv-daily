<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: SPOT: Secure and Privacy-preserving prOximiTy protocol for e-healthcare systems. (arXiv:2212.00381v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00381">http://arxiv.org/abs/2212.00381</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00381] SPOT: Secure and Privacy-preserving prOximiTy protocol for e-healthcare systems](http://arxiv.org/abs/2212.00381) #secure</code></li>
<li>Summary: <p>This paper introduces SPOT, a Secure and Privacy-preserving prOximity based
protocol for e-healthcare systems. It relies on a distributed proxy-based
approach to preserve users' privacy and a semi-trusted computing server to
ensure data consistency and integrity. The proposed protocol ensures a balance
between security, privacy and scalability. As far as we know, in terms of
security, SPOT is the first one to prevent malicious users from colluding and
generating false positives. In terms of privacy, SPOT supports both anonymity
of users being in proximity of infected people and unlinkability of contact
information issued by the same user. A concrete construction based on
structure-preserving signatures and NIWI proofs is proposed and a detailed
security and privacy analysis proves that SPOT is secure under standard
assumptions. In terms of scalability, SPOT's procedures and algorithms are
implemented to show its efficiency and practical usability with acceptable
computation and communication overhead.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Data Synthetisation for Secure Information Sharing. (arXiv:2212.00484v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00484">http://arxiv.org/abs/2212.00484</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00484] Privacy-Preserving Data Synthetisation for Secure Information Sharing](http://arxiv.org/abs/2212.00484) #secure</code></li>
<li>Summary: <p>We can protect user data privacy via many approaches, such as statistical
transformation or generative models. However, each of them has critical
drawbacks. On the one hand, creating a transformed data set using conventional
techniques is highly time-consuming. On the other hand, in addition to long
training phases, recent deep learning-based solutions require significant
computational resources. In this paper, we propose PrivateSMOTE, a technique
designed for competitive effectiveness in protecting cases at maximum risk of
re-identification while requiring much less time and computational resources.
It works by synthetic data generation via interpolation to obfuscate high-risk
cases while minimizing data utility loss of the original data. Compared to
multiple conventional and state-of-the-art privacy-preservation methods on 20
data sets, PrivateSMOTE demonstrates competitive results in re-identification
risk. Also, it presents similar or higher predictive performance than the
baselines, including generative adversarial networks and variational
autoencoders, reducing their energy consumption and time requirements by a
minimum factor of 9 and 12, respectively.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Concealed Object Detection for Passive Millimeter-Wave Security Imaging Based on Task-Aligned Detection Transformer. (arXiv:2212.00313v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00313">http://arxiv.org/abs/2212.00313</a></li>
<li>Code URL: <a href="https://github.com/ch3ngguo/opening-source-pmmw-dataset">https://github.com/ch3ngguo/opening-source-pmmw-dataset</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00313] Concealed Object Detection for Passive Millimeter-Wave Security Imaging Based on Task-Aligned Detection Transformer](http://arxiv.org/abs/2212.00313) #security</code></li>
<li>Summary: <p>Passive millimeter-wave (PMMW) is a significant potential technique for human
security screening. Several popular object detection networks have been used
for PMMW images. However, restricted by the low resolution and high noise of
PMMW images, PMMW hidden object detection based on deep learning usually
suffers from low accuracy and low classification confidence. To tackle the
above problems, this paper proposes a Task-Aligned Detection Transformer
network, named PMMW-DETR. In the first stage, a Denoising Coarse-to-Fine
Transformer (DCFT) backbone is designed to extract long- and short-range
features in the different scales. In the second stage, we propose the Query
Selection module to introduce learned spatial features into the network as
prior knowledge, which enhances the semantic perception capability of the
network. In the third stage, aiming to improve the classification performance,
we perform a Task-Aligned Dual-Head block to decouple the classification and
regression tasks. Based on our self-developed PMMW security screening dataset,
experimental results including comparison with State-Of-The-Art (SOTA) methods
and ablation study demonstrate that the PMMW-DETR obtains higher accuracy and
classification confidence than previous works, and exhibits robustness to the
PMMW images of low quality.
</p></li>
</ul>

<h3>Title: Security and Privacy-Preservation of IoT Data in Cloud-Fog Computing Environment. (arXiv:2212.00321v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00321">http://arxiv.org/abs/2212.00321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00321] Security and Privacy-Preservation of IoT Data in Cloud-Fog Computing Environment](http://arxiv.org/abs/2212.00321) #security</code></li>
<li>Summary: <p>IoT is the fastest-growing technology with a wide range of applications in
various domains. IoT devices generate data from a real-world environment every
second and transfer it to the cloud due to the less storage at the edge site.
An outsourced cloud is a solution for handling the storage problem. Users'
privacy can be exposed by storing the data on the cloud. Therefore, we propose
a Private Data Storage model that stores IoT data on the outsourced cloud with
privacy preservation. Fog nodes are used at the edge side for data partition
and encryption. Partitioned and encrypted data is aggregated with the help of
homomorphic encryption on the outsourced cloud. For secure query processing and
accessing the data from the outsourced cloud, the introduced model can be used
on the outsourced cloud.
</p></li>
</ul>

<h3>Title: What Physical Layer Security Can Do for 6G Security. (arXiv:2212.00427v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00427">http://arxiv.org/abs/2212.00427</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00427] What Physical Layer Security Can Do for 6G Security](http://arxiv.org/abs/2212.00427) #security</code></li>
<li>Summary: <p>While existing security protocols were designed with a focus on the core
network, the enhancement of the security of the B5G access network becomes of
critical importance. Despite the strengthening of 5G security protocols with
respect to LTE, there are still open issues that have not been fully addressed.
This work is articulated around the premise that rethinking the security design
bottom up, starting at the physical layer, is not only viable in 6G but
importantly, arises as an efficient way to overcome security hurdles in novel
use cases, notably massive machine type communications (mMTC), ultra reliable
low latency communications (URLLC) and autonomous cyberphysical systems. Unlike
existing review papers that treat physical layer security orthogonally to
cryptography, we will try to provide a few insights of underlying connections.
Discussing many practical issues, we will present a comprehensive review of the
state-of-the-art in i) secret key generation from shared randomness, ii) the
wiretap channel and fundamental limits, iii) authentication of devices using
physical unclonable functions (PUFs), localization and multi-factor
authentication, and, iv) jamming attacks at the physical layer. We finally
conclude with the proposers' aspirations for the 6G security landscape, in the
hyper-connectivity and semantic communications era.
</p></li>
</ul>

<h3>Title: Adversarial Artifact Detection in EEG-Based Brain-Computer Interfaces. (arXiv:2212.00727v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00727">http://arxiv.org/abs/2212.00727</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00727] Adversarial Artifact Detection in EEG-Based Brain-Computer Interfaces](http://arxiv.org/abs/2212.00727) #security</code></li>
<li>Summary: <p>Machine learning has achieved great success in electroencephalogram (EEG)
based brain-computer interfaces (BCIs). Most existing BCI research focused on
improving its accuracy, but few had considered its security. Recent studies,
however, have shown that EEG-based BCIs are vulnerable to adversarial attacks,
where small perturbations added to the input can cause misclassification.
Detection of adversarial examples is crucial to both the understanding of this
phenomenon and the defense. This paper, for the first time, explores
adversarial detection in EEG-based BCIs. Experiments on two EEG datasets using
three convolutional neural networks were performed to verify the performances
of multiple detection approaches. We showed that both white-box and black-box
attacks can be detected, and the former are easier to detect.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: CONDA: Continual Unsupervised Domain Adaptation Learning in Visual Perception for Self-Driving Cars. (arXiv:2212.00621v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00621">http://arxiv.org/abs/2212.00621</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00621] CONDA: Continual Unsupervised Domain Adaptation Learning in Visual Perception for Self-Driving Cars](http://arxiv.org/abs/2212.00621) #privacy</code></li>
<li>Summary: <p>Although unsupervised domain adaptation methods have achieved remarkable
performance in semantic scene segmentation in visual perception for
self-driving cars, these approaches remain impractical in real-world use cases.
In practice, the segmentation models may encounter new data that have not been
seen yet. Also, the previous data training of segmentation models may be
inaccessible due to privacy problems. Therefore, to address these problems, in
this work, we propose a Continual Unsupervised Domain Adaptation (CONDA)
approach that allows the model to continuously learn and adapt with respect to
the presence of the new data. Moreover, our proposed approach is designed
without the requirement of accessing previous training data. To avoid the
catastrophic forgetting problem and maintain the performance of the
segmentation models, we present a novel Bijective Maximum Likelihood loss to
impose the constraint of predicted segmentation distribution shifts. The
experimental results on the benchmark of continual unsupervised domain
adaptation have shown the advanced performance of the proposed CONDA method.
</p></li>
</ul>

<h3>Title: Differentially Private Enhanced Permissioned Blockchain for Private Data Sharing in Industrial IoT. (arXiv:2212.00068v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00068">http://arxiv.org/abs/2212.00068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00068] Differentially Private Enhanced Permissioned Blockchain for Private Data Sharing in Industrial IoT](http://arxiv.org/abs/2212.00068) #privacy</code></li>
<li>Summary: <p>The integration of permissioned blockchain such as Hyperledger fabric (HF)
and Industrial internet of Things (IIoT) has opened new opportunities for
interdependent supply chain partners to improve their performance through data
sharing and coordination. The multichannel mechanism, private data collection
and querying mechanism of HF enable private data sharing, transparency,
traceability, and verification across the supply chain. However, the existing
querying mechanism of HF needs further improvement for statistical data sharing
because the query is evaluated on the original data recorded on the ledger. As
a result, it gives rise to privacy issues such as leak of business secrets,
tracking of resources and assets, and disclose of personal information.
Therefore, we solve this problem by proposing a differentially private enhanced
permissioned blockchain for private data sharing in the context of supply chain
in IIoT which is known as (EDH-IIoT). We propose an algorithms to efficiently
utilize the $\epsilon$ through the reuse of the privacy budget for the repeated
queries. Furthermore, the reuse and tracking of $\epsilon$ enable the data
owner to get ensure that $\epsilon$ does not exceed the threshold which is the
maximum privacy budget ($\epsilon_{t}$). Finally, we model two privacy attacks
namely linking attack and composition attack to evaluate and compare privacy
preservation, and the efficiency of reuse of {\epsilon} with the default
chaincode of HF and traditional differential privacy model, respectively. The
results confirm that EDH-IIoT obtains an accuracy of 97% in the shared data for
$\epsilon_{t}$ = 1, and a reduction of 35.96% in spending of $\epsilon$.
</p></li>
</ul>

<h3>Title: An Optimized Privacy-Utility Trade-off Framework for Differentially Private Data Sharing in Blockchain-based Internet of Things. (arXiv:2212.00128v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00128">http://arxiv.org/abs/2212.00128</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00128] An Optimized Privacy-Utility Trade-off Framework for Differentially Private Data Sharing in Blockchain-based Internet of Things](http://arxiv.org/abs/2212.00128) #privacy</code></li>
<li>Summary: <p>Differential private (DP) query and response mechanisms have been widely
adopted in various applications based on Internet of Things (IoT) to leverage
variety of benefits through data analysis. The protection of sensitive
information is achieved through the addition of noise into the query response
which hides the individual records in a dataset. However, the noise addition
negatively impacts the accuracy which gives rise to privacy-utility trade-off.
Moreover, the DP budget or cost $\epsilon$ is often fixed and it accumulates
due to the sequential composition which limits the number of queries.
Therefore, in this paper, we propose a framework known as optimized
privacy-utility trade-off framework for data sharing in IoT (OPU-TF-IoT).
Firstly, OPU-TF-IoT uses an adaptive approach to utilize the DP budget
$\epsilon$ by considering a new metric of population or dataset size along with
the query. Secondly, our proposed heuristic search algorithm reduces the DP
budget accordingly whereas satisfying both data owner and data user. Thirdly,
to make the utilization of DP budget transparent to the data owners, a
blockchain-based verification mechanism is also proposed. Finally, the proposed
framework is evaluated using real-world datasets and compared with the
traditional DP model and other related state-of-the-art works. The results
confirm that our proposed framework not only utilize the DP budget $\epsilon$
efficiently, but it also optimizes the number of queries. Furthermore, the data
owners can effectively make sure that their data is shared accordingly through
our blockchain-based verification mechanism which encourages them to share
their data into the IoT system.
</p></li>
</ul>

<h3>Title: Answering Private Linear Queries Adaptively using the Common Mechanism. (arXiv:2212.00135v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00135">http://arxiv.org/abs/2212.00135</a></li>
<li>Code URL: <a href="https://github.com/cmla-psu/commonmech">https://github.com/cmla-psu/commonmech</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00135] Answering Private Linear Queries Adaptively using the Common Mechanism](http://arxiv.org/abs/2212.00135) #privacy</code></li>
<li>Summary: <p>When analyzing confidential data through a privacy filter, a data scientist
often needs to decide which queries will best support their intended analysis.
For example, an analyst may wish to study noisy two-way marginals in a dataset
produced by a mechanism M1. But, if the data are relatively sparse, the analyst
may choose to examine noisy one-way marginals, produced by a mechanism M2
instead. Since the choice of whether to use M1 or M2 is data-dependent, a
typical differentially private workflow is to first split the privacy loss
budget rho into two parts: rho1 and rho2, then use the first part rho1 to
determine which mechanism to use, and the remainder rho2 to obtain noisy
answers from the chosen mechanism. In a sense, the first step seems wasteful
because it takes away part of the privacy loss budget that could have been used
to make the query answers more accurate.
</p></li>
</ul>

<p>In this paper, we consider the question of whether the choice between M1 and
M2 can be performed without wasting any privacy loss budget. For linear
queries, we propose a method for decomposing M1 and M2 into three parts: (1) a
mechanism M* that captures their shared information, (2) a mechanism M1' that
captures information that is specific to M1, (3) a mechanism M2' that captures
information that is specific to M2. Running M* and M1' together is completely
equivalent to running M1 (both in terms of query answer accuracy and total
privacy cost rho). Similarly, running M* and M2' together is completely
equivalent to running M2.
</p>
<p>Since M* will be used no matter what, the analyst can use its output to
decide whether to subsequently run M1'(thus recreating the analysis supported
by M1) or M2'(recreating the analysis supported by M2), without wasting privacy
loss budget.
</p>

<h3>Title: Split Learning without Local Weight Sharing to Enhance Client-side Data Privacy. (arXiv:2212.00250v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00250">http://arxiv.org/abs/2212.00250</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00250] Split Learning without Local Weight Sharing to Enhance Client-side Data Privacy](http://arxiv.org/abs/2212.00250) #privacy</code></li>
<li>Summary: <p>Split learning (SL) aims to protect user data privacy by splitting deep
models between client-server and keeping private data locally. SL has been
demonstrated to achieve similar accuracy as the centralized learning model. In
SL with multiple clients, the local training weights are shared between clients
for local model aggregation. This paper investigates the potential of data
leakage due to local weight sharing among the clients in SL by performing model
inversion attacks. To mitigate the identified leakage issue, we propose and
analyze privacy-enhancement SL (P-SL), e.g., SL without local weight sharing,
to boost client-side data privacy. We also propose paralleled P-SL to speed up
the training process by employing multiple servers without accuracy reduction.
Finally, we investigate P-SL with late participating clients and develop a
server-based cache-based training to address the forgetting phenomenon in SL.
Experimental results demonstrate that P-SL helps reduce up to 50% of
client-side data leakage compared to SL. Moreover, P-SL and its cache-based
version achieve comparable accuracy to SL under various data distributions with
lower computation and communications costs. Also, caching in P-SL reduces the
negative effect of forgetting, stabilizes the learning, and enables effective
and low-complexity training in a dynamic environment with late-arriving
clients.
</p></li>
</ul>

<h3>Title: Decentralized Matrix Factorization with Heterogeneous Differential Privacy. (arXiv:2212.00306v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00306">http://arxiv.org/abs/2212.00306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00306] Decentralized Matrix Factorization with Heterogeneous Differential Privacy](http://arxiv.org/abs/2212.00306) #privacy</code></li>
<li>Summary: <p>Conventional matrix factorization relies on centralized collection of users'
data for recommendation, which might introduce an increased risk of privacy
leakage especially when the recommender is untrusted. Existing differentially
private matrix factorization methods either assume the recommender is trusted,
or can only provide a uniform level of privacy protection for all users and
items with untrusted recommender. In this paper, we propose a novel
Heterogeneous Differentially Private Matrix Factorization algorithm (denoted as
HDPMF) for untrusted recommender. To the best of our knowledge, we are the
first to achieve heterogeneous differential privacy for decentralized matrix
factorization in untrusted recommender scenario. Specifically, our framework
uses modified stretching mechanism with an innovative rescaling scheme to
achieve better trade off between privacy and accuracy. Meanwhile, by allocating
privacy budget properly, we can capture homogeneous privacy preference within a
user/item but heterogeneous privacy preference across different users/items.
Theoretical analysis confirms that HDPMF renders rigorous privacy guarantee,
and exhaustive experiments demonstrate its superiority especially in strong
privacy guarantee, high dimension model and sparse dataset scenario.
</p></li>
</ul>

<h3>Title: Differentially Private Adaptive Optimization with Delayed Preconditioners. (arXiv:2212.00309v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00309">http://arxiv.org/abs/2212.00309</a></li>
<li>Code URL: <a href="https://github.com/kenziyuliu/dp2">https://github.com/kenziyuliu/dp2</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00309] Differentially Private Adaptive Optimization with Delayed Preconditioners](http://arxiv.org/abs/2212.00309) #privacy</code></li>
<li>Summary: <p>Privacy noise may negate the benefits of using adaptive optimizers in
differentially private model training. Prior works typically address this issue
by using auxiliary information (e.g., public data) to boost the effectiveness
of adaptive optimization. In this work, we explore techniques to estimate and
efficiently adapt to gradient geometry in private adaptive optimization without
auxiliary data. Motivated by the observation that adaptive methods can tolerate
stale preconditioners, we propose differentially private adaptive training with
delayed preconditioners (DP^2), a simple method that constructs delayed but
less noisy preconditioners to better realize the benefits of adaptivity.
Theoretically, we provide convergence guarantees for our method for both convex
and non-convex problems, and analyze trade-offs between delay and privacy noise
reduction. Empirically, we explore DP^2 across several real-world datasets,
demonstrating that it can improve convergence speed by as much as 4x relative
to non-adaptive baselines and match the performance of state-of-the-art
optimization methods that require auxiliary data.
</p></li>
</ul>

<h3>Title: Differentially Private Learning with Per-Sample Adaptive Clipping. (arXiv:2212.00328v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00328">http://arxiv.org/abs/2212.00328</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00328] Differentially Private Learning with Per-Sample Adaptive Clipping](http://arxiv.org/abs/2212.00328) #privacy</code></li>
<li>Summary: <p>Privacy in AI remains a topic that draws attention from researchers and the
general public in recent years. As one way to implement privacy-preserving AI,
differentially private learning is a framework that enables AI models to use
differential privacy (DP). To achieve DP in the learning process, existing
algorithms typically limit the magnitude of gradients with a constant clipping,
which requires carefully tuned due to its significant impact on model
performance. As a solution to this issue, latest works NSGD and Auto-S
innovatively propose to use normalization instead of clipping to avoid
hyperparameter tuning. However, normalization-based approaches like NSGD and
Auto-S rely on a monotonic weight function, which imposes excessive weight on
small gradient samples and introduces extra deviation to the update. In this
paper, we propose a Differentially Private Per-Sample Adaptive Clipping
(DP-PSAC) algorithm based on a non-monotonic adaptive weight function, which
guarantees privacy without the typical hyperparameter tuning process of using a
constant clipping while significantly reducing the deviation between the update
and true batch-averaged gradient. We provide a rigorous theoretical convergence
analysis and show that with convergence rate at the same order, the proposed
algorithm achieves a lower non-vanishing bound, which is maintained over
training iterations, compared with NSGD/Auto-S. In addition, through extensive
experimental evaluation, we show that DP-PSAC outperforms or matches the
state-of-the-art methods on multiple main-stream vision and language tasks.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Leveraging Large-scale Multimedia Datasets to Refine Content Moderation Models. (arXiv:2212.00668v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00668">http://arxiv.org/abs/2212.00668</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00668] Leveraging Large-scale Multimedia Datasets to Refine Content Moderation Models](http://arxiv.org/abs/2212.00668) #protect</code></li>
<li>Summary: <p>The sheer volume of online user-generated content has rendered content
moderation technologies essential in order to protect digital platform
audiences from content that may cause anxiety, worry, or concern. Despite the
efforts towards developing automated solutions to tackle this problem, creating
accurate models remains challenging due to the lack of adequate task-specific
training data. The fact that manually annotating such data is a highly
demanding procedure that could severely affect the annotators' emotional
well-being is directly related to the latter limitation. In this paper, we
propose the CM-Refinery framework that leverages large-scale multimedia
datasets to automatically extend initial training datasets with hard examples
that can refine content moderation models, while significantly reducing the
involvement of human annotators. We apply our method on two model adaptation
strategies designed with respect to the different challenges observed while
collecting data, i.e. lack of (i) task-specific negative data or (ii) both
positive and negative data. Additionally, we introduce a diversity criterion
applied to the data collection process that further enhances the generalization
performance of the refined models. The proposed method is evaluated on the Not
Safe for Work (NSFW) and disturbing content detection tasks on benchmark
datasets achieving 1.32% and 1.94% accuracy improvements compared to the state
of the art, respectively. Finally, it significantly reduces human involvement,
as 92.54% of data are automatically annotated in case of disturbing content
while no human intervention is required for the NSFW task.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Location analysis of players in UEFA EURO 2020 and 2022 using generalized valuation of defense by estimating probabilities. (arXiv:2212.00021v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00021">http://arxiv.org/abs/2212.00021</a></li>
<li>Code URL: <a href="https://github.com/rikuhei-ynwa/generalized-vdep">https://github.com/rikuhei-ynwa/generalized-vdep</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00021] Location analysis of players in UEFA EURO 2020 and 2022 using generalized valuation of defense by estimating probabilities](http://arxiv.org/abs/2212.00021) #defense</code></li>
<li>Summary: <p>Analyzing defenses in team sports is generally challenging because of the
limited event data. Researchers have previously proposed methods to evaluate
football team defense by predicting the events of ball gain and being attacked
using locations of all players and the ball. However, they did not consider the
importance of the events, assumed the perfect observation of all 22 players,
and did not fully investigated the influence of the diversity (e.g.,
nationality and sex). Here, we propose a generalized valuation method of
defensive teams by score-scaling the predicted probabilities of the events.
Using the open-source location data of all players in broadcast video frames in
football games of men's Euro 2020 and women's Euro 2022, we investigated the
effect of the number of players on the prediction and validated our approach by
analyzing the games. Results show that for the predictions of being attacked,
scoring, and conceding, all players' information was not necessary, while that
of ball gain required information on three to four offensive and defensive
players. With game analyses we explained the excellence in defense of finalist
teams in Euro 2020. Our approach might be applicable to location data from
broadcast video frames in football games.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: All You Need Is Hashing: Defending Against Data Reconstruction Attack in Vertical Federated Learning. (arXiv:2212.00325v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00325">http://arxiv.org/abs/2212.00325</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00325] All You Need Is Hashing: Defending Against Data Reconstruction Attack in Vertical Federated Learning](http://arxiv.org/abs/2212.00325) #attack</code></li>
<li>Summary: <p>Vertical federated learning is a trending solution for multi-party
collaboration in training machine learning models. Industrial frameworks adopt
secure multi-party computation methods such as homomorphic encryption to
guarantee data security and privacy. However, a line of work has revealed that
there are still leakage risks in VFL. The leakage is caused by the correlation
between the intermediate representations and the raw data. Due to the powerful
approximation ability of deep neural networks, an adversary can capture the
correlation precisely and reconstruct the data. To deal with the threat of the
data reconstruction attack, we propose a hashing-based VFL framework, called
\textit{HashVFL}, to cut off the reversibility directly. The one-way nature of
hashing allows our framework to block all attempts to recover data from hash
codes. However, integrating hashing also brings some challenges, e.g., the loss
of information. This paper proposes and addresses three challenges to
integrating hashing: learnability, bit balance, and consistency. Experimental
results demonstrate \textit{HashVFL}'s efficiency in keeping the main task's
performance and defending against data reconstruction attacks. Furthermore, we
also analyze its potential value in detecting abnormal inputs. In addition, we
conduct extensive experiments to prove \textit{HashVFL}'s generalization in
various settings. In summary, \textit{HashVFL} provides a new perspective on
protecting multi-party's data security and privacy in VFL. We hope our study
can attract more researchers to expand the application domains of
\textit{HashVFL}.
</p></li>
</ul>

<h3>Title: Purifier: Defending Data Inference Attacks via Transforming Confidence Scores. (arXiv:2212.00612v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00612">http://arxiv.org/abs/2212.00612</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00612] Purifier: Defending Data Inference Attacks via Transforming Confidence Scores](http://arxiv.org/abs/2212.00612) #attack</code></li>
<li>Summary: <p>Neural networks are susceptible to data inference attacks such as the
membership inference attack, the adversarial model inversion attack and the
attribute inference attack, where the attacker could infer useful information
such as the membership, the reconstruction or the sensitive attributes of a
data sample from the confidence scores predicted by the target classifier. In
this paper, we propose a method, namely PURIFIER, to defend against membership
inference attacks. It transforms the confidence score vectors predicted by the
target classifier and makes purified confidence scores indistinguishable in
individual shape, statistical distribution and prediction label between members
and non-members. The experimental results show that PURIFIER helps defend
membership inference attacks with high effectiveness and efficiency,
outperforming previous defense methods, and also incurs negligible utility
loss. Besides, our further experiments show that PURIFIER is also effective in
defending adversarial model inversion attacks and attribute inference attacks.
For example, the inversion error is raised about 4+ times on the Facescrub530
classifier, and the attribute inference accuracy drops significantly when
PURIFIER is deployed in our experiment.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Single Slice Thigh CT Muscle Group Segmentation with Domain Adaptation and Self-Training. (arXiv:2212.00059v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00059">http://arxiv.org/abs/2212.00059</a></li>
<li>Code URL: <a href="https://github.com/masilab/da_ct_muscle_seg">https://github.com/masilab/da_ct_muscle_seg</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00059] Single Slice Thigh CT Muscle Group Segmentation with Domain Adaptation and Self-Training](http://arxiv.org/abs/2212.00059) #robust</code></li>
<li>Summary: <p>Objective: Thigh muscle group segmentation is important for assessment of
muscle anatomy, metabolic disease and aging. Many efforts have been put into
quantifying muscle tissues with magnetic resonance (MR) imaging including
manual annotation of individual muscles. However, leveraging publicly available
annotations in MR images to achieve muscle group segmentation on single slice
computed tomography (CT) thigh images is challenging.
</p></li>
</ul>

<p>Method: We propose an unsupervised domain adaptation pipeline with
self-training to transfer labels from 3D MR to single CT slice. First, we
transform the image appearance from MR to CT with CycleGAN and feed the
synthesized CT images to a segmenter simultaneously. Single CT slices are
divided into hard and easy cohorts based on the entropy of pseudo labels
inferenced by the segmenter. After refining easy cohort pseudo labels based on
anatomical assumption, self-training with easy and hard splits is applied to
fine tune the segmenter.
</p>
<p>Results: On 152 withheld single CT thigh images, the proposed pipeline
achieved a mean Dice of 0.888(0.041) across all muscle groups including
sartorius, hamstrings, quadriceps femoris and gracilis. muscles
</p>
<p>Conclusion: To our best knowledge, this is the first pipeline to achieve
thigh imaging domain adaptation from MR to CT. The proposed pipeline is
effective and robust in extracting muscle groups on 2D single slice CT thigh
images.The container is available for public use at
https://github.com/MASILab/DA_CT_muscle_seg
</p>

<h3>Title: FIESTA: FIber gEneration and bundle Segmentation in Tractography using Autoencoders. (arXiv:2212.00143v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00143">http://arxiv.org/abs/2212.00143</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00143] FIESTA: FIber gEneration and bundle Segmentation in Tractography using Autoencoders](http://arxiv.org/abs/2212.00143) #robust</code></li>
<li>Summary: <p>White matter bundle segmentation is a cornerstone of modern tractography to
study the brain's structural connectivity in domains such as neurological
disorders, neurosurgery, and aging. In this study, we present FIESTA (FIber
gEneration and bundle Segmentation in Tractography using Autoencoders), a
reliable and robust, fully automated, and easily semi-automatically calibrated
pipeline based on deep autoencoders that can dissect and fully populate WM
bundles. Our framework allows the transition from one anatomical bundle
definition to another with marginal calibrating time. This pipeline is built
upon FINTA, CINTA, and GESTA methods that demonstrated how autoencoders can be
used successfully for streamline filtering, bundling, and streamline generation
in tractography. Our proposed method improves bundling coverage by recovering
hard-to-track bundles with generative sampling through the latent space seeding
of the subject bundle and the atlas bundle. A latent space of streamlines is
learned using autoencoder-based modeling combined with contrastive learning.
Using an atlas of bundles in standard space (MNI), our proposed method segments
new tractograms using the autoencoder latent distance between each tractogram
streamline and its closest neighbor bundle in the atlas of bundles.
Intra-subject bundle reliability is improved by recovering hard-to-track
streamlines, using the autoencoder to generate new streamlines that increase
each bundle's spatial coverage while remaining anatomically meaningful. Results
show that our method is more reliable than state-of-the-art automated virtual
dissection methods such as RecoBundles, RecoBundlesX, TractSeg, White Matter
Analysis and XTRACT. Overall, these results show that our framework improves
the practicality and usability of current state-of-the-art bundling framework
</p></li>
</ul>

<h3>Title: Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning. (arXiv:2212.00259v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00259">http://arxiv.org/abs/2212.00259</a></li>
<li>Code URL: <a href="https://github.com/lizw14/super-clevr">https://github.com/lizw14/super-clevr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00259] Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning](http://arxiv.org/abs/2212.00259) #robust</code></li>
<li>Summary: <p>Visual Question Answering (VQA) models often perform poorly on
out-of-distribution data and struggle on domain generalization. Due to the
multi-modal nature of this task, multiple factors of variation are intertwined,
making generalization difficult to analyze. This motivates us to introduce a
virtual benchmark, Super-CLEVR, where different factors in VQA domain shifts
can be isolated in order that their effects can be studied independently. Four
factors are considered: visual complexity, question redundancy, concept
distribution and concept compositionality. With controllably generated data,
Super-CLEVR enables us to test VQA methods in situations where the test data
differs from the training data along each of these axes. We study four existing
methods, including two neural symbolic methods NSCL and NSVQA, and two
non-symbolic methods FiLM and mDETR; and our proposed method, probabilistic
NSVQA (P-NSVQA), which extends NSVQA with uncertainty reasoning. P-NSVQA
outperforms other methods on three of the four domain shift factors. Our
results suggest that disentangling reasoning and perception, combined with
probabilistic uncertainty, form a strong VQA model that is more robust to
domain shifts. The dataset and code are released at
https://github.com/Lizw14/Super-CLEVR.
</p></li>
</ul>

<h3>Title: FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning. (arXiv:2212.00465v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00465">http://arxiv.org/abs/2212.00465</a></li>
<li>Code URL: <a href="https://github.com/yuleiqin/fopro">https://github.com/yuleiqin/fopro</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00465] FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning](http://arxiv.org/abs/2212.00465) #robust</code></li>
<li>Summary: <p>Recently, webly supervised learning (WSL) has been studied to leverage
numerous and accessible data from the Internet. Most existing methods focus on
learning noise-robust models from web images while neglecting the performance
drop caused by the differences between web domain and real-world domain.
However, only by tackling the performance gap above can we fully exploit the
practical value of web datasets. To this end, we propose a Few-shot guided
Prototypical (FoPro) representation learning method, which only needs a few
labeled examples from reality and can significantly improve the performance in
the real-world domain. Specifically, we initialize each class center with
few-shot real-world data as the <code>realistic" prototype. Then, the intra-class
distance between web instances and</code>realistic" prototypes is narrowed by
contrastive learning. Finally, we measure image-prototype distance with a
learnable metric. Prototypes are polished by adjacent high-quality web images
and involved in removing distant out-of-distribution samples. In experiments,
FoPro is trained on web datasets with a few real-world examples guided and
evaluated on real-world datasets. Our method achieves the state-of-the-art
performance on three fine-grained datasets and two large-scale datasets.
Compared with existing WSL methods under the same few-shot settings, FoPro
still excels in real-world generalization. Code is available at
https://github.com/yuleiqin/fopro.
</p></li>
</ul>

<h3>Title: Noisy Label Classification using Label Noise Selection with Test-Time Augmentation Cross-Entropy and NoiseMix Learning. (arXiv:2212.00479v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00479">http://arxiv.org/abs/2212.00479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00479] Noisy Label Classification using Label Noise Selection with Test-Time Augmentation Cross-Entropy and NoiseMix Learning](http://arxiv.org/abs/2212.00479) #robust</code></li>
<li>Summary: <p>As the size of the dataset used in deep learning tasks increases, the noisy
label problem, which is a task of making deep learning robust to the
incorrectly labeled data, has become an important task. In this paper, we
propose a method of learning noisy label data using the label noise selection
with test-time augmentation (TTA) cross-entropy and classifier learning with
the NoiseMix method. In the label noise selection, we propose TTA cross-entropy
by measuring the cross-entropy to predict the test-time augmented training
data. In the classifier learning, we propose the NoiseMix method based on MixUp
and BalancedMix methods by mixing the samples from the noisy and the clean
label data. In experiments on the ISIC-18 public skin lesion diagnosis dataset,
the proposed TTA cross-entropy outperformed the conventional cross-entropy and
the TTA uncertainty in detecting label noise data in the label noise selection
process. Moreover, the proposed NoiseMix not only outperformed the
state-of-the-art methods in the classification performance but also showed the
most robustness to the label noise in the classifier learning.
</p></li>
</ul>

<h3>Title: Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis. (arXiv:2212.00678v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00678">http://arxiv.org/abs/2212.00678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00678] Adapted Multimodal BERT with Layer-wise Fusion for Sentiment Analysis](http://arxiv.org/abs/2212.00678) #robust</code></li>
<li>Summary: <p>Multimodal learning pipelines have benefited from the success of pretrained
language models. However, this comes at the cost of increased model parameters.
In this work, we propose Adapted Multimodal BERT (AMB), a BERT-based
architecture for multimodal tasks that uses a combination of adapter modules
and intermediate fusion layers. The adapter adjusts the pretrained language
model for the task at hand, while the fusion layers perform task-specific,
layer-wise fusion of audio-visual information with textual BERT
representations. During the adaptation process the pre-trained language model
parameters remain frozen, allowing for fast, parameter-efficient training. In
our ablations we see that this approach leads to efficient models, that can
outperform their fine-tuned counterparts and are robust to input noise. Our
experiments on sentiment analysis with CMU-MOSEI show that AMB outperforms the
current state-of-the-art across metrics, with 3.4% relative reduction in the
resulting error and 2.1% relative improvement in 7-class classification
accuracy.
</p></li>
</ul>

<h3>Title: Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks. (arXiv:2212.00771v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00771">http://arxiv.org/abs/2212.00771</a></li>
<li>Code URL: <a href="https://github.com/mjamroz90/dnn-class-fitting">https://github.com/mjamroz90/dnn-class-fitting</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00771] Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks](http://arxiv.org/abs/2212.00771) #robust</code></li>
<li>Summary: <p>We leverage probabilistic models of neural representations to investigate how
residual networks fit classes. To this end, we estimate class-conditional
density models for representations learned by deep ResNets. We then use these
models to characterize distributions of representations across learned classes.
Surprisingly, we find that classes in the investigated models are not fitted in
an uniform way. On the contrary: we uncover two groups of classes that are
fitted with markedly different distributions of representations. These distinct
modes of class-fitting are evident only in the deeper layers of the
investigated models, indicating that they are not related to low-level image
features. We show that the uncovered structure in neural representations
correlate with memorization of training examples and adversarial robustness.
Finally, we compare class-conditional distributions of neural representations
between memorized and typical examples. This allows us to uncover where in the
network structure class labels arise for memorized and standard inputs.
</p></li>
</ul>

<h3>Title: FakeOut: Leveraging Out-of-domain Self-supervision for Multi-modal Video Deepfake Detection. (arXiv:2212.00773v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00773">http://arxiv.org/abs/2212.00773</a></li>
<li>Code URL: <a href="https://github.com/gilikn/fakeout">https://github.com/gilikn/fakeout</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00773] FakeOut: Leveraging Out-of-domain Self-supervision for Multi-modal Video Deepfake Detection](http://arxiv.org/abs/2212.00773) #robust</code></li>
<li>Summary: <p>Video synthesis methods rapidly improved in recent years, allowing easy
creation of synthetic humans. This poses a problem, especially in the era of
social media, as synthetic videos of speaking humans can be used to spread
misinformation in a convincing manner. Thus, there is a pressing need for
accurate and robust deepfake detection methods, that can detect forgery
techniques not seen during training. In this work, we explore whether this can
be done by leveraging a multi-modal, out-of-domain backbone trained in a
self-supervised manner, adapted to the video deepfake domain. We propose
FakeOut; a novel approach that relies on multi-modal data throughout both the
pre-training phase and the adaption phase. We demonstrate the efficacy and
robustness of FakeOut in detecting various types of deepfakes, especially
manipulations which were not seen during training. Our method achieves
state-of-the-art results in cross-manipulation and cross-dataset
generalization. This study shows that, perhaps surprisingly, training on
out-of-domain videos (i.e., videos with no speaking humans), can lead to better
deepfake detection systems. Code is available on GitHub.
</p></li>
</ul>

<h3>Title: Universe Points Representation Learning for Partial Multi-Graph Matching. (arXiv:2212.00780v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00780">http://arxiv.org/abs/2212.00780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00780] Universe Points Representation Learning for Partial Multi-Graph Matching](http://arxiv.org/abs/2212.00780) #robust</code></li>
<li>Summary: <p>Many challenges from natural world can be formulated as a graph matching
problem. Previous deep learning-based methods mainly consider a full two-graph
matching setting. In this work, we study the more general partial matching
problem with multi-graph cycle consistency guarantees. Building on a recent
progress in deep learning on graphs, we propose a novel data-driven method
(URL) for partial multi-graph matching, which uses an object-to-universe
formulation and learns latent representations of abstract universe points. The
proposed approach advances the state of the art in semantic keypoint matching
problem, evaluated on Pascal VOC, CUB, and Willow datasets. Moreover, the set
of controlled experiments on a synthetic graph matching dataset demonstrates
the scalability of our method to graphs with large number of nodes and its
robustness to high partiality.
</p></li>
</ul>

<h3>Title: Sparsity Agnostic Depth Completion. (arXiv:2212.00790v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00790">http://arxiv.org/abs/2212.00790</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00790] Sparsity Agnostic Depth Completion](http://arxiv.org/abs/2212.00790) #robust</code></li>
<li>Summary: <p>We present a novel depth completion approach agnostic to the sparsity of
depth points, that is very likely to vary in many practical applications.
State-of-the-art approaches yield accurate results only when processing a
specific density and distribution of input points, i.e. the one observed during
training, narrowing their deployment in real use cases. On the contrary, our
solution is robust to uneven distributions and extremely low densities never
witnessed during training. Experimental results on standard indoor and outdoor
benchmarks highlight the robustness of our framework, achieving accuracy
comparable to state-of-the-art methods when tested with density and
distribution equal to the training one while being much more accurate in the
other cases. Our pretrained models and further material are available in our
project page.
</p></li>
</ul>

<h3>Title: Language Model Pre-training on True Negatives. (arXiv:2212.00460v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00460">http://arxiv.org/abs/2212.00460</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00460] Language Model Pre-training on True Negatives](http://arxiv.org/abs/2212.00460) #robust</code></li>
<li>Summary: <p>Discriminative pre-trained language models (PLMs) learn to predict original
texts from intentionally corrupted ones. Taking the former text as positive and
the latter as negative samples, the PLM can be trained effectively for
contextualized representation. However, the training of such a type of PLMs
highly relies on the quality of the automatically constructed samples. Existing
PLMs simply treat all corrupted texts as equal negative without any
examination, which actually lets the resulting model inevitably suffer from the
false negative issue where training is carried out on pseudo-negative data and
leads to less efficiency and less robustness in the resulting PLMs. In this
work, on the basis of defining the false negative issue in discriminative PLMs
that has been ignored for a long time, we design enhanced pre-training methods
to counteract false negative predictions and encourage pre-training language
models on true negatives by correcting the harmful gradient updates subject to
false negative predictions. Experimental results on GLUE and SQuAD benchmarks
show that our counter-false-negative pre-training methods indeed bring about
better performance together with stronger robustness.
</p></li>
</ul>

<h3>Title: Embedding generation for text classification of Brazilian Portuguese user reviews: from bag-of-words to transformers. (arXiv:2212.00587v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00587">http://arxiv.org/abs/2212.00587</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00587] Embedding generation for text classification of Brazilian Portuguese user reviews: from bag-of-words to transformers](http://arxiv.org/abs/2212.00587) #robust</code></li>
<li>Summary: <p>Text classification is a natural language processing (NLP) task relevant to
many commercial applications, like e-commerce and customer service. Naturally,
classifying such excerpts accurately often represents a challenge, due to
intrinsic language aspects, like irony and nuance. To accomplish this task, one
must provide a robust numerical representation for documents, a process known
as embedding. Embedding represents a key NLP field nowadays, having faced a
significant advance in the last decade, especially after the introduction of
the word-to-vector concept and the popularization of Deep Learning models for
solving NLP tasks, including Convolutional Neural Networks (CNNs), Recurrent
Neural Networks (RNNs), and Transformer-based Language Models (TLMs). Despite
the impressive achievements in this field, the literature coverage regarding
generating embeddings for Brazilian Portuguese texts is scarce, especially when
considering commercial user reviews. Therefore, this work aims to provide a
comprehensive experimental study of embedding approaches targeting a binary
sentiment classification of user reviews in Brazilian Portuguese. This study
includes from classical (Bag-of-Words) to state-of-the-art (Transformer-based)
NLP models. The methods are evaluated with five open-source databases with
pre-defined data partitions made available in an open digital repository to
encourage reproducibility. The Fine-tuned TLMs achieved the best results for
all cases, being followed by the Feature-based TLM, LSTM, and CNN, with
alternate ranks, depending on the database under analysis.
</p></li>
</ul>

<h3>Title: Extensible Prompts for Language Models. (arXiv:2212.00616v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00616">http://arxiv.org/abs/2212.00616</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00616] Extensible Prompts for Language Models](http://arxiv.org/abs/2212.00616) #robust</code></li>
<li>Summary: <p>We propose eXtensible Prompt (X-Prompt) for prompting a large language model
(LLM) beyond natural language (NL). X-Prompt instructs an LLM with not only NL
but also an extensible vocabulary of imaginary words that are introduced to
help represent what NL words hardly describe, allowing a prompt to be more
descriptive. Like NL prompts, X-Prompt is out-of-distribution (OOD) robust, for
which we propose context-guided learning with prompt augmentation to learn its
imaginary words for general usability, enabling them to use in different prompt
contexts for fine-grain specifications. The promising results of X-Prompt
demonstrate its potential of approaching advanced interaction between humans
and LLMs to bridge their communication gap.
</p></li>
</ul>

<h3>Title: Scalable Pathogen Detection from Next Generation DNA Sequencing with Deep Learning. (arXiv:2212.00015v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00015">http://arxiv.org/abs/2212.00015</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00015] Scalable Pathogen Detection from Next Generation DNA Sequencing with Deep Learning](http://arxiv.org/abs/2212.00015) #robust</code></li>
<li>Summary: <p>Next-generation sequencing technologies have enhanced the scope of
Internet-of-Things (IoT) to include genomics for personalized medicine through
the increased availability of an abundance of genome data collected from
heterogeneous sources at a reduced cost. Given the sheer magnitude of the
collected data and the significant challenges offered by the presence of highly
similar genomic structure across species, there is a need for robust, scalable
analysis platforms to extract actionable knowledge such as the presence of
potentially zoonotic pathogens. The emergence of zoonotic diseases from novel
pathogens, such as the influenza virus in 1918 and SARS-CoV-2 in 2019 that can
jump species barriers and lead to pandemic underscores the need for scalable
metagenome analysis. In this work, we propose MG2Vec, a deep learning-based
solution that uses the transformer network as its backbone, to learn robust
features from raw metagenome sequences for downstream biomedical tasks such as
targeted and generalized pathogen detection. Extensive experiments on four
increasingly challenging, yet realistic diagnostic settings, show that the
proposed approach can help detect pathogens from uncurated, real-world clinical
samples with minimal human supervision in the form of labels. Further, we
demonstrate that the learned representations can generalize to completely
unrelated pathogens across diseases and species for large-scale metagenome
analysis. We provide a comprehensive evaluation of a novel representation
learning framework for metagenome-based disease diagnostics with deep learning
and provide a way forward for extracting and using robust vector
representations from low-cost next generation sequencing to develop
generalizable diagnostic tools.
</p></li>
</ul>

<h3>Title: Semi-Supervised Heterogeneous Graph Learning with Multi-level Data Augmentation. (arXiv:2212.00024v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00024">http://arxiv.org/abs/2212.00024</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00024] Semi-Supervised Heterogeneous Graph Learning with Multi-level Data Augmentation](http://arxiv.org/abs/2212.00024) #robust</code></li>
<li>Summary: <p>In recent years, semi-supervised graph learning with data augmentation (DA)
is currently the most commonly used and best-performing method to enhance model
robustness in sparse scenarios with few labeled samples. Differing from
homogeneous graph, DA in heterogeneous graph has greater challenges:
heterogeneity of information requires DA strategies to effectively handle
heterogeneous relations, which considers the information contribution of
different types of neighbors and edges to the target nodes. Furthermore,
over-squashing of information is caused by the negative curvature that formed
by the non-uniformity distribution and strong clustering in complex graph. To
address these challenges, this paper presents a novel method named
Semi-Supervised Heterogeneous Graph Learning with Multi-level Data Augmentation
(HG-MDA). For the problem of heterogeneity of information in DA, node and
topology augmentation strategies are proposed for the characteristics of
heterogeneous graph. And meta-relation-based attention is applied as one of the
indexes for selecting augmented nodes and edges. For the problem of
over-squashing of information, triangle based edge adding and removing are
designed to alleviate the negative curvature and bring the gain of topology.
Finally, the loss function consists of the cross-entropy loss for labeled data
and the consistency regularization for unlabeled data. In order to effectively
fuse the prediction results of various DA strategies, the sharpening is used.
Existing experiments on public datasets, i.e., ACM, DBLP, OGB, and industry
dataset MB show that HG-MDA outperforms current SOTA models. Additionly, HG-MDA
is applied to user identification in internet finance scenarios, helping the
business to add 30% key users, and increase loans and balances by 3.6%, 11.1%,
and 9.8%.
</p></li>
</ul>

<h3>Title: Evidential Conditional Neural Processes. (arXiv:2212.00131v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00131">http://arxiv.org/abs/2212.00131</a></li>
<li>Code URL: <a href="https://github.com/pandeydeep9/ecnp">https://github.com/pandeydeep9/ecnp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00131] Evidential Conditional Neural Processes](http://arxiv.org/abs/2212.00131) #robust</code></li>
<li>Summary: <p>The Conditional Neural Process (CNP) family of models offer a promising
direction to tackle few-shot problems by achieving better scalability and
competitive predictive performance. However, the current CNP models only
capture the overall uncertainty for the prediction made on a target data point.
They lack a systematic fine-grained quantification on the distinct sources of
uncertainty that are essential for model training and decision-making under the
few-shot setting. We propose Evidential Conditional Neural Processes (ECNP),
which replace the standard Gaussian distribution used by CNP with a much richer
hierarchical Bayesian structure through evidential learning to achieve
epistemic-aleatoric uncertainty decomposition. The evidential hierarchical
structure also leads to a theoretically justified robustness over noisy
training tasks. Theoretical analysis on the proposed ECNP establishes the
relationship with CNP while offering deeper insights on the roles of the
evidential parameters. Extensive experiments conducted on both synthetic and
real-world data demonstrate the effectiveness of our proposed model in various
few-shot settings.
</p></li>
</ul>

<h3>Title: SPADE: Semi-supervised Anomaly Detection under Distribution Mismatch. (arXiv:2212.00173v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00173">http://arxiv.org/abs/2212.00173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00173] SPADE: Semi-supervised Anomaly Detection under Distribution Mismatch](http://arxiv.org/abs/2212.00173) #robust</code></li>
<li>Summary: <p>Semi-supervised anomaly detection is a common problem, as often the datasets
containing anomalies are partially labeled. We propose a canonical framework:
Semi-supervised Pseudo-labeler Anomaly Detection with Ensembling (SPADE) that
isn't limited by the assumption that labeled and unlabeled data come from the
same distribution. Indeed, the assumption is often violated in many
applications - for example, the labeled data may contain only anomalies unlike
unlabeled data, or unlabeled data may contain different types of anomalies, or
labeled data may contain only 'easy-to-label' samples. SPADE utilizes an
ensemble of one class classifiers as the pseudo-labeler to improve the
robustness of pseudo-labeling with distribution mismatch. Partial matching is
proposed to automatically select the critical hyper-parameters for
pseudo-labeling without validation data, which is crucial with limited labeled
data. SPADE shows state-of-the-art semi-supervised anomaly detection
performance across a wide range of scenarios with distribution mismatch in both
tabular and image domains. In some common real-world settings such as model
facing new types of unlabeled anomalies, SPADE outperforms the state-of-the-art
alternatives by 5% AUC in average.
</p></li>
</ul>

<h3>Title: Experimental Observations of the Topology of Convolutional Neural Network Activations. (arXiv:2212.00222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00222">http://arxiv.org/abs/2212.00222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00222] Experimental Observations of the Topology of Convolutional Neural Network Activations](http://arxiv.org/abs/2212.00222) #robust</code></li>
<li>Summary: <p>Topological data analysis (TDA) is a branch of computational mathematics,
bridging algebraic topology and data science, that provides compact,
noise-robust representations of complex structures. Deep neural networks (DNNs)
learn millions of parameters associated with a series of transformations
defined by the model architecture, resulting in high-dimensional,
difficult-to-interpret internal representations of input data. As DNNs become
more ubiquitous across multiple sectors of our society, there is increasing
recognition that mathematical methods are needed to aid analysts, researchers,
and practitioners in understanding and interpreting how these models' internal
representations relate to the final classification. In this paper, we apply
cutting edge techniques from TDA with the goal of gaining insight into the
interpretability of convolutional neural networks used for image
classification. We use two common TDA approaches to explore several methods for
modeling hidden-layer activations as high-dimensional point clouds, and provide
experimental evidence that these point clouds capture valuable structural
information about the model's process. First, we demonstrate that a distance
metric based on persistent homology can be used to quantify meaningful
differences between layers, and we discuss these distances in the broader
context of existing representational similarity metrics for neural network
interpretability. Second, we show that a mapper graph can provide semantic
insight into how these models organize hierarchical class knowledge at each
layer. These observations demonstrate that TDA is a useful tool to help deep
learning practitioners unlock the hidden structures of their models.
</p></li>
</ul>

<h3>Title: Generalizing and Improving Jacobian and Hessian Regularization. (arXiv:2212.00311v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00311">http://arxiv.org/abs/2212.00311</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00311] Generalizing and Improving Jacobian and Hessian Regularization](http://arxiv.org/abs/2212.00311) #robust</code></li>
<li>Summary: <p>Jacobian and Hessian regularization aim to reduce the magnitude of the first
and second-order partial derivatives with respect to neural network inputs, and
they are predominantly used to ensure the adversarial robustness of image
classifiers. In this work, we generalize previous efforts by extending the
target matrix from zero to any matrix that admits efficient matrix-vector
products. The proposed paradigm allows us to construct novel regularization
terms that enforce symmetry or diagonality on square Jacobian and Hessian
matrices. On the other hand, the major challenge for Jacobian and Hessian
regularization has been high computational complexity. We introduce
Lanczos-based spectral norm minimization to tackle this difficulty. This
technique uses a parallelized implementation of the Lanczos algorithm and is
capable of effective and stable regularization of large Jacobian and Hessian
matrices. Theoretical justifications and empirical evidence are provided for
the proposed paradigm and technique. We carry out exploratory experiments to
validate the effectiveness of our novel regularization terms. We also conduct
comparative experiments to evaluate Lanczos-based spectral norm minimization
against prior methods. Results show that the proposed methodologies are
advantageous for a wide range of tasks.
</p></li>
</ul>

<h3>Title: Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View. (arXiv:2212.00535v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00535">http://arxiv.org/abs/2212.00535</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00535] Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View](http://arxiv.org/abs/2212.00535) #robust</code></li>
<li>Summary: <p>Graph anomaly detection (GAD) is a vital task in graph-based machine learning
and has been widely applied in many real-world applications. The primary goal
of GAD is to capture anomalous nodes from graph datasets, which evidently
deviate from the majority of nodes. Recent methods have paid attention to
various scales of contrastive strategies for GAD, i.e., node-subgraph and
node-node contrasts. However, they neglect the subgraph-subgraph comparison
information which the normal and abnormal subgraph pairs behave differently in
terms of embeddings and structures in GAD, resulting in sub-optimal task
performance. In this paper, we fulfill the above idea in the proposed
multi-view multi-scale contrastive learning framework with subgraph-subgraph
contrast for the first practice. To be specific, we regard the original input
graph as the first view and generate the second view by graph augmentation with
edge modifications. With the guidance of maximizing the similarity of the
subgraph pairs, the proposed subgraph-subgraph contrast contributes to more
robust subgraph embeddings despite of the structure variation. Moreover, the
introduced subgraph-subgraph contrast cooperates well with the widely-adopted
node-subgraph and node-node contrastive counterparts for mutual GAD performance
promotions. Besides, we also conduct sufficient experiments to investigate the
impact of different graph augmentation approaches on detection performance. The
comprehensive experimental results well demonstrate the superiority of our
method compared with the state-of-the-art approaches and the effectiveness of
the multi-view subgraph pair contrastive strategy for the GAD task.
</p></li>
</ul>

<h3>Title: Deep Kernel Learning for Mortality Prediction in the Face of Temporal Shift. (arXiv:2212.00557v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00557">http://arxiv.org/abs/2212.00557</a></li>
<li>Code URL: <a href="https://github.com/mriosb08/dkl-temporal-shift">https://github.com/mriosb08/dkl-temporal-shift</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00557] Deep Kernel Learning for Mortality Prediction in the Face of Temporal Shift](http://arxiv.org/abs/2212.00557) #robust</code></li>
<li>Summary: <p>Neural models, with their ability to provide novel representations, have
shown promising results in prediction tasks in healthcare. However, patient
demographics, medical technology, and quality of care change over time. This
often leads to drop in the performance of neural models for prospective
patients, especially in terms of their calibration. The deep kernel learning
(DKL) framework may be robust to such changes as it combines neural models with
Gaussian processes, which are aware of prediction uncertainty. Our hypothesis
is that out-of-distribution test points will result in probabilities closer to
the global mean and hence prevent overconfident predictions. This in turn, we
hypothesise, will result in better calibration on prospective data.
</p></li>
</ul>

<p>This paper investigates DKL's behaviour when facing a temporal shift, which
was naturally introduced when an information system that feeds a cohort
database was changed. We compare DKL's performance to that of a neural baseline
based on recurrent neural networks. We show that DKL indeed produced superior
calibrated predictions. We also confirm that the DKL's predictions were indeed
less sharp. In addition, DKL's discrimination ability was even improved: its
AUC was 0.746 (+- 0.014 std), compared to 0.739 (+- 0.028 std) for the
baseline. The paper demonstrated the importance of including uncertainty in
neural computing, especially for their prospective use.
</p>

<h2>biometric</h2>
<h2>steal</h2>
<h3>Title: Crowd-level Abnormal Behavior Detection via Multi-scale Motion Consistency Learning. (arXiv:2212.00501v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00501">http://arxiv.org/abs/2212.00501</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00501] Crowd-level Abnormal Behavior Detection via Multi-scale Motion Consistency Learning](http://arxiv.org/abs/2212.00501) #steal</code></li>
<li>Summary: <p>Detecting abnormal crowd motion emerging from complex interactions of
individuals is paramount to ensure the safety of crowds. Crowd-level abnormal
behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the
crucial causes of many crowd disasters. In the recent decade, video anomaly
detection (VAD) techniques have achieved remarkable success in detecting
individual-level abnormal behaviors (e.g., sudden running, fighting and
stealing), but research on VAD for CABs is rather limited. Unlike
individual-level anomaly, CABs usually do not exhibit salient difference from
the normal behaviors when observed locally, and the scale of CABs could vary
from one scenario to another. In this paper, we present a systematic study to
tackle the important problem of VAD for CABs with a novel crowd motion learning
framework, multi-scale motion consistency network (MSMC-Net). MSMC-Net first
captures the spatial and temporal crowd motion consistency information in a
graph representation. Then, it simultaneously trains multiple feature graphs
constructed at different scales to capture rich crowd patterns. An attention
network is used to adaptively fuse the multi-scale features for better CAB
detection. For the empirical study, we consider three large-scale crowd event
datasets, UMN, Hajj and Love Parade. Experimental results show that MSMC-Net
could substantially improve the state-of-the-art performance on all the
datasets.
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: Open Relation and Event Type Discovery with Type Abstraction. (arXiv:2212.00178v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00178">http://arxiv.org/abs/2212.00178</a></li>
<li>Code URL: <a href="https://github.com/raspberryice/type-discovery-abs">https://github.com/raspberryice/type-discovery-abs</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00178] Open Relation and Event Type Discovery with Type Abstraction](http://arxiv.org/abs/2212.00178) #extraction</code></li>
<li>Summary: <p>Conventional closed-world information extraction (IE) approaches rely on
human ontologies to define the scope for extraction. As a result, such
approaches fall short when applied to new domains. This calls for systems that
can automatically infer new types from given corpora, a task which we refer to
as type discovery. To tackle this problem, we introduce the idea of type
abstraction, where the model is prompted to generalize and name the type. Then
we use the similarity between inferred names to induce clusters. Observing that
this abstraction-based representation is often complementary to the
entity/trigger token representation, we set up these two representations as two
views and design our model as a co-training framework. Our experiments on
multiple relation extraction and event extraction datasets consistently show
the advantage of our type abstraction approach. Code available at
https://github.com/raspberryice/type-discovery-abs.
</p></li>
</ul>

<h3>Title: CliMedBERT: A Pre-trained Language Model for Climate and Health-related Text. (arXiv:2212.00689v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00689">http://arxiv.org/abs/2212.00689</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00689] CliMedBERT: A Pre-trained Language Model for Climate and Health-related Text](http://arxiv.org/abs/2212.00689) #extraction</code></li>
<li>Summary: <p>Climate change is threatening human health in unprecedented orders and many
ways. These threats are expected to grow unless effective and evidence-based
policies are developed and acted upon to minimize or eliminate them. Attaining
such a task requires the highest degree of the flow of knowledge from science
into policy. The multidisciplinary, location-specific, and vastness of
published science makes it challenging to keep track of novel work in this
area, as well as making the traditional knowledge synthesis methods inefficient
in infusing science into policy. To this end, we consider developing multiple
domain-specific language models (LMs) with different variations from Climate-
and Health-related information, which can serve as a foundational step toward
capturing available knowledge to enable solving different tasks, such as
detecting similarities between climate- and health-related concepts,
fact-checking, relation extraction, evidence of health effects to policy text
generation, and more. To our knowledge, this is the first work that proposes
developing multiple domain-specific language models for the considered domains.
We will make the developed models, resources, and codebase available for the
researchers.
</p></li>
</ul>

<h3>Title: Explainable Artificial Intelligence for Improved Modeling of Processes. (arXiv:2212.00695v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00695">http://arxiv.org/abs/2212.00695</a></li>
<li>Code URL: <a href="https://github.com/rizavelioglu/ml4prom">https://github.com/rizavelioglu/ml4prom</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00695] Explainable Artificial Intelligence for Improved Modeling of Processes](http://arxiv.org/abs/2212.00695) #extraction</code></li>
<li>Summary: <p>In modern business processes, the amount of data collected has increased
substantially in recent years. Because this data can potentially yield valuable
insights, automated knowledge extraction based on process mining has been
proposed, among other techniques, to provide users with intuitive access to the
information contained therein. At present, the majority of technologies aim to
reconstruct explicit business process models. These are directly interpretable
but limited concerning the integration of diverse and real-valued information
sources. On the other hand, Machine Learning (ML) benefits from the vast amount
of data available and can deal with high-dimensional sources, yet it has rarely
been applied to being used in processes. In this contribution, we evaluate the
capability of modern Transformer architectures as well as more classical ML
technologies of modeling process regularities, as can be quantitatively
evaluated by their prediction capability. In addition, we demonstrate the
capability of attentional properties and feature relevance determination by
highlighting features that are crucial to the processes' predictive abilities.
We demonstrate the efficacy of our approach using five benchmark datasets and
show that the ML models are capable of predicting critical outcomes and that
the attention mechanisms or XAI components offer new insights into the
underlying processes.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: AUG-FedPrompt: Practical Few-shot Federated NLP with Data-augmented Prompts. (arXiv:2212.00192v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00192">http://arxiv.org/abs/2212.00192</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00192] AUG-FedPrompt: Practical Few-shot Federated NLP with Data-augmented Prompts](http://arxiv.org/abs/2212.00192) #federate</code></li>
<li>Summary: <p>Transformer-based pre-trained models have become the de-facto solution for
NLP tasks. Fine-tuning such pre-trained models for downstream tasks often
requires tremendous amount of data that is both private and labeled. However,
in reality: 1) such private data cannot be collected and is distributed across
mobile devices, and 2) well-curated labeled data is scarce. To tackle those
issues, we first define a data generator for federated few-shot learning tasks,
which encompasses the quantity and distribution of scarce labeled data in a
realistic setting. Then we propose AUG-FedPrompt, a prompt-based federated
learning algorithm that carefully annotates abundant unlabeled data for data
augmentation. AUG-FedPrompt can perform on par with full-set fine-tuning with
very few initial labeled data.
</p></li>
</ul>

<h3>Title: Hijack Vertical Federated Learning Models with Adversarial Embedding. (arXiv:2212.00322v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00322">http://arxiv.org/abs/2212.00322</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00322] Hijack Vertical Federated Learning Models with Adversarial Embedding](http://arxiv.org/abs/2212.00322) #federate</code></li>
<li>Summary: <p>Vertical federated learning (VFL) is an emerging paradigm that enables
collaborators to build machine learning models together in a distributed
fashion. In general, these parties have a group of users in common but own
different features. Existing VFL frameworks use cryptographic techniques to
provide data privacy and security guarantees, leading to a line of works
studying computing efficiency and fast implementation. However, the security of
VFL's model remains underexplored.
</p></li>
</ul>

<h3>Title: Early prediction of the risk of ICU mortality with Deep Federated Learning. (arXiv:2212.00554v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00554">http://arxiv.org/abs/2212.00554</a></li>
<li>Code URL: <a href="https://github.com/randlbem/early_icu_mortality_prediction_with_deep_fl">https://github.com/randlbem/early_icu_mortality_prediction_with_deep_fl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00554] Early prediction of the risk of ICU mortality with Deep Federated Learning](http://arxiv.org/abs/2212.00554) #federate</code></li>
<li>Summary: <p>Intensive Care Units usually carry patients with a serious risk of mortality.
Recent research has shown the ability of Machine Learning to indicate the
patients' mortality risk and point physicians toward individuals with a
heightened need for care. Nevertheless, healthcare data is often subject to
privacy regulations and can therefore not be easily shared in order to build
Centralized Machine Learning models that use the combined data of multiple
hospitals. Federated Learning is a Machine Learning framework designed for data
privacy that can be used to circumvent this problem. In this study, we evaluate
the ability of deep Federated Learning to predict the risk of Intensive Care
Unit mortality at an early stage. We compare the predictive performance of
Federated, Centralized, and Local Machine Learning in terms of AUPRC, F1-score,
and AUROC. Our results show that Federated Learning performs equally well as
the centralized approach and is substantially better than the local approach,
thus providing a viable solution for early Intensive Care Unit mortality
prediction. In addition, we show that the prediction performance is higher when
the patient history window is closer to discharge or death. Finally, we show
that using the F1-score as an early stopping metric can stabilize and increase
the performance of our approach for the task at hand.
</p></li>
</ul>

<h3>Title: Vertical Federated Learning: A Structured Literature Review. (arXiv:2212.00622v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00622">http://arxiv.org/abs/2212.00622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00622] Vertical Federated Learning: A Structured Literature Review](http://arxiv.org/abs/2212.00622) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) has emerged as a promising distributed learning
paradigm with an added advantage of data privacy. With the growing interest in
having collaboration among data owners, FL has gained significant attention of
organizations. The idea of FL is to enable collaborating participants train
machine learning (ML) models on decentralized data without breaching privacy.
In simpler words, federated learning is the approach of ``bringing the model to
the data, instead of bringing the data to the mode''. Federated learning, when
applied to data which is partitioned vertically across participants, is able to
build a complete ML model by combining local models trained only using the data
with distinct features at the local sites. This architecture of FL is referred
to as vertical federated learning (VFL), which differs from the conventional FL
on horizontally partitioned data. As VFL is different from conventional FL, it
comes with its own issues and challenges. In this paper, we present a
structured literature review discussing the state-of-the-art approaches in VFL.
Additionally, the literature review highlights the existing solutions to
challenges in VFL and provides potential research directions in this domain.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Learning to Generate Text-grounded Mask for Open-world Semantic Segmentation from Only Image-Text Pairs. (arXiv:2212.00785v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00785">http://arxiv.org/abs/2212.00785</a></li>
<li>Code URL: <a href="https://github.com/kakaobrain/tcl">https://github.com/kakaobrain/tcl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00785] Learning to Generate Text-grounded Mask for Open-world Semantic Segmentation from Only Image-Text Pairs](http://arxiv.org/abs/2212.00785) #fair</code></li>
<li>Summary: <p>We tackle open-world semantic segmentation, which aims at learning to segment
arbitrary visual concepts in images, by using only image-text pairs without
dense annotations. Existing open-world segmentation methods have shown
impressive advances by employing contrastive learning (CL) to learn diverse
visual concepts and adapting the learned image-level understanding to the
segmentation task. However, these methods based on CL have a discrepancy since
it only considers image-text level alignment in training time, while the
segmentation task requires region-text level alignment at test time. In this
paper, we propose a novel Text-grounded Contrastive Learning (TCL) framework to
directly align a text and a region described by the text to address the
train-test discrepancy. Our method generates a segmentation mask associated
with a given text, extracts grounded image embedding from the masked region,
and aligns it with text embedding via TCL. The framework addresses the
discrepancy by letting the model learn region-text level alignment instead of
image-text level alignment and encourages the model to directly improve the
quality of generated segmentation masks. In addition, for a rigorous and fair
comparison, we present a unified evaluation protocol with widely used 8
semantic segmentation datasets. TCL achieves state-of-the-art zero-shot
segmentation performance with large margins in all datasets. Code is available
at https://github.com/kakaobrain/tcl.
</p></li>
</ul>

<h3>Title: CUNI Non-Autoregressive System for the WMT 22 Efficient Translation Shared Task. (arXiv:2212.00477v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00477">http://arxiv.org/abs/2212.00477</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00477] CUNI Non-Autoregressive System for the WMT 22 Efficient Translation Shared Task](http://arxiv.org/abs/2212.00477) #fair</code></li>
<li>Summary: <p>We present a non-autoregressive system submission to the WMT 22 Efficient
Translation Shared Task. Our system was used by Helcl et al. (2022) in an
attempt to provide fair comparison between non-autoregressive and
autoregressive models. This submission is an effort to establish solid
baselines along with sound evaluation methodology, particularly in terms of
measuring the decoding speed. The model itself is a 12-layer Transformer model
trained with connectionist temporal classification on knowledge-distilled
dataset by a strong autoregressive teacher model.
</p></li>
</ul>

<h3>Title: Probably Approximate Shapley Fairness with Applications in Machine Learning. (arXiv:2212.00630v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00630">http://arxiv.org/abs/2212.00630</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00630] Probably Approximate Shapley Fairness with Applications in Machine Learning](http://arxiv.org/abs/2212.00630) #fair</code></li>
<li>Summary: <p>The Shapley value (SV) is adopted in various scenarios in machine learning
(ML), including data valuation, agent valuation, and feature attribution, as it
satisfies their fairness requirements. However, as exact SVs are infeasible to
compute in practice, SV estimates are approximated instead. This approximation
step raises an important question: do the SV estimates preserve the fairness
guarantees of exact SVs? We observe that the fairness guarantees of exact SVs
are too restrictive for SV estimates. Thus, we generalise Shapley fairness to
probably approximate Shapley fairness and propose fidelity score, a metric to
measure the variation of SV estimates, that determines how probable the
fairness guarantees hold. Our last theoretical contribution is a novel greedy
active estimation (GAE) algorithm that will maximise the lowest fidelity score
and achieve a better fairness guarantee than the de facto Monte-Carlo
estimation. We empirically verify GAE outperforms several existing methods in
guaranteeing fairness while remaining competitive in estimation accuracy in
various ML scenarios using real-world datasets.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Implicit Mixture of Interpretable Experts for Global and Local Interpretability. (arXiv:2212.00471v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00471">http://arxiv.org/abs/2212.00471</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00471] Implicit Mixture of Interpretable Experts for Global and Local Interpretability](http://arxiv.org/abs/2212.00471) #interpretability</code></li>
<li>Summary: <p>We investigate the feasibility of using mixtures of interpretable experts
(MoIE) to build interpretable image classifiers on MNIST10. MoIE uses a
black-box router to assign each input to one of many inherently interpretable
experts, thereby providing insight into why a particular classification
decision was made. We find that a naively trained MoIE will learn to 'cheat',
whereby the black-box router will solve the classification problem by itself,
with each expert simply learning a constant function for one particular class.
We propose to solve this problem by introducing interpretable routers and
training the black-box router's decisions to match the interpretable router. In
addition, we propose a novel implicit parameterization scheme that allows us to
build mixtures of arbitrary numbers of experts, allowing us to study how
classification performance, local and global interpretability vary as the
number of experts is increased. Our new model, dubbed Implicit Mixture of
Interpretable Experts (IMoIE) can match state-of-the-art classification
accuracy on MNIST10 while providing local interpretability, and can provide
global interpretability albeit at the cost of reduced classification accuracy.
</p></li>
</ul>

<h3>Title: Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection. (arXiv:2212.00789v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00789">http://arxiv.org/abs/2212.00789</a></li>
<li>Code URL: <a href="https://github.com/talreiss/accurate-interpretable-vad">https://github.com/talreiss/accurate-interpretable-vad</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00789] Attribute-based Representations for Accurate and Interpretable Video Anomaly Detection](http://arxiv.org/abs/2212.00789) #interpretability</code></li>
<li>Summary: <p>Video anomaly detection (VAD) is a challenging computer vision task with many
practical applications. As anomalies are inherently ambiguous, it is essential
for users to understand the reasoning behind a system's decision in order to
determine if the rationale is sound. In this paper, we propose a simple but
highly effective method that pushes the boundaries of VAD accuracy and
interpretability using attribute-based representations. Our method represents
every object by its velocity and pose. The anomaly scores are computed using a
density-based approach. Surprisingly, we find that this simple representation
is sufficient to achieve state-of-the-art performance in ShanghaiTech, the
largest and most complex VAD dataset. Combining our interpretable
attribute-based representations with implicit, deep representation yields
state-of-the-art performance with a $99.1\%, 93.3\%$, and $85.9\%$ AUROC on
Ped2, Avenue, and ShanghaiTech, respectively. Our method is accurate,
interpretable, and easy to implement.
</p></li>
</ul>

<h3>Title: Research on the application of contrastive learning in multi-label text classification. (arXiv:2212.00552v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00552">http://arxiv.org/abs/2212.00552</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00552] Research on the application of contrastive learning in multi-label text classification](http://arxiv.org/abs/2212.00552) #interpretability</code></li>
<li>Summary: <p>The effective application of contrastive learning technology in natural
language processing tasks shows the superiority of contrastive learning in text
analysis tasks. How to construct positive and negative samples correctly and
reasonably is the core challenge of contrastive learning. Since it is difficult
to construct contrastive objects in multi-label multi-classification tasks,
there are few contrastive losses for multi-label multi-classification text
classification. In this paper, we propose five contrastive losses for
multi-label multi-classification tasks. They are Strict Contrastive Loss (SCL),
Intra-label Contrastive Loss (ICL), Jaccard Similarity Contrastive Loss (JSCL),
and Jaccard Similarity Probability Contrastive Loss (JSPCL) and Stepwise Label
Contrastive Loss (SLCL). We explore the effectiveness of contrastive learning
for multi-label multi-classification tasks under different strategies, and
provide a set of baseline methods for contrastive learning techniques on
multi-label classification tasks. We also perform an interpretability analysis
of our approach to show how different contrastive learning methods play their
roles. The experimental results in this paper demonstrate that our proposed
contrastive losses can bring some improvement for multi-label
multi-classification tasks. Our work reveal how to "appropriately" change the
contrastive way of contrastive learning is the key idea to improve the
adaptability of contrastive learning in multi-label multi-classification tasks.
</p></li>
</ul>

<h3>Title: Knowledge-augmented Deep Learning and Its Applications: A Survey. (arXiv:2212.00017v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00017">http://arxiv.org/abs/2212.00017</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00017] Knowledge-augmented Deep Learning and Its Applications: A Survey](http://arxiv.org/abs/2212.00017) #interpretability</code></li>
<li>Summary: <p>Deep learning models, though having achieved great success in many different
fields over the past years, are usually data hungry, fail to perform well on
unseen samples, and lack of interpretability. Various prior knowledge often
exists in the target domain and their use can alleviate the deficiencies with
deep learning. To better mimic the behavior of human brains, different advanced
methods have been proposed to identify domain knowledge and integrate it into
deep models for data-efficient, generalizable, and interpretable deep learning,
which we refer to as knowledge-augmented deep learning (KADL). In this survey,
we define the concept of KADL, and introduce its three major tasks, i.e.,
knowledge identification, knowledge representation, and knowledge integration.
Different from existing surveys that are focused on a specific type of
knowledge, we provide a broad and complete taxonomy of domain knowledge and its
representations. Based on our taxonomy, we provide a systematic review of
existing techniques, different from existing works that survey integration
approaches agnostic to taxonomy of knowledge. This survey subsumes existing
works and offers a bird's-eye view of research in the general area of
knowledge-augmented deep learning. The thorough and critical reviews of
numerous papers help not only understand current progresses but also identify
future directions for the research on knowledge-augmented deep learning.
</p></li>
</ul>

<h3>Title: Task Discovery: Finding the Tasks that Neural Networks Generalize on. (arXiv:2212.00261v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00261">http://arxiv.org/abs/2212.00261</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00261] Task Discovery: Finding the Tasks that Neural Networks Generalize on](http://arxiv.org/abs/2212.00261) #interpretability</code></li>
<li>Summary: <p>When developing deep learning models, we usually decide what task we want to
solve then search for a model that generalizes well on the task. An intriguing
question would be: what if, instead of fixing the task and searching in the
model space, we fix the model and search in the task space? Can we find tasks
that the model generalizes on? How do they look, or do they indicate anything?
These are the questions we address in this paper.
</p></li>
</ul>

<p>We propose a task discovery framework that automatically finds examples of
such tasks via optimizing a generalization-based quantity called agreement
score. We demonstrate that one set of images can give rise to many tasks on
which neural networks generalize well. These tasks are a reflection of the
inductive biases of the learning framework and the statistical patterns present
in the data, thus they can make a useful tool for analysing the neural networks
and their biases. As an example, we show that the discovered tasks can be used
to automatically create adversarial train-test splits which make a model fail
at test time, without changing the pixels or labels, but by only selecting how
the datapoints should be split between the train and test sets. We end with a
discussion on human-interpretability of the discovered tasks.
</p>

<h2>explainability</h2>
<h3>Title: Task-Specific Embeddings for Ante-Hoc Explainable Text Classification. (arXiv:2212.00086v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00086">http://arxiv.org/abs/2212.00086</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00086] Task-Specific Embeddings for Ante-Hoc Explainable Text Classification](http://arxiv.org/abs/2212.00086) #explainability</code></li>
<li>Summary: <p>Current state-of-the-art approaches to text classification typically leverage
BERT-style Transformer models with a softmax classifier, jointly fine-tuned to
predict class labels of a target task. In this paper, we instead propose an
alternative training objective in which we learn task-specific embeddings of
text: our proposed objective learns embeddings such that all texts that share
the same target class label should be close together in the embedding space,
while all others should be far apart. This allows us to replace the softmax
classifier with a more interpretable k-nearest-neighbor classification
approach. In a series of experiments, we show that this yields a number of
interesting benefits: (1) The resulting order induced by distances in the
embedding space can be used to directly explain classification decisions. (2)
This facilitates qualitative inspection of the training data, helping us to
better understand the problem space and identify labelling quality issues. (3)
The learned distances to some degree generalize to unseen classes, allowing us
to incrementally add new classes without retraining the model. We present
extensive experiments which show that the benefits of ante-hoc explainability
and incremental learning come at no cost in overall classification accuracy,
thus pointing to practical applicability of our proposed approach.
</p></li>
</ul>

<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Shape-Guided Diffusion with Inside-Outside Attention. (arXiv:2212.00210v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00210">http://arxiv.org/abs/2212.00210</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00210] Shape-Guided Diffusion with Inside-Outside Attention](http://arxiv.org/abs/2212.00210) #diffusion</code></li>
<li>Summary: <p>Shape can specify key object constraints, yet existing text-to-image
diffusion models ignore this cue and synthesize objects that are incorrectly
scaled, cut off, or replaced with background content. We propose a
training-free method, Shape-Guided Diffusion, which uses a novel Inside-Outside
Attention mechanism to constrain the cross-attention (and self-attention) maps
such that prompt tokens (and pixels) referring to the inside of the shape
cannot attend outside the shape, and vice versa. To demonstrate the efficacy of
our method, we propose a new image editing task where the model must replace an
object specified by its mask and a text prompt. We curate a new ShapePrompts
benchmark based on MS-COCO and achieve SOTA results in shape faithfulness, text
alignment, and realism according to both quantitative metrics and human
preferences. Our data and code will be made available at
https://shape-guided-diffusion.github.io.
</p></li>
</ul>

<h3>Title: VIDM: Video Implicit Diffusion Models. (arXiv:2212.00235v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00235">http://arxiv.org/abs/2212.00235</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00235] VIDM: Video Implicit Diffusion Models](http://arxiv.org/abs/2212.00235) #diffusion</code></li>
<li>Summary: <p>Diffusion models have emerged as a powerful generative method for
synthesizing high-quality and diverse set of images. In this paper, we propose
a video generation method based on diffusion models, where the effects of
motion are modeled in an implicit condition manner, i.e. one can sample
plausible video motions according to the latent feature of frames. We improve
the quality of the generated videos by proposing multiple strategies such as
sampling space truncation, robustness penalty, and positional group
normalization. Various experiments are conducted on datasets consisting of
videos with different resolutions and different number of frames. Results show
that the proposed method outperforms the state-of-the-art generative
adversarial network-based methods by a significant margin in terms of FVD
scores as well as perceptible visual quality.
</p></li>
</ul>

<h3>Title: Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model. (arXiv:2212.00490v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00490">http://arxiv.org/abs/2212.00490</a></li>
<li>Code URL: <a href="https://github.com/wyhuai/ddnm">https://github.com/wyhuai/ddnm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00490] Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model](http://arxiv.org/abs/2212.00490) #diffusion</code></li>
<li>Summary: <p>Most existing Image Restoration (IR) models are task-specific, which can not
be generalized to different degradation operators. In this work, we propose the
Denoising Diffusion Null-Space Model (DDNM), a novel zero-shot framework for
arbitrary linear IR problems, including but not limited to image
super-resolution, colorization, inpainting, compressed sensing, and deblurring.
DDNM only needs a pre-trained off-the-shelf diffusion model as the generative
prior, without any extra training or network modifications. By refining only
the null-space contents during the reverse diffusion process, we can yield
diverse results satisfying both data consistency and realness. We further
propose an enhanced and robust version, dubbed DDNM+, to support noisy
restoration and improve restoration quality for hard tasks. Our experiments on
several IR tasks reveal that DDNM outperforms other state-of-the-art zero-shot
IR methods. We also demonstrate that DDNM+ can solve complex real-world
applications, e.g., old photo restoration.
</p></li>
</ul>

<h3>Title: Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation. (arXiv:2212.00774v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00774">http://arxiv.org/abs/2212.00774</a></li>
<li>Code URL: <a href="https://github.com/pals-ttic/sjc">https://github.com/pals-ttic/sjc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00774] Score Jacobian Chaining: Lifting Pretrained 2D Diffusion Models for 3D Generation](http://arxiv.org/abs/2212.00774) #diffusion</code></li>
<li>Summary: <p>A diffusion model learns to predict a vector field of gradients. We propose
to apply chain rule on the learned gradients, and back-propagate the score of a
diffusion model through the Jacobian of a differentiable renderer, which we
instantiate to be a voxel radiance field. This setup aggregates 2D scores at
multiple camera viewpoints into a 3D score, and repurposes a pretrained 2D
model for 3D data generation. We identify a technical challenge of distribution
mismatch that arises in this application, and propose a novel estimation
mechanism to resolve it. We run our algorithm on several off-the-shelf
diffusion image generative models, including the recently released Stable
Diffusion trained on the large-scale LAION dataset.
</p></li>
</ul>

<h3>Title: Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion. (arXiv:2212.00787v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00787">http://arxiv.org/abs/2212.00787</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00787] Multi-Class Segmentation from Aerial Views using Recursive Noise Diffusion](http://arxiv.org/abs/2212.00787) #diffusion</code></li>
<li>Summary: <p>Semantic segmentation from aerial views is a vital task for autonomous drones
as they require precise and accurate segmentation to traverse safely and
efficiently. Segmenting images from aerial views is especially challenging as
they include diverse view-points, extreme scale variation and high scene
complexity. To address this problem, we propose an end-to-end multi-class
semantic segmentation diffusion model. We introduce recursive denoising which
allows predicted error to propagate through the denoising process. In addition,
we combine this with a hierarchical multi-scale approach, complementary to the
diffusion process. Our method achieves state-of-the-art results on UAVid and on
the Vaihingen building segmentation benchmark.
</p></li>
</ul>

<h3>Title: SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction. (arXiv:2212.00792v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00792">http://arxiv.org/abs/2212.00792</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00792] SparseFusion: Distilling View-conditioned Diffusion for 3D Reconstruction](http://arxiv.org/abs/2212.00792) #diffusion</code></li>
<li>Summary: <p>We propose SparseFusion, a sparse view 3D reconstruction approach that
unifies recent advances in neural rendering and probabilistic image generation.
Existing approaches typically build on neural rendering with re-projected
features but fail to generate unseen regions or handle uncertainty under large
viewpoint changes. Alternate methods treat this as a (probabilistic) 2D
synthesis task, and while they can generate plausible 2D images, they do not
infer a consistent underlying 3D. However, we find that this trade-off between
3D consistency and probabilistic image generation does not need to exist. In
fact, we show that geometric consistency and generative inference can be
complementary in a mode-seeking behavior. By distilling a 3D consistent scene
representation from a view-conditioned latent diffusion model, we are able to
recover a plausible 3D representation whose renderings are both accurate and
realistic. We evaluate our approach across 51 categories in the CO3D dataset
and show that it outperforms existing methods, in both distortion and
perception metrics, for sparse-view novel view synthesis.
</p></li>
</ul>

<h3>Title: Unite and Conquer: Cross Dataset Multimodal Synthesis using Diffusion Models. (arXiv:2212.00793v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00793">http://arxiv.org/abs/2212.00793</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00793] Unite and Conquer: Cross Dataset Multimodal Synthesis using Diffusion Models](http://arxiv.org/abs/2212.00793) #diffusion</code></li>
<li>Summary: <p>Generating photos satisfying multiple constraints find broad utility in the
content creation industry. A key hurdle to accomplishing this task is the need
for paired data consisting of all modalities (i.e., constraints) and their
corresponding output. Moreover, existing methods need retraining using paired
data across all modalities to introduce a new condition. This paper proposes a
solution to this problem based on denoising diffusion probabilistic models
(DDPMs). Our motivation for choosing diffusion models over other generative
models comes from the flexible internal structure of diffusion models. Since
each sampling step in the DDPM follows a Gaussian distribution, we show that
there exists a closed-form solution for generating an image given various
constraints. Our method can unite multiple diffusion models trained on multiple
sub-tasks and conquer the combined task through our proposed sampling strategy.
We also introduce a novel reliability parameter that allows using different
off-the-shelf diffusion models trained across various datasets during sampling
time alone to guide it to the desired outcome satisfying multiple constraints.
We perform experiments on various standard multimodal tasks to demonstrate the
effectiveness of our approach. More details can be found in
https://nithin-gk.github.io/projectpages/Multidiff/index.html
</p></li>
</ul>

<h3>Title: Why Are Conditional Generative Models Better Than Unconditional Ones?. (arXiv:2212.00362v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2212.00362">http://arxiv.org/abs/2212.00362</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2212.00362] Why Are Conditional Generative Models Better Than Unconditional Ones?](http://arxiv.org/abs/2212.00362) #diffusion</code></li>
<li>Summary: <p>Extensive empirical evidence demonstrates that conditional generative models
are easier to train and perform better than unconditional ones by exploiting
the labels of data. So do score-based diffusion models. In this paper, we
analyze the phenomenon formally and identify that the key of conditional
learning is to partition the data properly. Inspired by the analyses, we
propose self-conditioned diffusion models (SCDM), which is trained conditioned
on indices clustered by the k-means algorithm on the features extracted by a
model pre-trained in a self-supervised manner. SCDM significantly improves the
unconditional model across various datasets and achieves a record-breaking FID
of 3.94 on ImageNet 64x64 without labels. Besides, SCDM achieves a slightly
better FID than the corresponding conditional model on CIFAR10.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
