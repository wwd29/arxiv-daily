<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-03-07</h1>
<h3>Title: Knowledge-guided EEG Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Aditya Kommineni, Kleanthis Avramidis, Richard Leahy, Shrikanth Narayanan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03222">https://arxiv.org/abs/2403.03222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03222">https://arxiv.org/pdf/2403.03222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03222]] Knowledge-guided EEG Representation Learning(https://arxiv.org/abs/2403.03222)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Self-supervised learning has produced impressive results in multimedia domains of audio, vision and speech. This paradigm is equally, if not more, relevant for the domain of biosignals, owing to the scarcity of labelled data in such scenarios. The ability to leverage large-scale unlabelled data to learn robust representations could help improve the performance of numerous inference tasks on biosignals. Given the inherent domain differences between multimedia modalities and biosignals, the established objectives for self-supervised learning may not translate well to this domain. Hence, there is an unmet need to adapt these methods to biosignal analysis. In this work we propose a self-supervised model for EEG, which provides robust performance and remarkable parameter efficiency by using state space-based deep learning architecture. We also propose a novel knowledge-guided pre-training objective that accounts for the idiosyncrasies of the EEG signal. The results indicate improved embedding representation learning and downstream performance compared to prior works on exemplary tasks. Also, the proposed objective significantly reduces the amount of pre-training data required to obtain performance equivalent to prior works.</li>
</ul>

<h3>Title: Towards an AI-Enhanced Cyber Threat Intelligence Processing Pipeline</h3>
<ul>
<li><strong>Authors: </strong>Lampis Alevizos, Martijn Dekker</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03265">https://arxiv.org/abs/2403.03265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03265">https://arxiv.org/pdf/2403.03265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03265]] Towards an AI-Enhanced Cyber Threat Intelligence Processing Pipeline(https://arxiv.org/abs/2403.03265)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, interpretability</a></li>
<li><strong>Abstract: </strong>Cyber threats continue to evolve in complexity, thereby traditional Cyber Threat Intelligence (CTI) methods struggle to keep pace. AI offers a potential solution, automating and enhancing various tasks, from data ingestion to resilience verification. This paper explores the potential of integrating Artificial Intelligence (AI) into CTI. We provide a blueprint of an AI-enhanced CTI processing pipeline, and detail its components and functionalities. The pipeline highlights the collaboration of AI and human expertise, which is necessary to produce timely and high-fidelity cyber threat intelligence. We also explore the automated generation of mitigation recommendations, harnessing AI's capabilities to provide real-time, contextual, and predictive insights. However, the integration of AI into CTI is not without challenges. Thereby, we discuss ethical dilemmas, potential biases, and the imperative for transparency in AI-driven decisions. We address the need for data privacy, consent mechanisms, and the potential misuse of technology. Moreover, we highlights the importance of addressing biases both during CTI analysis and AI models warranting their transparency and interpretability. Lastly, our work points out future research directions such as the exploration of advanced AI models to augment cyber defences, and the human-AI collaboration optimization. Ultimately, the fusion of AI with CTI appears to hold significant potential in cybersecurity domain.</li>
</ul>

<h3>Title: TTPXHunter: Actionable Threat Intelligence Extraction as TTPs form  Finished Cyber Threat Reports</h3>
<ul>
<li><strong>Authors: </strong>Nanda Rani, Bikash Saha, Vikas Maurya, Sandeep Kumar Shukla</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03267">https://arxiv.org/abs/2403.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03267">https://arxiv.org/pdf/2403.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03267]] TTPXHunter: Actionable Threat Intelligence Extraction as TTPs form  Finished Cyber Threat Reports(https://arxiv.org/abs/2403.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction</a></li>
<li><strong>Abstract: </strong>Understanding the modus operandi of adversaries aids organizations in employing efficient defensive strategies and sharing intelligence in the community. This knowledge is often present in unstructured natural language text within threat analysis reports. A translation tool is needed to interpret the modus operandi explained in the sentences of the threat report and translate it into a structured format. This research introduces a methodology named TTPXHunter for the automated extraction of threat intelligence in terms of Tactics, Techniques, and Procedures (TTPs) from finished cyber threat reports. It leverages cyber domain-specific state-of-the-art natural language processing (NLP) to augment sentences for minority class TTPs and refine pinpointing the TTPs in threat analysis reports significantly. The knowledge of threat intelligence in terms of TTPs is essential for comprehensively understanding cyber threats and enhancing detection and mitigation strategies. We create two datasets: an augmented sentence-TTP dataset of 39,296 samples and a 149 real-world cyber threat intelligence report-to-TTP dataset. Further, we evaluate TTPXHunter on the augmented sentence dataset and the cyber threat reports. The TTPXHunter achieves the highest performance of 92.42% f1-score on the augmented dataset, and it also outperforms existing state-of-the-art solutions in TTP extraction by achieving an f1-score of 97.09% when evaluated over the report dataset. TTPXHunter significantly improves cybersecurity threat intelligence by offering quick, actionable insights into attacker behaviors. This advancement automates threat intelligence analysis, providing a crucial tool for cybersecurity professionals fighting cyber threats.</li>
</ul>

<h3>Title: DINOv2 based Self Supervised Learning For Few Shot Medical Image  Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lev Ayzenberg, Raja Giryes, Hayit Greenspan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03273">https://arxiv.org/abs/2403.03273</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03273">https://arxiv.org/pdf/2403.03273</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03273]] DINOv2 based Self Supervised Learning For Few Shot Medical Image  Segmentation(https://arxiv.org/abs/2403.03273)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Deep learning models have emerged as the cornerstone of medical image segmentation, but their efficacy hinges on the availability of extensive manually labeled datasets and their adaptability to unforeseen categories remains a challenge. Few-shot segmentation (FSS) offers a promising solution by endowing models with the capacity to learn novel classes from limited labeled examples. A leading method for FSS is ALPNet, which compares features between the query image and the few available support segmented images. A key question about using ALPNet is how to design its features. In this work, we delve into the potential of using features from DINOv2, which is a foundational self-supervised learning model in computer vision. Leveraging the strengths of ALPNet and harnessing the feature extraction capabilities of DINOv2, we present a novel approach to few-shot segmentation that not only enhances performance but also paves the way for more robust and adaptable medical image analysis.</li>
</ul>

<h3>Title: CenterDisks: Real-time instance segmentation with disk covering</h3>
<ul>
<li><strong>Authors: </strong>Katia Jodogne-Del Litto, Guillaume-Alexandre Bilodeau</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03296">https://arxiv.org/abs/2403.03296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03296">https://arxiv.org/pdf/2403.03296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03296]] CenterDisks: Real-time instance segmentation with disk covering(https://arxiv.org/abs/2403.03296)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Increasing the accuracy of instance segmentation methods is often done at the expense of speed. Using coarser representations, we can reduce the number of parameters and thus obtain real-time masks. In this paper, we take inspiration from the set cover problem to predict mask approximations. Given ground-truth binary masks of objects of interest as training input, our method learns to predict the approximate coverage of these objects by disks without supervision on their location or radius. Each object is represented by a fixed number of disks with different radii. In the learning phase, we consider the radius as proportional to a standard deviation in order to compute the error to propagate on a set of two-dimensional Gaussian functions rather than disks. We trained and tested our instance segmentation method on challenging datasets showing dense urban settings with various road users. Our method achieve state-of-the art results on the IDD and KITTI dataset with an inference time of 0.040 s on a single RTX 3090 GPU.</li>
</ul>

<h3>Title: Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event  Argument Data</h3>
<ul>
<li><strong>Authors: </strong>Joseph Gatto, Parker Seegmiller, Omar Sharif, Sarah M. Preum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03304">https://arxiv.org/abs/2403.03304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03304">https://arxiv.org/pdf/2403.03304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03304]] Mad Libs Are All You Need: Augmenting Cross-Domain Document-Level Event  Argument Data(https://arxiv.org/abs/2403.03304)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Document-Level Event Argument Extraction (DocEAE) is an extremely difficult information extraction problem -- with significant limitations in low-resource cross-domain settings. To address this problem, we introduce Mad Lib Aug (MLA), a novel generative DocEAE data augmentation framework. Our approach leverages the intuition that Mad Libs, which are categorically masked documents used as a part of a popular game, can be generated and solved by LLMs to produce data for DocEAE. Using MLA, we achieve a 2.6-point average improvement in overall F1 score. Moreover, this approach achieves a 3.9 and 5.2 point average increase in zero and few-shot event roles compared to augmentation-free baselines across all experiments. To better facilitate analysis of cross-domain DocEAE, we additionally introduce a new metric, Role-Depth F1 (RDF1), which uses statistical depth to identify roles in the target domain which are semantic outliers with respect to roles observed in the source domain. Our experiments show that MLA augmentation can boost RDF1 performance by an average of 5.85 points compared to non-augmented datasets.</li>
</ul>

<h3>Title: Book2Dial: Generating Teacher-Student Interactions from Textbooks for  Cost-Effective Development of Educational Chatbots</h3>
<ul>
<li><strong>Authors: </strong>Junling Wang, Jakub Macina, Nico Daheim, Sankalan Pal Chowdhury, Mrinmaya Sachan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03307">https://arxiv.org/abs/2403.03307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03307">https://arxiv.org/pdf/2403.03307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03307]] Book2Dial: Generating Teacher-Student Interactions from Textbooks for  Cost-Effective Development of Educational Chatbots(https://arxiv.org/abs/2403.03307)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Educational chatbots are a promising tool for assisting student learning. However, the development of effective chatbots in education has been challenging, as high-quality data is seldom available in this domain. In this paper, we propose a framework for generating synthetic teacher-student interactions grounded in a set of textbooks. Our approaches capture one aspect of learning interactions where curious students with partial knowledge interactively ask a teacher questions about the material in the textbook. We highlight various quality criteria that such dialogues should fulfill and compare several approaches relying on either prompting or fine-tuning large language models. We use synthetic dialogues to train educational chatbots and show benefits of further fine-tuning in different educational domains. However, human evaluation shows that our best data synthesis method still suffers from hallucinations and tends to reiterate information from previous conversations. Our findings offer insights for future efforts in synthesizing conversational data that strikes a balance between size and quality. We will open-source our data and code.</li>
</ul>

<h3>Title: Learning Zero-Shot Material States Segmentation, by Implanting Natural  Image Patterns in Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Sagi Eppel, Jolina Li, Manuel Drehwald, Alan Aspuru-Guzik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03309">https://arxiv.org/abs/2403.03309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03309">https://arxiv.org/pdf/2403.03309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03309]] Learning Zero-Shot Material States Segmentation, by Implanting Natural  Image Patterns in Synthetic Data(https://arxiv.org/abs/2403.03309)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Visual understanding and segmentation of materials and their states is fundamental for understanding the physical world. The infinite textures, shapes and often blurry boundaries formed by material make this task particularly hard to generalize. Whether it's identifying wet regions of a surface, minerals in rocks, infected regions in plants, or pollution in water, each material state has its own unique form. For neural nets to learn class-agnostic materials segmentation it is necessary to first collect and annotate data that capture this complexity. Collecting real-world images and manually annotating is limited both by the cost and limited precision of manual labor. In contrast, synthetic data is highly accurate and almost cost-free but fails to replicate the vast diversity of the material world. In this work, we suggest a method to bridge this crucial gap, by implanting patterns extracted from real-world images, in synthetic data. Hence, patterns automatically collected from natural images are used to map materials into synthetic scenes. This unsupervised approach allows the generated data to capture the vast complexity of the real world while maintaining the precision and scale of synthetic data. We also present the first general benchmark for class-agnostic material state segmentation. The benchmark images contain a wide range of real-world images of material states, from cooking, food, rocks, construction, plants, and liquids each in various states (wet/dry/stained/cooked/burned/worned/rusted/sediment/foam...). The annotation includes both partial similarity between regions with similar but not identical materials, and hard segmentation of only points of the exact same material state. We show that net trains on MatSeg significantly outperform existing state-of-the-art methods on this task.</li>
</ul>

<h3>Title: An Ensemble Framework for Explainable Geospatial Machine Learning Models</h3>
<ul>
<li><strong>Authors: </strong>Lingbo Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03328">https://arxiv.org/abs/2403.03328</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03328">https://arxiv.org/pdf/2403.03328</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03328]] An Ensemble Framework for Explainable Geospatial Machine Learning Models(https://arxiv.org/abs/2403.03328)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Analyzing spatial varying effect is pivotal in geographic analysis. Yet, accurately capturing and interpreting this variability is challenging due to the complexity and non-linearity of geospatial data. Herein, we introduce an integrated framework that merges local spatial weighting scheme, Explainable Artificial Intelligence (XAI), and cutting-edge machine learning technologies to bridge the gap between traditional geographic analysis models and general machine learning approaches. Through tests on synthetic datasets, this framework is verified to enhance the interpretability and accuracy of predictions in both geographic regression and classification by elucidating spatial variability. It significantly boosts prediction precision, offering a novel approach to understanding spatial phenomena.</li>
</ul>

<h3>Title: Guardrail Baselines for Unlearning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Pratiksha Thaker, Yash Maurya, Virginia Smith</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03329">https://arxiv.org/abs/2403.03329</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03329">https://arxiv.org/pdf/2403.03329</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03329]] Guardrail Baselines for Unlearning in LLMs(https://arxiv.org/abs/2403.03329)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent work has demonstrated that fine-tuning is a promising approach to `unlearn' concepts from large language models. However, fine-tuning can be expensive, as it requires both generating a set of examples and running iterations of fine-tuning to update the model. In this work, we show that simple guardrail-based approaches such as prompting and filtering can achieve unlearning results comparable to fine-tuning. We recommend that researchers investigate these lightweight baselines when evaluating the performance of more computationally intensive fine-tuning methods. While we do not claim that methods such as prompting or filtering are universal solutions to the problem of unlearning, our work suggests the need for evaluation metrics that can better separate the power of guardrails vs. fine-tuning, and highlights scenarios where guardrails themselves may be advantageous for unlearning, such as in generating examples for fine-tuning or unlearning when only API access is available.</li>
</ul>

<h3>Title: Solution Simplex Clustering for Heterogeneous Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Dennis Grinwald, Philipp Wiesner, Shinichi Nakajima</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03333">https://arxiv.org/abs/2403.03333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03333">https://arxiv.org/pdf/2403.03333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03333]] Solution Simplex Clustering for Heterogeneous Federated Learning(https://arxiv.org/abs/2403.03333)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We tackle a major challenge in federated learning (FL) -- achieving good performance under highly heterogeneous client distributions. The difficulty partially arises from two seemingly contradictory goals: learning a common model by aggregating the information from clients, and learning local personalized models that should be adapted to each local distribution. In this work, we propose Solution Simplex Clustered Federated Learning (SosicFL) for dissolving such contradiction. Based on the recent ideas of learning solution simplices, SosicFL assigns a subregion in a simplex to each client, and performs FL to learn a common solution simplex. This allows the client models to possess their characteristics within the degrees of freedom in the solution simplex, and at the same time achieves the goal of learning a global common model. Our experiments show that SosicFL improves the performance and accelerates the training process for global and personalized FL with minimal computational overhead.</li>
</ul>

<h3>Title: DIVERSE: Deciphering Internet Views on the U.S. Military Through Video  Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification</h3>
<ul>
<li><strong>Authors: </strong>Iain J. Cruickshank, Lynnette Hui Xian Ng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03334">https://arxiv.org/abs/2403.03334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03334">https://arxiv.org/pdf/2403.03334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03334]] DIVERSE: Deciphering Internet Views on the U.S. Military Through Video  Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification(https://arxiv.org/abs/2403.03334)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stance detection of social media text is a key component of downstream tasks involving the identification of groups of users with opposing opinions on contested topics such as vaccination and within arguments. In particular, stance provides an indication of an opinion towards an entity. This paper introduces DIVERSE, a dataset of over 173,000 YouTube video comments annotated for their stance towards videos of the U.S. military. The stance is annotated through a human-guided, machine-assisted labeling methodology that makes use of weak signals of tone within the sentence as supporting indicators, as opposed to using manual annotations by humans. These weak signals consist of the presence of hate speech and sarcasm, the presence of specific keywords, the sentiment of the text, and the stance inference from two Large Language Models. The weak signals are then consolidated using a data programming model before each comment is annotated with a final stance label. On average, the videos have 200 comments each, and the stance of the comments skews slightly towards the "against" characterization for both the U.S. Army and the videos posted on the channel.</li>
</ul>

<h3>Title: Scope of Large Language Models for Mining Emerging Opinions in Online  Health Discourse</h3>
<ul>
<li><strong>Authors: </strong>Joseph Gatto, Madhusudan Basak, Yash Srivastava, Philip Bohlman, Sarah M. Preum</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03336">https://arxiv.org/abs/2403.03336</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03336">https://arxiv.org/pdf/2403.03336</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03336]] Scope of Large Language Models for Mining Emerging Opinions in Online  Health Discourse(https://arxiv.org/abs/2403.03336)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we develop an LLM-powered framework for the curation and evaluation of emerging opinion mining in online health communities. We formulate emerging opinion mining as a pairwise stance detection problem between (title, comment) pairs sourced from Reddit, where post titles contain emerging health-related claims on a topic that is not predefined. The claims are either explicitly or implicitly expressed by the user. We detail (i) a method of claim identification -- the task of identifying if a post title contains a claim and (ii) an opinion mining-driven evaluation framework for stance detection using LLMs. We facilitate our exploration by releasing a novel test dataset, Long COVID-Stance, or LC-stance, which can be used to evaluate LLMs on the tasks of claim identification and stance detection in online health communities. Long Covid is an emerging post-COVID disorder with uncertain and complex treatment guidelines, thus making it a suitable use case for our task. LC-Stance contains long COVID treatment related discourse sourced from a Reddit community. Our evaluation shows that GPT-4 significantly outperforms prior works on zero-shot stance detection. We then perform thorough LLM model diagnostics, identifying the role of claim type (i.e. implicit vs explicit claims) and comment length as sources of model error.</li>
</ul>

<h3>Title: Bridge the Future: High-Performance Networks in Confidential VMs without  Trusted I/O devices</h3>
<ul>
<li><strong>Authors: </strong>Mengyuan Li, Shashvat Srivastava, Mengjia Yan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03360">https://arxiv.org/abs/2403.03360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03360">https://arxiv.org/pdf/2403.03360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03360]] Bridge the Future: High-Performance Networks in Confidential VMs without  Trusted I/O devices(https://arxiv.org/abs/2403.03360)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Trusted I/O (TIO) is an appealing solution to improve I/O performance for confidential VMs (CVMs), with the potential to eliminate broad sources of I/O overhead. However, this paper emphasizes that not all types of I/O can derive substantial benefits from TIO, particularly network I/O. Given the obligatory use of encryption protocols for network traffic in CVM's threat model, TIO's approach of I/O encryption over the PCIe bus becomes redundant. Furthermore, TIO solutions need to expand the Trusted Computing Base (TCB) to include TIO devices and are commercially unavailable. Motivated by these insights, the goal of this paper is to propose a software solution that helps CVMs immediately benefit from high-performance networks, while confining trust only to the on-chip CVM. We present FOLIO, a software solution crafted from a secure and efficient Data Plane Development Kit (DPDK) extension compatible with the latest version of AMD Secure Encrypted Virtualization (SEV), a.k.a., Secure Nested Paging (SNP). Our design is informed by a thorough analysis of all possible factors that impact SNP VM's network performance. By extensively removing overhead sources, we arrive at a design that approaches the efficiency of an optimal TIO-based configuration. Evaluation shows that FOLIO has a performance dip less than 6% relative to the optimal TIO configuration, while only relying on off-the-shelf CPUs.</li>
</ul>

<h3>Title: Leveraging Federated Learning for Automatic Detection of Clopidogrel  Treatment Failures</h3>
<ul>
<li><strong>Authors: </strong>Samuel Kim, Min Sang Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03368">https://arxiv.org/abs/2403.03368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03368">https://arxiv.org/pdf/2403.03368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03368]] Leveraging Federated Learning for Automatic Detection of Clopidogrel  Treatment Failures(https://arxiv.org/abs/2403.03368)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate</a></li>
<li><strong>Abstract: </strong>The effectiveness of clopidogrel, a widely used antiplatelet medication, varies significantly among individuals, necessitating the development of precise predictive models to optimize patient care. In this study, we leverage federated learning strategies to address clopidogrel treatment failure detection. Our research harnesses the collaborative power of multiple healthcare institutions, allowing them to jointly train machine learning models while safeguarding sensitive patient data. Utilizing the UK Biobank dataset, which encompasses a vast and diverse population, we partitioned the data based on geographic centers and evaluated the performance of federated learning. Our results show that while centralized training achieves higher Area Under the Curve (AUC) values and faster convergence, federated learning approaches can substantially narrow this performance gap. Our findings underscore the potential of federated learning in addressing clopidogrel treatment failure detection, offering a promising avenue for enhancing patient care through personalized treatment strategies while respecting data privacy. This study contributes to the growing body of research on federated learning in healthcare and lays the groundwork for secure and privacy-preserving predictive models for various medical conditions.</li>
</ul>

<h3>Title: F$^3$Loc: Fusion and Filtering for Floorplan Localization</h3>
<ul>
<li><strong>Authors: </strong>Changan Chen, Rui Wang, Christoph Vogel, Marc Pollefeys</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03370">https://arxiv.org/abs/2403.03370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03370">https://arxiv.org/pdf/2403.03370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03370]] F$^3$Loc: Fusion and Filtering for Floorplan Localization(https://arxiv.org/abs/2403.03370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper we propose an efficient data-driven solution to self-localization within a floorplan. Floorplan data is readily available, long-term persistent and inherently robust to changes in the visual appearance. Our method does not require retraining per map and location or demand a large database of images of the area of interest. We propose a novel probabilistic model consisting of an observation and a novel temporal filtering module. Operating internally with an efficient ray-based representation, the observation module consists of a single and a multiview module to predict horizontal depth from images and fuses their results to benefit from advantages offered by either methodology. Our method operates on conventional consumer hardware and overcomes a common limitation of competing methods that often demand upright images. Our full system meets real-time requirements, while outperforming the state-of-the-art by a significant margin.</li>
</ul>

<h3>Title: Japanese-English Sentence Translation Exercises Dataset for Automatic  Grading</h3>
<ul>
<li><strong>Authors: </strong>Naoki Miura, Hiroaki Funayama, Seiya Kikuchi, Yuichiroh Matsubayashi, Yuya Iwase, Kentaro Inui</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03396">https://arxiv.org/abs/2403.03396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03396">https://arxiv.org/pdf/2403.03396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03396]] Japanese-English Sentence Translation Exercises Dataset for Automatic  Grading(https://arxiv.org/abs/2403.03396)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper proposes the task of automatic assessment of Sentence Translation Exercises (STEs), that have been used in the early stage of L2 language learning. We formalize the task as grading student responses for each rubric criterion pre-specified by the educators. We then create a dataset for STE between Japanese and English including 21 questions, along with a total of 3, 498 student responses (167 on average). The answer responses were collected from students and crowd workers. Using this dataset, we demonstrate the performance of baselines including finetuned BERT and GPT models with few-shot in-context learning. Experimental results show that the baseline model with finetuned BERT was able to classify correct responses with approximately 90% in F1, but only less than 80% for incorrect responses. Furthermore, the GPT models with few-shot learning show poorer results than finetuned BERT, indicating that our newly proposed task presents a challenging issue, even for the stateof-the-art large language models.</li>
</ul>

<h3>Title: Causality-based Cross-Modal Representation Learning for  Vision-and-Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Liuyi Wang, Zongtao He, Ronghao Dang, Huiyi Chen, Chengju Liu, Qijun Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03405">https://arxiv.org/abs/2403.03405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03405">https://arxiv.org/pdf/2403.03405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03405]] Causality-based Cross-Modal Representation Learning for  Vision-and-Language Navigation(https://arxiv.org/abs/2403.03405)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-and-Language Navigation (VLN) has gained significant research interest in recent years due to its potential applications in real-world scenarios. However, existing VLN methods struggle with the issue of spurious associations, resulting in poor generalization with a significant performance gap between seen and unseen environments. In this paper, we tackle this challenge by proposing a unified framework CausalVLN based on the causal learning paradigm to train a robust navigator capable of learning unbiased feature representations. Specifically, we establish reasonable assumptions about confounders for vision and language in VLN using the structured causal model (SCM). Building upon this, we propose an iterative backdoor-based representation learning (IBRL) method that allows for the adaptive and effective intervention on confounders. Furthermore, we introduce the visual and linguistic backdoor causal encoders to enable unbiased feature expression for multi-modalities during training and validation, enhancing the agent's capability to generalize across different environments. Experiments on three VLN datasets (R2R, RxR, and REVERIE) showcase the superiority of our proposed method over previous state-of-the-art approaches. Moreover, detailed visualization analysis demonstrates the effectiveness of CausalVLN in significantly narrowing down the performance gap between seen and unseen environments, underscoring its strong generalization capability.</li>
</ul>

<h3>Title: Advancing Out-of-Distribution Detection through Data Purification and  Dynamic Activation Function Design</h3>
<ul>
<li><strong>Authors: </strong>Yingrui Ji, Yao Zhu, Zhigang Li, Jiansheng Chen, Yunlong Kong, Jingbo Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03412">https://arxiv.org/abs/2403.03412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03412">https://arxiv.org/pdf/2403.03412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03412]] Advancing Out-of-Distribution Detection through Data Purification and  Dynamic Activation Function Design(https://arxiv.org/abs/2403.03412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>In the dynamic realms of machine learning and deep learning, the robustness and reliability of models are paramount, especially in critical real-world applications. A fundamental challenge in this sphere is managing Out-of-Distribution (OOD) samples, significantly increasing the risks of model misclassification and uncertainty. Our work addresses this challenge by enhancing the detection and management of OOD samples in neural networks. We introduce OOD-R (Out-of-Distribution-Rectified), a meticulously curated collection of open-source datasets with enhanced noise reduction properties. In-Distribution (ID) noise in existing OOD datasets can lead to inaccurate evaluation of detection algorithms. Recognizing this, OOD-R incorporates noise filtering technologies to refine the datasets, ensuring a more accurate and reliable evaluation of OOD detection algorithms. This approach not only improves the overall quality of data but also aids in better distinguishing between OOD and ID samples, resulting in up to a 2.5\% improvement in model accuracy and a minimum 3.2\% reduction in false positives. Furthermore, we present ActFun, an innovative method that fine-tunes the model's response to diverse inputs, thereby improving the stability of feature extraction and minimizing specificity issues. ActFun addresses the common problem of model overconfidence in OOD detection by strategically reducing the influence of hidden units, which enhances the model's capability to estimate OOD uncertainty more accurately. Implementing ActFun in the OOD-R dataset has led to significant performance enhancements, including an 18.42\% increase in AUROC of the GradNorm method and a 16.93\% decrease in FPR95 of the Energy method. Overall, our research not only advances the methodologies in OOD detection but also emphasizes the importance of dataset integrity for accurate algorithm evaluation.</li>
</ul>

<h3>Title: Negating Negatives: Alignment without Human Positive Samples via  Distributional Dispreference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Shitong Duan, Xiaoyuan Yi, Peng Zhang, Tun Lu, Xing Xie, Ning Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03419">https://arxiv.org/abs/2403.03419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03419">https://arxiv.org/pdf/2403.03419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03419]] Negating Negatives: Alignment without Human Positive Samples via  Distributional Dispreference Optimization(https://arxiv.org/abs/2403.03419)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have revolutionized the role of AI, yet also pose potential risks of propagating unethical content. Alignment technologies have been introduced to steer LLMs towards human preference, gaining increasing attention. Despite notable breakthroughs in this direction, existing methods heavily rely on high-quality positive-negative training pairs, suffering from noisy labels and the marginal distinction between preferred and dispreferred response data. Given recent LLMs' proficiency in generating helpful responses, this work pivots towards a new research focus: achieving alignment using solely human-annotated negative samples, preserving helpfulness while reducing harmfulness. For this purpose, we propose Distributional Dispreference Optimization (D$^2$O), which maximizes the discrepancy between the generated responses and the dispreferred ones to effectively eschew harmful information. We theoretically demonstrate that D$^2$O is equivalent to learning a distributional instead of instance-level preference model reflecting human dispreference against the distribution of negative responses. Besides, D$^2$O integrates an implicit Jeffrey Divergence regularization to balance the exploitation and exploration of reference policies and converges to a non-negative one during training. Extensive experiments demonstrate that our method achieves comparable generation quality and surpasses the latest baselines in producing less harmful and more informative responses with better training stability and faster convergence.</li>
</ul>

<h3>Title: LEAD: Learning Decomposition for Source-free Universal Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Sanqing Qu, Tianpei Zou, Lianghua He, Florian Röhrbein, Alois Knoll, Guang Chen, Changjun Jiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03421">https://arxiv.org/abs/2403.03421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03421">https://arxiv.org/pdf/2403.03421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03421]] LEAD: Learning Decomposition for Source-free Universal Domain Adaptation(https://arxiv.org/abs/2403.03421)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Universal Domain Adaptation (UniDA) targets knowledge transfer in the presence of both covariate and label shifts. Recently, Source-free Universal Domain Adaptation (SF-UniDA) has emerged to achieve UniDA without access to source data, which tends to be more practical due to data protection policies. The main challenge lies in determining whether covariate-shifted samples belong to target-private unknown categories. Existing methods tackle this either through hand-crafted thresholding or by developing time-consuming iterative clustering strategies. In this paper, we propose a new idea of LEArning Decomposition (LEAD), which decouples features into source-known and -unknown components to identify target-private data. Technically, LEAD initially leverages the orthogonal decomposition analysis for feature decomposition. Then, LEAD builds instance-level decision boundaries to adaptively identify target-private data. Extensive experiments across various UniDA scenarios have demonstrated the effectiveness and superiority of LEAD. Notably, in the OPDA scenario on VisDA dataset, LEAD outperforms GLC by 3.5% overall H-score and reduces 75% time to derive pseudo-labeling decision boundaries. Besides, LEAD is also appealing in that it is complementary to most existing methods. The code is available at https://github.com/ispc-lab/LEAD.</li>
</ul>

<h3>Title: Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for  Text-Oriented Molecular Optimization</h3>
<ul>
<li><strong>Authors: </strong>Kaiwei Zhang, Yange Lin, Guangcheng Wu, Yuxiang Ren, Xuecang Zhang, Bo wang, Xiaoyu Zhang, Weitao Du</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03425">https://arxiv.org/abs/2403.03425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03425">https://arxiv.org/pdf/2403.03425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03425]] Sculpting Molecules in 3D: A Flexible Substructure Aware Framework for  Text-Oriented Molecular Optimization(https://arxiv.org/abs/2403.03425)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The integration of deep learning, particularly AI-Generated Content, with high-quality data derived from ab initio calculations has emerged as a promising avenue for transforming the landscape of scientific research. However, the challenge of designing molecular drugs or materials that incorporate multi-modality prior knowledge remains a critical and complex undertaking. Specifically, achieving a practical molecular design necessitates not only meeting the diversity requirements but also addressing structural and textural constraints with various symmetries outlined by domain experts. In this article, we present an innovative approach to tackle this inverse design problem by formulating it as a multi-modality guidance generation/optimization task. Our proposed solution involves a textural-structure alignment symmetric diffusion framework for the implementation of molecular generation/optimization tasks, namely 3DToMolo. 3DToMolo aims to harmonize diverse modalities, aligning them seamlessly to produce molecular structures adhere to specified symmetric structural and textural constraints by experts in the field. Experimental trials across three guidance generation settings have shown a superior hit generation performance compared to state-of-the-art methodologies. Moreover, 3DToMolo demonstrates the capability to generate novel molecules, incorporating specified target substructures, without the need for prior knowledge. This work not only holds general significance for the advancement of deep learning methodologies but also paves the way for a transformative shift in molecular design strategies. 3DToMolo creates opportunities for a more nuanced and effective exploration of the vast chemical space, opening new frontiers in the development of molecular entities with tailored properties and functionalities.</li>
</ul>

<h3>Title: Towards Understanding Cross and Self-Attention in Stable Diffusion for  Text-Guided Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Bingyan Liu, Chengyu Wang, Tingfeng Cao, Kui Jia, Jun Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03431">https://arxiv.org/abs/2403.03431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03431">https://arxiv.org/pdf/2403.03431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03431]] Towards Understanding Cross and Self-Attention in Stable Diffusion for  Text-Guided Image Editing(https://arxiv.org/abs/2403.03431)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Deep Text-to-Image Synthesis (TIS) models such as Stable Diffusion have recently gained significant popularity for creative Text-to-image generation. Yet, for domain-specific scenarios, tuning-free Text-guided Image Editing (TIE) is of greater importance for application developers, which modify objects or object properties in images by manipulating feature components in attention layers during the generation process. However, little is known about what semantic meanings these attention layers have learned and which parts of the attention maps contribute to the success of image editing. In this paper, we conduct an in-depth probing analysis and demonstrate that cross-attention maps in Stable Diffusion often contain object attribution information that can result in editing failures. In contrast, self-attention maps play a crucial role in preserving the geometric and shape details of the source image during the transformation to the target image. Our analysis offers valuable insights into understanding cross and self-attention maps in diffusion models. Moreover, based on our findings, we simplify popular image editing methods and propose a more straightforward yet more stable and efficient tuning-free procedure that only modifies self-attention maps of the specified attention layers during the denoising process. Experimental results show that our simplified method consistently surpasses the performance of popular approaches on multiple datasets.</li>
</ul>

<h3>Title: Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language  Models</h3>
<ul>
<li><strong>Authors: </strong>Wenfeng Feng, Chuzhan Hao, Yuewei Zhang, Yu Han, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03432">https://arxiv.org/abs/2403.03432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03432">https://arxiv.org/pdf/2403.03432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03432]] Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language  Models(https://arxiv.org/abs/2403.03432)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Instruction Tuning has the potential to stimulate or enhance specific capabilities of large language models (LLMs). However, achieving the right balance of data is crucial to prevent catastrophic forgetting and interference between tasks. To address these limitations and enhance training flexibility, we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and parameter-efficient tuning method designed for multi-task learning with LLMs. In this paper, we start by individually training multiple domain-specific LoRA modules using corresponding supervised corpus data. These LoRA modules can be aligned with the expert design principles observed in Mixture-of-Experts (MoE). Subsequently, we combine the multiple LoRAs using an explicit routing strategy and introduce domain labels to facilitate multi-task learning, which help prevent interference between tasks and ultimately enhances the performance of each individual task. Furthermore, each LoRA model can be iteratively adapted to a new domain, allowing for quick domain-specific adaptation. Experiments on diverse tasks demonstrate superior and robust performance, which can further promote the wide application of domain-specific LLMs.</li>
</ul>

<h3>Title: Uncertainty quantification for deeponets with ensemble kalman inversion</h3>
<ul>
<li><strong>Authors: </strong>Andrew Pensoneault, Xueyu Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03444">https://arxiv.org/abs/2403.03444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03444">https://arxiv.org/pdf/2403.03444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03444]] Uncertainty quantification for deeponets with ensemble kalman inversion(https://arxiv.org/abs/2403.03444)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, operator learning, particularly the DeepONet, has received much attention for efficiently learning complex mappings between input and output functions across diverse fields. However, in practical scenarios with limited and noisy data, accessing the uncertainty in DeepONet predictions becomes essential, especially in mission-critical or safety-critical applications. Existing methods, either computationally intensive or yielding unsatisfactory uncertainty quantification, leave room for developing efficient and informative uncertainty quantification (UQ) techniques tailored for DeepONets. In this work, we proposed a novel inference approach for efficient UQ for operator learning by harnessing the power of the Ensemble Kalman Inversion (EKI) approach. EKI, known for its derivative-free, noise-robust, and highly parallelizable feature, has demonstrated its advantages for UQ for physics-informed neural networks [28]. Our innovative application of EKI enables us to efficiently train ensembles of DeepONets while obtaining informative uncertainty estimates for the output of interest. We deploy a mini-batch variant of EKI to accommodate larger datasets, mitigating the computational demand due to large datasets during the training stage. Furthermore, we introduce a heuristic method to estimate the artificial dynamics covariance, thereby improving our uncertainty estimates. Finally, we demonstrate the effectiveness and versatility of our proposed methodology across various benchmark problems, showcasing its potential to address the pressing challenges of uncertainty quantification in DeepONets, especially for practical applications with limited and noisy data.</li>
</ul>

<h3>Title: HDRFlow: Real-Time HDR Video Reconstruction with Large Motions</h3>
<ul>
<li><strong>Authors: </strong>Gangwei Xu, Yujin Wang, Jinwei Gu, Tianfan Xue, Xin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03447">https://arxiv.org/abs/2403.03447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03447">https://arxiv.org/pdf/2403.03447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03447]] HDRFlow: Real-Time HDR Video Reconstruction with Large Motions(https://arxiv.org/abs/2403.03447)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reconstructing High Dynamic Range (HDR) video from image sequences captured with alternating exposures is challenging, especially in the presence of large camera or object motion. Existing methods typically align low dynamic range sequences using optical flow or attention mechanism for deghosting. However, they often struggle to handle large complex motions and are computationally expensive. To address these challenges, we propose a robust and efficient flow estimator tailored for real-time HDR video reconstruction, named HDRFlow. HDRFlow has three novel designs: an HDR-domain alignment loss (HALoss), an efficient flow network with a multi-size large kernel (MLK), and a new HDR flow training scheme. The HALoss supervises our flow network to learn an HDR-oriented flow for accurate alignment in saturated and dark regions. The MLK can effectively model large motions at a negligible cost. In addition, we incorporate synthetic data, Sintel, into our training dataset, utilizing both its provided forward flow and backward flow generated by us to supervise our flow network, enhancing our performance in large motion regions. Extensive experiments demonstrate that our HDRFlow outperforms previous methods on standard benchmarks. To the best of our knowledge, HDRFlow is the first real-time HDR video reconstruction method for video sequences captured with alternating exposures, capable of processing 720p resolution inputs at 25ms.</li>
</ul>

<h3>Title: Kernel Correlation-Dissimilarity for Multiple Kernel k-Means Clustering</h3>
<ul>
<li><strong>Authors: </strong>Rina Su, Yu Guo, Caiying Wu, Qiyu Jin, Tieyong Zeng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03448">https://arxiv.org/abs/2403.03448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03448">https://arxiv.org/pdf/2403.03448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03448]] Kernel Correlation-Dissimilarity for Multiple Kernel k-Means Clustering(https://arxiv.org/abs/2403.03448)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The main objective of the Multiple Kernel k-Means (MKKM) algorithm is to extract non-linear information and achieve optimal clustering by optimizing base kernel matrices. Current methods enhance information diversity and reduce redundancy by exploiting interdependencies among multiple kernels based on correlations or dissimilarities. Nevertheless, relying solely on a single metric, such as correlation or dissimilarity, to define kernel relationships introduces bias and incomplete characterization. Consequently, this limitation hinders efficient information extraction, ultimately compromising clustering performance. To tackle this challenge, we introduce a novel method that systematically integrates both kernel correlation and dissimilarity. Our approach comprehensively captures kernel relationships, facilitating more efficient classification information extraction and improving clustering performance. By emphasizing the coherence between kernel correlation and dissimilarity, our method offers a more objective and transparent strategy for extracting non-linear information and significantly improving clustering precision, supported by theoretical rationale. We assess the performance of our algorithm on 13 challenging benchmark datasets, demonstrating its superiority over contemporary state-of-the-art MKKM techniques.</li>
</ul>

<h3>Title: D4C glove-train: solving the RPM and Bongard-logo problem by  distributing and Circumscribing concepts</h3>
<ul>
<li><strong>Authors: </strong>Ruizhuo Song, Beiming Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03452">https://arxiv.org/abs/2403.03452</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03452">https://arxiv.org/pdf/2403.03452</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03452]] D4C glove-train: solving the RPM and Bongard-logo problem by  distributing and Circumscribing concepts(https://arxiv.org/abs/2403.03452)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>This paper presents significant advancements in the field of abstract reasoning, particularly for Raven's Progressive Matrices (RPM) and Bongard-Logo problems. We first introduce D2C, a method that redefines concept boundaries in these domains and bridges the gap between high-level concepts and their low-dimensional representations. Leveraging this foundation, we propose D3C, a novel approach for tackling Bongard-Logo problems. D3C estimates the distributions of image representations and measures their Sinkhorn distance to achieve remarkable reasoning accuracy. This innovative method provides new insights into the relationships between images and advances the state-of-the-art in abstract reasoning. To further enhance computational efficiency without sacrificing performance, we introduce D3C-cos. This variant of D3C constrains distribution distances, offering a more computationally efficient solution for RPM problems while maintaining high accuracy. Additionally, we present Lico-Net, a baseline network for RPM that integrates D3C and D3C-cos. By estimating and constraining the distributions of regularity representations, Lico-Net addresses both problem-solving and interpretability challenges, achieving state-of-the-art performance. Finally, we extend our methodology with D4C, an adversarial approach that further refines concept boundaries compared to D2C. Tailored for RPM and Bongard-Logo problems, D4C demonstrates significant improvements in addressing the challenges of abstract reasoning. Overall, our contributions advance the field of abstract reasoning, providing new perspectives and practical solutions to long-standing problems.</li>
</ul>

<h3>Title: DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with  Generative Adversarial Network</h3>
<ul>
<li><strong>Authors: </strong>Xiangquan Gui, Binxuan Zhang, Li Li, Yi Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03456">https://arxiv.org/abs/2403.03456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03456">https://arxiv.org/pdf/2403.03456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03456]] DLP-GAN: Learning to Draw Modern Chinese Landscape Photos with  Generative Adversarial Network(https://arxiv.org/abs/2403.03456)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Chinese landscape painting has a unique and artistic style, and its drawing technique is highly abstract in both the use of color and the realistic representation of objects. Previous methods focus on transferring from modern photos to ancient ink paintings. However, little attention has been paid to translating landscape paintings into modern photos. To solve such problems, in this paper, we (1) propose DLP-GAN (\textbf{D}raw Modern Chinese \textbf{L}andscape \textbf{P}hotos with \textbf{G}enerative \textbf{A}dversarial \textbf{N}etwork), an unsupervised cross-domain image translation framework with a novel asymmetric cycle mapping, and (2) introduce a generator based on a dense-fusion module to match different translation directions. Moreover, a dual-consistency loss is proposed to balance the realism and abstraction of model painting. In this way, our model can draw landscape photos and sketches in the modern sense. Finally, based on our collection of modern landscape and sketch datasets, we compare the images generated by our model with other benchmarks. Extensive experiments including user studies show that our model outperforms state-of-the-art methods.</li>
</ul>

<h3>Title: Slot Abstractors: Toward Scalable Abstract Visual Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Shanka Subhra Mondal, Jonathan D. Cohen, Taylor W. Webb</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03458">https://arxiv.org/abs/2403.03458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03458">https://arxiv.org/pdf/2403.03458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03458]] Slot Abstractors: Toward Scalable Abstract Visual Reasoning(https://arxiv.org/abs/2403.03458)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Abstract visual reasoning is a characteristically human ability, allowing the identification of relational patterns that are abstracted away from object features, and the systematic generalization of those patterns to unseen problems. Recent work has demonstrated strong systematic generalization in visual reasoning tasks involving multi-object inputs, through the integration of slot-based methods used for extracting object-centric representations coupled with strong inductive biases for relational abstraction. However, this approach was limited to problems containing a single rule, and was not scalable to visual reasoning problems containing a large number of objects. Other recent work proposed Abstractors, an extension of Transformers that incorporates strong relational inductive biases, thereby inheriting the Transformer's scalability and multi-head architecture, but it has yet to be demonstrated how this approach might be applied to multi-object visual inputs. Here we combine the strengths of the above approaches and propose Slot Abstractors, an approach to abstract visual reasoning that can be scaled to problems involving a large number of objects and multiple relations among them. The approach displays state-of-the-art performance across four abstract visual reasoning tasks.</li>
</ul>

<h3>Title: A Density-Guided Temporal Attention Transformer for Indiscernible Object  Counting in Underwater Video</h3>
<ul>
<li><strong>Authors: </strong>Cheng-Yen Yang, Hsiang-Wei Huang, Zhongyu Jiang, Hao Wang, Farron Wallace, Jenq-Neng Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03461">https://arxiv.org/abs/2403.03461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03461">https://arxiv.org/pdf/2403.03461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03461]] A Density-Guided Temporal Attention Transformer for Indiscernible Object  Counting in Underwater Video(https://arxiv.org/abs/2403.03461)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Dense object counting or crowd counting has come a long way thanks to the recent development in the vision community. However, indiscernible object counting, which aims to count the number of targets that are blended with respect to their surroundings, has been a challenge. Image-based object counting datasets have been the mainstream of the current publicly available datasets. Therefore, we propose a large-scale dataset called YoutubeFish-35, which contains a total of 35 sequences of high-definition videos with high frame-per-second and more than 150,000 annotated center points across a selected variety of scenes. For benchmarking purposes, we select three mainstream methods for dense object counting and carefully evaluate them on the newly collected dataset. We propose TransVidCount, a new strong baseline that combines density and regression branches along the temporal domain in a unified framework and can effectively tackle indiscernible object counting with state-of-the-art performance on YoutubeFish-35 dataset.</li>
</ul>

<h3>Title: FLAME Diffuser: Grounded Wildfire Image Synthesis using Mask Guided  Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Sayed Pedram Haeri Boroujeni, Xiwen Chen, Ashish Bastola, Huayu Li, Abolfazl Razi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03463">https://arxiv.org/abs/2403.03463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03463">https://arxiv.org/pdf/2403.03463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03463]] FLAME Diffuser: Grounded Wildfire Image Synthesis using Mask Guided  Diffusion(https://arxiv.org/abs/2403.03463)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The rise of machine learning in recent years has brought benefits to various research fields such as wide fire detection. Nevertheless, small object detection and rare object detection remain a challenge. To address this problem, we present a dataset automata that can generate ground truth paired datasets using diffusion models. Specifically, we introduce a mask-guided diffusion framework that can fusion the wildfire into the existing images while the flame position and size can be precisely controlled. In advance, to fill the gap that the dataset of wildfire images in specific scenarios is missing, we vary the background of synthesized images by controlling both the text prompt and input image. Furthermore, to solve the color tint problem or the well-known domain shift issue, we apply the CLIP model to filter the generated massive dataset to preserve quality. Thus, our proposed framework can generate a massive dataset of that images are high-quality and ground truth-paired, which well addresses the needs of the annotated datasets in specific tasks.</li>
</ul>

<h3>Title: Self-Attention Empowered Graph Convolutional Network for Structure  Learning and Node Embedding</h3>
<ul>
<li><strong>Authors: </strong>Mengying Jiang, Guizhong Liu, Yuanchao Su, Xinliang Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03465">https://arxiv.org/abs/2403.03465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03465">https://arxiv.org/pdf/2403.03465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03465]] Self-Attention Empowered Graph Convolutional Network for Structure  Learning and Node Embedding(https://arxiv.org/abs/2403.03465)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In representation learning on graph-structured data, many popular graph neural networks (GNNs) fail to capture long-range dependencies, leading to performance degradation. Furthermore, this weakness is magnified when the concerned graph is characterized by heterophily (low homophily). To solve this issue, this paper proposes a novel graph learning framework called the graph convolutional network with self-attention (GCN-SA). The proposed scheme exhibits an exceptional generalization capability in node-level representation learning. The proposed GCN-SA contains two enhancements corresponding to edges and node features. For edges, we utilize a self-attention mechanism to design a stable and effective graph-structure-learning module that can capture the internal correlation between any pair of nodes. This graph-structure-learning module can identify reliable neighbors for each node from the entire graph. Regarding the node features, we modify the transformer block to make it more applicable to enable GCN to fuse valuable information from the entire graph. These two enhancements work in distinct ways to help our GCN-SA capture long-range dependencies, enabling it to perform representation learning on graphs with varying levels of homophily. The experimental results on benchmark datasets demonstrate the effectiveness of the proposed GCN-SA. Compared to other outstanding GNN counterparts, the proposed GCN-SA is competitive.</li>
</ul>

<h3>Title: Multi-task Learning for Real-time Autonomous Driving Leveraging  Task-adaptive Attention Generator</h3>
<ul>
<li><strong>Authors: </strong>Wonhyeok Choi, Mingyu Shin, Hyukzae Lee, Jaehoon Cho, Jaehyeon Park, Sunghoon Im</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03468">https://arxiv.org/abs/2403.03468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03468">https://arxiv.org/pdf/2403.03468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03468]] Multi-task Learning for Real-time Autonomous Driving Leveraging  Task-adaptive Attention Generator(https://arxiv.org/abs/2403.03468)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Real-time processing is crucial in autonomous driving systems due to the imperative of instantaneous decision-making and rapid response. In real-world scenarios, autonomous vehicles are continuously tasked with interpreting their surroundings, analyzing intricate sensor data, and making decisions within split seconds to ensure safety through numerous computer vision tasks. In this paper, we present a new real-time multi-task network adept at three vital autonomous driving tasks: monocular 3D object detection, semantic segmentation, and dense depth estimation. To counter the challenge of negative transfer, which is the prevalent issue in multi-task learning, we introduce a task-adaptive attention generator. This generator is designed to automatically discern interrelations across the three tasks and arrange the task-sharing pattern, all while leveraging the efficiency of the hard-parameter sharing approach. To the best of our knowledge, the proposed model is pioneering in its capability to concurrently handle multiple tasks, notably 3D object detection, while maintaining real-time processing speeds. Our rigorously optimized network, when tested on the Cityscapes-3D datasets, consistently outperforms various baseline models. Moreover, an in-depth ablation study substantiates the efficacy of the methodologies integrated into our framework.</li>
</ul>

<h3>Title: Inverse-Free Fast Natural Gradient Descent Method for Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinwei Ou, Ce Zhu, Xiaolin Huang, Yipeng Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03473">https://arxiv.org/abs/2403.03473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03473">https://arxiv.org/pdf/2403.03473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03473]] Inverse-Free Fast Natural Gradient Descent Method for Deep Learning(https://arxiv.org/abs/2403.03473)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Second-order methods can converge much faster than first-order methods by incorporating second-order derivates or statistics, but they are far less prevalent in deep learning due to their computational inefficiency. To handle this, many of the existing solutions focus on reducing the size of the matrix to be inverted. However, it is still needed to perform the inverse operator in each iteration. In this paper, we present a fast natural gradient descent (FNGD) method, which only requires computing the inverse during the first epoch. Firstly, we reformulate the gradient preconditioning formula in the natural gradient descent (NGD) as a weighted sum of per-sample gradients using the Sherman-Morrison-Woodbury formula. Building upon this, to avoid the iterative inverse operation involved in computing coefficients, the weighted coefficients are shared across epochs without affecting the empirical performance. FNGD approximates the NGD as a fixed-coefficient weighted sum, akin to the average sum in first-order methods. Consequently, the computational complexity of FNGD can approach that of first-order methods. To demonstrate the efficiency of the proposed FNGD, we perform empirical evaluations on image classification and machine translation tasks. For training ResNet-18 on the CIFAR-100 dataset, FNGD can achieve a speedup of 2.05$\times$ compared with KFAC. For training Transformer on Multi30K, FNGD outperforms AdamW by 24 BLEU score while requiring almost the same training time.</li>
</ul>

<h3>Title: Continual Segmentation with Disentangled Objectness Learning and Class  Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yizheng Gong, Siyue Yu, Xiaoyang Wang, Jimin Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03477">https://arxiv.org/abs/2403.03477</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03477">https://arxiv.org/pdf/2403.03477</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03477]] Continual Segmentation with Disentangled Objectness Learning and Class  Recognition(https://arxiv.org/abs/2403.03477)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Most continual segmentation methods tackle the problem as a per-pixel classification task. However, such a paradigm is very challenging, and we find query-based segmenters with built-in objectness have inherent advantages compared with per-pixel ones, as objectness has strong transfer ability and forgetting resistance. Based on these findings, we propose CoMasTRe by disentangling continual segmentation into two stages: forgetting-resistant continual objectness learning and well-researched continual classification. CoMasTRe uses a two-stage segmenter learning class-agnostic mask proposals at the first stage and leaving recognition to the second stage. During continual learning, a simple but effective distillation is adopted to strengthen objectness. To further mitigate the forgetting of old classes, we design a multi-label class distillation strategy suited for segmentation. We assess the effectiveness of CoMasTRe on PASCAL VOC and ADE20K. Extensive experiments show that our method outperforms per-pixel and query-based methods on both datasets. Code will be available at https://github.com/jordangong/CoMasTRe.</li>
</ul>

<h3>Title: NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on  Noise Cropping and Merging</h3>
<ul>
<li><strong>Authors: </strong>Takahiro Shirakawa, Seiichi Uchida</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03485">https://arxiv.org/abs/2403.03485</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03485">https://arxiv.org/pdf/2403.03485</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03485]] NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on  Noise Cropping and Merging(https://arxiv.org/abs/2403.03485)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Layout-aware text-to-image generation is a task to generate multi-object images that reflect layout conditions in addition to text conditions. The current layout-aware text-to-image diffusion models still have several issues, including mismatches between the text and layout conditions and quality degradation of generated images. This paper proposes a novel layout-aware text-to-image diffusion model called NoiseCollage to tackle these issues. During the denoising process, NoiseCollage independently estimates noises for individual objects and then crops and merges them into a single noise. This operation helps avoid condition mismatches; in other words, it can put the right objects in the right places. Qualitative and quantitative evaluations show that NoiseCollage outperforms several state-of-the-art models. These successful results indicate that the crop-and-merge operation of noises is a reasonable strategy to control image generation. We also show that NoiseCollage can be integrated with ControlNet to use edges, sketches, and pose skeletons as additional conditions. Experimental results show that this integration boosts the layout accuracy of ControlNet. The code is available at https://github.com/univ-esuty/noisecollage.</li>
</ul>

<h3>Title: PhenoAuth: A Novel PUF-Phenotype-based Authentication Protocol for IoT  Devices</h3>
<ul>
<li><strong>Authors: </strong>Hongming Fei, Owen Millwood, Gope Prosanta, Jack Miskelly, Biplab Sikdar</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03486">https://arxiv.org/abs/2403.03486</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03486">https://arxiv.org/pdf/2403.03486</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03486]] PhenoAuth: A Novel PUF-Phenotype-based Authentication Protocol for IoT  Devices(https://arxiv.org/abs/2403.03486)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Physical Unclonable Functions (PUFs) have been shown to be a highly promising solution for enabling high security systems tailored for low-power devices. Commonly, PUFs are utilised to generate cryptographic keys on-the-fly, replacing the need to store keys in vulnerable, non-volatile memories. Due to the physical nature of PUFs, environmental variations cause noise, manifesting themselves as errors which are apparent in the initial PUF measurements. This necessitates expensive active error correction techniques which can run counter to the goal of lightweight security. ML-based techniques for authenticating noisy PUF measurements were explored as an alternative to error correction techniques, bringing about the concept of a PUF Phenotype, where PUF identity is considered as a structure agnostic representation of the PUF, with relevant noise encoding. This work proposes a full noise-tolerant authentication protocol based on the PUF Phenotype concept and methodology for an Internet-of-Things (IoT) network, demonstrating mutual authentication and forward secrecy in a setting suitable for device-to-device communication. Upon conducting security and performance analyses, it is evident that our proposed scheme demonstrates resilience against various attacks compared to the currently existing PUF protocols.</li>
</ul>

<h3>Title: A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiangci Li, Linfeng Song, Lifeng Jin, Haitao Mi, Jessica Ouyang, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03496">https://arxiv.org/abs/2403.03496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03496">https://arxiv.org/pdf/2403.03496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03496]] A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation(https://arxiv.org/abs/2403.03496)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge-based, open-domain dialogue generation aims to build chit-chat systems that talk to humans using mined support knowledge. Many types and sources of knowledge have previously been shown to be useful as support knowledge. Even in the era of large language models, response generation grounded in knowledge retrieved from additional up-to-date sources remains a practically important approach. While prior work using single-source knowledge has shown a clear positive correlation between the performances of knowledge selection and response generation, there are no existing multi-source datasets for evaluating support knowledge retrieval. Further, prior work has assumed that the knowledge sources available at test time are the same as during training. This unrealistic assumption unnecessarily handicaps models, as new knowledge sources can become available after a model is trained. In this paper, we present a high-quality benchmark named multi-source Wizard of Wikipedia (Ms.WoW) for evaluating multi-source dialogue knowledge selection and response generation. Unlike existing datasets, it contains clean support knowledge, grounded at the utterance level and partitioned into multiple knowledge sources. We further propose a new challenge, dialogue knowledge plug-and-play, which aims to test an already trained dialogue model on using new support knowledge from previously unseen sources in a zero-shot fashion.</li>
</ul>

<h3>Title: Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid  Texts</h3>
<ul>
<li><strong>Authors: </strong>Zijie Zeng, Shiqi Liu, Lele Sha, Zhuang Li, Kaixun Yang, Sannyuya Liu, Dragan Gašević, Guanliang Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03506">https://arxiv.org/abs/2403.03506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03506">https://arxiv.org/pdf/2403.03506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03506]] Towards Detecting AI-Generated Text within Human-AI Collaborative Hybrid  Texts(https://arxiv.org/abs/2403.03506)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This study explores the challenge of sentence-level AI-generated text detection within human-AI collaborative hybrid texts. Existing studies of AI-generated text detection for hybrid texts often rely on synthetic datasets. These typically involve hybrid texts with a limited number of boundaries. We contend that studies of detecting AI-generated content within hybrid texts should cover different types of hybrid texts generated in realistic settings to better inform real-world applications. Therefore, our study utilizes the CoAuthor dataset, which includes diverse, realistic hybrid texts generated through the collaboration between human writers and an intelligent writing system in multi-turn interactions. We adopt a two-step, segmentation-based pipeline: (i) detect segments within a given hybrid text where each segment contains sentences of consistent authorship, and (ii) classify the authorship of each identified segment. Our empirical findings highlight (1) detecting AI-generated sentences in hybrid texts is overall a challenging task because (1.1) human writers' selecting and even editing AI-generated sentences based on personal preferences adds difficulty in identifying the authorship of segments; (1.2) the frequent change of authorship between neighboring sentences within the hybrid text creates difficulties for segment detectors in identifying authorship-consistent segments; (1.3) the short length of text segments within hybrid texts provides limited stylistic cues for reliable authorship determination; (2) before embarking on the detection process, it is beneficial to assess the average length of segments within the hybrid text. This assessment aids in deciding whether (2.1) to employ a text segmentation-based strategy for hybrid texts with longer segments, or (2.2) to adopt a direct sentence-by-sentence classification strategy for those with shorter segments.</li>
</ul>

<h3>Title: GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Zhao, Zhenyu Zhang, Beidi Chen, Zhangyang Wang, Anima Anandkumar, Yuandong Tian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03507">https://arxiv.org/abs/2403.03507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03507">https://arxiv.org/pdf/2403.03507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03507]] GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection(https://arxiv.org/abs/2403.03507)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) presents significant memory challenges, predominantly due to the growing size of weights and optimizer states. Common memory-reduction approaches, such as low-rank adaptation (LoRA), add a trainable low-rank matrix to the frozen pre-trained weight in each layer, reducing trainable parameters and optimizer states. However, such approaches typically underperform training with full-rank weights in both pre-training and fine-tuning stages since they limit the parameter search to a low-rank subspace and alter the training dynamics, and further, may require full-rank warm start. In this work, we propose Gradient Low-Rank Projection (GaLore), a training strategy that allows full-parameter learning but is more memory-efficient than common low-rank adaptation methods such as LoRA. Our approach reduces memory usage by up to 65.5% in optimizer states while maintaining both efficiency and performance for pre-training on LLaMA 1B and 7B architectures with C4 dataset with up to 19.7B tokens, and on fine-tuning RoBERTa on GLUE tasks. Our 8-bit GaLore further reduces optimizer memory by up to 82.5% and total training memory by 63.3%, compared to a BF16 baseline. Notably, we demonstrate, for the first time, the feasibility of pre-training a 7B model on consumer GPUs with 24GB memory (e.g., NVIDIA RTX 4090) without model parallel, checkpointing, or offloading strategies.</li>
</ul>

<h3>Title: Probing the Robustness of Time-series Forecasting Models with  CounterfacTS</h3>
<ul>
<li><strong>Authors: </strong>Håkon Hanisch Kjærnli, Lluis Mas-Ribas, Aida Ashrafi, Gleb Sizov, Helge Langseth, Odd Erik Gundersen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03508">https://arxiv.org/abs/2403.03508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03508">https://arxiv.org/pdf/2403.03508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03508]] Probing the Robustness of Time-series Forecasting Models with  CounterfacTS(https://arxiv.org/abs/2403.03508)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A common issue for machine learning models applied to time-series forecasting is the temporal evolution of the data distributions (i.e., concept drift). Because most of the training data does not reflect such changes, the models present poor performance on the new out-of-distribution scenarios and, therefore, the impact of such events cannot be reliably anticipated ahead of time. We present and publicly release CounterfacTS, a tool to probe the robustness of deep learning models in time-series forecasting tasks via counterfactuals. CounterfacTS has a user-friendly interface that allows the user to visualize, compare and quantify time series data and their forecasts, for a number of datasets and deep learning models. Furthermore, the user can apply various transformations to the time series and explore the resulting changes in the forecasts in an interpretable manner. Through example cases, we illustrate how CounterfacTS can be used to i) identify the main features characterizing and differentiating sets of time series, ii) assess how the model performance depends on these characateristics, and iii) guide transformations of the original time series to create counterfactuals with desired properties for training and increasing the forecasting performance in new regions of the data distribution. We discuss the importance of visualizing and considering the location of the data in a projected feature space to transform time-series and create effective counterfactuals for training the models. Overall, CounterfacTS aids at creating counterfactuals to efficiently explore the impact of hypothetical scenarios not covered by the original data in time-series forecasting tasks.</li>
</ul>

<h3>Title: Dcl-Net: Dual Contrastive Learning Network for Semi-Supervised  Multi-Organ Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Lu Wen, Zhenghao Feng, Yun Hou, Peng Wang, Xi Wu, Jiliu Zhou, Yan Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03512">https://arxiv.org/abs/2403.03512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03512">https://arxiv.org/pdf/2403.03512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03512]] Dcl-Net: Dual Contrastive Learning Network for Semi-Supervised  Multi-Organ Segmentation(https://arxiv.org/abs/2403.03512)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised learning is a sound measure to relieve the strict demand of abundant annotated datasets, especially for challenging multi-organ segmentation . However, most existing SSL methods predict pixels in a single image independently, ignoring the relations among images and categories. In this paper, we propose a two-stage Dual Contrastive Learning Network for semi-supervised MoS, which utilizes global and local contrastive learning to strengthen the relations among images and classes. Concretely, in Stage 1, we develop a similarity-guided global contrastive learning to explore the implicit continuity and similarity among images and learn global context. Then, in Stage 2, we present an organ-aware local contrastive learning to further attract the class representations. To ease the computation burden, we introduce a mask center computation algorithm to compress the category representations for local contrastive learning. Experiments conducted on the public 2017 ACDC dataset and an in-house RC-OARs dataset has demonstrated the superior performance of our method.</li>
</ul>

<h3>Title: CLongEval: A Chinese Benchmark for Evaluating Long-Context Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zexuan Qiu, Jingjing Li, Shijue Huang, Wanjun Zhong, Irwin King</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03514">https://arxiv.org/abs/2403.03514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03514">https://arxiv.org/pdf/2403.03514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03514]] CLongEval: A Chinese Benchmark for Evaluating Long-Context Large  Language Models(https://arxiv.org/abs/2403.03514)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Developing Large Language Models (LLMs) with robust long-context capabilities has been the recent research focus, resulting in the emergence of long-context LLMs proficient in Chinese. However, the evaluation of these models remains underdeveloped due to a lack of benchmarks. To address this gap, we present CLongEval, a comprehensive Chinese benchmark for evaluating long-context LLMs. CLongEval is characterized by three key features: (1) Sufficient data volume, comprising 7 distinct tasks and 7,267 examples; (2) Broad applicability, accommodating to models with context windows size from 1K to 100K; (3) High quality, with over 2,000 manually annotated question-answer pairs in addition to the automatically constructed labels. With CLongEval, we undertake a comprehensive assessment of 6 open-source long-context LLMs and 2 leading commercial counterparts that feature both long-context abilities and proficiency in Chinese. We also provide in-depth analysis based on the empirical results, trying to shed light on the critical capabilities that present challenges in long-context settings. The dataset, evaluation scripts, and model outputs will be released.</li>
</ul>

<h3>Title: Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling</h3>
<ul>
<li><strong>Authors: </strong>Chao-Wei Huang, Chen-An Li, Tsu-Yuan Hsu, Chen-Yu Hsu, Yun-Nung Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03516">https://arxiv.org/abs/2403.03516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03516">https://arxiv.org/pdf/2403.03516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03516]] Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling(https://arxiv.org/abs/2403.03516)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Dense retrieval methods have demonstrated promising performance in multilingual information retrieval, where queries and documents can be in different languages. However, dense retrievers typically require a substantial amount of paired data, which poses even greater challenges in multilingual scenarios. This paper introduces UMR, an Unsupervised Multilingual dense Retriever trained without any paired data. Our approach leverages the sequence likelihood estimation capabilities of multilingual language models to acquire pseudo labels for training dense retrievers. We propose a two-stage framework which iteratively improves the performance of multilingual dense retrievers. Experimental results on two benchmark datasets show that UMR outperforms supervised baselines, showcasing the potential of training multilingual retrievers without paired data, thereby enhancing their practicality. Our source code, data, and models are publicly available at https://github.com/MiuLab/UMR</li>
</ul>

<h3>Title: DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE  Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Zhongkai Hao, Chang Su, Songming Liu, Julius Berner, Chengyang Ying, Hang Su, Anima Anandkumar, Jian Song, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03542">https://arxiv.org/abs/2403.03542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03542">https://arxiv.org/pdf/2403.03542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03542]] DPOT: Auto-Regressive Denoising Operator Transformer for Large-Scale PDE  Pre-Training(https://arxiv.org/abs/2403.03542)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pre-training has been investigated to improve the efficiency and performance of training neural operators in data-scarce settings. However, it is largely in its infancy due to the inherent complexity and diversity, such as long trajectories, multiple scales and varying dimensions of partial differential equations (PDEs) data. In this paper, we present a new auto-regressive denoising pre-training strategy, which allows for more stable and efficient pre-training on PDE data and generalizes to various downstream tasks. Moreover, by designing a flexible and scalable model architecture based on Fourier attention, we can easily scale up the model for large-scale pre-training. We train our PDE foundation model with up to 0.5B parameters on 10+ PDE datasets with more than 100k trajectories. Extensive experiments show that we achieve SOTA on these benchmarks and validate the strong generalizability of our model to significantly enhance performance on diverse downstream PDE tasks like 3D data. Code is available at \url{https://github.com/thu-ml/DPOT}.</li>
</ul>

<h3>Title: Benchmarking Hallucination in Large Language Models based on  Unanswerable Math Word Problem</h3>
<ul>
<li><strong>Authors: </strong>Yuhong Sun, Zhangyue Yin, Qipeng Guo, Jiawen Wu, Xipeng Qiu, Hui Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03558">https://arxiv.org/abs/2403.03558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03558">https://arxiv.org/pdf/2403.03558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03558]] Benchmarking Hallucination in Large Language Models based on  Unanswerable Math Word Problem(https://arxiv.org/abs/2403.03558)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are highly effective in various natural language processing (NLP) tasks. However, they are susceptible to producing unreliable conjectures in ambiguous contexts called hallucination. This paper presents a new method for evaluating LLM hallucination in Question Answering (QA) based on the unanswerable math word problem (MWP). To support this approach, we innovatively develop a dataset called Unanswerable Math Word Problem (UMWP) which comprises 5200 questions across five categories. We developed an evaluation methodology combining text similarity and mathematical expression detection to determine whether LLM considers the question unanswerable. The results of extensive experiments conducted on 31 LLMs, including GPT-3, InstructGPT, LLaMA, and Claude, demonstrate that in-context learning and reinforcement learning with human feedback (RLHF) training significantly enhance the model's ability to avoid hallucination. We show that utilizing MWP is a reliable and effective approach to assess hallucination. Our code and data are available at https://github.com/Yuki-Asuuna/UMWP.</li>
</ul>

<h3>Title: Efficient Algorithms for Empirical Group Distributional Robust  Optimization and Beyond</h3>
<ul>
<li><strong>Authors: </strong>Dingzhi Yu, Yunuo Cai, Wei Jiang, Lijun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03562">https://arxiv.org/abs/2403.03562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03562">https://arxiv.org/pdf/2403.03562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03562]] Efficient Algorithms for Empirical Group Distributional Robust  Optimization and Beyond(https://arxiv.org/abs/2403.03562)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We investigate the empirical counterpart of group distributionally robust optimization (GDRO), which aims to minimize the maximal empirical risk across $m$ distinct groups. We formulate empirical GDRO as a $\textit{two-level}$ finite-sum convex-concave minimax optimization problem and develop a stochastic variance reduced mirror prox algorithm. Unlike existing methods, we construct the stochastic gradient by per-group sampling technique and perform variance reduction for all groups, which fully exploits the $\textit{two-level}$ finite-sum structure of empirical GDRO. Furthermore, we compute the snapshot and mirror snapshot point by a one-index-shifted weighted average, which distinguishes us from the naive ergodic average. Our algorithm also supports non-constant learning rates, which is different from existing literature. We establish convergence guarantees both in expectation and with high probability, demonstrating a complexity of $\mathcal{O}\left(\frac{m\sqrt{\bar{n}\ln{m}}}{\varepsilon}\right)$, where $\bar n$ is the average number of samples among $m$ groups. Remarkably, our approach outperforms the state-of-the-art method by a factor of $\sqrt{m}$. Furthermore, we extend our methodology to deal with the empirical minimax excess risk optimization (MERO) problem and manage to give the expectation bound and the high probability bound, accordingly. The complexity of our empirical MERO algorithm matches that of empirical GDRO at $\mathcal{O}\left(\frac{m\sqrt{\bar{n}\ln{m}}}{\varepsilon}\right)$, significantly surpassing the bounds of existing methods.</li>
</ul>

<h3>Title: Design of an Open-Source Architecture for Neural Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Séamus Lankford, Haithem Afli, Andy Way</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03582">https://arxiv.org/abs/2403.03582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03582">https://arxiv.org/pdf/2403.03582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03582]] Design of an Open-Source Architecture for Neural Machine Translation(https://arxiv.org/abs/2403.03582)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>adaptNMT is an open-source application that offers a streamlined approach to the development and deployment of Recurrent Neural Networks and Transformer models. This application is built upon the widely-adopted OpenNMT ecosystem, and is particularly useful for new entrants to the field, as it simplifies the setup of the development environment and creation of train, validation, and test splits. The application offers a graphing feature that illustrates the progress of model training, and employs SentencePiece for creating subword segmentation models. Furthermore, the application provides an intuitive user interface that facilitates hyperparameter customization. Notably, a single-click model development approach has been implemented, and models developed by adaptNMT can be evaluated using a range of metrics. To encourage eco-friendly research, adaptNMT incorporates a green report that flags the power consumption and kgCO${_2}$ emissions generated during model development. The application is freely available.</li>
</ul>

<h3>Title: RouteExplainer: An Explanation Framework for Vehicle Routing Problem</h3>
<ul>
<li><strong>Authors: </strong>Daisuke Kikuta, Hiroki Ikeuchi, Kengo Tajiri, Yuusuke Nakano</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03585">https://arxiv.org/abs/2403.03585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03585">https://arxiv.org/pdf/2403.03585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03585]] RouteExplainer: An Explanation Framework for Vehicle Routing Problem(https://arxiv.org/abs/2403.03585)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, large language model</a></li>
<li><strong>Abstract: </strong>The Vehicle Routing Problem (VRP) is a widely studied combinatorial optimization problem and has been applied to various practical problems. While the explainability for VRP is significant for improving the reliability and interactivity in practical VRP applications, it remains unexplored. In this paper, we propose RouteExplainer, a post-hoc explanation framework that explains the influence of each edge in a generated route. Our framework realizes this by rethinking a route as the sequence of actions and extending counterfactual explanations based on the action influence model to VRP. To enhance the explanation, we additionally propose an edge classifier that infers the intentions of each edge, a loss function to train the edge classifier, and explanation-text generation by Large Language Models (LLMs). We quantitatively evaluate our edge classifier on four different VRPs. The results demonstrate its rapid computation while maintaining reasonable accuracy, thereby highlighting its potential for deployment in practical applications. Moreover, on the subject of a tourist route, we qualitatively evaluate explanations generated by our framework. This evaluation not only validates our framework but also shows the synergy between explanation frameworks and LLMs. See https://ntt-dkiku.github.io/xai-vrp for our code, datasets, models, and demo.</li>
</ul>

<h3>Title: DeepEclipse: How to Break White-Box DNN-Watermarking Schemes</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Pegoraro, Carlotta Segna, Kavita Kumari, Ahmad-Reza Sadeghi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03590">https://arxiv.org/abs/2403.03590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03590">https://arxiv.org/pdf/2403.03590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03590]] DeepEclipse: How to Break White-Box DNN-Watermarking Schemes(https://arxiv.org/abs/2403.03590)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, watermark</a></li>
<li><strong>Abstract: </strong>Deep Learning (DL) models have become crucial in digital transformation, thus raising concerns about their intellectual property rights. Different watermarking techniques have been developed to protect Deep Neural Networks (DNNs) from IP infringement, creating a competitive field for DNN watermarking and removal methods. The predominant watermarking schemes use white-box techniques, which involve modifying weights by adding a unique signature to specific DNN layers. On the other hand, existing attacks on white-box watermarking usually require knowledge of the specific deployed watermarking scheme or access to the underlying data for further training and fine-tuning. We propose DeepEclipse, a novel and unified framework designed to remove white-box watermarks. We present obfuscation techniques that significantly differ from the existing white-box watermarking removal schemes. DeepEclipse can evade watermark detection without prior knowledge of the underlying watermarking scheme, additional data, or training and fine-tuning. Our evaluation reveals that DeepEclipse excels in breaking multiple white-box watermarking schemes, reducing watermark detection to random guessing while maintaining a similar model accuracy as the original one. Our framework showcases a promising solution to address the ongoing DNN watermark protection and removal challenges.</li>
</ul>

<h3>Title: Wildest Dreams: Reproducible Research in Privacy-preserving Neural  Network Training</h3>
<ul>
<li><strong>Authors: </strong>Tanveer Khan, Mindaugas Budzys, Khoa Nguyen, Antonis Michalas</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03592">https://arxiv.org/abs/2403.03592</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03592">https://arxiv.org/pdf/2403.03592</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03592]] Wildest Dreams: Reproducible Research in Privacy-preserving Neural  Network Training(https://arxiv.org/abs/2403.03592)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Machine Learning (ML), addresses a multitude of complex issues in multiple disciplines, including social sciences, finance, and medical research. ML models require substantial computing power and are only as powerful as the data utilized. Due to high computational cost of ML methods, data scientists frequently use Machine Learning-as-a-Service (MLaaS) to outsource computation to external servers. However, when working with private information, like financial data or health records, outsourcing the computation might result in privacy issues. Recent advances in Privacy-Preserving Techniques (PPTs) have enabled ML training and inference over protected data through the use of Privacy-Preserving Machine Learning (PPML). However, these techniques are still at a preliminary stage and their application in real-world situations is demanding. In order to comprehend discrepancy between theoretical research suggestions and actual applications, this work examines the past and present of PPML, focusing on Homomorphic Encryption (HE) and Secure Multi-party Computation (SMPC) applied to ML. This work primarily focuses on the ML model's training phase, where maintaining user data privacy is of utmost importance. We provide a solid theoretical background that eases the understanding of current approaches and their limitations. In addition, we present a SoK of the most recent PPML frameworks for model training and provide a comprehensive comparison in terms of the unique properties and performances on standard benchmarks. Also, we reproduce the results for some of the papers and examine at what level existing works in the field provide support for open science. We believe our work serves as a valuable contribution by raising awareness about the current gap between theoretical advancements and real-world applications in PPML, specifically regarding open-source availability, reproducibility, and usability.</li>
</ul>

<h3>Title: Do You Trust Your Model? Emerging Malware Threats in the Deep Learning  Ecosystem</h3>
<ul>
<li><strong>Authors: </strong>Dorjan Hitaj, Giulio Pagnotta, Fabio De Gaspari, Sediola Ruko, Briland Hitaj, Luigi V. Mancini, Fernando Perez-Cruz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03593">https://arxiv.org/abs/2403.03593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03593">https://arxiv.org/pdf/2403.03593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03593]] Do You Trust Your Model? Emerging Malware Threats in the Deep Learning  Ecosystem(https://arxiv.org/abs/2403.03593)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, steal, federate</a></li>
<li><strong>Abstract: </strong>Training high-quality deep learning models is a challenging task due to computational and technical requirements. A growing number of individuals, institutions, and companies increasingly rely on pre-trained, third-party models made available in public repositories. These models are often used directly or integrated in product pipelines with no particular precautions, since they are effectively just data in tensor form and considered safe. In this paper, we raise awareness of a new machine learning supply chain threat targeting neural networks. We introduce MaleficNet 2.0, a novel technique to embed self-extracting, self-executing malware in neural networks. MaleficNet 2.0 uses spread-spectrum channel coding combined with error correction techniques to inject malicious payloads in the parameters of deep neural networks. MaleficNet 2.0 injection technique is stealthy, does not degrade the performance of the model, and is robust against removal techniques. We design our approach to work both in traditional and distributed learning settings such as Federated Learning, and demonstrate that it is effective even when a reduced number of bits is used for the model parameters. Finally, we implement a proof-of-concept self-extracting neural network malware using MaleficNet 2.0, demonstrating the practicality of the attack against a widely adopted machine learning framework. Our aim with this work is to raise awareness against these new, dangerous attacks both in the research community and industry, and we hope to encourage further research in mitigation techniques against such threats.</li>
</ul>

<h3>Title: GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D  Scene Understanding</h3>
<ul>
<li><strong>Authors: </strong>Zi-Ting Chou, Sheng-Yu Huang, I-Jieh Liu, Yu-Chiang Frank Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03608">https://arxiv.org/abs/2403.03608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03608">https://arxiv.org/pdf/2403.03608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03608]] GSNeRF: Generalizable Semantic Neural Radiance Fields with Enhanced 3D  Scene Understanding(https://arxiv.org/abs/2403.03608)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Utilizing multi-view inputs to synthesize novel-view images, Neural Radiance Fields (NeRF) have emerged as a popular research topic in 3D vision. In this work, we introduce a Generalizable Semantic Neural Radiance Field (GSNeRF), which uniquely takes image semantics into the synthesis process so that both novel view images and the associated semantic maps can be produced for unseen scenes. Our GSNeRF is composed of two stages: Semantic Geo-Reasoning and Depth-Guided Visual rendering. The former is able to observe multi-view image inputs to extract semantic and geometry features from a scene. Guided by the resulting image geometry information, the latter performs both image and semantic rendering with improved performances. Our experiments not only confirm that GSNeRF performs favorably against prior works on both novel-view image and semantic segmentation synthesis but the effectiveness of our sampling strategy for visual rendering is further verified.</li>
</ul>

<h3>Title: Multimodal Large Language Models to Support Real-World Fact-Checking</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Geng, Yova Kementchedjhieva, Preslav Nakov, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03627">https://arxiv.org/abs/2403.03627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03627">https://arxiv.org/pdf/2403.03627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03627]] Multimodal Large Language Models to Support Real-World Fact-Checking(https://arxiv.org/abs/2403.03627)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing open-source models exhibit strong biases and are highly sensitive to the prompt. Our study offers insights into combating false multimodal information and building secure, trustworthy multimodal models. To the best of our knowledge, we are the first to evaluate MLLMs for real-world fact-checking.</li>
</ul>

<h3>Title: GPTopic: Dynamic and Interactive Topic Representations</h3>
<ul>
<li><strong>Authors: </strong>Arik Reuter, Anton Thielmann, Christoph Weisser, Sebastian Fischer, Benjamin Säfken</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03628">https://arxiv.org/abs/2403.03628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03628">https://arxiv.org/pdf/2403.03628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03628]] GPTopic: Dynamic and Interactive Topic Representations(https://arxiv.org/abs/2403.03628)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Topic modeling seems to be almost synonymous with generating lists of top words to represent topics within large text corpora. However, deducing a topic from such list of individual terms can require substantial expertise and experience, making topic modelling less accessible to people unfamiliar with the particularities and pitfalls of top-word interpretation. A topic representation limited to top-words might further fall short of offering a comprehensive and easily accessible characterization of the various aspects, facets and nuances a topic might have. To address these challenges, we introduce GPTopic, a software package that leverages Large Language Models (LLMs) to create dynamic, interactive topic representations. GPTopic provides an intuitive chat interface for users to explore, analyze, and refine topics interactively, making topic modeling more accessible and comprehensive. The corresponding code is available here: https://github. com/05ec6602be/GPTopic.</li>
</ul>

<h3>Title: Tackling Missing Values in Probabilistic Wind Power Forecasting: A  Generative Approach</h3>
<ul>
<li><strong>Authors: </strong>Honglin Wen, Pierre Pinson, Jie Gu, Zhijian Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03631">https://arxiv.org/abs/2403.03631</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03631">https://arxiv.org/pdf/2403.03631</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03631]] Tackling Missing Values in Probabilistic Wind Power Forecasting: A  Generative Approach(https://arxiv.org/abs/2403.03631)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Machine learning techniques have been successfully used in probabilistic wind power forecasting. However, the issue of missing values within datasets due to sensor failure, for instance, has been overlooked for a long time. Although it is natural to consider addressing this issue by imputing missing values before model estimation and forecasting, we suggest treating missing values and forecasting targets indifferently and predicting all unknown values simultaneously based on observations. In this paper, we offer an efficient probabilistic forecasting approach by estimating the joint distribution of features and targets based on a generative model. It is free of preprocessing, and thus avoids introducing potential errors. Compared with the traditional "impute, then predict" pipeline, the proposed approach achieves better performance in terms of continuous ranked probability score.</li>
</ul>

<h3>Title: A Survey on Applications of Reinforcement Learning in Spatial Resource  Allocation</h3>
<ul>
<li><strong>Authors: </strong>Di Zhang, Moyang Wang, Joseph Mango, Xiang Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03643">https://arxiv.org/abs/2403.03643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03643">https://arxiv.org/pdf/2403.03643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03643]] A Survey on Applications of Reinforcement Learning in Spatial Resource  Allocation(https://arxiv.org/abs/2403.03643)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The challenge of spatial resource allocation is pervasive across various domains such as transportation, industry, and daily life. As the scale of real-world issues continues to expand and demands for real-time solutions increase, traditional algorithms face significant computational pressures, struggling to achieve optimal efficiency and real-time capabilities. In recent years, with the escalating computational power of computers, the remarkable achievements of reinforcement learning in domains like Go and robotics have demonstrated its robust learning and sequential decision-making capabilities. Given these advancements, there has been a surge in novel methods employing reinforcement learning to tackle spatial resource allocation problems. These methods exhibit advantages such as rapid solution convergence and strong model generalization abilities, offering a new perspective on resolving spatial resource allocation problems. Therefore, this paper aims to summarize and review recent theoretical methods and applied research utilizing reinforcement learning to address spatial resource allocation problems. It provides a summary and comprehensive overview of its fundamental principles, related methodologies, and applied research. Additionally, it highlights several unresolved issues that urgently require attention in this direction for the future.</li>
</ul>

<h3>Title: Integrity-protecting block cipher modes -- Untangling a tangled web</h3>
<ul>
<li><strong>Authors: </strong>Chris J Mitchell</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03654">https://arxiv.org/abs/2403.03654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03654">https://arxiv.org/pdf/2403.03654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03654]] Integrity-protecting block cipher modes -- Untangling a tangled web(https://arxiv.org/abs/2403.03654)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>This paper re-examines the security of three related block cipher modes of operation designed to provide authenticated encryption. These modes, known as PES-PCBC, IOBC and EPBC, were all proposed in the mid-1990s. However, analyses of security of the latter two modes were published more recently. In each case one or more papers describing security issues with the schemes were eventually published, although a flaw in one of these analyses (of EPBC) was subsequently discovered - this means that until now EPBC had no known major issues. This paper establishes that, despite this, all three schemes possess defects which should prevent their use - especially as there are a number of efficient alternative schemes possessing proofs of security.</li>
</ul>

<h3>Title: Kronos: A Robust Sharding Blockchain Consensus with Optimal  Communication Overhead</h3>
<ul>
<li><strong>Authors: </strong>Andi Liu, Yizhong Liu, Zhuocheng Pan, Yinuo Li, Jianwei Liu, Yuan Lu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03655">https://arxiv.org/abs/2403.03655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03655">https://arxiv.org/pdf/2403.03655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03655]] Kronos: A Robust Sharding Blockchain Consensus with Optimal  Communication Overhead(https://arxiv.org/abs/2403.03655)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Sharding enhances blockchain scalability by dividing the network into shards, each managing specific unspent transaction outputs or accounts. Cross-shard transactions pose a critical challenge to the security and efficiency of sharding blockchains. Current solutions, however, either prioritize security with assumptions and substantial investments, or focus on reducing overhead and overlooking security considerations. In this paper, we present Kronos, a generic and efficient sharding blockchain consensus ensuring robust security. We introduce a buffer mechanism for atomic cross-shard transaction processing. Shard members collectively maintain a buffer to manage cross-shard inputs, ensuring that a transaction is committed only if all inputs are available, and no fund is transferred for invalid requests. While ensuring security, Kronos processes transactions with optimal intra-shard communication overhead. Additionally, we propose a reduction for transaction invalidity proof generation to simple and fast multicasting, leading to atomic rejection without executing full-fledged Byzantine fault tolerance protocol in optimistic scenarios. Moreover, Kronos adopts a newly designed batch mechanism, reducing inter-shard message complexity to $O((m$log$m/b)\lambda)$. Kronos operates without dependence on any time or client honesty assumption, serving as a plug-in sharding blockchain consensus supporting applications in diverse network environments including asynchronous ones. We implement Kronos using two prominent BFT protocols: Speeding Dumbo and HotStuff. Extensive experiments demonstrate Kronos achieving a substantial throughput of 68.6ktx/sec with 1.7sec latency. Compared with state-of-the-art solutions, Kronos outperforms in all cases, achieving up to a 42x improvement in throughput and a 50% reduction in latency when cross-shard transactions dominate the workload.</li>
</ul>

<h3>Title: Robust Graph Structure Learning under Heterophily</h3>
<ul>
<li><strong>Authors: </strong>Xuanting Xie, Zhao Kang, Wenyu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03659">https://arxiv.org/abs/2403.03659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03659">https://arxiv.org/pdf/2403.03659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03659]] Robust Graph Structure Learning under Heterophily(https://arxiv.org/abs/2403.03659)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph is a fundamental mathematical structure in characterizing relations between different objects and has been widely used on various learning tasks. Most methods implicitly assume a given graph to be accurate and complete. However, real data is inevitably noisy and sparse, which will lead to inferior results. Despite the remarkable success of recent graph representation learning methods, they inherently presume that the graph is homophilic, and largely overlook heterophily, where most connected nodes are from different classes. In this regard, we propose a novel robust graph structure learning method to achieve a high-quality graph from heterophilic data for downstream tasks. We first apply a high-pass filter to make each node more distinctive from its neighbors by encoding structure information into the node features. Then, we learn a robust graph with an adaptive norm characterizing different levels of noise. Afterwards, we propose a novel regularizer to further refine the graph structure. Clustering and semi-supervised classification experiments on heterophilic graphs verify the effectiveness of our method.</li>
</ul>

<h3>Title: Harnessing Meta-Learning for Improving Full-Frame Video Stabilization</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Kashif Ali, Eun Woo Im, Dongjin Kim, Tae Hyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03662">https://arxiv.org/abs/2403.03662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03662">https://arxiv.org/pdf/2403.03662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03662]] Harnessing Meta-Learning for Improving Full-Frame Video Stabilization(https://arxiv.org/abs/2403.03662)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Video stabilization is a longstanding computer vision problem, particularly pixel-level synthesis solutions for video stabilization which synthesize full frames add to the complexity of this task. These techniques aim to stabilize videos by synthesizing full frames while enhancing the stability of the considered video. This intensifies the complexity of the task due to the distinct mix of unique motion profiles and visual content present in each video sequence, making robust generalization with fixed parameters difficult. In our study, we introduce a novel approach to enhance the performance of pixel-level synthesis solutions for video stabilization by adapting these models to individual input video sequences. The proposed adaptation exploits low-level visual cues accessible during test-time to improve both the stability and quality of resulting videos. We highlight the efficacy of our methodology of "test-time adaptation" through simple fine-tuning of one of these models, followed by significant stability gain via the integration of meta-learning techniques. Notably, significant improvement is achieved with only a single adaptation step. The versatility of the proposed algorithm is demonstrated by consistently improving the performance of various pixel-level synthesis models for video stabilization in real-world scenarios.</li>
</ul>

<h3>Title: Adversarial Infrared Geometry: Using Geometry to Perform Adversarial  Attack against Infrared Pedestrian Detectors</h3>
<ul>
<li><strong>Authors: </strong>Kalibinuer Tiliwalidi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03674">https://arxiv.org/abs/2403.03674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03674">https://arxiv.org/pdf/2403.03674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03674]] Adversarial Infrared Geometry: Using Geometry to Perform Adversarial  Attack against Infrared Pedestrian Detectors(https://arxiv.org/abs/2403.03674)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, steal</a></li>
<li><strong>Abstract: </strong>Currently, infrared imaging technology enjoys widespread usage, with infrared object detection technology experiencing a surge in prominence. While previous studies have delved into physical attacks on infrared object detectors, the implementation of these techniques remains complex. For instance, some approaches entail the use of bulb boards or infrared QR suits as perturbations to execute attacks, which entail costly optimization and cumbersome deployment processes. Other methodologies involve the utilization of irregular aerogel as physical perturbations for infrared attacks, albeit at the expense of optimization expenses and perceptibility issues. In this study, we propose a novel infrared physical attack termed Adversarial Infrared Geometry (\textbf{AdvIG}), which facilitates efficient black-box query attacks by modeling diverse geometric shapes (lines, triangles, ellipses) and optimizing their physical parameters using Particle Swarm Optimization (PSO). Extensive experiments are conducted to evaluate the effectiveness, stealthiness, and robustness of AdvIG. In digital attack experiments, line, triangle, and ellipse patterns achieve attack success rates of 93.1\%, 86.8\%, and 100.0\%, respectively, with average query times of 71.7, 113.1, and 2.57, respectively, thereby confirming the efficiency of AdvIG. Physical attack experiments are conducted to assess the attack success rate of AdvIG at different distances. On average, the line, triangle, and ellipse achieve attack success rates of 61.1\%, 61.2\%, and 96.2\%, respectively. Further experiments are conducted to comprehensively analyze AdvIG, including ablation experiments, transfer attack experiments, and adversarial defense mechanisms. Given the superior performance of our method as a simple and efficient black-box adversarial attack in both digital and physical environments, we advocate for widespread attention to AdvIG.</li>
</ul>

<h3>Title: Simplified PCNet with Robustness</h3>
<ul>
<li><strong>Authors: </strong>Bingheng Li, Xuanting Xie, Haoxiang Lei, Ruiyi Fang, Zhao Kang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03676">https://arxiv.org/abs/2403.03676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03676">https://arxiv.org/pdf/2403.03676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03676]] Simplified PCNet with Robustness(https://arxiv.org/abs/2403.03676)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) have garnered significant attention for their success in learning the representation of homophilic or heterophilic graphs. However, they cannot generalize well to real-world graphs with different levels of homophily. In response, the Possion-Charlier Network (PCNet) \cite{li2024pc}, the previous work, allows graph representation to be learned from heterophily to homophily. Although PCNet alleviates the heterophily issue, there remain some challenges in further improving the efficacy and efficiency. In this paper, we simplify PCNet and enhance its robustness. We first extend the filter order to continuous values and reduce its parameters. Two variants with adaptive neighborhood sizes are implemented. Theoretical analysis shows our model's robustness to graph structure perturbations or adversarial attacks. We validate our approach through semi-supervised learning tasks on various datasets representing both homophilic and heterophilic graphs.</li>
</ul>

<h3>Title: General2Specialized LLMs Translation for E-commerce</h3>
<ul>
<li><strong>Authors: </strong>Kaidi Chen, Ben Chen, Dehong Gao, Huangyu Dai, Wen Jiang, Wei Ning, Shanqing Yu, Libin Yang, Xiaoyan Cai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03689">https://arxiv.org/abs/2403.03689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03689">https://arxiv.org/pdf/2403.03689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03689]] General2Specialized LLMs Translation for E-commerce(https://arxiv.org/abs/2403.03689)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Existing Neural Machine Translation (NMT) models mainly handle translation in the general domain, while overlooking domains with special writing formulas, such as e-commerce and legal documents. Taking e-commerce as an example, the texts usually include amounts of domain-related words and have more grammar problems, which leads to inferior performances of current NMT methods. To address these problems, we collect two domain-related resources, including a set of term pairs (aligned Chinese-English bilingual terms) and a parallel corpus annotated for the e-commerce domain. Furthermore, we propose a two-step fine-tuning paradigm (named G2ST) with self-contrastive semantic enhancement to transfer one general NMT model to the specialized NMT model for e-commerce. The paradigm can be used for the NMT models based on Large language models (LLMs). Extensive evaluations on real e-commerce titles demonstrate the superior translation quality and robustness of our G2ST approach, as compared with state-of-the-art NMT models such as LLaMA, Qwen, GPT-3.5, and even GPT-4.</li>
</ul>

<h3>Title: Rapidly Developing High-quality Instruction Data and Evaluation  Benchmark for Large Language Models with Minimal Human Effort: A Case Study  on Japanese</h3>
<ul>
<li><strong>Authors: </strong>Yikun Sun, Zhen Wan, Nobuhiro Ueda, Sakiko Yahata, Fei Cheng, Chenhui Chu, Sadao Kurohashi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03690">https://arxiv.org/abs/2403.03690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03690">https://arxiv.org/pdf/2403.03690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03690]] Rapidly Developing High-quality Instruction Data and Evaluation  Benchmark for Large Language Models with Minimal Human Effort: A Case Study  on Japanese(https://arxiv.org/abs/2403.03690)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The creation of instruction data and evaluation benchmarks for serving Large language models often involves enormous human annotation. This issue becomes particularly pronounced when rapidly developing such resources for a non-English language like Japanese. Instead of following the popular practice of directly translating existing English resources into Japanese (e.g., Japanese-Alpaca), we propose an efficient self-instruct method based on GPT-4. We first translate a small amount of English instructions into Japanese and post-edit them to obtain native-level quality. GPT-4 then utilizes them as demonstrations to automatically generate Japanese instruction data. We also construct an evaluation benchmark containing 80 questions across 8 categories, using GPT-4 to automatically assess the response quality of LLMs without human references. The empirical results suggest that the models fine-tuned on our GPT-4 self-instruct data significantly outperformed the Japanese-Alpaca across all three base pre-trained models. Our GPT-4 self-instruct data allowed the LLaMA 13B model to defeat GPT-3.5 (Davinci-003) with a 54.37\% win-rate. The human evaluation exhibits the consistency between GPT-4's assessments and human preference. Our high-quality instruction data and evaluation benchmark have been released here.</li>
</ul>

<h3>Title: MolNexTR: A Generalized Deep Learning Model for Molecular Image  Recognition</h3>
<ul>
<li><strong>Authors: </strong>Yufan Chen, Ching Ting Leung, Yong Huang, Jianwei Sun, Hao Chen, Hanyu Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03691">https://arxiv.org/abs/2403.03691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03691">https://arxiv.org/pdf/2403.03691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03691]] MolNexTR: A Generalized Deep Learning Model for Molecular Image  Recognition(https://arxiv.org/abs/2403.03691)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>In the field of chemical structure recognition, the task of converting molecular images into graph structures and SMILES string stands as a significant challenge, primarily due to the varied drawing styles and conventions prevalent in chemical literature. To bridge this gap, we proposed MolNexTR, a novel image-to-graph deep learning model that collaborates to fuse the strengths of ConvNext, a powerful Convolutional Neural Network variant, and Vision-TRansformer. This integration facilitates a more nuanced extraction of both local and global features from molecular images. MolNexTR can predict atoms and bonds simultaneously and understand their layout rules. It also excels at flexibly integrating symbolic chemistry principles to discern chirality and decipher abbreviated structures. We further incorporate a series of advanced algorithms, including improved data augmentation module, image contamination module, and a post-processing module to get the final SMILES output. These modules synergistically enhance the model's robustness against the diverse styles of molecular imagery found in real literature. In our test sets, MolNexTR has demonstrated superior performance, achieving an accuracy rate of 81-97%, marking a significant advancement in the domain of molecular structure recognition. Scientific contribution: MolNexTR is a novel image-to-graph model that incorporates a unique dual-stream encoder to extract complex molecular image features, and combines chemical rules to predict atoms and bonds while understanding atom and bond layout rules. In addition, it employs a series of novel augmentation algorithms to significantly enhance the robustness and performance of the model.</li>
</ul>

<h3>Title: Towards Controllable Time Series Generation</h3>
<ul>
<li><strong>Authors: </strong>Yifan Bao, Yihao Ang, Qiang Huang, Anthony K. H. Tung, Zhiyong Huang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03698">https://arxiv.org/abs/2403.03698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03698">https://arxiv.org/pdf/2403.03698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03698]] Towards Controllable Time Series Generation(https://arxiv.org/abs/2403.03698)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Time Series Generation (TSG) has emerged as a pivotal technique in synthesizing data that accurately mirrors real-world time series, becoming indispensable in numerous applications. Despite significant advancements in TSG, its efficacy frequently hinges on having large training datasets. This dependency presents a substantial challenge in data-scarce scenarios, especially when dealing with rare or unique conditions. To confront these challenges, we explore a new problem of Controllable Time Series Generation (CTSG), aiming to produce synthetic time series that can adapt to various external conditions, thereby tackling the data scarcity issue. In this paper, we propose \textbf{C}ontrollable \textbf{T}ime \textbf{S}eries (\textsf{CTS}), an innovative VAE-agnostic framework tailored for CTSG. A key feature of \textsf{CTS} is that it decouples the mapping process from standard VAE training, enabling precise learning of a complex interplay between latent features and external conditions. Moreover, we develop a comprehensive evaluation scheme for CTSG. Extensive experiments across three real-world time series datasets showcase \textsf{CTS}'s exceptional capabilities in generating high-quality, controllable outputs. This underscores its adeptness in seamlessly integrating latent features with external conditions. Extending \textsf{CTS} to the image domain highlights its remarkable potential for explainability and further reinforces its versatility across different modalities.</li>
</ul>

<h3>Title: Security Testing of RESTful APIs With Test Case Mutation</h3>
<ul>
<li><strong>Authors: </strong>Sebastien Salva, Jarod Sue</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03701">https://arxiv.org/abs/2403.03701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03701">https://arxiv.org/pdf/2403.03701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03701]] Security Testing of RESTful APIs With Test Case Mutation(https://arxiv.org/abs/2403.03701)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The focus of this paper is on automating the security testing of RESTful APIs. The testing stage of this specific kind of components is often performed manually, and this is yet considered as a long and difficult activity. This paper proposes an automated approach to help developers generate test cases for experimenting with each service in isolation. This approach is based upon the notion of test case mutation, which automatically generates new test cases from an original test case set. Test case mutation operators perform slight test case modifications to mimic possible failures or to test the component under test with new interactions. In this paper, we examine test case mutation operators for RESTful APIs and define 17 operators specialised in security testing. Then, we present our test case mutation algorithm. We evaluate its effectiveness and performance on four web service compositions.</li>
</ul>

<h3>Title: Causal Prototype-inspired Contrast Adaptation for Unsupervised Domain  Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery</h3>
<ul>
<li><strong>Authors: </strong>Jingru Zhu, Ya Guo, Geng Sun, Liang Hong, Jie Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03704">https://arxiv.org/abs/2403.03704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03704">https://arxiv.org/pdf/2403.03704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03704]] Causal Prototype-inspired Contrast Adaptation for Unsupervised Domain  Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery(https://arxiv.org/abs/2403.03704)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of high-resolution remote sensing imagery (HRSI) suffers from the domain shift, resulting in poor performance of the model in another unseen domain. Unsupervised domain adaptive (UDA) semantic segmentation aims to adapt the semantic segmentation model trained on the labeled source domain to an unlabeled target domain. However, the existing UDA semantic segmentation models tend to align pixels or features based on statistical information related to labels in source and target domain data, and make predictions accordingly, which leads to uncertainty and fragility of prediction results. In this paper, we propose a causal prototype-inspired contrast adaptation (CPCA) method to explore the invariant causal mechanisms between different HRSIs domains and their semantic labels. It firstly disentangles causal features and bias features from the source and target domain images through a causal feature disentanglement module. Then, a causal prototypical contrast module is used to learn domain invariant causal features. To further de-correlate causal and bias features, a causal intervention module is introduced to intervene on the bias features to generate counterfactual unbiased samples. By forcing the causal features to meet the principles of separability, invariance and intervention, CPCA can simulate the causal factors of source and target domains, and make decisions on the target domain based on the causal features, which can observe improved generalization ability. Extensive experiments under three cross-domain tasks indicate that CPCA is remarkably superior to the state-of-the-art methods.</li>
</ul>

<h3>Title: Multi-Grained Cross-modal Alignment for Learning Open-vocabulary  Semantic Segmentation from Text Supervision</h3>
<ul>
<li><strong>Authors: </strong>Yajie Liu, Pu Ge, Qingjie Liu, Di Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03707">https://arxiv.org/abs/2403.03707</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03707">https://arxiv.org/pdf/2403.03707</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03707]] Multi-Grained Cross-modal Alignment for Learning Open-vocabulary  Semantic Segmentation from Text Supervision(https://arxiv.org/abs/2403.03707)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recently, learning open-vocabulary semantic segmentation from text supervision has achieved promising downstream performance. Nevertheless, current approaches encounter an alignment granularity gap owing to the absence of dense annotations, wherein they learn coarse image/region-text alignment during training yet perform group/pixel-level predictions at inference. Such discrepancy leads to suboptimal learning efficiency and inferior zero-shot segmentation results. In this paper, we introduce a Multi-Grained Cross-modal Alignment (MGCA) framework, which explicitly learns pixel-level alignment along with object- and region-level alignment to bridge the granularity gap without any dense annotations. Specifically, MGCA ingeniously constructs pseudo multi-granular semantic correspondences upon image-text pairs and collaborates with hard sampling strategies to facilitate fine-grained cross-modal contrastive learning. Further, we point out the defects of existing group and pixel prediction units in downstream segmentation and develop an adaptive semantic unit which effectively mitigates their dilemmas including under- and over-segmentation. Training solely on CC3M, our method achieves significant advancements over state-of-the-art methods, demonstrating its effectiveness and efficiency.</li>
</ul>

<h3>Title: Multimodal Transformer for Comics Text-Cloze</h3>
<ul>
<li><strong>Authors: </strong>Emanuele Vivoli, Joan Lafuente Baeza, Ernest Valveny Llobet, Dimosthenis Karatzas</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03719">https://arxiv.org/abs/2403.03719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03719">https://arxiv.org/pdf/2403.03719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03719]] Multimodal Transformer for Comics Text-Cloze(https://arxiv.org/abs/2403.03719)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>This work explores a closure task in comics, a medium where visual and textual elements are intricately intertwined. Specifically, Text-cloze refers to the task of selecting the correct text to use in a comic panel, given its neighboring panels. Traditional methods based on recurrent neural networks have struggled with this task due to limited OCR accuracy and inherent model limitations. We introduce a novel Multimodal Large Language Model (Multimodal-LLM) architecture, specifically designed for Text-cloze, achieving a 10% improvement over existing state-of-the-art models in both its easy and hard variants. Central to our approach is a Domain-Adapted ResNet-50 based visual encoder, fine-tuned to the comics domain in a self-supervised manner using SimCLR. This encoder delivers comparable results to more complex models with just one-fifth of the parameters. Additionally, we release new OCR annotations for this dataset, enhancing model input quality and resulting in another 1% improvement. Finally, we extend the task to a generative format, establishing new baselines and expanding the research possibilities in the field of comics analysis.</li>
</ul>

<h3>Title: Diffusion on language model embeddings for protein sequence generation</h3>
<ul>
<li><strong>Authors: </strong>Viacheslav Meshchaninov, Pavel Strashnov, Andrey Shevtsov, Fedor Nikolaev, Nikita Ivanisenko, Olga Kardymon, Dmitry Vetrov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03726">https://arxiv.org/abs/2403.03726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03726">https://arxiv.org/pdf/2403.03726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03726]] Diffusion on language model embeddings for protein sequence generation(https://arxiv.org/abs/2403.03726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Protein design requires a deep understanding of the inherent complexities of the protein universe. While many efforts lean towards conditional generation or focus on specific families of proteins, the foundational task of unconditional generation remains underexplored and undervalued. Here, we explore this pivotal domain, introducing DiMA, a model that leverages continuous diffusion on embeddings derived from the protein language model, ESM-2, to generate amino acid sequences. DiMA surpasses leading solutions, including autoregressive transformer-based and discrete diffusion models, and we quantitatively illustrate the impact of the design choices that lead to its superior performance. We extensively evaluate the quality, diversity, distribution similarity, and biological relevance of the generated sequences using multiple metrics across various modalities. Our approach consistently produces novel, diverse protein sequences that accurately reflect the inherent structural and functional diversity of the protein space. This work advances the field of protein design and sets the stage for conditional models by providing a robust framework for scalable and high-quality protein sequence generation.</li>
</ul>

<h3>Title: Unifying Generation and Compression: Ultra-low bitrate Image Coding Via  Multi-stage Transformer</h3>
<ul>
<li><strong>Authors: </strong>Naifu Xue, Qi Mao, Zijian Wang, Yuan Zhang, Siwei Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03736">https://arxiv.org/abs/2403.03736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03736">https://arxiv.org/pdf/2403.03736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03736]] Unifying Generation and Compression: Ultra-low bitrate Image Coding Via  Multi-stage Transformer(https://arxiv.org/abs/2403.03736)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Recent progress in generative compression technology has significantly improved the perceptual quality of compressed data. However, these advancements primarily focus on producing high-frequency details, often overlooking the ability of generative models to capture the prior distribution of image content, thus impeding further bitrate reduction in extreme compression scenarios (<0.05 bpp). Motivated by the capabilities of predictive language models for lossless compression, this paper introduces a novel Unified Image Generation-Compression (UIGC) paradigm, merging the processes of generation and compression. A key feature of the UIGC framework is the adoption of vector-quantized (VQ) image models for tokenization, alongside a multi-stage transformer designed to exploit spatial contextual information for modeling the prior distribution. As such, the dual-purpose framework effectively utilizes the learned prior for entropy estimation and assists in the regeneration of lost tokens. Extensive experiments demonstrate the superiority of the proposed UIGC framework over existing codecs in perceptual quality and human perception, particularly in ultra-low bitrate scenarios (<=0.03 bpp), pioneering a new direction in generative compression.</li>
</ul>

<h3>Title: Probabilistic Topic Modelling with Transformer Representations</h3>
<ul>
<li><strong>Authors: </strong>Arik Reuter, Anton Thielmann, Christoph Weisser, Benjamin Säfken, Thomas Kneib</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03737">https://arxiv.org/abs/2403.03737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03737">https://arxiv.org/pdf/2403.03737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03737]] Probabilistic Topic Modelling with Transformer Representations(https://arxiv.org/abs/2403.03737)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Topic modelling was mostly dominated by Bayesian graphical models during the last decade. With the rise of transformers in Natural Language Processing, however, several successful models that rely on straightforward clustering approaches in transformer-based embedding spaces have emerged and consolidated the notion of topics as clusters of embedding vectors. We propose the Transformer-Representation Neural Topic Model (TNTM), which combines the benefits of topic representations in transformer-based embedding spaces and probabilistic modelling. Therefore, this approach unifies the powerful and versatile notion of topics based on transformer embeddings with fully probabilistic modelling, as in models such as Latent Dirichlet Allocation (LDA). We utilize the variational autoencoder (VAE) framework for improved inference speed and modelling flexibility. Experimental results show that our proposed model achieves results on par with various state-of-the-art approaches in terms of embedding coherence while maintaining almost perfect topic diversity. The corresponding source code is available at https://github.com/ArikReuter/TNTM.</li>
</ul>

<h3>Title: German also Hallucinates! Inconsistency Detection in News Summaries with  the Absinth Dataset</h3>
<ul>
<li><strong>Authors: </strong>Laura Mascarell, Ribin Chalumattu, Annette Rios</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03750">https://arxiv.org/abs/2403.03750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03750">https://arxiv.org/pdf/2403.03750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03750]] German also Hallucinates! Inconsistency Detection in News Summaries with  the Absinth Dataset(https://arxiv.org/abs/2403.03750)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and release the absinth dataset to foster further research on hallucination detection in German.</li>
</ul>

<h3>Title: Verified Training for Counterfactual Explanation Robustness under Data  Shift</h3>
<ul>
<li><strong>Authors: </strong>Anna P. Meyer, Yuhao Zhang, Aws Albarghouthi, Loris D'Antoni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03773">https://arxiv.org/abs/2403.03773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03773">https://arxiv.org/pdf/2403.03773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03773]] Verified Training for Counterfactual Explanation Robustness under Data  Shift(https://arxiv.org/abs/2403.03773)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations (CEs) enhance the interpretability of machine learning models by describing what changes to an input are necessary to change its prediction to a desired class. These explanations are commonly used to guide users' actions, e.g., by describing how a user whose loan application was denied can be approved for a loan in the future. Existing approaches generate CEs by focusing on a single, fixed model, and do not provide any formal guarantees on the CEs' future validity. When models are updated periodically to account for data shift, if the generated CEs are not robust to the shifts, users' actions may no longer have the desired impacts on their predictions. This paper introduces VeriTraCER, an approach that jointly trains a classifier and an explainer to explicitly consider the robustness of the generated CEs to small model shifts. VeriTraCER optimizes over a carefully designed loss function that ensures the verifiable robustness of CEs to local model updates, thus providing deterministic guarantees to CE validity. Our empirical evaluation demonstrates that VeriTraCER generates CEs that (1) are verifiably robust to small model updates and (2) display competitive robustness to state-of-the-art approaches in handling empirical model updates including random initialization, leave-one-out, and distribution shifts.</li>
</ul>

<h3>Title: PPTC-R benchmark: Towards Evaluating the Robustness of Large Language  Models for PowerPoint Task Completion</h3>
<ul>
<li><strong>Authors: </strong>Zekai Zhang, Yiduo Guo, Yaobo Liang, Dongyan Zhao, Nan Duan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03788">https://arxiv.org/abs/2403.03788</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03788">https://arxiv.org/pdf/2403.03788</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03788]] PPTC-R benchmark: Towards Evaluating the Robustness of Large Language  Models for PowerPoint Task Completion(https://arxiv.org/abs/2403.03788)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The growing dependence on Large Language Models (LLMs) for finishing user instructions necessitates a comprehensive understanding of their robustness to complex task completion in real-world situations. To address this critical need, we propose the PowerPoint Task Completion Robustness benchmark (PPTC-R) to measure LLMs' robustness to the user PPT task instruction and software version. Specifically, we construct adversarial user instructions by attacking user instructions at sentence, semantic, and multi-language levels. To assess the robustness of Language Models to software versions, we vary the number of provided APIs to simulate both the newest version and earlier version settings. Subsequently, we test 3 closed-source and 4 open-source LLMs using a benchmark that incorporates these robustness settings, aiming to evaluate how deviations impact LLMs' API calls for task completion. We find that GPT-4 exhibits the highest performance and strong robustness in our benchmark, particularly in the version update and the multilingual settings. However, we find that all LLMs lose their robustness when confronted with multiple challenges (e.g., multi-turn) simultaneously, leading to significant performance drops. We further analyze the robustness behavior and error reasons of LLMs in our benchmark, which provide valuable insights for researchers to understand the LLM's robustness in task completion and develop more robust LLMs and agents. We release the code and data at \url{https://github.com/ZekaiGalaxy/PPTCR}.</li>
</ul>

<h3>Title: Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection  from Remote Sensing Imagery</h3>
<ul>
<li><strong>Authors: </strong>Wei Zhang, Miaoxin Cai, Tong Zhang, Guoqiang Lei, Yin Zhuang, Xuerui Mao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03790">https://arxiv.org/abs/2403.03790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03790">https://arxiv.org/pdf/2403.03790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03790]] Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection  from Remote Sensing Imagery(https://arxiv.org/abs/2403.03790)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Ship detection needs to identify ship locations from remote sensing (RS) scenes. However, due to different imaging payloads, various appearances of ships, and complicated background interference from the bird's eye view, it is difficult to set up a unified paradigm for achieving multi-source ship detection. Therefore, in this article, considering that the large language models (LLMs) emerge the powerful generalization ability, a novel unified visual-language model called Popeye is proposed for multi-source ship detection from RS imagery. First, to bridge the interpretation gap between multi-source images for ship detection, a novel image-instruction-answer way is designed to integrate the various ship detection ways (e.g., horizontal bounding box (HBB), oriented bounding box (OBB)) into a unified labeling paradigm. Then, in view of this, a cross-modal image interpretation method is developed for the proposed Popeye to enhance interactive comprehension ability between visual and language content, which can be easily migrated into any multi-source ship detection task. Subsequently, owing to objective domain differences, a knowledge adaption mechanism is designed to adapt the pre-trained visual-language knowledge from the nature scene into the RS domain for multi-source ship detection. In addition, the segment anything model (SAM) is also seamlessly integrated into the proposed Popeye to achieve pixel-level ship segmentation without additional training costs. Finally, extensive experiments are conducted on the newly constructed instruction dataset named MMShip, and the results indicate that the proposed Popeye outperforms current specialist, open-vocabulary, and other visual-language models for zero-shot multi-source ship detection.</li>
</ul>

<h3>Title: Neural Exec: Learning (and Learning from) Execution Triggers for Prompt  Injection Attacks</h3>
<ul>
<li><strong>Authors: </strong>Dario Pasquini, Martin Strohmeier, Carmela Troncoso</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03792">https://arxiv.org/abs/2403.03792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03792">https://arxiv.org/pdf/2403.03792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03792]] Neural Exec: Learning (and Learning from) Execution Triggers for Prompt  Injection Attacks(https://arxiv.org/abs/2403.03792)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>We introduce a new family of prompt injection attacks, termed Neural Exec. Unlike known attacks that rely on handcrafted strings (e.g., "Ignore previous instructions and..."), we show that it is possible to conceptualize the creation of execution triggers as a differentiable search problem and use learning-based methods to autonomously generate them. Our results demonstrate that a motivated adversary can forge triggers that are not only drastically more effective than current handcrafted ones but also exhibit inherent flexibility in shape, properties, and functionality. In this direction, we show that an attacker can design and generate Neural Execs capable of persisting through multi-stage preprocessing pipelines, such as in the case of Retrieval-Augmented Generation (RAG)-based applications. More critically, our findings show that attackers can produce triggers that deviate markedly in form and shape from any known attack, sidestepping existing blacklist-based detection and sanitation approaches.</li>
</ul>

<h3>Title: ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing</h3>
<ul>
<li><strong>Authors: </strong>Kiran Madhusudhanan, Gunnar Behrens, Maximilian Stubbemann, Lars Schmidt-Thieme</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03812">https://arxiv.org/abs/2403.03812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03812">https://arxiv.org/pdf/2403.03812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03812]] ProbSAINT: Probabilistic Tabular Regression for Used Car Pricing(https://arxiv.org/abs/2403.03812)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Used car pricing is a critical aspect of the automotive industry, influenced by many economic factors and market dynamics. With the recent surge in online marketplaces and increased demand for used cars, accurate pricing would benefit both buyers and sellers by ensuring fair transactions. However, the transition towards automated pricing algorithms using machine learning necessitates the comprehension of model uncertainties, specifically the ability to flag predictions that the model is unsure about. Although recent literature proposes the use of boosting algorithms or nearest neighbor-based approaches for swift and precise price predictions, encapsulating model uncertainties with such algorithms presents a complex challenge. We introduce ProbSAINT, a model that offers a principled approach for uncertainty quantification of its price predictions, along with accurate point predictions that are comparable to state-of-the-art boosting techniques. Furthermore, acknowledging that the business prefers pricing used cars based on the number of days the vehicle was listed for sale, we show how ProbSAINT can be used as a dynamic forecasting model for predicting price probabilities for different expected offer duration. Our experiments further indicate that ProbSAINT is especially accurate on instances where it is highly certain. This proves the applicability of its probabilistic predictions in real-world scenarios where trustworthiness is crucial.</li>
</ul>

<h3>Title: Evaluating the Elementary Multilingual Capabilities of Large Language  Models with MultiQ</h3>
<ul>
<li><strong>Authors: </strong>Carolin Holtermann, Paul Röttger, Timm Dill, Anne Lauscher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03814">https://arxiv.org/abs/2403.03814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03814">https://arxiv.org/pdf/2403.03814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03814]] Evaluating the Elementary Multilingual Capabilities of Large Language  Models with MultiQ(https://arxiv.org/abs/2403.03814)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) need to serve everyone, including a global majority of non-English speakers. However, most LLMs today, and open LLMs in particular, are often intended for use in just English (e.g. Llama2, Mistral) or a small handful of high-resource languages (e.g. Mixtral, Qwen). Recent research shows that, despite limits in their intended use, people prompt LLMs in many different languages. Therefore, in this paper, we investigate the basic multilingual capabilities of state-of-the-art open LLMs beyond their intended use. For this purpose, we introduce MultiQ, a new silver standard benchmark for basic open-ended question answering with 27.4k test questions across a typologically diverse set of 137 languages. With MultiQ, we evaluate language fidelity, i.e.\ whether models respond in the prompted language, and question answering accuracy. All LLMs we test respond faithfully and/or accurately for at least some languages beyond their intended use. Most models are more accurate when they respond faithfully. However, differences across models are large, and there is a long tail of languages where models are neither accurate nor faithful. We explore differences in tokenization as a potential explanation for our findings, identifying possible correlations that warrant further investigation.</li>
</ul>

<h3>Title: Feature Selection as Deep Sequential Generative Learning</h3>
<ul>
<li><strong>Authors: </strong>Wangyang Ying, Dongjie Wang, Haifeng Chen, Yanjie Fu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03838">https://arxiv.org/abs/2403.03838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03838">https://arxiv.org/pdf/2403.03838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03838]] Feature Selection as Deep Sequential Generative Learning(https://arxiv.org/abs/2403.03838)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Feature selection aims to identify the most pattern-discriminative feature subset. In prior literature, filter (e.g., backward elimination) and embedded (e.g., Lasso) methods have hyperparameters (e.g., top-K, score thresholding) and tie to specific models, thus, hard to generalize; wrapper methods search a feature subset in a huge discrete space and is computationally costly. To transform the way of feature selection, we regard a selected feature subset as a selection decision token sequence and reformulate feature selection as a deep sequential generative learning task that distills feature knowledge and generates decision sequences. Our method includes three steps: (1) We develop a deep variational transformer model over a joint of sequential reconstruction, variational, and performance evaluator losses. Our model can distill feature selection knowledge and learn a continuous embedding space to map feature selection decision sequences into embedding vectors associated with utility scores. (2) We leverage the trained feature subset utility evaluator as a gradient provider to guide the identification of the optimal feature subset embedding;(3) We decode the optimal feature subset embedding to autoregressively generate the best feature selection decision sequence with autostop. Extensive experimental results show this generative perspective is effective and generic, without large discrete search space and expert-specific hyperparameters.</li>
</ul>

<h3>Title: On the Effectiveness of Distillation in Mitigating Backdoors in  Pre-trained Encoder</h3>
<ul>
<li><strong>Authors: </strong>Tingxu Han, Shenghan Huang, Ziqi Ding, Weisong Sun, Yebo Feng, Chunrong Fang, Jun Li, Hanwei Qian, Cong Wu, Quanjun Zhang, Yang Liu, Zhenyu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03846">https://arxiv.org/abs/2403.03846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03846">https://arxiv.org/pdf/2403.03846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03846]] On the Effectiveness of Distillation in Mitigating Backdoors in  Pre-trained Encoder(https://arxiv.org/abs/2403.03846)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>In this paper, we study a defense against poisoned encoders in SSL called distillation, which is a defense used in supervised learning originally. Distillation aims to distill knowledge from a given model (a.k.a the teacher net) and transfer it to another (a.k.a the student net). Now, we use it to distill benign knowledge from poisoned pre-trained encoders and transfer it to a new encoder, resulting in a clean pre-trained encoder. In particular, we conduct an empirical study on the effectiveness and performance of distillation against poisoned encoders. Using two state-of-the-art backdoor attacks against pre-trained image encoders and four commonly used image classification datasets, our experimental results show that distillation can reduce attack success rate from 80.87% to 27.51% while suffering a 6.35% loss in accuracy. Moreover, we investigate the impact of three core components of distillation on performance: teacher net, student net, and distillation loss. By comparing 4 different teacher nets, 3 student nets, and 6 distillation losses, we find that fine-tuned teacher nets, warm-up-training-based student nets, and attention-based distillation loss perform best, respectively.</li>
</ul>

<h3>Title: Accelerating Convergence of Score-Based Diffusion Models, Provably</h3>
<ul>
<li><strong>Authors: </strong>Gen Li, Yu Huang, Timofey Efimov, Yuting Wei, Yuejie Chi, Yuxin Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03852">https://arxiv.org/abs/2403.03852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03852">https://arxiv.org/pdf/2403.03852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03852]] Accelerating Convergence of Score-Based Diffusion Models, Provably(https://arxiv.org/abs/2403.03852)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Score-based diffusion models, while achieving remarkable empirical performance, often suffer from low sampling speed, due to extensive function evaluations needed during the sampling phase. Despite a flurry of recent activities towards speeding up diffusion generative modeling in practice, theoretical underpinnings for acceleration techniques remain severely limited. In this paper, we design novel training-free algorithms to accelerate popular deterministic (i.e., DDIM) and stochastic (i.e., DDPM) samplers. Our accelerated deterministic sampler converges at a rate $O(1/{T}^2)$ with $T$ the number of steps, improving upon the $O(1/T)$ rate for the DDIM sampler; and our accelerated stochastic sampler converges at a rate $O(1/T)$, outperforming the rate $O(1/\sqrt{T})$ for the DDPM sampler. The design of our algorithms leverages insights from higher-order approximation, and shares similar intuitions as popular high-order ODE solvers like the DPM-Solver-2. Our theory accommodates $\ell_2$-accurate score estimates, and does not require log-concavity or smoothness on the target distribution.</li>
</ul>

<h3>Title: ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect</h3>
<ul>
<li><strong>Authors: </strong>Xin Men, Mingyu Xu, Qingyu Zhang, Bingning Wang, Hongyu Lin, Yaojie Lu, Xianpei Han, Weipeng Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03853">https://arxiv.org/abs/2403.03853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03853">https://arxiv.org/pdf/2403.03853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03853]] ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect(https://arxiv.org/abs/2403.03853)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) continue to advance in performance, their size has escalated significantly, with current LLMs containing billions or even trillions of parameters. However, in this study, we discovered that many layers of LLMs exhibit high similarity, and some layers play a negligible role in network functionality. Based on this observation, we define a metric called Block Influence (BI) to gauge the significance of each layer in LLMs. We then propose a straightforward pruning approach: layer removal, in which we directly delete the redundant layers in LLMs based on their BI scores. Experiments demonstrate that our method, which we call ShortGPT, significantly outperforms previous state-of-the-art (SOTA) methods in model pruning. Moreover, ShortGPT is orthogonal to quantization-like methods, enabling further reduction in parameters and computation. The ability to achieve better results through simple layer removal, as opposed to more complex pruning techniques, suggests a high degree of redundancy in the model architecture.</li>
</ul>

<h3>Title: ECAP: Extensive Cut-and-Paste Augmentation for Unsupervised Domain  Adaptive Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Erik Brorsson, Knut Åkesson, Lennart Svensson, Kristofer Bengtsson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03854">https://arxiv.org/abs/2403.03854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03854">https://arxiv.org/pdf/2403.03854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03854]] ECAP: Extensive Cut-and-Paste Augmentation for Unsupervised Domain  Adaptive Semantic Segmentation(https://arxiv.org/abs/2403.03854)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We consider unsupervised domain adaptation (UDA) for semantic segmentation in which the model is trained on a labeled source dataset and adapted to an unlabeled target dataset. Unfortunately, current self-training methods are susceptible to misclassified pseudo-labels resulting from erroneous predictions. Since certain classes are typically associated with less reliable predictions in UDA, reducing the impact of such pseudo-labels without skewing the training towards some classes is notoriously difficult. To this end, we propose an extensive cut-and-paste strategy (ECAP) to leverage reliable pseudo-labels through data augmentation. Specifically, ECAP maintains a memory bank of pseudo-labeled target samples throughout training and cut-and-pastes the most confident ones onto the current training batch. We implement ECAP on top of the recent method MIC and boost its performance on two synthetic-to-real domain adaptation benchmarks. Notably, MIC+ECAP reaches an unprecedented performance of 69.1 mIoU on the Synthia->Cityscapes benchmark. Our code is available at https://github.com/ErikBrorsson/ECAP.</li>
</ul>

<h3>Title: Emojinize : Enriching Any Text with Emoji Translations</h3>
<ul>
<li><strong>Authors: </strong>Lars Henning Klein, Roland Aydin, Robert West</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03857">https://arxiv.org/abs/2403.03857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03857">https://arxiv.org/pdf/2403.03857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03857]] Emojinize : Enriching Any Text with Emoji Translations(https://arxiv.org/abs/2403.03857)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Emoji have become ubiquitous in written communication, on the Web and beyond. They can emphasize or clarify emotions, add details to conversations, or simply serve decorative purposes. This casual use, however, barely scratches the surface of the expressive power of emoji. To further unleash this power, we present Emojinize, a method for translating arbitrary text phrases into sequences of one or more emoji without requiring human input. By leveraging the power of large language models, Emojinize can choose appropriate emoji by disambiguating based on context (eg, cricket-bat vs bat) and can express complex concepts compositionally by combining multiple emoji (eq, ''Emojinize'' is translated to input-latin-letters right-arrow grinning-face). In a cloze test--based user study, we show that Emojinize's emoji translations increase the human guessability of masked words by 55%, whereas human-picked emoji translations do so by only 29%. These results suggest that emoji provide a sufficiently rich vocabulary to accurately translate a wide variety of words. Moreover, annotating words and phrases with Emojinize's emoji translations opens the door to numerous downstream applications, including children learning how to read, adults learning foreign languages, and text understanding for people with learning disabilities.</li>
</ul>

<h3>Title: Exploring Jamming and Hijacking Attacks for Micro Aerial Drones</h3>
<ul>
<li><strong>Authors: </strong>Yassine Mekdad, Abbas Acar, Ahmet Aris, Abdeslam El Fergougui, Mauro Conti, Riccardo Lazzeretti, Selcuk Uluagac</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03858">https://arxiv.org/abs/2403.03858</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03858">https://arxiv.org/pdf/2403.03858</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03858]] Exploring Jamming and Hijacking Attacks for Micro Aerial Drones(https://arxiv.org/abs/2403.03858)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Recent advancements in drone technology have shown that commercial off-the-shelf Micro Aerial Drones are more effective than large-sized drones for performing flight missions in narrow environments, such as swarming, indoor navigation, and inspection of hazardous locations. Due to their deployments in many civilian and military applications, safe and reliable communication of these drones throughout the mission is critical. The Crazyflie ecosystem is one of the most popular Micro Aerial Drones and has the potential to be deployed worldwide. In this paper, we empirically investigate two interference attacks against the Crazy Real Time Protocol (CRTP) implemented within the Crazyflie drones. In particular, we explore the feasibility of experimenting two attack vectors that can disrupt an ongoing flight mission: the jamming attack, and the hijacking attack. Our experimental results demonstrate the effectiveness of such attacks in both autonomous and non-autonomous flight modes on a Crazyflie 2.1 drone. Finally, we suggest potential shielding strategies that guarantee a safe and secure flight mission. To the best of our knowledge, this is the first work investigating jamming and hijacking attacks against Micro Aerial Drones, both in autonomous and non-autonomous modes.</li>
</ul>

<h3>Title: X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot  Learning Simultaneously in Classification</h3>
<ul>
<li><strong>Authors: </strong>Hanzi Xu, Muhao Chen, Lifu Huang, Slobodan Vucetic, Wenpeng Yin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03863">https://arxiv.org/abs/2403.03863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03863">https://arxiv.org/pdf/2403.03863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03863]] X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot  Learning Simultaneously in Classification(https://arxiv.org/abs/2403.03863)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, few-shot and zero-shot learning, which learn to predict labels with limited annotated instances, have garnered significant attention. Traditional approaches often treat frequent-shot (freq-shot; labels with abundant instances), few-shot, and zero-shot learning as distinct challenges, optimizing systems for just one of these scenarios. Yet, in real-world settings, label occurrences vary greatly. Some of them might appear thousands of times, while others might only appear sporadically or not at all. For practical deployment, it is crucial that a system can adapt to any label occurrence. We introduce a novel classification challenge: X-shot, reflecting a real-world context where freq-shot, few-shot, and zero-shot labels co-occur without predefined limits. Here, X can span from 0 to positive infinity. The crux of X-shot centers on open-domain generalization and devising a system versatile enough to manage various label scenarios. To solve X-shot, we propose BinBin (Binary INference Based on INstruction following) that leverages the Indirect Supervision from a large collection of NLP tasks via instruction following, bolstered by Weak Supervision provided by large language models. BinBin surpasses previous state-of-the-art techniques on three benchmark datasets across multiple domains. To our knowledge, this is the first work addressing X-shot learning, where X remains variable.</li>
</ul>

<h3>Title: Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious  Challenges in Multimodal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Deepanway Ghosal, Vernon Toh Yan Han, Chia Yew Ken, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03864">https://arxiv.org/abs/2403.03864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03864">https://arxiv.org/pdf/2403.03864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03864]] Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious  Challenges in Multimodal Reasoning(https://arxiv.org/abs/2403.03864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces the novel task of multimodal puzzle solving, framed within the context of visual question-answering. We present a new dataset, AlgoPuzzleVQA designed to challenge and evaluate the capabilities of multimodal language models in solving algorithmic puzzles that necessitate both visual understanding, language understanding, and complex algorithmic reasoning. We create the puzzles to encompass a diverse array of mathematical and algorithmic topics such as boolean logic, combinatorics, graph theory, optimization, search, etc., aiming to evaluate the gap between visual data interpretation and algorithmic problem-solving skills. The dataset is generated automatically from code authored by humans. All our puzzles have exact solutions that can be found from the algorithm without tedious human calculations. It ensures that our dataset can be scaled up arbitrarily in terms of reasoning complexity and dataset size. Our investigation reveals that large language models (LLMs) such as GPT4V and Gemini exhibit limited performance in puzzle-solving tasks. We find that their performance is near random in a multi-choice question-answering setup for a significant number of puzzles. The findings emphasize the challenges of integrating visual, language, and algorithmic knowledge for solving complex reasoning problems.</li>
</ul>

<h3>Title: KIWI: A Dataset of Knowledge-Intensive Writing Instructions for  Answering Research Questions</h3>
<ul>
<li><strong>Authors: </strong>Fangyuan Xu, Kyle Lo, Luca Soldaini, Bailey Kuehl, Eunsol Choi, David Wadden</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03866">https://arxiv.org/abs/2403.03866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03866">https://arxiv.org/pdf/2403.03866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03866]] KIWI: A Dataset of Knowledge-Intensive Writing Instructions for  Answering Research Questions(https://arxiv.org/abs/2403.03866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) adapted to follow user instructions are now widely deployed as conversational agents. In this work, we examine one increasingly common instruction-following task: providing writing assistance to compose a long-form answer. To evaluate the capabilities of current LLMs on this task, we construct KIWI, a dataset of knowledge-intensive writing instructions in the scientific domain. Given a research question, an initial model-generated answer and a set of relevant papers, an expert annotator iteratively issues instructions for the model to revise and improve its answer. We collect 1,260 interaction turns from 234 interaction sessions with three state-of-the-art LLMs. Each turn includes a user instruction, a model response, and a human evaluation of the model response. Through a detailed analysis of the collected responses, we find that all models struggle to incorporate new information into an existing answer, and to perform precise and unambiguous edits. Further, we find that models struggle to judge whether their outputs successfully followed user instructions, with accuracy at least 10 points short of human agreement. Our findings indicate that KIWI will be a valuable resource to measure progress and improve LLMs' instruction-following capabilities for knowledge intensive writing tasks.</li>
</ul>

<h3>Title: On the Origins of Linear Representations in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yibo Jiang, Goutham Rajendran, Pradeep Ravikumar, Bryon Aragam, Victor Veitch</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03867">https://arxiv.org/abs/2403.03867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03867">https://arxiv.org/pdf/2403.03867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03867]] On the Origins of Linear Representations in Large Language Models(https://arxiv.org/abs/2403.03867)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent works have argued that high-level semantic concepts are encoded "linearly" in the representation space of large language models. In this work, we study the origins of such linear representations. To that end, we introduce a simple latent variable model to abstract and formalize the concept dynamics of the next token prediction. We use this formalism to show that the next token prediction objective (softmax with cross-entropy) and the implicit bias of gradient descent together promote the linear representation of concepts. Experiments show that linear representations emerge when learning from data matching the latent variable model, confirming that this simple structure already suffices to yield linear representations. We additionally confirm some predictions of the theory using the LLaMA-2 large language model, giving evidence that the simplified model yields generalizable insights.</li>
</ul>

<h3>Title: Learning to Decode Collaboratively with Multiple Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shannon Zejiang Shen, Hunter Lang, Bailin Wang, Yoon Kim, David Sontag</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03870">https://arxiv.org/abs/2403.03870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03870">https://arxiv.org/pdf/2403.03870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03870]] Learning to Decode Collaboratively with Multiple Language Models(https://arxiv.org/abs/2403.03870)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose a method to teach multiple large language models (LLM) to collaborate by interleaving their generations at the token level. We model the decision of which LLM generates the next token as a latent variable. By optimizing the marginal likelihood of a training set under our latent variable model, the base LLM automatically learns when to generate itself and when to call on one of the ``assistant'' language models to generate, all without direct supervision. Token-level collaboration during decoding allows for a fusion of each model's expertise in a manner tailored to the specific task at hand. Our collaborative decoding is especially useful in cross-domain settings where a generalist base LLM learns to invoke domain expert models. On instruction-following, domain-specific QA, and reasoning tasks, we show that the performance of the joint system exceeds that of the individual models. Through qualitative analysis of the learned latent decisions, we show models trained with our method exhibit several interesting collaboration patterns, e.g., template-filling. Our code is available at https://github.com/clinicalml/co-llm.</li>
</ul>

<h3>Title: Decoupled Vertical Federated Learning for Practical Training on  Vertically Partitioned Data</h3>
<ul>
<li><strong>Authors: </strong>Avi Amalanshu, Yash Sirvi, David I. Inouye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03871">https://arxiv.org/abs/2403.03871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03871">https://arxiv.org/pdf/2403.03871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03871]] Decoupled Vertical Federated Learning for Practical Training on  Vertically Partitioned Data(https://arxiv.org/abs/2403.03871)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, federate</a></li>
<li><strong>Abstract: </strong>Vertical Federated Learning (VFL) is an emergent distributed machine learning paradigm wherein owners of disjoint features of a common set of entities collaborate to learn a global model without sharing data. In VFL, a host client owns data labels for each entity and learns a final representation based on intermediate local representations from all guest clients. Therefore, the host is a single point of failure and label feedback can be used by malicious guest clients to infer private features. Requiring all participants to remain active and trustworthy throughout the entire training process is generally impractical and altogether infeasible outside of controlled environments. We propose Decoupled VFL (DVFL), a blockwise learning approach to VFL. By training each model on its own objective, DVFL allows for decentralized aggregation and isolation between feature learning and label supervision. With these properties, DVFL is fault tolerant and secure. We implement DVFL to train split neural networks and show that model performance is comparable to VFL on a variety of classification datasets.</li>
</ul>

<h3>Title: Redefining cystoscopy with ai: bladder cancer diagnosis using an  efficient hybrid cnn-transformer model</h3>
<ul>
<li><strong>Authors: </strong>Meryem Amaouche, Ouassim Karrakchou, Mounir Ghogho, Anouar El Ghazzaly, Mohamed Alami, Ahmed Ameur</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03879">https://arxiv.org/abs/2403.03879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03879">https://arxiv.org/pdf/2403.03879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03879]] Redefining cystoscopy with ai: bladder cancer diagnosis using an  efficient hybrid cnn-transformer model(https://arxiv.org/abs/2403.03879)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Bladder cancer ranks within the top 10 most diagnosed cancers worldwide and is among the most expensive cancers to treat due to the high recurrence rates which require lifetime follow-ups. The primary tool for diagnosis is cystoscopy, which heavily relies on doctors' expertise and interpretation. Therefore, annually, numerous cases are either undiagnosed or misdiagnosed and treated as urinary infections. To address this, we suggest a deep learning approach for bladder cancer detection and segmentation which combines CNNs with a lightweight positional-encoding-free transformer and dual attention gates that fuse self and spatial attention for feature enhancement. The architecture suggested in this paper is efficient making it suitable for medical scenarios that require real time inference. Experiments have proven that this model addresses the critical need for a balance between computational efficiency and diagnostic accuracy in cystoscopic imaging as despite its small size it rivals large models in performance.</li>
</ul>

<h3>Title: Graph neural network outputs are almost surely asymptotically constant</h3>
<ul>
<li><strong>Authors: </strong>Sam Adam-Day, Michael Benedikt, İsmail İlkan Ceylan, Ben Finkelshtein</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03880">https://arxiv.org/abs/2403.03880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03880">https://arxiv.org/pdf/2403.03880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03880]] Graph neural network outputs are almost surely asymptotically constant(https://arxiv.org/abs/2403.03880)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Graph neural networks (GNNs) are the predominant architectures for a variety of learning tasks on graphs. We present a new angle on the expressive power of GNNs by studying how the predictions of a GNN probabilistic classifier evolve as we apply it on larger graphs drawn from some random graph model. We show that the output converges to a constant function, which upper-bounds what these classifiers can express uniformly. This convergence phenomenon applies to a very wide class of GNNs, including state of the art models, with aggregates including mean and the attention-based mechanism of graph transformers. Our results apply to a broad class of random graph models, including the (sparse) Erd\H{o}s-R\'enyi model and the stochastic block model. We empirically validate these findings, observing that the convergence phenomenon already manifests itself on graphs of relatively modest size.</li>
</ul>

<h3>Title: Latent Dataset Distillation with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03881">https://arxiv.org/abs/2403.03881</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03881">https://arxiv.org/pdf/2403.03881</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03881]] Latent Dataset Distillation with Diffusion Models(https://arxiv.org/abs/2403.03881)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both challenges. LD3M incorporates a novel diffusion process tailored for dataset distillation, which improves the gradient norms for learning synthetic images. By adjusting the number of diffusion steps, LD3M also offers a straightforward way of controlling the trade-off between speed and accuracy. We evaluate our approach in several ImageNet subsets and for high-resolution images (128x128 and 256x256). As a result, LD3M consistently outperforms state-of-the-art distillation techniques by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively.</li>
</ul>

<h3>Title: Self and Mixed Supervision to Improve Training Labels for Multi-Class  Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Jianfei Liu, Christopher Parnell, Ronald M. Summers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03882">https://arxiv.org/abs/2403.03882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03882">https://arxiv.org/pdf/2403.03882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03882]] Self and Mixed Supervision to Improve Training Labels for Multi-Class  Medical Image Segmentation(https://arxiv.org/abs/2403.03882)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate training labels are a key component for multi-class medical image segmentation. Their annotation is costly and time-consuming because it requires domain expertise. This work aims to develop a dual-branch network and automatically improve training labels for multi-class image segmentation. Transfer learning is used to train the network and improve inaccurate weak labels sequentially. The dual-branch network is first trained by weak labels alone to initialize model parameters. After the network is stabilized, the shared encoder is frozen, and strong and weak decoders are fine-tuned by strong and weak labels together. The accuracy of weak labels is iteratively improved in the fine-tuning process. The proposed method was applied to a three-class segmentation of muscle, subcutaneous and visceral adipose tissue on abdominal CT scans. Validation results on 11 patients showed that the accuracy of training labels was statistically significantly improved, with the Dice similarity coefficient of muscle, subcutaneous and visceral adipose tissue increased from 74.2% to 91.5%, 91.2% to 95.6%, and 77.6% to 88.5%, respectively (p<0.05). In comparison with our earlier method, the label accuracy was also significantly improved (p<0.05). These experimental results suggested that the combination of the dual-branch network and transfer learning is an efficient means to improve training labels for multi-class segmentation.</li>
</ul>

<h3>Title: SaulLM-7B: A pioneering Large Language Model for Law</h3>
<ul>
<li><strong>Authors: </strong>Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, Caio Corro, Andre F. T. Martins, Fabrizio Esposito, Vera Lúcia Raposo, Sofia Morgado, Michael Desa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03883">https://arxiv.org/abs/2403.03883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03883">https://arxiv.org/pdf/2403.03883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03883]] SaulLM-7B: A pioneering Large Language Model for Law(https://arxiv.org/abs/2403.03883)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English legal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional fine-tuning method that leverages legal datasets to further enhance SaulLM-7B's performance in legal tasks. SaulLM-7B is released under the CC-BY-SA-4.0 License.</li>
</ul>

<h3>Title: Did Translation Models Get More Robust Without Anyone Even Noticing?</h3>
<ul>
<li><strong>Authors: </strong>Ben Peters, André F.T. Martins</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03923">https://arxiv.org/abs/2403.03923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03923">https://arxiv.org/pdf/2403.03923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03923]] Did Translation Models Get More Robust Without Anyone Even Noticing?(https://arxiv.org/abs/2403.03923)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Neural machine translation (MT) models achieve strong results across a variety of settings, but it is widely believed that they are highly sensitive to "noisy" inputs, such as spelling errors, abbreviations, and other formatting issues. In this paper, we revisit this insight in light of recent multilingual MT models and large language models (LLMs) applied to machine translation. Somewhat surprisingly, we show through controlled experiments that these models are far more robust to many kinds of noise than previous models, even when they perform similarly on clean data. This is notable because, even though LLMs have more parameters and more complex training processes than past models, none of the open ones we consider use any techniques specifically designed to encourage robustness. Next, we show that similar trends hold for social media translation experiments -- LLMs are more robust to social media text. We include an analysis of the circumstances in which source correction techniques can be used to mitigate the effects of noise. Altogether, we show that robustness to many types of noise has increased.</li>
</ul>

<h3>Title: Extreme Precipitation Nowcasting using Transformer-based Generative  Models</h3>
<ul>
<li><strong>Authors: </strong>Cristian Meo, Ankush Roy, Mircea Lică, Junzhe Yin, Zeineb Bou Che, Yanbo Wang, Ruben Imhoff, Remko Uijlenhoet, Justin Dauwels</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03929">https://arxiv.org/abs/2403.03929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03929">https://arxiv.org/pdf/2403.03929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03929]] Extreme Precipitation Nowcasting using Transformer-based Generative  Models(https://arxiv.org/abs/2403.03929)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>This paper presents an innovative approach to extreme precipitation nowcasting by employing Transformer-based generative models, namely NowcastingGPT with Extreme Value Loss (EVL) regularization. Leveraging a comprehensive dataset from the Royal Netherlands Meteorological Institute (KNMI), our study focuses on predicting short-term precipitation with high accuracy. We introduce a novel method for computing EVL without assuming fixed extreme representations, addressing the limitations of current models in capturing extreme weather events. We present both qualitative and quantitative analyses, demonstrating the superior performance of the proposed NowcastingGPT-EVL in generating accurate precipitation forecasts, especially when dealing with extreme precipitation events. The code is available at \url{https://github.com/Cmeo97/NowcastingGPT}.</li>
</ul>

<h3>Title: GUIDE: Guidance-based Incremental Learning with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Bartosz Cywiński, Kamil Deja, Tomasz Trzciński, Bartłomiej Twardowski, Łukasz Kuciński</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03938">https://arxiv.org/abs/2403.03938</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03938">https://arxiv.org/pdf/2403.03938</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03938]] GUIDE: Guidance-based Incremental Learning with Diffusion Models(https://arxiv.org/abs/2403.03938)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We introduce GUIDE, a novel continual learning approach that directs diffusion models to rehearse samples at risk of being forgotten. Existing generative strategies combat catastrophic forgetting by randomly sampling rehearsal examples from a generative model. Such an approach contradicts buffer-based approaches where sampling strategy plays an important role. We propose to bridge this gap by integrating diffusion models with classifier guidance techniques to produce rehearsal examples specifically targeting information forgotten by a continuously trained model. This approach enables the generation of samples from preceding task distributions, which are more likely to be misclassified in the context of recently encountered classes. Our experimental results show that GUIDE significantly reduces catastrophic forgetting, outperforming conventional random sampling approaches and surpassing recent state-of-the-art methods in continual learning with generative replay.</li>
</ul>

<h3>Title: SPEAR:Exact Gradient Inversion of Batches in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Dimitar I. Dimitrov, Maximilian Baader, Mark Niklas Müller, Martin Vechev</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03945">https://arxiv.org/abs/2403.03945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03945">https://arxiv.org/pdf/2403.03945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03945]] SPEAR:Exact Gradient Inversion of Batches in Federated Learning(https://arxiv.org/abs/2403.03945)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a popular framework for collaborative machine learning where multiple clients only share gradient updates on their local data with the server and not the actual data. Unfortunately, it was recently shown that gradient inversion attacks can reconstruct this data from these shared gradients. Existing attacks enable exact reconstruction only for a batch size of $b=1$ in the important honest-but-curious setting, with larger batches permitting only approximate reconstruction. In this work, we propose \emph{the first algorithm reconstructing whole batches with $b >1$ exactly}. This approach combines mathematical insights into the explicit low-rank structure of gradients with a sampling-based algorithm. Crucially, we leverage ReLU-induced gradient sparsity to precisely filter out large numbers of incorrect samples, making a final reconstruction step tractable. We provide an efficient GPU implementation for fully connected networks and show that it recovers batches of $b \lesssim 25$ elements exactly while being tractable for large network widths and depths.</li>
</ul>

<h3>Title: Stop Regressing: Training Value Functions via Classification for  Scalable Deep RL</h3>
<ul>
<li><strong>Authors: </strong>Jesse Farebrother, Jordi Orbay, Quan Vuong, Adrien Ali Taïga, Yevgen Chebotar, Ted Xiao, Alex Irpan, Sergey Levine, Pablo Samuel Castro, Aleksandra Faust, Aviral Kumar, Rishabh Agarwal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2403.03950">https://arxiv.org/abs/2403.03950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2403.03950">https://arxiv.org/pdf/2403.03950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2403.03950]] Stop Regressing: Training Value Functions via Classification for  Scalable Deep RL(https://arxiv.org/abs/2403.03950)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Value functions are a central component of deep reinforcement learning (RL). These functions, parameterized by neural networks, are trained using a mean squared error regression objective to match bootstrapped target values. However, scaling value-based RL methods that use regression to large networks, such as high-capacity Transformers, has proven challenging. This difficulty is in stark contrast to supervised learning: by leveraging a cross-entropy classification loss, supervised methods have scaled reliably to massive networks. Observing this discrepancy, in this paper, we investigate whether the scalability of deep RL can also be improved simply by using classification in place of regression for training value functions. We demonstrate that value functions trained with categorical cross-entropy significantly improves performance and scalability in a variety of domains. These include: single-task RL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scale ResNets, robotic manipulation with Q-transformers, playing Chess without search, and a language-agent Wordle task with high-capacity Transformers, achieving state-of-the-art results on these domains. Through careful analysis, we show that the benefits of categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity. Overall, we argue that a simple shift to training value functions with categorical cross-entropy can yield substantial improvements in the scalability of deep RL at little-to-no cost.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
