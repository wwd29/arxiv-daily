<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-07-04</h1>
<h3>Title: Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows</h3>
<ul>
<li><strong>Authors: </strong>Mengtao Yan, Qi Wang, Haining Wang, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Fan Yu, Qi Qi, Hao Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.01975">https://arxiv.org/abs/2507.01975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.01975">https://arxiv.org/pdf/2507.01975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.01975]] Learnable-Differentiable Finite Volume Solver for Accelerated Simulation of Flows(https://arxiv.org/abs/2507.01975)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Simulation of fluid flows is crucial for modeling physical phenomena like meteorology, aerodynamics, and biomedicine. Classical numerical solvers often require fine spatiotemporal grids to satisfy stability, consistency, and convergence conditions, leading to substantial computational costs. Although machine learning has demonstrated better efficiency, they typically suffer from issues of interpretability, generalizability, and data dependency. Hence, we propose a learnable and differentiable finite volume solver, called LDSolver, designed for efficient and accurate simulation of fluid flows on spatiotemporal coarse grids. LDSolver comprises two key components: (1) a differentiable finite volume solver, and (2) an learnable module providing equivalent approximation for fluxes (derivatives and interpolations), and temporal error correction on coarse grids. Even with limited training data (e.g., only a few trajectories), our model could accelerate the simulation while maintaining a high accuracy with superior generalizability. Experiments on different flow systems (e.g., Burgers, decaying, forced and shear flows) show that LDSolver achieves state-of-the-art performance, surpassing baseline models with notable margins.</li>
</ul>

<h3>Title: MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation</h3>
<ul>
<li><strong>Authors: </strong>Lu Yan, Zhuo Zhang, Xiangzhe Xu, Shengwei An, Guangyu Shen, Zhou Xuan, Xuan Chen, Xiangyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02057">https://arxiv.org/abs/2507.02057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02057">https://arxiv.org/pdf/2507.02057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02057]] MGC: A Compiler Framework Exploiting Compositional Blindness in Aligned LLMs for Malware Generation(https://arxiv.org/abs/2507.02057)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have democratized software development, reducing the expertise barrier for programming complex applications. This accessibility extends to malicious software development, raising significant security concerns. While LLM providers have implemented alignment mechanisms to prevent direct generation of overtly malicious code, these safeguards predominantly evaluate individual prompts in isolation, overlooking a critical vulnerability: malicious operations can be systematically decomposed into benign-appearing sub-tasks. In this paper, we introduce the Malware Generation Compiler (MGC), a novel framework that leverages this vulnerability through modular decomposition and alignment-evasive generation. MGC employs a specialized Malware Description Intermediate Representation (MDIR) to bridge high-level malicious intents and benign-appearing code snippets. Extensive evaluation demonstrates that our attack reliably generates functional malware across diverse task specifications and categories, outperforming jailbreaking methods by +365.79% and underground services by +78.07% in correctness on three benchmark datasets. Case studies further show that MGC can reproduce and even enhance 16 real-world malware samples. This work provides critical insights for security researchers by exposing the risks of compositional attacks against aligned AI systems. Demonstrations are available at this https URL.</li>
</ul>

<h3>Title: Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02074">https://arxiv.org/abs/2507.02074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02074">https://arxiv.org/pdf/2507.02074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02074]] Large Language Models for Crash Detection in Video: A Survey of Methods, Datasets, and Challenges(https://arxiv.org/abs/2507.02074)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Crash detection from video feeds is a critical problem in intelligent transportation systems. Recent developments in large language models (LLMs) and vision-language models (VLMs) have transformed how we process, reason about, and summarize multimodal information. This paper surveys recent methods leveraging LLMs for crash detection from video data. We present a structured taxonomy of fusion strategies, summarize key datasets, analyze model architectures, compare performance benchmarks, and discuss ongoing challenges and opportunities. Our review provides a foundation for future research in this fast-growing intersection of video understanding and foundation models.</li>
</ul>

<h3>Title: GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters</h3>
<ul>
<li><strong>Authors: </strong>Wanjia Zhao, Jiaqi Han, Siyi Gu, Mingjian Jiang, James Zou, Stefano Ermon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02085">https://arxiv.org/abs/2507.02085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02085">https://arxiv.org/pdf/2507.02085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02085]] GeoAda: Efficiently Finetune Geometric Diffusion Models with Equivariant Adapters(https://arxiv.org/abs/2507.02085)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Geometric diffusion models have shown remarkable success in molecular dynamics and structure generation. However, efficiently fine-tuning them for downstream tasks with varying geometric controls remains underexplored. In this work, we propose an SE(3)-equivariant adapter framework ( GeoAda) that enables flexible and parameter-efficient fine-tuning for controlled generative tasks without modifying the original model architecture. GeoAda introduces a structured adapter design: control signals are first encoded through coupling operators, then processed by a trainable copy of selected pretrained model layers, and finally projected back via decoupling operators followed by an equivariant zero-initialized convolution. By fine-tuning only these lightweight adapter modules, GeoAda preserves the model's geometric consistency while mitigating overfitting and catastrophic forgetting. We theoretically prove that the proposed adapters maintain SE(3)-equivariance, ensuring that the geometric inductive biases of the pretrained diffusion model remain intact during adaptation. We demonstrate the wide applicability of GeoAda across diverse geometric control types, including frame control, global control, subgraph control, and a broad range of application domains such as particle dynamics, molecular dynamics, human motion prediction, and molecule generation. Empirical results show that GeoAda achieves state-of-the-art fine-tuning performance while preserving original task accuracy, whereas other baselines experience significant performance degradation due to overfitting and catastrophic forgetting.</li>
</ul>

<h3>Title: Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions</h3>
<ul>
<li><strong>Authors: </strong>Eitan Anzenberg, Arunava Samajpati, Sivasankaran Chandrasekar, Varun Kacholia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02087">https://arxiv.org/abs/2507.02087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02087">https://arxiv.org/pdf/2507.02087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02087]] Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions(https://arxiv.org/abs/2507.02087)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>The use of large language models (LLMs) in hiring promises to streamline candidate screening, but it also raises serious concerns regarding accuracy and algorithmic bias where sufficient safeguards are not in place. In this work, we benchmark several state-of-the-art foundational LLMs - including models from OpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our proprietary domain-specific hiring model (Match Score) for job candidate matching. We evaluate each model's predictive accuracy (ROC AUC, Precision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis across declared gender, race, and intersectional subgroups). Our experiments on a dataset of roughly 10,000 real-world recent candidate-job pairs show that Match Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs 0.77) and achieves significantly more equitable outcomes across demographic groups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957 (near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the intersectionals, respectively). We discuss why pretraining biases may cause LLMs with insufficient safeguards to propagate societal biases in hiring scenarios, whereas a bespoke supervised model can more effectively mitigate these biases. Our findings highlight the importance of domain-specific modeling and bias auditing when deploying AI in high-stakes domains such as hiring, and caution against relying on off-the-shelf LLMs for such tasks without extensive fairness safeguards. Furthermore, we show with empirical evidence that there shouldn't be a dichotomy between choosing accuracy and fairness in hiring: a well-designed algorithm can achieve both accuracy in hiring and fairness in outcomes.</li>
</ul>

<h3>Title: McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tian Lan, Xiangdong Su, Xu Liu, Ruirui Wang, Ke Chang, Jiang Li, Guanglai Gao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02088">https://arxiv.org/abs/2507.02088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02088">https://arxiv.org/pdf/2507.02088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02088]] McBE: A Multi-task Chinese Bias Evaluation Benchmark for Large Language Models(https://arxiv.org/abs/2507.02088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are increasingly applied to various NLP tasks, their inherent biases are gradually disclosed. Therefore, measuring biases in LLMs is crucial to mitigate its ethical risks. However, most existing bias evaluation datasets focus on English and North American culture, and their bias categories are not fully applicable to other cultures. The datasets grounded in the Chinese language and culture are scarce. More importantly, these datasets usually only support single evaluation tasks and cannot evaluate the bias from multiple aspects in LLMs. To address these issues, we present a Multi-task Chinese Bias Evaluation Benchmark (McBE) that includes 4,077 bias evaluation instances, covering 12 single bias categories, 82 subcategories and introducing 5 evaluation tasks, providing extensive category coverage, content diversity, and measuring comprehensiveness. Additionally, we evaluate several popular LLMs from different series and with parameter sizes. In general, all these LLMs demonstrated varying degrees of bias. We conduct an in-depth analysis of results, offering novel insights into bias in LLMs.</li>
</ul>

<h3>Title: Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model</h3>
<ul>
<li><strong>Authors: </strong>Xingtu Liu, Lin F. Yang, Sharan Vaswani</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02089">https://arxiv.org/abs/2507.02089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02089">https://arxiv.org/pdf/2507.02089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02089]] Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model(https://arxiv.org/abs/2507.02089)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We consider infinite-horizon $\gamma$-discounted (linear) constrained Markov decision processes (CMDPs) where the objective is to find a policy that maximizes the expected cumulative reward subject to expected cumulative constraints. Given access to a generative model, we propose to solve CMDPs with a primal-dual framework that can leverage any black-box unconstrained MDP solver. For linear CMDPs with feature dimension $d$, we instantiate the framework by using mirror descent value iteration (\texttt{MDVI})~\citep{kitamura2023regularization} an example MDP solver. We provide sample complexity bounds for the resulting CMDP algorithm in two cases: (i) relaxed feasibility, where small constraint violations are allowed, and (ii) strict feasibility, where the output policy is required to exactly satisfy the constraint. For (i), we prove that the algorithm can return an $\epsilon$-optimal policy with high probability by using $\tilde{O}\left(\frac{d^2}{(1-\gamma)^4\epsilon^2}\right)$ samples. We note that these results exhibit a near-optimal dependence on both $d$ and $\epsilon$. For (ii), we show that the algorithm requires $\tilde{O}\left(\frac{d^2}{(1-\gamma)^6\epsilon^2\zeta^2}\right)$ samples, where $\zeta$ is the problem-dependent Slater constant that characterizes the size of the feasible region. Finally, we instantiate our framework for tabular CMDPs and show that it can be used to recover near-optimal sample complexities in this setting.</li>
</ul>

<h3>Title: Energy-Based Transformers are Scalable Learners and Thinkers</h3>
<ul>
<li><strong>Authors: </strong>Alexi Gladstone, Ganesh Nanduru, Md Mofijul Islam, Peixuan Han, Hyeonjeong Ha, Aman Chadha, Yilun Du, Heng Ji, Jundong Li, Tariq Iqbal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02092">https://arxiv.org/abs/2507.02092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02092">https://arxiv.org/pdf/2507.02092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02092]] Energy-Based Transformers are Scalable Learners and Thinkers(https://arxiv.org/abs/2507.02092)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question "Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?" Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on most downstream tasks given the same or worse pretraining performance, suggesting that EBTs generalize better than existing approaches. Consequently, EBTs are a promising new paradigm for scaling both the learning and thinking capabilities of models.</li>
</ul>

<h3>Title: Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Shikai Qiu, Lechao Xiao, Andrew Gordon Wilson, Jeffrey Pennington, Atish Agarwala</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02119">https://arxiv.org/abs/2507.02119</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02119">https://arxiv.org/pdf/2507.02119</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02119]] Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks(https://arxiv.org/abs/2507.02119)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>What scaling limits govern neural network training dynamics when model size and training time grow in tandem? We show that despite the complex interactions between architecture, training algorithms, and data, compute-optimally trained models exhibit a remarkably precise universality. Specifically, loss curves from models of varying sizes collapse onto a single universal curve when training compute and loss are normalized to unity at the end of training. With learning rate decay, the collapse becomes so tight that differences in the normalized curves across models fall below the noise floor of individual loss curves across random seeds, a phenomenon we term supercollapse. We observe supercollapse across learning rate schedules, datasets, and architectures, including transformers trained on next-token prediction, and find it breaks down when hyperparameters are scaled suboptimally, providing a precise and practical indicator of good scaling. We explain these phenomena by connecting collapse to the power-law structure in typical neural scaling laws, and analyzing a simple yet surprisingly effective model of SGD noise dynamics that accurately predicts loss curves across various learning rate schedules and quantitatively explains the origin of supercollapse.</li>
</ul>

<h3>Title: Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities</h3>
<ul>
<li><strong>Authors: </strong>Giulio Caldarelli</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY, cs.GT, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02125">https://arxiv.org/abs/2507.02125</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02125">https://arxiv.org/pdf/2507.02125</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02125]] Can Artificial Intelligence solve the blockchain oracle problem? Unpacking the Challenges and Possibilities(https://arxiv.org/abs/2507.02125)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The blockchain oracle problem, which refers to the challenge of injecting reliable external data into decentralized systems, remains a fundamental limitation to the development of trustless applications. While recent years have seen a proliferation of architectural, cryptographic, and economic strategies to mitigate this issue, no one has yet fully resolved the fundamental question of how a blockchain can gain knowledge about the off-chain world. In this position paper, we critically assess the role artificial intelligence (AI) can play in tackling the oracle problem. Drawing from both academic literature and practitioner implementations, we examine how AI techniques such as anomaly detection, language-based fact extraction, dynamic reputation modeling, and adversarial resistance can enhance oracle systems. We observe that while AI introduces powerful tools for improving data quality, source selection, and system resilience, it cannot eliminate the reliance on unverifiable off-chain inputs. Therefore, this study supports the idea that AI should be understood as a complementary layer of inference and filtering within a broader oracle design, not a substitute for trust assumptions.</li>
</ul>

<h3>Title: CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jingyu Pan, Isaac Jacobson, Zheng Zhao, Tung-Chieh Chen, Guanglei Zhou, Chen-Chia Chang, Vineet Rashingkar, Yiran Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02128">https://arxiv.org/abs/2507.02128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02128">https://arxiv.org/pdf/2507.02128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02128]] CROP: Circuit Retrieval and Optimization with Parameter Guidance using LLMs(https://arxiv.org/abs/2507.02128)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Modern very large-scale integration (VLSI) design requires the implementation of integrated circuits using electronic design automation (EDA) tools. Due to the complexity of EDA algorithms, the vast parameter space poses a huge challenge to chip design optimization, as the combination of even moderate numbers of parameters creates an enormous solution space to explore. Manual parameter selection remains industrial practice despite being excessively laborious and limited by expert experience. To address this issue, we present CROP, the first large language model (LLM)-powered automatic VLSI design flow tuning framework. Our approach includes: (1) a scalable methodology for transforming RTL source code into dense vector representations, (2) an embedding-based retrieval system for matching designs with semantically similar circuits, and (3) a retrieval-augmented generation (RAG)-enhanced LLM-guided parameter search system that constrains the search process with prior knowledge from similar designs. Experiment results demonstrate CROP's ability to achieve superior quality-of-results (QoR) with fewer iterations than existing approaches on industrial designs, including a 9.9% reduction in power consumption.</li>
</ul>

<h3>Title: Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction</h3>
<ul>
<li><strong>Authors: </strong>Xiao Li, Liangji Zhu, Anand Rangarajan, Sanjay Ranka</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02129">https://arxiv.org/abs/2507.02129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02129">https://arxiv.org/pdf/2507.02129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02129]] Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction(https://arxiv.org/abs/2507.02129)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models have demonstrated strong performance in conditional settings and can be viewed as a form of data compression, where the condition serves as a compact representation. However, their limited controllability and reconstruction accuracy restrict their practical application to data compression. In this work, we propose an efficient latent diffusion framework that bridges this gap by combining a variational autoencoder with a conditional diffusion model. Our method compresses only a small number of keyframes into latent space and uses them as conditioning inputs to reconstruct the remaining frames via generative interpolation, eliminating the need to store latent representations for every frame. This approach enables accurate spatiotemporal reconstruction while significantly reducing storage costs. Experimental results across multiple datasets show that our method achieves up to 10 times higher compression ratios than rule-based state-of-the-art compressors such as SZ3, and up to 63 percent better performance than leading learning-based methods under the same reconstruction error.</li>
</ul>

<h3>Title: Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization</h3>
<ul>
<li><strong>Authors: </strong>Keyan Jin, Yapeng Wang, Leonel Santos, Tao Fang, Xu Yang, Sio Kei Im, Hugo Gonçalo Oliveira</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02145">https://arxiv.org/abs/2507.02145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02145">https://arxiv.org/pdf/2507.02145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02145]] Reasoning or Not? A Comprehensive Evaluation of Reasoning LLMs for Dialogue Summarization(https://arxiv.org/abs/2507.02145)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dialogue summarization is a challenging task with significant practical value in customer service, meeting analysis, and conversational AI. Although large language models (LLMs) have achieved substantial progress in summarization tasks, the performance of step-by-step reasoning architectures-specifically Long Chain-of-Thought (CoT) implementations such as OpenAI-o1 and DeepSeek-R1-remains unexplored for dialogue scenarios requiring concurrent abstraction and conciseness. In this work, we present the first comprehensive and systematic evaluation of state-of-the-art reasoning LLMs and non-reasoning LLMs across three major paradigms-generic, role-oriented, and query-oriented dialogue summarization. Our study spans diverse languages, domains, and summary lengths, leveraging strong benchmarks (SAMSum, DialogSum, CSDS, and QMSum) and advanced evaluation protocols that include both LLM-based automatic metrics and human-inspired criteria. Contrary to trends in other reasoning-intensive tasks, our findings show that explicit stepwise reasoning does not consistently improve dialogue summarization quality. Instead, reasoning LLMs are often prone to verbosity, factual inconsistencies, and less concise summaries compared to their non-reasoning counterparts. Through scenario-specific analyses and detailed case studies, we further identify when and why explicit reasoning may fail to benefit-or even hinder-summarization in complex dialogue contexts. Our work provides new insights into the limitations of current reasoning LLMs and highlights the need for targeted modeling and evaluation strategies for real-world dialogue summarization.</li>
</ul>

<h3>Title: Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zijie Cai, Christopher Metzler</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02148">https://arxiv.org/abs/2507.02148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02148">https://arxiv.org/pdf/2507.02148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02148]] Underwater Monocular Metric Depth Estimation: Real-World Benchmarks and Synthetic Fine-Tuning(https://arxiv.org/abs/2507.02148)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Monocular depth estimation has recently advanced to provide not only relative but also metric depth predictions. However, its reliability in underwater environments remains limited due to light attenuation and scattering, color distortion, turbidity, and the lack of high-quality metric ground-truth data. In this paper, we present a comprehensive benchmark of zero-shot and fine-tuned monocular metric depth estimation models on real-world underwater datasets with metric depth annotations, such as FLSea and SQUID. We evaluate a diverse set of state-of-the-art models across a range of underwater conditions with different ranges. Our results show that large-scale models trained on terrestrial (real or synthetic) data, while effective in in-air settings, perform poorly underwater due to significant domain shifts. To address this, we fine-tune Depth Anything V2 with a ViT-S backbone encoder on a synthetic underwater variant of the Hypersim dataset, which we generated using a physically based underwater image formation model. We demonstrate our fine-tuned model consistently improves performance across all benchmarks and outperforms baselines trained only on the clean in-air Hypersim dataset. Our study provides a detailed evaluation and visualization for monocular metric depth estimation in underwater scenes, highlighting the importance of domain adaptation and scale-aware supervision for achieving robust and generalizable metric depth predictions in challenging underwater environments for future research.</li>
</ul>

<h3>Title: Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Tuo Wang, Jian Kang, Yujun Yan, Adithya Kulkarni, Dawei Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02151">https://arxiv.org/abs/2507.02151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02151">https://arxiv.org/pdf/2507.02151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02151]] Non-exchangeable Conformal Prediction for Temporal Graph Neural Networks(https://arxiv.org/abs/2507.02151)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Conformal prediction for graph neural networks (GNNs) offers a promising framework for quantifying uncertainty, enhancing GNN reliability in high-stakes applications. However, existing methods predominantly focus on static graphs, neglecting the evolving nature of real-world graphs. Temporal dependencies in graph structure, node attributes, and ground truth labels violate the fundamental exchangeability assumption of standard conformal prediction methods, limiting their applicability. To address these challenges, in this paper, we introduce NCPNET, a novel end-to-end conformal prediction framework tailored for temporal graphs. Our approach extends conformal prediction to dynamic settings, mitigating statistical coverage violations induced by temporal dependencies. To achieve this, we propose a diffusion-based non-conformity score that captures both topological and temporal uncertainties within evolving networks. Additionally, we develop an efficiency-aware optimization algorithm that improves the conformal prediction process, enhancing computational efficiency and reducing coverage violations. Extensive experiments on diverse real-world temporal graphs, including WIKI, REDDIT, DBLP, and IBM Anti-Money Laundering dataset, demonstrate NCPNET's capability to ensure guaranteed coverage in temporal graphs, achieving up to a 31% reduction in prediction set size on the WIKI dataset, significantly improving efficiency compared to state-of-the-art methods. Our data and code are available at this https URL.</li>
</ul>

<h3>Title: ARMOUR US: Android Runtime Zero-permission Sensor Usage Monitoring from User Space</h3>
<ul>
<li><strong>Authors: </strong>Yan Long, Jiancong Cui, Yuqing Yang, Tobias Alam, Zhiqiang Lin, Kevin Fu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02177">https://arxiv.org/abs/2507.02177</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02177">https://arxiv.org/pdf/2507.02177</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02177]] ARMOUR US: Android Runtime Zero-permission Sensor Usage Monitoring from User Space(https://arxiv.org/abs/2507.02177)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>This work investigates how to monitor access to Android zero-permission sensors which could cause privacy leakage to users. Moreover, monitoring such sensitive access allows security researchers to characterize potential sensor abuse patterns. Zero-permission sensors such as accelerometers have become an indispensable part of Android devices. The critical information they provide has attracted extensive research investigating how data collectors could capture more sensor data to enable both benign and exploitative applications. In contrast, little work has explored how to enable data providers, such as end users, to understand sensor usage. While existing methods such as static analysis and hooking-based dynamic analysis face challenges of requiring complicated development chains, rooting privilege, and app-specific reverse engineering analysis, our work aims to bridge this gap by developing ARMOUR for user-space runtime monitoring, leveraging the intrinsic sampling rate variation and convergence behaviors of Android. ARMOUR enables privacy-aware users to easily monitor how third-party apps use sensor data and support security researchers to perform rapid app-agnostic sensor access analysis. Our evaluation with 1,448 commercial applications shows the effectiveness of ARMOUR in detecting sensor usage in obfuscated code and other conditions, and observes salient sensor abuse patterns such as 50% of apps from seemingly sensor-independent categories accessing data of multiple zero-permission sensors. We analyze the impact of Android's recent policy changes on zero-permission sensors and remaining technical and regulatory problems.</li>
</ul>

<h3>Title: Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher</h3>
<ul>
<li><strong>Authors: </strong>Pantelimon Stanica, Ranit Dutta, Bimal Mandal</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02181">https://arxiv.org/abs/2507.02181</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02181">https://arxiv.org/pdf/2507.02181</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02181]] Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher(https://arxiv.org/abs/2507.02181)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>This paper introduces {\em truncated inner $c$-differential cryptanalysis}, a novel technique that for the first time enables the practical application of $c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE Trans. Inf. Theory, 2020) established the notion of $c$-differential uniformity using $(F(x\oplus a), cF(x))$, a key challenge remained: multiplication by $c$ disrupts the structural properties essential for block cipher analysis, particularly key addition. We resolve this challenge by developing an \emph{inner} $c$-differential approach where multiplication by $c$ affects the input: $(F(cx\oplus a), F(x))$. We prove that the inner $c$-differential uniformity of a function $F$ equals the outer $c$-differential uniformity of $F^{-1}$, establishing a fundamental duality. This modification preserves cipher structure while enabling practical cryptanalytic applications. Our main contribution is a comprehensive multi-faceted statistical-computational framework, implementing truncated $c$-differential analysis against the full 9-round Kuznyechik cipher (the inner $c$-differentials are immune to the key whitening at the backend). Through extensive computational analysis involving millions of differential pairs, we demonstrate statistically significant non-randomness across all tested round counts. For the full 9-round cipher, we identify multiple configurations triggering critical security alerts, with bias ratios reaching $1.7\times$ and corrected p-values as low as $1.85 \times 10^{-3}$, suggesting insufficient security margin against this new attack vector. This represents the first practical distinguisher against the full 9-round Kuznyechik.</li>
</ul>

<h3>Title: Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer</h3>
<ul>
<li><strong>Authors: </strong>Wenquan Lu, Yuechuan Yang, Kyle Lee, Yanshu Li, Enqi Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02199">https://arxiv.org/abs/2507.02199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02199">https://arxiv.org/pdf/2507.02199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02199]] Latent Chain-of-Thought? Decoding the Depth-Recurrent Transformer(https://arxiv.org/abs/2507.02199)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Chain-of-thought (CoT) reasoning has enabled transformer-based language models to excel at complex mathematics and multi-step planning. However, in standard decoder-only architectures, these reasoning steps are externalized in natural language, improving interpretability at the cost of efficiency. To capture reasoning that is not easily represented in words, many works have explored recurrent architectures that aim to internalize reasoning in latent space, potentially supporting latent CoT. In this paper, we investigate whether such reasoning structures emerge in Huginn-3.5B, a depth-recurrent Transformer that reuses layers at inference time without increasing parameter count. We examine the model's internal behavior on arithmetic tasks using a suite of probing techniques including the Logit Lens and Coda Lens. Our findings reveal limited evidence of interpretable latent CoT by tracking rank trajectories of final and intermediate result tokens. Furthermore, we uncover significant probing inconsistencies across recurrent blocks, where the interpretability of hidden states depends heavily on both the layer index and the decoding method. Finally, we empirically show that increasing recurrence depth yields only marginal gains and falls well short of models that explicitly externalize reasoning steps. The code is available at this https URL.</li>
</ul>

<h3>Title: ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xiao Wang, Jingtao Jiang, Qiang Chen, Lan Chen, Lin Zhu, Yaowei Wang, Yonghong Tian, Jin Tang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02200">https://arxiv.org/abs/2507.02200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02200">https://arxiv.org/pdf/2507.02200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02200]] ESTR-CoT: Towards Explainable and Accurate Event Stream based Scene Text Recognition with Chain-of-Thought Reasoning(https://arxiv.org/abs/2507.02200)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Event stream based scene text recognition is a newly arising research topic in recent years which performs better than the widely used RGB cameras in extremely challenging scenarios, especially the low illumination, fast motion. Existing works either adopt end-to-end encoder-decoder framework or large language models for enhanced recognition, however, they are still limited by the challenges of insufficient interpretability and weak contextual logical reasoning. In this work, we propose a novel chain-of-thought reasoning based event stream scene text recognition framework, termed ESTR-CoT. Specifically, we first adopt the vision encoder EVA-CLIP (ViT-G/14) to transform the input event stream into tokens and utilize a Llama tokenizer to encode the given generation prompt. A Q-former is used to align the vision token to the pre-trained large language model Vicuna-7B and output both the answer and chain-of-thought (CoT) reasoning process simultaneously. Our framework can be optimized using supervised fine-tuning in an end-to-end manner. In addition, we also propose a large-scale CoT dataset to train our framework via a three stage processing (i.e., generation, polish, and expert verification). This dataset provides a solid data foundation for the development of subsequent reasoning-based large models. Extensive experiments on three event stream STR benchmark datasets (i.e., EventSTR, WordArt*, IC15*) fully validated the effectiveness and interpretability of our proposed framework. The source code and pre-trained models will be released on this https URL.</li>
</ul>

<h3>Title: EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer</h3>
<ul>
<li><strong>Authors: </strong>Ranyang Zhou, Abeer Matar A. Almalky, Gamana Aragonda, Sabbir Ahmed, Filip Roth Trønnes-Christensen, Adnan Siraj Rakin, Shaahin Angizi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02206">https://arxiv.org/abs/2507.02206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02206">https://arxiv.org/pdf/2507.02206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02206]] EIM-TRNG: Obfuscating Deep Neural Network Weights with Encoding-in-Memory True Random Number Generator via RowHammer(https://arxiv.org/abs/2507.02206)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, robust, extraction</a></li>
<li><strong>Abstract: </strong>True Random Number Generators (TRNGs) play a fundamental role in hardware security, cryptographic systems, and data protection. In the context of Deep NeuralNetworks (DNNs), safeguarding model parameters, particularly weights, is critical to ensure the integrity, privacy, and intel-lectual property of AI systems. While software-based pseudo-random number generators are widely used, they lack the unpredictability and resilience offered by hardware-based TRNGs. In this work, we propose a novel and robust Encoding-in-Memory TRNG called EIM-TRNG that leverages the inherent physical randomness in DRAM cell behavior, particularly under RowHammer-induced disturbances, for the first time. We demonstrate how the unpredictable bit-flips generated through carefully controlled RowHammer operations can be harnessed as a reliable entropy source. Furthermore, we apply this TRNG framework to secure DNN weight data by encoding via a combination of fixed and unpredictable bit-flips. The encrypted data is later decrypted using a key derived from the probabilistic flip behavior, ensuring both data confidentiality and model authenticity. Our results validate the effectiveness of DRAM-based entropy extraction for robust, low-cost hardware security and offer a promising direction for protecting machine learning models at the hardware level.</li>
</ul>

<h3>Title: Understanding Trade offs When Conditioning Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Brandon Trabucco, Qasim Wani, Benjamin Pikus, Vasu Sharma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02217">https://arxiv.org/abs/2507.02217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02217">https://arxiv.org/pdf/2507.02217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02217]] Understanding Trade offs When Conditioning Synthetic Data(https://arxiv.org/abs/2507.02217)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Learning robust object detectors from only a handful of images is a critical challenge in industrial vision systems, where collecting high quality training data can take months. Synthetic data has emerged as a key solution for data efficient visual inspection and pick and place robotics. Current pipelines rely on 3D engines such as Blender or Unreal, which offer fine control but still require weeks to render a small dataset, and the resulting images often suffer from a large gap between simulation and reality. Diffusion models promise a step change because they can generate high quality images in minutes, yet precise control, especially in low data regimes, remains difficult. Although many adapters now extend diffusion beyond plain text prompts, the effect of different conditioning schemes on synthetic data quality is poorly understood. We study eighty diverse visual concepts drawn from four standard object detection benchmarks and compare two conditioning strategies: prompt based and layout based. When the set of conditioning cues is narrow, prompt conditioning yields higher quality synthetic data; as diversity grows, layout conditioning becomes superior. When layout cues match the full training distribution, synthetic data raises mean average precision by an average of thirty four percent and by as much as one hundred seventy seven percent compared with using real data alone.</li>
</ul>

<h3>Title: GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons</h3>
<ul>
<li><strong>Authors: </strong>Steven Song, Anirudh Subramanyam, Zhenyu Zhang, Aarti Venkat, Robert L. Grossman</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02221">https://arxiv.org/abs/2507.02221</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02221">https://arxiv.org/pdf/2507.02221</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02221]] GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons(https://arxiv.org/abs/2507.02221)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Motivation: The Genomic Data Commons (GDC) provides access to high quality, harmonized cancer genomics data through a unified curation and analysis platform centered around patient cohorts. While GDC users can interactively create complex cohorts through the graphical Cohort Builder, users (especially new ones) may struggle to find specific cohort descriptors across hundreds of possible fields and properties. However, users may be better able to describe their desired cohort in free-text natural language. Results: We introduce GDC Cohort Copilot, an open-source copilot tool for curating cohorts from the GDC. GDC Cohort Copilot automatically generates the GDC cohort filter corresponding to a user-input natural language description of their desired cohort, before exporting the cohort back to the GDC for further analysis. An interactive user interface allows users to further refine the generated cohort. We develop and evaluate multiple large language models (LLMs) for GDC Cohort Copilot and demonstrate that our locally-served, open-source GDC Cohort LLM achieves better results than GPT-4o prompting in generating GDC cohorts. Availability and implementation: The standalone docker image for GDC Cohort Copilot is available at this https URL. Source code is available at this https URL. GDC Cohort LLM weights are available at this https URL.</li>
</ul>

<h3>Title: High-Fidelity Differential-information Driven Binary Vision Transformer</h3>
<ul>
<li><strong>Authors: </strong>Tian Gao, Zhiyuan Zhang, Kaijie Yin, Xu-Cheng Zhong, Hui Kong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02222">https://arxiv.org/abs/2507.02222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02222">https://arxiv.org/pdf/2507.02222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02222]] High-Fidelity Differential-information Driven Binary Vision Transformer(https://arxiv.org/abs/2507.02222)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The binarization of vision transformers (ViTs) offers a promising approach to addressing the trade-off between high computational/storage demands and the constraints of edge-device deployment. However, existing binary ViT methods often suffer from severe performance degradation or rely heavily on full-precision modules. To address these issues, we propose DIDB-ViT, a novel binary ViT that is highly informative while maintaining the original ViT architecture and computational efficiency. Specifically, we design an informative attention module incorporating differential information to mitigate information loss caused by binarization and enhance high-frequency retention. To preserve the fidelity of the similarity calculations between binary Q and K tensors, we apply frequency decomposition using the discrete Haar wavelet and integrate similarities across different frequencies. Additionally, we introduce an improved RPReLU activation function to restructure the activation distribution, expanding the model's representational capacity. Experimental results demonstrate that our DIDB-ViT significantly outperforms state-of-the-art network quantization methods in multiple ViT architectures, achieving superior image classification and segmentation performance.</li>
</ul>

<h3>Title: PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations</h3>
<ul>
<li><strong>Authors: </strong>Xinquan Huang, Paris Perdikaris</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02227">https://arxiv.org/abs/2507.02227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02227">https://arxiv.org/pdf/2507.02227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02227]] PhysicsCorrect: A Training-Free Approach for Stable Neural PDE Simulations(https://arxiv.org/abs/2507.02227)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural networks have emerged as powerful surrogates for solving partial differential equations (PDEs), offering significant computational speedups over traditional methods. However, these models suffer from a critical limitation: error accumulation during long-term rollouts, where small inaccuracies compound exponentially, eventually causing complete divergence from physically valid solutions. We present PhysicsCorrect, a training-free correction framework that enforces PDE consistency at each prediction step by formulating correction as a linearized inverse problem based on PDE residuals. Our key innovation is an efficient caching strategy that precomputes the Jacobian and its pseudoinverse during an offline warm-up phase, reducing computational overhead by two orders of magnitude compared to standard correction approaches. Across three representative PDE systems -- Navier-Stokes fluid dynamics, wave equations, and the chaotic Kuramoto-Sivashinsky equation -- PhysicsCorrect reduces prediction errors by up to 100x while adding negligible inference time (under 5\%). The framework integrates seamlessly with diverse architectures including Fourier Neural Operators, UNets, and Vision Transformers, effectively transforming unstable neural surrogates into reliable simulation tools that bridge the gap between deep learning's computational efficiency and the physical fidelity demanded by practical scientific applications.</li>
</ul>

<h3>Title: VERBA: Verbalizing Model Differences Using Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shravan Doda, Shashidhar Reddy Javaji, Zining Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02241">https://arxiv.org/abs/2507.02241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02241">https://arxiv.org/pdf/2507.02241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02241]] VERBA: Verbalizing Model Differences Using Large Language Models(https://arxiv.org/abs/2507.02241)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In the current machine learning landscape, we face a "model lake" phenomenon: Given a task, there is a proliferation of trained models with similar performances despite different behavior. For model users attempting to navigate and select from the models, documentation comparing model pairs is helpful. However, for every $N$ models there could be $O(N^2)$ pairwise comparisons, a number prohibitive for the model developers to manually perform pairwise comparisons and prepare documentations. To facilitate fine-grained pairwise comparisons among models, we introduced $\textbf{VERBA}$. Our approach leverages a large language model (LLM) to generate verbalizations of model differences by sampling from the two models. We established a protocol that evaluates the informativeness of the verbalizations via simulation. We also assembled a suite with a diverse set of commonly used machine learning models as a benchmark. For a pair of decision tree models with up to 5% performance difference but 20-25% behavioral differences, $\textbf{VERBA}$ effectively verbalizes their variations with up to 80% overall accuracy. When we included the models' structural information, the verbalization's accuracy further improved to 90%. $\textbf{VERBA}$ opens up new research avenues for improving the transparency and comparability of machine learning models in a post-hoc manner.</li>
</ul>

<h3>Title: Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies</h3>
<ul>
<li><strong>Authors: </strong>Fangzhou Shi, Xiaopeng Ke, Xinye Xiong, Kexin Meng, Chang Men, Zhengdan Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02244">https://arxiv.org/abs/2507.02244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02244">https://arxiv.org/pdf/2507.02244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02244]] Order Acquisition Under Competitive Pressure: A Rapidly Adaptive Reinforcement Learning Approach for Ride-Hailing Subsidy Strategies(https://arxiv.org/abs/2507.02244)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>The proliferation of ride-hailing aggregator platforms presents significant growth opportunities for ride-service providers by increasing order volume and gross merchandise value (GMV). On most ride-hailing aggregator platforms, service providers that offer lower fares are ranked higher in listings and, consequently, are more likely to be selected by passengers. This competitive ranking mechanism creates a strong incentive for service providers to adopt coupon strategies that lower prices to secure a greater number of orders, as order volume directly influences their long-term viability and sustainability. Thus, designing an effective coupon strategy that can dynamically adapt to market fluctuations while optimizing order acquisition under budget constraints is a critical research challenge. However, existing studies in this area remain scarce. To bridge this gap, we propose FCA-RL, a novel reinforcement learning-based subsidy strategy framework designed to rapidly adapt to competitors' pricing adjustments. Our approach integrates two key techniques: Fast Competition Adaptation (FCA), which enables swift responses to dynamic price changes, and Reinforced Lagrangian Adjustment (RLA), which ensures adherence to budget constraints while optimizing coupon decisions on new price landscape. Furthermore, we introduce RideGym, the first dedicated simulation environment tailored for ride-hailing aggregators, facilitating comprehensive evaluation and benchmarking of different pricing strategies without compromising real-world operational efficiency. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches across diverse market conditions, highlighting its effectiveness in subsidy optimization for ride-hailing service providers.</li>
</ul>

<h3>Title: FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Jiangxia Chen, Tongyuan Huang, Ke Song</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02250">https://arxiv.org/abs/2507.02250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02250">https://arxiv.org/pdf/2507.02250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02250]] FMOcc: TPV-Driven Flow Matching for 3D Occupancy Prediction with Selective State Space Model(https://arxiv.org/abs/2507.02250)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D semantic occupancy prediction plays a pivotal role in autonomous driving. However, inherent limitations of fewframe images and redundancy in 3D space compromise prediction accuracy for occluded and distant scenes. Existing methods enhance performance by fusing historical frame data, which need additional data and significant computational resources. To address these issues, this paper propose FMOcc, a Tri-perspective View (TPV) refinement occupancy network with flow matching selective state space model for few-frame 3D occupancy prediction. Firstly, to generate missing features, we designed a feature refinement module based on a flow matching model, which is called Flow Matching SSM module (FMSSM). Furthermore, by designing the TPV SSM layer and Plane Selective SSM (PS3M), we selectively filter TPV features to reduce the impact of air voxels on non-air voxels, thereby enhancing the overall efficiency of the model and prediction capability for distant scenes. Finally, we design the Mask Training (MT) method to enhance the robustness of FMOcc and address the issue of sensor data loss. Experimental results on the Occ3D-nuScenes and OpenOcc datasets show that our FMOcc outperforms existing state-of-theart methods. Our FMOcc with two frame input achieves notable scores of 43.1% RayIoU and 39.8% mIoU on Occ3D-nuScenes validation, 42.6% RayIoU on OpenOcc with 5.4 G inference memory and 330ms inference time.</li>
</ul>

<h3>Title: SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Lei, Hongyuan Yu, Jinlin Wu, Zhen Chen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02252">https://arxiv.org/abs/2507.02252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02252">https://arxiv.org/pdf/2507.02252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02252]] SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement(https://arxiv.org/abs/2507.02252)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.</li>
</ul>

<h3>Title: Uncertainty-aware Reward Design Process</h3>
<ul>
<li><strong>Authors: </strong>Yang Yang, Xiaolu Zhou, Bosong Ding, Miao Xin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02256">https://arxiv.org/abs/2507.02256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02256">https://arxiv.org/pdf/2507.02256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02256]] Uncertainty-aware Reward Design Process(https://arxiv.org/abs/2507.02256)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Designing effective reward functions is a cornerstone of reinforcement learning (RL), yet it remains a challenging process due to the inefficiencies and inconsistencies inherent in conventional reward engineering methodologies. Recent advances have explored leveraging large language models (LLMs) to automate reward function design. However, their suboptimal performance in numerical optimization often yields unsatisfactory reward quality, while the evolutionary search paradigm demonstrates inefficient utilization of simulation resources, resulting in prohibitively lengthy design cycles with disproportionate computational overhead. To address these challenges, we propose the Uncertainty-aware Reward Design Process (URDP), a novel framework that integrates large language models to streamline reward function design and evaluation in RL environments. URDP quantifies candidate reward function uncertainty based on self-consistency analysis, enabling simulation-free identification of ineffective reward components while discovering novel reward components. Furthermore, we introduce uncertainty-aware Bayesian optimization (UABO), which incorporates uncertainty estimation to significantly enhance hyperparameter configuration efficiency. Finally, we construct a bi-level optimization architecture by decoupling the reward component optimization and the hyperparameter tuning. URDP orchestrates synergistic collaboration between the reward logic reasoning of the LLMs and the numerical optimization strengths of the Bayesian Optimization. We conduct a comprehensive evaluation of URDP across 35 diverse tasks spanning three benchmark environments. Our experimental results demonstrate that URDP not only generates higher-quality reward functions but also achieves significant improvements in the efficiency of automated reward design compared to existing approaches.</li>
</ul>

<h3>Title: Multi-Label Classification Framework for Hurricane Damage Assessment</h3>
<ul>
<li><strong>Authors: </strong>Zhangding Liu, Neda Mohammadi, John E. Taylor</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02265">https://arxiv.org/abs/2507.02265</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02265">https://arxiv.org/pdf/2507.02265</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02265]] Multi-Label Classification Framework for Hurricane Damage Assessment(https://arxiv.org/abs/2507.02265)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Hurricanes cause widespread destruction, resulting in diverse damage types and severities that require timely and accurate assessment for effective disaster response. While traditional single-label classification methods fall short of capturing the complexity of post-hurricane damage, this study introduces a novel multi-label classification framework for assessing damage using aerial imagery. The proposed approach integrates a feature extraction module based on ResNet and a class-specific attention mechanism to identify multiple damage types within a single image. Using the Rescuenet dataset from Hurricane Michael, the proposed method achieves a mean average precision of 90.23%, outperforming existing baseline methods. This framework enhances post-hurricane damage assessment, enabling more targeted and efficient disaster response and contributing to future strategies for disaster mitigation and resilience. This paper has been accepted at the ASCE International Conference on Computing in Civil Engineering (i3CE 2025), and the camera-ready version will appear in the official conference proceedings.</li>
</ul>

<h3>Title: Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yuxiang Zhang, Wei Li, Wen Jia, Mengmeng Zhang, Ran Tao, Shunlin Liang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02268">https://arxiv.org/abs/2507.02268</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02268">https://arxiv.org/pdf/2507.02268</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02268]] Cross-domain Hyperspectral Image Classification based on Bi-directional Domain Adaptation(https://arxiv.org/abs/2507.02268)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Utilizing hyperspectral remote sensing technology enables the extraction of fine-grained land cover classes. Typically, satellite or airborne images used for training and testing are acquired from different regions or times, where the same class has significant spectral shifts in different scenes. In this paper, we propose a Bi-directional Domain Adaptation (BiDA) framework for cross-domain hyperspectral image (HSI) classification, which focuses on extracting both domain-invariant features and domain-specific information in the independent adaptive space, thereby enhancing the adaptability and separability to the target scene. In the proposed BiDA, a triple-branch transformer architecture (the source branch, target branch, and coupled branch) with semantic tokenizer is designed as the backbone. Specifically, the source branch and target branch independently learn the adaptive space of source and target domains, a Coupled Multi-head Cross-attention (CMCA) mechanism is developed in coupled branch for feature interaction and inter-domain correlation mining. Furthermore, a bi-directional distillation loss is designed to guide adaptive space learning using inter-domain correlation. Finally, we propose an Adaptive Reinforcement Strategy (ARS) to encourage the model to focus on specific generalized feature extraction within both source and target scenes in noise condition. Experimental results on cross-temporal/scene airborne and satellite datasets demonstrate that the proposed BiDA performs significantly better than some state-of-the-art domain adaptation approaches. In the cross-temporal tree species classification task, the proposed BiDA is more than 3\%$\sim$5\% higher than the most advanced method. The codes will be available from the website: this https URL.</li>
</ul>

<h3>Title: LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Juntao Liu, Liqiang Niu, Wenchao Chen, Jie Zhou, Fandong Meng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02279">https://arxiv.org/abs/2507.02279</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02279">https://arxiv.org/pdf/2507.02279</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02279]] LaCo: Efficient Layer-wise Compression of Visual Tokens for Multimodal Large Language Models(https://arxiv.org/abs/2507.02279)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing visual token compression methods for Multimodal Large Language Models (MLLMs) predominantly operate as post-encoder modules, limiting their potential for efficiency gains. To address this limitation, we propose LaCo (Layer-wise Visual Token Compression), a novel framework that enables effective token compression within the intermediate layers of the vision encoder. LaCo introduces two core components: 1) a layer-wise pixel-shuffle mechanism that systematically merges adjacent tokens through space-to-channel transformations, and 2) a residual learning architecture with non-parametric shortcuts that preserves critical visual information during compression. Extensive experiments indicate that our LaCo outperforms all existing methods when compressing tokens in the intermediate layers of the vision encoder, demonstrating superior effectiveness. In addition, compared to external compression, our method improves training efficiency beyond 20% and inference throughput over 15% while maintaining strong performance.</li>
</ul>

<h3>Title: Linearly Homomorphic Ring Signature Scheme over Lattices</h3>
<ul>
<li><strong>Authors: </strong>Heng Guo, Kun Tian, Fengxia Liu, Zhiyong Zheng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02281">https://arxiv.org/abs/2507.02281</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02281">https://arxiv.org/pdf/2507.02281</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02281]] Linearly Homomorphic Ring Signature Scheme over Lattices(https://arxiv.org/abs/2507.02281)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack</a></li>
<li><strong>Abstract: </strong>Homomorphic ring signature schemes combine the strong anonymity of ring signatures with the computability of homomorphic signatures, demonstrating significant potential in scenarios requiring both anonymous data provenance and verifiable homomorphic computation (e.g., confidential blockchain transactions and secure multi-party computation). However, no feasible homomorphic ring signature scheme currently exists. In this work, we propose the first lattice-based linearly homomorphic ring signature scheme. Proven secure in the standard model under the small integer solution (SIS) assumption, our scheme achieves strong anonymity under full key exposure and unforgeability against insider corruption attacks. As the first unified framework for ring signatures and linear homomorphic signatures, this construction provides a post-quantum-secure solution for the aforementioned applications, advancing the development of privacy-enhanced homomorphic computation.</li>
</ul>

<h3>Title: Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>De Cheng, Zhipeng Xu, Xinyang Jiang, Dongsheng Li, Nannan Wang, Xinbo Gao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02288">https://arxiv.org/abs/2507.02288</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02288">https://arxiv.org/pdf/2507.02288</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02288]] Prompt Disentanglement via Language Guidance and Representation Alignment for Domain Generalization(https://arxiv.org/abs/2507.02288)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Domain Generalization (DG) seeks to develop a versatile model capable of performing effectively on unseen target domains. Notably, recent advances in pre-trained Visual Foundation Models (VFMs), such as CLIP, have demonstrated considerable potential in enhancing the generalization capabilities of deep learning models. Despite the increasing attention toward VFM-based domain prompt tuning within DG, the effective design of prompts capable of disentangling invariant features across diverse domains remains a critical challenge. In this paper, we propose addressing this challenge by leveraging the controllable and flexible language prompt of the VFM. Noting that the text modality of VFMs is naturally easier to disentangle, we introduce a novel framework for text feature-guided visual prompt tuning. This framework first automatically disentangles the text prompt using a large language model (LLM) and then learns domain-invariant visual representation guided by the disentangled text feature. However, relying solely on language to guide visual feature disentanglement has limitations, as visual features can sometimes be too complex or nuanced to be fully captured by descriptive text. To address this, we introduce Worst Explicit Representation Alignment (WERA), which extends text-guided visual prompts by incorporating an additional set of abstract prompts. These prompts enhance source domain diversity through stylized image augmentations, while alignment constraints ensure that visual representations remain consistent across both the original and augmented distributions. Experiments conducted on major DG datasets, including PACS, VLCS, OfficeHome, DomainNet, and TerraInc, demonstrate that our proposed method outperforms state-of-the-art DG methods.</li>
</ul>

<h3>Title: Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications</h3>
<ul>
<li><strong>Authors: </strong>Zhaoyu Zhang, Lingyi Wang, Wei Wu, Fuhui Zhou, Qihui Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02291">https://arxiv.org/abs/2507.02291</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02291">https://arxiv.org/pdf/2507.02291</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02291]] Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic Communications(https://arxiv.org/abs/2507.02291)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Data-driven semantic communication is based on superficial statistical patterns, thereby lacking interpretability and generalization, especially for applications with the presence of unseen data. To address these challenges, we propose a novel knowledge graph-enhanced zero-shot semantic communication (KGZS-SC) network. Guided by the structured semantic information from a knowledge graph-based semantic knowledge base (KG-SKB), our scheme provides generalized semantic representations and enables reasoning for unseen cases. Specifically, the KG-SKB aligns the semantic features in a shared category semantics embedding space and enhances the generalization ability of the transmitter through aligned semantic features, thus reducing communication overhead by selectively transmitting compact visual semantics. At the receiver, zero-shot learning (ZSL) is leveraged to enable direct classification for unseen cases without the demand for retraining or additional computational overhead, thereby enhancing the adaptability and efficiency of the classification process in dynamic or resource-constrained environments. The simulation results conducted on the APY datasets show that the proposed KGZS-SC network exhibits robust generalization and significantly outperforms existing SC frameworks in classifying unseen categories across a range of SNR levels.</li>
</ul>

<h3>Title: ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Hanbo Bi, Yulong Xu, Ya Li, Yongqiang Mao, Boyuan Tong, Chongyang Li, Chunbo Lang, Wenhui Diao, Hongqi Wang, Yingchao Feng, Xian Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02294">https://arxiv.org/abs/2507.02294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02294">https://arxiv.org/pdf/2507.02294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02294]] ViRefSAM: Visual Reference-Guided Segment Anything Model for Remote Sensing Segmentation(https://arxiv.org/abs/2507.02294)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The Segment Anything Model (SAM), with its prompt-driven paradigm, exhibits strong generalization in generic segmentation tasks. However, applying SAM to remote sensing (RS) images still faces two major challenges. First, manually constructing precise prompts for each image (e.g., points or boxes) is labor-intensive and inefficient, especially in RS scenarios with dense small objects or spatially fragmented distributions. Second, SAM lacks domain adaptability, as it is pre-trained primarily on natural images and struggles to capture RS-specific semantics and spatial characteristics, especially when segmenting novel or unseen classes. To address these issues, inspired by few-shot learning, we propose ViRefSAM, a novel framework that guides SAM utilizing only a few annotated reference images that contain class-specific objects. Without requiring manual prompts, ViRefSAM enables automatic segmentation of class-consistent objects across RS images. Specifically, ViRefSAM introduces two key components while keeping SAM's original architecture intact: (1) a Visual Contextual Prompt Encoder that extracts class-specific semantic clues from reference images and generates object-aware prompts via contextual interaction with target images; and (2) a Dynamic Target Alignment Adapter, integrated into SAM's image encoder, which mitigates the domain gap by injecting class-specific semantics into target image features, enabling SAM to dynamically focus on task-relevant regions. Extensive experiments on three few-shot segmentation benchmarks, including iSAID-5$^i$, LoveDA-2$^i$, and COCO-20$^i$, demonstrate that ViRefSAM enables accurate and automatic segmentation of unseen classes by leveraging only a few reference images and consistently outperforms existing few-shot segmentation methods across diverse datasets.</li>
</ul>

<h3>Title: DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation</h3>
<ul>
<li><strong>Authors: </strong>Yunhan Yang, Shuo Chen, Yukun Huang, Xiaoyang Wu, Yuan-Chen Guo, Edmund Y. Lam, Hengshuang Zhao, Tong He, Xihui Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02299">https://arxiv.org/abs/2507.02299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02299">https://arxiv.org/pdf/2507.02299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02299]] DreamComposer++: Empowering Diffusion Models with Multi-View Conditions for 3D Content Generation(https://arxiv.org/abs/2507.02299)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in leveraging pre-trained 2D diffusion models achieve the generation of high-quality novel views from a single in-the-wild image. However, existing works face challenges in producing controllable novel views due to the lack of information from multiple views. In this paper, we present DreamComposer++, a flexible and scalable framework designed to improve current view-aware diffusion models by incorporating multi-view conditions. Specifically, DreamComposer++ utilizes a view-aware 3D lifting module to extract 3D representations of an object from various views. These representations are then aggregated and rendered into the latent features of target view through the multi-view feature fusion module. Finally, the obtained features of target view are integrated into pre-trained image or video diffusion models for novel view synthesis. Experimental results demonstrate that DreamComposer++ seamlessly integrates with cutting-edge view-aware diffusion models and enhances their abilities to generate controllable novel views from multi-view conditions. This advancement facilitates controllable 3D object reconstruction and enables a wide range of applications.</li>
</ul>

<h3>Title: DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Dohoon Kim, Donghun Kang, Taesup Moon</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02302">https://arxiv.org/abs/2507.02302</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02302">https://arxiv.org/pdf/2507.02302</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02302]] DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning(https://arxiv.org/abs/2507.02302)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Domain-Adaptive Pre-training (DAP) has recently gained attention for its effectiveness in fine-tuning pre-trained models. Building on this, continual DAP has been explored to develop pre-trained models capable of incrementally incorporating different domain datasets. However, existing continual DAP methods face several limitations: (1) high computational cost and GPU memory usage during training; (2) sensitivity to incremental data order; and (3) providing a single, generalized model for all end tasks, which contradicts the essence of DAP. In this paper, we propose DoMIX, a novel approach that addresses these challenges by leveraging LoRA modules, a representative parameter-efficient fine-tuning (PEFT) method. Our approach enables efficient and parallel domain-adaptive pre-training that is robust to domain order and effectively utilizes accumulated knowledge to provide tailored pre-trained models for specific tasks. We also demonstrate that our method can be extended beyond the DAP setting to standard LLM fine-tuning scenarios. Code is available at this https URL.</li>
</ul>

<h3>Title: LMPNet for Weakly-supervised Keypoint Discovery</h3>
<ul>
<li><strong>Authors: </strong>Pei Guo, Ryan Farrell</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02308">https://arxiv.org/abs/2507.02308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02308">https://arxiv.org/pdf/2507.02308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02308]] LMPNet for Weakly-supervised Keypoint Discovery(https://arxiv.org/abs/2507.02308)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we explore the task of semantic object keypoint discovery weakly-supervised by only category labels. This is achieved by transforming discriminatively-trained intermediate layer filters into keypoint detectors. We begin by identifying three preferred characteristics of keypoint detectors: (i) spatially sparse activations, (ii) consistency and (iii) diversity. Instead of relying on hand-crafted loss terms, a novel computationally-efficient leaky max pooling (LMP) layer is proposed to explicitly encourage final conv-layer filters to learn "non-repeatable local patterns" that are well aligned with object keypoints. Informed by visualizations, a simple yet effective selection strategy is proposed to ensure consistent filter activations and attention mask-out is then applied to force the network to distribute its attention to the whole object instead of just the most discriminative region. For the final keypoint prediction, a learnable clustering layer is proposed to group keypoint proposals into keypoint predictions. The final model, named LMPNet, is highly interpretable in that it directly manipulates network filters to detect predefined concepts. Our experiments show that LMPNet can (i) automatically discover semantic keypoints that are robust to object pose and (ii) achieves strong prediction accuracy comparable to a supervised pose estimation model.</li>
</ul>

<h3>Title: Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle</h3>
<ul>
<li><strong>Authors: </strong>Anbin Wu (1), Zhiyong Feng (1), Ruitao Feng (2) ((1) The College of Intelligence and Computing, Tianjin University, (2) The Southern Cross University)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02309">https://arxiv.org/abs/2507.02309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02309">https://arxiv.org/pdf/2507.02309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02309]] Rethinking Broken Object Level Authorization Attacks Under Zero Trust Principle(https://arxiv.org/abs/2507.02309)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>RESTful APIs facilitate data exchange between applications, but they also expose sensitive resources to potential exploitation. Broken Object Level Authorization (BOLA) is the top vulnerability in the OWASP API Security Top 10, exemplifies a critical access control flaw where attackers manipulate API parameters to gain unauthorized access. To address this, we propose BOLAZ, a defense framework grounded in zero trust principles. BOLAZ analyzes the data flow of resource IDs, pinpointing BOLA attack injection points and determining the associated authorization intervals to prevent horizontal privilege escalation. Our approach leverages static taint tracking to categorize APIs into producers and consumers based on how they handle resource IDs. By mapping the propagation paths of resource IDs, BOLAZ captures the context in which these IDs are produced and consumed, allowing for precise identification of authorization boundaries. Unlike defense methods based on common authorization models, BOLAZ is the first authorization-guided method that adapts defense rules based on the system's best-practice authorization logic. We validate BOLAZ through empirical research on 10 GitHub projects. The results demonstrate BOLAZ's effectiveness in defending against vulnerabilities collected from CVE and discovering 35 new BOLA vulnerabilities in the wild, demonstrating its practicality in real-world deployments.</li>
</ul>

<h3>Title: Perception Activator: An intuitive and portable framework for brain cognitive exploration</h3>
<ul>
<li><strong>Authors: </strong>Le Xu, Qi Zhang, Qixian Zhang, Hongyun Zhang, Duoqian Miao, Cairong Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02311">https://arxiv.org/abs/2507.02311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02311">https://arxiv.org/pdf/2507.02311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02311]] Perception Activator: An intuitive and portable framework for brain cognitive exploration(https://arxiv.org/abs/2507.02311)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Recent advances in brain-vision decoding have driven significant progress, reconstructing with high fidelity perceived visual stimuli from neural activity, e.g., functional magnetic resonance imaging (fMRI), in the human visual cortex. Most existing methods decode the brain signal using a two-level strategy, i.e., pixel-level and semantic-level. However, these methods rely heavily on low-level pixel alignment yet lack sufficient and fine-grained semantic alignment, resulting in obvious reconstruction distortions of multiple semantic objects. To better understand the brain's visual perception patterns and how current decoding models process semantic objects, we have developed an experimental framework that uses fMRI representations as intervention conditions. By injecting these representations into multi-scale image features via cross-attention, we compare both downstream performance and intermediate feature changes on object detection and instance segmentation tasks with and without fMRI information. Our results demonstrate that incorporating fMRI signals enhances the accuracy of downstream detection and segmentation, confirming that fMRI contains rich multi-object semantic cues and coarse spatial localization information-elements that current models have yet to fully exploit or integrate.</li>
</ul>

<h3>Title: MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation</h3>
<ul>
<li><strong>Authors: </strong>JaeHyuck Choi, MinJun Kim, JeHyeong Hong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02314">https://arxiv.org/abs/2507.02314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02314">https://arxiv.org/pdf/2507.02314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02314]] MAGIC: Mask-Guided Diffusion Inpainting with Multi-Level Perturbations and Context-Aware Alignment for Few-Shot Anomaly Generation(https://arxiv.org/abs/2507.02314)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Few-shot anomaly generation is emerging as a practical solution for augmenting the scarce anomaly data in industrial quality control settings. An ideal generator would meet three demands at once, namely (i) keep the normal background intact, (ii) inpaint anomalous regions to tightly overlap with the corresponding anomaly masks, and (iii) generate anomalous regions in a semantically valid location, while still producing realistic, diverse appearances from only a handful of real examples. Existing diffusion-based methods usually satisfy at most two of these requirements: global anomaly generators corrupt the background, whereas mask-guided ones often falter when the mask is imprecise or misplaced. We propose MAGIC--Mask-guided inpainting with multi-level perturbations and Context-aware alignment--to resolve all three issues. At its core, MAGIC fine-tunes a Stable Diffusion inpainting backbone that preserves normal regions and ensures strict adherence of the synthesized anomaly to the supplied mask, directly addressing background corruption and misalignment. To offset the diversity loss that fine-tuning can cause, MAGIC adds two complementary perturbation strategies: (i) Gaussian prompt-level perturbation applied during fine-tuning and inference that broadens the global appearance of anomalies while avoiding low-fidelity textual appearances, and (ii) mask-guided spatial noise injection that enriches local texture variations. Additionally, the context-aware mask alignment module forms semantic correspondences and relocates masks so that every anomaly remains plausibly contained within the host object, eliminating out-of-boundary artifacts. Under a consistent identical evaluation protocol on the MVTec-AD dataset, MAGIC outperforms previous state-of-the-arts in downstream anomaly tasks.</li>
</ul>

<h3>Title: Transformer-based EEG Decoding: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Haodong Zhang, Hongqi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02320">https://arxiv.org/abs/2507.02320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02320">https://arxiv.org/pdf/2507.02320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02320]] Transformer-based EEG Decoding: A Survey(https://arxiv.org/abs/2507.02320)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Electroencephalography (EEG) is one of the most common signals used to capture the electrical activity of the brain, and the decoding of EEG, to acquire the user intents, has been at the forefront of brain-computer/machine interfaces (BCIs/BMIs) research. Compared to traditional EEG analysis methods with machine learning, the advent of deep learning approaches have gradually revolutionized the field by providing an end-to-end long-cascaded architecture, which can learn more discriminative features automatically. Among these, Transformer is renowned for its strong handling capability of sequential data by the attention mechanism, and the application of Transformers in various EEG processing tasks is increasingly prevalent. This article delves into a relevant survey, summarizing the latest application of Transformer models in EEG decoding since it appeared. The evolution of the model architecture is followed to sort and organize the related advances, in which we first elucidate the fundamentals of the Transformer that benefits EEG decoding and its direct application. Then, the common hybrid architectures by integrating basic Transformer with other deep learning techniques (convolutional/recurrent/graph/spiking neural netwo-rks, generative adversarial networks, diffusion models, etc.) is overviewed in detail. The research advances of applying the modified intrinsic structures of customized Transformer have also been introduced. Finally, the current challenges and future development prospects in this rapidly evolving field are discussed. This paper aims to help readers gain a clear understanding of the current state of Transformer applications in EEG decoding and to provide valuable insights for future research endeavors.</li>
</ul>

<h3>Title: Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback</h3>
<ul>
<li><strong>Authors: </strong>Nina Konovalova, Maxim Nikolaev, Andrey Kuznetsov, Aibek Alanov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02321">https://arxiv.org/abs/2507.02321</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02321">https://arxiv.org/pdf/2507.02321</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02321]] Heeding the Inner Voice: Aligning ControlNet Training via Intermediate Features Feedback(https://arxiv.org/abs/2507.02321)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite significant progress in text-to-image diffusion models, achieving precise spatial control over generated outputs remains challenging. ControlNet addresses this by introducing an auxiliary conditioning module, while ControlNet++ further refines alignment through a cycle consistency loss applied only to the final denoising steps. However, this approach neglects intermediate generation stages, limiting its effectiveness. We propose InnerControl, a training strategy that enforces spatial consistency across all diffusion steps. Our method trains lightweight convolutional probes to reconstruct input control signals (e.g., edges, depth) from intermediate UNet features at every denoising step. These probes efficiently extract signals even from highly noisy latents, enabling pseudo ground truth controls for training. By minimizing the discrepancy between predicted and target conditions throughout the entire diffusion process, our alignment loss improves both control fidelity and generation quality. Combined with established techniques like ControlNet++, InnerControl achieves state-of-the-art performance across diverse conditioning methods (e.g., edges, depth).</li>
</ul>

<h3>Title: Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model</h3>
<ul>
<li><strong>Authors: </strong>Farida Siddiqi Prity, Mirza Raquib, Saydul Akbar Murad, Md. Jubayar Alam Rafi, Md. Khairul Bashar Bhuiyan, Anupam Kumar Bairagi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02322">https://arxiv.org/abs/2507.02322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02322">https://arxiv.org/pdf/2507.02322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02322]] Neural Network-based Study for Rice Leaf Disease Recognition and Classification: A Comparative Analysis Between Feature-based Model and Direct Imaging Model(https://arxiv.org/abs/2507.02322)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Rice leaf diseases significantly reduce productivity and cause economic losses, highlighting the need for early detection to enable effective management and improve yields. This study proposes Artificial Neural Network (ANN)-based image-processing techniques for timely classification and recognition of rice diseases. Despite the prevailing approach of directly inputting images of rice leaves into ANNs, there is a noticeable absence of thorough comparative analysis between the Feature Analysis Detection Model (FADM) and Direct Image-Centric Detection Model (DICDM), specifically when it comes to evaluating the effectiveness of Feature Extraction Algorithms (FEAs). Hence, this research presents initial experiments on the Feature Analysis Detection Model, utilizing various image Feature Extraction Algorithms, Dimensionality Reduction Algorithms (DRAs), Feature Selection Algorithms (FSAs), and Extreme Learning Machine (ELM). The experiments are carried out on datasets encompassing bacterial leaf blight, brown spot, leaf blast, leaf scald, Sheath blight rot, and healthy leaf, utilizing 10-fold Cross-Validation method. A Direct Image-Centric Detection Model is established without the utilization of any FEA, and the evaluation of classification performance relies on different metrics. Ultimately, an exhaustive contrast is performed between the achievements of the Feature Analysis Detection Model and Direct Image-Centric Detection Model in classifying rice leaf diseases. The results reveal that the highest performance is attained using the Feature Analysis Detection Model. The adoption of the proposed Feature Analysis Detection Model for detecting rice leaf diseases holds excellent potential for improving crop health, minimizing yield losses, and enhancing overall productivity and sustainability of rice farming.</li>
</ul>

<h3>Title: PII Jailbreaking in LLMs via Activation Steering Reveals Personal Information Leakage</h3>
<ul>
<li><strong>Authors: </strong>Krishna Kanth Nakka, Xue Jiang, Xuebing Zhou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02332">https://arxiv.org/abs/2507.02332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02332">https://arxiv.org/pdf/2507.02332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02332]] PII Jailbreaking in LLMs via Activation Steering Reveals Personal Information Leakage(https://arxiv.org/abs/2507.02332)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper investigates privacy jailbreaking in LLMs via steering, focusing on whether manipulating activations can bypass LLM alignment and alter response behaviors to privacy related queries (e.g., a certain public figure's sexual orientation). We begin by identifying attention heads predictive of refusal behavior for private attributes (e.g., sexual orientation) using lightweight linear probes trained with privacy evaluator labels. Next, we steer the activations of a small subset of these attention heads guided by the trained probes to induce the model to generate non-refusal responses. Our experiments show that these steered responses often disclose sensitive attribute details, along with other private information about data subjects such as life events, relationships, and personal histories that the models would typically refuse to produce. Evaluations across four LLMs reveal jailbreaking disclosure rates of at least 95%, with more than 50% on average of these responses revealing true personal information. Our controlled study demonstrates that private information memorized in LLMs can be extracted through targeted manipulation of internal activations.</li>
</ul>

<h3>Title: Lightweight Shrimp Disease Detection Research Based on YOLOv8n</h3>
<ul>
<li><strong>Authors: </strong>Fei Yuhuan, Wang Gengchen, Liu Fenghao, Zang Ran, Sun Xufei, Chang Hao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02354">https://arxiv.org/abs/2507.02354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02354">https://arxiv.org/pdf/2507.02354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02354]] Lightweight Shrimp Disease Detection Research Based on YOLOv8n(https://arxiv.org/abs/2507.02354)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Shrimp diseases are one of the primary causes of economic losses in shrimp aquaculture. To prevent disease transmission and enhance intelligent detection efficiency in shrimp farming, this paper proposes a lightweight network architecture based on YOLOv8n. First, by designing the RLDD detection head and C2f-EMCM module, the model reduces computational complexity while maintaining detection accuracy, improving computational efficiency. Subsequently, an improved SegNext_Attention self-attention mechanism is introduced to further enhance the model's feature extraction capability, enabling more precise identification of disease characteristics. Extensive experiments, including ablation studies and comparative evaluations, are conducted on a self-constructed shrimp disease dataset, with generalization tests extended to the URPC2020 dataset. Results demonstrate that the proposed model achieves a 32.3% reduction in parameters compared to the original YOLOv8n, with a mAP@0.5 of 92.7% (3% improvement over YOLOv8n). Additionally, the model outperforms other lightweight YOLO-series models in mAP@0.5, parameter count, and model size. Generalization experiments on the URPC2020 dataset further validate the model's robustness, showing a 4.1% increase in mAP@0.5 compared to YOLOv8n. The proposed method achieves an optimal balance between accuracy and efficiency, providing reliable technical support for intelligent disease detection in shrimp aquaculture.</li>
</ul>

<h3>Title: Offline Reinforcement Learning with Penalized Action Noise Injection</h3>
<ul>
<li><strong>Authors: </strong>JunHyeok Oh, Byung-Jun Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02356">https://arxiv.org/abs/2507.02356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02356">https://arxiv.org/pdf/2507.02356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02356]] Offline Reinforcement Learning with Penalized Action Noise Injection(https://arxiv.org/abs/2507.02356)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Offline reinforcement learning (RL) optimizes a policy using only a fixed dataset, making it a practical approach in scenarios where interaction with the environment is costly. Due to this limitation, generalization ability is key to improving the performance of offline RL algorithms, as demonstrated by recent successes of offline RL with diffusion models. However, it remains questionable whether such diffusion models are necessary for highly performing offline RL algorithms, given their significant computational requirements during inference. In this paper, we propose Penalized Action Noise Injection (PANI), a method that simply enhances offline learning by utilizing noise-injected actions to cover the entire action space, while penalizing according to the amount of noise injected. This approach is inspired by how diffusion models have worked in offline RL algorithms. We provide a theoretical foundation for this method, showing that offline RL algorithms with such noise-injected actions solve a modified Markov Decision Process (MDP), which we call the noisy action MDP. PANI is compatible with a wide range of existing off-policy and offline RL algorithms, and despite its simplicity, it demonstrates significant performance improvements across various benchmarks.</li>
</ul>

<h3>Title: Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Christian Jaumann, Annemarie Friedrich, Rainer Lienhart</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02357">https://arxiv.org/abs/2507.02357</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02357">https://arxiv.org/pdf/2507.02357</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02357]] Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models(https://arxiv.org/abs/2507.02357)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper describes our system for the SciVQA 2025 Shared Task on Scientific Visual Question Answering. Our system employs an ensemble of two Multimodal Large Language Models and various few-shot example retrieval strategies. The model and few-shot setting are selected based on the figure and question type. We also select answers based on the models' confidence levels. On the blind test data, our system ranks third out of seven with an average F1 score of 85.12 across ROUGE-1, ROUGE-L, and BERTS. Our code is publicly available.</li>
</ul>

<h3>Title: QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers</h3>
<ul>
<li><strong>Authors: </strong>Pilsung Kang</a></li>
<li><strong>Subjects: </strong>cs.CL, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02364">https://arxiv.org/abs/2507.02364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02364">https://arxiv.org/pdf/2507.02364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02364]] QFFN-BERT: An Empirical Study of Depth, Performance, and Data Efficiency in Hybrid Quantum-Classical Transformers(https://arxiv.org/abs/2507.02364)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Parameterized quantum circuits (PQCs) have recently emerged as promising components for enhancing the expressibility of neural architectures. In this work, we introduce QFFN-BERT, a hybrid quantum-classical transformer where the feedforward network (FFN) modules of a compact BERT variant are replaced by PQC-based layers. This design is motivated by the dominant parameter contribution of FFNs, which account for approximately two-thirds of the parameters within standard Transformer encoder blocks. While prior studies have primarily integrated PQCs into self-attention modules, our work focuses on the FFN and systematically investigates the trade-offs between PQC depth, expressibility, and trainability. Our final PQC architecture incorporates a residual connection, both $R_Y$ and $R_Z$ rotations, and an alternating entanglement strategy to ensure stable training and high expressibility. Our experiments, conducted on a classical simulator, on the SST-2 and DBpedia benchmarks demonstrate two key findings. First, a carefully configured QFFN-BERT achieves up to 102.0% of the baseline accuracy, surpassing its classical counterpart in a full-data setting while reducing FFN-specific parameters by over 99%. Second, our model exhibits a consistent and competitive edge in few-shot learning scenarios, confirming its potential for superior data efficiency. These results, supported by an ablation study on a non-optimized PQC that failed to learn, confirm that PQCs can serve as powerful and parameter-efficient alternatives to classical FFNs when co-designed with foundational deep learning principles.</li>
</ul>

<h3>Title: Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Usama, Dong Eui Chang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02365">https://arxiv.org/abs/2507.02365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02365">https://arxiv.org/pdf/2507.02365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02365]] Deep Reinforcement Learning-Based DRAM Equalizer Parameter Optimization Using Latent Representations(https://arxiv.org/abs/2507.02365)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Equalizer parameter optimization for signal integrity in high-speed Dynamic Random Access Memory systems is crucial but often computationally demanding or model-reliant. This paper introduces a data-driven framework employing learned latent signal representations for efficient signal integrity evaluation, coupled with a model-free Advantage Actor-Critic reinforcement learning agent for parameter optimization. The latent representation captures vital signal integrity features, offering a fast alternative to direct eye diagram analysis during optimization, while the reinforcement learning agent derives optimal equalizer settings without explicit system models. Applied to industry-standard Dynamic Random Access Memory waveforms, the method achieved significant eye-opening window area improvements: 42.7\% for cascaded Continuous-Time Linear Equalizer and Decision Feedback Equalizer structures, and 36.8\% for Decision Feedback Equalizer-only configurations. These results demonstrate superior performance, computational efficiency, and robust generalization across diverse Dynamic Random Access Memory units compared to existing techniques. Core contributions include an efficient latent signal integrity metric for optimization, a robust model-free reinforcement learning strategy, and validated superior performance for complex equalizer architectures.</li>
</ul>

<h3>Title: UVLM: Benchmarking Video Language Model for Underwater World Understanding</h3>
<ul>
<li><strong>Authors: </strong>Xizhe Xue, Yang Zhou, Dawei Yan, Ying Li, Haokui Zhang, Rong Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02373">https://arxiv.org/abs/2507.02373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02373">https://arxiv.org/pdf/2507.02373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02373]] UVLM: Benchmarking Video Language Model for Underwater World Understanding(https://arxiv.org/abs/2507.02373)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently, the remarkable success of large language models (LLMs) has achieved a profound impact on the field of artificial intelligence. Numerous advanced works based on LLMs have been proposed and applied in various scenarios. Among them, video language models (VidLMs) are particularly widely used. However, existing works primarily focus on terrestrial scenarios, overlooking the highly demanding application needs of underwater observation. To overcome this gap, we introduce UVLM, an under water observation benchmark which is build through a collaborative approach combining human expertise and AI models. To ensure data quality, we have conducted in-depth considerations from multiple perspectives. First, to address the unique challenges of underwater environments, we selected videos that represent typical underwater challenges including light variations, water turbidity, and diverse viewing angles to construct the dataset. Second, to ensure data diversity, the dataset covers a wide range of frame rates, resolutions, 419 classes of marine animals, and various static plants and terrains. Next, for task diversity, we adopted a structured design where observation targets are categorized into two major classes: biological and environmental. Each category includes content observation and change/action observation, totaling 20 distinct task types. Finally, we designed several challenging evaluation metrics to enable quantitative comparison and analysis of different methods. Experiments on two representative VidLMs demonstrate that fine-tuning VidLMs on UVLM significantly improves underwater world understanding while also showing potential for slight improvements on existing in-air VidLM benchmarks, such as VideoMME and Perception text. The dataset and prompt engineering will be released publicly.</li>
</ul>

<h3>Title: Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection</h3>
<ul>
<li><strong>Authors: </strong>Weijie Lyu, Sheng-Jun Huang, Xuan Xia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02378">https://arxiv.org/abs/2507.02378</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02378">https://arxiv.org/pdf/2507.02378</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02378]] Efficient Code LLM Training via Distribution-Consistent and Diversity-Aware Data Selection(https://arxiv.org/abs/2507.02378)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have significantly improved code generation and program comprehension, accelerating the evolution of software engineering. Current methods primarily enhance model performance by leveraging vast amounts of data, focusing on data quantity while often overlooking data quality, thereby reducing training efficiency. To address this, we introduce an approach that utilizes a parametric model for code data selection, aimed at improving both training efficiency and model performance. Our method optimizes the parametric model to ensure distribution consistency and diversity within the selected subset, guaranteeing high-quality data. Experimental results demonstrate that using only 10K samples, our method achieves gains of 2.4% (HumanEval) and 2.3% (MBPP) over 92K full-sampled baseline, outperforming other sampling approaches in both performance and efficiency. This underscores that our method effectively boosts model performance while significantly reducing computational costs.</li>
</ul>

<h3>Title: Evaluating Language Models For Threat Detection in IoT Security Logs</h3>
<ul>
<li><strong>Authors: </strong>Jorge J. Tejero-Fernández, Alfonso Sánchez-Macián</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02390">https://arxiv.org/abs/2507.02390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02390">https://arxiv.org/pdf/2507.02390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02390]] Evaluating Language Models For Threat Detection in IoT Security Logs(https://arxiv.org/abs/2507.02390)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Log analysis is a relevant research field in cybersecurity as they can provide a source of information for the detection of threats to networks and systems. This paper presents a pipeline to use fine-tuned Large Language Models (LLMs) for anomaly detection and mitigation recommendation using IoT security logs. Utilizing classical machine learning classifiers as a baseline, three open-source LLMs are compared for binary and multiclass anomaly detection, with three strategies: zero-shot, few-shot prompting and fine-tuning using an IoT dataset. LLMs give better results on multi-class attack classification than the corresponding baseline models. By mapping detected threats to MITRE CAPEC, defining a set of IoT-specific mitigation actions, and fine-tuning the models with those actions, the models are able to provide a combined detection and recommendation guidance.</li>
</ul>

<h3>Title: PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Seokyeong Lee, Sithu Aung, Junyong Choi, Seungryong Kim, Ig-Jae Kim, Junghyun Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02393">https://arxiv.org/abs/2507.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02393">https://arxiv.org/pdf/2507.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02393]] PLOT: Pseudo-Labeling via Video Object Tracking for Scalable Monocular 3D Object Detection(https://arxiv.org/abs/2507.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Monocular 3D object detection (M3OD) has long faced challenges due to data scarcity caused by high annotation costs and inherent 2D-to-3D ambiguity. Although various weakly supervised methods and pseudo-labeling methods have been proposed to address these issues, they are mostly limited by domain-specific learning or rely solely on shape information from a single observation. In this paper, we propose a novel pseudo-labeling framework that uses only video data and is more robust to occlusion, without requiring a multi-view setup, additional sensors, camera poses, or domain-specific training. Specifically, we explore a technique for aggregating the pseudo-LiDARs of both static and dynamic objects across temporally adjacent frames using object point tracking, enabling 3D attribute extraction in scenarios where 3D data acquisition is infeasible. Extensive experiments demonstrate that our method ensures reliable accuracy and strong scalability, making it a practical and effective solution for M3OD.</li>
</ul>

<h3>Title: Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Byung Hyun Lee, Wongi Jeong, Woojae Han, Kyoungbun Lee, Se Young Chun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02395">https://arxiv.org/abs/2507.02395</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02395">https://arxiv.org/pdf/2507.02395</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02395]] Continual Multiple Instance Learning with Enhanced Localization for Histopathological Whole Slide Image Analysis(https://arxiv.org/abs/2507.02395)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Multiple instance learning (MIL) significantly reduced annotation costs via bag-level weak labels for large-scale images, such as histopathological whole slide images (WSIs). However, its adaptability to continual tasks with minimal forgetting has been rarely explored, especially on instance classification for localization. Weakly incremental learning for semantic segmentation has been studied for continual localization, but it focused on natural images, leveraging global relationships among hundreds of small patches (e.g., $16 \times 16$) using pre-trained models. This approach seems infeasible for MIL localization due to enormous amounts ($\sim 10^5$) of large patches (e.g., $256 \times 256$) and no available global relationships such as cancer cells. To address these challenges, we propose Continual Multiple Instance Learning with Enhanced Localization (CoMEL), an MIL framework for both localization and adaptability with minimal forgetting. CoMEL consists of (1) Grouped Double Attention Transformer (GDAT) for efficient instance encoding, (2) Bag Prototypes-based Pseudo-Labeling (BPPL) for reliable instance pseudo-labeling, and (3) Orthogonal Weighted Low-Rank Adaptation (OWLoRA) to mitigate forgetting in both bag and instance classification. Extensive experiments on three public WSI datasets demonstrate superior performance of CoMEL, outperforming the prior arts by up to $11.00\%$ in bag-level accuracy and up to $23.4\%$ in localization accuracy under the continual MIL setup.</li>
</ul>

<h3>Title: Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection</h3>
<ul>
<li><strong>Authors: </strong>Taehoon Kim, Jongwook Choi, Yonghyun Jeong, Haeun Noh, Jaejun Yoo, Seungryul Baek, Jongwon Choi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02398">https://arxiv.org/abs/2507.02398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02398">https://arxiv.org/pdf/2507.02398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02398]] Beyond Spatial Frequency: Pixel-wise Temporal Frequency-based Deepfake Video Detection(https://arxiv.org/abs/2507.02398)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We introduce a deepfake video detection approach that exploits pixel-wise temporal inconsistencies, which traditional spatial frequency-based detectors often overlook. Traditional detectors represent temporal information merely by stacking spatial frequency spectra across frames, resulting in the failure to detect temporal artifacts in the pixel plane. Our approach performs a 1D Fourier transform on the time axis for each pixel, extracting features highly sensitive to temporal inconsistencies, especially in areas prone to unnatural movements. To precisely locate regions containing the temporal artifacts, we introduce an attention proposal module trained in an end-to-end manner. Additionally, our joint transformer module effectively integrates pixel-wise temporal frequency features with spatio-temporal context features, expanding the range of detectable forgery artifacts. Our framework represents a significant advancement in deepfake video detection, providing robust performance across diverse and challenging detection scenarios.</li>
</ul>

<h3>Title: TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Peilin Zhang, Shaouxan Wua, Jun Feng, Zhuo Jin, Zhizezhang Gao, Jingkun Chen, Yaqiong Xing, Xiao Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02399">https://arxiv.org/abs/2507.02399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02399">https://arxiv.org/pdf/2507.02399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02399]] TABNet: A Triplet Augmentation Self-Recovery Framework with Boundary-Aware Pseudo-Labels for Medical Image Segmentation(https://arxiv.org/abs/2507.02399)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Background and objective: Medical image segmentation is a core task in various clinical applications. However, acquiring large-scale, fully annotated medical image datasets is both time-consuming and costly. Scribble annotations, as a form of sparse labeling, provide an efficient and cost-effective alternative for medical image segmentation. However, the sparsity of scribble annotations limits the feature learning of the target region and lacks sufficient boundary supervision, which poses significant challenges for training segmentation networks. Methods: We propose TAB Net, a novel weakly-supervised medical image segmentation framework, consisting of two key components: the triplet augmentation self-recovery (TAS) module and the boundary-aware pseudo-label supervision (BAP) module. The TAS module enhances feature learning through three complementary augmentation strategies: intensity transformation improves the model's sensitivity to texture and contrast variations, cutout forces the network to capture local anatomical structures by masking key regions, and jigsaw augmentation strengthens the modeling of global anatomical layout by disrupting spatial continuity. By guiding the network to recover complete masks from diverse augmented inputs, TAS promotes a deeper semantic understanding of medical images under sparse supervision. The BAP module enhances pseudo-supervision accuracy and boundary modeling by fusing dual-branch predictions into a loss-weighted pseudo-label and introducing a boundary-aware loss for fine-grained contour refinement. Results: Experimental evaluations on two public datasets, ACDC and MSCMR seg, demonstrate that TAB Net significantly outperforms state-of-the-art methods for scribble-based weakly supervised segmentation. Moreover, it achieves performance comparable to that of fully supervised methods.</li>
</ul>

<h3>Title: Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings</h3>
<ul>
<li><strong>Authors: </strong>Mufhumudzi Muthivhi, Terence L. van Zyl</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02403">https://arxiv.org/abs/2507.02403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02403">https://arxiv.org/pdf/2507.02403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02403]] Wildlife Target Re-Identification Using Self-supervised Learning in Non-Urban Settings(https://arxiv.org/abs/2507.02403)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Wildlife re-identification aims to match individuals of the same species across different observations. Current state-of-the-art (SOTA) models rely on class labels to train supervised models for individual classification. This dependence on annotated data has driven the curation of numerous large-scale wildlife datasets. This study investigates self-supervised learning Self-Supervised Learning (SSL) for wildlife re-identification. We automatically extract two distinct views of an individual using temporal image pairs from camera trap data without supervision. The image pairs train a self-supervised model from a potentially endless stream of video data. We evaluate the learnt representations against supervised features on open-world scenarios and transfer learning in various wildlife downstream tasks. The analysis of the experimental results shows that self-supervised models are more robust even with limited data. Moreover, self-supervised features outperform supervision across all downstream tasks. The code is available here this https URL.</li>
</ul>

<h3>Title: PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration</h3>
<ul>
<li><strong>Authors: </strong>Ayantika Das, Moitreya Chaudhuri, Koushik Bhat, Keerthi Ram, Mihail Bota, Mohanasankar Sivaprakasam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02405">https://arxiv.org/abs/2507.02405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02405">https://arxiv.org/pdf/2507.02405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02405]] PosDiffAE: Position-aware Diffusion Auto-encoder For High-Resolution Brain Tissue Classification Incorporating Artifact Restoration(https://arxiv.org/abs/2507.02405)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Denoising diffusion models produce high-fidelity image samples by capturing the image distribution in a progressive manner while initializing with a simple distribution and compounding the distribution complexity. Although these models have unlocked new applicabilities, the sampling mechanism of diffusion does not offer means to extract image-specific semantic representation, which is inherently provided by auto-encoders. The encoding component of auto-encoders enables mapping between a specific image and its latent space, thereby offering explicit means of enforcing structures in the latent space. By integrating an encoder with the diffusion model, we establish an auto-encoding formulation, which learns image-specific representations and offers means to organize the latent space. In this work, First, we devise a mechanism to structure the latent space of a diffusion auto-encoding model, towards recognizing region-specific cellular patterns in brain images. We enforce the representations to regress positional information of the patches from high-resolution images. This creates a conducive latent space for differentiating tissue types of the brain. Second, we devise an unsupervised tear artifact restoration technique based on neighborhood awareness, utilizing latent representations and the constrained generation capability of diffusion models during inference. Third, through representational guidance and leveraging the inference time steerable noising and denoising capability of diffusion, we devise an unsupervised JPEG artifact restoration technique.</li>
</ul>

<h3>Title: Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Caio Azevedo, Lina Achaji, Stefano Sabatini, Nicola Poerio, Grzegorz Bartyzel, Sascha Hornauer, Fabien Moutarde</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02406">https://arxiv.org/abs/2507.02406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02406">https://arxiv.org/pdf/2507.02406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02406]] Improving Consistency in Vehicle Trajectory Prediction Through Preference Optimization(https://arxiv.org/abs/2507.02406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Trajectory prediction is an essential step in the pipeline of an autonomous vehicle. Inaccurate or inconsistent predictions regarding the movement of agents in its surroundings lead to poorly planned maneuvers and potentially dangerous situations for the end-user. Current state-of-the-art deep-learning-based trajectory prediction models can achieve excellent accuracy on public datasets. However, when used in more complex, interactive scenarios, they often fail to capture important interdependencies between agents, leading to inconsistent predictions among agents in the traffic scene. Inspired by the efficacy of incorporating human preference into large language models, this work fine-tunes trajectory prediction models in multi-agent settings using preference optimization. By taking as input automatically calculated preference rankings among predicted futures in the fine-tuning process, our experiments--using state-of-the-art models on three separate datasets--show that we are able to significantly improve scene consistency while minimally sacrificing trajectory prediction accuracy and without adding any excess computational requirements at inference time.</li>
</ul>

<h3>Title: Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability</h3>
<ul>
<li><strong>Authors: </strong>Mark Atta Mensah, Isaac Wiafe, Akon Ekpezu, Justice Kwame Appati, Jamal-Deen Abdulai, Akosua Nyarkoa Wiafe-Akenten, Frank Ernest Yeboah, Gifty Odame</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02407">https://arxiv.org/abs/2507.02407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02407">https://arxiv.org/pdf/2507.02407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02407]] Benchmarking Akan ASR Models Across Domain-Specific Datasets: A Comparative Evaluation of Performance, Scalability, and Adaptability(https://arxiv.org/abs/2507.02407)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Most existing automatic speech recognition (ASR) research evaluate models using in-domain datasets. However, they seldom evaluate how they generalize across diverse speech contexts. This study addresses this gap by benchmarking seven Akan ASR models built on transformer architectures, such as Whisper and Wav2Vec2, using four Akan speech corpora to determine their performance. These datasets encompass various domains, including culturally relevant image descriptions, informal conversations, biblical scripture readings, and spontaneous financial dialogues. A comparison of the word error rate and character error rate highlighted domain dependency, with models performing optimally only within their training domains while showing marked accuracy degradation in mismatched scenarios. This study also identified distinct error behaviors between the Whisper and Wav2Vec2 architectures. Whereas fine-tuned Whisper Akan models led to more fluent but potentially misleading transcription errors, Wav2Vec2 produced more obvious yet less interpretable outputs when encountering unfamiliar inputs. This trade-off between readability and transparency in ASR errors should be considered when selecting architectures for low-resource language (LRL) applications. These findings highlight the need for targeted domain adaptation techniques, adaptive routing strategies, and multilingual training frameworks for Akan and other LRLs.</li>
</ul>

<h3>Title: A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern</h3>
<ul>
<li><strong>Authors: </strong>Duong Nguyen-Ngoc Tran, Long Hoang Pham, Chi Dai Tran, Quoc Pham-Nam Ho, Huy-Hung Nguyen, Jae Wook Jeon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02408">https://arxiv.org/abs/2507.02408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02408">https://arxiv.org/pdf/2507.02408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02408]] A Novel Tuning Method for Real-time Multiple-Object Tracking Utilizing Thermal Sensor with Complexity Motion Pattern(https://arxiv.org/abs/2507.02408)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-Object Tracking in thermal images is essential for surveillance systems, particularly in challenging environments where RGB cameras struggle due to low visibility or poor lighting conditions. Thermal sensors enhance recognition tasks by capturing infrared signatures, but a major challenge is their low-level feature representation, which makes it difficult to accurately detect and track pedestrians. To address this, the paper introduces a novel tuning method for pedestrian tracking, specifically designed to handle the complex motion patterns in thermal imagery. The proposed framework optimizes two-stages, ensuring that each stage is tuned with the most suitable hyperparameters to maximize tracking performance. By fine-tuning hyperparameters for real-time tracking, the method achieves high accuracy without relying on complex reidentification or motion models. Extensive experiments on PBVS Thermal MOT dataset demonstrate that the approach is highly effective across various thermal camera conditions, making it a robust solution for real-world surveillance applications.</li>
</ul>

<h3>Title: S2FGL: Spatial Spectral Federated Graph Learning</h3>
<ul>
<li><strong>Authors: </strong>Zihan Tan, Suyuan Huang, Guancheng Wan, Wenke Huang, He Li, Mang Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02409">https://arxiv.org/abs/2507.02409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02409">https://arxiv.org/pdf/2507.02409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02409]] S2FGL: Spatial Spectral Federated Graph Learning(https://arxiv.org/abs/2507.02409)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Graph Learning (FGL) combines the privacy-preserving capabilities of federated learning (FL) with the strong graph modeling capability of Graph Neural Networks (GNNs). Current research addresses subgraph-FL only from the structural perspective, neglecting the propagation of graph signals on spatial and spectral domains of the structure. From a spatial perspective, subgraph-FL introduces edge disconnections between clients, leading to disruptions in label signals and a degradation in the class knowledge of the global GNN. From a spectral perspective, spectral heterogeneity causes inconsistencies in signal frequencies across subgraphs, which makes local GNNs overfit the local signal propagation schemes. As a result, spectral client drifts occur, undermining global generalizability. To tackle the challenges, we propose a global knowledge repository to mitigate label signal disruption and a frequency alignment to address spectral client drifts. The combination of spatial and spectral strategies forms our framework S2FGL. Extensive experiments on multiple datasets demonstrate the superiority of S2FGL. The code is available at this https URL.</li>
</ul>

<h3>Title: Privacy-preserving Preselection for Face Identification Based on Packing</h3>
<ul>
<li><strong>Authors: </strong>Rundong Xin, Taotao Wang, Jin Wang, Chonghe Zhao, Jing Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02414">https://arxiv.org/abs/2507.02414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02414">https://arxiv.org/pdf/2507.02414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02414]] Privacy-preserving Preselection for Face Identification Based on Packing(https://arxiv.org/abs/2507.02414)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, biometric</a></li>
<li><strong>Abstract: </strong>Face identification systems operating in the ciphertext domain have garnered significant attention due to increasing privacy concerns and the potential recovery of original facial data. However, as the size of ciphertext template libraries grows, the face retrieval process becomes progressively more time-intensive. To address this challenge, we propose a novel and efficient scheme for face retrieval in the ciphertext domain, termed Privacy-Preserving Preselection for Face Identification Based on Packing (PFIP). PFIP incorporates an innovative preselection mechanism to reduce computational overhead and a packing module to enhance the flexibility of biometric systems during the enrollment stage. Extensive experiments conducted on the LFW and CASIA datasets demonstrate that PFIP preserves the accuracy of the original face recognition model, achieving a 100% hit rate while retrieving 1,000 ciphertext face templates within 300 milliseconds. Compared to existing approaches, PFIP achieves a nearly 50x improvement in retrieval efficiency.</li>
</ul>

<h3>Title: Determination Of Structural Cracks Using Deep Learning Frameworks</h3>
<ul>
<li><strong>Authors: </strong>Subhasis Dasgupta, Jaydip Sen, Tuhina Halder</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02416">https://arxiv.org/abs/2507.02416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02416">https://arxiv.org/pdf/2507.02416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02416]] Determination Of Structural Cracks Using Deep Learning Frameworks(https://arxiv.org/abs/2507.02416)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Structural crack detection is a critical task for public safety as it helps in preventing potential structural failures that could endanger lives. Manual detection by inexperienced personnel can be slow, inconsistent, and prone to human error, which may compromise the reliability of assessments. The current study addresses these challenges by introducing a novel deep-learning architecture designed to enhance the accuracy and efficiency of structural crack detection. In this research, various configurations of residual U-Net models were utilized. These models, due to their robustness in capturing fine details, were further integrated into an ensemble with a meta-model comprising convolutional blocks. This unique combination aimed to boost prediction efficiency beyond what individual models could achieve. The ensemble's performance was evaluated against well-established architectures such as SegNet and the traditional U-Net. Results demonstrated that the residual U-Net models outperformed their predecessors, particularly with low-resolution imagery, and the ensemble model exceeded the performance of individual models, proving it as the most effective. The assessment was based on the Intersection over Union (IoU) metric and DICE coefficient. The ensemble model achieved the highest scores, signifying superior accuracy. This advancement suggests way for more reliable automated systems in structural defects monitoring tasks.</li>
</ul>

<h3>Title: AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars</h3>
<ul>
<li><strong>Authors: </strong>Yiming Zhong, Xiaolin Zhang, Ligang Liu, Yao Zhao, Yunchao Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02419">https://arxiv.org/abs/2507.02419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02419">https://arxiv.org/pdf/2507.02419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02419]] AvatarMakeup: Realistic Makeup Transfer for 3D Animatable Head Avatars(https://arxiv.org/abs/2507.02419)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Similar to facial beautification in real life, 3D virtual avatars require personalized customization to enhance their visual appeal, yet this area remains insufficiently explored. Although current 3D Gaussian editing methods can be adapted for facial makeup purposes, these methods fail to meet the fundamental requirements for achieving realistic makeup effects: 1) ensuring a consistent appearance during drivable expressions, 2) preserving the identity throughout the makeup process, and 3) enabling precise control over fine details. To address these, we propose a specialized 3D makeup method named AvatarMakeup, leveraging a pretrained diffusion model to transfer makeup patterns from a single reference photo of any individual. We adopt a coarse-to-fine idea to first maintain the consistent appearance and identity, and then to refine the details. In particular, the diffusion model is employed to generate makeup images as supervision. Due to the uncertainties in diffusion process, the generated images are inconsistent across different viewpoints and expressions. Therefore, we propose a Coherent Duplication method to coarsely apply makeup to the target while ensuring consistency across dynamic and multiview effects. Coherent Duplication optimizes a global UV map by recoding the averaged facial attributes among the generated makeup images. By querying the global UV map, it easily synthesizes coherent makeup guidance from arbitrary views and expressions to optimize the target avatar. Given the coarse makeup avatar, we further enhance the makeup by incorporating a Refinement Module into the diffusion model to achieve high makeup quality. Experiments demonstrate that AvatarMakeup achieves state-of-the-art makeup transfer quality and consistency throughout animation.</li>
</ul>

<h3>Title: CyberRAG: An agentic RAG cyber attack classification and reporting tool</h3>
<ul>
<li><strong>Authors: </strong>Francesco Blefari, Cristian Cosentino, Francesco Aurelio Pironti, Angelo Furfaro, Fabrizio Marozzo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02424">https://arxiv.org/abs/2507.02424</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02424">https://arxiv.org/pdf/2507.02424</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02424]] CyberRAG: An agentic RAG cyber attack classification and reporting tool(https://arxiv.org/abs/2507.02424)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, interpretability</a></li>
<li><strong>Abstract: </strong>Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.</li>
</ul>

<h3>Title: IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising</h3>
<ul>
<li><strong>Authors: </strong>Hailong Yan, Junjian Huang, Tingwen Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02445">https://arxiv.org/abs/2507.02445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02445">https://arxiv.org/pdf/2507.02445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02445]] IGDNet: Zero-Shot Robust Underexposed Image Enhancement via Illumination-Guided and Denoising(https://arxiv.org/abs/2507.02445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current methods for restoring underexposed images typically rely on supervised learning with paired underexposed and well-illuminated images. However, collecting such datasets is often impractical in real-world scenarios. Moreover, these methods can lead to over-enhancement, distorting well-illuminated regions. To address these issues, we propose IGDNet, a Zero-Shot enhancement method that operates solely on a single test image, without requiring guiding priors or training data. IGDNet exhibits strong generalization ability and effectively suppresses noise while restoring illumination. The framework comprises a decomposition module and a denoising module. The former separates the image into illumination and reflection components via a dense connection network, while the latter enhances non-uniformly illuminated regions using an illumination-guided pixel adaptive correction method. A noise pair is generated through downsampling and refined iteratively to produce the final result. Extensive experiments on four public datasets demonstrate that IGDNet significantly improves visual quality under complex lighting conditions. Quantitative results on metrics like PSNR (20.41dB) and SSIM (0.860dB) show that it outperforms 14 state-of-the-art unsupervised methods. The code will be released soon.</li>
</ul>

<h3>Title: Effectively Identifying Wi-Fi Devices through State Transitions</h3>
<ul>
<li><strong>Authors: </strong>Melissa Safari, Abhishek K. Mishra, Mathieu Cunche</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02478">https://arxiv.org/abs/2507.02478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02478">https://arxiv.org/pdf/2507.02478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02478]] Effectively Identifying Wi-Fi Devices through State Transitions(https://arxiv.org/abs/2507.02478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Wi-Fi management frames reveal structured communication patterns that persist even under randomization of MAC addresses. Prior approaches to associating randomized MAC addresses with devices primarily focus on probe requests, overlooking the broader set of management frames and their transition dynamics. This narrow focus limits their robustness in dense, real-world environments with high device mobility, where probe activity alone fails to yield stable and distinctive signatures. In this paper, we present a novel framework for fingerprinting Wi-Fi devices based on behavioral dynamics extracted from passively observed management frames. We model each device's behavior as a finite state machine and introduce matrix-based representations that encode both structural (state transition frequencies) and temporal (inter-state delays) characteristics. These matrices are embedded into compact feature vectors, enabling efficient similarity comparison. Through extensive evaluation in diverse real-world settings, our method achieves over 86% identification accuracy for non-randomized devices using only Wi-Fi management frames, with further improvements observed through temporal burst aggregation. Our findings are sufficient to uniquely and consistently characterize devices at scale, outperforming the state-of-the-art.</li>
</ul>

<h3>Title: CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Teng Fu, Yuwen Chen, Zhuofan Chen, Mengyang Zhao, Bin Li, Xiangyang Xue</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02479">https://arxiv.org/abs/2507.02479</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02479">https://arxiv.org/pdf/2507.02479</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02479]] CrowdTrack: A Benchmark for Difficult Multiple Pedestrian Tracking in Real Scenarios(https://arxiv.org/abs/2507.02479)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-object tracking is a classic field in computer vision. Among them, pedestrian tracking has extremely high application value and has become the most popular research category. Existing methods mainly use motion or appearance information for tracking, which is often difficult in complex scenarios. For the motion information, mutual occlusions between objects often prevent updating of the motion state; for the appearance information, non-robust results are often obtained due to reasons such as only partial visibility of the object or blurred images. Although learning how to perform tracking in these situations from the annotated data is the simplest solution, the existing MOT dataset fails to satisfy this solution. Existing methods mainly have two drawbacks: relatively simple scene composition and non-realistic scenarios. Although some of the video sequences in existing dataset do not have the above-mentioned drawbacks, the number is far from adequate for research purposes. To this end, we propose a difficult large-scale dataset for multi-pedestrian tracking, shot mainly from the first-person view and all from real-life complex scenarios. We name it ``CrowdTrack'' because there are numerous objects in most of the sequences. Our dataset consists of 33 videos, containing a total of 5,185 trajectories. Each object is annotated with a complete bounding box and a unique object ID. The dataset will provide a platform to facilitate the development of algorithms that remain effective in complex situations. We analyzed the dataset comprehensively and tested multiple SOTA models on our dataset. Besides, we analyzed the performance of the foundation models on our dataset. The dataset and project code is released at: this https URL .</li>
</ul>

<h3>Title: MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention</h3>
<ul>
<li><strong>Authors: </strong>Zunhui Xia, Hongxing Li, Libin Lan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02488">https://arxiv.org/abs/2507.02488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02488">https://arxiv.org/pdf/2507.02488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02488]] MedFormer: Hierarchical Medical Vision Transformer with Content-Aware Dual Sparse Selection Attention(https://arxiv.org/abs/2507.02488)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Medical image recognition serves as a key way to aid in clinical diagnosis, enabling more accurate and timely identification of diseases and abnormalities. Vision transformer-based approaches have proven effective in handling various medical recognition tasks. However, these methods encounter two primary challenges. First, they are often task-specific and architecture-tailored, limiting their general applicability. Second, they usually either adopt full attention to model long-range dependencies, resulting in high computational costs, or rely on handcrafted sparse attention, potentially leading to suboptimal performance. To tackle these issues, we present MedFormer, an efficient medical vision transformer with two key ideas. First, it employs a pyramid scaling structure as a versatile backbone for various medical image recognition tasks, including image classification and dense prediction tasks such as semantic segmentation and lesion detection. This structure facilitates hierarchical feature representation while reducing the computation load of feature maps, highly beneficial for boosting performance. Second, it introduces a novel Dual Sparse Selection Attention (DSSA) with content awareness to improve computational efficiency and robustness against noise while maintaining high performance. As the core building technique of MedFormer, DSSA is explicitly designed to attend to the most relevant content. In addition, a detailed theoretical analysis has been conducted, demonstrating that MedFormer has superior generality and efficiency in comparison to existing medical vision transformers. Extensive experiments on a variety of imaging modality datasets consistently show that MedFormer is highly effective in enhancing performance across all three above-mentioned medical image recognition tasks. The code is available at this https URL.</li>
</ul>

<h3>Title: A 10-bit S-box generated by Feistel construction from cellular automata</h3>
<ul>
<li><strong>Authors: </strong>Thomas Prévost (I3S), Bruno Martin (I3S)</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02489">https://arxiv.org/abs/2507.02489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02489">https://arxiv.org/pdf/2507.02489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02489]] A 10-bit S-box generated by Feistel construction from cellular automata(https://arxiv.org/abs/2507.02489)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We propose a new 10-bit S-box generated from a Feistel construction. The subpermutations are generated by a 5-cell cellular automaton based on a unique well-chosen rule and bijective affine transformations. In particular, the cellular automaton rule is chosen based on empirical tests of its ability to generate good pseudorandom output on a ring cellular automaton. Similarly, Feistel's network layout is based on empirical data regarding the quality of the output S-box. We perform cryptanalysis of the generated 10-bit S-box, and we find security properties comparable to or sometimes even better than those of the standard AES S-box. We believe that our S-box could be used to replace the 5-bit substitution of ciphers like ASCON.</li>
</ul>

<h3>Title: Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy</h3>
<ul>
<li><strong>Authors: </strong>Luca Parolari, Andrea Cherubini, Lamberto Ballan, Carlo Biffi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02493">https://arxiv.org/abs/2507.02493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02493">https://arxiv.org/pdf/2507.02493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02493]] Temporally-Aware Supervised Contrastive Learning for Polyp Counting in Colonoscopy(https://arxiv.org/abs/2507.02493)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automated polyp counting in colonoscopy is a crucial step toward automated procedure reporting and quality control, aiming to enhance the cost-effectiveness of colonoscopy screening. Counting polyps in a procedure involves detecting and tracking polyps, and then clustering tracklets that belong to the same polyp entity. Existing methods for polyp counting rely on self-supervised learning and primarily leverage visual appearance, neglecting temporal relationships in both tracklet feature learning and clustering stages. In this work, we introduce a paradigm shift by proposing a supervised contrastive loss that incorporates temporally-aware soft targets. Our approach captures intra-polyp variability while preserving inter-polyp discriminability, leading to more robust clustering. Additionally, we improve tracklet clustering by integrating a temporal adjacency constraint, reducing false positive re-associations between visually similar but temporally distant tracklets. We train and validate our method on publicly available datasets and evaluate its performance with a leave-one-out cross-validation strategy. Results demonstrate a 2.2x reduction in fragmentation rate compared to prior approaches. Our results highlight the importance of temporal awareness in polyp counting, establishing a new state-of-the-art. Code is available at this https URL.</li>
</ul>

<h3>Title: Online Conformal Prediction with Efficiency Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Vaidehi Srinivas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS, math.ST, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02496">https://arxiv.org/abs/2507.02496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02496">https://arxiv.org/pdf/2507.02496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02496]] Online Conformal Prediction with Efficiency Guarantees(https://arxiv.org/abs/2507.02496)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the problem of conformal prediction in a novel online framework that directly optimizes efficiency. In our problem, we are given a target miscoverage rate $\alpha > 0$, and a time horizon $T$. On each day $t \le T$ an algorithm must output an interval $I_t \subseteq [0, 1]$, then a point $y_t \in [0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is, $y_t \in I_t$ on (close to) a $(1 - \alpha)$-fraction of days, while maintaining efficiency, that is, minimizing the average volume (length) of the intervals played. This problem is an online analogue to the problem of constructing efficient confidence intervals. We study this problem over arbitrary and exchangeable (random order) input sequences. For exchangeable sequences, we show that it is possible to construct intervals that achieve coverage $(1 - \alpha) - o(1)$, while having length upper bounded by the best fixed interval that achieves coverage in hindsight. For arbitrary sequences however, we show that any algorithm that achieves a $\mu$-approximation in average length compared to the best fixed interval achieving coverage in hindsight, must make a multiplicative factor more mistakes than $\alpha T$, where the multiplicative factor depends on $\mu$ and the aspect ratio of the problem. Our main algorithmic result is a matching algorithm that can recover all Pareto-optimal settings of $\mu$ and number of mistakes. Furthermore, our algorithm is deterministic and therefore robust to an adaptive adversary. This gap between the exchangeable and arbitrary settings is in contrast to the classical online learning problem. In fact, we show that no single algorithm can simultaneously be Pareto-optimal for arbitrary sequences and optimal for exchangeable sequences. On the algorithmic side, we give an algorithm that achieves the near-optimal tradeoff between the two cases.</li>
</ul>

<h3>Title: Continual Gradient Low-Rank Projection Fine-Tuning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02503">https://arxiv.org/abs/2507.02503</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02503">https://arxiv.org/pdf/2507.02503</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02503]] Continual Gradient Low-Rank Projection Fine-Tuning for LLMs(https://arxiv.org/abs/2507.02503)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model's ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit parameter constraints. We propose GORP (Gradient LOw Rank Projection) for Continual Learning, a novel training strategy that overcomes these limitations by synergistically combining full and low-rank parameters and jointly updating within a unified low-rank gradient subspace. GORP expands the optimization space while preserving efficiency and mitigating catastrophic forgetting. Extensive experiments on continual learning benchmarks demonstrate GORP's superior performance compared to existing state-of-the-art approaches. Code is available at this https URL.</li>
</ul>

<h3>Title: IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders</h3>
<ul>
<li><strong>Authors: </strong>Sneha Deshmukh, Prathmesh Kamble</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02506">https://arxiv.org/abs/2507.02506</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02506">https://arxiv.org/pdf/2507.02506</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02506]] IndianBailJudgments-1200: A Multi-Attribute Dataset for Legal NLP on Indian Bail Orders(https://arxiv.org/abs/2507.02506)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Legal NLP remains underdeveloped in regions like India due to the scarcity of structured datasets. We introduce IndianBailJudgments-1200, a new benchmark dataset comprising 1200 Indian court judgments on bail decisions, annotated across 20+ attributes including bail outcome, IPC sections, crime type, and legal reasoning. Annotations were generated using a prompt-engineered GPT-4o pipeline and verified for consistency. This resource supports a wide range of legal NLP tasks such as outcome prediction, summarization, and fairness analysis, and is the first publicly available dataset focused specifically on Indian bail jurisprudence.</li>
</ul>

<h3>Title: TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification</h3>
<ul>
<li><strong>Authors: </strong>Ahmed G. Habashi, Ahmed M. Azab, Seif Eldawlatly, Gamal M. Aly</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02510">https://arxiv.org/abs/2507.02510</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02510">https://arxiv.org/pdf/2507.02510</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02510]] TFOC-Net: A Short-time Fourier Transform-based Deep Learning Approach for Enhancing Cross-Subject Motor Imagery Classification(https://arxiv.org/abs/2507.02510)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cross-subject motor imagery (CS-MI) classification in brain-computer interfaces (BCIs) is a challenging task due to the significant variability in Electroencephalography (EEG) patterns across different individuals. This variability often results in lower classification accuracy compared to subject-specific models, presenting a major barrier to developing calibration-free BCIs suitable for real-world applications. In this paper, we introduce a novel approach that significantly enhances cross-subject MI classification performance through optimized preprocessing and deep learning techniques. Our approach involves direct classification of Short-Time Fourier Transform (STFT)-transformed EEG data, optimized STFT parameters, and a balanced batching strategy during training of a Convolutional Neural Network (CNN). This approach is uniquely validated across four different datasets, including three widely-used benchmark datasets leading to substantial improvements in cross-subject classification, achieving 67.60% on the BCI Competition IV Dataset 1 (IV-1), 65.96% on Dataset 2A (IV-2A), and 80.22% on Dataset 2B (IV-2B), outperforming state-of-the-art techniques. Additionally, we systematically investigate the classification performance using MI windows ranging from the full 4-second window to 1-second windows. These results establish a new benchmark for generalizable, calibration-free MI classification in addition to contributing a robust open-access dataset to advance research in this domain.</li>
</ul>

<h3>Title: Detecting Multiple Diseases in Multiple Crops Using Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Vivek Yadav, Anugrah Jain</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02517">https://arxiv.org/abs/2507.02517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02517">https://arxiv.org/pdf/2507.02517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02517]] Detecting Multiple Diseases in Multiple Crops Using Deep Learning(https://arxiv.org/abs/2507.02517)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>India, as a predominantly agrarian economy, faces significant challenges in agriculture, including substantial crop losses caused by diseases, pests, and environmental stress. Early detection and accurate identification of diseases across different crops are critical for improving yield and ensuring food security. This paper proposes a deep learning based solution for detecting multiple diseases in multiple crops, aimed to cover India's diverse agricultural landscape. We first create a unified dataset encompassing images of 17 different crops and 34 different diseases from various available repositories. Proposed deep learning model is trained on this dataset and outperforms the state-of-the-art in terms of accuracy and the number of crops, diseases covered. We achieve a significant detection accuracy, i.e., 99 percent for our unified dataset which is 7 percent more when compared to state-of-the-art handling 14 crops and 26 different diseases only. By improving the number of crops and types of diseases that can be detected, proposed solution aims to provide a better product for Indian farmers.</li>
</ul>

<h3>Title: IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Abiam Remache González, Meriem Chagour, Timon Bijan Rüth, Raúl Trapiella Cañedo, Marina Martínez Soler, Álvaro Lorenzo Felipe, Hyun-Suk Shin, María-Jesús Zamorano Serrano, Ricardo Torres, Juan-Antonio Castillo Parra, Eduardo Reyes Abad, Miguel-Ángel Ferrer Ballester, Juan-Manuel Afonso López, Francisco-Mario Hernández Tejera, Adrian Penate-Sanchez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02519">https://arxiv.org/abs/2507.02519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02519">https://arxiv.org/pdf/2507.02519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02519]] IMASHRIMP: Automatic White Shrimp (Penaeus vannamei) Biometrical Analysis from Laboratory Images Using Computer Vision and Deep Learning(https://arxiv.org/abs/2507.02519)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>This paper introduces IMASHRIMP, an adapted system for the automated morphological analysis of white shrimp (Penaeus vannamei}, aimed at optimizing genetic selection tasks in aquaculture. Existing deep learning and computer vision techniques were modified to address the specific challenges of shrimp morphology analysis from RGBD images. IMASHRIMP incorporates two discrimination modules, based on a modified ResNet-50 architecture, to classify images by the point of view and determine rostrum integrity. It is proposed a "two-factor authentication (human and IA)" system, it reduces human error in view classification from 0.97% to 0% and in rostrum detection from 12.46% to 3.64%. Additionally, a pose estimation module was adapted from VitPose to predict 23 key points on the shrimp's skeleton, with separate networks for lateral and dorsal views. A morphological regression module, using a Support Vector Machine (SVM) model, was integrated to convert pixel measurements to centimeter units. Experimental results show that the system effectively reduces human error, achieving a mean average precision (mAP) of 97.94% for pose estimation and a pixel-to-centimeter conversion error of 0.07 (+/- 0.1) cm. IMASHRIMP demonstrates the potential to automate and accelerate shrimp morphological analysis, enhancing the efficiency of genetic selection and contributing to more sustainable aquaculture this http URL code are available at this https URL</li>
</ul>

<h3>Title: RetrySQL: text-to-SQL training with retry data for self-correcting query generation</h3>
<ul>
<li><strong>Authors: </strong>Alicja Rączkowska, Riccardo Belluzzo, Piotr Zieliński, Joanna Baran, Paweł Olszewski</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02529">https://arxiv.org/abs/2507.02529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02529">https://arxiv.org/pdf/2507.02529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02529]] RetrySQL: text-to-SQL training with retry data for self-correcting query generation(https://arxiv.org/abs/2507.02529)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The text-to-SQL task is an active challenge in Natural Language Processing. Many existing solutions focus on using black-box language models extended with specialized components within customized end-to-end text-to-SQL pipelines. While these solutions use both closed-source proprietary language models and coding-oriented open-source models, there is a lack of research regarding SQL-specific generative models. At the same time, recent advancements in self-correcting generation strategies show promise for improving the capabilities of existing architectures. The application of these concepts to the text-to-SQL task remains unexplored. In this paper, we introduce RetrySQL, a new approach to training text-to-SQL generation models. We prepare reasoning steps for reference SQL queries and then corrupt them to create retry data that contains both incorrect and corrected steps, divided with a special token. We continuously pre-train an open-source coding model with this data and demonstrate that retry steps yield an improvement of up to 4 percentage points in both overall and challenging execution accuracy metrics, compared to pre-training without retry data. Additionally, we confirm that supervised fine-tuning with LoRA is ineffective for learning from retry data and that full-parameter pre-training is a necessary requirement for that task. We showcase that the self-correcting behavior is learned by the model and the increase in downstream accuracy metrics is a result of this additional skill. Finally, we incorporate RetrySQL-trained models into the full text-to-SQL pipeline and showcase that they are competitive in terms of execution accuracy with proprietary models that contain orders of magnitude more parameters. RetrySQL demonstrates that self-correction can be learned in the text-to-SQL task and provides a novel way of improving generation accuracy for SQL-oriented language models.</li>
</ul>

<h3>Title: Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Azmat Ullah, Maria Ilaria Lunesu, Lodovica Marchesi, Roberto Tonelli</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02536">https://arxiv.org/abs/2507.02536</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02536">https://arxiv.org/pdf/2507.02536</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02536]] Real-Time Monitoring and Transparency in Pizza Production Using IoT and Blockchain(https://arxiv.org/abs/2507.02536)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>This paper presents a blockchain-based Internet of Things (IoT) system for monitoring pizza production in restaurants. IoT devices track temperature and humidity in real-time, while blockchain ensures secure and tamper-proof data. A Raspberry Pi processes sensor data, captures images, triggers alerts, and interacts with smart contracts. The system detects abnormal conditions, enabling quick responses. Blockchain adds transparency and traceability, supporting compliance and audits. Experiments show improved ingredient management, reduced waste, and increased kitchen efficiency.</li>
</ul>

<h3>Title: Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Luca Baroni, Galvin Khara, Joachim Schaeffer, Marat Subkhankulov, Stefan Heimersheim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02559">https://arxiv.org/abs/2507.02559</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02559">https://arxiv.org/pdf/2507.02559</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02559]] Transformers Don't Need LayerNorm at Inference Time: Scaling LayerNorm Removal to GPT-2 XL and the Implications for Mechanistic Interpretability(https://arxiv.org/abs/2507.02559)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Layer-wise normalization (LN) is an essential component of virtually all transformer-based large language models. While its effects on training stability are well documented, its role at inference time is poorly understood. Additionally, LN layers hinder mechanistic interpretability by introducing additional nonlinearities and increasing the interconnectedness of individual model components. Here, we show that all LN layers can be removed from every GPT-2 model with only a small increase in validation loss (e.g. +0.03 cross-entropy loss for GPT-2 XL). Thus, LN cannot play a substantial role in language modeling. We find that the amount of fine-tuning data needed for LN removal grows sublinearly with model parameters, suggesting scaling to larger models is feasible. We release a suite of LN-free GPT-2 models on Hugging Face. Furthermore, we test interpretability techniques on LN-free models. Direct logit attribution now gives the exact direct effect of individual components, while the accuracy of attribution patching does not significantly improve. We also confirm that GPT-2's "confidence neurons" are inactive in the LN-free models. Our work clarifies the role of LN layers in language modeling, showing that GPT-2-class models can function without LN layers. We hope that our LN-free analogs of the GPT-2 family of models will enable more precise interpretability research and improve our understanding of language models.</li>
</ul>

<h3>Title: Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Buzhen Huang, Chen Li, Chongyang Xu, Dongyue Lu, Jinnan Chen, Yangang Wang, Gim Hee Lee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02565">https://arxiv.org/abs/2507.02565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02565">https://arxiv.org/pdf/2507.02565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02565]] Reconstructing Close Human Interaction with Appearance and Proxemics Reasoning(https://arxiv.org/abs/2507.02565)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Due to visual ambiguities and inter-person occlusions, existing human pose estimation methods cannot recover plausible close interactions from in-the-wild videos. Even state-of-the-art large foundation models~(\eg, SAM) cannot accurately distinguish human semantics in such challenging scenarios. In this work, we find that human appearance can provide a straightforward cue to address these obstacles. Based on this observation, we propose a dual-branch optimization framework to reconstruct accurate interactive motions with plausible body contacts constrained by human appearances, social proxemics, and physical laws. Specifically, we first train a diffusion model to learn the human proxemic behavior and pose prior knowledge. The trained network and two optimizable tensors are then incorporated into a dual-branch optimization framework to reconstruct human motions and appearances. Several constraints based on 3D Gaussians, 2D keypoints, and mesh penetrations are also designed to assist the optimization. With the proxemics prior and diverse constraints, our method is capable of estimating accurate interactions from in-the-wild videos captured in complex environments. We further build a dataset with pseudo ground-truth interaction annotations, which may promote future research on pose estimation and human behavior understanding. Experimental results on several benchmarks demonstrate that our method outperforms existing approaches. The code and data are available at this https URL.</li>
</ul>

<h3>Title: Parametric shape models for vessels learned from segmentations via differentiable voxelization</h3>
<ul>
<li><strong>Authors: </strong>Alina F. Dima, Suprosanna Shit, Huaqi Qiu, Robbie Holland, Tamara T. Mueller, Fabio Antonio Musio, Kaiyuan Yang, Bjoern Menze, Rickmer Braren, Marcus Makowski, Daniel Rueckert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02576">https://arxiv.org/abs/2507.02576</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02576">https://arxiv.org/pdf/2507.02576</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02576]] Parametric shape models for vessels learned from segmentations via differentiable voxelization(https://arxiv.org/abs/2507.02576)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Vessels are complex structures in the body that have been studied extensively in multiple representations. While voxelization is the most common of them, meshes and parametric models are critical in various applications due to their desirable properties. However, these representations are typically extracted through segmentations and used disjointly from each other. We propose a framework that joins the three representations under differentiable transformations. By leveraging differentiable voxelization, we automatically extract a parametric shape model of the vessels through shape-to-segmentation fitting, where we learn shape parameters from segmentations without the explicit need for ground-truth shape parameters. The vessel is parametrized as centerlines and radii using cubic B-splines, ensuring smoothness and continuity by construction. Meshes are differentiably extracted from the learned shape parameters, resulting in high-fidelity meshes that can be manipulated post-fit. Our method can accurately capture the geometry of complex vessels, as demonstrated by the volumetric fits in experiments on aortas, aneurysms, and brain vessels.</li>
</ul>

<h3>Title: AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding</h3>
<ul>
<li><strong>Authors: </strong>Weili Xu, Enxin Song, Wenhao Chai, Xuexiang Wen, Tian Ye, Gaoang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02591">https://arxiv.org/abs/2507.02591</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02591">https://arxiv.org/pdf/2507.02591</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02591]] AuroraLong: Bringing RNNs Back to Efficient Open-Ended Video Understanding(https://arxiv.org/abs/2507.02591)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The challenge of long video understanding lies in its high computational complexity and prohibitive memory cost, since the memory and computation required by transformer-based LLMs scale quadratically with input sequence length. We propose AuroraLong to address this challenge by replacing the LLM component in MLLMs with a linear RNN language model that handles input sequence of arbitrary length with constant-size hidden states. To further increase throughput and efficiency, we combine visual token merge with linear RNN models by reordering the visual tokens by their sizes in ascending order. Despite having only 2B parameters and being trained exclusively on public data, AuroraLong achieves performance comparable to Transformer-based models of similar size trained on private datasets across multiple video benchmarks. This demonstrates the potential of efficient, linear RNNs to democratize long video understanding by lowering its computational entry barrier. To our best knowledge, we are the first to use a linear RNN based LLM backbone in a LLaVA-like model for open-ended video understanding.</li>
</ul>

<h3>Title: Revisiting Active Learning under (Human) Label Variation</h3>
<ul>
<li><strong>Authors: </strong>Cornelia Gruber, Helen Alber, Bernd Bischl, Göran Kauermann, Barbara Plank, Matthias Aßenmacher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02593">https://arxiv.org/abs/2507.02593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02593">https://arxiv.org/pdf/2507.02593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02593]] Revisiting Active Learning under (Human) Label Variation(https://arxiv.org/abs/2507.02593)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Access to high-quality labeled data remains a limiting factor in applied supervised learning. While label variation (LV), i.e., differing labels for the same instance, is common, especially in natural language processing, annotation frameworks often still rest on the assumption of a single ground truth. This overlooks human label variation (HLV), the occurrence of plausible differences in annotations, as an informative signal. Similarly, active learning (AL), a popular approach to optimizing the use of limited annotation budgets in training ML models, often relies on at least one of several simplifying assumptions, which rarely hold in practice when acknowledging HLV. In this paper, we examine foundational assumptions about truth and label nature, highlighting the need to decompose observed LV into signal (e.g., HLV) and noise (e.g., annotation error). We survey how the AL and (H)LV communities have addressed -- or neglected -- these distinctions and propose a conceptual framework for incorporating HLV throughout the AL loop, including instance selection, annotator choice, and label representation. We further discuss the integration of large language models (LLM) as annotators. Our work aims to lay a conceptual foundation for HLV-aware active learning, better reflecting the complexities of real-world annotation.</li>
</ul>

<h3>Title: MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion</h3>
<ul>
<li><strong>Authors: </strong>Xin Guan, PeiHsin Lin, Zekun Wu, Ze Wang, Ruibo Zhang, Emre Kazim, Adriano Koshiyama</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02595">https://arxiv.org/abs/2507.02595</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02595">https://arxiv.org/pdf/2507.02595</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02595]] MPF: Aligning and Debiasing Language Models post Deployment via Multi Perspective Fusion(https://arxiv.org/abs/2507.02595)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multiperspective Fusion (MPF) is a novel posttraining alignment framework for large language models (LLMs) developed in response to the growing need for easy bias mitigation. Built on top of the SAGED pipeline, an automated system for constructing bias benchmarks and extracting interpretable baseline distributions, MPF leverages multiperspective generations to expose and align biases in LLM outputs with nuanced, humanlike baselines. By decomposing baseline, such as sentiment distributions from HR professionals, into interpretable perspective components, MPF guides generation through sampling and balancing of responses, weighted by the probabilities obtained in the decomposition. Empirically, we demonstrate its ability to align LLM sentiment distributions with both counterfactual baselines (absolute equality) and the HR baseline (biased for Top Univeristy), resulting in small KL divergence, reduction of calibration error and generalization to unseen questions. This shows that MPF offers a scalable and interpretable method for alignment and bias mitigation, compatible with deployed LLMs and requiring no extensive prompt engineering or finetuning.</li>
</ul>

<h3>Title: Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Gallon, Fabian Schiemenz, Alessandra Menicucci, Eberhard Gill</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02602">https://arxiv.org/abs/2507.02602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02602">https://arxiv.org/pdf/2507.02602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02602]] Addressing Camera Sensors Faults in Vision-Based Navigation: Simulation and Dataset Development(https://arxiv.org/abs/2507.02602)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The increasing importance of Vision-Based Navigation (VBN) algorithms in space missions raises numerous challenges in ensuring their reliability and operational robustness. Sensor faults can lead to inaccurate outputs from navigation algorithms or even complete data processing faults, potentially compromising mission objectives. Artificial Intelligence (AI) offers a powerful solution for detecting such faults, overcoming many of the limitations associated with traditional fault detection methods. However, the primary obstacle to the adoption of AI in this context is the lack of sufficient and representative datasets containing faulty image data. This study addresses these challenges by focusing on an interplanetary exploration mission scenario. A comprehensive analysis of potential fault cases in camera sensors used within the VBN pipeline is presented. The causes and effects of these faults are systematically characterized, including their impact on image quality and navigation algorithm performance, as well as commonly employed mitigation strategies. To support this analysis, a simulation framework is introduced to recreate faulty conditions in synthetically generated images, enabling a systematic and controlled reproduction of faulty data. The resulting dataset of fault-injected images provides a valuable tool for training and testing AI-based fault detection algorithms. The final link to the dataset will be added after an embargo period. For peer-reviewers, this private link is available.</li>
</ul>

<h3>Title: Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures</h3>
<ul>
<li><strong>Authors: </strong>Frida Sundfeldt, Bianca Widstam, Mahshid Helali Moghadam, Kuo-Yun Liang, Anders Vesterberg</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02607">https://arxiv.org/abs/2507.02607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02607">https://arxiv.org/pdf/2507.02607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02607]] Alleviating Attack Data Scarcity: SCANIA's Experience Towards Enhancing In-Vehicle Cyber Security Measures(https://arxiv.org/abs/2507.02607)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The digital evolution of connected vehicles and the subsequent security risks emphasize the critical need for implementing in-vehicle cyber security measures such as intrusion detection and response systems. The continuous advancement of attack scenarios further highlights the need for adaptive detection mechanisms that can detect evolving, unknown, and complex threats. The effective use of ML-driven techniques can help address this challenge. However, constraints on implementing diverse attack scenarios on test vehicles due to safety, cost, and ethical considerations result in a scarcity of data representing attack scenarios. This limitation necessitates alternative efficient and effective methods for generating high-quality attack-representing data. This paper presents a context-aware attack data generator that generates attack inputs and corresponding in-vehicle network log, i.e., controller area network (CAN) log, representing various types of attack including denial of service (DoS), fuzzy, spoofing, suspension, and replay attacks. It utilizes parameterized attack models augmented with CAN message decoding and attack intensity adjustments to configure the attack scenarios with high similarity to real-world scenarios and promote variability. We evaluate the practicality of the generated attack-representing data within an intrusion detection system (IDS) case study, in which we develop and perform an empirical evaluation of two deep neural network IDS models using the generated data. In addition to the efficiency and scalability of the approach, the performance results of IDS models, high detection and classification capabilities, validate the consistency and effectiveness of the generated data as well. In this experience study, we also elaborate on the aspects influencing the fidelity of the data to real-world scenarios and provide insights into its application.</li>
</ul>

<h3>Title: Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation</h3>
<ul>
<li><strong>Authors: </strong>François Rozet, Ruben Ohana, Michael McCabe, Gilles Louppe, François Lanusse, Shirley Ho</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02608">https://arxiv.org/abs/2507.02608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02608">https://arxiv.org/pdf/2507.02608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02608]] Lost in Latent Space: An Empirical Study of Latent Diffusion Models for Physics Emulation(https://arxiv.org/abs/2507.02608)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>The steep computational cost of diffusion models at inference hinders their use as fast physics emulators. In the context of image and video generation, this computational drawback has been addressed by generating in the latent space of an autoencoder instead of the pixel space. In this work, we investigate whether a similar strategy can be effectively applied to the emulation of dynamical systems and at what cost. We find that the accuracy of latent-space emulation is surprisingly robust to a wide range of compression rates (up to 1000x). We also show that diffusion-based emulators are consistently more accurate than non-generative counterparts and compensate for uncertainty in their predictions with greater diversity. Finally, we cover practical design choices, spanning from architectures to optimizers, that we found critical to train latent-space emulators.</li>
</ul>

<h3>Title: A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes</h3>
<ul>
<li><strong>Authors: </strong>Antoine Honoré, Borja Rodríguez Gálvez, Yoomi Park, Yitian Zhou, Volker M. Lauschke, Ming Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02624">https://arxiv.org/abs/2507.02624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02624">https://arxiv.org/pdf/2507.02624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02624]] A Matrix Variational Auto-Encoder for Variant Effect Prediction in Pharmacogenes(https://arxiv.org/abs/2507.02624)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Variant effect predictors (VEPs) aim to assess the functional impact of protein variants, traditionally relying on multiple sequence alignments (MSAs). This approach assumes that naturally occurring variants are fit, an assumption challenged by pharmacogenomics, where some pharmacogenes experience low evolutionary pressure. Deep mutational scanning (DMS) datasets provide an alternative by offering quantitative fitness scores for variants. In this work, we propose a transformer-based matrix variational auto-encoder (matVAE) with a structured prior and evaluate its performance on 33 DMS datasets corresponding to 26 drug target and ADME proteins from the ProteinGym benchmark. Our model trained on MSAs (matVAE-MSA) outperforms the state-of-the-art DeepSequence model in zero-shot prediction on DMS datasets, despite using an order of magnitude fewer parameters and requiring less computation at inference time. We also compare matVAE-MSA to matENC-DMS, a model of similar capacity trained on DMS data, and find that the latter performs better on supervised prediction tasks. Additionally, incorporating AlphaFold-generated structures into our transformer model further improves performance, achieving results comparable to DeepSequence trained on MSAs and finetuned on DMS. These findings highlight the potential of DMS datasets to replace MSAs without significant loss in predictive performance, motivating further development of DMS datasets and exploration of their relationships to enhance variant effect prediction.</li>
</ul>

<h3>Title: Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data</h3>
<ul>
<li><strong>Authors: </strong>Irena Girshovitz, Atai Ambus, Moni Shahar, Ran Gilad-Bachrach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02628">https://arxiv.org/abs/2507.02628</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02628">https://arxiv.org/pdf/2507.02628</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02628]] Medical Data Pecking: A Context-Aware Approach for Automated Quality Evaluation of Structured Medical Data(https://arxiv.org/abs/2507.02628)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Background: The use of Electronic Health Records (EHRs) for epidemiological studies and artificial intelligence (AI) training is increasing rapidly. The reliability of the results depends on the accuracy and completeness of EHR data. However, EHR data often contain significant quality issues, including misrepresentations of subpopulations, biases, and systematic errors, as they are primarily collected for clinical and billing purposes. Existing quality assessment methods remain insufficient, lacking systematic procedures to assess data fitness for research. Methods: We present the Medical Data Pecking approach, which adapts unit testing and coverage concepts from software engineering to identify data quality concerns. We demonstrate our approach using the Medical Data Pecking Tool (MDPT), which consists of two main components: (1) an automated test generator that uses large language models and grounding techniques to create a test suite from data and study descriptions, and (2) a data testing framework that executes these tests, reporting potential errors and coverage. Results: We evaluated MDPT on three datasets: All of Us (AoU), MIMIC-III, and SyntheticMass, generating 55-73 tests per cohort across four conditions. These tests correctly identified 20-43 non-aligned or non-conforming data issues. We present a detailed analysis of the LLM-generated test suites in terms of reference grounding and value accuracy. Conclusion: Our approach incorporates external medical knowledge to enable context-sensitive data quality testing as part of the data analysis workflow to improve the validity of its outcomes. Our approach tackles these challenges from a quality assurance perspective, laying the foundation for further development such as additional data modalities and improved grounding methods.</li>
</ul>

<h3>Title: High-Order Deep Meta-Learning with Category-Theoretic Interpretation</h3>
<ul>
<li><strong>Authors: </strong>David H. Mguni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02634">https://arxiv.org/abs/2507.02634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02634">https://arxiv.org/pdf/2507.02634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02634]] High-Order Deep Meta-Learning with Category-Theoretic Interpretation(https://arxiv.org/abs/2507.02634)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce a new hierarchical deep learning framework for recursive higher-order meta-learning that enables neural networks (NNs) to construct, solve, and generalise across hierarchies of tasks. Central to this approach is a generative mechanism that creates \emph{virtual tasks} -- synthetic problem instances designed to enable the meta-learner to learn \emph{soft constraints} and unknown generalisable rules across related tasks. Crucially, this enables the framework to generate its own informative, task-grounded datasets thereby freeing machine learning (ML) training from the limitations of relying entirely on human-generated data. By actively exploring the virtual point landscape and seeking out tasks lower-level learners find difficult, the meta-learner iteratively refines constraint regions. This enhances inductive biases, regularises the adaptation process, and produces novel, unanticipated tasks and constraints required for generalisation. Each meta-level of the hierarchy corresponds to a progressively abstracted generalisation of problems solved at lower levels, enabling a structured and interpretable learning progression. By interpreting meta-learners as category-theoretic \emph{functors} that generate and condition a hierarchy of subordinate learners, we establish a compositional structure that supports abstraction and knowledge transfer across progressively generalised tasks. The category-theoretic perspective unifies existing meta-learning models and reveals how learning processes can be transformed and compared through functorial relationships, while offering practical design principles for structuring meta-learning. We speculate this architecture may underpin the next generation of NNs capable of autonomously generating novel, instructive tasks and their solutions, thereby advancing ML towards general artificial intelligence.</li>
</ul>

<h3>Title: SAT-BO: Verification Rule Learning and Optimization for FraudTransaction Detection</h3>
<ul>
<li><strong>Authors: </strong>Mao Luo, Zhi Wang, Yiwen Huang, Qingyun Zhang, Zhouxing Su, Zhipeng Lv, Wen Hu, Jianguo Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02635">https://arxiv.org/abs/2507.02635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02635">https://arxiv.org/pdf/2507.02635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02635]] SAT-BO: Verification Rule Learning and Optimization for FraudTransaction Detection(https://arxiv.org/abs/2507.02635)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Electronic payment platforms are estimated to process billions oftransactions daily, with the cumulative value of these transactionspotentially reaching into the trillions. Even a minor error within thishigh-volume environment could precipitate substantial financiallosses. To mitigate this risk, manually constructed verification rules,developed by domain experts, are typically employed to identifyand scrutinize transactions in production environments. However,due to the absence of a systematic approach to ensure the robust-ness of these verification rules against vulnerabilities, they remainsusceptible to this http URL mitigate this risk, manually constructed verification rules, de-veloped by domain experts, are typically employed to identify andscrutinize transactions in production environments. However, dueto the absence of a systematic approach to ensure the robustness ofthese verification rules against vulnerabilities, they remain suscep-tible to exploitation. To ensure data security, database maintainersusually compose complex verification rules to check whether aquery/update request is valid. However, the rules written by ex-perts are usually imperfect, and malicious requests may bypassthese rules. As a result, the demand for identifying the defects ofthe rules systematically emerges.</li>
</ul>

<h3>Title: Fair Deepfake Detectors Can Generalize</h3>
<ul>
<li><strong>Authors: </strong>Harry Cheng, Ming-Hui Liu, Yangyang Guo, Tianyi Wang, Liqiang Nie, Mohan Kankanhalli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02645">https://arxiv.org/abs/2507.02645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02645">https://arxiv.org/pdf/2507.02645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02645]] Fair Deepfake Detectors Can Generalize(https://arxiv.org/abs/2507.02645)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Deepfake detection models face two critical challenges: generalization to unseen manipulations and demographic fairness among population groups. However, existing approaches often demonstrate that these two objectives are inherently conflicting, revealing a trade-off between them. In this paper, we, for the first time, uncover and formally define a causal relationship between fairness and generalization. Building on the back-door adjustment, we show that controlling for confounders (data distribution and model capacity) enables improved generalization via fairness interventions. Motivated by this insight, we propose Demographic Attribute-insensitive Intervention Detection (DAID), a plug-and-play framework composed of: i) Demographic-aware data rebalancing, which employs inverse-propensity weighting and subgroup-wise feature normalization to neutralize distributional biases; and ii) Demographic-agnostic feature aggregation, which uses a novel alignment loss to suppress sensitive-attribute signals. Across three cross-domain benchmarks, DAID consistently achieves superior performance in both fairness and generalization compared to several state-of-the-art detectors, validating both its theoretical foundation and practical effectiveness.</li>
</ul>

<h3>Title: AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ziyin Zhou, Yunpeng Luo, Yuanchen Wu, Ke Sun, Jiayi Ji, Ke Yan, Shouhong Ding, Xiaoshuai Sun, Yunsheng Wu, Rongrong Ji</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02664">https://arxiv.org/abs/2507.02664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02664">https://arxiv.org/pdf/2507.02664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02664]] AIGI-Holmes: Towards Explainable and Generalizable AI-Generated Image Detection via Multimodal Large Language Models(https://arxiv.org/abs/2507.02664)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of AI-generated content (AIGC) technology has led to the misuse of highly realistic AI-generated images (AIGI) in spreading misinformation, posing a threat to public information security. Although existing AIGI detection techniques are generally effective, they face two issues: 1) a lack of human-verifiable explanations, and 2) a lack of generalization in the latest generation technology. To address these issues, we introduce a large-scale and comprehensive dataset, Holmes-Set, which includes the Holmes-SFTSet, an instruction-tuning dataset with explanations on whether images are AI-generated, and the Holmes-DPOSet, a human-aligned preference dataset. Our work introduces an efficient data annotation method called the Multi-Expert Jury, enhancing data generation through structured MLLM explanations and quality control via cross-model evaluation, expert defect filtering, and human preference modification. In addition, we propose Holmes Pipeline, a meticulously designed three-stage training framework comprising visual expert pre-training, supervised fine-tuning, and direct preference optimization. Holmes Pipeline adapts multimodal large language models (MLLMs) for AIGI detection while generating human-verifiable and human-aligned explanations, ultimately yielding our model AIGI-Holmes. During the inference stage, we introduce a collaborative decoding strategy that integrates the model perception of the visual expert with the semantic reasoning of MLLMs, further enhancing the generalization capabilities. Extensive experiments on three benchmarks validate the effectiveness of our AIGI-Holmes.</li>
</ul>

<h3>Title: Guided Generation for Developable Antibodies</h3>
<ul>
<li><strong>Authors: </strong>Siqi Zhao, Joshua Moller, Porfi Quintero-Cadena, Lood van Niekerk</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02670">https://arxiv.org/abs/2507.02670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02670">https://arxiv.org/pdf/2507.02670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02670]] Guided Generation for Developable Antibodies(https://arxiv.org/abs/2507.02670)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Therapeutic antibodies require not only high-affinity target engagement, but also favorable manufacturability, stability, and safety profiles for clinical effectiveness. These properties are collectively called `developability'. To enable a computational framework for optimizing antibody sequences for favorable developability, we introduce a guided discrete diffusion model trained on natural paired heavy- and light-chain sequences from the Observed Antibody Space (OAS) and quantitative developability measurements for 246 clinical-stage antibodies. To steer generation toward biophysically viable candidates, we integrate a Soft Value-based Decoding in Diffusion (SVDD) Module that biases sampling without compromising naturalness. In unconstrained sampling, our model reproduces global features of both the natural repertoire and approved therapeutics, and under SVDD guidance we achieve significant enrichment in predicted developability scores over unguided baselines. When combined with high-throughput developability assays, this framework enables an iterative, ML-driven pipeline for designing antibodies that satisfy binding and biophysical criteria in tandem.</li>
</ul>

<h3>Title: Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs</h3>
<ul>
<li><strong>Authors: </strong>Francesco Di Salvo, Hanh Huyen My Nguyen, Christian Ledig</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02671">https://arxiv.org/abs/2507.02671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02671">https://arxiv.org/pdf/2507.02671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02671]] Embedding-Based Federated Data Sharing via Differentially Private Conditional VAEs(https://arxiv.org/abs/2507.02671)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, generative</a></li>
<li><strong>Abstract: </strong>Deep Learning (DL) has revolutionized medical imaging, yet its adoption is constrained by data scarcity and privacy regulations, limiting access to diverse datasets. Federated Learning (FL) enables decentralized training but suffers from high communication costs and is often restricted to a single downstream task, reducing flexibility. We propose a data-sharing method via Differentially Private (DP) generative models. By adopting foundation models, we extract compact, informative embeddings, reducing redundancy and lowering computational overhead. Clients collaboratively train a Differentially Private Conditional Variational Autoencoder (DP-CVAE) to model a global, privacy-aware data distribution, supporting diverse downstream tasks. Our approach, validated across multiple feature extractors, enhances privacy, scalability, and efficiency, outperforming traditional FL classifiers while ensuring differential privacy. Additionally, DP-CVAE produces higher-fidelity embeddings than DP-CGAN while requiring $5{\times}$ fewer parameters.</li>
</ul>

<h3>Title: Exploring Gender Bias Beyond Occupational Titles</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Sabir, Rajesh Sharama</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02679">https://arxiv.org/abs/2507.02679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02679">https://arxiv.org/pdf/2507.02679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02679]] Exploring Gender Bias Beyond Occupational Titles(https://arxiv.org/abs/2507.02679)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In this work, we investigate the correlation between gender and contextual biases, focusing on elements such as action verbs, object nouns, and particularly on occupations. We introduce a novel dataset, GenderLexicon, and a framework that can estimate contextual bias and its related gender bias. Our model can interpret the bias with a score and thus improve the explainability of gender bias. Also, our findings confirm the existence of gender biases beyond occupational stereotypes. To validate our approach and demonstrate its effectiveness, we conduct evaluations on five diverse datasets, including a Japanese dataset.</li>
</ul>

<h3>Title: Learning few-step posterior samplers by unfolding and distillation of diffusion models</h3>
<ul>
<li><strong>Authors: </strong>Charlesquin Kemajou Mbakam, Jonathan Spence, Marcelo Pereyra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02686">https://arxiv.org/abs/2507.02686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02686">https://arxiv.org/pdf/2507.02686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02686]] Learning few-step posterior samplers by unfolding and distillation of diffusion models(https://arxiv.org/abs/2507.02686)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have emerged as powerful image priors in Bayesian computational imaging. Two primary strategies have been proposed for leveraging DMs in this context: Plug-and-Play methods, which are zero-shot and highly flexible but rely on approximations; and specialized conditional DMs, which achieve higher accuracy and faster inference for specific tasks through supervised training. In this work, we introduce a novel framework that integrates deep unfolding and model distillation to transform a DM image prior into a few-step conditional model for posterior sampling. A central innovation of our approach is the unfolding of a Markov chain Monte Carlo (MCMC) algorithm - specifically, the recently proposed LATINO Langevin sampler (Spagnoletti et al., 2025) - representing the first known instance of deep unfolding applied to a Monte Carlo sampling scheme. We demonstrate our proposed unfolded and distilled samplers through extensive experiments and comparisons with the state of the art, where they achieve excellent accuracy and computational efficiency, while retaining the flexibility to adapt to variations in the forward model at inference time.</li>
</ul>

<h3>Title: APT: Adaptive Personalized Training for Diffusion Models with Limited Data</h3>
<ul>
<li><strong>Authors: </strong>JungWoo Chae, Jiyoon Kim, JaeWoong Choi, Kyungyul Kim, Sangheum Hwang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02687">https://arxiv.org/abs/2507.02687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02687">https://arxiv.org/pdf/2507.02687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02687]] APT: Adaptive Personalized Training for Diffusion Models with Limited Data(https://arxiv.org/abs/2507.02687)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Personalizing diffusion models using limited data presents significant challenges, including overfitting, loss of prior knowledge, and degradation of text alignment. Overfitting leads to shifts in the noise prediction distribution, disrupting the denoising trajectory and causing the model to lose semantic coherence. In this paper, we propose Adaptive Personalized Training (APT), a novel framework that mitigates overfitting by employing adaptive training strategies and regularizing the model's internal representations during fine-tuning. APT consists of three key components: (1) Adaptive Training Adjustment, which introduces an overfitting indicator to detect the degree of overfitting at each time step bin and applies adaptive data augmentation and adaptive loss weighting based on this indicator; (2)Representation Stabilization, which regularizes the mean and variance of intermediate feature maps to prevent excessive shifts in noise prediction; and (3) Attention Alignment for Prior Knowledge Preservation, which aligns the cross-attention maps of the fine-tuned model with those of the pretrained model to maintain prior knowledge and semantic coherence. Through extensive experiments, we demonstrate that APT effectively mitigates overfitting, preserves prior knowledge, and outperforms existing methods in generating high-quality, diverse images with limited reference data.</li>
</ul>

<h3>Title: Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions</h3>
<ul>
<li><strong>Authors: </strong>Thomas Hazenberg, Yao Ma, Seyed Sahand Mohammadi Ziabari, Marijn van Rijswijk</a></li>
<li><strong>Subjects: </strong>cs.LG, econ.EM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02698">https://arxiv.org/abs/2507.02698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02698">https://arxiv.org/pdf/2507.02698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02698]] Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions(https://arxiv.org/abs/2507.02698)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>This study investigates how Multi-Agent Reinforcement Learning (MARL) can improve dynamic pricing strategies in supply chains, particularly in contexts where traditional ERP systems rely on static, rule-based approaches that overlook strategic interactions among market actors. While recent research has applied reinforcement learning to pricing, most implementations remain single-agent and fail to model the interdependent nature of real-world supply chains. This study addresses that gap by evaluating the performance of three MARL algorithms: MADDPG, MADQN, and QMIX against static rule-based baselines, within a simulated environment informed by real e-commerce transaction data and a LightGBM demand prediction model. Results show that rule-based agents achieve near-perfect fairness (Jain's Index: 0.9896) and the highest price stability (volatility: 0.024), but they fully lack competitive dynamics. Among MARL agents, MADQN exhibits the most aggressive pricing behaviour, with the highest volatility and the lowest fairness (0.5844). MADDPG provides a more balanced approach, supporting market competition (share volatility: 9.5 pp) while maintaining relatively high fairness (0.8819) and stable pricing. These findings suggest that MARL introduces emergent strategic behaviour not captured by static pricing rules and may inform future developments in dynamic pricing.</li>
</ul>

<h3>Title: Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents</h3>
<ul>
<li><strong>Authors: </strong>Jiangrong Wu, Yuhong Nan, Jianliang Wu, Zitong Yao, Zibin Zheng</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02699">https://arxiv.org/abs/2507.02699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02699">https://arxiv.org/pdf/2507.02699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02699]] Control at Stake: Evaluating the Security Landscape of LLM-Driven Email Agents(https://arxiv.org/abs/2507.02699)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The increasing capabilities of LLMs have led to the rapid proliferation of LLM agent apps, where developers enhance LLMs with access to external resources to support complex task execution. Among these, LLM email agent apps represent one of the widely used categories, as email remains a critical communication medium for users. LLM email agents are capable of managing and responding to email using LLM-driven reasoning and autonomously executing user instructions via external email APIs (e.g., send email). However, despite their growing deployment and utility, the security mechanism of LLM email agent apps remains underexplored. Currently, there is no comprehensive study into the potential security risk within these agent apps and their broader implications. In this paper, we conduct the first in-depth and systematic security study of LLM email agents. We propose the Email Agent Hijacking (EAH) attack, which overrides the original prompts of the email agent via external email resources, allowing attackers to gain control of the email agent remotely and further perform specific attack scenarios without user awareness. To facilitate the large-scale evaluation, we propose EAHawk, a pipeline to evaluate the EAH attack of LLM email agent apps. By EAHawk, we performed an empirical study spanning 14 representative LLM agent frameworks, 63 agent apps, 12 LLMs, and 20 email services, which led to the generation of 1,404 real-world email agent instances for evaluation. Experimental results indicate that all 1,404 instances were successfully hijacked; on average, only 2.03 attack attempts are required to control an email agent instance. Even worse, for some LLMs, the average number of attempts needed to achieve full agent control drops to as few as 1.23.</li>
</ul>

<h3>Title: Fluid Democracy in Federated Data Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Aditya Vema Reddy Kesari, Krishna Reddy Kesari</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02710">https://arxiv.org/abs/2507.02710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02710">https://arxiv.org/pdf/2507.02710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02710]] Fluid Democracy in Federated Data Aggregation(https://arxiv.org/abs/2507.02710)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) mechanisms typically require each client to transfer their weights to a central server, irrespective of how useful they are. In order to avoid wasteful data transfer costs from clients to the central server, we propose the use of consensus based protocols to identify a subset of clients with most useful model weights at each data transfer step. First, we explore the application of existing fluid democracy protocols to FL from a performance standpoint, comparing them with traditional one-person-one-vote (also known as 1p1v or FedAvg). We propose a new fluid democracy protocol named viscous-retained democracy that always does better than 1p1v under the same assumptions as existing fluid democracy protocols while also not allowing for influence accumulation. Secondly, we identify weaknesses of fluid democracy protocols from an adversarial lens in terms of their dependence on topology and/ or number of adversaries required to negatively impact the global model weights. To this effect, we propose an algorithm (FedVRD) that dynamically limits the effect of adversaries while minimizing cost by leveraging the delegation topology.</li>
</ul>

<h3>Title: UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Qin Guo, Ailing Zeng, Dongxu Yue, Ceyuan Yang, Yang Cao, Hanzhong Guo, Fei Shen, Wei Liu, Xihui Liu, Dan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02713">https://arxiv.org/abs/2507.02713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02713">https://arxiv.org/pdf/2507.02713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02713]] UniMC: Taming Diffusion Transformer for Unified Keypoint-Guided Multi-Class Image Generation(https://arxiv.org/abs/2507.02713)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Although significant advancements have been achieved in the progress of keypoint-guided Text-to-Image diffusion models, existing mainstream keypoint-guided models encounter challenges in controlling the generation of more general non-rigid objects beyond humans (e.g., animals). Moreover, it is difficult to generate multiple overlapping humans and animals based on keypoint controls solely. These challenges arise from two main aspects: the inherent limitations of existing controllable methods and the lack of suitable datasets. First, we design a DiT-based framework, named UniMC, to explore unifying controllable multi-class image generation. UniMC integrates instance- and keypoint-level conditions into compact tokens, incorporating attributes such as class, bounding box, and keypoint coordinates. This approach overcomes the limitations of previous methods that struggled to distinguish instances and classes due to their reliance on skeleton images as conditions. Second, we propose HAIG-2.9M, a large-scale, high-quality, and diverse dataset designed for keypoint-guided human and animal image generation. HAIG-2.9M includes 786K images with 2.9M instances. This dataset features extensive annotations such as keypoints, bounding boxes, and fine-grained captions for both humans and animals, along with rigorous manual inspection to ensure annotation accuracy. Extensive experiments demonstrate the high quality of HAIG-2.9M and the effectiveness of UniMC, particularly in heavy occlusions and multi-class scenarios.</li>
</ul>

<h3>Title: FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Wang, Tianwei Cao, Huayu Zhang, Zhongjiang He, Kongming Liang, Zhanyu Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02714">https://arxiv.org/abs/2507.02714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02714">https://arxiv.org/pdf/2507.02714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02714]] FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models(https://arxiv.org/abs/2507.02714)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Image generation has achieved remarkable progress with the development of large-scale text-to-image models, especially diffusion-based models. However, generating human images with plausible details, such as faces or hands, remains challenging due to insufficient supervision of local regions during training. To address this issue, we propose FairHuman, a multi-objective fine-tuning approach designed to enhance both global and local generation quality fairly. Specifically, we first construct three learning objectives: a global objective derived from the default diffusion objective function and two local objectives for hands and faces based on pre-annotated positional priors. Subsequently, we derive the optimal parameter updating strategy under the guidance of the Minimum Potential Delay (MPD) criterion, thereby attaining fairness-ware optimization for this multi-objective problem. Based on this, our proposed method can achieve significant improvements in generating challenging local details while maintaining overall quality. Extensive experiments showcase the effectiveness of our method in improving the performance of human image generation under different scenarios.</li>
</ul>

<h3>Title: Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms</h3>
<ul>
<li><strong>Authors: </strong>Shiyi Liu, Buwen Liang, Yuetong Fang, Zixuan Jiang, Renjing Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02724">https://arxiv.org/abs/2507.02724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02724">https://arxiv.org/pdf/2507.02724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02724]] Hierarchical Multi-Label Contrastive Learning for Protein-Protein Interaction Prediction Across Organisms(https://arxiv.org/abs/2507.02724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in AI for science have highlighted the power of contrastive learning in bridging heterogeneous biological data modalities. Building on this paradigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction across Organisms), a hierarchical contrastive framework for protein-protein interaction(PPI) prediction, where protein sequences and their hierarchical attributes are aligned through multi-tiered biological representation matching. The proposed approach incorporates hierarchical contrastive loss functions that emulate the structured relationship among functional classes of proteins. The framework adaptively incorporates domain and family knowledge through a data-driven penalty mechanism, enforcing consistency between the learned embedding space and the intrinsic hierarchy of protein functions. Experiments on benchmark datasets demonstrate that HIPPO achieves state-of-the-art performance, outperforming existing methods and showing robustness in low-data regimes. Notably, the model demonstrates strong zero-shot transferability to other species without retraining, enabling reliable PPI prediction and functional inference even in less characterized or rare organisms where experimental data are limited. Further analysis reveals that hierarchical feature fusion is critical for capturing conserved interaction determinants, such as binding motifs and functional annotations. This work advances cross-species PPI prediction and provides a unified framework for interaction prediction in scenarios with sparse or imbalanced multi-species data.</li>
</ul>

<h3>Title: Quantifying Classifier Utility under Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Ye Zheng, Yidan Hu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02727">https://arxiv.org/abs/2507.02727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02727">https://arxiv.org/pdf/2507.02727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02727]] Quantifying Classifier Utility under Local Differential Privacy(https://arxiv.org/abs/2507.02727)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Local differential privacy (LDP) provides a rigorous and quantifiable privacy guarantee for personal data by introducing perturbation at the data source. However, quantifying the impact of these perturbations on classifier utility remains a theoretical challenge, particularly for complex or black-box classifiers. This paper presents a framework for theoretically quantifying classifier utility under LDP mechanisms. The key insight is that LDP perturbation is concentrated around the original data with a specific probability, transforming utility analysis of the classifier into its robustness analysis in this concentrated region. Our framework connects the concentration analysis of LDP mechanisms with the robustness analysis of classifiers. It treats LDP mechanisms as general distributional functions and classifiers as black-box functions, thus applicable to any LDP mechanism and classifier. A direct application of our utility quantification is guiding the selection of LDP mechanisms and privacy parameters for a given classifier. Notably, our analysis shows that a piecewise-based mechanism leads to better utility compared to alternatives in common scenarios. Using this framework alongside two novel refinement techniques, we conduct case studies on utility quantification for typical mechanism-classifier combinations. The results demonstrate that our theoretical utility quantification aligns closely with empirical observations, particularly when classifiers operate in lower-dimensional input spaces.</li>
</ul>

<h3>Title: Classification by Separating Hypersurfaces: An Entropic Approach</h3>
<ul>
<li><strong>Authors: </strong>Argimiro Arratia, Mahmoud El Daou, Henryk Gzyl</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.IT, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02732">https://arxiv.org/abs/2507.02732</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02732">https://arxiv.org/pdf/2507.02732</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02732]] Classification by Separating Hypersurfaces: An Entropic Approach(https://arxiv.org/abs/2507.02732)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We consider the following classification problem: Given a population of individuals characterized by a set of attributes represented as a vector in ${\mathbb R}^N$, the goal is to find a hyperplane in ${\mathbb R}^N$ that separates two sets of points corresponding to two distinct classes. This problem, with a history dating back to the perceptron model, remains central to machine learning. In this paper we propose a novel approach by searching for a vector of parameters in a bounded $N$-dimensional hypercube centered at the origin and a positive vector in ${\mathbb R}^M$, obtained through the minimization of an entropy-based function defined over the space of unknown variables. The method extends to polynomial surfaces, allowing the separation of data points by more complex decision boundaries. This provides a robust alternative to traditional linear or quadratic optimization techniques, such as support vector machines and gradient descent. Numerical experiments demonstrate the efficiency and versatility of the method in handling diverse classification tasks, including linear and non-linear separability.</li>
</ul>

<h3>Title: Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks</h3>
<ul>
<li><strong>Authors: </strong>Sizhe Chen, Arman Zharmagambetov, David Wagner, Chuan Guo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02735">https://arxiv.org/abs/2507.02735</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02735">https://arxiv.org/pdf/2507.02735</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02735]] Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks(https://arxiv.org/abs/2507.02735)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.</li>
</ul>

<h3>Title: Early Signs of Steganographic Capabilities in Frontier LLMs</h3>
<ul>
<li><strong>Authors: </strong>Artur Zolkowski, Kei Nishimura-Gasparian, Robert McCarthy, Roland S. Zimmermann, David Lindner</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02737">https://arxiv.org/abs/2507.02737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02737">https://arxiv.org/pdf/2507.02737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02737]] Early Signs of Steganographic Capabilities in Frontier LLMs(https://arxiv.org/abs/2507.02737)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Monitoring Large Language Model (LLM) outputs is crucial for mitigating risks from misuse and misalignment. However, LLMs could evade monitoring through steganography: Encoding hidden information within seemingly benign generations. In this paper, we evaluate the steganography capabilities in frontier LLMs to better understand the risk they pose. We focus on two types of steganography: passing encoded messages and performing encoded reasoning. We find that current models are unable to encode short messages in their outputs without a monitor noticing under standard affordances. They can succeed, however, if given additional affordances such as using an unmonitored scratchpad and coordinating on what encoding scheme to use. We additionally find early signs that models can perform basic encoded reasoning in a simple state-tracking problem. This includes some ability to reason with their own and pre-defined schemes, including encoding schemes such as Hexadecimal. Despite this, they can rarely hide reasoning subtly within a cover task to fool a monitor. Overall, our results indicate that current LLMs exhibit nascent steganographic capabilities. While these capabilities are likely insufficient to bypass well-designed monitors at present, this could change in the future.</li>
</ul>

<h3>Title: Prompt learning with bounding box constraints for medical image segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mélanie Gaillochet, Mehrdad Noori, Sahar Dastani, Christian Desrosiers, Hervé Lombaert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02743">https://arxiv.org/abs/2507.02743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02743">https://arxiv.org/pdf/2507.02743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02743]] Prompt learning with bounding box constraints for medical image segmentation(https://arxiv.org/abs/2507.02743)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Pixel-wise annotations are notoriously labourious and costly to obtain in the medical domain. To mitigate this burden, weakly supervised approaches based on bounding box annotations-much easier to acquire-offer a practical alternative. Vision foundation models have recently shown noteworthy segmentation performance when provided with prompts such as points or bounding boxes. Prompt learning exploits these models by adapting them to downstream tasks and automating segmentation, thereby reducing user intervention. However, existing prompt learning approaches depend on fully annotated segmentation masks. This paper proposes a novel framework that combines the representational power of foundation models with the annotation efficiency of weakly supervised segmentation. More specifically, our approach automates prompt generation for foundation models using only bounding box annotations. Our proposed optimization scheme integrates multiple constraints derived from box annotations with pseudo-labels generated by the prompted foundation model. Extensive experiments across multimodal datasets reveal that our weakly supervised method achieves an average Dice score of 84.90% in a limited data setting, outperforming existing fully-supervised and weakly-supervised approaches. The code is available at this https URL</li>
</ul>

<h3>Title: Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics</h3>
<ul>
<li><strong>Authors: </strong>Alex Colagrande, Paul Caillon, Eva Feillet, Alexandre Allauzen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02748">https://arxiv.org/abs/2507.02748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02748">https://arxiv.org/pdf/2507.02748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02748]] Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics(https://arxiv.org/abs/2507.02748)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have become the de facto standard for a wide range of tasks, from image classification to physics simulations. Despite their impressive performance, the quadratic complexity of standard Transformers in both memory and time with respect to the input length makes them impractical for processing high-resolution inputs. Therefore, several variants have been proposed, the most successful relying on patchification, downsampling, or coarsening techniques, often at the cost of losing the finest-scale details. In this work, we take a different approach. Inspired by state-of-the-art techniques in $n$-body numerical simulations, we cast attention as an interaction problem between grid points. We introduce the Multipole Attention Neural Operator (MANO), which computes attention in a distance-based multiscale fashion. MANO maintains, in each attention head, a global receptive field and achieves linear time and memory complexity with respect to the number of grid points. Empirical results on image classification and Darcy flows demonstrate that MANO rivals state-of-the-art models such as ViT and Swin Transformer, while reducing runtime and peak memory usage by orders of magnitude. We open source our code for reproducibility at this https URL.</li>
</ul>

<h3>Title: Fast and Simplex: 2-Simplicial Attention in Triton</h3>
<ul>
<li><strong>Authors: </strong>Aurko Roy, Timothy Chou, Sai Surya Duvvuri, Sijia Chen, Jiecao Yu, Xiaodong Wang, Manzil Zaheer, Rohan Anil</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02754">https://arxiv.org/abs/2507.02754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02754">https://arxiv.org/pdf/2507.02754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02754]] Fast and Simplex: 2-Simplicial Attention in Triton(https://arxiv.org/abs/2507.02754)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent work has shown that training loss scales as a power law with both model size and the number of tokens, and that achieving compute-optimal models requires scaling model size and token count together. However, these scaling laws assume an infinite supply of data and apply primarily in compute-bound settings. As modern large language models increasingly rely on massive internet-scale datasets, the assumption that they are compute-bound is becoming less valid. This shift highlights the need for architectures that prioritize token efficiency. In this work, we investigate the use of the 2-simplicial Transformer, an architecture that generalizes standard dot-product attention to trilinear functions through an efficient Triton kernel implementation. We demonstrate that the 2-simplicial Transformer achieves better token efficiency than standard Transformers: for a fixed token budget, similarly sized models outperform their dot-product counterparts on tasks involving mathematics, coding, reasoning, and logic. We quantify these gains by demonstrating that $2$-simplicial attention changes the exponent in the scaling laws for knowledge and reasoning tasks compared to dot product attention.</li>
</ul>

<h3>Title: Contextual Online Pricing with (Biased) Offline Data</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Zhang, Ruihao Zhu, Qiaomin Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02762">https://arxiv.org/abs/2507.02762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02762">https://arxiv.org/pdf/2507.02762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02762]] Contextual Online Pricing with (Biased) Offline Data(https://arxiv.org/abs/2507.02762)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study contextual online pricing with biased offline data. For the scalar price elasticity case, we identify the instance-dependent quantity $\delta^2$ that measures how far the offline data lies from the (unknown) online optimum. We show that the time length $T$, bias bound $V$, size $N$ and dispersion $\lambda_{\min}(\hat{\Sigma})$ of the offline data, and $\delta^2$ jointly determine the statistical complexity. An Optimism-in-the-Face-of-Uncertainty (OFU) policy achieves a minimax-optimal, instance-dependent regret bound $\tilde{\mathcal{O}}\big(d\sqrt{T} \wedge (V^2T + \frac{dT}{\lambda_{\min}(\hat{\Sigma}) + (N \wedge T) \delta^2})\big)$. For general price elasticity, we establish a worst-case, minimax-optimal rate $\tilde{\mathcal{O}}\big(d\sqrt{T} \wedge (V^2T + \frac{dT }{\lambda_{\min}(\hat{\Sigma})})\big)$ and provide a generalized OFU algorithm that attains it. When the bias bound $V$ is unknown, we design a robust variant that always guarantees sub-linear regret and strictly improves on purely online methods whenever the exact bias is small. These results deliver the first tight regret guarantees for contextual pricing in the presence of biased offline data. Our techniques also transfer verbatim to stochastic linear bandits with biased offline data, yielding analogous bounds.</li>
</ul>

<h3>Title: NVIDIA GPU Confidential Computing Demystified</h3>
<ul>
<li><strong>Authors: </strong>Zhongshu Gu, Enriquillo Valdez, Salman Ahmed, Julian James Stephen, Michael Le, Hani Jamjoom, Shixuan Zhao, Zhiqiang Lin</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02770">https://arxiv.org/abs/2507.02770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02770">https://arxiv.org/pdf/2507.02770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02770]] NVIDIA GPU Confidential Computing Demystified(https://arxiv.org/abs/2507.02770)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>GPU Confidential Computing (GPU-CC) was introduced as part of the NVIDIA Hopper Architecture, extending the trust boundary beyond traditional CPU-based confidential computing. This innovation enables GPUs to securely process AI workloads, providing a robust and efficient solution for handling sensitive data. For end users, transitioning to GPU-CC mode is seamless, requiring no modifications to existing AI applications. However, this ease of adoption contrasts sharply with the complexity of the underlying proprietary systems. The lack of transparency presents significant challenges for security researchers seeking a deeper understanding of GPU-CC's architecture and operational mechanisms. The challenges of analyzing the NVIDIA GPU-CC system arise from a scarcity of detailed specifications, the proprietary nature of the ecosystem, and the complexity of product design. In this paper, we aim to demystify the implementation of NVIDIA GPU-CC system by piecing together the fragmented and incomplete information disclosed from various sources. Our investigation begins with a high-level discussion of the threat model and security principles before delving into the low-level details of each system component. We instrument the GPU kernel module -- the only open-source component of the system -- and conduct a series of experiments to identify the security weaknesses and potential exploits. For certain components that are out of reach through experiments, we propose well-reasoned speculations about their inner working mechanisms. We have responsibly reported all security findings presented in this paper to the NVIDIA PSIRT Team.</li>
</ul>

<h3>Title: Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ken Tsui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02778">https://arxiv.org/abs/2507.02778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02778">https://arxiv.org/pdf/2507.02778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02778]] Self-Correction Bench: Revealing and Addressing the Self-Correction Blind Spot in LLMs(https://arxiv.org/abs/2507.02778)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although large language models (LLMs) have become transformative, they still make mistakes and can explore unproductive reasoning paths. Self-correction is an important capability for a trustworthy LLM, particularly an autoregressive LLM. While LLMs can identify error in user input, they exhibit a systematic 'Self-Correction Blind Spot' - failing to correct identical error in their own outputs. To systematically study this phenomenon, we introduce Self-Correction Bench, a systematic framework to measure this phenomenon through controlled error injection at three complexity levels. Testing 14 models, we find an average 64.5% blind spot rate. We find multiple evidences that this limitation relates to training data composition: human training demonstrations predominantly show error-free responses rather than error-correction sequences, unlike RL-trained models that learn error correction through outcome feedback. Remarkably, simply appending "Wait" reduces blind spots by 89.3%, suggesting that the capability exists but requires activation. Our work highlights a critical limitation in current LLMs and offers potential avenues for improving their reliability and trustworthiness.</li>
</ul>

<h3>Title: From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images</h3>
<ul>
<li><strong>Authors: </strong>Danrong Zhang, Huili Huang, N. Simrill Smith, Nimisha Roy, J. David Frost</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02781">https://arxiv.org/abs/2507.02781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02781">https://arxiv.org/pdf/2507.02781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02781]] From Pixels to Damage Severity: Estimating Earthquake Impacts Using Semantic Segmentation of Social Media Images(https://arxiv.org/abs/2507.02781)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In the aftermath of earthquakes, social media images have become a crucial resource for disaster reconnaissance, providing immediate insights into the extent of damage. Traditional approaches to damage severity assessment in post-earthquake social media images often rely on classification methods, which are inherently subjective and incapable of accounting for the varying extents of damage within an image. Addressing these limitations, this study proposes a novel approach by framing damage severity assessment as a semantic segmentation problem, aiming for a more objective analysis of damage in earthquake-affected areas. The methodology involves the construction of a segmented damage severity dataset, categorizing damage into three degrees: undamaged structures, damaged structures, and debris. Utilizing this dataset, the study fine-tunes a SegFormer model to generate damage severity segmentations for post-earthquake social media images. Furthermore, a new damage severity scoring system is introduced, quantifying damage by considering the varying degrees of damage across different areas within images, adjusted for depth estimation. The application of this approach allows for the quantification of damage severity in social media images in a more objective and comprehensive manner. By providing a nuanced understanding of damage, this study enhances the ability to offer precise guidance to disaster reconnaissance teams, facilitating more effective and targeted response efforts in the aftermath of earthquakes.</li>
</ul>

<h3>Title: Understanding and Improving Length Generalization in Recurrent Models</h3>
<ul>
<li><strong>Authors: </strong>Ricardo Buitrago Ruiz, Albert Gu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02782">https://arxiv.org/abs/2507.02782</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02782">https://arxiv.org/pdf/2507.02782</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02782]] Understanding and Improving Length Generalization in Recurrent Models(https://arxiv.org/abs/2507.02782)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recently, recurrent models such as state space models and linear attention have become popular due to their linear complexity in the sequence length. Thanks to their recurrent nature, in principle they can process arbitrarily long sequences, but their performance sometimes drops considerably beyond their training context lengths-i.e. they fail to length generalize. In this work, we provide comprehensive empirical and theoretical analysis to support the unexplored states hypothesis, which posits that models fail to length generalize when during training they are only exposed to a limited subset of the distribution of all attainable states (i.e. states that would be attained if the recurrence was applied to long sequences). Furthermore, we investigate simple training interventions that aim to increase the coverage of the states that the model is trained on, e.g. by initializing the state with Gaussian noise or with the final state of a different input sequence. With only 500 post-training steps ($\sim 0.1\%$ of the pre-training budget), these interventions enable length generalization for sequences that are orders of magnitude longer than the training context (e.g. $2k\longrightarrow 128k$) and show improved performance in long context tasks, thus presenting a simple and efficient way to enable robust length generalization in general recurrent models.</li>
</ul>

<h3>Title: From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding</h3>
<ul>
<li><strong>Authors: </strong>Xiangfeng Wang, Xiao Li, Yadong Wei, Xueyu Song, Yang Song, Xiaoqiang Xia, Fangrui Zeng, Zaiyi Chen, Liu Liu, Gu Xu, Tong Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02790">https://arxiv.org/abs/2507.02790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02790">https://arxiv.org/pdf/2507.02790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02790]] From Long Videos to Engaging Clips: A Human-Inspired Video Editing Framework with Multimodal Narrative Understanding(https://arxiv.org/abs/2507.02790)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The rapid growth of online video content, especially on short video platforms, has created a growing demand for efficient video editing techniques that can condense long-form videos into concise and engaging clips. Existing automatic editing methods predominantly rely on textual cues from ASR transcripts and end-to-end segment selection, often neglecting the rich visual context and leading to incoherent outputs. In this paper, we propose a human-inspired automatic video editing framework (HIVE) that leverages multimodal narrative understanding to address these limitations. Our approach incorporates character extraction, dialogue analysis, and narrative summarization through multimodal large language models, enabling a holistic understanding of the video content. To further enhance coherence, we apply scene-level segmentation and decompose the editing process into three subtasks: highlight detection, opening/ending selection, and pruning of irrelevant content. To facilitate research in this area, we introduce DramaAD, a novel benchmark dataset comprising over 800 short drama episodes and 500 professionally edited advertisement clips. Experimental results demonstrate that our framework consistently outperforms existing baselines across both general and advertisement-oriented editing tasks, significantly narrowing the quality gap between automatic and human-edited videos.</li>
</ul>

<h3>Title: RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Liheng Zhang, Lexi Pang, Hang Ye, Xiaoxuan Ma, Yizhou Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02792">https://arxiv.org/abs/2507.02792</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02792">https://arxiv.org/pdf/2507.02792</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02792]] RichControl: Structure- and Appearance-Rich Training-Free Spatial Control for Text-to-Image Generation(https://arxiv.org/abs/2507.02792)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) diffusion models have shown remarkable success in generating high-quality images from text prompts. Recent efforts extend these models to incorporate conditional images (e.g., depth or pose maps) for fine-grained spatial control. Among them, feature injection methods have emerged as a training-free alternative to traditional fine-tuning approaches. However, they often suffer from structural misalignment, condition leakage, and visual artifacts, especially when the condition image diverges significantly from natural RGB distributions. By revisiting existing methods, we identify a core limitation: the synchronous injection of condition features fails to account for the trade-off between domain alignment and structural preservation during denoising. Inspired by this observation, we propose a flexible feature injection framework that decouples the injection timestep from the denoising process. At its core is a structure-rich injection module, which enables the model to better adapt to the evolving interplay between alignment and structure preservation throughout the diffusion steps, resulting in more faithful structural generation. In addition, we introduce appearance-rich prompting and a restart refinement strategy to further enhance appearance control and visual quality. Together, these designs enable training-free generation that is both structure-rich and appearance-rich. Extensive experiments show that our approach achieves state-of-the-art performance across diverse zero-shot conditioning scenarios.</li>
</ul>

<h3>Title: No time to train! Training-Free Reference-Based Instance Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Miguel Espinosa, Chenhongyi Yang, Linus Ericsson, Steven McDonagh, Elliot J. Crowley</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02798">https://arxiv.org/abs/2507.02798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02798">https://arxiv.org/pdf/2507.02798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02798]] No time to train! Training-Free Reference-Based Instance Segmentation(https://arxiv.org/abs/2507.02798)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The performance of image segmentation models has historically been constrained by the high cost of collecting large-scale annotated data. The Segment Anything Model (SAM) alleviates this original problem through a promptable, semantics-agnostic, segmentation paradigm and yet still requires manual visual-prompts or complex domain-dependent prompt-generation rules to process a new image. Towards reducing this new burden, our work investigates the task of object segmentation when provided with, alternatively, only a small set of reference images. Our key insight is to leverage strong semantic priors, as learned by foundation models, to identify corresponding regions between a reference and a target image. We find that correspondences enable automatic generation of instance-level segmentation masks for downstream tasks and instantiate our ideas via a multi-stage, training-free method incorporating (1) memory bank construction; (2) representation aggregation and (3) semantic-aware feature matching. Our experiments show significant improvements on segmentation metrics, leading to state-of-the-art performance on COCO FSOD (36.8% nAP), PASCAL VOC Few-Shot (71.2% nAP50) and outperforming existing training-free approaches on the Cross-Domain FSOD benchmark (22.4% nAP).</li>
</ul>

<h3>Title: Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Cantini, Nicola Gabriele, Alessio Orsino, Domenico Talia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02799">https://arxiv.org/abs/2507.02799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02799">https://arxiv.org/pdf/2507.02799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02799]] Is Reasoning All You Need? Probing Bias in the Age of Reasoning Language Models(https://arxiv.org/abs/2507.02799)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, fair, large language model</a></li>
<li><strong>Abstract: </strong>Reasoning Language Models (RLMs) have gained traction for their ability to perform complex, multi-step reasoning tasks through mechanisms such as Chain-of-Thought (CoT) prompting or fine-tuned reasoning traces. While these capabilities promise improved reliability, their impact on robustness to social biases remains unclear. In this work, we leverage the CLEAR-Bias benchmark, originally designed for Large Language Models (LLMs), to investigate the adversarial robustness of RLMs to bias elicitation. We systematically evaluate state-of-the-art RLMs across diverse sociocultural dimensions, using an LLM-as-a-judge approach for automated safety scoring and leveraging jailbreak techniques to assess the strength of built-in safety mechanisms. Our evaluation addresses three key questions: (i) how the introduction of reasoning capabilities affects model fairness and robustness; (ii) whether models fine-tuned for reasoning exhibit greater safety than those relying on CoT prompting at inference time; and (iii) how the success rate of jailbreak attacks targeting bias elicitation varies with the reasoning mechanisms employed. Our findings reveal a nuanced relationship between reasoning capabilities and bias safety. Surprisingly, models with explicit reasoning, whether via CoT prompting or fine-tuned reasoning traces, are generally more vulnerable to bias elicitation than base models without such mechanisms, suggesting reasoning may unintentionally open new pathways for stereotype reinforcement. Reasoning-enabled models appear somewhat safer than those relying on CoT prompting, which are particularly prone to contextual reframing attacks through storytelling prompts, fictional personas, or reward-shaped instructions. These results challenge the assumption that reasoning inherently improves robustness and underscore the need for more bias-aware approaches to reasoning design.</li>
</ul>

<h3>Title: Multimodal Mathematical Reasoning with Diverse Solving Perspective</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Shi, Zhiqiang Hu, Yi Bin, Yang Yang, See-Kiong Ng, Heng Tao Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02804">https://arxiv.org/abs/2507.02804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02804">https://arxiv.org/pdf/2507.02804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02804]] Multimodal Mathematical Reasoning with Diverse Solving Perspective(https://arxiv.org/abs/2507.02804)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent progress in large-scale reinforcement learning (RL) has notably enhanced the reasoning capabilities of large language models (LLMs), especially in mathematical domains. However, current multimodal LLMs (MLLMs) for mathematical reasoning often rely on one-to-one image-text pairs and single-solution supervision, overlooking the diversity of valid reasoning perspectives and internal reflections. In this work, we introduce MathV-DP, a novel dataset that captures multiple diverse solution trajectories for each image-question pair, fostering richer reasoning supervision. We further propose Qwen-VL-DP, a model built upon Qwen-VL, fine-tuned with supervised learning and enhanced via group relative policy optimization (GRPO), a rule-based RL approach that integrates correctness discrimination and diversity-aware reward functions. Our method emphasizes learning from varied reasoning perspectives and distinguishing between correct yet distinct solutions. Extensive experiments on the MathVista's minitest and Math-V benchmarks demonstrate that Qwen-VL-DP significantly outperforms prior base MLLMs in both accuracy and generative diversity, highlighting the importance of incorporating diverse perspectives and reflective reasoning in multimodal mathematical reasoning.</li>
</ul>

<h3>Title: LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Fangfu Liu, Hao Li, Jiawei Chi, Hanyang Wang, Minghui Yang, Fudong Wang, Yueqi Duan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02813">https://arxiv.org/abs/2507.02813</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02813">https://arxiv.org/pdf/2507.02813</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02813]] LangScene-X: Reconstruct Generalizable 3D Language-Embedded Scenes with TriMap Video Diffusion(https://arxiv.org/abs/2507.02813)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Recovering 3D structures with open-vocabulary scene understanding from 2D images is a fundamental but daunting task. Recent developments have achieved this by performing per-scene optimization with embedded language information. However, they heavily rely on the calibrated dense-view reconstruction paradigm, thereby suffering from severe rendering artifacts and implausible semantic synthesis when limited views are available. In this paper, we introduce a novel generative framework, coined LangScene-X, to unify and generate 3D consistent multi-modality information for reconstruction and understanding. Powered by the generative capability of creating more consistent novel observations, we can build generalizable 3D language-embedded scenes from only sparse views. Specifically, we first train a TriMap video diffusion model that can generate appearance (RGBs), geometry (normals), and semantics (segmentation maps) from sparse inputs through progressive knowledge integration. Furthermore, we propose a Language Quantized Compressor (LQC), trained on large-scale image datasets, to efficiently encode language embeddings, enabling cross-scene generalization without per-scene retraining. Finally, we reconstruct the language surface fields by aligning language information onto the surface of 3D scenes, enabling open-ended language queries. Extensive experiments on real-world data demonstrate the superiority of our LangScene-X over state-of-the-art methods in terms of quality and generalizability. Project Page: this https URL.</li>
</ul>

<h3>Title: SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Wencheng Zhang, Shiqin Qiao, Lingjie Luo, Yinfeng Li, Chuanyang Zheng, Qian Xu, Meng Li, Yong Gui, Yijun He, Jianing Qiu, Jindong Hong, Jiankai Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02822">https://arxiv.org/abs/2507.02822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02822">https://arxiv.org/pdf/2507.02822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02822]] SynapseRoute: An Auto-Route Switching Framework on Dual-State Large Language Model(https://arxiv.org/abs/2507.02822)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the widespread adoption of large language models (LLMs) in practical applications, selecting an appropriate model requires balancing not only performance but also operational cost. The emergence of reasoning-capable models has further widened the cost gap between "thinking" (high reasoning) and "non-thinking" (fast, low-cost) modes. In this work, we reveal that approximately 58% of medical questions can be accurately answered by the non-thinking mode alone, without requiring the high-cost reasoning process. This highlights a clear dichotomy in problem complexity and suggests that dynamically routing queries to the appropriate mode based on complexity could optimize accuracy, cost-efficiency, and overall user experience. Based on this, we further propose SynapseRoute, a machine learning-based dynamic routing framework that intelligently assigns input queries to either thinking or non-thinking modes. Experimental results on several medical datasets demonstrate that SynapseRoute not only improves overall accuracy (0.8390 vs. 0.8272) compared to the thinking mode alone but also reduces inference time by 36.8% and token consumption by 39.66%. Importantly, qualitative analysis indicates that over-reasoning on simpler queries can lead to unnecessary delays and even decreased accuracy, a pitfall avoided by our adaptive routing. Finally, this work further introduces the Accuracy-Inference-Token (AIT) index to comprehensively evaluate the trade-offs among accuracy, latency, and token cost.</li>
</ul>

<h3>Title: Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Panpan Ji, Junni Song, Hang Xiao, Hanyu Liu, Chao Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02826">https://arxiv.org/abs/2507.02826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02826">https://arxiv.org/pdf/2507.02826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02826]] Confidence-driven Gradient Modulation for Multimodal Human Activity Recognition: A Dynamic Contrastive Dual-Path Learning Approach(https://arxiv.org/abs/2507.02826)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Sensor-based Human Activity Recognition (HAR) is a core technology that enables intelligent systems to perceive and interact with their environment. However, multimodal HAR systems still encounter key challenges, such as difficulties in cross-modal feature alignment and imbalanced modality contributions. To address these issues, we propose a novel framework called the Dynamic Contrastive Dual-Path Network (DCDP-HAR). The framework comprises three key components. First, a dual-path feature extraction architecture is employed, where ResNet and DenseNet branches collaboratively process multimodal sensor data. Second, a multi-stage contrastive learning mechanism is introduced to achieve progressive alignment from local perception to semantic abstraction. Third, we present a confidence-driven gradient modulation strategy that dynamically monitors and adjusts the learning intensity of each modality branch during backpropagation, effectively alleviating modality competition. In addition, a momentum-based gradient accumulation strategy is adopted to enhance training stability. We conduct ablation studies to validate the effectiveness of each component and perform extensive comparative experiments on four public benchmark datasets.</li>
</ul>

<h3>Title: USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network</h3>
<ul>
<li><strong>Authors: </strong>Ying Yu, Hang Xiao, Siyao Li, Jiarui Li, Haotian Tang, Hanyu Liu, Chao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02827">https://arxiv.org/abs/2507.02827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02827">https://arxiv.org/pdf/2507.02827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02827]] USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network(https://arxiv.org/abs/2507.02827)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, extraction, diffusion</a></li>
<li><strong>Abstract: </strong>The primary objective of human activity recognition (HAR) is to infer ongoing human actions from sensor data, a task that finds broad applications in health monitoring, safety protection, and sports analysis. Despite proliferating research, HAR still faces key challenges, including the scarcity of labeled samples for rare activities, insufficient extraction of high-level features, and suboptimal model performance on lightweight devices. To address these issues, this paper proposes a comprehensive optimization approach centered on multi-attention interaction mechanisms. First, an unsupervised, statistics-guided diffusion model is employed to perform data augmentation, thereby alleviating the problems of labeled data scarcity and severe class imbalance. Second, a multi-branch spatio-temporal interaction network is designed, which captures multi-scale features of sequential data through parallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels. Simultaneously, temporal attention mechanisms are incorporated to identify critical time points, while spatial attention enhances inter-sensor interactions. A cross-branch feature fusion unit is further introduced to improve the overall feature representation capability. Finally, an adaptive multi-loss function fusion strategy is integrated, allowing for dynamic adjustment of loss weights and overall model optimization. Experimental results on three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the proposed unsupervised data augmentation spatio-temporal attention diffusion network (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively, significantly outperforming existing approaches. Furthermore, practical deployment on embedded devices verifies the efficiency and feasibility of the proposed method.</li>
</ul>

<h3>Title: ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Ruiyang Zhou, Shuozhe Li, Amy Zhang, Liu Leqi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02834">https://arxiv.org/abs/2507.02834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02834">https://arxiv.org/pdf/2507.02834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02834]] ExPO: Unlocking Hard Reasoning with Self-Explanation-Guided Reinforcement Learning(https://arxiv.org/abs/2507.02834)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models have been driven by reinforcement learning (RL)-style post-training, which improves reasoning by optimizing model outputs based on reward or preference signals. GRPO-style approaches implement this by using self-generated samples labeled by an outcome-based verifier. However, these methods depend heavily on the model's initial ability to produce positive samples. They primarily refine what the model already knows (distribution sharpening) rather than enabling the model to solve problems where it initially fails. This limitation is especially problematic in early-stage RL training and on challenging reasoning tasks, where positive samples are unlikely to be generated. To unlock reasoning ability in such settings, the model must explore new reasoning trajectories beyond its current output distribution. Such exploration requires access to sufficiently good positive samples to guide the learning. While expert demonstrations seem like a natural solution, we find that they are often ineffective in RL post-training. Instead, we identify two key properties of effective positive samples: they should (1) be likely under the current policy, and (2) increase the model's likelihood of predicting the correct answer. Based on these insights, we propose $\textbf{Self-Explanation Policy Optimization (ExPO)}$-a simple and modular framework that generates such samples by conditioning on the ground-truth answer. ExPO enables efficient exploration and guides the model to produce reasoning trajectories more aligned with its policy than expert-written CoTs, while ensuring higher quality than its own (incorrect) samples. Experiments show that ExPO improves both learning efficiency and final performance on reasoning benchmarks, surpassing expert-demonstration-based methods in challenging settings such as MATH level-5, where the model initially struggles the most.</li>
</ul>

<h3>Title: LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Ma, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02843">https://arxiv.org/abs/2507.02843</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02843">https://arxiv.org/pdf/2507.02843</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02843]] LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding(https://arxiv.org/abs/2507.02843)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Estimating treatment effects is crucial for personalized decision-making in medicine, but this task faces unique challenges in clinical practice. At training time, models for estimating treatment effects are typically trained on well-structured medical datasets that contain detailed patient information. However, at inference time, predictions are often made using textual descriptions (e.g., descriptions with self-reported symptoms), which are incomplete representations of the original patient information. In this work, we make three contributions. (1) We show that the discrepancy between the data available during training time and inference time can lead to biased estimates of treatment effects. We formalize this issue as an inference time text confounding problem, where confounders are fully observed during training time but only partially available through text at inference time. (2) To address this problem, we propose a novel framework for estimating treatment effects that explicitly accounts for inference time text confounding. Our framework leverages large language models together with a custom doubly robust learner to mitigate biases caused by the inference time text confounding. (3) Through a series of experiments, we demonstrate the effectiveness of our framework in real-world applications.</li>
</ul>

<h3>Title: Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection</h3>
<ul>
<li><strong>Authors: </strong>Ziqi Miao, Yi Ding, Lijun Li, Jing Shao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02844">https://arxiv.org/abs/2507.02844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02844">https://arxiv.org/pdf/2507.02844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02844]] Visual Contextual Attack: Jailbreaking MLLMs with Image-Driven Context Injection(https://arxiv.org/abs/2507.02844)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>With the emergence of strong visual-language capabilities, multimodal large language models (MLLMs) have demonstrated tremendous potential for real-world applications. However, the security vulnerabilities exhibited by the visual modality pose significant challenges to deploying such models in open-world environments. Recent studies have successfully induced harmful responses from target MLLMs by encoding harmful textual semantics directly into visual inputs. However, in these approaches, the visual modality primarily serves as a trigger for unsafe behavior, often exhibiting semantic ambiguity and lacking grounding in realistic scenarios. In this work, we define a novel setting: visual-centric jailbreak, where visual information serves as a necessary component in constructing a complete and realistic jailbreak context. Building on this setting, we propose the VisCo (Visual Contextual) Attack. VisCo fabricates contextual dialogue using four distinct visual-focused strategies, dynamically generating auxiliary images when necessary to construct a visual-centric jailbreak scenario. To maximize attack effectiveness, it incorporates automatic toxicity obfuscation and semantic refinement to produce a final attack prompt that reliably triggers harmful responses from the target black-box MLLMs. Specifically, VisCo achieves a toxicity score of 4.78 and an Attack Success Rate (ASR) of 85% on MM-SafetyBench against GPT-4o, significantly outperforming the baseline, which performs a toxicity score of 2.48 and an ASR of 22.2%. The code is available at this https URL.</li>
</ul>

<h3>Title: LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users</h3>
<ul>
<li><strong>Authors: </strong>Almog Hilel, Idan Shenfeld, Leshem Choshen, Jacob Andreas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02850">https://arxiv.org/abs/2507.02850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02850">https://arxiv.org/pdf/2507.02850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02850]] LLM Hypnosis: Exploiting User Feedback for Unauthorized Knowledge Injection to All Users(https://arxiv.org/abs/2507.02850)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>We describe a vulnerability in language models (LMs) trained with user feedback, whereby a single user can persistently alter LM knowledge and behavior given only the ability to provide prompts and upvote / downvote feedback on LM outputs. To implement the attack, the attacker prompts the LM to stochastically output either a "poisoned" or benign response, then upvotes the poisoned response or downvotes the benign one. When feedback signals are used in a subsequent preference tuning behavior, LMs exhibit increased probability of producing poisoned responses even in contexts without malicious prompts. We show that this attack can be used to (1) insert factual knowledge the model did not previously possess, (2) modify code generation patterns in ways that introduce exploitable security flaws, and (3) inject fake financial news. Our finding both identifies a new qualitative feature of language model preference tuning (showing that it even highly restricted forms of preference data can be used to exert fine-grained control over behavior), and a new attack mechanism for LMs trained with user feedback (extending work on pretraining-time data poisoning and deployment-time prompt injection).</li>
</ul>

<h3>Title: MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Purbesh Mitra, Sennur Ulukus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IT, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02851">https://arxiv.org/abs/2507.02851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02851">https://arxiv.org/pdf/2507.02851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02851]] MOTIF: Modular Thinking via Reinforcement Fine-tuning in LLMs(https://arxiv.org/abs/2507.02851)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in the reasoning capabilities of large language models (LLMs) show that employing group relative policy optimization (GRPO) algorithm for reinforcement learning (RL) training allows the models to use more thinking/reasoning tokens for generating better responses. However, LLMs can generate only a finite amount of tokens while maintaining attention to the previously generated tokens. This limit, also known as the context size of an LLM, is a bottleneck in LLM reasoning with arbitrarily large number of tokens. To think beyond the limit of context size, an LLM must employ a modular thinking strategy to reason over multiple rounds. In this work, we propose $\textbf{MOTIF: Modular Thinking via Reinforcement Finetuning}$ -- an RL training method for generating thinking tokens in multiple rounds, effectively allowing the model to think with additional context size. We trained the open-source model Qwen2.5-3B-Instruct on GSM8K dataset via parameter efficient fine-tuning and tested its accuracy on MATH500 and AIME2024 benchmarks. Our experiments show 3.8\% and 3.3\% improvements over vanilla GRPO based training in the respective benchmarks. Furthermore, this improvement was achieved with only 15\% of samples, thus demonstrating sample efficiency of MOTIF. Our code and models are available at this https URL and this https URL, respectively.</li>
</ul>

<h3>Title: Answer Matching Outperforms Multiple Choice for Language Model Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02856">https://arxiv.org/abs/2507.02856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02856">https://arxiv.org/pdf/2507.02856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02856]] Answer Matching Outperforms Multiple Choice for Language Model Evaluation(https://arxiv.org/abs/2507.02856)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Multiple choice benchmarks have long been the workhorse of language model evaluation because grading multiple choice is objective and easy to automate. However, we show multiple choice questions from popular benchmarks can often be answered without even seeing the question. These shortcuts arise from a fundamental limitation of discriminative evaluation not shared by evaluations of the model's free-form, generative answers. Until recently, there appeared to be no viable, scalable alternative to multiple choice--but, we show that this has changed. We consider generative evaluation via what we call answer matching: Give the candidate model the question without the options, have it generate a free-form response, then use a modern language model with the reference answer to determine if the response matches the reference. To compare the validity of different evaluation strategies, we annotate MMLU-Pro and GPQA-Diamond to obtain human grading data, and measure the agreement of each evaluation approach. We find answer matching using recent models--even small ones--achieves near-perfect agreement, in the range of inter-annotator agreement. In contrast, both multiple choice evaluation and using LLM-as-a-judge without reference answers aligns poorly with human grading. Improving evaluations via answer matching is not merely a conceptual concern: the rankings of several models change significantly when evaluating their free-form responses with answer matching. In light of these findings, we discuss how to move the evaluation ecosystem from multiple choice to answer matching.</li>
</ul>

<h3>Title: AnyI2V: Animating Any Conditional Image with Motion Control</h3>
<ul>
<li><strong>Authors: </strong>Ziye Li, Hao Luo, Xincheng Shuai, Henghui Ding</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02857">https://arxiv.org/abs/2507.02857</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02857">https://arxiv.org/pdf/2507.02857</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02857]] AnyI2V: Animating Any Conditional Image with Motion Control(https://arxiv.org/abs/2507.02857)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in video generation, particularly in diffusion models, have driven notable progress in text-to-video (T2V) and image-to-video (I2V) synthesis. However, challenges remain in effectively integrating dynamic motion signals and flexible spatial constraints. Existing T2V methods typically rely on text prompts, which inherently lack precise control over the spatial layout of generated content. In contrast, I2V methods are limited by their dependence on real images, which restricts the editability of the synthesized content. Although some methods incorporate ControlNet to introduce image-based conditioning, they often lack explicit motion control and require computationally expensive training. To address these limitations, we propose AnyI2V, a training-free framework that animates any conditional images with user-defined motion trajectories. AnyI2V supports a broader range of modalities as the conditional image, including data types such as meshes and point clouds that are not supported by ControlNet, enabling more flexible and versatile video generation. Additionally, it supports mixed conditional inputs and enables style transfer and editing via LoRA and text prompts. Extensive experiments demonstrate that the proposed AnyI2V achieves superior performance and provides a new perspective in spatial- and motion-controlled video generation. Code is available at this https URL.</li>
</ul>

<h3>Title: Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Jiaer Xia, Bingkui Tong, Yuhang Zang, Rui Shao, Kaiyang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02859">https://arxiv.org/abs/2507.02859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02859">https://arxiv.org/pdf/2507.02859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02859]] Bootstrapping Grounded Chain-of-Thought in Multimodal LLMs for Data-Efficient Model Adaptation(https://arxiv.org/abs/2507.02859)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in interpreting images using natural language. However, without using large-scale datasets for retraining, these models are difficult to adapt to specialized vision tasks, e.g., chart understanding. This problem is caused by a mismatch between pre-training and downstream datasets: pre-training datasets primarily concentrate on scenes and objects but contain limited information about specialized, non-object images, such as charts and tables. In this paper, we share an interesting finding that training an MLLM with Chain-of-Thought (CoT) reasoning data can facilitate model adaptation in specialized vision tasks, especially under data-limited regimes. However, we identify a critical issue within CoT data distilled from pre-trained MLLMs, i.e., the data often contains multiple factual errors in the reasoning steps. To address the problem, we propose Grounded Chain-of-Thought (GCoT), a simple bootstrapping-based approach that aims to inject grounding information (i.e., bounding boxes) into CoT data, essentially making the reasoning steps more faithful to input images. We evaluate our approach on five specialized vision tasks, which cover a variety of visual formats including charts, tables, receipts, and reports. The results demonstrate that under data-limited regimes our approach significantly improves upon fine-tuning and distillation.</li>
</ul>

<h3>Title: Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching</h3>
<ul>
<li><strong>Authors: </strong>Xin Zhou, Dingkang Liang, Kaijin Chen, Tianrui Feng, Xiwu Chen, Hongkai Lin, Yikang Ding, Feiyang Tan, Hengshuang Zhao, Xiang Bai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02860">https://arxiv.org/abs/2507.02860</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02860">https://arxiv.org/pdf/2507.02860</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02860]] Less is Enough: Training-Free Video Diffusion Acceleration via Runtime-Adaptive Caching(https://arxiv.org/abs/2507.02860)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Video generation models have demonstrated remarkable performance, yet their broader adoption remains constrained by slow inference speeds and substantial computational costs, primarily due to the iterative nature of the denoising process. Addressing this bottleneck is essential for democratizing advanced video synthesis technologies and enabling their integration into real-world applications. This work proposes EasyCache, a training-free acceleration framework for video diffusion models. EasyCache introduces a lightweight, runtime-adaptive caching mechanism that dynamically reuses previously computed transformation vectors, avoiding redundant computations during inference. Unlike prior approaches, EasyCache requires no offline profiling, pre-computation, or extensive parameter tuning. We conduct comprehensive studies on various large-scale video generation models, including OpenSora, Wan2.1, and HunyuanVideo. Our method achieves leading acceleration performance, reducing inference time by up to 2.1-3.3$\times$ compared to the original baselines while maintaining high visual fidelity with a significant up to 36% PSNR improvement compared to the previous SOTA method. This improvement makes our EasyCache a efficient and highly accessible solution for high-quality video generation in both research and practical applications. The code is available at this https URL.</li>
</ul>

<h3>Title: LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans</h3>
<ul>
<li><strong>Authors: </strong>Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nießner, Joan Lasenby</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2507.02861">https://arxiv.org/abs/2507.02861</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2507.02861">https://arxiv.org/pdf/2507.02861</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2507.02861]] LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans(https://arxiv.org/abs/2507.02861)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor environments into compact, realistic, and interactive 3D virtual replicas. LiteReality not only reconstructs scenes that visually resemble reality but also supports key features essential for graphics pipelines -- such as object individuality, articulation, high-quality physically based rendering materials, and physically based interaction. At its core, LiteReality first performs scene understanding and parses the results into a coherent 3D layout and objects with the help of a structured scene graph. It then reconstructs the scene by retrieving the most visually similar 3D artist-crafted models from a curated asset database. Next, the Material Painting module enhances realism by recovering high-quality, spatially varying materials. Finally, the reconstructed scene is integrated into a simulation engine with basic physical properties to enable interactive behavior. The resulting scenes are compact, editable, and fully compatible with standard graphics pipelines, making them suitable for applications in AR/VR, gaming, robotics, and digital twins. In addition, LiteReality introduces a training-free object retrieval module that achieves state-of-the-art similarity performance on the Scan2CAD benchmark, along with a robust material painting module capable of transferring appearances from images of any style to 3D assets -- even under severe misalignment, occlusion, and poor lighting. We demonstrate the effectiveness of LiteReality on both real-life scans and public datasets. Project page: this https URL; Video: this https URL</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
