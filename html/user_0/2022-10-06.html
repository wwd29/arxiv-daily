<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Bicoptor: Two-round Secure Three-party Non-linear Computation without Preprocessing for Privacy-preserving Machine Learning. (arXiv:2210.01988v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01988">http://arxiv.org/abs/2210.01988</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01988] Bicoptor: Two-round Secure Three-party Non-linear Computation without Preprocessing for Privacy-preserving Machine Learning](http://arxiv.org/abs/2210.01988)</code></li>
<li>Summary: <p>The overhead of non-linear functions dominates the performance of the secure
multiparty computation (MPC) based privacy-preserving machine learning (PPML).
This work introduces two sets of novel secure three-party computation (3PC)
protocols, using additive and replicated secret sharing schemes respectively.
We name the whole family of protocols as Bicoptor, its basis is a new sign
determination protocol, which relies on a clever use of the truncation protocol
proposed in SecureML (S&amp;P 2017). Our 3PC sign determination protocol only
requires two communication rounds, and does not involve any preprocessing. Such
sign determination protocol is well-suited for computing non-linear functions
in PPML, e.g. the activation function ReLU, Maxpool, and their variants. We
develop suitable protocols for these non-linear functions, which form a family
of GPU-friendly protocols, Bicoptor. All Bicoptor protocols only require two
communication rounds without preprocessing. We evaluate the protocols using
additive secret sharing under a 3-party LAN network over a public cloud, and
achieve 90,000 DReLU/ReLU or 3,200 Maxpool (find the maximum value of nine
inputs) operations per second. Under the same settings and environment, our
ReLU protocol has a one or even two order(s) of magnitude improvement to the
state-of-the-art works, Edabits (CRYPTO 2020) or Falcon (PETS 2021),
respectively without batch processing.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Hiding Images in Deep Probabilistic Models. (arXiv:2210.02257v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02257">http://arxiv.org/abs/2210.02257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02257] Hiding Images in Deep Probabilistic Models](http://arxiv.org/abs/2210.02257)</code></li>
<li>Summary: <p>Data hiding with deep neural networks (DNNs) has experienced impressive
successes in recent years. A prevailing scheme is to train an autoencoder,
consisting of an encoding network to embed (or transform) secret messages in
(or into) a carrier, and a decoding network to extract the hidden messages.
This scheme may suffer from several limitations regarding practicability,
security, and embedding capacity. In this work, we describe a different
computational framework to hide images in deep probabilistic models.
Specifically, we use a DNN to model the probability density of cover images,
and hide a secret image in one particular location of the learned distribution.
As an instantiation, we adopt a SinGAN, a pyramid of generative adversarial
networks (GANs), to learn the patch distribution of one cover image. We hide
the secret image by fitting a deterministic mapping from a fixed set of noise
maps (generated by an embedding key) to the secret image during patch
distribution learning. The stego SinGAN, behaving as the original SinGAN, is
publicly communicated; only the receiver with the embedding key is able to
extract the secret image. We demonstrate the feasibility of our SinGAN approach
in terms of extraction accuracy and model security. Moreover, we show the
flexibility of the proposed method in terms of hiding multiple images for
different receivers and obfuscating the secret image.
</p></li>
</ul>

<h3>Title: Security and Privacy Concerns in Cloud-based Scientific and Business Workflows: A Systematic Review. (arXiv:2210.02161v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02161">http://arxiv.org/abs/2210.02161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02161] Security and Privacy Concerns in Cloud-based Scientific and Business Workflows: A Systematic Review](http://arxiv.org/abs/2210.02161)</code></li>
<li>Summary: <p>Today, the number of data-intensive and compute-intensive applications like
business and scientific workflows has dramatically increased, which made cloud
computing more popular in the matter of delivering a large amount of computing
resources on demand. On the other hand, security is a critical issue affecting
the wide adoption of cloud technologies, especially for workflows that are
mostly dealing with sensitive data and tasks. In this paper, we carry out a
review of the state-of-the-art on how security and privacy concerns in
scientific and business workflows in cloud environments are being addressed and
identify the limitations and gaps in the current body of knowledge in this
area. In this extensive literature review, we first present a classification of
the state-of-the-art security solutions organized according to the phases of
the workflow life cycle they target. Based on our findings, we provide a
detailed review and classification of the most relevant available literature
focusing on the execution, monitoring, and adaptation phases of workflows.
Finally, we present a list of open research issues related to the security of
cloud-based workflows and discuss them.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy-Patterns for IoT Application Developers. (arXiv:2210.01853v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01853">http://arxiv.org/abs/2210.01853</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01853] Privacy-Patterns for IoT Application Developers](http://arxiv.org/abs/2210.01853)</code></li>
<li>Summary: <p>Designing Internet of things (IoT) applications (apps) is challenging due to
the heterogeneous nature of the systems on which these apps are deployed.
Personal data, often classified as sensitive, may be collected and analysed by
IoT apps, where data privacy laws are expected to protect such information.
Various approaches already exist to support privacy-by-design (PbD) schemes,
enabling developers to take data privacy into account at the design phase of
application development. However, developers are not widely adopting these
approaches because of understandability and interpretation challenges. A
limited number of tools currently exist to assist developers in this context --
leading to our proposal for "PARROT" (PrivAcy by design tool foR inteRnet Of
Things). PARROT supports a number of techniques to enable PbD techniques to be
more widely used. We present the findings of a controlled study and discuss how
this privacy-preserving tool increases the ability of IoT developers to apply
privacy laws (such as GDPR) and privacy patterns. Our students demonstrate that
the PARROT prototype tool increases the awareness of privacy requirements in
design and increases the likelihood of the subsequent design to be more
cognisant of data privacy requirements.
</p></li>
</ul>

<h3>Title: Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints. (arXiv:2210.01864v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01864">http://arxiv.org/abs/2210.01864</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01864] Recycling Scraps: Improving Private Learning by Leveraging Intermediate Checkpoints](http://arxiv.org/abs/2210.01864)</code></li>
<li>Summary: <p>All state-of-the-art (SOTA) differentially private machine learning (DP ML)
methods are iterative in nature, and their privacy analyses allow publicly
releasing the intermediate training checkpoints. However, DP ML benchmarks, and
even practical deployments, typically use only the final training checkpoint to
make predictions. In this work, for the first time, we comprehensively explore
various methods that aggregate intermediate checkpoints to improve the utility
of DP training. Empirically, we demonstrate that checkpoint aggregations
provide significant gains in the prediction accuracy over the existing SOTA for
CIFAR10 and StackOverflow datasets, and that these gains get magnified in
settings with periodically varying training data distributions. For instance,
we improve SOTA StackOverflow accuracies to 22.7% (+0.43% absolute) for
$\epsilon=8.2$, and 23.84% (+0.43%) for $\epsilon=18.9$. Theoretically, we show
that uniform tail averaging of checkpoints improves the empirical risk
minimization bound compared to the last checkpoint of DP-SGD. Lastly, we
initiate an exploration into estimating the uncertainty that DP noise adds in
the predictions of DP ML models. We prove that, under standard assumptions on
the loss function, the sample variance from last few checkpoints provides a
good approximation of the variance of the final model of a DP run. Empirically,
we show that the last few checkpoints can provide a reasonable lower bound for
the variance of a converged DP model.
</p></li>
</ul>

<h3>Title: Fine-Tuning with Differential Privacy Necessitates an Additional Hyperparameter Search. (arXiv:2210.02156v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02156">http://arxiv.org/abs/2210.02156</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02156] Fine-Tuning with Differential Privacy Necessitates an Additional Hyperparameter Search](http://arxiv.org/abs/2210.02156)</code></li>
<li>Summary: <p>Models need to be trained with privacy-preserving learning algorithms to
prevent leakage of possibly sensitive information contained in their training
data. However, canonical algorithms like differentially private stochastic
gradient descent (DP-SGD) do not benefit from model scale in the same way as
non-private learning. This manifests itself in the form of unappealing
tradeoffs between privacy and utility (accuracy) when using DP-SGD on complex
tasks. To remediate this tension, a paradigm is emerging: fine-tuning with
differential privacy from a model pretrained on public (i.e., non-sensitive)
training data.
</p></li>
</ul>

<p>In this work, we identify an oversight of existing approaches for
differentially private fine tuning. They do not tailor the fine-tuning approach
to the specifics of learning with privacy. Our main result is to show how
carefully selecting the layers being fine-tuned in the pretrained neural
network allows us to establish new state-of-the-art tradeoffs between privacy
and accuracy. For instance, we achieve 77.9% accuracy for $(\varepsilon,
\delta)=(2, 10^{-5})$ on CIFAR-100 for a model pretrained on ImageNet. Our work
calls for additional hyperparameter search to configure the differentially
private fine-tuning procedure itself.
</p>

<h3>Title: On the Statistical Complexity of Estimation and Testing under Privacy Constraints. (arXiv:2210.02215v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02215">http://arxiv.org/abs/2210.02215</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02215] On the Statistical Complexity of Estimation and Testing under Privacy Constraints](http://arxiv.org/abs/2210.02215)</code></li>
<li>Summary: <p>Producing statistics that respect the privacy of the samples while still
maintaining their accuracy is an important topic of research. We study minimax
lower bounds when the class of estimators is restricted to the differentially
private ones. In particular, we show that characterizing the power of a
distributional test under differential privacy can be done by solving a
transport problem. With specific coupling constructions, this observation
allows us to derivate Le Cam-type and Fano-type inequalities for both regular
definitions of differential privacy and for divergence-based ones (based on
Renyi divergence). We then proceed to illustrate our results on three simple,
fully worked out examples. In particular, we show that the problem class has a
huge importance on the provable degradation of utility due to privacy. For some
problems, privacy leads to a provable degradation only when the rate of the
privacy parameters is small enough whereas for other problem, the degradation
systematically occurs under much looser hypotheses on the privacy parametters.
Finally, we show that the known privacy guarantees of DP-SGLD, a private convex
solver, when used to perform maximum likelihood, leads to an algorithm that is
near-minimax optimal in both the sample size and the privacy tuning parameters
of the problem for a broad class of parametric estimation procedures that
includes exponential families.
</p></li>
</ul>

<h3>Title: Over-the-Air Federated Learning with Privacy Protection via Correlated Additive Perturbations. (arXiv:2210.02235v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02235">http://arxiv.org/abs/2210.02235</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02235] Over-the-Air Federated Learning with Privacy Protection via Correlated Additive Perturbations](http://arxiv.org/abs/2210.02235)</code></li>
<li>Summary: <p>In this paper, we consider privacy aspects of wireless federated learning
(FL) with Over-the-Air (OtA) transmission of gradient updates from multiple
users/agents to an edge server. By exploiting the waveform superposition
property of multiple access channels, OtA FL enables the users to transmit
their updates simultaneously with linear processing techniques, which improves
resource efficiency. However, this setting is vulnerable to privacy leakage
since an adversary node can hear directly the uncoded message. Traditional
perturbation-based methods provide privacy protection while sacrificing the
training accuracy due to the reduced signal-to-noise ratio. In this work, we
aim at minimizing privacy leakage to the adversary and the degradation of model
accuracy at the edge server at the same time. More explicitly, spatially
correlated perturbations are added to the gradient vectors at the users before
transmission. Using the zero-sum property of the correlated perturbations, the
side effect of the added perturbation on the aggregated gradients at the edge
server can be minimized. In the meanwhile, the added perturbation will not be
canceled out at the adversary, which prevents privacy leakage. Theoretical
analysis of the perturbation covariance matrix, differential privacy, and model
convergence is provided, based on which an optimization problem is formulated
to jointly design the covariance matrix and the power scaling factor to balance
between privacy protection and convergence performance. Simulation results
validate the correlated perturbation approach can provide strong defense
ability while guaranteeing high learning accuracy.
</p></li>
</ul>

<h3>Title: Differentially Private Propensity Scores for Bias Correction. (arXiv:2210.02360v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02360">http://arxiv.org/abs/2210.02360</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02360] Differentially Private Propensity Scores for Bias Correction](http://arxiv.org/abs/2210.02360)</code></li>
<li>Summary: <p>In surveys, it is typically up to the individuals to decide if they want to
participate or not, which leads to participation bias: the individuals willing
to share their data might not be representative of the entire population.
Similarly, there are cases where one does not have direct access to any data of
the target population and has to resort to publicly available proxy data
sampled from a different distribution. In this paper, we present Differentially
Private Propensity Scores for Bias Correction (DiPPS), a method for
approximating the true data distribution of interest in both of the above
settings. We assume that the data analyst has access to a dataset $\tilde{D}$
that was sampled from the distribution of interest in a biased way. As
individuals may be more willing to share their data when given a privacy
guarantee, we further assume that the analyst is allowed locally differentially
private access to a set of samples $D$ from the true, unbiased distribution.
Each data point from the private, unbiased dataset $D$ is mapped to a
probability distribution over clusters (learned from the biased dataset
$\tilde{D}$), from which a single cluster is sampled via the exponential
mechanism and shared with the data analyst. This way, the analyst gathers a
distribution over clusters, which they use to compute propensity scores for the
points in the biased $\tilde{D}$, which are in turn used to reweight the points
in $\tilde{D}$ to approximate the true data distribution. It is now possible to
compute any function on the resulting reweighted dataset without further access
to the private $D$. In experiments on datasets from various domains, we show
that DiPPS successfully brings the distribution of the available dataset closer
to the distribution of interest in terms of Wasserstein distance. We further
show that this results in improved estimates for different statistics.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses. (arXiv:2210.01940v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01940">http://arxiv.org/abs/2210.01940</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01940] On the Robustness of Deep Clustering Models: Adversarial Attacks and Defenses](http://arxiv.org/abs/2210.01940)</code></li>
<li>Summary: <p>Clustering models constitute a class of unsupervised machine learning methods
which are used in a number of application pipelines, and play a vital role in
modern data science. With recent advancements in deep learning -- deep
clustering models have emerged as the current state-of-the-art over traditional
clustering approaches, especially for high-dimensional image datasets. While
traditional clustering approaches have been analyzed from a robustness
perspective, no prior work has investigated adversarial attacks and robustness
for deep clustering models in a principled manner. To bridge this gap, we
propose a blackbox attack using Generative Adversarial Networks (GANs) where
the adversary does not know which deep clustering model is being used, but can
query it for outputs. We analyze our attack against multiple state-of-the-art
deep clustering models and real-world datasets, and find that it is highly
successful. We then employ some natural unsupervised defense approaches, but
find that these are unable to mitigate our attack. Finally, we attack Face++, a
production-level face clustering API service, and find that we can
significantly reduce its performance as well. Through this work, we thus aim to
motivate the need for truly robust deep clustering models.
</p></li>
</ul>

<h3>Title: Robust Fair Clustering: A Novel Fairness Attack and Defense Framework. (arXiv:2210.01953v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01953">http://arxiv.org/abs/2210.01953</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01953] Robust Fair Clustering: A Novel Fairness Attack and Defense Framework](http://arxiv.org/abs/2210.01953)</code></li>
<li>Summary: <p>Clustering algorithms are widely used in many societal resource allocation
applications, such as loan approvals and candidate recruitment, among others,
and hence, biased or unfair model outputs can adversely impact individuals that
rely on these applications. To this end, many fair clustering approaches have
been recently proposed to counteract this issue. Due to the potential for
significant harm, it is essential to ensure that fair clustering algorithms
provide consistently fair outputs even under adversarial influence. However,
fair clustering algorithms have not been studied from an adversarial attack
perspective. In contrast to previous research, we seek to bridge this gap and
conduct a robustness analysis against fair clustering by proposing a novel
black-box fairness attack. Through comprehensive experiments, we find that
state-of-the-art models are highly susceptible to our attack as it can reduce
their fairness performance significantly. Finally, we propose Consensus Fair
Clustering (CFC), the first robust fair clustering approach that transforms
consensus clustering into a fair graph partitioning problem, and iteratively
learns to generate fair cluster outputs. Experimentally, we observe that CFC is
highly robust to the proposed attack and is thus a truly robust fair clustering
alternative.
</p></li>
</ul>

<h3>Title: When Physical Layer Key Generation Meets RIS: Opportunities, Challenges, and Road Ahead. (arXiv:2210.02337v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02337">http://arxiv.org/abs/2210.02337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02337] When Physical Layer Key Generation Meets RIS: Opportunities, Challenges, and Road Ahead](http://arxiv.org/abs/2210.02337)</code></li>
<li>Summary: <p>Physical layer key generation (PLKG) is a promising technology to obtain
symmetric keys between a pair of wireless communication users in a
plug-and-play manner. The shared entropy source almost entirely comes from the
intrinsic randomness of the radio channel, which is highly dependent on the
wireless environment. However, in some static wireless environments, the
intrinsic randomness of wireless channel is hard to be guaranteed. Very
recently, thanks to reconfigurable intelligent surfaces (RISs) with their
excellent ability on electromagnetic wave control, the wireless channel
environment can be customized. In this article, we overview the RIS-aided PLKG
in a static indoor environment, including its potential application scenarios,
channel model and hardware architectures. Then, we analyze the design
challenges of RIS-aided PLKG, including channel reciprocity, RIS switch speed
and RIS deployment via proof-of-concept experiments on a RIS-aided PLKG
prototype system. In particular, our experimental results show that the key
generation rate is 15-fold higher than that without RIS in a static indoor
environment. Next, we design a RIS flip attack via a prototype experiment and
discuss its possible attack-defense countermeasures. Finally, several
conclusions and future directions are identified.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks. (arXiv:2210.02041v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02041">http://arxiv.org/abs/2210.02041</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02041] Natural Color Fool: Towards Boosting Black-box Unrestricted Attacks](http://arxiv.org/abs/2210.02041)</code></li>
<li>Summary: <p>Unrestricted color attacks, which manipulate semantically meaningful color of
an image, have shown their stealthiness and success in fooling both human eyes
and deep neural networks. However, current works usually sacrifice the
flexibility of the uncontrolled setting to ensure the naturalness of
adversarial examples. As a result, the black-box attack performance of these
methods is limited. To boost transferability of adversarial examples without
damaging image quality, we propose a novel Natural Color Fool (NCF) which is
guided by realistic color distributions sampled from a publicly available
dataset and optimized by our neighborhood search and initialization reset. By
conducting extensive experiments and visualizations, we convincingly
demonstrate the effectiveness of our proposed method. Notably, on average,
results show that our NCF can outperform state-of-the-art approaches by
15.0%$\sim$32.9% for fooling normally trained models and 10.0%$\sim$25.3% for
evading defense methods. Our code is available at
https://github.com/ylhz/Natural-Color-Fool.
</p></li>
</ul>

<h3>Title: Jitter Does Matter: Adapting Gaze Estimation to New Domains. (arXiv:2210.02082v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02082">http://arxiv.org/abs/2210.02082</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02082] Jitter Does Matter: Adapting Gaze Estimation to New Domains](http://arxiv.org/abs/2210.02082)</code></li>
<li>Summary: <p>Deep neural networks have demonstrated superior performance on
appearance-based gaze estimation tasks. However, due to variations in person,
illuminations, and background, performance degrades dramatically when applying
the model to a new domain. In this paper, we discover an interesting gaze
jitter phenomenon in cross-domain gaze estimation, i.e., the gaze predictions
of two similar images can be severely deviated in target domain. This is
closely related to cross-domain gaze estimation tasks, but surprisingly, it has
not been noticed yet previously. Therefore, we innovatively propose to utilize
the gaze jitter to analyze and optimize the gaze domain adaptation task. We
find that the high-frequency component (HFC) is an important factor that leads
to jitter. Based on this discovery, we add high-frequency components to input
images using the adversarial attack and employ contrastive learning to
encourage the model to obtain similar representations between original and
perturbed data, which reduces the impacts of HFC. We evaluate the proposed
method on four cross-domain gaze estimation tasks, and experimental results
demonstrate that it significantly reduces the gaze jitter and improves the gaze
estimation performance in target domains.
</p></li>
</ul>

<h3>Title: On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks. (arXiv:2210.02191v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02191">http://arxiv.org/abs/2210.02191</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02191] On Attacking Out-Domain Uncertainty Estimation in Deep Neural Networks](http://arxiv.org/abs/2210.02191)</code></li>
<li>Summary: <p>In many applications with real-world consequences, it is crucial to develop
reliable uncertainty estimation for the predictions made by the AI decision
systems. Targeting at the goal of estimating uncertainty, various deep neural
network (DNN) based uncertainty estimation algorithms have been proposed.
However, the robustness of the uncertainty returned by these algorithms has not
been systematically explored. In this work, to raise the awareness of the
research community on robust uncertainty estimation, we show that
state-of-the-art uncertainty estimation algorithms could fail catastrophically
under our proposed adversarial attack despite their impressive performance on
uncertainty estimation. In particular, we aim at attacking the out-domain
uncertainty estimation: under our attack, the uncertainty model would be fooled
to make high-confident predictions for the out-domain data, which they
originally would have rejected. Extensive experimental results on various
benchmark image datasets show that the uncertainty estimated by
state-of-the-art methods could be easily corrupted by our attack.
</p></li>
</ul>

<h3>Title: Invariant Aggregator for Defending Federated Backdoor Attacks. (arXiv:2210.01834v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01834">http://arxiv.org/abs/2210.01834</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01834] Invariant Aggregator for Defending Federated Backdoor Attacks](http://arxiv.org/abs/2210.01834)</code></li>
<li>Summary: <p>Federated learning is gaining popularity as it enables training of
high-utility models across several clients without directly sharing their
private data. As a downside, the federated setting makes the model vulnerable
to various adversarial attacks in the presence of malicious clients.
Specifically, an adversary can perform backdoor attacks to control model
predictions via poisoning the training dataset with a trigger. In this work, we
propose a mitigation for backdoor attacks in a federated learning setup. Our
solution forces the model optimization trajectory to focus on the invariant
directions that are generally useful for utility and avoid selecting directions
that favor few and possibly malicious clients. Concretely, we consider the sign
consistency of the pseudo-gradient (the client update) as an estimation of the
invariance. Following this, our approach performs dimension-wise filtering to
remove pseudo-gradient elements with low sign consistency. Then, a robust mean
estimator eliminates outliers among the remaining dimensions. Our theoretical
analysis further shows the necessity of the defense combination and illustrates
how our proposed solution defends the federated learning model. Empirical
results on three datasets with different modalities and varying number of
clients show that our approach mitigates backdoor attacks with a negligible
cost on the model utility.
</p></li>
</ul>

<h3>Title: Thermal (and Hybrid Thermal/Audio) Side-Channel Attacks on Keyboard Input. (arXiv:2210.02234v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02234">http://arxiv.org/abs/2210.02234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02234] Thermal (and Hybrid Thermal/Audio) Side-Channel Attacks on Keyboard Input](http://arxiv.org/abs/2210.02234)</code></li>
<li>Summary: <p>To date, there has been no systematic investigation of thermal profiles of
keyboards, and thus no efforts have been made to secure them. This serves as
our main motivation for constructing a means for password harvesting from
keyboard thermal emanations. Specifically, we introduce Thermanator: a new
post-factum insider attack based on heat transfer caused by a user typing a
password on a typical external (plastic) keyboard.
</p></li>
</ul>

<p>We conduct and describe a user study that collected thermal residues from 30
users entering 10 unique passwords (both weak and strong) on 4 popular
commodity keyboards. Results show that entire sets of key-presses can be
recovered by non-expert users as late as 30 seconds after initial password
entry, while partial sets can be recovered as late as 1 minute after entry.
However, the thermal residue side-channel lacks information about password
length, duplicate key-presses, and key-press ordering. To overcome these
limitations, we leverage keyboard acoustic emanations and combine the two to
yield AcuTherm, the first hybrid side-channel attack on keyboards. AcuTherm
significantly reduces password search without the need for any training on the
victim's typing. We report results gathered for many representative passwords
based on a user study involving 19 subjects.
</p>
<p>The takeaway of this work is three-fold: (1) using plastic keyboards to enter
secrets (such as passwords and PINs) is even less secure than previously
recognized, (2) post-factum thermal imaging attacks are realistic, and (3)
hybrid (multiple side-channel) attacks are both realistic and effective.
</p>

<h3>Title: Detecting Anomalies within Smart Buildings using Do-It-Yourself Internet of Things. (arXiv:2210.01840v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01840">http://arxiv.org/abs/2210.01840</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01840] Detecting Anomalies within Smart Buildings using Do-It-Yourself Internet of Things](http://arxiv.org/abs/2210.01840)</code></li>
<li>Summary: <p>Detecting anomalies at the time of happening is vital in environments like
buildings and homes to identify potential cyber-attacks. This paper discussed
the various mechanisms to detect anomalies as soon as they occur. We shed light
on crucial considerations when building machine learning models. We constructed
and gathered data from multiple self-build (DIY) IoT devices with different
in-situ sensors and found effective ways to find the point, contextual and
combine anomalies. We also discussed several challenges and potential solutions
when dealing with sensing devices that produce data at different sampling rates
and how we need to pre-process them in machine learning models. This paper also
looks at the pros and cons of extracting sub-datasets based on environmental
conditions.
</p></li>
</ul>

<h3>Title: Dynamical systems' based neural networks. (arXiv:2210.02373v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02373">http://arxiv.org/abs/2210.02373</a></li>
<li>Code URL: <a href="https://github.com/davidemurari/structuredneuralnetworks">https://github.com/davidemurari/structuredneuralnetworks</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02373] Dynamical systems' based neural networks](http://arxiv.org/abs/2210.02373)</code></li>
<li>Summary: <p>Neural networks have gained much interest because of their effectiveness in
many applications. However, their mathematical properties are generally not
well understood. If there is some underlying geometric structure inherent to
the data or to the function to approximate, it is often desirable to take this
into account in the design of the neural network. In this work, we start with a
non-autonomous ODE and build neural networks using a suitable,
structure-preserving, numerical time-discretisation. The structure of the
neural network is then inferred from the properties of the ODE vector field.
Besides injecting more structure into the network architectures, this modelling
procedure allows a better theoretical understanding of their behaviour. We
present two universal approximation results and demonstrate how to impose some
particular properties on the neural networks. A particular focus is on
1-Lipschitz architectures including layers that are not 1-Lipschitz. These
networks are expressive and robust against adversarial attacks, as shown for
the CIFAR-10 dataset.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: AdaWAC: Adaptively Weighted Augmentation Consistency Regularization for Volumetric Medical Image Segmentation. (arXiv:2210.01891v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01891">http://arxiv.org/abs/2210.01891</a></li>
<li>Code URL: <a href="https://github.com/gail-yxie/adawac">https://github.com/gail-yxie/adawac</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01891] AdaWAC: Adaptively Weighted Augmentation Consistency Regularization for Volumetric Medical Image Segmentation](http://arxiv.org/abs/2210.01891)</code></li>
<li>Summary: <p>Sample reweighting is an effective strategy for learning from training data
coming from a mixture of subpopulations. In volumetric medical image
segmentation, the data inputs are similarly distributed, but the associated
data labels fall into two subpopulations -- "label-sparse" and "label-dense" --
depending on whether the data image occurs near the beginning/end of the
volumetric scan or the middle. Existing reweighting algorithms have focused on
hard- and soft- thresholding of the label-sparse data, which results in loss of
information and reduced sample efficiency by discarding valuable data input.
For this setting, we propose AdaWAC as an adaptive weighting algorithm that
introduces a set of trainable weights which, at the saddle point of the
underlying objective, assigns label-dense samples to supervised cross-entropy
loss and label-sparse samples to unsupervised consistency regularization. We
provide a convergence guarantee for AdaWAC by recasting the optimization as
online mirror descent on a saddle point problem. Moreover, we empirically
demonstrate that AdaWAC not only enhances segmentation performance and sample
efficiency but also improves robustness to the subpopulation shift in labels.
</p></li>
</ul>

<h3>Title: Meta-Ensemble Parameter Learning. (arXiv:2210.01973v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01973">http://arxiv.org/abs/2210.01973</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01973] Meta-Ensemble Parameter Learning](http://arxiv.org/abs/2210.01973)</code></li>
<li>Summary: <p>Ensemble of machine learning models yields improved performance as well as
robustness. However, their memory requirements and inference costs can be
prohibitively high. Knowledge distillation is an approach that allows a single
model to efficiently capture the approximate performance of an ensemble while
showing poor scalability as demand for re-training when introducing new teacher
models. In this paper, we study if we can utilize the meta-learning strategy to
directly predict the parameters of a single model with comparable performance
of an ensemble. Hereto, we introduce WeightFormer, a Transformer-based model
that can predict student network weights layer by layer in a forward pass,
according to the teacher model parameters. The proprieties of WeightFormer are
investigated on the CIFAR-10, CIFAR-100, and ImageNet datasets for model
structures of VGGNet-11, ResNet-50, and ViT-B/32, where it demonstrates that
our method can achieve approximate classification performance of an ensemble
and outperforms both the single network and standard knowledge distillation.
More encouragingly, we show that WeightFormer results can further exceeds
average ensemble with minor fine-tuning. Importantly, our task along with the
model and results can potentially lead to a new, more efficient, and scalable
paradigm of ensemble networks parameter learning.
</p></li>
</ul>

<h3>Title: MOTSLAM: MOT-assisted monocular dynamic SLAM using single-view depth estimation. (arXiv:2210.02038v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02038">http://arxiv.org/abs/2210.02038</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02038] MOTSLAM: MOT-assisted monocular dynamic SLAM using single-view depth estimation](http://arxiv.org/abs/2210.02038)</code></li>
<li>Summary: <p>Visual SLAM systems targeting static scenes have been developed with
satisfactory accuracy and robustness. Dynamic 3D object tracking has then
become a significant capability in visual SLAM with the requirement of
understanding dynamic surroundings in various scenarios including autonomous
driving, augmented and virtual reality. However, performing dynamic SLAM solely
with monocular images remains a challenging problem due to the difficulty of
associating dynamic features and estimating their positions. In this paper, we
present MOTSLAM, a dynamic visual SLAM system with the monocular configuration
that tracks both poses and bounding boxes of dynamic objects. MOTSLAM first
performs multiple object tracking (MOT) with associated both 2D and 3D bounding
box detection to create initial 3D objects. Then, neural-network-based
monocular depth estimation is applied to fetch the depth of dynamic features.
Finally, camera poses, object poses, and both static, as well as dynamic map
points, are jointly optimized using a novel bundle adjustment. Our experiments
on the KITTI dataset demonstrate that our system has reached best performance
on both camera ego-motion and object tracking on monocular dynamic SLAM.
</p></li>
</ul>

<h3>Title: Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders. (arXiv:2210.02077v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02077">http://arxiv.org/abs/2210.02077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02077] Exploring The Role of Mean Teachers in Self-supervised Masked Auto-Encoders](http://arxiv.org/abs/2210.02077)</code></li>
<li>Summary: <p>Masked image modeling (MIM) has become a popular strategy for self-supervised
learning~(SSL) of visual representations with Vision Transformers. A
representative MIM model, the masked auto-encoder (MAE), randomly masks a
subset of image patches and reconstructs the masked patches given the unmasked
patches. Concurrently, many recent works in self-supervised learning utilize
the student/teacher paradigm which provides the student with an additional
target based on the output of a teacher composed of an exponential moving
average (EMA) of previous students. Although common, relatively little is known
about the dynamics of the interaction between the student and teacher. Through
analysis on a simple linear model, we find that the teacher conditionally
removes previous gradient directions based on feature similarities which
effectively acts as a conditional momentum regularizer. From this analysis, we
present a simple SSL method, the Reconstruction-Consistent Masked Auto-Encoder
(RC-MAE) by adding an EMA teacher to MAE. We find that RC-MAE converges faster
and requires less memory usage than state-of-the-art self-distillation methods
during pre-training, which may provide a way to enhance the practicality of
prohibitively expensive self-supervised learning of Vision Transformer models.
Additionally, we show that RC-MAE achieves more robustness and better
performance compared to MAE on downstream tasks such as ImageNet-1K
classification, object detection, and instance segmentation.
</p></li>
</ul>

<h3>Title: Decanus to Legatus: Synthetic training for 2D-3D human pose lifting. (arXiv:2210.02231v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02231">http://arxiv.org/abs/2210.02231</a></li>
<li>Code URL: <a href="https://github.com/zhuyue0324/decanus-to-legatus">https://github.com/zhuyue0324/decanus-to-legatus</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02231] Decanus to Legatus: Synthetic training for 2D-3D human pose lifting](http://arxiv.org/abs/2210.02231)</code></li>
<li>Summary: <p>3D human pose estimation is a challenging task because of the difficulty to
acquire ground-truth data outside of controlled environments. A number of
further issues have been hindering progress in building a universal and robust
model for this task, including domain gaps between different datasets, unseen
actions between train and test datasets, various hardware settings and high
cost of annotation, etc. In this paper, we propose an algorithm to generate
infinite 3D synthetic human poses (Legatus) from a 3D pose distribution based
on 10 initial handcrafted 3D poses (Decanus) during the training of a 2D to 3D
human pose lifter neural network. Our results show that we can achieve 3D pose
estimation performance comparable to methods using real data from specialized
datasets but in a zero-shot setup, showing the generalization potential of our
framework.
</p></li>
</ul>

<h3>Title: Image Masking for Robust Self-Supervised Monocular Depth Estimation. (arXiv:2210.02357v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02357">http://arxiv.org/abs/2210.02357</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02357] Image Masking for Robust Self-Supervised Monocular Depth Estimation](http://arxiv.org/abs/2210.02357)</code></li>
<li>Summary: <p>Self-supervised monocular depth estimation is a salient task for 3D scene
understanding. Learned jointly with monocular ego-motion estimation, several
methods have been proposed to predict accurate pixel-wise depth without using
labeled data. Nevertheless, these methods focus on improving performance under
ideal conditions without natural or digital corruptions. A general absence of
occlusions is assumed even for object-specific depth estimation. These methods
are also vulnerable to adversarial attacks, which is a pertinent concern for
their reliable deployment on robots and autonomous driving systems. We propose
MIMDepth, a method that adapts masked image modeling (MIM) for self-supervised
monocular depth estimation. While MIM has been used to learn generalizable
features during pre-training, we show how it could be adapted for direct
training of monocular depth estimation. Our experiments show that MIMDepth is
more robust to noise, blur, weather conditions, digital artifacts, occlusions,
as well as untargeted and targeted adversarial attacks.
</p></li>
</ul>

<h3>Title: COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge and Inheritance in Pre-trained Language Models. (arXiv:2210.01963v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01963">http://arxiv.org/abs/2210.01963</a></li>
<li>Code URL: <a href="https://github.com/kanishkamisra/comps">https://github.com/kanishkamisra/comps</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01963] COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge and Inheritance in Pre-trained Language Models](http://arxiv.org/abs/2210.01963)</code></li>
<li>Summary: <p>A characteristic feature of human semantic memory is its ability to not only
store and retrieve the properties of concepts observed through experience, but
to also facilitate the inheritance of properties (can breathe) from
superordinate concepts (animal) to their subordinates (dog) -- i.e. demonstrate
property inheritance. In this paper, we present COMPS, a collection of minimal
pair sentences that jointly tests pre-trained language models (PLMs) on their
ability to attribute properties to concepts and their ability to demonstrate
property inheritance behavior. Analyses of 22 different PLMs on COMPS reveal
that they can easily distinguish between concepts on the basis of a property
when they are trivially different, but find it relatively difficult when
concepts are related on the basis of nuanced knowledge representations.
Furthermore, we find that PLMs can demonstrate behavior consistent with
property inheritance to a great extent, but fail in the presence of distracting
information, which decreases the performance of many models, sometimes even
below chance. This lack of robustness in demonstrating simple reasoning raises
important questions about PLMs' capacity to make correct inferences even when
they appear to possess the prerequisite knowledge.
</p></li>
</ul>

<h3>Title: BayesFT: Bayesian Optimization for Fault Tolerant Neural Network Architecture. (arXiv:2210.01795v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01795">http://arxiv.org/abs/2210.01795</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01795] BayesFT: Bayesian Optimization for Fault Tolerant Neural Network Architecture](http://arxiv.org/abs/2210.01795)</code></li>
<li>Summary: <p>To deploy deep learning algorithms on resource-limited scenarios, an emerging
device-resistive random access memory (ReRAM) has been regarded as promising
via analog computing. However, the practicability of ReRAM is primarily limited
due to the weight drifting of ReRAM neural networks due to multi-factor
reasons, including manufacturing, thermal noises, and etc. In this paper, we
propose a novel Bayesian optimization method for fault tolerant neural network
architecture (BayesFT). For neural architecture search space design, instead of
conducting neural architecture search on the whole feasible neural architecture
search space, we first systematically explore the weight drifting tolerance of
different neural network components, such as dropout, normalization, number of
layers, and activation functions in which dropout is found to be able to
improve the neural network robustness to weight drifting. Based on our
analysis, we propose an efficient search space by only searching for dropout
rates for each layer. Then, we use Bayesian optimization to search for the
optimal neural architecture robust to weight drifting. Empirical experiments
demonstrate that our algorithmic framework has outperformed the
state-of-the-art methods by up to 10 times on various tasks, such as image
classification and object detection.
</p></li>
</ul>

<h3>Title: Neural Distillation as a State Representation Bottleneck in Reinforcement Learning. (arXiv:2210.02224v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02224">http://arxiv.org/abs/2210.02224</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02224] Neural Distillation as a State Representation Bottleneck in Reinforcement Learning](http://arxiv.org/abs/2210.02224)</code></li>
<li>Summary: <p>Learning a good state representation is a critical skill when dealing with
multiple tasks in Reinforcement Learning as it allows for transfer and better
generalization between tasks. However, defining what constitute a useful
representation is far from simple and there is so far no standard method to
find such an encoding. In this paper, we argue that distillation -- a process
that aims at imitating a set of given policies with a single neural network --
can be used to learn a state representation displaying favorable
characteristics. In this regard, we define three criteria that measure
desirable features of a state encoding: the ability to select important
variables in the input space, the ability to efficiently separate states
according to their corresponding optimal action, and the robustness of the
state encoding on new tasks. We first evaluate these criteria and verify the
contribution of distillation on state representation on a toy environment based
on the standard inverted pendulum problem, before extending our analysis on
more complex visual tasks from the Atari and Procgen benchmarks.
</p></li>
</ul>

<h3>Title: Tree Mover's Distance: Bridging Graph Metrics and Stability of Graph Neural Networks. (arXiv:2210.01906v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01906">http://arxiv.org/abs/2210.01906</a></li>
<li>Code URL: <a href="https://github.com/chingyaoc/tmd">https://github.com/chingyaoc/tmd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01906] Tree Mover's Distance: Bridging Graph Metrics and Stability of Graph Neural Networks](http://arxiv.org/abs/2210.01906)</code></li>
<li>Summary: <p>Understanding generalization and robustness of machine learning models
fundamentally relies on assuming an appropriate metric on the data space.
Identifying such a metric is particularly challenging for non-Euclidean data
such as graphs. Here, we propose a pseudometric for attributed graphs, the Tree
Mover's Distance (TMD), and study its relation to generalization. Via a
hierarchical optimal transport problem, TMD reflects the local distribution of
node attributes as well as the distribution of local computation trees, which
are known to be decisive for the learning behavior of graph neural networks
(GNNs). First, we show that TMD captures properties relevant to graph
classification: a simple TMD-SVM performs competitively with standard GNNs.
Second, we relate TMD to generalization of GNNs under distribution shifts, and
show that it correlates well with performance drop under such shifts.
</p></li>
</ul>

<h3>Title: MAtt: A Manifold Attention Network for EEG Decoding. (arXiv:2210.01986v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01986">http://arxiv.org/abs/2210.01986</a></li>
<li>Code URL: <a href="https://github.com/cecnl/matt">https://github.com/cecnl/matt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01986] MAtt: A Manifold Attention Network for EEG Decoding](http://arxiv.org/abs/2210.01986)</code></li>
<li>Summary: <p>Recognition of electroencephalographic (EEG) signals highly affect the
efficiency of non-invasive brain-computer interfaces (BCIs). While recent
advances of deep-learning (DL)-based EEG decoders offer improved performances,
the development of geometric learning (GL) has attracted much attention for
offering exceptional robustness in decoding noisy EEG data. However, there is a
lack of studies on the merged use of deep neural networks (DNNs) and geometric
learning for EEG decoding. We herein propose a manifold attention network
(mAtt), a novel geometric deep learning (GDL)-based model, featuring a manifold
attention mechanism that characterizes spatiotemporal representations of EEG
data fully on a Riemannian symmetric positive definite (SPD) manifold. The
evaluation of the proposed MAtt on both time-synchronous and -asyncronous EEG
datasets suggests its superiority over other leading DL methods for general EEG
decoding. Furthermore, analysis of model interpretation reveals the capability
of MAtt in capturing informative EEG features and handling the non-stationarity
of brain dynamics.
</p></li>
</ul>

<h3>Title: ChemAlgebra: Algebraic Reasoning on Chemical Reactions. (arXiv:2210.02095v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02095">http://arxiv.org/abs/2210.02095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02095] ChemAlgebra: Algebraic Reasoning on Chemical Reactions](http://arxiv.org/abs/2210.02095)</code></li>
<li>Summary: <p>While showing impressive performance on various kinds of learning tasks, it
is yet unclear whether deep learning models have the ability to robustly tackle
reasoning tasks. than by learning the underlying reasoning process that is
actually required to solve the tasks. Measuring the robustness of reasoning in
machine learning models is challenging as one needs to provide a task that
cannot be easily shortcut by exploiting spurious statistical correlations in
the data, while operating on complex objects and constraints. reasoning task.
To address this issue, we propose ChemAlgebra, a benchmark for measuring the
reasoning capabilities of deep learning models through the prediction of
stoichiometrically-balanced chemical reactions. ChemAlgebra requires
manipulating sets of complex discrete objects -- molecules represented as
formulas or graphs -- under algebraic constraints such as the mass preservation
principle. We believe that ChemAlgebra can serve as a useful test bed for the
next generation of machine reasoning models and as a promoter of their
development.
</p></li>
</ul>

<h3>Title: SECOE: Alleviating Sensors Failure in Machine Learning-Coupled IoT Systems. (arXiv:2210.02144v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02144">http://arxiv.org/abs/2210.02144</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02144] SECOE: Alleviating Sensors Failure in Machine Learning-Coupled IoT Systems](http://arxiv.org/abs/2210.02144)</code></li>
<li>Summary: <p>Machine learning (ML) applications continue to revolutionize many domains. In
recent years, there has been considerable research interest in building novel
ML applications for a variety of Internet of Things (IoT) domains, such as
precision agriculture, smart cities, and smart manufacturing. IoT domains are
characterized by continuous streams of data originating from diverse,
geographically distributed sensors, and they often require a real-time or
semi-real-time response. IoT characteristics pose several fundamental
challenges to designing and implementing effective ML applications.
Sensor/network failures that result in data stream interruptions is one such
challenge. Unfortunately, the performance of many ML applications quickly
degrades when faced with data incompleteness. Current techniques to handle data
incompleteness are based upon data imputation ( i.e., they try to fill-in
missing data). Unfortunately, these techniques may fail, especially when
multiple sensors' data streams become concurrently unavailable (due to
simultaneous sensor failures). With the aim of building robust IoT-coupled ML
applications, this paper proposes SECOE, a unique, proactive approach for
alleviating potentially simultaneous sensor failures. The fundamental idea
behind SECOE is to create a carefully chosen ensemble of ML models in which
each model is trained assuming a set of failed sensors (i.e., the training set
omits corresponding values). SECOE includes a novel technique to minimize the
number of models in the ensemble by harnessing the correlations among sensors.
We demonstrate the efficacy of the SECOE approach through a series of
experiments involving three distinct datasets. The experimental findings reveal
that SECOE effectively preserves prediction accuracy in the presence of sensor
failures.
</p></li>
</ul>

<h3>Title: Bayesian Quadrature for Probability Threshold Robustness of Partially Undefined Functions. (arXiv:2210.02168v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02168">http://arxiv.org/abs/2210.02168</a></li>
<li>Code URL: <a href="https://github.com/fiveai/hgp_experiments">https://github.com/fiveai/hgp_experiments</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02168] Bayesian Quadrature for Probability Threshold Robustness of Partially Undefined Functions](http://arxiv.org/abs/2210.02168)</code></li>
<li>Summary: <p>In engineering design, one often wishes to calculate the probability that the
performance of a system is satisfactory under uncertainty. State of the art
algorithms exist to solve this problem using active learning with Gaussian
process models. However, these algorithms cannot be applied to problems which
often occur in the autonomous vehicle domain where the performance of a system
may be undefined under certain circumstances. Na\"ive modification of existing
algorithms by simply masking undefined values will introduce a discontinuous
system performance function, and would be unsuccessful because these algorithms
are known to fail for discontinuous performance functions. We solve this
problem using a hierarchical model for the system performance, where undefined
performance is classified before the performance is regressed. This enables
active learning Gaussian process methods to be applied to problems where the
performance of the system is sometimes undefined, and we demonstrate this by
testing our methodology on synthetic numerical examples for the autonomous
driving domain.
</p></li>
</ul>

<h3>Title: A new family of Constitutive Artificial Neural Networks towards automated model discovery. (arXiv:2210.02202v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02202">http://arxiv.org/abs/2210.02202</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02202] A new family of Constitutive Artificial Neural Networks towards automated model discovery](http://arxiv.org/abs/2210.02202)</code></li>
<li>Summary: <p>For more than 100 years, chemical, physical, and material scientists have
proposed competing constitutive models to best characterize the behavior of
natural and man-made materials in response to mechanical loading. Now, computer
science offers a universal solution: Neural Networks. Neural Networks are
powerful function approximators that can learn constitutive relations from
large data without any knowledge of the underlying physics. However, classical
Neural Networks entirely ignore a century of research in constitutive modeling,
violate thermodynamic considerations, and fail to predict the behavior outside
the training regime. Here we design a new family of Constitutive Artificial
Neural Networks that inherently satisfy common kinematic, thermodynamic, and
physic constraints and, at the same time, constrain the design space of
admissible functions to create robust approximators, even in the presence of
sparse data. Towards this goal we revisit the non-linear field theories of
mechanics and reverse-engineer the network input to account for material
objectivity, symmetry, and incompressibility; the network output to enforce
thermodynamic consistency; the activation functions to implement physically
reasonable restrictions; and the network architecture to ensure polyconvexity.
We demonstrate that this new class of models is a generalization of the
classical neo Hooke, Blatz Ko, Mooney Rivlin, Yeoh, and Demiray models and that
the network weights have a clear physical interpretation. When trained with
classical benchmark data for rubber under uniaxial tension, biaxial extension,
and pure shear, our network autonomously selects the best constitutive model
and learns its set of parameters. Our findings suggests that Constitutive
Artificial Neural Networks have the potential to induce a paradigm shift in
constitutive modeling, from user-defined model selection to automated model
discovery.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Point Cloud Recognition with Position-to-Structure Attention Transformers. (arXiv:2210.02030v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02030">http://arxiv.org/abs/2210.02030</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02030] Point Cloud Recognition with Position-to-Structure Attention Transformers](http://arxiv.org/abs/2210.02030)</code></li>
<li>Summary: <p>In this paper, we present Position-to-Structure Attention Transformers
(PS-Former), a Transformer-based algorithm for 3D point cloud recognition.
PS-Former deals with the challenge in 3D point cloud representation where
points are not positioned in a fixed grid structure and have limited feature
description (only 3D coordinates ($x, y, z$) for scattered points). Existing
Transformer-based architectures in this domain often require a pre-specified
feature engineering step to extract point features. Here, we introduce two new
aspects in PS-Former: 1) a learnable condensation layer that performs point
downsampling and feature extraction; and 2) a Position-to-Structure Attention
mechanism that recursively enriches the structural information with the
position attention branch. Compared with the competing methods, while being
generic with less heuristics feature designs, PS-Former demonstrates
competitive experimental results on three 3D point cloud tasks including
classification, part segmentation, and scene segmentation.
</p></li>
</ul>

<h3>Title: Spatio-Temporal Learnable Proposals for End-to-End Video Object Detection. (arXiv:2210.02368v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02368">http://arxiv.org/abs/2210.02368</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02368] Spatio-Temporal Learnable Proposals for End-to-End Video Object Detection](http://arxiv.org/abs/2210.02368)</code></li>
<li>Summary: <p>This paper presents the novel idea of generating object proposals by
leveraging temporal information for video object detection. The feature
aggregation in modern region-based video object detectors heavily relies on
learned proposals generated from a single-frame RPN. This imminently introduces
additional components like NMS and produces unreliable proposals on low-quality
frames. To tackle these restrictions, we present SparseVOD, a novel video
object detection pipeline that employs Sparse R-CNN to exploit temporal
information. In particular, we introduce two modules in the dynamic head of
Sparse R-CNN. First, the Temporal Feature Extraction module based on the
Temporal RoI Align operation is added to extract the RoI proposal features.
Second, motivated by sequence-level semantic aggregation, we incorporate the
attention-guided Semantic Proposal Feature Aggregation module to enhance object
feature representation before detection. The proposed SparseVOD effectively
alleviates the overhead of complicated post-processing methods and makes the
overall pipeline end-to-end trainable. Extensive experiments show that our
method significantly improves the single-frame Sparse RCNN by 8%-9% in mAP.
Furthermore, besides achieving state-of-the-art 80.3% mAP on the ImageNet VID
dataset with ResNet-50 backbone, our SparseVOD outperforms existing
proposal-based methods by a significant margin on increasing IoU thresholds
(IoU > 0.5).
</p></li>
</ul>

<h3>Title: Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot Document-Level Question Answering. (arXiv:2210.01959v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01959">http://arxiv.org/abs/2210.01959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01959] Detect, Retrieve, Comprehend: A Flexible Framework for Zero-Shot Document-Level Question Answering](http://arxiv.org/abs/2210.01959)</code></li>
<li>Summary: <p>Businesses generate thousands of documents that communicate their strategic
vision and provide details of key products, services, entities, and processes.
Knowledge workers then face the laborious task of reading these documents to
identify, extract, and synthesize information relevant to their organizational
goals. To automate information gathering, question answering (QA) offers a
flexible framework where human-posed questions can be adapted to extract
diverse knowledge. Finetuning QA systems requires access to labeled data
(tuples of context, question, and answer). However, data curation for document
QA is uniquely challenging because the context (i.e., answer evidence passage)
needs to be retrieved from potentially long, ill-formatted documents. Existing
QA datasets sidestep this challenge by providing short, well-defined contexts
that are unrealistic in real-world applications. We present a three-stage
document QA approach: (1) text extraction from PDF; (2) evidence retrieval from
extracted texts to form well-posed contexts; (3) QA to extract knowledge from
contexts to return high-quality answers - extractive, abstractive, or Boolean.
Using QASPER as a surrogate to our proprietary data, our
detect-retrieve-comprehend (DRC) system achieves a +6.25 improvement in
Answer-F1 over existing baselines while delivering superior context selection.
Our results demonstrate that DRC holds tremendous promise as a flexible
framework for practical document QA.
</p></li>
</ul>

<h3>Title: STGIN: A Spatial Temporal Graph-Informer Network for Long Sequence Traffic Speed Forecasting. (arXiv:2210.01799v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01799">http://arxiv.org/abs/2210.01799</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01799] STGIN: A Spatial Temporal Graph-Informer Network for Long Sequence Traffic Speed Forecasting](http://arxiv.org/abs/2210.01799)</code></li>
<li>Summary: <p>Accurate long series forecasting of traffic information is critical for the
development of intelligent traffic systems. We may benefit from the rapid
growth of neural network analysis technology to better understand the
underlying functioning patterns of traffic networks as a result of this
progress. Due to the fact that traffic data and facility utilization
circumstances are sequentially dependent on past and present situations,
several related neural network techniques based on temporal dependency
extraction models have been developed to solve the problem. The complicated
topological road structure, on the other hand, amplifies the effect of spatial
interdependence, which cannot be captured by pure temporal extraction
approaches. Additionally, the typical Deep Recurrent Neural Network (RNN)
topology has a constraint on global information extraction, which is required
for comprehensive long-term prediction. This study proposes a new
spatial-temporal neural network architecture, called Spatial-Temporal
Graph-Informer (STGIN), to handle the long-term traffic parameters forecasting
issue by merging the Informer and Graph Attention Network (GAT) layers for
spatial and temporal relationships extraction. The attention mechanism
potentially guarantees long-term prediction performance without significant
information loss from distant inputs. On two real-world traffic datasets with
varying horizons, experimental findings validate the long sequence prediction
abilities, and further interpretation is provided.
</p></li>
</ul>

<h3>Title: On Neural Consolidation for Transfer in Reinforcement Learning. (arXiv:2210.02240v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02240">http://arxiv.org/abs/2210.02240</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02240] On Neural Consolidation for Transfer in Reinforcement Learning](http://arxiv.org/abs/2210.02240)</code></li>
<li>Summary: <p>Although transfer learning is considered to be a milestone in deep
reinforcement learning, the mechanisms behind it are still poorly understood.
In particular, predicting if knowledge can be transferred between two given
tasks is still an unresolved problem. In this work, we explore the use of
network distillation as a feature extraction method to better understand the
context in which transfer can occur. Notably, we show that distillation does
not prevent knowledge transfer, including when transferring from multiple tasks
to a new one, and we compare these results with transfer without prior
distillation. We focus our work on the Atari benchmark due to the variability
between different games, but also to their similarities in terms of visual
features.
</p></li>
</ul>

<h3>Title: Automated Graph Self-supervised Learning via Multi-teacher Knowledge Distillation. (arXiv:2210.02099v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02099">http://arxiv.org/abs/2210.02099</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02099] Automated Graph Self-supervised Learning via Multi-teacher Knowledge Distillation](http://arxiv.org/abs/2210.02099)</code></li>
<li>Summary: <p>Self-supervised learning on graphs has recently achieved remarkable success
in graph representation learning. With hundreds of self-supervised pretext
tasks proposed over the past few years, the research community has greatly
developed, and the key is no longer to design more powerful but complex pretext
tasks, but to make more effective use of those already on hand. This paper
studies the problem of how to automatically, adaptively, and dynamically learn
instance-level self-supervised learning strategies for each node from a given
pool of pretext tasks. In this paper, we propose a novel multi-teacher
knowledge distillation framework for Automated Graph Self-Supervised Learning
(AGSSL), which consists of two main branches: (i) Knowledge Extraction:
training multiple teachers with different pretext tasks, so as to extract
different levels of knowledge with different inductive biases; (ii) Knowledge
Integration: integrating different levels of knowledge and distilling them into
the student model. Without simply treating different teachers as equally
important, we provide a provable theoretical guideline for how to integrate the
knowledge of different teachers, i.e., the integrated teacher probability
should be close to the true Bayesian class-probability. To approach the
theoretical optimum in practice, two adaptive knowledge integration strategies
are proposed to construct a relatively "good" integrated teacher. Extensive
experiments on eight datasets show that AGSSL can benefit from multiple pretext
tasks, outperforming the corresponding individual tasks; by combining a few
simple but classical pretext tasks, the resulting performance is comparable to
other leading counterparts.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning. (arXiv:2210.02326v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02326">http://arxiv.org/abs/2210.02326</a></li>
<li>Code URL: <a href="https://github.com/erosinho13/ladd">https://github.com/erosinho13/ladd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02326] Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning](http://arxiv.org/abs/2210.02326)</code></li>
<li>Summary: <p>Federated Learning (FL) has recently emerged as a possible way to tackle the
domain shift in real-world Semantic Segmentation (SS) without compromising the
private nature of the collected data. However, most of the existing works on FL
unrealistically assume labeled data in the remote clients. Here we propose a
novel task (FFREEDA) in which the clients' data is unlabeled and the server
accesses a source labeled dataset for pre-training only. To solve FFREEDA, we
propose LADD, which leverages the knowledge of the pre-trained model by
employing self-supervision with ad-hoc regularization techniques for local
training and introducing a novel federated clustered aggregation scheme based
on the clients' style. Our experiments show that our algorithm is able to
efficiently tackle the new task outperforming existing approaches. The code is
available at https://github.com/Erosinho13/LADD.
</p></li>
</ul>

<h3>Title: Split Federated Learning on Micro-controllers: A Keyword Spotting Showcase. (arXiv:2210.01961v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01961">http://arxiv.org/abs/2210.01961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01961] Split Federated Learning on Micro-controllers: A Keyword Spotting Showcase](http://arxiv.org/abs/2210.01961)</code></li>
<li>Summary: <p>Nowadays, AI companies improve service quality by aggressively collecting
users' data generated by edge devices, which jeopardizes data privacy. To
prevent this, Federated Learning is proposed as a private learning scheme,
using which users can locally train the model without collecting users' raw
data to servers. However, for machine-learning applications on edge devices
that have hard memory constraints, implementing a large model using FL is
infeasible. To meet the memory requirement, a recent collaborative learning
scheme named split federal learning is a potential solution since it keeps a
small model on the device and keeps the rest of the model on the server. In
this work, we implement a simply SFL framework on the Arduino board and verify
its correctness on the Chinese digits audio dataset for keyword spotting
application with over 90% accuracy. Furthermore, on the English digits audio
dataset, our SFL implementation achieves 13.89% higher accuracy compared to a
state-of-the-art FL implementation.
</p></li>
</ul>

<h3>Title: Federated Graph-based Networks with Shared Embedding. (arXiv:2210.01803v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01803">http://arxiv.org/abs/2210.01803</a></li>
<li>Code URL: <a href="https://github.com/GraphSAINT/GraphSAINT">https://github.com/GraphSAINT/GraphSAINT</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01803] Federated Graph-based Networks with Shared Embedding](http://arxiv.org/abs/2210.01803)</code></li>
<li>Summary: <p>Nowadays, user privacy is becoming an issue that cannot be bypassed for
system developers, especially for that of web applications where data can be
easily transferred through internet. Thankfully, federated learning proposes an
innovative method to train models with distributed devices while data are kept
in local storage. However, unlike general neural networks, although graph-based
networks have achieved great success in classification tasks and advanced
recommendation system, its high performance relies on the rich context provided
by a graph structure, which is vulnerable when data attributes are incomplete.
Therefore, the latter becomes a realistic problem when implementing federated
learning for graph-based networks. Knowing that data embedding is a
representation in a different space, we propose our Federated Graph-based
Networks with Shared Embedding (Feras), which uses shared embedding data to
train the network and avoids the direct sharing of original data. A solid
theoretical proof of the convergence of Feras is given in this work.
Experiments on different datasets (PPI, Flickr, Reddit) are conducted to show
the efficiency of Feras for centralized learning. Finally, Feras enables the
training of current graph-based models in the federated learning framework for
privacy concern.
</p></li>
</ul>

<h3>Title: FedMT: Federated Learning with Mixed-type Labels. (arXiv:2210.02042v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02042">http://arxiv.org/abs/2210.02042</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02042] FedMT: Federated Learning with Mixed-type Labels](http://arxiv.org/abs/2210.02042)</code></li>
<li>Summary: <p>In federated learning (FL), classifiers (e.g., deep networks) are trained on
datasets from multiple centers without exchanging data across them, and thus
improves sample efficiency. In the classical setting of FL, the same labeling
criterion is usually employed across all centers being involved in training.
This constraint greatly limits the applicability of FL. For example, standards
used for disease diagnosis are more likely to be different across clinical
centers, which mismatches the classical FL setting. In this paper, we consider
an important yet under-explored setting of FL, namely FL with mixed-type labels
where different labeling criteria can be employed by various centers, leading
to inter-center label space differences and challenging existing FL methods
designed for the classical setting. To effectively and efficiently train models
with mixed-type labels, we propose a theory-guided and model-agnostic approach
that can make use of the underlying correspondence between those label spaces
and can be easily combined with various FL methods such as FedAvg. We present
convergence analysis based on over-parameterized ReLU networks. We show that
the proposed method can achieve linear convergence in label projection, and
demonstrate the impact of the parameters of our new setting on the convergence
rate. The proposed method is evaluated and the theoretical findings are
validated on benchmark and medical datasets.
</p></li>
</ul>

<h3>Title: ISFL: Trustworthy Federated Learning for Non-i.i.d. Data with Local Importance Sampling. (arXiv:2210.02119v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02119">http://arxiv.org/abs/2210.02119</a></li>
<li>Code URL: <a href="https://github.com/zhuzzq/isfl">https://github.com/zhuzzq/isfl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02119] ISFL: Trustworthy Federated Learning for Non-i](http://arxiv.org/abs/2210.02119)</code></li>
<li>Summary: <p>As a promising integrated computation and communication learning paradigm,
federated learning (FL) carries a periodic sharing from distributed clients.
Due to the non-i.i.d. data distribution on clients, FL model suffers from the
gradient diversity, poor performance, bad convergence, etc. In this work, we
aim to tackle this key issue by adopting data-driven importance sampling (IS)
for local training. We propose a trustworthy framework, named importance
sampling federated learning (ISFL), which is especially compatible with neural
network (NN) models. The framework is evaluated both theoretically and
experimentally. Firstly, we derive the parameter deviation bound between ISFL
and the centralized full-data training to identify the main factors of the
non-i.i.d. dilemmas. We will then formulate the selection of optimal IS weights
as an optimization problem and obtain theoretical solutions. We also employ
water-filling methods to calculate the IS weights and develop the complete ISFL
algorithms. The experimental results on CIFAR-10 fit our proposed theories well
and prove that ISFL reaps higher performance, as well as better convergence on
non-i.i.d. data. To the best of our knowledge, ISFL is the first non-i.i.d. FL
solution from the local sampling aspect which exhibits theoretical NN
compatibility. Furthermore, as a local sampling approach, ISFL can be easily
migrated into emerging FL frameworks.
</p></li>
</ul>

<h3>Title: Domain Discrepancy Aware Distillation for Model Aggregation in Federated Learning. (arXiv:2210.02190v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02190">http://arxiv.org/abs/2210.02190</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02190] Domain Discrepancy Aware Distillation for Model Aggregation in Federated Learning](http://arxiv.org/abs/2210.02190)</code></li>
<li>Summary: <p>Knowledge distillation has recently become popular as a method of model
aggregation on the server for federated learning. It is generally assumed that
there are abundant public unlabeled data on the server. However, in reality,
there exists a domain discrepancy between the datasets of the server domain and
a client domain, which limits the performance of knowledge distillation. How to
improve the aggregation under such a domain discrepancy setting is still an
open problem. In this paper, we first analyze the generalization bound of the
aggregation model produced from knowledge distillation for the client domains,
and then describe two challenges, server-to-client discrepancy and
client-to-client discrepancy, brought to the aggregation model by the domain
discrepancies. Following our analysis, we propose an adaptive knowledge
aggregation algorithm FedD3A based on domain discrepancy aware distillation to
lower the bound. FedD3A performs adaptive weighting at the sample level in each
round of FL. For each sample in the server domain, only the client models of
its similar domains will be selected for playing the teacher role. To achieve
this, we show that the discrepancy between the server-side sample and the
client domain can be approximately measured using a subspace projection matrix
calculated on each client without accessing its raw data. The server can thus
leverage the projection matrices from multiple clients to assign weights to the
corresponding teacher models for each server-side sample. We validate FedD3A on
two popular cross-domain datasets and show that it outperforms the compared
competitors in both cross-silo and cross-device FL settings.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Ten Years after ImageNet: A 360{\deg} Perspective on AI. (arXiv:2210.01797v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01797">http://arxiv.org/abs/2210.01797</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01797] Ten Years after ImageNet: A 360{\deg} Perspective on AI](http://arxiv.org/abs/2210.01797)</code></li>
<li>Summary: <p>It is ten years since neural networks made their spectacular comeback.
Prompted by this anniversary, we take a holistic perspective on Artificial
Intelligence (AI). Supervised Learning for cognitive tasks is effectively
solved - provided we have enough high-quality labeled data. However, deep
neural network models are not easily interpretable, and thus the debate between
blackbox and whitebox modeling has come to the fore. The rise of attention
networks, self-supervised learning, generative modeling, and graph neural
networks has widened the application space of AI. Deep Learning has also
propelled the return of reinforcement learning as a core building block of
autonomous decision making systems. The possible harms made possible by new AI
technologies have raised socio-technical issues such as transparency, fairness,
and accountability. The dominance of AI by Big-Tech who control talent,
computing resources, and most importantly, data may lead to an extreme AI
divide. Failure to meet high expectations in high profile, and much heralded
flagship projects like self-driving vehicles could trigger another AI winter.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: SIMPLE: A Gradient Estimator for $k$-Subset Sampling. (arXiv:2210.01941v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01941">http://arxiv.org/abs/2210.01941</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01941] SIMPLE: A Gradient Estimator for $k$-Subset Sampling](http://arxiv.org/abs/2210.01941)</code></li>
<li>Summary: <p>$k$-subset sampling is ubiquitous in machine learning, enabling
regularization and interpretability through sparsity. The challenge lies in
rendering $k$-subset sampling amenable to end-to-end learning. This has
typically involved relaxing the reparameterized samples to allow for
backpropagation, with the risk of introducing high bias and high variance. In
this work, we fall back to discrete $k$-subset sampling on the forward pass.
This is coupled with using the gradient with respect to the exact marginals,
computed efficiently, as a proxy for the true gradient. We show that our
gradient estimator, SIMPLE, exhibits lower bias and variance compared to
state-of-the-art estimators, including the straight-through Gumbel estimator
when $k = 1$. Empirical results show improved performance on learning to
explain and sparse linear regression. We provide an algorithm for computing the
exact ELBO for the $k$-subset distribution, obtaining significantly lower loss
compared to SOTA.
</p></li>
</ul>

<h3>Title: Towards Prototype-Based Self-Explainable Graph Neural Network. (arXiv:2210.01974v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.01974">http://arxiv.org/abs/2210.01974</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2210.01974] Towards Prototype-Based Self-Explainable Graph Neural Network](http://arxiv.org/abs/2210.01974)</code></li>
<li>Summary: <p>Graph Neural Networks (GNNs) have shown great ability in modeling
graph-structured data for various domains. However, GNNs are known as black-box
models that lack interpretability. Without understanding their inner working,
we cannot fully trust them, which largely limits their adoption in high-stake
scenarios. Though some initial efforts have been taken to interpret the
predictions of GNNs, they mainly focus on providing post-hoc explanations using
an additional explainer, which could misrepresent the true inner working
mechanism of the target GNN. The works on self-explainable GNNs are rather
limited. Therefore, we study a novel problem of learning prototype-based
self-explainable GNNs that can simultaneously give accurate predictions and
prototype-based explanations on predictions. We design a framework which can
learn prototype graphs that capture representative patterns of each class as
class-level explanations. The learned prototypes are also used to
simultaneously make prediction for for a test instance and provide
instance-level explanation. Extensive experiments on real-world and synthetic
datasets show the effectiveness of the proposed framework for both prediction
accuracy and explanation quality.
</p></li>
</ul>

<h3>Title: The Vendi Score: A Diversity Evaluation Metric for Machine Learning. (arXiv:2210.02410v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2210.02410">http://arxiv.org/abs/2210.02410</a></li>
<li>Code URL: <a href="https://github.com/vertaix/vendi-score">https://github.com/vertaix/vendi-score</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2210.02410] The Vendi Score: A Diversity Evaluation Metric for Machine Learning](http://arxiv.org/abs/2210.02410)</code></li>
<li>Summary: <p>Diversity is an important criterion for many areas of machine learning (ML),
including generative modeling and dataset curation. Yet little work has gone
into understanding, formalizing, and measuring diversity in ML. In this paper,
we address the diversity evaluation problem by proposing the Vendi Score, which
connects and extends ideas from ecology and quantum statistical mechanics to
ML. The Vendi Score is defined as the exponential of the Shannon entropy of the
eigenvalues of a similarity matrix. This matrix is induced by a user-defined
similarity function applied to the sample to be evaluated for diversity. In
taking a similarity function as input, the Vendi Score enables its user to
specify any desired form of diversity. Importantly, unlike many existing
metrics in ML, the Vendi Score doesn't require a reference dataset or
distribution over samples or labels, it is therefore general and applicable to
any generative model, decoding algorithm, and dataset from any domain where
similarity can be defined. We showcased the Vendi Score on molecular generative
modeling, a domain where diversity plays an important role in enabling the
discovery of novel molecules. We found that the Vendi Score addresses
shortcomings of the current diversity metric of choice in that domain. We also
applied the Vendi Score to generative models of images and decoding algorithms
of text and found it confirms known results about diversity in those domains.
Furthermore, we used the Vendi Score to measure mode collapse, a known
limitation of generative adversarial networks (GANs). In particular, the Vendi
Score revealed that even GANs that capture all the modes of a labeled dataset
can be less diverse than the original dataset. Finally, the interpretability of
the Vendi Score allowed us to diagnose several benchmark ML datasets for
diversity, opening the door for diversity-informed data augmentation.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
