<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2026-01-21</h1>
<h3>Title: CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration</h3>
<ul>
<li><strong>Authors: </strong>Boyang Wang, Yash Vishe, Xin Xu, Zachary Novack, Julian McAuley, Junda Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11556">https://arxiv.org/abs/2601.11556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11556">https://arxiv.org/pdf/2601.11556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11556]] CSyMR: Benchmarking Compositional Symbolic Muisc Reasoning With MIR Tool Integration(https://arxiv.org/abs/2601.11556)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are leveraged in symbolic music reasoning, yet existing benchmarks emphasize isolated knowledge or atomic analyses rather than the integrative compositional reasoning needed to connect musical structures. To address this, we present the Compositional Symbolic Music Reasoning Benchmark (CSyMR-Bench), a curated multiple-choice dataset of 126 questions derived from expert forums and professional examinations. Each item involves combining several atomic analyses to arrive at the final answer. Furthermore, we introduce a tool-augmented agent framework that leverages symbolic music analysis tools from the music21 library to address the challenges posed by CSyMR-Bench. Experiments validate that CSyMR-Bench poses a non-trivial challenge across both community-sourced and exam-style questions, while our tool-augmented agent consistently outperforms all baselines, achieving 5-7% absolute accuracy gains.</li>
</ul>

<h3>Title: Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths</h3>
<ul>
<li><strong>Authors: </strong>Ahilan Ayyachamy Nadar Ponnusamy, Karthic Chandran, M Maruf Hossain</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11564">https://arxiv.org/abs/2601.11564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11564">https://arxiv.org/pdf/2601.11564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11564]] Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths(https://arxiv.org/abs/2601.11564)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.</li>
</ul>

<h3>Title: Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings</h3>
<ul>
<li><strong>Authors: </strong>Pakorn Ueareeworakul, Shuman Liu, Jinghao Feng, Ling Hu, Zhantang Shi, Chengqi Sun, Liang Yao, Panyi Ouyang, Haibo Zhang, Anxiang Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11565">https://arxiv.org/abs/2601.11565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11565">https://arxiv.org/pdf/2601.11565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11565]] Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings(https://arxiv.org/abs/2601.11565)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.</li>
</ul>

<h3>Title: Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology</h3>
<ul>
<li><strong>Authors: </strong>Vanessa D'Amario, Randy Daniel, Alessandro Zanetti, Dhruv Edamadaka, Nitya Alaparthy, Joshua Tarkoff</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11567">https://arxiv.org/abs/2601.11567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11567">https://arxiv.org/pdf/2601.11567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11567]] Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology(https://arxiv.org/abs/2601.11567)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.</li>
</ul>

<h3>Title: AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control</h3>
<ul>
<li><strong>Authors: </strong>Quang-Hung Bui, Anh Son Ta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11568">https://arxiv.org/abs/2601.11568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11568">https://arxiv.org/pdf/2601.11568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11568]] AdaFRUGAL: Adaptive Memory-Efficient Training with Dynamic Control(https://arxiv.org/abs/2601.11568)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Training Large Language Models (LLMs) is highly memory-intensive due to optimizer state overhead. The FRUGAL framework mitigates this with gradient splitting, but its static hyperparameters -- the subspace ratio ($\rho$) and update frequency ($T$) -- require costly manual tuning, limiting adaptability. We present AdaFRUGAL, which automates this process by introducing two dynamic controls: (i) a linear decay for $\rho$ to progressively reduce memory, and (ii) a loss-aware schedule for $T$ to lower computational overhead. Experiments across large-scale pre-training (English C4, Vietnamese VietVault) and fine-tuning (GLUE) demonstrate that AdaFRUGAL achieves a compelling trade-off. It maintains competitive performance against AdamW and static FRUGAL while significantly reducing both GPU memory and training time, offering a more practical, autonomous solution for resource-constrained LLM training.</li>
</ul>

<h3>Title: Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp</h3>
<ul>
<li><strong>Authors: </strong>Pengcheng Xie</a></li>
<li><strong>Subjects: </strong>cs.CR, math.NA, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11570">https://arxiv.org/abs/2601.11570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11570">https://arxiv.org/pdf/2601.11570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11570]] Privacy-Preserving Black-Box Optimization (PBBO): Theory and the Model-Based Algorithm DFOp(https://arxiv.org/abs/2601.11570)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>This paper focuses on solving unconstrained privacy-preserving black-box optimization (PBBO), its corresponding least Frobenius norm updating of quadratic models, and the differentially privacy mechanisms for PBBO. Optimization problems with transformed/encrypted objective functions aim to minimize F(x), which is encrypted/transformed/encrypted to F_k(x) as the output at the k-th iteration. A new derivative-free solver named DFOp, with its implementation, is proposed in this paper, which has a new updating formula for the quadratic model functions. The convergence of DFOp for solving problems with transformed/encrypted objective functions is given. Other analyses, including the new model updating formula and the analysis of the transformation's impact to model functions are presented. We propose two differentially private noise-adding mechanisms for privacy-preserving black-box optimization. Numerical results show that DFOp performs better than compared algorithms. To the best of our knowledge, DFOp is the first derivative-free solver that can solve black-box optimization problems with step-encryption and privacy-preserving black-box problems exactly, which also tries to answer the open question about the combination of derivative-free optimization and privacy.</li>
</ul>

<h3>Title: Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces</h3>
<ul>
<li><strong>Authors: </strong>Timo Aukusti Laine</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11572">https://arxiv.org/abs/2601.11572</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11572">https://arxiv.org/pdf/2601.11572</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11572]] Discrete Semantic States and Hamiltonian Dynamics in LLM Embedding Spaces(https://arxiv.org/abs/2601.11572)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We investigate the structure of Large Language Model (LLM) embedding spaces using mathematical concepts, particularly linear algebra and the Hamiltonian formalism, drawing inspiration from analogies with quantum mechanical systems. Motivated by the observation that LLM embeddings exhibit distinct states, suggesting discrete semantic representations, we explore the application of these mathematical tools to analyze semantic relationships. We demonstrate that the L2 normalization constraint, a characteristic of many LLM architectures, results in a structured embedding space suitable for analysis using a Hamiltonian formalism. We derive relationships between cosine similarity and perturbations of embedding vectors, and explore direct and indirect semantic transitions. Furthermore, we explore a quantum-inspired perspective, deriving an analogue of zero-point energy and discussing potential connections to Koopman-von Neumann mechanics. While the interpretation warrants careful consideration, our results suggest that this approach offers a promising avenue for gaining deeper insights into LLMs and potentially informing new methods for mitigating hallucinations.</li>
</ul>

<h3>Title: An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Muneeb, David B. Ascher</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11573">https://arxiv.org/abs/2601.11573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11573">https://arxiv.org/pdf/2601.11573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11573]] An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT(https://arxiv.org/abs/2601.11573)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\% and 70\% for PRSGPT and 6\% and 18\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.</li>
</ul>

<h3>Title: GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment</h3>
<ul>
<li><strong>Authors: </strong>Lukas Abrie Nel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11574">https://arxiv.org/abs/2601.11574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11574">https://arxiv.org/pdf/2601.11574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11574]] GRADE: Replacing Policy Gradients with Backpropagation for LLM Alignment(https://arxiv.org/abs/2601.11574)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from human feedback (RLHF) has become the dominant paradigm for aligning large language models with human preferences. However, policy gradient methods such as PPO suffer from high variance gradient estimates, requiring careful hyperparameter tuning and extensive computational resources. We introduce GRADE (Gumbel-softmax Relaxation for Alignment via Differentiable Estimation), a method that replaces high-variance policy gradient estimation with direct backpropagation through a differentiable relaxation of the discrete token sampling process. Using the Gumbel-Softmax reparameterization with straight-through estimation (GRADE-STE), we enable end-to-end gradient flow from reward signals through generated tokens to model parameters. On sentiment-controlled text generation using the IMDB dataset, GRADE-STE achieves a test reward of 0.763 +- 0.344 compared to PPO's 0.510 +- 0.313 and REINFORCE's 0.617 +- 0.378, representing a 50% relative improvement over PPO. Critically, GRADE-STE exhibits gradient variance over 14 times lower than REINFORCE and maintains stable training dynamics throughout optimization. Our rigorous evaluation with proper train/validation/test splits demonstrates that these improvements generalize to held-out data, with GRADE-STE showing the best generalization characteristics among all methods tested. GRADE offers a simpler, more stable, and more effective alternative to reinforcement learning for LLM alignment.</li>
</ul>

<h3>Title: Concept Attractors in LLMs and their Applications</h3>
<ul>
<li><strong>Authors: </strong>Sotirios Panagiotis Chytas, Vikas Singh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11575">https://arxiv.org/abs/2601.11575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11575">https://arxiv.org/pdf/2601.11575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11575]] Concept Attractors in LLMs and their Applications(https://arxiv.org/abs/2601.11575)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.</li>
</ul>

<h3>Title: LimAgents: Multi-Agent LLMs for Generating Research Limitations</h3>
<ul>
<li><strong>Authors: </strong>Ibrahim Al Azher, Zhishuai Guo, Hamed Alhoori</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11578">https://arxiv.org/abs/2601.11578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11578">https://arxiv.org/pdf/2601.11578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11578]] LimAgents: Multi-Agent LLMs for Generating Research Limitations(https://arxiv.org/abs/2601.11578)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.</li>
</ul>

<h3>Title: Bielik 11B v3: Multilingual Large Language Model for European Languages</h3>
<ul>
<li><strong>Authors: </strong>Krzysztof Ociepa, Łukasz Flis, Remigiusz Kinas, Krzysztof Wróbel, Adrian Gwoździej</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11579">https://arxiv.org/abs/2601.11579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11579">https://arxiv.org/pdf/2601.11579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11579]] Bielik 11B v3: Multilingual Large Language Model for European Languages(https://arxiv.org/abs/2601.11579)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning. Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning. The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.</li>
</ul>

<h3>Title: Speculative Decoding: Performance or Illusion?</h3>
<ul>
<li><strong>Authors: </strong>Xiaoxuan Liu, Jiaxiang Yu, Jongseok Park, Ion Stoica, Alvin Cheung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11580">https://arxiv.org/abs/2601.11580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11580">https://arxiv.org/pdf/2601.11580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11580]] Speculative Decoding: Performance or Illusion?(https://arxiv.org/abs/2601.11580)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.</li>
</ul>

<h3>Title: Enhancing the QA Model through a Multi-domain Debiasing Framework</h3>
<ul>
<li><strong>Authors: </strong>Yuefeng Wang, ChangJae Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11581">https://arxiv.org/abs/2601.11581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11581">https://arxiv.org/pdf/2601.11581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11581]] Enhancing the QA Model through a Multi-domain Debiasing Framework(https://arxiv.org/abs/2601.11581)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.</li>
</ul>

<h3>Title: Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Hyunjun Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11585">https://arxiv.org/abs/2601.11585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11585">https://arxiv.org/pdf/2601.11585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11585]] Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents(https://arxiv.org/abs/2601.11585)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.</li>
</ul>

<h3>Title: A Multimodal Data Processing Pipeline for MIMIC-IV Dataset</h3>
<ul>
<li><strong>Authors: </strong>Farzana Islam Adiba, Varsha Danduri, Fahmida Liza Piya, Ali Abbasi, Mehak Gupta, Rahmatollah Beheshti</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11606">https://arxiv.org/abs/2601.11606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11606">https://arxiv.org/pdf/2601.11606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11606]] A Multimodal Data Processing Pipeline for MIMIC-IV Dataset(https://arxiv.org/abs/2601.11606)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The MIMIC-IV dataset is a large, publicly available electronic health record (EHR) resource widely used for clinical machine learning research. It comprises multiple modalities, including structured data, clinical notes, waveforms, and imaging data. Working with these disjointed modalities requires an extensive manual effort to preprocess and align them for downstream analysis. While several pipelines for MIMIC-IV data extraction are available, they target a small subset of modalities or do not fully support arbitrary downstream applications. In this work, we greatly expand our prior popular unimodal pipeline and present a comprehensive and customizable multimodal pipeline that can significantly reduce multimodal processing time and enhance the reproducibility of MIMIC-based studies. Our pipeline systematically integrates the listed modalities, enabling automated cohort selection, temporal alignment across modalities, and standardized multimodal output formats suitable for arbitrary static and time-series downstream applications. We release the code, a simple UI, and a Python package for selective integration (with embedding) at this https URL.</li>
</ul>

<h3>Title: Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction</h3>
<ul>
<li><strong>Authors: </strong>Weinuo Ou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11609">https://arxiv.org/abs/2601.11609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11609">https://arxiv.org/pdf/2601.11609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11609]] Auxiliary-predicted Compress Memory Model(ApCM Model): A Neural Memory Storage Model Based on Invertible Compression and Learnable Prediction(https://arxiv.org/abs/2601.11609)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current large language models (LLMs) generally lack an effective runtime memory mechanism,making it difficult to adapt to dynamic and personalized interaction requirements. To address this issue, this paper proposes a novel neural memory storage architecture--the Auxiliary Prediction Compression Memory Model (ApCM Model).</li>
</ul>

<h3>Title: Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home</h3>
<ul>
<li><strong>Authors: </strong>Marina Vicini, Martin Rudorfer, Zhuangzhuang Dai, Luis J. Manso</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11611">https://arxiv.org/abs/2601.11611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11611">https://arxiv.org/pdf/2601.11611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11611]] Integrating Temporal Context into Streaming Data for Human Activity Recognition in Smart Home(https://arxiv.org/abs/2601.11611)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>With the global population ageing, it is crucial to enable individuals to live independently and safely in their homes. Using ubiquitous sensors such as Passive InfraRed sensors (PIR) and door sensors is drawing increasing interest for monitoring daily activities and facilitating preventative healthcare interventions for the elderly. Human Activity Recognition (HAR) from passive sensors mostly relies on traditional machine learning and includes data segmentation, feature extraction, and classification. While techniques like Sensor Weighting Mutual Information (SWMI) capture spatial context in a feature vector, effectively leveraging temporal information remains a challenge. We tackle this by clustering activities into morning, afternoon, and night, and encoding them into the feature weighting method calculating distinct mutual information matrices. We further propose to extend the feature vector by incorporating time of day and day of week as cyclical temporal features, as well as adding a feature to track the user's location. The experiments show improved accuracy and F1-score over existing state-of-the-art methods in three out of four real-world datasets, with highest gains in a low-data regime. These results highlight the potential of our approach for developing effective smart home solutions to support ageing in place.</li>
</ul>

<h3>Title: Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study</h3>
<ul>
<li><strong>Authors: </strong>Arnav S. Sonavane</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11612">https://arxiv.org/abs/2601.11612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11612">https://arxiv.org/pdf/2601.11612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11612]] Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study(https://arxiv.org/abs/2601.11612)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: this https URL</li>
</ul>

<h3>Title: Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Jason Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11614">https://arxiv.org/abs/2601.11614</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11614">https://arxiv.org/pdf/2601.11614</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11614]] Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning(https://arxiv.org/abs/2601.11614)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.</li>
</ul>

<h3>Title: PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM</h3>
<ul>
<li><strong>Authors: </strong>Xu Wang, Boyao Han, Xiaojun Chen, Ying Liu, Ruihui Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11617">https://arxiv.org/abs/2601.11617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11617">https://arxiv.org/pdf/2601.11617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11617]] PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM(https://arxiv.org/abs/2601.11617)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.</li>
</ul>

<h3>Title: Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention</h3>
<ul>
<li><strong>Authors: </strong>Luis Rosario Freytes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11618">https://arxiv.org/abs/2601.11618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11618">https://arxiv.org/pdf/2601.11618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11618]] Geometric Attention: A Regime-Explicit Operator Semantics for Transformer Attention(https://arxiv.org/abs/2601.11618)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Geometric Attention (GA) specifies an attention layer by four independent inputs: a finite carrier (what indices are addressable), an evidence-kernel rule (how masked proto-scores and a link induce nonnegative weights), a probe family (which observables are treated as admissible), and an anchor/update rule (which representative kernel is selected and how it is applied). Probe families induce an operational equivalence relation on kernels and therefore a gauge; anchors select representatives relative to that probe. Under a scalar relational-work representation and a multiplicative compositionality law for evidence, the admissible link family is exponential, yielding Gibbs weights; with row anchoring this includes the softmax kernel family as a subregime. After quotienting unary row/column score fields, the remaining interaction component admits a canonical rank-r normal form (Eckart-Young/SVD); dot-product score charts implement the corresponding low-rank interaction regime. Fixing the carrier and extensionalizing the update yields the standard fixed-token Transformer attention operator; allowing carrier updates yields adaptive-carrier and staged-depth regimes. The operator language also supports multihead/mixed kernels, plan-based anchors (e.g., entropic OT/Sinkhorn), and unary operators (e.g., FFN-style fields) as explicit regime choices. This separates invariant structure from modeling choice, enabling principled comparison and extension of attention mechanisms, and attention-based architectures.</li>
</ul>

<h3>Title: NoiseFormer -- Noise Diffused Symmetric Attention Transformer</h3>
<ul>
<li><strong>Authors: </strong>Phani Kumar, Nyshadham, Jyothendra Varma, Polisetty V R K, Aditya Rathore</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11619">https://arxiv.org/abs/2601.11619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11619">https://arxiv.org/pdf/2601.11619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11619]] NoiseFormer -- Noise Diffused Symmetric Attention Transformer(https://arxiv.org/abs/2601.11619)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Transformer architecture has been very successful long runner in the field of Deep Learning (DL) and Large Language Models (LLM) because of its powerful attention-based learning and parallel-natured architecture. As the models grow gigantic in terms of memory footprint, difficulties in fitting the model on a device like a GPU or an AI accelerator give rise to the need for multiple computing devices thereby escalating the computing cost. This increased training/inference cost paved the way for efficient model size reduction/parametric reduction deploying Sparse Attention techniques. In this paper, we start analyzing one of the techniques of Sparse Attention called Symmetric Dot-Product Attention (referred to as Symmetric Attention) and propose a novel unified model architecture called Noise Diffused Symmetric Attention Transformer to enhance the model's performance. While maintaining the memory gains of Symmetric Attention, with minute overhead in terms of model parameters and computational overhead, the proposed model brings in enhanced performance in terms of accuracy and inference-time sampling. The proposed model is validated upon GPT2 base model and the results reflect the performance gains falling between plain Symmetric attention and GPT2 base model on a variety of GLUE benchmark tasks in terms of accuracy, with significant model size reduction with respect to the base model.</li>
</ul>

<h3>Title: Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings</h3>
<ul>
<li><strong>Authors: </strong>Hassan Ugail, Jan Ritch-Frel, Irina Matuzava</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11627">https://arxiv.org/abs/2601.11627</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11627">https://arxiv.org/pdf/2601.11627</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11627]] Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings(https://arxiv.org/abs/2601.11627)</code><input type="text"></li>
<li><strong>Keywords: </strong>biometric</a></li>
<li><strong>Abstract: </strong>Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.</li>
</ul>

<h3>Title: Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs</h3>
<ul>
<li><strong>Authors: </strong>Nghia T. Le, Alan Ritter, Kartik Goyal</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11629">https://arxiv.org/abs/2601.11629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11629">https://arxiv.org/pdf/2601.11629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11629]] Semantic Differentiation for Tackling Challenges in Watermarking Low-Entropy Constrained Generation Outputs(https://arxiv.org/abs/2601.11629)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark</a></li>
<li><strong>Abstract: </strong>We demonstrate that while the current approaches for language model watermarking are effective for open-ended generation, they are inadequate at watermarking LM outputs for constrained generation tasks with low-entropy output spaces. Therefore, we devise SeqMark, a sequence-level watermarking algorithm with semantic differentiation that balances the output quality, watermark detectability, and imperceptibility. It improves on the shortcomings of the prevalent token-level watermarking algorithms that cause under-utilization of the sequence-level entropy available for constrained generation tasks. Moreover, we identify and improve upon a different failure mode we term region collapse, associated with prior sequence-level watermarking algorithms. This occurs because the pseudorandom partitioning of semantic space for watermarking in these approaches causes all high-probability outputs to collapse into either invalid or valid regions, leading to a trade-off in output quality and watermarking effectiveness. SeqMark instead, differentiates the high-probable output subspace and partitions it into valid and invalid regions, ensuring the even spread of high-quality outputs among all the regions. On various constrained generation tasks like machine translation, code generation, and abstractive summarization, SeqMark substantially improves watermark detection accuracy (up to 28% increase in F1) while maintaining high generation quality.</li>
</ul>

<h3>Title: A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow</h3>
<ul>
<li><strong>Authors: </strong>Haonan Wei, Linyuan Wang, Nuolin Sun, Zhizhong Zheng, Lei Li, Bin Yan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11630">https://arxiv.org/abs/2601.11630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11630">https://arxiv.org/pdf/2601.11630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11630]] A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow(https://arxiv.org/abs/2601.11630)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.</li>
</ul>

<h3>Title: KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zhiyang Li, Ao Ke, Yukun Cao, Xike Xie</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11632">https://arxiv.org/abs/2601.11632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11632">https://arxiv.org/pdf/2601.11632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11632]] KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering(https://arxiv.org/abs/2601.11632)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.</li>
</ul>

<h3>Title: Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos</h3>
<ul>
<li><strong>Authors: </strong>Anil Egin, Andrea Tangherloni, Antitza Dantcheva</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11635">https://arxiv.org/abs/2601.11635</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11635">https://arxiv.org/pdf/2601.11635</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11635]] Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos(https://arxiv.org/abs/2601.11635)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.</li>
</ul>

<h3>Title: Global Optimization By Gradient from Hierarchical Score-Matching Spaces</h3>
<ul>
<li><strong>Authors: </strong>Ming Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11639">https://arxiv.org/abs/2601.11639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11639">https://arxiv.org/pdf/2601.11639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11639]] Global Optimization By Gradient from Hierarchical Score-Matching Spaces(https://arxiv.org/abs/2601.11639)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Gradient descent is the most commonly used optimization method, but limited to local optimality, and confined to the field of continuous differentiable problems with simple convex constraints. This work solve these limitations and restrictions by unifying all optimization problems with various complex constraints as a general hierarchical optimization objective without constraints, which is optimized by gradient obtained through score matching. By this way, global optimization by deterministic method using strict gradient is achieved for the first time, and verified through simple-constructed and complex-practical experiments. Even more importantly, it reveals the profound connection between global optimization and diffusion based generative modeling.</li>
</ul>

<h3>Title: Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Yuxi Liu, Yipeng Hu, Zekun Zhang, Kunze Jiang, Kun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11641">https://arxiv.org/abs/2601.11641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11641">https://arxiv.org/pdf/2601.11641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11641]] Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers(https://arxiv.org/abs/2601.11641)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.</li>
</ul>

<h3>Title: PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models</h3>
<ul>
<li><strong>Authors: </strong>Abbas Alzubaidi, Ali Al-Bayaty</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11642">https://arxiv.org/abs/2601.11642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11642">https://arxiv.org/pdf/2601.11642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11642]] PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models(https://arxiv.org/abs/2601.11642)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust</a></li>
<li><strong>Abstract: </strong>Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.</li>
</ul>

<h3>Title: Predicting When to Trust Vision-Language Models for Spatial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Imran, Yugyung Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11644">https://arxiv.org/abs/2601.11644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11644">https://arxiv.org/pdf/2601.11644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11644]] Predicting When to Trust Vision-Language Models for Spatial Reasoning(https://arxiv.org/abs/2601.11644)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.</li>
</ul>

<h3>Title: IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Ujjwal Jain, Oshin Misra, Roshni Chakraborty, Mahua Bhattacharya</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11645">https://arxiv.org/abs/2601.11645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11645">https://arxiv.org/pdf/2601.11645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11645]] IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation(https://arxiv.org/abs/2601.11645)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.</li>
</ul>

<h3>Title: Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Miriam Doh, Aditya Gulati, Corina Canali, Nuria Oliver</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11651">https://arxiv.org/abs/2601.11651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11651">https://arxiv.org/pdf/2601.11651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11651]] Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification(https://arxiv.org/abs/2601.11651)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition. Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.</li>
</ul>

<h3>Title: PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Kaustubh Shivshankar Shejole, Gaurav Mishra</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11654">https://arxiv.org/abs/2601.11654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11654">https://arxiv.org/pdf/2601.11654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11654]] PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation(https://arxiv.org/abs/2601.11654)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: this https URL.</li>
</ul>

<h3>Title: Towards AGI A Pragmatic Approach Towards Self Evolving Agent</h3>
<ul>
<li><strong>Authors: </strong>Indrajit Kar, Sammy Zonunpuia, Zonunfeli Ralte</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11658">https://arxiv.org/abs/2601.11658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11658">https://arxiv.org/pdf/2601.11658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11658]] Towards AGI A Pragmatic Approach Towards Self Evolving Agent(https://arxiv.org/abs/2601.11658)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.</li>
</ul>

<h3>Title: Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores</h3>
<ul>
<li><strong>Authors: </strong>Chunshu Wu, Ruibing Song, Sushant Kondguli, Tong Geng, Ang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11660">https://arxiv.org/abs/2601.11660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11660">https://arxiv.org/pdf/2601.11660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11660]] Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores(https://arxiv.org/abs/2601.11660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs. We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency. To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.</li>
</ul>

<h3>Title: Activation Sensitivity as a Unifying Principle for Post-Training Quantization</h3>
<ul>
<li><strong>Authors: </strong>Bruce Changlong Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11663">https://arxiv.org/abs/2601.11663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11663">https://arxiv.org/pdf/2601.11663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11663]] Activation Sensitivity as a Unifying Principle for Post-Training Quantization(https://arxiv.org/abs/2601.11663)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Post-training quantization (PTQ) methods for large language models rely on heuristics that implicitly estimate which weight channels most strongly influence model behavior. Two dominant paradigms have emerged: activation-aware methods such as AWQ prioritize channels with large activation magnitudes, while second-order methods such as GPTQ allocate quantization error according to input covariance structure. Despite strong empirical performance, these approaches remain conceptually fragmented, and it is unclear what underlying quantity they are approximating. In this work, we present a unified theoretical framework for PTQ by formalizing activation sensitivity, defined as the expected impact of channel-wise perturbations on the loss. Using a first-order Taylor expansion, we show that sensitivity naturally arises as the squared norm of gradient-weighted activations, yielding a principled measure of channel importance that captures both activation magnitude and downstream error propagation. Within this framework, AWQ and GPTQ can be interpreted as complementary approximations that recover sensitivity under distinct simplifying assumptions. We analyze the design space of sensitivity metrics, connect gradient-based saliency, Fisher information, and Hessian-based criteria, and clarify their relationships to classical pruning methods such as Optimal Brain Damage and Optimal Brain Surgeon. Rather than proposing a new quantization algorithm, this work provides a conceptual foundation for understanding and comparing post-training quantization methods through the lens of sensitivity.</li>
</ul>

<h3>Title: Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Chetan Pathade, Vinod Dhimam, Sheheryar Ahmad, Ilsa Lareb</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11664">https://arxiv.org/abs/2601.11664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11664">https://arxiv.org/pdf/2601.11664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11664]] Serverless AI Security: Attack Surface Analysis and Runtime Protection Mechanisms for FaaS-Based Machine Learning(https://arxiv.org/abs/2601.11664)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, extraction</a></li>
<li><strong>Abstract: </strong>Serverless computing has achieved widespread adoption, with over 70% of AWS organizations using serverless solutions [1]. Meanwhile, machine learning inference workloads increasingly migrate to Function-as-a-Service (FaaS) platforms for their scalability and cost-efficiency [2], [3], [4]. However, this convergence introduces critical security challenges, with recent reports showing a 220% increase in AI/ML vulnerabilities [5] and serverless computing's fragmented architecture raises new security concerns distinct from traditional cloud deployments [6], [7]. This paper presents the first comprehensive security analysis of machine learning workloads in serverless environments. We systematically characterize the attack surface across five categories: function-level vulnerabilities (cold start exploitation, dependency poisoning), model-specific threats (API-based extraction, adversarial inputs), infrastructure attacks (cross-function contamination, privilege escalation), supply chain risks (malicious layers, backdoored libraries), and IAM complexity (ephemeral nature, serverless functions). Through empirical assessments across AWS Lambda, Azure Functions, and Google Cloud Functions, we demonstrate real-world attack scenarios and quantify their security impact. We propose Serverless AI Shield (SAS), a multi-layered defense framework providing pre-deployment validation, runtime monitoring, and post-execution forensics. Our evaluation shows SAS achieves 94% detection rates while maintaining performance overhead below 9% for inference latency. We release an open-source security toolkit to enable practitioners to assess and harden their serverless AI deployments, advancing the field toward more resilient cloud-native machine learning systems.</li>
</ul>

<h3>Title: UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM</h3>
<ul>
<li><strong>Authors: </strong>Amir Farzin Nikkhah, Dong Chen, Bradford Campbell, Somayeh Asadi, Arsalan Heydarian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11665">https://arxiv.org/abs/2601.11665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11665">https://arxiv.org/pdf/2601.11665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11665]] UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM(https://arxiv.org/abs/2601.11665)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.</li>
</ul>

<h3>Title: MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Imran, Chi Lee, Yugyung Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11666">https://arxiv.org/abs/2601.11666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11666">https://arxiv.org/pdf/2601.11666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11666]] MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models(https://arxiv.org/abs/2601.11666)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.</li>
</ul>

<h3>Title: Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction</h3>
<ul>
<li><strong>Authors: </strong>Xiaojie Xia, Huigang Zhang, Chaoliang Zhong, Jun Sun, Yusuke Oishi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11667">https://arxiv.org/abs/2601.11667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11667">https://arxiv.org/pdf/2601.11667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11667]] Distill-then-Replace: Efficient Task-Specific Hybrid Attention Model Construction(https://arxiv.org/abs/2601.11667)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer architectures deliver state-of-the-art accuracy via dense full-attention, but their quadratic time and memory complexity with respect to sequence length limits practical deployment. Linear attention mechanisms offer linear or near-linear scaling yet often incur performance degradation. Hybrid models that integrate full and linear attention layers promise a balance between efficiency and expressiveness, but face two major challenges: training such hybrid models from scratch is computationally expensive, and manually designing the optimal placement of attention types is highly nontrivial. We address both issues by first transferring weights from the pretrained full-attention modules to its linear attention counterparts through blockwise local distillation, and second, introducing a greedy layer replacement strategy that iteratively substitutes full attention blocks with linear ones while monitoring validation performance on the target task. This yields a task-specific hybrid model in a single efficient pass, without costly re-training or neural architecture search, and can be applied to any pretrained full-attention backbone for diverse downstream tasks.</li>
</ul>

<h3>Title: IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenwen Liao, Hang Ruan, Jianbo Yu, Xiaofeng Yang, Qingchao Jiang, Xuefeng Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11669">https://arxiv.org/abs/2601.11669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11669">https://arxiv.org/pdf/2601.11669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11669]] IPEC: Test-Time Incremental Prototype Enhancement Classifier for Few-Shot Learning(https://arxiv.org/abs/2601.11669)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Metric-based few-shot approaches have gained significant popularity due to their relatively straightforward implementation, high interpret ability, and computational efficiency. However, stemming from the batch-independence assumption during testing, which prevents the model from leveraging valuable knowledge accumulated from previous batches. To address these challenges, we propose a novel test-time method called Incremental Prototype Enhancement Classifier (IPEC), a test-time method that optimizes prototype estimation by leveraging information from previous query samples. IPEC maintains a dynamic auxiliary set by selectively incorporating query samples that are classified with high confidence. To ensure sample quality, we design a robust dual-filtering mechanism that assesses each query sample based on both global prediction confidence and local discriminative ability. By aggregating this auxiliary set with the support set in subsequent tasks, IPEC builds progressively more stable and representative prototypes, effectively reducing its reliance on the initial support set. We ground this approach in a Bayesian interpretation, conceptualizing the support set as a prior and the auxiliary set as a data-driven posterior, which in turn motivates the design of a practical "warm-up and test" two-stage inference protocol. Extensive empirical results validate the superior performance of our proposed method across multiple few-shot classification tasks.</li>
</ul>

<h3>Title: A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Jinshi Liu, Pan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11670">https://arxiv.org/abs/2601.11670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11670">https://arxiv.org/pdf/2601.11670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11670]] A Confidence-Variance Theory for Pseudo-Label Selection in Semi-Supervised Learning(https://arxiv.org/abs/2601.11670)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Most pseudo-label selection strategies in semi-supervised learning rely on fixed confidence thresholds, implicitly assuming that prediction confidence reliably indicates correctness. In practice, deep networks are often overconfident: high-confidence predictions can still be wrong, while informative low-confidence samples near decision boundaries are discarded. This paper introduces a Confidence-Variance (CoVar) theory framework that provides a principled joint reliability criterion for pseudo-label selection. Starting from the entropy minimization principle, we derive a reliability measure that combines maximum confidence (MC) with residual-class variance (RCV), which characterizes how probability mass is distributed over non-maximum classes. The derivation shows that reliable pseudo-labels should have both high MC and low RCV, and that the influence of RCV increases as confidence grows, thereby correcting overconfident but unstable predictions. From this perspective, we cast pseudo-label selection as a spectral relaxation problem that maximizes separability in a confidence-variance feature space, and design a threshold-free selection mechanism to distinguish high- from low-reliability predictions. We integrate CoVar as a plug-in module into representative semi-supervised semantic segmentation and image classification methods. Across PASCAL VOC 2012, Cityscapes, CIFAR-10, and Mini-ImageNet with varying label ratios and backbones, it consistently improves over strong baselines, indicating that combining confidence with residual-class variance provides a more reliable basis for pseudo-label selection than fixed confidence thresholds. (Code: this https URL)</li>
</ul>

<h3>Title: Generating metamers of human scene understanding</h3>
<ul>
<li><strong>Authors: </strong>Ritik Raina, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Dimitris Samaras, Gregory J. Zelinsky</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11675">https://arxiv.org/abs/2601.11675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11675">https://arxiv.org/pdf/2601.11675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11675]] Generating metamers of human scene understanding(https://arxiv.org/abs/2601.11675)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.</li>
</ul>

<h3>Title: A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges</h3>
<ul>
<li><strong>Authors: </strong>Shuai Zhang, Minzhao Lyu, Hassan Habibi Gharakheili</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11678">https://arxiv.org/abs/2601.11678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11678">https://arxiv.org/pdf/2601.11678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11678]] A Survey on Mapping Digital Systems with Bill of Materials: Development, Practices, and Challenges(https://arxiv.org/abs/2601.11678)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Modern digital ecosystems, spanning software, hardware, learning models, datasets, and cryptographic products, continue to grow in complexity, making it difficult for organizations to understand and manage component dependencies. Bills of Materials (BOMs) have emerged as a structured way to document product components, their interrelationships, and key metadata, improving visibility and security across digital supply chains. This survey provides the first comprehensive cross-domain review of BOM developments and practices. We start by examining the evolution of BOM frameworks in three stages (i.e., pre-development, initial, and accelerated) and summarizing their core principles, key stakeholders, and standardization efforts for hardware, software, artificial intelligence (AI) models, datasets, and cryptographic assets. We then review industry practices for generating BOM data, evaluating its quality, and securely sharing it. Next, we review practical downstream uses of BOM data, including dependency modeling, compliance verification, operational risk assessment, and vulnerability tracking. We also discuss academic efforts to address limitations in current BOM frameworks through refinements, extensions, or new models tailored to emerging domains such as data ecosystems and AI supply chains. Finally, we identify four key gaps that limit the usability and reliability of today's BOM frameworks, motivating future research directions.</li>
</ul>

<h3>Title: Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyi Shang, Jiasen Li, Pengzhen Chen, Yanwei Liu, Xiaoyan Gu, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11683">https://arxiv.org/abs/2601.11683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11683">https://arxiv.org/pdf/2601.11683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11683]] Attesting Model Lineage by Consisted Knowledge Evolution with Fine-Tuning Trajectory(https://arxiv.org/abs/2601.11683)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>The fine-tuning technique in deep learning gives rise to an emerging lineage relationship among models. This lineage provides a promising perspective for addressing security concerns such as unauthorized model redistribution and false claim of model provenance, which are particularly pressing in \textcolor{blue}{open-weight model} libraries where robust lineage verification mechanisms are often lacking. Existing approaches to model lineage detection primarily rely on static architectural similarities, which are insufficient to capture the dynamic evolution of knowledge that underlies true lineage relationships. Drawing inspiration from the genetic mechanism of human evolution, we tackle the problem of model lineage attestation by verifying the joint trajectory of knowledge evolution and parameter modification. To this end, we propose a novel model lineage attestation framework. In our framework, model editing is first leveraged to quantify parameter-level changes introduced by fine-tuning. Subsequently, we introduce a novel knowledge vectorization mechanism that refines the evolved knowledge within the edited models into compact representations by the assistance of probe samples. The probing strategies are adapted to different types of model families. These embeddings serve as the foundation for verifying the arithmetic consistency of knowledge relationships across models, thereby enabling robust attestation of model lineage. Extensive experimental evaluations demonstrate the effectiveness and resilience of our approach in a variety of adversarial scenarios in the real world. Our method consistently achieves reliable lineage verification across a broad spectrum of model types, including classifiers, diffusion models, and large language models.</li>
</ul>

<h3>Title: Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Caron, Christophe Guyeux, Hassan Noura, Benjamin Aynes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11686">https://arxiv.org/abs/2601.11686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11686">https://arxiv.org/pdf/2601.11686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11686]] Proof of Concept: Multi-Target Wildfire Risk Prediction and Large Language Model Synthesis(https://arxiv.org/abs/2601.11686)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current state-of-the-art approaches to wildfire risk assessment often overlook operational needs, limiting their practical value for first responders and firefighting services. Effective wildfire management requires a multi-target analysis that captures the diverse dimensions of wildfire risk, including meteorological danger, ignition activity, intervention complexity, and resource mobilization, rather than relying on a single predictive indicator. In this proof of concept, we propose the development of a hybrid framework that combines predictive models for each risk dimension with large language models (LLMs) to synthesize heterogeneous outputs into structured, actionable reports.</li>
</ul>

<h3>Title: Telling Human and Machine Handwriting Apart</h3>
<ul>
<li><strong>Authors: </strong>Luis A. Leiva, Moises Diaz, Nuwan T. Attygalle, Miguel A. Ferrer, Rejean Plamondon</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11700">https://arxiv.org/abs/2601.11700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11700">https://arxiv.org/pdf/2601.11700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11700]] Telling Human and Machine Handwriting Apart(https://arxiv.org/abs/2601.11700)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, biometric, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.</li>
</ul>

<h3>Title: RAC: Retrieval-Augmented Clarification for Faithful Conversational Search</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Rayane Kebir, Vincent Guigue, Lynda Said Lhadj, Laure Soulier</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11722">https://arxiv.org/abs/2601.11722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11722">https://arxiv.org/pdf/2601.11722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11722]] RAC: Retrieval-Augmented Clarification for Faithful Conversational Search(https://arxiv.org/abs/2601.11722)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.</li>
</ul>

<h3>Title: LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text</h3>
<ul>
<li><strong>Authors: </strong>George Mihaila, Suleyman Olcay Polat, Poli Nemkova, Himanshu Sharma, Namratha V. Urs, Mark V. Albert</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11746">https://arxiv.org/abs/2601.11746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11746">https://arxiv.org/pdf/2601.11746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11746]] LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text(https://arxiv.org/abs/2601.11746)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict "Single Mask-Single Sample" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.</li>
</ul>

<h3>Title: Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Arnab Das Utsa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11758">https://arxiv.org/abs/2601.11758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11758">https://arxiv.org/pdf/2601.11758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11758]] Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation(https://arxiv.org/abs/2601.11758)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.</li>
</ul>

<h3>Title: Industry-Aligned Granular Topic Modeling</h3>
<ul>
<li><strong>Authors: </strong>Sae Young Moon, Myeongjun Erik Jang, Haoyan Luo, Chunyang Xiao, Antonios Georgiadis, Fran Silavong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11762">https://arxiv.org/abs/2601.11762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11762">https://arxiv.org/pdf/2601.11762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11762]] Industry-Aligned Granular Topic Modeling(https://arxiv.org/abs/2601.11762)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.</li>
</ul>

<h3>Title: From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce</h3>
<ul>
<li><strong>Authors: </strong>Cheng Lyu, Jingyue Zhang, Ryan Maunu, Mengwei Li, Vinny DeGenova, Yuanli Pei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11769">https://arxiv.org/abs/2601.11769</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11769">https://arxiv.org/pdf/2601.11769</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11769]] From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce(https://arxiv.org/abs/2601.11769)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.</li>
</ul>

<h3>Title: Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kaituo Zhang, Zhimeng Jiang, Na Zou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11776">https://arxiv.org/abs/2601.11776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11776">https://arxiv.org/pdf/2601.11776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11776]] Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models(https://arxiv.org/abs/2601.11776)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.</li>
</ul>

<h3>Title: Cross-Domain Object Detection Using Unsupervised Image Translation</h3>
<ul>
<li><strong>Authors: </strong>Vinicius F. Arruda, Rodrigo F. Berriel, Thiago M. Paixão, Claudine Badue, Alberto F. De Souza, Nicu Sebe, Thiago Oliveira-Santos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11779">https://arxiv.org/abs/2601.11779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11779">https://arxiv.org/pdf/2601.11779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11779]] Cross-Domain Object Detection Using Unsupervised Image Translation(https://arxiv.org/abs/2601.11779)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.</li>
</ul>

<h3>Title: ARM MTE Performance in Practice (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Taehyun Noh, Yingchen Wang, Tal Garfinkel, Mahesh Madhav, Daniel Moghimi, Mattan Erez, Shravan Narayan</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11786">https://arxiv.org/abs/2601.11786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11786">https://arxiv.org/pdf/2601.11786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11786]] ARM MTE Performance in Practice (Extended Version)(https://arxiv.org/abs/2601.11786)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>We present the first comprehensive analysis of ARM MTE hardware performance on four different microarchitectures: ARM Big (A7x), Little (A5x), and Performance (Cortex-X) cores on the Google Pixel 8 and Pixel 9, and on Ampere Computing's AmpereOne CPU core. We also include preliminary analysis of MTE on Apple's M5 chip. We investigate performance in MTE's primary application -- probabilistic memory safety -- on both SPEC CPU benchmarks and in server workloads such as RocksDB, Nginx, PostgreSQL, and Memcached. While MTE often exhibits modest overheads, we also see performance slowdowns up to 6.64x on certain benchmarks. We identify the microarchitectural cause of these overheads and where they can be addressed in future processors. We then analyze MTE's performance for more specialized security applications such as memory tracing, time-of-check time-of-use prevention, sandboxing, and CFI. In some of these cases, MTE offers significant advantages today, while the benefits for other cases are negligible or will depend on future hardware. Finally, we explore where prior work characterizing MTE performance has either been incomplete or incorrect due to methodological or experimental errors.</li>
</ul>

<h3>Title: Beyond Tokens: Concept-Level Training Objectives for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Laya Iyer, Pranav Somani, Alice Guo, Dan Jurafsky, Chen Shani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11791">https://arxiv.org/abs/2601.11791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11791">https://arxiv.org/pdf/2601.11791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11791]] Beyond Tokens: Concept-Level Training Objectives for LLMs(https://arxiv.org/abs/2601.11791)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\rightarrow$ \textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.</li>
</ul>

<h3>Title: Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing</h3>
<ul>
<li><strong>Authors: </strong>Abdelrahman Ramadan, Zahra Dorbeigi Namaghi, Emily Taylor, Lucas Edwards, Xan Giuliani, David S. McLagan, Sidney Givigi, Melissa Greeff</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11794">https://arxiv.org/abs/2601.11794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11794">https://arxiv.org/pdf/2601.11794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11794]] Physics-Constrained Denoising Autoencoders for Data-Scarce Wildfire UAV Sensing(https://arxiv.org/abs/2601.11794)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Wildfire monitoring requires high-resolution atmospheric measurements, yet low-cost sensors on Unmanned Aerial Vehicles (UAVs) exhibit baseline drift, cross-sensitivity, and response lag that corrupt concentration estimates. Traditional deep learning denoising approaches demand large datasets impractical to obtain from limited UAV flight campaigns. We present PC$^2$DAE, a physics-informed denoising autoencoder that addresses data scarcity by embedding physical constraints directly into the network architecture. Non-negative concentration estimates are enforced via softplus activations and physically plausible temporal smoothing, ensuring outputs are physically admissible by construction rather than relying on loss function penalties. The architecture employs hierarchical decoder heads for Black Carbon, Gas, and CO$_2$ sensor families, with two variants: PC$^2$DAE-Lean (21k parameters) for edge deployment and PC$^2$DAE-Wide (204k parameters) for offline processing. We evaluate on 7,894 synchronized 1 Hz samples collected from UAV flights during prescribed burns in Saskatchewan, Canada (approximately 2.2 hours of flight data), two orders of magnitude below typical deep learning requirements. PC$^2$DAE-Lean achieves 67.3\% smoothness improvement and 90.7\% high-frequency noise reduction with zero physics violations. Five baselines (LSTM-AE, U-Net, Transformer, CBDAE, DeSpaWN) produce 15--23\% negative outputs. The lean variant outperforms wide (+5.6\% smoothness), suggesting reduced capacity with strong inductive bias prevents overfitting in data-scarce regimes. Training completes in under 65 seconds on consumer hardware.</li>
</ul>

<h3>Title: MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization</h3>
<ul>
<li><strong>Authors: </strong>Andrea Rubbi, Amir Akbarnejad, Mohammad Vali Sanian, Aryan Yazdan Parast, Hesam Asadollahzadeh, Arian Amani, Naveed Akhtar, Sarah Cooper, Andrew Bassett, Pietro Liò, Lassi Paavolainen, Sattar Vakili, Mo Lotfollahi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11827">https://arxiv.org/abs/2601.11827</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11827">https://arxiv.org/pdf/2601.11827</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11827]] MixFlow: Mixture-Conditioned Flow Matching for Out-of-Distribution Generalization(https://arxiv.org/abs/2601.11827)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Achieving robust generalization under distribution shift remains a central challenge in conditional generative modeling, as existing conditional flow-based methods often struggle to extrapolate beyond the training conditions. We introduce MixFlow, a conditional flow-matching framework for descriptor-controlled generation that directly targets this limitation by jointly learning a descriptor-conditioned base distribution and a descriptor-conditioned flow field via shortest-path flow matching. By modeling the base distribution as a learnable, descriptor-dependent mixture, MixFlow enables smooth interpolation and extrapolation to unseen conditions, leading to substantially improved out-of-distribution generalization. We provide analytical insights into the behavior of the proposed framework and empirically demonstrate its effectiveness across multiple domains, including prediction of responses to unseen perturbations in single-cell transcriptomic data and high-content microscopy-based drug screening tasks. Across these diverse settings, MixFlow consistently outperforms standard conditional flow-matching baselines. Overall, MixFlow offers a simple yet powerful approach for achieving robust, generalizable, and controllable generative modeling across heterogeneous domains.</li>
</ul>

<h3>Title: SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing</h3>
<ul>
<li><strong>Authors: </strong>Hao Lyu, Jingzheng Wu, Xiang Ling, Yicheng Zhong, Zhiyuan Li, Tianyue Luo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11838">https://arxiv.org/abs/2601.11838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11838">https://arxiv.org/pdf/2601.11838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11838]] SimFuzz: Similarity-guided Block-level Mutation for RISC-V Processor Fuzzing(https://arxiv.org/abs/2601.11838)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The Instruction Set Architecture (ISA) defines processor operations and serves as the interface between hardware and software. As an open ISA, RISC-V lowers the barriers to processor design and encourages widespread adoption, but also exposes processors to security risks such as functional bugs. Processor fuzzing is a powerful technique for automatically detecting these bugs. However, existing fuzzing methods suffer from two main limitations. First, their emphasis on redundant test case generation causes them to overlook cross-processor corner cases. Second, they rely too heavily on coverage guidance. Current coverage metrics are biased and inefficient, and become ineffective once coverage growth plateaus. To overcome these limitations, we propose SimFuzz, a fuzzing framework that constructs a high-quality seed corpus from historical bug-triggering inputs and employs similarity-guided, block-level mutation to efficiently explore the processor input space. By introducing instruction similarity, SimFuzz expands the input space around seeds while preserving control-flow structure, enabling deeper exploration without relying on coverage feedback. We evaluate SimFuzz on three widely used open-source RISC-V processors: Rocket, BOOM, and XiangShan, and discover 17 bugs in total, including 14 previously unknown issues, 7 of which have been assigned CVE identifiers. These bugs affect the decode and memory units, cause instruction and data errors, and can lead to kernel instability or system crashes. Experimental results show that SimFuzz achieves up to 73.22% multiplexer coverage on the high-quality seed corpus. Our findings highlight critical security bugs in mainstream RISC-V processors and offer actionable insights for improving functional verification.</li>
</ul>

<h3>Title: The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization</h3>
<ul>
<li><strong>Authors: </strong>Natalia Tomashenko, Xiaoxiao Miao, Pierre Champion, Sarina Meyer, Michele Panariello, Xin Wang, Nicholas Evans, Emmanuel Vincent, Junichi Yamagishi, Massimiliano Todisco</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11846">https://arxiv.org/abs/2601.11846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11846">https://arxiv.org/pdf/2601.11846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11846]] The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization(https://arxiv.org/abs/2601.11846)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.</li>
</ul>

<h3>Title: ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System</h3>
<ul>
<li><strong>Authors: </strong>Yifei Zhang, Hooshang Nayyeri, Rinat Khaziev, Emine Yilmaz, Gokhan Tur, Dilek Hakkani-Tür, Hari Thadakamalla</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11854">https://arxiv.org/abs/2601.11854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11854">https://arxiv.org/pdf/2601.11854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11854]] ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System(https://arxiv.org/abs/2601.11854)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.</li>
</ul>

<h3>Title: AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Li, Yuan Wu, Yi Chang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11864">https://arxiv.org/abs/2601.11864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11864">https://arxiv.org/pdf/2601.11864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11864]] AGGC: Adaptive Group Gradient Clipping for Stabilizing Large Language Model Training(https://arxiv.org/abs/2601.11864)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To stabilize the training of Large Language Models (LLMs), gradient clipping is a nearly ubiquitous heuristic used to alleviate exploding gradients. However, traditional global norm clipping erroneously presupposes gradient homogeneity across different functional modules, leading to an adverse "spill-over" effect where volatile parameters force unnecessary scaling on stable ones. To overcome this, we propose Adaptive Group-wise Gradient Clipping (AGGC). AGGC partitions parameters into groups based on functional types and regulates each according to its historical behavior using an Exponential Moving Average (EMA). Specifically, it constructs an adaptive interval to simultaneously mitigate gradient explosion and vanishing, while employing a time-dependent scheduling mechanism to balance exploration and convergence. Experiments on LLaMA 2-7B, Mistral-7B, and Gemma-7B models show that AGGC consistently outperforms LoRA and frequently surpasses Full Fine-Tuning. On the GSM8K benchmark, Mistral-7B fine-tuned with AGGC achieves an accuracy of 72.93%, exceeding LoRA's 69.5%. AGGC also effectively stabilizes Reinforcement Learning with Verifiable Rewards (RLVR), enhancing the logic deduction of Qwen 2.5 and Llama 3.2 models. Experimental results demonstrate that AGGC effectively addresses the limitations of traditional gradient clipping methods, particularly in overcoming gradient heterogeneity, by utilizing a modular, adaptive clipping strategy to stabilize the training process. Due to its lightweight design, AGGC can be seamlessly integrated into existing post-training pipelines with negligible overhead.</li>
</ul>

<h3>Title: Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving</h3>
<ul>
<li><strong>Authors: </strong>Kie Shidara, Preethi Prem, Jonathan Kim, Anna Podlasek, Feng Liu, Ahmed Alaa, Danilo Bernardo</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11866">https://arxiv.org/abs/2601.11866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11866">https://arxiv.org/pdf/2601.11866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11866]] Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving(https://arxiv.org/abs/2601.11866)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.</li>
</ul>

<h3>Title: TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures</h3>
<ul>
<li><strong>Authors: </strong>Yingxiao Zhang, Jiaxin Duan, Junfu Zhang, Ke Feng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11880">https://arxiv.org/abs/2601.11880</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11880">https://arxiv.org/pdf/2601.11880</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11880]] TF-CoDiT: Conditional Time Series Synthesis with Diffusion Transformers for Treasury Futures(https://arxiv.org/abs/2601.11880)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiT) have achieved milestones in synthesizing financial time-series data, such as stock prices and order flows. However, their performance in synthesizing treasury futures data is still underexplored. This work emphasizes the characteristics of treasury futures data, including its low volume, market dependencies, and the grouped correlations among multivariables. To overcome these challenges, we propose TF-CoDiT, the first DiT framework for language-controlled treasury futures synthesis. To facilitate low-data learning, TF-CoDiT adapts the standard DiT by transforming multi-channel 1-D time series into Discrete Wavelet Transform (DWT) coefficient matrices. A U-shape VAE is proposed to encode cross-channel dependencies hierarchically into a latent variable and bridge the latent and DWT spaces through decoding, thereby enabling latent diffusion generation. To derive prompts that cover essential conditions, we introduce the Financial Market Attribute Protocol (FinMAP) - a multi-level description system that standardizes daily$/$periodical market dynamics by recognizing 17$/$23 economic indicators from 7/8 perspectives. In our experiments, we gather four types of treasury futures data covering the period from 2015 to 2025, and define data synthesis tasks with durations ranging from one week to four months. Extensive evaluations demonstrate that TF-CoDiT can produce highly authentic data with errors at most 0.433 (MSE) and 0.453 (MAE) to the ground-truth. Further studies evidence the robustness of TF-CoDiT across contracts and temporal horizons.</li>
</ul>

<h3>Title: Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework</h3>
<ul>
<li><strong>Authors: </strong>Zimo Ji, Daoyuan Wu, Wenyuan Jiang, Pingchuan Ma, Zongjie Li, Yudong Gao, Shuai Wang, Yingjiu Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11893">https://arxiv.org/abs/2601.11893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11893">https://arxiv.org/pdf/2601.11893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11893]] Taming Various Privilege Escalation in LLM-Based Agent Systems: A Mandatory Access Control Framework(https://arxiv.org/abs/2601.11893)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM)-based agent systems are increasingly deployed for complex real-world tasks but remain vulnerable to natural language-based attacks that exploit over-privileged tool use. This paper aims to understand and mitigate such attacks through the lens of privilege escalation, defined as agent actions exceeding the least privilege required for a user's intended task. Based on a formal model of LLM agent systems, we identify novel privilege escalation scenarios, particularly in multi-agent systems, including a variant akin to the classic confused deputy problem. To defend against both known and newly demonstrated privilege escalation, we propose SEAgent, a mandatory access control (MAC) framework built upon attribute-based access control (ABAC). SEAgent monitors agent-tool interactions via an information flow graph and enforces customizable security policies based on entity attributes. Our evaluations show that SEAgent effectively blocks various privilege escalation while maintaining a low false positive rate and negligible system overhead. This demonstrates its robustness and adaptability in securing LLM-based agent systems.</li>
</ul>

<h3>Title: DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Pareesa Ameneh Golnari, Adarsh Kumarappan, Wen Wen, Xiaoyu Liu, Gabriel Ryan, Yuting Sun, Shengyu Fu, Elsie Nallipogu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11895">https://arxiv.org/abs/2601.11895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11895">https://arxiv.org/pdf/2601.11895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11895]] DevBench: A Realistic, Developer-Informed Benchmark for Code Generation Models(https://arxiv.org/abs/2601.11895)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>DevBench is a telemetry-driven benchmark designed to evaluate Large Language Models (LLMs) on realistic code completion tasks. It includes 1,800 evaluation instances across six programming languages and six task categories derived from real developer telemetry, such as API usage and code purpose understanding. Unlike prior benchmarks, it emphasizes ecological validity, avoids training data contamination, and enables detailed diagnostics. The evaluation combines functional correctness, similarity-based metrics, and LLM-judge assessments focused on usefulness and contextual relevance. 9 state-of-the-art models were assessed, revealing differences in syntactic precision, semantic reasoning, and practical utility. Our benchmark provides actionable insights to guide model selection and improvement-detail that is often missing from other benchmarks but is essential for both practical deployment and targeted model development.</li>
</ul>

<h3>Title: Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening</h3>
<ul>
<li><strong>Authors: </strong>Ngoc-Khai Hoang, Thi-Nhu-Mai Nguyen, Huy-Hieu Pham</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11896">https://arxiv.org/abs/2601.11896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11896">https://arxiv.org/pdf/2601.11896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11896]] Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening(https://arxiv.org/abs/2601.11896)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.</li>
</ul>

<h3>Title: Task-tailored Pre-processing: Fair Downstream Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Jinwon Sohn, Guang Lin, Qifan Song</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ME, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11897">https://arxiv.org/abs/2601.11897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11897">https://arxiv.org/pdf/2601.11897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11897]] Task-tailored Pre-processing: Fair Downstream Supervised Learning(https://arxiv.org/abs/2601.11897)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Fairness-aware machine learning has recently attracted various communities to mitigate discrimination against certain societal groups in data-driven tasks. For fair supervised learning, particularly in pre-processing, there have been two main categories: data fairness and task-tailored fairness. The former directly finds an intermediate distribution among the groups, independent of the type of the downstream model, so a learned downstream classification/regression model returns similar predictive scores to individuals inputting the same covariates irrespective of their sensitive attributes. The latter explicitly takes the supervised learning task into account when constructing the pre-processing map. In this work, we study algorithmic fairness for supervised learning and argue that the data fairness approaches impose overly strong regularization from the perspective of the HGR correlation. This motivates us to devise a novel pre-processing approach tailored to supervised learning. We account for the trade-off between fairness and utility in obtaining the pre-processing map. Then we study the behavior of arbitrary downstream supervised models learned on the transformed data to find sufficient conditions to guarantee their fairness improvement and utility preservation. To our knowledge, no prior work in the branch of task-tailored methods has theoretically investigated downstream guarantees when using pre-processed data. We further evaluate our framework through comparison studies based on tabular and image data sets, showing the superiority of our framework which preserves consistent trade-offs among multiple downstream models compared to recent competing models. Particularly for computer vision data, we see our method alters only necessary semantic features related to the central machine learning task to achieve fairness.</li>
</ul>

<h3>Title: RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection</h3>
<ul>
<li><strong>Authors: </strong>Yilmaz Korkmaz, Vishal M. Patel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11898">https://arxiv.org/abs/2601.11898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11898">https://arxiv.org/pdf/2601.11898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11898]] RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection(https://arxiv.org/abs/2601.11898)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{this https URL}{\underline{here}}.</li>
</ul>

<h3>Title: Towards Airborne Object Detection: A Deep Learning Analysis</h3>
<ul>
<li><strong>Authors: </strong>Prosenjit Chatterjee, ANK Zaman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11907">https://arxiv.org/abs/2601.11907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11907">https://arxiv.org/pdf/2601.11907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11907]] Towards Airborne Object Detection: A Deep Learning Analysis(https://arxiv.org/abs/2601.11907)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.</li>
</ul>

<h3>Title: PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Byeongjin Kim, Gyuwan Kim, Seo Yeon Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11908">https://arxiv.org/abs/2601.11908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11908">https://arxiv.org/pdf/2601.11908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11908]] PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning(https://arxiv.org/abs/2601.11908)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.</li>
</ul>

<h3>Title: A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Guiying Zhu, Bowen Yang, Yin Zhuang, Tong Zhang, Guanqun Wang, Zhihao Che, He Chen, Lianlin Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11910">https://arxiv.org/abs/2601.11910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11910">https://arxiv.org/pdf/2601.11910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11910]] A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection(https://arxiv.org/abs/2601.11910)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.</li>
</ul>

<h3>Title: Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ibrahim, Alfe Suny, MD Sakib Ul Islam, Md. Imran Hossain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11911">https://arxiv.org/abs/2601.11911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11911">https://arxiv.org/pdf/2601.11911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11911]] Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh(https://arxiv.org/abs/2601.11911)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.</li>
</ul>

<h3>Title: LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yichen Jiang, Peng Ye, Jiakang Yuan, Chongjun Tu, Lei Bai, Tao Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11913">https://arxiv.org/abs/2601.11913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11913">https://arxiv.org/pdf/2601.11913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11913]] LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding(https://arxiv.org/abs/2601.11913)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.</li>
</ul>

<h3>Title: From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection</h3>
<ul>
<li><strong>Authors: </strong>Chi Wang, Xinjue Hu, Boyu Wang, Ziwen He, Zhangjie Fu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11915">https://arxiv.org/abs/2601.11915</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11915">https://arxiv.org/pdf/2601.11915</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11915]] From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection(https://arxiv.org/abs/2601.11915)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.</li>
</ul>

<h3>Title: Enhancing LLM-Based Data Annotation with Error Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Zhen Xu, Vedant Khatri, Yijun Dai, Xiner Liu, Siyan Li, Xuanming Zhang, Renzhe Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11920">https://arxiv.org/abs/2601.11920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11920">https://arxiv.org/pdf/2601.11920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11920]] Enhancing LLM-Based Data Annotation with Error Decomposition(https://arxiv.org/abs/2601.11920)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.</li>
</ul>

<h3>Title: Deep learning-based neurodevelopmental assessment in preterm infants</h3>
<ul>
<li><strong>Authors: </strong>Lexin Ren, Jiamiao Lu, Weichuan Zhang, Benqing Wu, Tuo Wang, Yi Liao, Jiapan Guo, Changming Sun, Liang Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11944">https://arxiv.org/abs/2601.11944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11944">https://arxiv.org/pdf/2601.11944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11944]] Deep learning-based neurodevelopmental assessment in preterm infants(https://arxiv.org/abs/2601.11944)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: this https URL.</li>
</ul>

<h3>Title: Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal</h3>
<ul>
<li><strong>Authors: </strong>Haonan An, Guang Hua, Wei Du, Hangcheng Cao, Yihang Tao, Guowen Xu, Susanto Rahardja, Yuguang Fang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11952">https://arxiv.org/abs/2601.11952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11952">https://arxiv.org/pdf/2601.11952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11952]] Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal(https://arxiv.org/abs/2601.11952)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack, robust, extraction, watermark, generative</a></li>
<li><strong>Abstract: </strong>Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.</li>
</ul>

<h3>Title: Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence</h3>
<ul>
<li><strong>Authors: </strong>Yuyin Lu, Ziran Liang, Yanghui Rao, Wenqi Fan, Fu Lee Wang, Qing Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11956">https://arxiv.org/abs/2601.11956</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11956">https://arxiv.org/pdf/2601.11956</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11956]] Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence(https://arxiv.org/abs/2601.11956)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.</li>
</ul>

<h3>Title: PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Bingxuan Li, Jeonghwan Kim, Cheng Qian, Xiusi Chen, Eitan Anzenberg, Niran Kundapur, Heng Ji</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11957">https://arxiv.org/abs/2601.11957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11957">https://arxiv.org/pdf/2601.11957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11957]] PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning(https://arxiv.org/abs/2601.11957)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.</li>
</ul>

<h3>Title: $\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zecheng Tang, Baibei Ji, Ruoxi Sun, Haitian Wang, WangJie You, Zhang Yijun, Wenpeng Zhu, Ji Qi, Juntao Li, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11969">https://arxiv.org/abs/2601.11969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11969">https://arxiv.org/pdf/2601.11969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11969]] $\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models(https://arxiv.org/abs/2601.11969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.</li>
</ul>

<h3>Title: Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms</h3>
<ul>
<li><strong>Authors: </strong>S. M. Khalid Bin Zahid, Md. Rakibul Hasan Nishat, Abdul Hasib, Md. Rakibul Hasan, Md. Ashiqussalehin, Md. Sahadat Hossen Sajib, A. S. M. Ahsanul Sarkar Akib</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11970">https://arxiv.org/abs/2601.11970</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11970">https://arxiv.org/pdf/2601.11970</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11970]] Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms(https://arxiv.org/abs/2601.11970)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, biometric</a></li>
<li><strong>Abstract: </strong>Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.</li>
</ul>

<h3>Title: One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints</h3>
<ul>
<li><strong>Authors: </strong>Ren He (Tsinghua University), Yinliang Xu (Tsinghua University), Jinfeng Wang (Guangdong Power Grid Co.), Jeremy Watson (University of Canterbury), Jian Song (Tsinghua University)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11977">https://arxiv.org/abs/2601.11977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11977">https://arxiv.org/pdf/2601.11977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11977]] One-Shot Price Forecasting with Covariate-Guided Experts under Privacy Constraints(https://arxiv.org/abs/2601.11977)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Forecasting in power systems often involves multivariate time series with complex dependencies and strict privacy constraints across regions. Traditional forecasting methods require significant expert knowledge and struggle to generalize across diverse deployment scenarios. Recent advancements in pre-trained time series models offer new opportunities, but their zero-shot performance on domain-specific tasks remains limited. To address these challenges, we propose a novel MoE Encoder module that augments pretrained forecasting models by injecting a sparse mixture-of-experts layer between tokenization and encoding. This design enables two key capabilities: (1) trans forming multivariate forecasting into an expert-guided univariate task, allowing the model to effectively capture inter-variable relations, and (2) supporting localized training and lightweight parameter sharing in federated settings where raw data cannot be exchanged. Extensive experiments on public multivariate datasets demonstrate that MoE-Encoder significantly improves forecasting accuracy compared to strong baselines. We further simulate federated environments and show that transferring only MoE-Encoder parameters allows efficient adaptation to new regions, with minimal performance degradation. Our findings suggest that MoE-Encoder provides a scalable and privacy-aware extension to foundation time series models.</li>
</ul>

<h3>Title: Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection</h3>
<ul>
<li><strong>Authors: </strong>Jian Lang, Rongpei Hong, Ting Zhong, Yong Wang, Fan Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11981">https://arxiv.org/abs/2601.11981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11981">https://arxiv.org/pdf/2601.11981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11981]] Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection(https://arxiv.org/abs/2601.11981)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.</li>
</ul>

<h3>Title: Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Khaled Berkani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11987">https://arxiv.org/abs/2601.11987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11987">https://arxiv.org/pdf/2601.11987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11987]] Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis(https://arxiv.org/abs/2601.11987)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.</li>
</ul>

<h3>Title: DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset</h3>
<ul>
<li><strong>Authors: </strong>Yiming Li, Chen Cai, Tianyi Liu, Dan Lin, Wenqian Wang, Wenfei Liang, Bingbing Li, Kim-Hui Yap</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11990">https://arxiv.org/abs/2601.11990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11990">https://arxiv.org/pdf/2601.11990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11990]] DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset(https://arxiv.org/abs/2601.11990)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.</li>
</ul>

<h3>Title: MongoDB Injection Query Classification Model using MongoDB Log files as Training Data</h3>
<ul>
<li><strong>Authors: </strong>Shaunak Perni, Minal Shirodkar, Ramdas Karmalli</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DB, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11996">https://arxiv.org/abs/2601.11996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11996">https://arxiv.org/pdf/2601.11996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11996]] MongoDB Injection Query Classification Model using MongoDB Log files as Training Data(https://arxiv.org/abs/2601.11996)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>NoSQL Injection attacks are a class of cybersecurity attacks where an attacker sends a specifically engineered query to a NoSQL database which then performs an unauthorized operation. To defend against such attacks, rule based systems were initially developed but then were found to be ineffective to innovative injection attacks hence a model based approach was developed. Most model based detection systems, during testing gave exponentially positive results but were trained only on the query statement sent to the server. However due to the scarcity of data and class imbalances these model based systems were found to be not effective against all attacks in the real world. This paper explores classifying NoSQL injection attacks sent to a MongoDB server based on Log Data, and other extracted features excluding raw query statements. The log data was collected from a simulated attack on an empty MongoDB server which was then processed and explored. A discriminant analysis was carried out to determine statistically significant features to discriminate between injection and benign queries resulting in a dataset of significant features. Several Machine learning based classification models using an AutoML library, "FLAML", as well as 6 manually programmed models were trained on this dataset , which were then trained on 50 randomized samples of data, cross validated and evaluated. The study found that the best model was the "FLAML" library's "XGBoost limited depth" model with an accuracy of 71%.</li>
</ul>

<h3>Title: Hybrid IDS Using Signature-Based and Anomaly-Based Detection</h3>
<ul>
<li><strong>Authors: </strong>Messaouda Boutassetta, Amina Makhlouf, Newfel Messaoudi, Abdelmadjid Benmachiche, Ines Boutabia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.11998">https://arxiv.org/abs/2601.11998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.11998">https://arxiv.org/pdf/2601.11998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.11998]] Hybrid IDS Using Signature-Based and Anomaly-Based Detection(https://arxiv.org/abs/2601.11998)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Intrusion detection systems (IDS) are essential for protecting computer systems and networks against a wide range of cyber threats that continue to evolve over time. IDS are commonly categorized into two main types, each with its own strengths and limitations, such as difficulty in detecting previously unseen attacks and the tendency to generate high false positive rates. This paper presents a comprehensive survey and a conceptual overview of Hybrid IDS, which integrate signature-based and anomaly-based detection techniques to enhance attack detection capabilities. The survey examines recent research on Hybrid IDS, classifies existing models into functional categories, and discusses their advantages, limitations, and application domains, including financial systems, air traffic control, and social networks. In addition, recent trends in Hybrid IDS research, such as machine learning-based approaches and cloud-based deployments, are reviewed. Finally, this work outlines potential future research directions aimed at developing more cost-effective Hybrid IDS solutions with improved ability to detect emerging and sophisticated cyberattacks.</li>
</ul>

<h3>Title: SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine</h3>
<ul>
<li><strong>Authors: </strong>Yifei Chen, Ross Greer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12010">https://arxiv.org/abs/2601.12010</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12010">https://arxiv.org/pdf/2601.12010</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12010]] SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine(https://arxiv.org/abs/2601.12010)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.</li>
</ul>

<h3>Title: SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture</h3>
<ul>
<li><strong>Authors: </strong>Pavan Kumar Yata, Pediredla Pradeep, Goli Himanish, Swathi M</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12015">https://arxiv.org/abs/2601.12015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12015">https://arxiv.org/pdf/2601.12015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12015]] SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture(https://arxiv.org/abs/2601.12015)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.</li>
</ul>

<h3>Title: Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Chaowei Zhang, Xiansheng Luo, Zewei Zhang, Yi Zhu, Jipeng Qiang, Longwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12019">https://arxiv.org/abs/2601.12019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12019">https://arxiv.org/pdf/2601.12019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12019]] Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning(https://arxiv.org/abs/2601.12019)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.</li>
</ul>

<h3>Title: DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering</h3>
<ul>
<li><strong>Authors: </strong>Guillermo Figueroa-Araneda, Iris Diana Jimenez, Florian Hofherr, Manny Ko, Hector Andrade-Loarca, Daniel Cremers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12020">https://arxiv.org/abs/2601.12020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12020">https://arxiv.org/pdf/2601.12020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12020]] DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering(https://arxiv.org/abs/2601.12020)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs). We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss. Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.</li>
</ul>

<h3>Title: Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Alif Al Hakim, Alfan Farizki Wicaksono, Fajri Koto</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12033">https://arxiv.org/abs/2601.12033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12033">https://arxiv.org/pdf/2601.12033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12033]] Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection(https://arxiv.org/abs/2601.12033)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, fair, large language model</a></li>
<li><strong>Abstract: </strong>Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.</li>
</ul>

<h3>Title: Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ziyi Zhao, Chongming Gao, Yang Zhang, Haoyan Liu, Weinan Gan, Huifeng Guo, Yong Liu, Fuli Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12034">https://arxiv.org/abs/2601.12034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12034">https://arxiv.org/pdf/2601.12034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12034]] Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs(https://arxiv.org/abs/2601.12034)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.</li>
</ul>

<h3>Title: Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Xiaomei Zhang, Zhaoxi Zhang, Leo Yu Zhang, Yanjun Zhang, Guanhong Tao, Shirui Pan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12042">https://arxiv.org/abs/2601.12042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12042">https://arxiv.org/pdf/2601.12042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12042]] Less Is More -- Until It Breaks: Security Pitfalls of Vision Token Compression in Large Vision-Language Models(https://arxiv.org/abs/2601.12042)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Visual token compression is widely adopted to improve the inference efficiency of Large Vision-Language Models (LVLMs), enabling their deployment in latency-sensitive and resource-constrained scenarios. However, existing work has mainly focused on efficiency and performance, while the security implications of visual token compression remain largely unexplored. In this work, we first reveal that visual token compression substantially degrades the robustness of LVLMs: models that are robust under uncompressed inference become highly vulnerable once compression is enabled. These vulnerabilities are state-specific; failure modes emerge only in the compressed setting and completely disappear when compression is disabled, making them particularly hidden and difficult to diagnose. By analyzing the key stages of the compression process, we identify instability in token importance ranking as the primary cause of this robustness degradation. Small and imperceptible perturbations can significantly alter token rankings, leading the compression mechanism to mistakenly discard task-critical information and ultimately causing model failure. Motivated by this observation, we propose a Compression-Aware Attack to systematically study and exploit this vulnerability. CAA directly targets the token selection mechanism and induces failures exclusively under compressed inference. We further extend this approach to more realistic black-box settings and introduce Transfer CAA, where neither the target model nor the compression configuration is accessible. We further evaluate potential defenses and find that they provide only limited protection. Extensive experiments across models, datasets, and compression methods show that visual token compression significantly undermines robustness, revealing a previously overlooked efficiency-security trade-off.</li>
</ul>

<h3>Title: \textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions</h3>
<ul>
<li><strong>Authors: </strong>Chenchen Zhao, Muxi Chen, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12049">https://arxiv.org/abs/2601.12049</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12049">https://arxiv.org/pdf/2601.12049</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12049]] \textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions(https://arxiv.org/abs/2601.12049)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability</a></li>
<li><strong>Abstract: </strong>Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.</li>
</ul>

<h3>Title: A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models</h3>
<ul>
<li><strong>Authors: </strong>Weixin Ye, Wei Wang, Yahui Liu, Yue Song, Bin Ren, Wei Bi, Rita Cucchiara, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12051">https://arxiv.org/abs/2601.12051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12051">https://arxiv.org/pdf/2601.12051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12051]] A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models(https://arxiv.org/abs/2601.12051)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, federate, transformer</a></li>
<li><strong>Abstract: </strong>In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via this https URL</li>
</ul>

<h3>Title: Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Zaiyan Zhang, Jie Li, Shaowei Shi, Qiangqiang Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12052">https://arxiv.org/abs/2601.12052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12052">https://arxiv.org/pdf/2601.12052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12052]] Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation(https://arxiv.org/abs/2601.12052)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.</li>
</ul>

<h3>Title: Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Jinsook Lee, Kirk Vanacore, Zhuqian Zhou, Jeanine Grutter, Rene F. Kizilcec</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12061">https://arxiv.org/abs/2601.12061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12061">https://arxiv.org/pdf/2601.12061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12061]] Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation(https://arxiv.org/abs/2601.12061)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.</li>
</ul>

<h3>Title: Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification</h3>
<ul>
<li><strong>Authors: </strong>Xiaomei Yang, Xizhan Gao, Antai Liu, Kang Wei, Fa Zhu, Guang Feng, Xiaofeng Qu, Sijie Niu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12062">https://arxiv.org/abs/2601.12062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12062">https://arxiv.org/pdf/2601.12062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12062]] Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification(https://arxiv.org/abs/2601.12062)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.</li>
</ul>

<h3>Title: Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation</h3>
<ul>
<li><strong>Authors: </strong>Zijie Lou, Xiangwei Feng, Jiaxin Wang, Xiaochao Qu, Luoqi Liu, Ting Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12066">https://arxiv.org/abs/2601.12066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12066">https://arxiv.org/pdf/2601.12066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12066]] Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation(https://arxiv.org/abs/2601.12066)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.</li>
</ul>

<h3>Title: ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification</h3>
<ul>
<li><strong>Authors: </strong>VSS Tejaswi Abburi, Ananya Singhal, Saurabh J. Shigwan, Nitin Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12067">https://arxiv.org/abs/2601.12067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12067">https://arxiv.org/pdf/2601.12067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12067]] ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification(https://arxiv.org/abs/2601.12067)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.</li>
</ul>

<h3>Title: Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset</h3>
<ul>
<li><strong>Authors: </strong>Rowzatul Zannat, Abdullah Al Shafi, Abdul Muntakim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12068">https://arxiv.org/abs/2601.12068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12068">https://arxiv.org/pdf/2601.12068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12068]] Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset(https://arxiv.org/abs/2601.12068)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.</li>
</ul>

<h3>Title: CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation</h3>
<ul>
<li><strong>Authors: </strong>H. Jiang, Y. Sun, Z. Dong, T. Liu, Y. Gu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12076">https://arxiv.org/abs/2601.12076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12076">https://arxiv.org/pdf/2601.12076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12076]] CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation(https://arxiv.org/abs/2601.12076)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.</li>
</ul>

<h3>Title: Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization</h3>
<ul>
<li><strong>Authors: </strong>Linfeng Du, Ye Yuan, Zichen Zhao, Fuyuan Lyu, Emiliano Penaloza, Xiuying Chen, Zipeng Sun, Jikun Kang, Laurent Charlin, Xue Liu, Haolun Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12078">https://arxiv.org/abs/2601.12078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12078">https://arxiv.org/pdf/2601.12078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12078]] Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization(https://arxiv.org/abs/2601.12078)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.</li>
</ul>

<h3>Title: Toward Real-World High-Precision Image Matting and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Haipeng Zhou, Zhaohu Xing, Hongqiu Wang, Jun Ma, Ping Li, Lei Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12080">https://arxiv.org/abs/2601.12080</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12080">https://arxiv.org/pdf/2601.12080</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12080]] Toward Real-World High-Precision Image Matting and Segmentation(https://arxiv.org/abs/2601.12080)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.</li>
</ul>

<h3>Title: Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data</h3>
<ul>
<li><strong>Authors: </strong>Matej Mok, Lukáš Gajdošech, Michal Mesároš, Martin Madaras, Viktor Kocur</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12090">https://arxiv.org/abs/2601.12090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12090">https://arxiv.org/pdf/2601.12090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12090]] Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data(https://arxiv.org/abs/2601.12090)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.</li>
</ul>

<h3>Title: Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate</h3>
<ul>
<li><strong>Authors: </strong>Qian Tan, Lei Jiang, Yuting Zeng, Shuoyang Ding, Xiaohua Xu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12091">https://arxiv.org/abs/2601.12091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12091">https://arxiv.org/pdf/2601.12091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12091]] Mitigating Cultural Bias in LLMs via Multi-Agent Cultural Debate(https://arxiv.org/abs/2601.12091)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) exhibit systematic Western-centric bias, yet whether prompting in non-Western languages (e.g., Chinese) can mitigate this remains understudied. Answering this question requires rigorous evaluation and effective mitigation, but existing approaches fall short on both fronts: evaluation methods force outputs into predefined cultural categories without a neutral option, while mitigation relies on expensive multi-cultural corpora or agent frameworks that use functional roles (e.g., Planner--Critique) lacking explicit cultural representation. To address these gaps, we introduce CEBiasBench, a Chinese--English bilingual benchmark, and Multi-Agent Vote (MAV), which enables explicit ``no bias'' judgments. Using this framework, we find that Chinese prompting merely shifts bias toward East Asian perspectives rather than eliminating it. To mitigate such persistent bias, we propose Multi-Agent Cultural Debate (MACD), a training-free framework that assigns agents distinct cultural personas and orchestrates deliberation via a "Seeking Common Ground while Reserving Differences" strategy. Experiments demonstrate that MACD achieves 57.6% average No Bias Rate evaluated by LLM-as-judge and 86.0% evaluated by MAV (vs. 47.6% and 69.0% baseline using GPT-4o as backbone) on CEBiasBench and generalizes to the Arabic CAMeL benchmark, confirming that explicit cultural representation in agent frameworks is essential for cross-cultural fairness.</li>
</ul>

<h3>Title: Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding</h3>
<ul>
<li><strong>Authors: </strong>Hamidreza Sadeghi, Saeedeh Momtazi, Reza Safabakhsh</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12095">https://arxiv.org/abs/2601.12095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12095">https://arxiv.org/pdf/2601.12095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12095]] Neural Isomorphic Fields: A Transformer-based Algebraic Numerical Embedding(https://arxiv.org/abs/2601.12095)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural network models often face challenges when processing very small or very large numbers due to issues such as overflow, underflow, and unstable output variations. To mitigate these problems, we propose using embedding vectors for numbers instead of directly using their raw values. These embeddings aim to retain essential algebraic properties while preventing numerical instabilities. In this paper, we introduce, for the first time, a fixed-length number embedding vector that preserves algebraic operations, including addition, multiplication, and comparison, within the field of rational numbers. We propose a novel Neural Isomorphic Field, a neural abstraction of algebraic structures such as groups and fields. The elements of this neural field are embedding vectors that maintain algebraic structure during computations. Our experiments demonstrate that addition performs exceptionally well, achieving over 95 percent accuracy on key algebraic tests such as identity, closure, and associativity. In contrast, multiplication exhibits challenges, with accuracy ranging from 53 percent to 73 percent across various algebraic properties. These findings highlight the model's strengths in preserving algebraic properties under addition while identifying avenues for further improvement in handling multiplication.</li>
</ul>

<h3>Title: Large language models struggle with ethnographic text annotation</h3>
<ul>
<li><strong>Authors: </strong>Leonardo S. Goodall, Dor Shilton, Daniel A. Mullins, Harvey Whitehouse</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12099">https://arxiv.org/abs/2601.12099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12099">https://arxiv.org/pdf/2601.12099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12099]] Large language models struggle with ethnographic text annotation(https://arxiv.org/abs/2601.12099)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.</li>
</ul>

<h3>Title: Powerful Training-Free Membership Inference Against Autoregressive Language Models</h3>
<ul>
<li><strong>Authors: </strong>David Ilić, David Stanojević, Kostadin Cvejoski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12104">https://arxiv.org/abs/2601.12104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12104">https://arxiv.org/pdf/2601.12104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12104]] Powerful Training-Free Membership Inference Against Autoregressive Language Models(https://arxiv.org/abs/2601.12104)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at this https URL.</li>
</ul>

<h3>Title: Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling</h3>
<ul>
<li><strong>Authors: </strong>Richik Chakraborty, Lawrence Liu, Syed Hasnain</a></li>
<li><strong>Subjects: </strong>cs.CR, stat.AP, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12105">https://arxiv.org/abs/2601.12105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12105">https://arxiv.org/pdf/2601.12105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12105]] Privacy-Preserving Cohort Analytics for Personalized Health Platforms: A Differentially Private Framework with Stochastic Risk Modeling(https://arxiv.org/abs/2601.12105)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Personalized health analytics increasingly rely on population benchmarks to provide contextual insights such as ''How do I compare to others like me?'' However, cohort-based aggregation of health data introduces nontrivial privacy risks, particularly in interactive and longitudinal digital platforms. Existing privacy frameworks such as $k$-anonymity and differential privacy provide essential but largely static guarantees that do not fully capture the cumulative, distributional, and tail-dominated nature of re-identification risk in deployed systems. In this work, we present a privacy-preserving cohort analytics framework that combines deterministic cohort constraints, differential privacy mechanisms, and synthetic baseline generation to enable personalized population comparisons while maintaining strong privacy protections. We further introduce a stochastic risk modeling approach that treats re-identification risk as a random variable evolving over time, enabling distributional evaluation through Monte Carlo simulation. Adapting quantitative risk measures from financial mathematics, we define Privacy Loss at Risk (P-VaR) to characterize worst-case privacy outcomes under realistic cohort dynamics and adversary assumptions. We validate our framework through system-level analysis and simulation experiments, demonstrating how privacy-utility tradeoffs can be operationalized for digital health platforms. Our results suggest that stochastic risk modeling complements formal privacy guarantees by providing interpretable, decision-relevant metrics for platform designers, regulators, and clinical informatics stakeholders.</li>
</ul>

<h3>Title: RCDN: Real-Centered Detection Network for Robust Face Forgery Identification</h3>
<ul>
<li><strong>Authors: </strong>Wyatt McCurdy, Xin Zhang, Yuqi Song, Min Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12111">https://arxiv.org/abs/2601.12111</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12111">https://arxiv.org/pdf/2601.12111</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12111]] RCDN: Real-Centered Detection Network for Robust Face Forgery Identification(https://arxiv.org/abs/2601.12111)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.</li>
</ul>

<h3>Title: SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Bing Hu, Yixin Li, Asma Bahamyirou, Helen Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12124">https://arxiv.org/abs/2601.12124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12124">https://arxiv.org/pdf/2601.12124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12124]] SynQP: A Framework and Metrics for Evaluating the Quality and Privacy Risk of Synthetic Data(https://arxiv.org/abs/2601.12124)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, fair</a></li>
<li><strong>Abstract: </strong>The use of synthetic data in health applications raises privacy concerns, yet the lack of open frameworks for privacy evaluations has slowed its adoption. A major challenge is the absence of accessible benchmark datasets for evaluating privacy risks, due to difficulties in acquiring sensitive data. To address this, we introduce SynQP, an open framework for benchmarking privacy in synthetic data generation (SDG) using simulated sensitive data, ensuring that original data remains confidential. We also highlight the need for privacy metrics that fairly account for the probabilistic nature of machine learning models. As a demonstration, we use SynQP to benchmark CTGAN and propose a new identity disclosure risk metric that offers a more accurate estimation of privacy risks compared to existing approaches. Our work provides a critical tool for improving the transparency and reliability of privacy evaluations, enabling safer use of synthetic data in health-related applications. % In our quality evaluations, non-private models achieved near-perfect machine-learning efficacy \(\ge0.97\). Our privacy assessments (Table II) reveal that DP consistently lowers both identity disclosure risk (SD-IDR) and membership-inference attack risk (SD-MIA), with all DP-augmented models staying below the 0.09 regulatory threshold. Code available at this https URL</li>
</ul>

<h3>Title: SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics</h3>
<ul>
<li><strong>Authors: </strong>Santosh Chapagain, MohammadReza EskandariNasab, Onur Vural, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12131">https://arxiv.org/abs/2601.12131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12131">https://arxiv.org/pdf/2601.12131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12131]] SolarGPT-QA: A Domain-Adaptive Large Language Model for Educational Question Answering in Space Weather and Heliophysics(https://arxiv.org/abs/2601.12131)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Solar activity, including solar flares, coronal mass ejections (CMEs), and geomagnetic storms, can significantly impact satellites, aviation, power grids, data centers, and space missions. Extreme solar events can cause substantial economic damage if not predicted in advance, highlighting the importance of accurate forecasting and effective education in space science. Although large language models (LLMs) perform well on general tasks, they often lack domain-specific knowledge and pedagogical capability to clearly explain complex space science concepts. We introduce SolarGPT-QA, a question answering system based on a domain-adapted large language model built on the LLaMA-3 base model. The model is trained using scientific literature and large-scale question-answer data generated with GPT-4 and refined using Grok-3 in a student-friendly storytelling style. Human pairwise evaluations show that SolarGPT-QA outperforms general-purpose models in zero-shot settings and achieves competitive performance compared to instruction-tuned models for educational explanations in space weather and heliophysics. A small pilot student comprehension study further suggests improved clarity and accessibility of the generated explanations. Ablation experiments indicate that combining domain-adaptive pretraining with pedagogical fine-tuning is important for balancing scientific accuracy and educational effectiveness. This work represents an initial step toward a broader SolarGPT framework for space science education and forecasting.</li>
</ul>

<h3>Title: Bengali Text Classification: An Evaluation of Large Language Model Approaches</h3>
<ul>
<li><strong>Authors: </strong>Md Mahmudul Hoque, Md Mehedi Hassain, Md Hojaifa Tanvir, Rahul Nandy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12132">https://arxiv.org/abs/2601.12132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12132">https://arxiv.org/pdf/2601.12132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12132]] Bengali Text Classification: An Evaluation of Large Language Model Approaches(https://arxiv.org/abs/2601.12132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the "Sports" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.</li>
</ul>

<h3>Title: CoSMeTIC: Zero-Knowledge Computational Sparse Merkle Trees with Inclusion-Exclusion Proofs for Clinical Research</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Shahid, Paritosh Ramanan, Mohammad Fili, Guiping Hu, Hillel Haim</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12136">https://arxiv.org/abs/2601.12136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12136">https://arxiv.org/pdf/2601.12136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12136]] CoSMeTIC: Zero-Knowledge Computational Sparse Merkle Trees with Inclusion-Exclusion Proofs for Clinical Research(https://arxiv.org/abs/2601.12136)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Analysis of clinical data is a cornerstone of biomedical research with applications in areas such as genomic testing and response characterization of therapeutic drugs. Maintaining strict privacy controls is essential because such data typically contains personally identifiable health information of patients. At the same time, regulatory compliance often requires study managers to demonstrate the integrity and authenticity of participant data used in analyses. Balancing these competing requirements, privacy preservation and verifiable accountability, remains a critical challenge. In this paper, we present CoSMeTIC, a zero-knowledge computational framework that proposes computational Sparse Merkle Trees (SMTs) as a means to generate verifiable inclusion and exclusion proofs for individual participants' data in clinical studies. We formally analyze the zero-knowledge properties of CoSMeTIC and evaluate its computational efficiency through extensive experiments. Using the Kolmogorov-Smirnov and likelihood-ratio hypothesis tests, along with logistic-regression-based genomic analyses on real-world Huntington's disease datasets, we demonstrate that CoSMeTIC achieves strong privacy guarantees while maintaining statistical fidelity. Our results suggest that CoSMeTIC provides a scalable and practical alternative for achieving regulatory compliance with rigorous privacy protection in large-scale clinical research.</li>
</ul>

<h3>Title: Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xingyue Huang, Xueying Ding, Mingxuan Ju, Yozen Liu, Neil Shah, Tong Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12145">https://arxiv.org/abs/2601.12145</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12145">https://arxiv.org/pdf/2601.12145</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12145]] Threshold Differential Attention for Sink-Free, Ultra-Sparse, and Non-Dispersive Language Modeling(https://arxiv.org/abs/2601.12145)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Softmax attention struggles with long contexts due to structural limitations: the strict sum-to-one constraint forces attention sinks on irrelevant tokens, and probability mass disperses as sequence lengths increase. We tackle these problems with Threshold Differential Attention (TDA), a sink-free attention mechanism that achieves ultra-sparsity and improved robustness at longer sequence lengths without the computational overhead of projection methods or the performance degradation caused by noise accumulation of standard rectified attention. TDA applies row-wise extreme-value thresholding with a length-dependent gate, retaining only exceedances. Inspired by the differential transformer, TDA also subtracts an inhibitory view to enhance expressivity. Theoretically, we prove that TDA controls the expected number of spurious survivors per row to $O(1)$ and that consensus spurious matches across independent views vanish as context grows. Empirically, TDA produces $>99\%$ exact zeros and eliminates attention sinks while maintaining competitive performance on standard and long-context benchmarks.</li>
</ul>

<h3>Title: Segment and Matte Anything in a Unified Model</h3>
<ul>
<li><strong>Authors: </strong>Zezhong Fan, Xiaohan Li, Topojoy Biswas, Kaushiki Nag, Kannan Achan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12147">https://arxiv.org/abs/2601.12147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12147">https://arxiv.org/pdf/2601.12147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12147]] Segment and Matte Anything in a Unified Model(https://arxiv.org/abs/2601.12147)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.</li>
</ul>

<h3>Title: Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Mengxuan Hu, Zihan Guan, John Kang, Sheng Li, Zhongliang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12150">https://arxiv.org/abs/2601.12150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12150">https://arxiv.org/pdf/2601.12150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12150]] Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models(https://arxiv.org/abs/2601.12150)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.</li>
</ul>

<h3>Title: Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Teodor-Călin Ionescu, Lifeng Han, Jan Heijdra Suasnabar, Anne Stiggelbout, Suzan Verberne</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12154">https://arxiv.org/abs/2601.12154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12154">https://arxiv.org/pdf/2601.12154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12154]] Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs(https://arxiv.org/abs/2601.12154)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair, interpretability</a></li>
<li><strong>Abstract: </strong>This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \textit{precision} and \textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.</li>
</ul>

<h3>Title: Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors</h3>
<ul>
<li><strong>Authors: </strong>Xiang Gao, Xinmu Wang, Yuanpeng Liu, Yue Wang, Junqi Huang, Wei Chen, Xianfeng Gu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12155">https://arxiv.org/abs/2601.12155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12155">https://arxiv.org/pdf/2601.12155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12155]] Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors(https://arxiv.org/abs/2601.12155)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.</li>
</ul>

<h3>Title: Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses</h3>
<ul>
<li><strong>Authors: </strong>Fallou Niakh</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12178">https://arxiv.org/abs/2601.12178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12178">https://arxiv.org/pdf/2601.12178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12178]] Federated Learning for the Design of Parametric Insurance Indices under Heterogeneous Renewable Production Losses(https://arxiv.org/abs/2601.12178)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We propose a federated learning framework for the calibration of parametric insurance indices under heterogeneous renewable energy production losses. Producers locally model their losses using Tweedie generalized linear models and private data, while a common index is learned through federated optimization without sharing raw observations. The approach accommodates heterogeneity in variance and link functions and directly minimizes a global deviance objective in a distributed setting. We implement and compare FedAvg, FedProx and FedOpt, and benchmark them against an existing approximation-based aggregation method. An empirical application to solar power production in Germany shows that federated learning recovers comparable index coefficients under moderate heterogeneity, while providing a more general and scalable framework.</li>
</ul>

<h3>Title: Tolerance Principle and Small Language Model Learning</h3>
<ul>
<li><strong>Authors: </strong>Adam E. Friedman, Stevan Harnad, Rushen Shi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12179">https://arxiv.org/abs/2601.12179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12179">https://arxiv.org/pdf/2601.12179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12179]] Tolerance Principle and Small Language Model Learning(https://arxiv.org/abs/2601.12179)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.</li>
</ul>

<h3>Title: CTC-DID: CTC-Based Arabic dialect identification for streaming applications</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Umar Farooq, Oscar Saz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12199">https://arxiv.org/abs/2601.12199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12199">https://arxiv.org/pdf/2601.12199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12199]] CTC-DID: CTC-Based Arabic dialect identification for streaming applications(https://arxiv.org/abs/2601.12199)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.</li>
</ul>

<h3>Title: Speculative Sampling with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Chenan Wang, Daniel H. Shi, Haipeng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12212">https://arxiv.org/abs/2601.12212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12212">https://arxiv.org/pdf/2601.12212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12212]] Speculative Sampling with Reinforcement Learning(https://arxiv.org/abs/2601.12212)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Inference time latency has remained an open challenge for real world applications of large language models (LLMs). State-of-the-art (SOTA) speculative sampling (SpS) methods for LLMs, like EAGLE-3, use tree-based drafting to explore multiple candidate continuations in parallel. However, the hyperparameters controlling the tree structure are static, which limits flexibility and efficiency across diverse contexts and domains. We introduce Reinforcement learning for Speculative Sampling (Re-SpS), the first reinforcement learning (RL)-based framework for draft tree hyperparameter optimization. Re-SpS dynamically adjusts draft tree hyperparameters in real-time, learning context-aware policies that maximize generation speed by balancing speculative aggression with computational overhead. It leverages efficient state representations from target model hidden states and introduces multi-step action persistence for better context modeling. Evaluation results across five diverse benchmarks demonstrate consistent improvements over the SOTA method EAGLE-3, achieving up to 5.45$\times$ speedup over the backbone LLM and up to 1.12$\times$ speedup compared to EAGLE-3 across five diverse benchmarks, with no loss in output fidelity.</li>
</ul>

<h3>Title: Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Megha Thukral, Cyrus Tanade, Simon A. Lee, Juhyeon Lee, Hao Zhou, Keum San Chun, Migyeong Gwak, Viswam Nathan, Md Mahbubur Rahman, Li Zhu, Mehrab Bin Morshed, Subramaniam Venkatraman, Sharanya Arcot Desai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12215">https://arxiv.org/abs/2601.12215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12215">https://arxiv.org/pdf/2601.12215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12215]] Wavelet-Driven Masked Multiscale Reconstruction for PPG Foundation Models(https://arxiv.org/abs/2601.12215)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Wearable foundation models have the potential to transform digital health by learning transferable representations from large-scale biosignals collected in everyday settings. While recent progress has been made in large-scale pretraining, most approaches overlook the spectral structure of photoplethysmography (PPG) signals, wherein physiological rhythms unfold across multiple frequency bands. Motivated by the insight that many downstream health-related tasks depend on multi-resolution features spanning fine-grained waveform morphology to global rhythmic dynamics, we introduce Masked Multiscale Reconstruction (MMR) for PPG representation learning - a self-supervised pretraining framework that explicitly learns from hierarchical time-frequency scales of PPG data. The pretraining task is designed to reconstruct randomly masked out coefficients obtained from a wavelet-based multiresolution decomposition of PPG signals, forcing the transformer encoder to integrate information across temporal and spectral scales. We pretrain our model with MMR using ~17 million unlabeled 10-second PPG segments from ~32,000 smartwatch users. On 17 of 19 diverse health-related tasks, MMR trained on large-scale wearable PPG data improves over or matches state-of-the-art open-source PPG foundation models, time-series foundation models, and other self-supervised baselines. Extensive analysis of our learned embeddings and systematic ablations underscores the value of wavelet-based representations, showing that they capture robust and physiologically-grounded features. Together, these results highlight the potential of MMR as a step toward generalizable PPG foundation models.</li>
</ul>

<h3>Title: Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion</h3>
<ul>
<li><strong>Authors: </strong>Meng Wei, Kun Yuan, Shi Li, Yue Zhou, Long Bai, Nassir Navab, Hongliang Ren, Hong Joo Lee, Tom Vercauteren, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12224">https://arxiv.org/abs/2601.12224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12224">https://arxiv.org/pdf/2601.12224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12224]] Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion(https://arxiv.org/abs/2601.12224)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.</li>
</ul>

<h3>Title: Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention</h3>
<ul>
<li><strong>Authors: </strong>Kaichuan Kong, Dongjie Liu, Xiaobo Jin, Shijie Xu, Guanggang Geng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12231">https://arxiv.org/abs/2601.12231</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12231">https://arxiv.org/pdf/2601.12231</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12231]] Wavelet-Aware Anomaly Detection in Multi-Channel User Logs via Deviation Modulation and Resolution-Adaptive Attention(https://arxiv.org/abs/2601.12231)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust</a></li>
<li><strong>Abstract: </strong>Insider threat detection is a key challenge in enterprise security, relying on user activity logs that capture rich and complex behavioral patterns. These logs are often multi-channel, non-stationary, and anomalies are rare, making anomaly detection challenging. To address these issues, we propose a novel framework that integrates wavelet-aware modulation, multi-resolution wavelet decomposition, and resolution-adaptive attention for robust anomaly detection. Our approach first applies a deviation-aware modulation scheme to suppress routine behaviors while amplifying anomalous deviations. Next, discrete wavelet transform (DWT) decomposes the log signals into multi-resolution representations, capturing both long-term trends and short-term anomalies. Finally, a learnable attention mechanism dynamically reweights the most discriminative frequency bands for detection. On the CERT r4.2 benchmark, our approach consistently outperforms existing baselines in precision, recall, and F1 score across various time granularities and scenarios.</li>
</ul>

<h3>Title: DiffusionQC: Artifact Detection in Histopathology via Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Zhenzhen Wang, Zhongliang Zhou, Zhuoyu Wen, Jeong Hwan Kook, John B Wojcik, John Kang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12233">https://arxiv.org/abs/2601.12233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12233">https://arxiv.org/pdf/2601.12233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12233]] DiffusionQC: Artifact Detection in Histopathology via Diffusion Model(https://arxiv.org/abs/2601.12233)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.</li>
</ul>

<h3>Title: Less is More: Label-Guided Summarization of Procedural and Instructional Videos</h3>
<ul>
<li><strong>Authors: </strong>Shreya Rajpal, Michal Golovanesky, Carsten Eickhoff</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12243">https://arxiv.org/abs/2601.12243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12243">https://arxiv.org/pdf/2601.12243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12243]] Less is More: Label-Guided Summarization of Procedural and Instructional Videos(https://arxiv.org/abs/2601.12243)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.</li>
</ul>

<h3>Title: Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Miao Li, Hanyang Jiang, Sikai Chen, Hengyu Fu, Yuhang Cai, Baihe Huang, Tinghan Ye, Xuanzhou Chen, Pascal Van Hentenryck</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12247">https://arxiv.org/abs/2601.12247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12247">https://arxiv.org/pdf/2601.12247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12247]] Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models(https://arxiv.org/abs/2601.12247)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.</li>
</ul>

<h3>Title: An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Sadeghi Pour, Mahdi Esmaeili, Morteza Romoozi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12249">https://arxiv.org/abs/2601.12249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12249">https://arxiv.org/pdf/2601.12249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12249]] An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion(https://arxiv.org/abs/2601.12249)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.</li>
</ul>

<h3>Title: Federated Joint Learning for Domain and Class Generalization</h3>
<ul>
<li><strong>Authors: </strong>Haoran Xu, Jiaze Li, Jianzhong Ju, Zhenbo Luo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12253">https://arxiv.org/abs/2601.12253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12253">https://arxiv.org/pdf/2601.12253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12253]] Federated Joint Learning for Domain and Class Generalization(https://arxiv.org/abs/2601.12253)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate</a></li>
<li><strong>Abstract: </strong>Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.</li>
</ul>

<h3>Title: Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy</h3>
<ul>
<li><strong>Authors: </strong>Fadlullah Raji, John Murray-Bruce</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CG, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12257">https://arxiv.org/abs/2601.12257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12257">https://arxiv.org/pdf/2601.12257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12257]] Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy(https://arxiv.org/abs/2601.12257)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.</li>
</ul>

<h3>Title: Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Du, Chenxiao Yu, Haoyan Xu, Ziyi Wang, Yue Zhao, Xiyang Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12263">https://arxiv.org/abs/2601.12263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12263">https://arxiv.org/pdf/2601.12263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12263]] Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers(https://arxiv.org/abs/2601.12263)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, fair, generative</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.</li>
</ul>

<h3>Title: SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels</h3>
<ul>
<li><strong>Authors: </strong>Reshabh K Sharma, Dan Grossman, David Kohlbrenner</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.PL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12270">https://arxiv.org/abs/2601.12270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12270">https://arxiv.org/pdf/2601.12270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12270]] SplittingSecrets: A Compiler-Based Defense for Preventing Data Memory-Dependent Prefetcher Side-Channels(https://arxiv.org/abs/2601.12270)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Traditional side-channels take advantage of secrets being used as inputs to unsafe instructions, used for memory accesses, or used in control flow decisions. Constant-time programming, which restricts such code patterns, has been widely adopted as a defense against these vulnerabilities. However, new hardware optimizations in the form of Data Memory-dependent Prefetchers (DMP) present in Apple, Intel, and ARM CPUs have shown such defenses are not sufficient. These prefetchers, unlike classical prefetchers, use the content of memory as well as the trace of prior accesses to determine prefetch targets. An adversary abusing such a prefetcher has been shown to be able to mount attacks leaking data-at-rest; data that is never used by the program, even speculatively, in an unsafe manner. In response, this paper introduces SplittingSecrets, a compiler-based tool that can harden software libraries against side-channels arising from DMPs. SplittingSecrets's approach avoids reasoning about the complex internals of different DMPs and instead relies on one key aspect of all DMPs: activation requires data to resemble addresses. To prevent secret data from leaking, SplittingSecrets transforms memory operations to ensure that secrets are never stored in memory in a manner resembling an address, thereby avoiding DMP activation on those secrets. Rather than disable a DMP entirely, SplittingSecrets can provide targeted hardening for only specific secrets entirely in software. We have implemented SplittingSecrets using LLVM, supporting both source-level memory operations and those generated by the compiler backend for the AArch64 architecture, We have analyzed the performance overhead involved in safeguarding secrets from DMP-induced attacks using common primitives in libsodium, a popular cryptographic library when built for Apple M-series CPUs.</li>
</ul>

<h3>Title: AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search</h3>
<ul>
<li><strong>Authors: </strong>Shahrzad Esmat, Mahdi Banisharif, Ali Jannesari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12272">https://arxiv.org/abs/2601.12272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12272">https://arxiv.org/pdf/2601.12272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12272]] AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search(https://arxiv.org/abs/2601.12272)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands. We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.</li>
</ul>

<h3>Title: SDiT: Semantic Region-Adaptive for Diffusion Transformers</h3>
<ul>
<li><strong>Authors: </strong>Bowen Lin, Fanjiang Ye, Yihua Liu, Zhenghui Guo, Boyuan Zhang, Weijian Zheng, Yufan Xu, Tiancheng Xing, Yuke Wang, Chengming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12283">https://arxiv.org/abs/2601.12283</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12283">https://arxiv.org/pdf/2601.12283</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12283]] SDiT: Semantic Region-Adaptive for Diffusion Transformers(https://arxiv.org/abs/2601.12283)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.</li>
</ul>

<h3>Title: Conversational Context Classification: A Representation Engineering Approach</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12286">https://arxiv.org/abs/2601.12286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12286">https://arxiv.org/pdf/2601.12286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12286]] Conversational Context Classification: A Representation Engineering Approach(https://arxiv.org/abs/2601.12286)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.</li>
</ul>

<h3>Title: Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations</h3>
<ul>
<li><strong>Authors: </strong>Shizhan Gong, Xiaofan Zhang, Qi Dou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12303">https://arxiv.org/abs/2601.12303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12303">https://arxiv.org/pdf/2601.12303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12303]] Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations(https://arxiv.org/abs/2601.12303)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.</li>
</ul>

<h3>Title: A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models</h3>
<ul>
<li><strong>Authors: </strong>Wutao Chen, Huaqin Zou, Chen Wan, Lifeng Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12304">https://arxiv.org/abs/2601.12304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12304">https://arxiv.org/pdf/2601.12304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12304]] A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models(https://arxiv.org/abs/2601.12304)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.</li>
</ul>

<h3>Title: Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Anurag Kaushish, Ayan Sar, Sampurna Roy, Sudeshna Chakraborty, Prashant Trivedi, Tanupriya Choudhury, Kanav Gupta</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12308">https://arxiv.org/abs/2601.12308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12308">https://arxiv.org/pdf/2601.12308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12308]] Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification(https://arxiv.org/abs/2601.12308)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.</li>
</ul>

<h3>Title: CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding</h3>
<ul>
<li><strong>Authors: </strong>Yongjun Jeon, Jongmin Shin, Kanggil Park, Seonmin Park, Soyoung Lim, Jung Yong Kim, Jinsoo Rhu, Jongman Kim, Gyu-Seong Choi, Namkee Oh, Kyu-Hwan Jung</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12312">https://arxiv.org/abs/2601.12312</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12312">https://arxiv.org/pdf/2601.12312</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12312]] CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding(https://arxiv.org/abs/2601.12312)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.</li>
</ul>

<h3>Title: S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Hu, Yicheng Hong, Hongchuang Zheng, Wenjun Zeng, Bingyao Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12313">https://arxiv.org/abs/2601.12313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12313">https://arxiv.org/pdf/2601.12313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12313]] S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection(https://arxiv.org/abs/2601.12313)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral this http URL the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.</li>
</ul>

<h3>Title: GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer</h3>
<ul>
<li><strong>Authors: </strong>Xinyuan Zhao, Xianrui Chen, Ahmad Chaddad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12316">https://arxiv.org/abs/2601.12316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12316">https://arxiv.org/pdf/2601.12316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12316]] GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer(https://arxiv.org/abs/2601.12316)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.</li>
</ul>

<h3>Title: Multi-Sensor Matching with HyperNetworks</h3>
<ul>
<li><strong>Authors: </strong>Eli Passov, Nathan S. Netanyahu, Yosi Keller</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12325">https://arxiv.org/abs/2601.12325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12325">https://arxiv.org/pdf/2601.12325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12325]] Multi-Sensor Matching with HyperNetworks(https://arxiv.org/abs/2601.12325)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.</li>
</ul>

<h3>Title: IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Zuha Fatima, Muhammad Anser Sohaib, Muhammad Talha, Ayesha Kanwal, Sidra Sultana, Nazia Perwaiz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12330">https://arxiv.org/abs/2601.12330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12330">https://arxiv.org/pdf/2601.12330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12330]] IceWatch: Forecasting Glacial Lake Outburst Floods (GLOFs) using Multimodal Deep Learning(https://arxiv.org/abs/2601.12330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Glacial Lake Outburst Floods (GLOFs) pose a serious threat in high mountain regions. They are hazardous to communities, infrastructure, and ecosystems further downstream. The classical methods of GLOF detection and prediction have so far mainly relied on hydrological modeling, threshold-based lake monitoring, and manual satellite image analysis. These approaches suffer from several drawbacks: slow updates, reliance on manual labor, and losses in accuracy when clouds interfere and/or lack on-site data. To tackle these challenges, we present IceWatch: a novel deep learning framework for GLOF prediction that incorporates both spatial and temporal perspectives. The vision component, RiskFlow, of IceWatch deals with Sentinel-2 multispectral satellite imagery using a CNN-based classifier and predicts GLOF events based on the spatial patterns of snow, ice, and meltwater. Its tabular counterpart confirms this prediction by considering physical dynamics. TerraFlow models glacier velocity from NASA ITS_LIVE time series while TempFlow forecasts near-surface temperature from MODIS LST records; both are trained on long-term observational archives and integrated via harmonized preprocessing and synchronization to enable multimodal, physics-informed GLOF prediction. Both together provide cross-validation, which will improve the reliability and interpretability of GLOF detection. This system ensures strong predictive performance, rapid data processing for real-time use, and robustness to noise and missing information. IceWatch paves the way for automatic, scalable GLOF warning systems. It also holds potential for integration with diverse sensor inputs and global glacier monitoring activities.</li>
</ul>

<h3>Title: Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption</h3>
<ul>
<li><strong>Authors: </strong>Huanyi Ye, Jiale Guo, Ziyao Liu, Kwok-Yan Lam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12331">https://arxiv.org/abs/2601.12331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12331">https://arxiv.org/pdf/2601.12331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12331]] Efficient Privacy-Preserving Retrieval Augmented Generation with Distance-Preserving Encryption(https://arxiv.org/abs/2601.12331)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack</a></li>
<li><strong>Abstract: </strong>RAG has emerged as a key technique for enhancing response quality of LLMs without high computational cost. In traditional architectures, RAG services are provided by a single entity that hosts the dataset within a trusted local environment. However, individuals or small organizations often lack the resources to maintain data storage servers, leading them to rely on outsourced cloud storage. This dependence on untrusted third-party services introduces privacy risks. Embedding-based retrieval mechanisms, commonly used in RAG systems, are vulnerable to privacy leakage such as vector-to-text reconstruction attacks and structural leakage via vector analysis. Several privacy-preserving RAG techniques have been proposed but most existing approaches rely on partially homomorphic encryption, which incurs substantial computational overhead. To address these challenges, we propose an efficient privacy-preserving RAG framework (ppRAG) tailored for untrusted cloud environments that defends against vector-to-text attack, vector analysis, and query analysis. We propose Conditional Approximate Distance-Comparison-Preserving Symmetric Encryption (CAPRISE) that encrypts embeddings while still allowing the cloud to compute similarity between an encrypted query and the encrypted database embeddings. CAPRISE preserves only the relative distance ordering between the encrypted query and each encrypted database embedding, without exposing inter-database distances, thereby enhancing both privacy and efficiency. To mitigate query analysis, we introduce DP by perturbing the query embedding prior to encryption, preventing the cloud from inferring sensitive patterns. Experimental results show that ppRAG achieves efficient processing throughput, high retrieval accuracy, strong privacy guarantees, making it a practical solution for resource-constrained users seeking secure cloud-augmented LLMs.</li>
</ul>

<h3>Title: Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?</h3>
<ul>
<li><strong>Authors: </strong>Yi Qian, Kunwei Qian, Xingbang He, Ligeng Chen, Jikang Zhang, Tiantai Zhang, Haiyang Wei, Linzhang Wang, Hao Wu, Bing Mao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12349">https://arxiv.org/abs/2601.12349</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12349">https://arxiv.org/pdf/2601.12349</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12349]] Zero-Permission Manipulation: Can We Trust Large Multimodal Model Powered GUI Agents?(https://arxiv.org/abs/2601.12349)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Large multimodal model powered GUI agents are emerging as high-privilege operators on mobile platforms, entrusted with perceiving screen content and injecting inputs. However, their design operates under the implicit assumption of Visual Atomicity: that the UI state remains invariant between observation and action. We demonstrate that this assumption is fundamentally invalid in Android, creating a critical attack surface. We present Action Rebinding, a novel attack that allows a seemingly-benign app with zero dangerous permissions to rebind an agent's execution. By exploiting the inevitable observation-to-action gap inherent in the agent's reasoning pipeline, the attacker triggers foreground transitions to rebind the agent's planned action toward the target app. We weaponize the agent's task-recovery logic and Android's UI state preservation to orchestrate programmable, multi-step attack chains. Furthermore, we introduce an Intent Alignment Strategy (IAS) that manipulates the agent's reasoning process to rationalize UI states, enabling it to bypass verification gates (e.g., confirmation dialogs) that would otherwise be rejected. We evaluate Action Rebinding Attacks on six widely-used Android GUI agents across 15 tasks. Our results demonstrate a 100% success rate for atomic action rebinding and the ability to reliably orchestrate multi-step attack chains. With IAS, the success rate in bypassing verification gates increases (from 0% to up to 100%). Notably, the attacker application requires no sensitive permissions and contains no privileged API calls, achieving a 0% detection rate across malware scanners (e.g., VirusTotal). Our findings reveal a fundamental architectural flaw in current agent-OS integration and provide critical insights for the secure design of future agent systems. To access experimental logs and demonstration videos, please contact yi_qian@smail.this http URL.</li>
</ul>

<h3>Title: LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH</h3>
<ul>
<li><strong>Authors: </strong>Beicheng Xu, Weitong Qian, Lingching Tung, Yupeng Lu, Bin Cui</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12355">https://arxiv.org/abs/2601.12355</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12355">https://arxiv.org/pdf/2601.12355</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12355]] LB-MCTS: Synergizing Large Language Models and Bayesian Optimization for Efficient CASH(https://arxiv.org/abs/2601.12355)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>To lower the expertise barrier in machine learning, the AutoML community has focused on the CASH problem, a fundamental challenge that automates the process of algorithm selection and hyperparameter tuning. While traditional methods like Bayesian Optimization (BO) struggle with cold-start issues, Large Language Models (LLMs) can mitigate these via semantic priors. However, existing LLM-based optimizers generalize poorly to the high-dimensional, structured CASH space. We propose LB-MCTS, a framework synergizing LLMs and BO within a Monte Carlo Tree Search structure. It maximizes LLM reasoning with Selective Tuning Memory (STM) and explicit exploration-exploitation trade-off. It combines the strengths of both paradigms by dynamically shifting from LLM-driven to BO-driven proposals as data accumulates. Experiments on 104 AMLB datasets demonstrate the superiority of LB-MCTS over the competitive baselines.</li>
</ul>

<h3>Title: From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Omar Y. Goba, Ahmed Y. Gado, Catherine M. Elias, Ahmed Hussein</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12358">https://arxiv.org/abs/2601.12358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12358">https://arxiv.org/pdf/2601.12358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12358]] From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles(https://arxiv.org/abs/2601.12358)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.</li>
</ul>

<h3>Title: Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Anirudh Sekar, Mrinal Agarwal, Rachel Sharma, Akitsugu Tanaka, Jasmine Zhang, Arjun Damerla, Kevin Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12359">https://arxiv.org/abs/2601.12359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12359">https://arxiv.org/pdf/2601.12359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12359]] Zero-Shot Embedding Drift Detection: A Lightweight Defense Against Prompt Injections in LLMs(https://arxiv.org/abs/2601.12359)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Prompt injection attacks have become an increasing vulnerability for LLM applications, where adversarial prompts exploit indirect input channels such as emails or user-generated content to circumvent alignment safeguards and induce harmful or unintended outputs. Despite advances in alignment, even state-of-the-art LLMs remain broadly vulnerable to adversarial prompts, underscoring the urgent need for robust, productive, and generalizable detection mechanisms beyond inefficient, model-specific patches. In this work, we propose Zero-Shot Embedding Drift Detection (ZEDD), a lightweight, low-engineering-overhead framework that identifies both direct and indirect prompt injection attempts by quantifying semantic shifts in embedding space between benign and suspect inputs. ZEDD operates without requiring access to model internals, prior knowledge of attack types, or task-specific retraining, enabling efficient zero-shot deployment across diverse LLM architectures. Our method uses adversarial-clean prompt pairs and measures embedding drift via cosine similarity to capture subtle adversarial manipulations inherent to real-world injection attacks. To ensure robust evaluation, we assemble and re-annotate the comprehensive LLMail-Inject dataset spanning five injection categories derived from publicly available sources. Extensive experiments demonstrate that embedding drift is a robust and transferable signal, outperforming traditional methods in detection accuracy and operational efficiency. With greater than 93% accuracy in classifying prompt injections across model architectures like Llama 3, Qwen 2, and Mistral and a false positive rate of <3%, our approach offers a lightweight, scalable defense layer that integrates into existing LLM pipelines, addressing a critical gap in securing LLM-powered systems to withstand adaptive adversarial threats.</li>
</ul>

<h3>Title: DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data</h3>
<ul>
<li><strong>Authors: </strong>Jiafei Zhang, Songliang Cao, Binghui Xu, Yanan Li, Weiwei Jia, Tingting Wu, Hao Lu, Weijuan Hu, Zhiguo Han</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12366">https://arxiv.org/abs/2601.12366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12366">https://arxiv.org/pdf/2601.12366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12366]] DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data(https://arxiv.org/abs/2601.12366)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.</li>
</ul>

<h3>Title: CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology</h3>
<ul>
<li><strong>Authors: </strong>Amro Khaled, Farah Khaled, Omar Riad, Catherine M. Elias</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12373">https://arxiv.org/abs/2601.12373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12373">https://arxiv.org/pdf/2601.12373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12373]] CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology(https://arxiv.org/abs/2601.12373)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.</li>
</ul>

<h3>Title: A Scalable Entity-Based Framework for Auditing Bias in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Akram Elbouanani, Aboubacar Tuo, Adrian Popescu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12374">https://arxiv.org/abs/2601.12374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12374">https://arxiv.org/pdf/2601.12374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12374]] A Scalable Entity-Based Framework for Auditing Bias in LLMs(https://arxiv.org/abs/2601.12374)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.</li>
</ul>

<h3>Title: LR-DWM: Efficient Watermarking for Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ofek Raban, Ethan Fetaya, Gal Chechik</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12376">https://arxiv.org/abs/2601.12376</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12376">https://arxiv.org/pdf/2601.12376</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12376]] LR-DWM: Efficient Watermarking for Diffusion Language Models(https://arxiv.org/abs/2601.12376)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.</li>
</ul>

<h3>Title: Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Jiahui Sheng, Yidan Shi, Shu Xiang, Xiaorun Li, Shuhan Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12379">https://arxiv.org/abs/2601.12379</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12379">https://arxiv.org/pdf/2601.12379</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12379]] Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection(https://arxiv.org/abs/2601.12379)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at this https URL.</li>
</ul>

<h3>Title: Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation</h3>
<ul>
<li><strong>Authors: </strong>Ou Deng, Shoji Nishimura, Atsushi Ogihara, Qun Jin</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12380">https://arxiv.org/abs/2601.12380</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12380">https://arxiv.org/pdf/2601.12380</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12380]] Statistical-Neural Interaction Networks for Interpretable Mixed-Type Data Imputation(https://arxiv.org/abs/2601.12380)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Real-world tabular databases routinely combine continuous measurements and categorical records, yet missing entries are pervasive and can distort downstream analysis. We propose Statistical-Neural Interaction (SNI), an interpretable mixed-type imputation framework that couples correlation-derived statistical priors with neural feature attention through a Controllable-Prior Feature Attention (CPFA) module. CPFA learns head-wise prior-strength coefficients $\{\lambda_h\}$ that softly regularize attention toward the prior while allowing data-driven deviations when nonlinear patterns appear to be present in the data. Beyond imputation, SNI aggregates attention maps into a directed feature-dependency matrix that summarizes which variables the imputer relied on, without requiring post-hoc explainers. We evaluate SNI against six baselines (Mean/Mode, MICE, KNN, MissForest, GAIN, MIWAE) on six datasets spanning ICU monitoring, population surveys, socio-economic statistics, and engineering applications. Under MCAR/strict-MAR at 30\% missingness, SNI is generally competitive on continuous metrics but is often outperformed by accuracy-first baselines (MissForest, MIWAE) on categorical variables; in return, it provides intrinsic dependency diagnostics and explicit statistical-neural trade-off parameters. We additionally report MNAR stress tests (with a mask-aware variant) and discuss computational cost, limitations -- particularly for severely imbalanced categorical targets -- and deployment scenarios where interpretability may justify the trade-off.</li>
</ul>

<h3>Title: A Hierarchical Benchmark of Foundation Models for Dermatology</h3>
<ul>
<li><strong>Authors: </strong>Furkan Yuceyalcin, Abdurrahim Yilmaz, Burak Temelkuran</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12382">https://arxiv.org/abs/2601.12382</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12382">https://arxiv.org/pdf/2601.12382</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12382]] A Hierarchical Benchmark of Foundation Models for Dermatology(https://arxiv.org/abs/2601.12382)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.</li>
</ul>

<h3>Title: NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages</h3>
<ul>
<li><strong>Authors: </strong>Lakshya Tomar, Vinayak Abrol, Puneet Agarwal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12389">https://arxiv.org/abs/2601.12389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12389">https://arxiv.org/pdf/2601.12389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12389]] NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages(https://arxiv.org/abs/2601.12389)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.</li>
</ul>

<h3>Title: Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation</h3>
<ul>
<li><strong>Authors: </strong>Dasith de Silva Edirimuni, Ajmal Saeed Mian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12391">https://arxiv.org/abs/2601.12391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12391">https://arxiv.org/pdf/2601.12391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12391]] Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation(https://arxiv.org/abs/2601.12391)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.</li>
</ul>

<h3>Title: Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Jinmei Liu, Haoru Li, Zhenhong Sun, Chaofeng Chen, Yatao Bian, Bo Wang, Daoyi Dong, Chunlin Chen, Zhi Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12401">https://arxiv.org/abs/2601.12401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12401">https://arxiv.org/pdf/2601.12401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12401]] Beyond the Dirac Delta: Mitigating Diversity Collapse in Reinforcement Fine-Tuning for Versatile Image Generation(https://arxiv.org/abs/2601.12401)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has emerged as a powerful paradigm for fine-tuning large-scale generative models, such as diffusion and flow models, to align with complex human preferences and user-specified tasks. A fundamental limitation remains \textit{the curse of diversity collapse}, where the objective formulation and optimization landscape inherently collapse the policy to a Dirac delta distribution. To address this challenge, we propose \textbf{DRIFT} (\textbf{D}ive\textbf{R}sity-\textbf{I}ncentivized Reinforcement \textbf{F}ine-\textbf{T}uning for Versatile Image Generation), an innovative framework that systematically incentivizes output diversity throughout the on-policy fine-tuning process, reconciling strong task alignment with high generation diversity to enhance versatility essential for applications that demand diverse candidate generations. We approach the problem across three representative perspectives: i) \textbf{sampling} a reward-concentrated subset that filters out reward outliers to prevent premature collapse; ii) \textbf{prompting} with stochastic variations to expand the conditioning space, and iii) \textbf{optimization} of the intra-group diversity with a potential-based reward shaping mechanism. Experimental results show that DRIFT achieves superior Pareto dominance regarding task alignment and generation diversity, yielding a $ 9.08\%\!\sim\! 43.46\%$ increase in diversity at equivalent alignment levels and a $ 59.65\% \!\sim\! 65.86\%$ increase in alignment at equivalent levels of diversity.</li>
</ul>

<h3>Title: Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants</h3>
<ul>
<li><strong>Authors: </strong>Manasi Kanade, Abhi Thakkar, Gabriela Fernandes</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12405">https://arxiv.org/abs/2601.12405</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12405">https://arxiv.org/pdf/2601.12405</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12405]] Explainable Machine Learning for Pediatric Dental Risk Stratification Using Socio-Demographic Determinants(https://arxiv.org/abs/2601.12405)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Background: Pediatric dental disease remains one of the most prevalent and inequitable chronic health conditions worldwide. Although strong epidemiological evidence links oral health outcomes to socio-economic and demographic determinants, most artificial intelligence (AI) applications in dentistry rely on image-based diagnosis and black-box prediction models, limiting transparency and ethical applicability in pediatric populations. Objective: This study aimed to develop and evaluate an explainable machine learning framework for pediatric dental risk stratification that prioritizes interpretability, calibration, and ethical deployment over maximal predictive accuracy. Methods: A supervised machine learning model was trained using population-level pediatric data including age, income-to-poverty ratio, race/ethnicity, gender, and medical history. Model performance was assessed using receiver operating characteristic (ROC) analysis and calibration curves. Explainability was achieved using SHapley Additive exPlanations (SHAP) to provide global and individual-level interpretation of predictions. Results: The model achieved modest discrimination (AUC = 0.61) with conservative calibration, underestimating risk at higher probability levels. SHAP analysis identified age and income-to-poverty ratio as the strongest contributors to predicted risk, followed by race/ethnicity and gender. Conclusion: Explainable machine learning enables transparent, prevention-oriented pediatric dental risk stratification and supports population screening and equitable resource allocation rather than diagnostic decision-making.</li>
</ul>

<h3>Title: De-Anonymization at Scale via Tournament-Style Attribution</h3>
<ul>
<li><strong>Authors: </strong>Lirui Zhang, Huishuai Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12407">https://arxiv.org/abs/2601.12407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12407">https://arxiv.org/pdf/2601.12407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12407]] De-Anonymization at Scale via Tournament-Style Attribution(https://arxiv.org/abs/2601.12407)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>As LLMs rapidly advance and enter real-world use, their privacy implications are increasingly important. We study an authorship de-anonymization threat: using LLMs to link anonymous documents to their authors, potentially compromising settings such as double-blind peer review. We propose De-Anonymization at Scale (DAS), a large language model-based method for attributing authorship among tens of thousands of candidate texts. DAS uses a sequential progression strategy: it randomly partitions the candidate corpus into fixed-size groups, prompts an LLM to select the text most likely written by the same author as a query text, and iteratively re-queries the surviving candidates to produce a ranked top-k list. To make this practical at scale, DAS adds a dense-retrieval prefilter to shrink the search space and a majority-voting style aggregation over multiple independent runs to improve robustness and ranking precision. Experiments on anonymized review data show DAS can recover same-author texts from pools of tens of thousands with accuracy well above chance, demonstrating a realistic privacy risk for anonymous platforms. On standard authorship benchmarks (Enron emails and blog posts), DAS also improves both accuracy and scalability over prior approaches, highlighting a new LLM-enabled de-anonymization vulnerability.</li>
</ul>

<h3>Title: Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF</h3>
<ul>
<li><strong>Authors: </strong>Wang Zixian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12415">https://arxiv.org/abs/2601.12415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12415">https://arxiv.org/pdf/2601.12415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12415]] Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF(https://arxiv.org/abs/2601.12415)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent alignment methods for large language models, including PPO, DPO, and IPO, are often presented as distinct algorithms. In this work, we show that many of these approaches implicitly conflate two fundamental and independent design choices: (i) the sampling geometry, which determines which samples dominate the gradient signal, and (ii) the optimization geometry, which determines how deviations in value are penalized. We formalize this observation by expressing alignment as the minimization of a generalized distance between policy energy and target energy, parameterized by an alpha-divergence-based sampling weight and a Bregman-divergence-based value metric. We demonstrate that the commonly used KL divergence induces an exponential penalty on unbounded value signals, leading to numerical instability and vanishing gradients in high-confidence regimes. To address this issue, we propose Orthogonalized Policy Optimization (OPO), a framework that explicitly decouples sampling geometry from optimization geometry. By combining alpha-weighted importance sampling with a chi-square-induced quadratic regularization in ratio coordinates, OPO yields a simple and well-conditioned objective with linear gradient dynamics. This formulation maintains stable optimization while preserving peak-seeking behavior and avoids gradient saturation even when model confidence is high. Our analysis positions OPO as a unifying perspective on existing alignment methods and provides a principled foundation for robust reasoning-oriented training.</li>
</ul>

<h3>Title: Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification</h3>
<ul>
<li><strong>Authors: </strong>Mahammad Namazov, Tomáš Koref, Ivan Habernal</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12419">https://arxiv.org/abs/2601.12419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12419">https://arxiv.org/pdf/2601.12419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12419]] Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification(https://arxiv.org/abs/2601.12419)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's "reasons" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at this https URL.</li>
</ul>

<h3>Title: Graph Attention Networks with Physical Constraints for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Mohammadhossein Homaei, Iman Khazrak, Ruben Molano, Andres Caro, Mar Avila</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12426">https://arxiv.org/abs/2601.12426</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12426">https://arxiv.org/pdf/2601.12426</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12426]] Graph Attention Networks with Physical Constraints for Anomaly Detection(https://arxiv.org/abs/2601.12426)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Water distribution systems (WDSs) face increasing cyber-physical risks, which make reliable anomaly detection essential. Many data-driven models ignore network topology and are hard to interpret, while model-based ones depend strongly on parameter accuracy. This work proposes a hydraulic-aware graph attention network using normalized conservation law violations as features. It combines mass and energy balance residuals with graph attention and bidirectional LSTM to learn spatio-temporal patterns. A multi-scale module aggregates detection scores from node to network level. On the BATADAL dataset, it reaches $F1=0.979$, showing $3.3$pp gain and high robustness under $15\%$ parameter noise.</li>
</ul>

<h3>Title: SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Shunyu Huang, Yunjiao Zhou, Jianfei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12432">https://arxiv.org/abs/2601.12432</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12432">https://arxiv.org/pdf/2601.12432</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12432]] SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition(https://arxiv.org/abs/2601.12432)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at this https URL.</li>
</ul>

<h3>Title: Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery</h3>
<ul>
<li><strong>Authors: </strong>Shahnawaz Alam, Mohammed Mudassir Uddin, Mohammed Kaif Pasha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12442">https://arxiv.org/abs/2601.12442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12442">https://arxiv.org/pdf/2601.12442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12442]] Constraint-Aware Neurosymbolic Uncertainty Quantification with Bayesian Deep Learning for Scientific Discovery(https://arxiv.org/abs/2601.12442)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Scientific Artificial Intelligence (AI) applications require models that deliver trustworthy uncertainty estimates while respecting domain constraints. Existing uncertainty quantification methods lack mechanisms to incorporate symbolic scientific knowledge, while neurosymbolic approaches operate deterministically without principled uncertainty modeling. We introduce the Constraint-Aware Neurosymbolic Uncertainty Framework (CANUF), unifying Bayesian deep learning with differentiable symbolic reasoning. The architecture comprises three components: automated constraint extraction from scientific literature, probabilistic neural backbone with variational inference, and differentiable constraint satisfaction layer ensuring physical consistency. Experiments on Materials Project (140,000+ materials), QM9 molecular properties, and climate benchmarks show CANUF reduces Expected Calibration Error by 34.7% versus Bayesian neural networks while maintaining 99.2% constraint satisfaction. Ablations reveal constraint-guided recalibration contributes 18.3% performance gain, with constraint extraction achieving 91.4% precision. CANUF provides the first end-to-end differentiable pipeline simultaneously addressing uncertainty quantification, constraint satisfaction, and interpretable explanations for scientific predictions.</li>
</ul>

<h3>Title: Adversarial Defense in Vision-Language Models: An Overview</h3>
<ul>
<li><strong>Authors: </strong>Xiaowei Fu, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12443">https://arxiv.org/abs/2601.12443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12443">https://arxiv.org/pdf/2601.12443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12443]] Adversarial Defense in Vision-Language Models: An Overview(https://arxiv.org/abs/2601.12443)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.</li>
</ul>

<h3>Title: Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Himayath Ali, Mohammed Aqib Abdullah, Syed Muneer Hussin, Mohammed Mudassir Uddin, Shahnawaz Alam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12447">https://arxiv.org/abs/2601.12447</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12447">https://arxiv.org/pdf/2601.12447</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12447]] Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees(https://arxiv.org/abs/2601.12447)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, federate, fair</a></li>
<li><strong>Abstract: </strong>Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains fundamentally unresolved. This paper introduces CryptoFair-FL, a novel cryptographic framework providing the first verifiable fairness guarantees for federated learning systems under formal security definitions. The proposed approach combines additively homomorphic encryption with secure multi-party computation to enable privacy-preserving verification of demographic parity and equalized odds metrics without revealing protected attribute distributions or individual predictions. A novel batched verification protocol reduces computational complexity from BigO(n^2) to BigO(n \log n) while maintaining (\dparam, \deltap)-differential privacy with dparam = 0.5 and deltap = 10^{-6}. Theoretical analysis establishes information-theoretic lower bounds on the privacy cost of fairness verification, demonstrating that the proposed protocol achieves near-optimal privacy-fairness tradeoffs. Comprehensive experiments across four benchmark datasets (MIMIC-IV healthcare records, Adult Income, CelebA, and a novel FedFair-100 benchmark) demonstrate that CryptoFair-FL reduces fairness violations from 0.231 to 0.031 demographic parity difference while incurring only 2.3 times computational overhead compared to standard federated averaging. The framework successfully defends against attribute inference attacks, maintaining adversarial success probability below 0.05 across all tested configurations. These results establish a practical pathway for deploying fairness-aware federated learning in regulated industries requiring both privacy protection and algorithmic accountability.</li>
</ul>

<h3>Title: AgenTRIM: Tool Risk Mitigation for Agentic AI</h3>
<ul>
<li><strong>Authors: </strong>Roy Betser, Shamik Bose, Amit Giloni, Chiara Picardi, Sindhu Padakandla, Roman Vainshtein</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12449">https://arxiv.org/abs/2601.12449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12449">https://arxiv.org/pdf/2601.12449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12449]] AgenTRIM: Tool Risk Mitigation for Agentic AI(https://arxiv.org/abs/2601.12449)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>AI agents are autonomous systems that combine LLMs with external tools to solve complex tasks. While such tools extend capability, improper tool permissions introduce security risks such as indirect prompt injection and tool misuse. We characterize these failures as unbalanced tool-driven agency. Agents may retain unnecessary permissions (excessive agency) or fail to invoke required tools (insufficient agency), amplifying the attack surface and reducing performance. We introduce AgenTRIM, a framework for detecting and mitigating tool-driven agency risks without altering an agent's internal reasoning. AgenTRIM addresses these risks through complementary offline and online phases. Offline, AgenTRIM reconstructs and verifies the agent's tool interface from code and execution traces. At runtime, it enforces per-step least-privilege tool access through adaptive filtering and status-aware validation of tool calls. Evaluating on the AgentDojo benchmark, AgenTRIM substantially reduces attack success while maintaining high task performance. Additional experiments show robustness to description-based attacks and effective enforcement of explicit safety policies. Together, these results demonstrate that AgenTRIM provides a practical, capability-preserving approach to safer tool use in LLM-based agents.</li>
</ul>

<h3>Title: TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhixin Xie, Xurui Song, Jun Luo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12460">https://arxiv.org/abs/2601.12460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12460">https://arxiv.org/pdf/2601.12460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12460]] TrojanPraise: Jailbreak LLMs via Benign Fine-Tuning(https://arxiv.org/abs/2601.12460)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>The demand of customized large language models (LLMs) has led to commercial LLMs offering black-box fine-tuning APIs, yet this convenience introduces a critical security loophole: attackers could jailbreak the LLMs by fine-tuning them with malicious data. Though this security issue has recently been exposed, the feasibility of such attacks is questionable as malicious training dataset is believed to be detectable by moderation models such as Llama-Guard-3. In this paper, we propose TrojanPraise, a novel finetuning-based attack exploiting benign and thus filter-approved data. Basically, TrojanPraise fine-tunes the model to associate a crafted word (e.g., "bruaf") with harmless connotations, then uses this word to praise harmful concepts, subtly shifting the LLM from refusal to compliance. To explain the attack, we decouple the LLM's internal representation of a query into two dimensions of knowledge and attitude. We demonstrate that successful jailbreak requires shifting the attitude while avoiding knowledge shift, a distortion in the model's understanding of the concept. To validate this attack, we conduct experiments on five opensource LLMs and two commercial LLMs under strict black-box settings. Results show that TrojanPraise achieves a maximum attack success rate of 95.88% while evading moderation.</li>
</ul>

<h3>Title: Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Yanrui Lu, Danyang Chen, Haowen Xiao, Jiarui Zhu, Fukang Ge, Binqian Zou, Jiali Guan, Jiayin Liang, Yuting Wang, Ziqian Guan, Xiangcheng Bao, Jinhao Bi, Lin Gu, Jun He, Yingying Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12464">https://arxiv.org/abs/2601.12464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12464">https://arxiv.org/pdf/2601.12464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12464]] Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild(https://arxiv.org/abs/2601.12464)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.</li>
</ul>

<h3>Title: Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping</h3>
<ul>
<li><strong>Authors: </strong>Miao Peng, Weizhou Shen, Nuo Chen, Chenliang Li, Ming Yan, Jia Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12465">https://arxiv.org/abs/2601.12465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12465">https://arxiv.org/pdf/2601.12465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12465]] Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping(https://arxiv.org/abs/2601.12465)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the "almost-there" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from "almost-there" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.</li>
</ul>

<h3>Title: Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Saurish Nagrath</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12467">https://arxiv.org/abs/2601.12467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12467">https://arxiv.org/pdf/2601.12467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12467]] Patch-Level Tokenization with CNN Encoders and Attention for Improved Transformer Time-Series Forecasting(https://arxiv.org/abs/2601.12467)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based models have shown strong performance in time-series forecasting by leveraging self-attention to model long-range temporal dependencies. However, their effectiveness depends critically on the quality and structure of input representations derived from raw multivariate time-series data. This work proposes a two-stage forecasting framework that explicitly separates local temporal representation learning from global dependency modelling. In the first stage, a convolutional neural network (CNN) operates on fixed-length temporal patches to extract short-range temporal dynamics and non-linear feature interactions, producing compact patch-level token embeddings. Token-level self-attention is subsequently applied during representation learning to refine these embeddings by enabling interactions across temporal patches. In the second stage, a Transformer encoder processes the resulting token sequence to model inter-patch temporal dependencies and generate per-patch forecasts. Experiments conducted on synthetic multivariate time-series data with controlled static and dynamic factors demonstrate that the proposed patch-based tokenization strategy achieves competitive forecasting performance compared to convolutional and patch-based Transformer baselines. The results highlight the importance of structured temporal representations and show that decoupling local temporal encoding from global attention-based modelling yields more effective and stable time-series forecasting.</li>
</ul>

<h3>Title: Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty</h3>
<ul>
<li><strong>Authors: </strong>Sravanthi Machcha, Sushrita Yerra, Sahil Gupta, Aishwarya Sahoo, Sharmin Sultana, Hong Yu, Zonghai Yao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12471">https://arxiv.org/abs/2601.12471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12471">https://arxiv.org/pdf/2601.12471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12471]] Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty(https://arxiv.org/abs/2601.12471)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.</li>
</ul>

<h3>Title: Capability-Aware Early-Stage Research Idea Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Renlong Jie, Chen Chu, Zhen Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12473">https://arxiv.org/abs/2601.12473</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12473">https://arxiv.org/pdf/2601.12473</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12473]] Capability-Aware Early-Stage Research Idea Evaluation(https://arxiv.org/abs/2601.12473)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.</li>
</ul>

<h3>Title: Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Mehrdad Noori, Gustavo Adolfo Vargas Hakim, David Osowiechi, Fereshteh Shakeri, Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Ismail Ben Ayed, Christian Desrosiers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12493">https://arxiv.org/abs/2601.12493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12493">https://arxiv.org/pdf/2601.12493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12493]] Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation(https://arxiv.org/abs/2601.12493)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at this https URL.</li>
</ul>

<h3>Title: DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity</h3>
<ul>
<li><strong>Authors: </strong>Ashish Raj Shekhar, Shiven Agarwal, Priyanuj Bordoloi, Yash Shah, Tejas Anvekar, Vivek Gupta</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12505">https://arxiv.org/abs/2601.12505</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12505">https://arxiv.org/pdf/2601.12505</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12505]] DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity(https://arxiv.org/abs/2601.12505)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.</li>
</ul>

<h3>Title: SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Ruo Qi, Linhui Dai, Yusong Qin, Chaolei Yang, Yanshan Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12507">https://arxiv.org/abs/2601.12507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12507">https://arxiv.org/pdf/2601.12507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12507]] SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection(https://arxiv.org/abs/2601.12507)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at this https URL.</li>
</ul>

<h3>Title: Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Abdullah Umut Hamzaogullari, Arkadas Ozakin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12519">https://arxiv.org/abs/2601.12519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12519">https://arxiv.org/pdf/2601.12519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12519]] Learning Relativistic Geodesics and Chaotic Dynamics via Stabilized Lagrangian Neural Networks(https://arxiv.org/abs/2601.12519)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Lagrangian Neural Networks (LNNs) can learn arbitrary Lagrangians from trajectory data, but their unusual optimization objective leads to significant training instabilities that limit their application to complex systems. We propose several improvements that address these fundamental challenges, namely, a Hessian regularization scheme that penalizes unphysical signatures in the Lagrangian's second derivatives with respect to velocities, preventing the network from learning unstable dynamics, activation functions that are better suited to the problem of learning Lagrangians, and a physics-aware coordinate scaling that improves stability. We systematically evaluate these techniques alongside previously proposed methods for improving stability. Our improved architecture successfully trains on systems of unprecedented complexity, including triple pendulums, and achieved 96.6\% lower validation loss value and 90.68\% better stability than baseline LNNs in double pendulum systems. With the improved framework, we show that our LNNs can learn Lagrangians representing geodesic motion in both non-relativistic and general relativistic settings. To deal with the relativistic setting, we extended our regularization to penalize violations of Lorentzian signatures, which allowed us to predict a geodesic Lagrangian under AdS\textsubscript{4} spacetime metric directly from trajectory data, which to our knowledge has not been done in the literature before. This opens new possibilities for automated discovery of geometric structures in physics, including extraction of spacetime metric tensor components from geodesic trajectories. While our approach inherits some limitations of the original LNN framework, particularly the requirement for invertible Hessians, it significantly expands the practical applicability of LNNs for scientific discovery tasks.</li>
</ul>

<h3>Title: Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem</h3>
<ul>
<li><strong>Authors: </strong>Alireza Ghahtarani, Martin Cousineau, Amir-massoud Farahmand, Jorge E. Mendoza</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12543">https://arxiv.org/abs/2601.12543</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12543">https://arxiv.org/pdf/2601.12543</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12543]] Press Start to Charge: Videogaming the Online Centralized Charging Scheduling Problem(https://arxiv.org/abs/2601.12543)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study the online centralized charging scheduling problem (OCCSP). In this problem, a central authority must decide, in real time, when to charge dynamically arriving electric vehicles (EVs), subject to capacity limits, with the objective of balancing load across a finite planning horizon. To solve the problem, we first gamify it; that is, we model it as a game where charging blocks are placed within temporal and capacity constraints on a grid. We design heuristic policies, train learning agents with expert demonstrations, and improve them using Dataset Aggregation (DAgger). From a theoretical standpoint, we show that gamification reduces model complexity and yields tighter generalization bounds than vector-based formulations. Experiments across multiple EV arrival patterns confirm that gamified learning enhances load balancing. In particular, the image-to-movement model trained with DAgger consistently outperforms heuristic baselines, vector-based approaches, and supervised learning agents, while also demonstrating robustness in sensitivity analyses. These operational gains translate into tangible economic value. In a real-world case study for the Greater Montréal Area (Québec, Canada) using utility cost data, the proposed methods lower system costs by tens of millions of dollars per year over the prevailing practice and show clear potential to delay costly grid upgrades.</li>
</ul>

<h3>Title: Benchmarking Concept-Spilling Across Languages in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ilia Badanin, Daniil Dzenhaliou, Imanol Schlag</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12549">https://arxiv.org/abs/2601.12549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12549">https://arxiv.org/pdf/2601.12549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12549]] Benchmarking Concept-Spilling Across Languages in LLMs(https://arxiv.org/abs/2601.12549)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.</li>
</ul>

<h3>Title: PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception</h3>
<ul>
<li><strong>Authors: </strong>Tong Wu</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12551">https://arxiv.org/abs/2601.12551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12551">https://arxiv.org/pdf/2601.12551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12551]] PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception(https://arxiv.org/abs/2601.12551)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.</li>
</ul>

<h3>Title: Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yihong Liu, Bingyu Xiong, Hinrich Schütze</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12555">https://arxiv.org/abs/2601.12555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12555">https://arxiv.org/pdf/2601.12555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12555]] Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models(https://arxiv.org/abs/2601.12555)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.</li>
</ul>

<h3>Title: Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory</h3>
<ul>
<li><strong>Authors: </strong>Mark Moussa, Amber V. Young, Brianna Isola, Vasuda Trehan, Michael D. Himes, Nicholas Wogan, Giada Arney</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12557">https://arxiv.org/abs/2601.12557</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12557">https://arxiv.org/pdf/2601.12557</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12557]] Life, Machine Learning, and the Search for Habitability: Predicting Biosignature Fluxes for the Habitable Worlds Observatory(https://arxiv.org/abs/2601.12557)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Future direct-imaging flagship missions, such as NASA's Habitable Worlds Observatory (HWO), face critical decisions in prioritizing observations due to extremely stringent time and resource constraints. In this paper, we introduce two advanced machine-learning architectures tailored for predicting biosignature species fluxes from exoplanetary reflected-light spectra: a Bayesian Convolutional Neural Network (BCNN) and our novel model architecture, the Spectral Query Adaptive Transformer (SQuAT). The BCNN robustly quantifies both epistemic and aleatoric uncertainties, offering reliable predictions under diverse observational conditions, whereas SQuAT employs query-driven attention mechanisms to enhance interpretability by explicitly associating spectral features with specific biosignature species. We demonstrate that both models achieve comparably high predictive accuracy on an augmented dataset spanning a wide range of exoplanetary conditions, while highlighting their distinct advantages in uncertainty quantification and spectral interpretability. These capabilities position our methods as promising tools for accelerating target triage, optimizing observation schedules, and maximizing scientific return for upcoming flagship missions such as HWO.</li>
</ul>

<h3>Title: VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps</h3>
<ul>
<li><strong>Authors: </strong>Ismat Jarin, Olivia Figueira, Yu Duan, Tu Le, Athina Markopoulou</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12563">https://arxiv.org/abs/2601.12563</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12563">https://arxiv.org/pdf/2601.12563</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12563]] VR ProfiLens: User Profiling Risks in Consumer Virtual Reality Apps(https://arxiv.org/abs/2601.12563)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Virtual reality (VR) platforms and apps collect user sensor data, including motion, facial, eye, and hand data, in abstracted form. These data may expose users to unique privacy risks without their knowledge or meaningful awareness, yet the extent of these risks remains understudied. To address this gap, we propose VR ProfiLens, a framework to study user profiling based on VR sensor data and the resulting privacy risks across consumer VR apps. To systematically study this problem, we first develop a taxonomy rooted in the CCPA definition of personal information and expand it by sensor, app, and threat contexts to identify user attributes at risk. Then, we conduct a user study in which we collect VR sensor data from four sensor groups from real users interacting with 10 popular consumer VR apps, followed by a survey. We design and apply an analysis pipeline to demonstrate the feasibility of inferring user attributes using these data. Our results show that sensitive personal information can be inferred with moderately high to high risk (up to 90% F1 score) from abstracted sensor data. Through feature analysis, we further identify correlations among app groups and sensor groups in inferring user attributes. Our findings highlight risks to users, including privacy loss, tracking, targeted advertising, and safety threats. Finally, we discuss design implications and regulatory recommendations to enhance transparency and better protect users' privacy in VR.</li>
</ul>

<h3>Title: Abusing the Internet of Medical Things: Evaluating Threat Models and Forensic Readiness for Multi-Vector Attacks on Connected Healthcare Devices</h3>
<ul>
<li><strong>Authors: </strong>Isabel Straw, Akhil Polamarasetty, Mustafa Jaafar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12593">https://arxiv.org/abs/2601.12593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12593">https://arxiv.org/pdf/2601.12593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12593]] Abusing the Internet of Medical Things: Evaluating Threat Models and Forensic Readiness for Multi-Vector Attacks on Connected Healthcare Devices(https://arxiv.org/abs/2601.12593)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Individuals experiencing interpersonal violence (IPV), who depend on medical devices, represent a uniquely vulnerable population as healthcare technologies become increasingly connected. Despite rapid growth in MedTech innovation and "health-at-home" ecosystems, the intersection of MedTech cybersecurity and technology-facilitated abuse remains critically under-examined. IPV survivors who rely on therapeutic devices encounter a qualitatively different threat environment from the external, technically sophisticated adversaries typically modeled in MedTech cybersecurity research. We address this gap through two complementary methods: (1) the development of hazard-integrated threat models that fuse Cyber physical system security modeling with tech-abuse frameworks, and (2) an immersive simulation with practitioners, deploying a live version of our model, identifying gaps in digital forensic practice. Our hazard-integrated CIA threat models map exploits to acute and chronic biological effects, uncovering (i) Integrity attack pathways that facilitate "Medical gaslighting" and "Munchausen-by-IoMT", (ii) Availability attacks that create life-critical and sub-acute harms (glycaemic emergencies, blindness, mood destabilization), and (iii) Confidentiality threats arising from MedTech advertisements (geolocation tracking from BLE broadcasts). Our simulation demonstrates that these attack surfaces are unlikely to be detected in practice: participants overlooked MedTech, misclassified reproductive and assistive technologies, and lacked awareness of BLE broadcast artifacts. Our findings show that MedTech cybersecurity in IPV contexts requires integrated threat modeling and improved forensic capabilities for detecting, preserving and interpreting harms arising from compromised patient-technology ecosystems.</li>
</ul>

<h3>Title: Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization</h3>
<ul>
<li><strong>Authors: </strong>Younes Bouhadjar, Maxime Fabre, Felix Schmidt, Emre Neftci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12598">https://arxiv.org/abs/2601.12598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12598">https://arxiv.org/pdf/2601.12598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12598]] Dissecting Linear Recurrent Models: How Different Gating Strategies Drive Selectivity and Generalization(https://arxiv.org/abs/2601.12598)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Linear recurrent neural networks have emerged as efficient alternatives to the original Transformer's softmax attention mechanism, thanks to their highly parallelizable training and constant memory and computation requirements at inference. Iterative refinements of these models have introduced an increasing number of architectural mechanisms, leading to increased complexity and computational costs. Nevertheless, systematic direct comparisons among these models remain limited. Existing benchmark tasks are either too simplistic to reveal substantial differences or excessively resource-intensive for experimentation. In this work, we propose a refined taxonomy of linear recurrent models and introduce SelectivBench, a set of lightweight and customizable synthetic benchmark tasks for systematically evaluating sequence models. SelectivBench specifically evaluates selectivity in sequence models at small to medium scale, such as the capacity to focus on relevant inputs while ignoring context-based distractors. It employs rule-based grammars to generate sequences with adjustable complexity, incorporating irregular gaps that intentionally violate transition rules. Evaluations of linear recurrent models on SelectivBench reveal performance patterns consistent with results from large-scale language tasks. Our analysis clarifies the roles of essential architectural features: gating and rapid forgetting mechanisms facilitate recall, in-state channel mixing is unnecessary for selectivity, but critical for generalization, and softmax attention remains dominant due to its memory capacity scaling with sequence length. Our benchmark enables targeted, efficient exploration of linear recurrent models and provides a controlled setting for studying behaviors observed in large-scale evaluations. Code is available at this https URL</li>
</ul>

<h3>Title: A Cloud-based Multi-Agentic Workflow for Science</h3>
<ul>
<li><strong>Authors: </strong>Anurag Acharya, Timothy Vega, Rizwan A. Ashraf, Anshu Sharma, Derek Parker, Robert Rallo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12607">https://arxiv.org/abs/2601.12607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12607">https://arxiv.org/pdf/2601.12607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12607]] A Cloud-based Multi-Agentic Workflow for Science(https://arxiv.org/abs/2601.12607)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.</li>
</ul>

<h3>Title: Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems</h3>
<ul>
<li><strong>Authors: </strong>Elham Tajik, Conrad Borchers, Bahar Shahrokhian, Sebastian Simon, Ali Keramati, Sonika Pal, Sreecharan Sankaranarayanan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12618">https://arxiv.org/abs/2601.12618</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12618">https://arxiv.org/pdf/2601.12618</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12618]] Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems(https://arxiv.org/abs/2601.12618)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.</li>
</ul>

<h3>Title: Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach</h3>
<ul>
<li><strong>Authors: </strong>Shiqi Wang, Mahdi Khosravy, Neeraj Gupta, Olaf Witkowski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12624">https://arxiv.org/abs/2601.12624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12624">https://arxiv.org/pdf/2601.12624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12624]] Towards Robust Universal Perturbation Attacks: A Float-Coded, Penalty-Driven Evolutionary Approach(https://arxiv.org/abs/2601.12624)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Universal adversarial perturbations (UAPs) have garnered significant attention due to their ability to undermine deep neural networks across multiple inputs using a single noise pattern. Evolutionary algorithms offer a promising approach to generating such perturbations due to their ability to navigate non-convex, gradient-free landscapes. In this work, we introduce a float-coded, penalty-driven single-objective evolutionary framework for UAP generation that achieves lower visibility perturbations while enhancing attack success rates. Our approach leverages continuous gene representations aligned with contemporary deep learning scales, incorporates dynamic evolutionary operators with adaptive scheduling, and utilizes a modular PyTorch implementation for seamless integration with modern architectures. Additionally, we ensure the universality of the generated perturbations by testing across diverse models and by periodically switching batches to prevent overfitting. Experimental results on the ImageNet dataset demonstrate that our framework consistently produces perturbations with smaller norms, higher misclassification effectiveness, and faster convergence compared to existing evolutionary-based methods. These findings highlight the robustness and scalability of our approach for universal adversarial attacks across various deep learning architectures.</li>
</ul>

<h3>Title: Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models</h3>
<ul>
<li><strong>Authors: </strong>Raphi Kang, Hongqiao Chen, Georgia Gkioxari, Pietro Perona</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12626">https://arxiv.org/abs/2601.12626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12626">https://arxiv.org/pdf/2601.12626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12626]] Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models(https://arxiv.org/abs/2601.12626)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: this https URL.</li>
</ul>

<h3>Title: BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kriti Bhattarai, Vipina K. Keloth, Donald Wright, Andrew Loza, Yang Ren, Hua Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12632">https://arxiv.org/abs/2601.12632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12632">https://arxiv.org/pdf/2601.12632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12632]] BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models(https://arxiv.org/abs/2601.12632)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases. Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents. Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36. Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.</li>
</ul>

<h3>Title: The Cost of Convenience: Identifying, Analyzing, and Mitigating Predatory Loan Applications on Android</h3>
<ul>
<li><strong>Authors: </strong>Olawale Amos Akanji, Manuel Egele, Gianluca Stringhini</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12634">https://arxiv.org/abs/2601.12634</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12634">https://arxiv.org/pdf/2601.12634</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12634]] The Cost of Convenience: Identifying, Analyzing, and Mitigating Predatory Loan Applications on Android(https://arxiv.org/abs/2601.12634)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust</a></li>
<li><strong>Abstract: </strong>Digital lending applications, commonly referred to as loan apps, have become a primary channel for microcredit in emerging markets. However, many of these apps demand excessive permissions and misuse sensitive user data for coercive debt-recovery practices, including harassment, blackmail, and public shaming that affect both borrowers and their contacts. This paper presents the first cross-country measurement of loan app compliance against both national regulations and Google's Financial Services Policy. We analyze 434 apps drawn from official registries and app markets from Indonesia, Kenya, Nigeria, Pakistan, and the Philippines. To operationalize policy requirements at scale, we translate policy text into testable permission checks using LLM-assisted policy-to-permission mapping and combine this with static and dynamic analyses of loan apps' code and runtime behavior. Our findings reveal pervasive non-compliance among approved apps: 141 violate national regulatory policy and 147 violate Google policy. Dynamic analysis further shows that several apps transmit sensitive data (contacts, SMS, location, media) before user signup or registration, undermining informed consent and enabling downstream harassment of borrowers and third parties. Following our disclosures, Google removed 93 flagged apps from Google Play, representing over 300M cumulative installs. We advocate for adopting our methodology as a proactive compliance-monitoring tool and offer targeted recommendations for regulators, platforms, and developers to strengthen privacy protections. Overall, our results highlight the need for coordinated enforcement and robust technical safeguards to ensure that digital lending supports financial inclusion without compromising user privacy or safety.</li>
</ul>

<h3>Title: From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2</h3>
<ul>
<li><strong>Authors: </strong>Satyaki Roy Chowdhury, Aswathnarayan Radhakrishnan, Hsiao Jou Hsu, Hari Subramoni, Joachim Moortgat</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12636">https://arxiv.org/abs/2601.12636</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12636">https://arxiv.org/pdf/2601.12636</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12636]] From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2(https://arxiv.org/abs/2601.12636)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.</li>
</ul>

<h3>Title: Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift</h3>
<ul>
<li><strong>Authors: </strong>Daniel Vennemeyer, Punya Syon Pandey, Phan Anh Duong, Michael Umeokoli, Samuel Ratnam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12639">https://arxiv.org/abs/2601.12639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12639">https://arxiv.org/pdf/2601.12639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12639]] Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift(https://arxiv.org/abs/2601.12639)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.</li>
</ul>

<h3>Title: Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?</h3>
<ul>
<li><strong>Authors: </strong>Nafiz Imtiaz Khan, Kylie Cleland, Vladimir Filkov, Roger Eric Goldman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12648">https://arxiv.org/abs/2601.12648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12648">https://arxiv.org/pdf/2601.12648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12648]] Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?(https://arxiv.org/abs/2601.12648)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.</li>
</ul>

<h3>Title: Augmenting Question Answering with A Hybrid RAG Approach</h3>
<ul>
<li><strong>Authors: </strong>Tianyi Yang, Nashrah Haque, Vaishnave Jonnalagadda, Yuya Jeremy Ong, Zhehui Chen, Yanzhao Wu, Lei Yu, Divyesh Jadav, Wenqi Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12658">https://arxiv.org/abs/2601.12658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12658">https://arxiv.org/pdf/2601.12658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12658]] Augmenting Question Answering with A Hybrid RAG Approach(https://arxiv.org/abs/2601.12658)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.</li>
</ul>

<h3>Title: Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images</h3>
<ul>
<li><strong>Authors: </strong>Elisa Gonçalves Ribeiro, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, André Ricardo Backes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12664">https://arxiv.org/abs/2601.12664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12664">https://arxiv.org/pdf/2601.12664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12664]] Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images(https://arxiv.org/abs/2601.12664)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.</li>
</ul>

<h3>Title: Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface</h3>
<ul>
<li><strong>Authors: </strong>Zonglin Li, Jieji Ren, Shuangfan Zhou, Heng Guo, Jinnuo Zhang, Jiang Zhou, Boxin Shi, Zhanyu Ma, Guoying Gu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12666">https://arxiv.org/abs/2601.12666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12666">https://arxiv.org/pdf/2601.12666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12666]] Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface(https://arxiv.org/abs/2601.12666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.</li>
</ul>

<h3>Title: Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification</h3>
<ul>
<li><strong>Authors: </strong>Thamara Leandra de Deus Melo, Rodrigo Moreira, Larissa Ferreira Rodrigues Moreira, André Ricardo Backes</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12671">https://arxiv.org/abs/2601.12671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12671">https://arxiv.org/pdf/2601.12671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12671]] Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification(https://arxiv.org/abs/2601.12671)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.</li>
</ul>

<h3>Title: VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness</h3>
<ul>
<li><strong>Authors: </strong>Qimao Chen, Fang Li, Shaoqing Xu, Zhiyi Lai, Zixun Xie, Yuechen Luo, Shengyin Jiang, Hanbing Li, Long Chen, Bing Wang, Yi Zhang, Zhi-Xin Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12672">https://arxiv.org/abs/2601.12672</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12672">https://arxiv.org/pdf/2601.12672</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12672]] VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness(https://arxiv.org/abs/2601.12672)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.</li>
</ul>

<h3>Title: MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning</h3>
<ul>
<li><strong>Authors: </strong>Zheng Fang, Wolfgang Mayer, Zeyu Zhang, Jian Wang, Hong-Yu Zhang, Wanli Li, Zaiwen Feng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12680">https://arxiv.org/abs/2601.12680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12680">https://arxiv.org/pdf/2601.12680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12680]] MetaToolAgent: Towards Generalizable Tool Usage in LLMs through Meta-Learning(https://arxiv.org/abs/2601.12680)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Tool learning is increasingly important for large language models (LLMs) to effectively coordinate and utilize a diverse set of tools in order to solve complex real-world tasks. By selecting and integrating appropriate tools, LLMs extend their capabilities beyond pure language understanding to perform specialized functions. However, existing methods for tool selection often focus on limited tool sets and struggle to generalize to novel tools encountered in practical deployments. To address these challenges, we introduce a comprehensive dataset spanning 7 domains, containing 155 tools and 9,377 question-answer pairs, which simulates realistic integration scenarios. Additionally, we propose MetaToolAgent (MTA), a meta-learning approach designed to improve cross-tool generalization. Experimental results show that MTA significantly outperforms baseline methods on unseen tools, demonstrating its promise for building flexible and scalable systems that require dynamic tool coordination.</li>
</ul>

<h3>Title: GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Liwei Liao, Ronggang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12683">https://arxiv.org/abs/2601.12683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12683">https://arxiv.org/pdf/2601.12683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12683]] GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation(https://arxiv.org/abs/2601.12683)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.</li>
</ul>

<h3>Title: BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS</h3>
<ul>
<li><strong>Authors: </strong>Mohoshin Ara Tahera, Sabbir Rahman, Shuvalaxmi Dass, Sharif Ullah, Mahmoud Abouyessef</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12693">https://arxiv.org/abs/2601.12693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12693">https://arxiv.org/pdf/2601.12693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12693]] BlocksecRT-DETR: Decentralized Privacy-Preserving and Token-Efficient Federated Transformer Learning for Secure Real-Time Object Detection in ITS(https://arxiv.org/abs/2601.12693)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, federate, transformer</a></li>
<li><strong>Abstract: </strong>Federated real-time object detection using transformers in Intelligent Transportation Systems (ITS) faces three major challenges: (1) missing-class non-IID data heterogeneity from geographically diverse traffic environments, (2) latency constraints on edge hardware for high-capacity transformer models, and (3) privacy and security risks from untrusted client updates and centralized aggregation. We propose BlockSecRT-DETR, a BLOCKchain-SECured Real-Time Object DEtection TRansformer framework for ITS that provides a decentralized, token-efficient, and privacy-preserving federated training solution using RT-DETR transformer, incorporating a blockchain-secured update validation mechanism for trustworthy aggregation. In this framework, challenges (1) and (2) are jointly addressed through a unified client-side design that integrates RT-DETR training with a Token Engineering Module (TEM). TEM prunes low-utility tokens, reducing encoder complexity and latency on edge hardware, while aggregated updates mitigate non-IID data heterogeneity across clients. To address challenge (3), BlockSecRT-DETR incorporates a decentralized blockchain-secured update validation mechanism that enables tamper-proof, privacy-preserving, and trust-free authenticated model aggregation without relying on a central server. We evaluated the proposed framework under a missing-class Non-IID partition of the KITTI dataset and conducted a blockchain case study to quantify security overhead. TEM improves inference latency by 17.2% and reduces encoder FLOPs by 47.8%, while maintaining global detection accuracy (89.20% mAP@0.5). The blockchain integration adds 400 ms per round, and the ledger size remains under 12 KB due to metadata-only on-chain storage.</li>
</ul>

<h3>Title: UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages</h3>
<ul>
<li><strong>Authors: </strong>Tassallah Abdullahi, Macton Mgonzo, Mardiyyah Oduwole, Paul Okewunmi, Abraham Owodunni, Ritambhara Singh, Carsten Eickhoff</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12696">https://arxiv.org/abs/2601.12696</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12696">https://arxiv.org/pdf/2601.12696</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12696]] UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages(https://arxiv.org/abs/2601.12696)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\footnote{Code repository available at this https URL.</li>
</ul>

<h3>Title: CellularSpecSec-Bench: A Staged Benchmark for Evidence-Grounded Interpretation and Security Reasoning over 3GPP Specifications</h3>
<ul>
<li><strong>Authors: </strong>Ke Xie, Xingyi Zhao, Yiwen Hu, Shuhan Yuan, Tian Xie</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12716">https://arxiv.org/abs/2601.12716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12716">https://arxiv.org/pdf/2601.12716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12716]] CellularSpecSec-Bench: A Staged Benchmark for Evidence-Grounded Interpretation and Security Reasoning over 3GPP Specifications(https://arxiv.org/abs/2601.12716)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, large language model</a></li>
<li><strong>Abstract: </strong>Cellular networks are critical infrastructure supporting billions of worldwide users and safety- and mission-critical services. Vulnerabilities in cellular networks can therefore cause service disruption, privacy breaches, and broad societal harm, motivating growing efforts to analyze 3GPP specifications that define required device and operator behavior. While large language models (LLMs) have demonstrated the capability for reading technical documents, cellular specifications impose unique challenges: faithful interpretation of normative language, reasoning across cross-referenced clauses, and verifiable conclusions grounded in multimodal evidence such as tables and figures. To address these challenges, we propose CellSpecSec-ARI, a unified Adapt-Retrieve-Integrate framework for systematic understanding and standard-driven security analysis of 3GPP specifications; CellularSpecSec-Bench, a staged benchmark, containing newly constructed high-quality datasets with expert-verified and corrected subsets from prior open-source resources. Together, they establish an accessible and reproducible foundation for quantifying progress in specification understanding and security reasoning in the cellular network security domain.</li>
</ul>

<h3>Title: S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Lin Zhao, Yushu Wu, Aleksei Lebedev, Dishani Lahiri, Meng Dong, Arpit Sahni, Michael Vasilkovsky, Hao Chen, Ju Hu, Aliaksandr Siarohin, Sergey Tulyakov, Yanzhi Wang, Anil Kag, Yanyu Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12719">https://arxiv.org/abs/2601.12719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12719">https://arxiv.org/pdf/2601.12719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12719]] S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation(https://arxiv.org/abs/2601.12719)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.</li>
</ul>

<h3>Title: DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Hanyu Zhu, Zhihao Zhan, Yuhang Ming, Liang Li, Dibo Hou, Javier Civera, Wanzeng Kong</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12729">https://arxiv.org/abs/2601.12729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12729">https://arxiv.org/pdf/2601.12729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12729]] DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition(https://arxiv.org/abs/2601.12729)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.</li>
</ul>

<h3>Title: Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off</h3>
<ul>
<li><strong>Authors: </strong>Zhaochun Li, Chen Wang, Jionghao Bai, Shisheng Cui, Ge Lan, Zhou Zhao, Yue Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12730">https://arxiv.org/abs/2601.12730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12730">https://arxiv.org/pdf/2601.12730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12730]] Distribution-Centric Policy Optimization Dominates Exploration-Exploitation Trade-off(https://arxiv.org/abs/2601.12730)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The exploration-exploitation (EE) trade-off is a central challenge in reinforcement learning (RL) for large language models (LLMs). With Group Relative Policy Optimization (GRPO), training tends to be exploitation driven: entropy decreases monotonically, samples convergence, and exploration fades. Most existing fixes are \textbf{sample-centric}: they seek or bonus rare samples, assuming exploration comes from novel trajectories and tokens. These heuristics depend on the "luck" of informative samples, lack principled control of the policy, and often yield limited or inconsistent gains. In this work, we are the first to introduce a \textbf{distribution-centric} perspective for RL, in which exploration is always guided by a "better" target distribution, and reveal that a policy's ability to resist entropy collapse is governed by the distribution itself rather than individual samples. Building on this insight, we propose Distribution-Centric Policy Optimization (DCPO), which reformulates entropy regulation as distribution-level regularization. DCPO achieves controllable entropy fully on-policy without sampling from external distributions, enabling efficient exploration while maintaining training stability. Across multiple models and seven benchmarks, DCPO improves over GRPO by about 20\% on average. Overall, DCPO replaces sample-level heuristics with distribution-level principles, offering a theoretically grounded and flexible framework for controllable exploration and a stronger EE trade-off. The code is available in this https URL.</li>
</ul>

<h3>Title: A Shared Geometry of Difficulty in Multilingual Language Models</h3>
<ul>
<li><strong>Authors: </strong>Stefano Civelli, Pietro Bernardelle, Nicolò Brunello, Gianluca Demartini</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12731">https://arxiv.org/abs/2601.12731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12731">https://arxiv.org/pdf/2601.12731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12731]] A Shared Geometry of Difficulty in Multilingual Language Models(https://arxiv.org/abs/2601.12731)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.</li>
</ul>

<h3>Title: KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Qingtian Zhu, Xu Cao, Zhixiang Wang, Yinqiang Zheng, Takafumi Taketomi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12736">https://arxiv.org/abs/2601.12736</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12736">https://arxiv.org/pdf/2601.12736</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12736]] KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction(https://arxiv.org/abs/2601.12736)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at this https URL.</li>
</ul>

<h3>Title: A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Miao Ye, Jing Cui, Yuan huang, Qian He, Yong Wang, Jiwen Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12745">https://arxiv.org/abs/2601.12745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12745">https://arxiv.org/pdf/2601.12745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12745]] A Graph Prompt Fine-Tuning Method for WSN Spatio-Temporal Correlation Anomaly Detection(https://arxiv.org/abs/2601.12745)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Anomaly detection of multi-temporal modal data in Wireless Sensor Network (WSN) can provide an important guarantee for reliable network operation. Existing anomaly detection methods in multi-temporal modal data scenarios have the problems of insufficient extraction of spatio-temporal correlation features, high cost of anomaly sample category annotation, and imbalance of anomaly samples. In this paper, a graph neural network anomaly detection backbone network incorporating spatio-temporal correlation features and a multi-task self-supervised training strategy of "pre-training - graph prompting - fine-tuning" are designed for the characteristics of WSN graph structure data. First, the anomaly detection backbone network is designed by improving the Mamba model based on a multi-scale strategy and inter-modal fusion method, and combining it with a variational graph convolution module, which is capable of fully extracting spatio-temporal correlation features in the multi-node, multi-temporal modal scenarios of WSNs. Secondly, we design a three-subtask learning "pre-training" method with no-negative comparative learning, prediction, and reconstruction to learn generic features of WSN data samples from unlabeled data, and design a "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning. The model is fine-tuned through the "graph prompting-fine-tuning" mechanism to guide the pre-trained self-supervised learning model to complete the parameter fine-tuning, thereby reducing the training cost and enhancing the detection generalization performance. The F1 metrics obtained from experiments on the public dataset and the actual collected dataset are up to 91.30% and 92.31%, respectively, which provides better detection performance and generalization ability than existing methods designed by the method.</li>
</ul>

<h3>Title: SSPFormer: Self-Supervised Pretrained Transformer for MRI Images</h3>
<ul>
<li><strong>Authors: </strong>Jingkai Li, Xiaoze Tian, Yuhang Shen, Jia Wang, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12747">https://arxiv.org/abs/2601.12747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12747">https://arxiv.org/pdf/2601.12747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12747]] SSPFormer: Self-Supervised Pretrained Transformer for MRI Images(https://arxiv.org/abs/2601.12747)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.</li>
</ul>

<h3>Title: Towards Robust Process Reward Modeling via Noise-aware Learning</h3>
<ul>
<li><strong>Authors: </strong>Bin Xie, Bingbing Xu, Xueyun Tian, Yilin Chen, Huawei Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12748">https://arxiv.org/abs/2601.12748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12748">https://arxiv.org/pdf/2601.12748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12748]] Towards Robust Process Reward Modeling via Noise-aware Learning(https://arxiv.org/abs/2601.12748)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \underline{\textbf{N}}oise-\underline{\textbf{A}}ware \underline{\textbf{I}}terative \underline{\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\% absolute gain in average F1 over PRMs trained with noisy supervision.</li>
</ul>

<h3>Title: A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining</h3>
<ul>
<li><strong>Authors: </strong>Manjish Pal</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12751">https://arxiv.org/abs/2601.12751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12751">https://arxiv.org/pdf/2601.12751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12751]] A Boolean Function-Theoretic Framework for Expressivity in GNNs with Applications to Fair Graph Mining(https://arxiv.org/abs/2601.12751)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>We propose a novel expressivity framework for Graph Neural Networks (GNNs) grounded in Boolean function theory, enabling a fine-grained analysis of their ability to capture complex subpopulation structures. We introduce the notion of \textit{Subpopulation Boolean Isomorphism} (SBI) as an invariant that strictly subsumes existing expressivity measures such as Weisfeiler-Lehman (WL), biconnectivity-based, and homomorphism-based frameworks. Our theoretical results identify Fourier degree, circuit class (AC$^0$, NC$^1$), and influence as key barriers to expressivity in fairness-aware GNNs. We design a circuit-traversal-based fairness algorithm capable of handling subpopulations defined by high-complexity Boolean functions, such as parity, which break existing baselines. Experiments on real-world graphs show that our method achieves low fairness gaps across intersectional groups where state-of-the-art methods fail, providing the first principled treatment of GNN expressivity tailored to fairness.</li>
</ul>

<h3>Title: VISPA: Pluralistic Alignment via Automatic Value Selection and Activation</h3>
<ul>
<li><strong>Authors: </strong>Shenyan Zheng, Jiayou Zhong, Anudeex Shetty, Heng Ji, Preslav Nakov, Usman Naseem</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12758">https://arxiv.org/abs/2601.12758</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12758">https://arxiv.org/pdf/2601.12758</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12758]] VISPA: Pluralistic Alignment via Automatic Value Selection and Activation(https://arxiv.org/abs/2601.12758)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.</li>
</ul>

<h3>Title: Moaw: Unleashing Motion Awareness for Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Tianqi Zhang, Ziyi Wang, Wenzhao Zheng, Weiliang Chen, Yuanhui Huang, Zhengyang Huang, Jie Zhou, Jiwen Lu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12761">https://arxiv.org/abs/2601.12761</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12761">https://arxiv.org/pdf/2601.12761</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12761]] Moaw: Unleashing Motion Awareness for Video Diffusion Models(https://arxiv.org/abs/2601.12761)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.</li>
</ul>

<h3>Title: Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration</h3>
<ul>
<li><strong>Authors: </strong>Lu Yue, Yue Fan, Shiwei Lian, Yu Zhao, Jiaxin Yu, Liang Xie, Feitian Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12766">https://arxiv.org/abs/2601.12766</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12766">https://arxiv.org/pdf/2601.12766</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12766]] Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration(https://arxiv.org/abs/2601.12766)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at this https URL.</li>
</ul>

<h3>Title: Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Zequn Xie, Boyun Zhang, Yuxiao Lin, Tao Jin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12768">https://arxiv.org/abs/2601.12768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12768">https://arxiv.org/pdf/2601.12768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12768]] Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval(https://arxiv.org/abs/2601.12768)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at this https URL.</li>
</ul>

<h3>Title: Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image</h3>
<ul>
<li><strong>Authors: </strong>Shuling Zhao, Dan Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12770">https://arxiv.org/abs/2601.12770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12770">https://arxiv.org/pdf/2601.12770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12770]] Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image(https://arxiv.org/abs/2601.12770)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative</a></li>
<li><strong>Abstract: </strong>Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.</li>
</ul>

<h3>Title: Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory</h3>
<ul>
<li><strong>Authors: </strong>Keito Inoshita</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12771">https://arxiv.org/abs/2601.12771</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12771">https://arxiv.org/pdf/2601.12771</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12771]] Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory(https://arxiv.org/abs/2601.12771)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.</li>
</ul>

<h3>Title: Open Vocabulary Panoptic Segmentation With Retrieval Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Nafis Sadeq, Qingfeng Liu, Mostafa El-Khamy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12779">https://arxiv.org/abs/2601.12779</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12779">https://arxiv.org/pdf/2601.12779</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12779]] Open Vocabulary Panoptic Segmentation With Retrieval Augmentation(https://arxiv.org/abs/2601.12779)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.</li>
</ul>

<h3>Title: DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems</h3>
<ul>
<li><strong>Authors: </strong>Suyang Sun, Weifei Jin, Yuxin Cao, Wei Song, Jie Hao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12786">https://arxiv.org/abs/2601.12786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12786">https://arxiv.org/pdf/2601.12786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12786]] DUAP: Dual-task Universal Adversarial Perturbations Against Voice Control Systems(https://arxiv.org/abs/2601.12786)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack</a></li>
<li><strong>Abstract: </strong>Modern Voice Control Systems (VCS) rely on the collaboration of Automatic Speech Recognition (ASR) and Speaker Recognition (SR) for secure interaction. However, prior adversarial attacks typically target these tasks in isolation, overlooking the coupled decision pipeline in real-world scenarios. Consequently, single-task attacks often fail to pose a practical threat. To fill this gap, we first utilize gradient analysis to reveal that ASR and SR exhibit no inherent conflicts. Building on this, we propose Dual-task Universal Adversarial Perturbation (DUAP). Specifically, DUAP employs a targeted surrogate objective to effectively disrupt ASR transcription and introduces a Dynamic Normalized Ensemble (DNE) strategy to enhance transferability across diverse SR models. Furthermore, we incorporate psychoacoustic masking to ensure perturbation imperceptibility. Extensive evaluations across five ASR and six SR models demonstrate that DUAP achieves high simultaneous attack success rates and superior imperceptibility, significantly outperforming existing single-task baselines.</li>
</ul>

<h3>Title: SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification</h3>
<ul>
<li><strong>Authors: </strong>Zhihan Zeng, Yang Zhao, Kaihe Wang, Dusit Niyato, Hongyuan Shu, Junchu Zhao, Yanjun Huang, Yue Xiu, Zhongpei Zhang, Ning Wei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12791">https://arxiv.org/abs/2601.12791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12791">https://arxiv.org/pdf/2601.12791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12791]] SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification(https://arxiv.org/abs/2601.12791)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.</li>
</ul>

<h3>Title: Combating Noisy Labels through Fostering Self- and Neighbor-Consistency</h3>
<ul>
<li><strong>Authors: </strong>Zeren Sun, Yazhou Yao, Tongliang Liu, Zechao Li, Fumin Shen, Jinhui Tang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12795">https://arxiv.org/abs/2601.12795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12795">https://arxiv.org/pdf/2601.12795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12795]] Combating Noisy Labels through Fostering Self- and Neighbor-Consistency(https://arxiv.org/abs/2601.12795)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.</li>
</ul>

<h3>Title: Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs</h3>
<ul>
<li><strong>Authors: </strong>Zixing Song, Irwin King</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12807">https://arxiv.org/abs/2601.12807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12807">https://arxiv.org/pdf/2601.12807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12807]] Semi-supervised Instruction Tuning for Large Language Models on Text-Attributed Graphs(https://arxiv.org/abs/2601.12807)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The emergent reasoning capabilities of Large Language Models (LLMs) offer a transformative paradigm for analyzing text-attributed graphs. While instruction tuning is the prevailing method for adapting pre-trained LLMs to graph learning tasks like node classification, it requires a substantial volume of annotated (INSTRUCTION, OUTPUT) pairs deriving from labeled nodes. This requirement is particularly prohibitive in the social domain, where obtaining expert labels for sensitive or evolving content is costly and slow. Furthermore, standard graph instruction tuning fails to exploit the vast amount of unlabeled nodes, which contain latent correlations due to edge connections that are beneficial for downstream predictions. To bridge this gap, we propose a novel Semi-supervised Instruction Tuning pipeline for Graph Learning, named SIT-Graph. Notably, SIT-Graph is model-agnostic and can be seamlessly integrated into any graph instruction tuning method that utilizes LLMs as the predictor. SIT-Graph operates via an iterative self-training process. Initially, the model is fine-tuned using instruction pairs constructed solely from the labeled nodes. Then it generates confidence-filtered pseudo-responses for unlabeled nodes to strategically augment the dataset for the next round of fine-tuning. Finally, this iterative refinement progressively aligns the LLM with the underlying node correlations. Extensive experiments demonstrate that when incorporated into state-of-the-art graph instruction tuning methods, SIT-Graph significantly enhances their performance on text-attributed graph benchmarks, achieving over 20% improvement under the low label ratio settings.</li>
</ul>

<h3>Title: Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data</h3>
<ul>
<li><strong>Authors: </strong>Takaki Yamamoto, Chihiro Noguchi, Toshihiro Tanizawa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12809">https://arxiv.org/abs/2601.12809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12809">https://arxiv.org/pdf/2601.12809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12809]] Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data(https://arxiv.org/abs/2601.12809)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.</li>
</ul>

<h3>Title: Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?</h3>
<ul>
<li><strong>Authors: </strong>Sushant Kumar Ray, Gautam Siddharth Kashyap, Sahil Tripathi, Nipun Joshi, Vijay Govindarajan, Rafiq Ali, Jiechao Gao, Usman Naseem</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12812">https://arxiv.org/abs/2601.12812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12812">https://arxiv.org/pdf/2601.12812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12812]] Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?(https://arxiv.org/abs/2601.12812)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.</li>
</ul>

<h3>Title: CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Yu-Jen Tseng, Chia-Hao Kao, Jing-Zhong Chen, Alessandro Gnutti, Shao-Yuan Lo, Yen-Yu Lin, Wen-Hsiao Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12814">https://arxiv.org/abs/2601.12814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12814">https://arxiv.org/pdf/2601.12814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12814]] CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting(https://arxiv.org/abs/2601.12814)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.</li>
</ul>

<h3>Title: A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling</h3>
<ul>
<li><strong>Authors: </strong>Wei Chen, Liang Wu, Shuyi Lu, Yuanyuan Sun, Wenkai Bi, Zilong Yuan, Yaoyao He, Feng Wang, Junchi Ma, Shuyong Liu, Zhaoping Cheng, Xiaoyan Hu, Jianfeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12820">https://arxiv.org/abs/2601.12820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12820">https://arxiv.org/pdf/2601.12820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12820]] A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling(https://arxiv.org/abs/2601.12820)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.</li>
</ul>

<h3>Title: Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification</h3>
<ul>
<li><strong>Authors: </strong>Teerapong Panboonyuen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12826">https://arxiv.org/abs/2601.12826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12826">https://arxiv.org/pdf/2601.12826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12826]] Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification(https://arxiv.org/abs/2601.12826)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.</li>
</ul>

<h3>Title: Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations</h3>
<ul>
<li><strong>Authors: </strong>Gyuyeon Na, Minjung Park, Soyoun Kim, Jungbin Shin, Sangmi Chai</a></li>
<li><strong>Subjects: </strong>cs.LG, q-fin.RM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12839">https://arxiv.org/abs/2601.12839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12839">https://arxiv.org/pdf/2601.12839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12839]] Knowledge-Integrated Representation Learning for Crypto Anomaly Detection under Extreme Label Scarcity; Relational Domain-Logic Integration with Retrieval-Grounded Context and Path-Level Explanations(https://arxiv.org/abs/2601.12839)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Detecting anomalous trajectories in decentralized crypto networks is fundamentally challenged by extreme label scarcity and the adaptive evasion strategies of illicit actors. While Graph Neural Networks (GNNs) effectively capture local structural patterns, they struggle to internalize multi hop, logic driven motifs such as fund dispersal and layering that characterize sophisticated money laundering, limiting their forensic accountability under regulations like the FATF Travel Rule. To address this limitation, we propose Relational Domain Logic Integration (RDLI), a framework that embeds expert derived heuristics as differentiable, logic aware latent signals within representation learning. Unlike static rule based approaches, RDLI enables the detection of complex transactional flows that evade standard message passing. To further account for market volatility, we incorporate a Retrieval Grounded Context (RGC) module that conditions anomaly scoring on regulatory and macroeconomic context, mitigating false positives caused by benign regime shifts. Under extreme label scarcity (0.01%), RDLI outperforms state of the art GNN baselines by 28.9% in F1 score. A micro expert user study further confirms that RDLI path level explanations significantly improve trustworthiness, perceived usefulness, and clarity compared to existing methods, highlighting the importance of integrating domain logic with contextual grounding for both accuracy and explainability.</li>
</ul>

<h3>Title: Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates</h3>
<ul>
<li><strong>Authors: </strong>Luca Schaufelberger, Aline Hartgers, Kjell Jorner</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.chem-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12859">https://arxiv.org/abs/2601.12859</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12859">https://arxiv.org/pdf/2601.12859</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12859]] Generating Cyclic Conformers with Flow Matching in Cremer-Pople Coordinates(https://arxiv.org/abs/2601.12859)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Cyclic molecules are ubiquitous across applications in chemistry and biology. Their restricted conformational flexibility provides structural pre-organization that is key to their function in drug discovery and catalysis. However, reliably sampling the conformer ensembles of ring systems remains challenging. Here, we introduce PuckerFlow, a generative machine learning model that performs flow matching on the Cremer-Pople space, a low-dimensional internal coordinate system capturing the relevant degrees of freedom of rings. Our approach enables generation of valid closed rings by design and demonstrates strong performance in generating conformers that are both diverse and precise. We show that PuckerFlow outperforms other conformer generation methods on nearly all quantitative metrics and illustrate the potential of PuckerFlow for ring systems relevant to chemical applications, particularly in catalysis and drug discovery. This work enables efficient and reliable conformer generation of cyclic structures, paving the way towards modeling structure-property relationships and the property-guided generation of rings across a wide range of applications in chemistry and biology.</li>
</ul>

<h3>Title: FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection</h3>
<ul>
<li><strong>Authors: </strong>Jun Wan, Xinyu Xiong, Ning Chen, Zhihui Lai, Jie Zhou, Wenwen Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12863">https://arxiv.org/abs/2601.12863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12863">https://arxiv.org/pdf/2601.12863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12863]] FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection(https://arxiv.org/abs/2601.12863)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at this https URL.</li>
</ul>

<h3>Title: Proxy Robustness in Vision Language Models is Effortlessly Transferable</h3>
<ul>
<li><strong>Authors: </strong>Xiaowei Fu, Fuxiang Huang, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12865">https://arxiv.org/abs/2601.12865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12865">https://arxiv.org/pdf/2601.12865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12865]] Proxy Robustness in Vision Language Models is Effortlessly Transferable(https://arxiv.org/abs/2601.12865)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust</a></li>
<li><strong>Abstract: </strong>As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of this http URL.</li>
</ul>

<h3>Title: PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection</h3>
<ul>
<li><strong>Authors: </strong>Sharmila S P</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12866">https://arxiv.org/abs/2601.12866</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12866">https://arxiv.org/pdf/2601.12866</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12866]] PDFInspect: A Unified Feature Extraction Framework for Malicious Document Detection(https://arxiv.org/abs/2601.12866)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>The increasing prevalence of malicious Portable Document Format (PDF) files necessitates robust and comprehensive feature extraction techniques for effective detection and analysis. This work presents a unified framework that integrates graph-based, structural, and metadata-driven analysis to generate a rich feature representation for each PDF document. The system extracts text from PDF pages and constructs undirected graphs based on pairwise word relationships, enabling the computation of graph-theoretic features such as node count, edge density, and clustering coefficient. Simultaneously, the framework parses embedded metadata to quantify character distributions, entropy patterns, and inconsistencies across fields such as author, title, and producer. Temporal features are derived from creation and modification timestamps to capture behavioral signatures, while structural elements including, object streams, fonts, and embedded images, are quantified to reflect document complexity. Boolean flags for potentially malicious PDF constructs (e.g., JavaScript, launch actions) are also extracted. Together, these features form a high-dimensional vector representation (170 dimensions) that is well-suited for downstream tasks such as malware classification, anomaly detection, and forensic analysis. The proposed approach is scalable, extensible, and designed to support real-world PDF threat intelligence workflows.6</li>
</ul>

<h3>Title: Race, Ethnicity and Their Implication on Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shiyue Hu, Ruizhe Li, Yanjun Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12868">https://arxiv.org/abs/2601.12868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12868">https://arxiv.org/pdf/2601.12868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12868]] Race, Ethnicity and Their Implication on Bias in Large Language Models(https://arxiv.org/abs/2601.12868)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.</li>
</ul>

<h3>Title: SWORD: A Secure LoW-Latency Offline-First Authentication and Data Sharing Scheme for Resource Constrained Distributed Networks</h3>
<ul>
<li><strong>Authors: </strong>Faisal Haque Bappy, Tahrim Hossain, Raiful Hasan, Kamrul Hasan, Mohamed Younis, Tariqul Islam</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12875">https://arxiv.org/abs/2601.12875</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12875">https://arxiv.org/pdf/2601.12875</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12875]] SWORD: A Secure LoW-Latency Offline-First Authentication and Data Sharing Scheme for Resource Constrained Distributed Networks(https://arxiv.org/abs/2601.12875)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>While many resource-constrained networks, such as Internet of Things (IoT) and Internet of Vehicles (IoV), are inherently distributed, the majority still rely on central servers for fast authentication and data sharing. Blockchain-based solutions offer decentralized alternatives but often struggle to meet the stringent latency requirements of real-time applications. Even with the rollout of 5G, network latency between servers and peers remains a significant challenge. To address this, we introduce SWORD, a novel offline-first authentication and data-sharing scheme designed specifically for resource-constrained networks. SWORD utilizes a proximity-based clustering approach to enable offline authentication and data sharing, ensuring low-latency, secure operations even in intermittently connected scenarios. Our experimental results show that SWORD outperforms traditional blockchain-based solutions while offering similar resource efficiency and authentication latency to central-server-based solutions. Additionally, we provide a comprehensive security analysis, demonstrating that SWORD is resilient against spoofing, impersonation, replay, and man-in-the-middle attacks.</li>
</ul>

<h3>Title: Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Mudassir Uddin, Shahnawaz Alam, Mohammed Kaif Pasha</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12879">https://arxiv.org/abs/2601.12879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12879">https://arxiv.org/pdf/2601.12879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12879]] Hierarchical Sparse Circuit Extraction from Billion-Parameter Language Models through Scalable Attribution Graph Decomposition(https://arxiv.org/abs/2601.12879)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability seeks to reverse-engineer neural network computations into human-understandable algorithms, yet extracting sparse computational circuits from billion-parameter language models remains challenging due to exponential search complexity and pervasive polysemanticity. The proposed Hierarchical Attribution Graph Decomposition (HAGD) framework reduces circuit discovery complexity from O(2^n) exhaustive enumeration to O(n^2 log n) through multi-resolution abstraction hierarchies and differentiable circuit search. The methodology integrates cross-layer transcoders for monosemantic feature extraction, graph neural network meta-learning for topology prediction, and causal intervention protocols for validation. Empirical evaluation spans GPT-2 variants, Llama-7B through Llama-70B, and Pythia suite models across algorithmic tasks and natural language benchmarks. On modular arithmetic tasks, the framework achieves up to 91% behavioral preservation ($\pm$2.3\% across runs) while maintaining interpretable subgraph sizes. Cross-architecture transfer experiments suggest that discovered circuits exhibit moderate structural similarity (averaging 67%) across model families, indicating potential shared computational patterns. These results provide preliminary foundations for interpretability at larger model scales while identifying significant limitations in current attribution methodologies that require future advances.</li>
</ul>

<h3>Title: AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs</h3>
<ul>
<li><strong>Authors: </strong>Ting Dang, Soumyajit Chatterjee, Hong Jia, Yu Wu, Flora Salim, Fahim Kawsar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12893">https://arxiv.org/abs/2601.12893</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12893">https://arxiv.org/pdf/2601.12893</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12893]] AdaNODEs: Test Time Adaptation for Time Series Forecasting Using Neural ODEs(https://arxiv.org/abs/2601.12893)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Test time adaptation (TTA) has emerged as a promising solution to adapt pre-trained models to new, unseen data distributions using unlabeled target domain data. However, most TTA methods are designed for independent data, often overlooking the time series data and rarely addressing forecasting tasks. This paper presents AdaNODEs, an innovative source-free TTA method tailored explicitly for time series forecasting. By leveraging Neural Ordinary Differential Equations (NODEs), we propose a novel adaptation framework that accommodates the unique characteristics of distribution shifts in time series data. Moreover, we innovatively propose a new loss function to tackle TTA for forecasting tasks. AdaNODEs only requires updating limited model parameters, showing effectiveness in capturing temporal dependencies while avoiding significant memory usage. Extensive experiments with one- and high-dimensional data demonstrate that AdaNODEs offer relative improvements of 5.88\% and 28.4\% over the SOTA baselines, especially demonstrating robustness across higher severity distribution shifts.</li>
</ul>

<h3>Title: TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents</h3>
<ul>
<li><strong>Authors: </strong>Chan Naseeb, Adeel Ashraf Cheema, Hassan Sami, Tayyab Afzal, Muhammad Omair, Usman Habib</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12895">https://arxiv.org/abs/2601.12895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12895">https://arxiv.org/pdf/2601.12895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12895]] TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents(https://arxiv.org/abs/2601.12895)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, transformer, generative, segmentation</a></li>
<li><strong>Abstract: </strong>The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.</li>
</ul>

<h3>Title: From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Wang, Weiyu Xie, Mingxing Zhang, Boxing Zhang, Jianwei Dong, Yuening Zhu, Chen Lin, Jinqi Tang, Yaochen Han, Zhiyuan Ai, Xianglin Chen, Yongwei Wu, Congfeng Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12904">https://arxiv.org/abs/2601.12904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12904">https://arxiv.org/pdf/2601.12904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12904]] From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation(https://arxiv.org/abs/2601.12904)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.</li>
</ul>

<h3>Title: Gated Differentiable Working Memory for Long-Context Language Modeling</h3>
<ul>
<li><strong>Authors: </strong>Lingrui Mei, Shenghua Liu, Yiwei Wang, Yuyao Ge, Baolong Bi, Jiayu Yao, Jun Wan, Ziling Yin, Jiafeng Guo, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12906">https://arxiv.org/abs/2601.12906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12906">https://arxiv.org/pdf/2601.12906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12906]] Gated Differentiable Working Memory for Long-Context Language Modeling(https://arxiv.org/abs/2601.12906)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.</li>
</ul>

<h3>Title: Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass</h3>
<ul>
<li><strong>Authors: </strong>Sangjun An, Seoksu Lee, Eun-Sun Cho</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12916">https://arxiv.org/abs/2601.12916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12916">https://arxiv.org/pdf/2601.12916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12916]] Static Detection of Core Structures in Tigress Virtualization-Based Obfuscation Using an LLVM Pass(https://arxiv.org/abs/2601.12916)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack</a></li>
<li><strong>Abstract: </strong>Malware often uses obfuscation to hinder security analysis. Among these techniques, virtualization-based obfuscation is particularly strong because it protects programs by translating original instructions into attacker-defined virtual machine (VM) bytecode, producing long and complex code that is difficult to analyze and deobfuscate. This paper aims to identify the structural components of virtualization-based obfuscation through static analysis. By examining the execution model of obfuscated code, we define and detect the key elements required for deobfuscation-namely the dispatch routine, handler blocks, and the VM region-using LLVM IR. Experimental results show that, in the absence of compiler optimizations, the proposed LLVM Pass successfully detects all core structures across major virtualization options, including switch, direct, and indirect modes.</li>
</ul>

<h3>Title: CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction</h3>
<ul>
<li><strong>Authors: </strong>He Sun, Jinrui Zhou, Li Li, Mingjun Xiao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12917">https://arxiv.org/abs/2601.12917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12917">https://arxiv.org/pdf/2601.12917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12917]] CooperLLM: Cloud-Edge-End Cooperative Federated Fine-tuning for LLMs via ZOO-based Gradient Correction(https://arxiv.org/abs/2601.12917)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) perform well on many NLP tasks, but fine-tuning them on resource-constrained mobile devices is challenging due to high memory and computation costs, despite growing demands for privacy-preserving personalization. Federated Learning (FL) enables local-data training, yet existing methods either rely on memory-intensive backpropagation or use zeroth-order optimization (ZOO), which avoids backward passes but suffers from slow convergence and degraded accuracy. We propose CooperLLM, a cloud-assisted edge-end cooperative federated fine-tuning framework that combines ZOO on mobile devices with cloud-guided gradient rectification. Mobile clients perform lightweight ZOO updates on private data, while the cloud fine-tunes on auxiliary public data using backpropagation and injects guided perturbations to rectify local updates, improving convergence and accuracy without violating privacy. To address system bottlenecks, CooperLLM introduces pipeline scheduling and adaptive compression to overlap computation and communication and reduce memory usage. Experiments on multiple Transformer models and datasets show that CooperLLM reduces on-device memory by up to $86.4\%$, accelerates convergence by $8.8 \times$, and improves accuracy by up to 10 percentage points over state-of-the-art ZOO-based baselines.</li>
</ul>

<h3>Title: Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection</h3>
<ul>
<li><strong>Authors: </strong>Jun Wan, Yuanzhi Yao, Zhihui Lai, Jie Zhou, Xianxu Hou, Wenwen Min</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12919">https://arxiv.org/abs/2601.12919</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12919">https://arxiv.org/pdf/2601.12919</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12919]] Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection(https://arxiv.org/abs/2601.12919)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.</li>
</ul>

<h3>Title: Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs</h3>
<ul>
<li><strong>Authors: </strong>Adimulya Kartiyasa, Bao Gia Cao, Boyang Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12921">https://arxiv.org/abs/2601.12921</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12921">https://arxiv.org/pdf/2601.12921</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12921]] Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs(https://arxiv.org/abs/2601.12921)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.</li>
</ul>

<h3>Title: Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Johannes Kaiser, Alexander Ziller, Eleni Triantafillou, Daniel Rückert, Georgios Kaissis</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12922">https://arxiv.org/abs/2601.12922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12922">https://arxiv.org/pdf/2601.12922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12922]] Your Privacy Depends on Others: Collusion Vulnerabilities in Individual Differential Privacy(https://arxiv.org/abs/2601.12922)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Individual Differential Privacy (iDP) promises users control over their privacy, but this promise can be broken in practice. We reveal a previously overlooked vulnerability in sampling-based iDP mechanisms: while conforming to the iDP guarantees, an individual's privacy risk is not solely governed by their own privacy budget, but critically depends on the privacy choices of all other data contributors. This creates a mismatch between the promise of individual privacy control and the reality of a system where risk is collectively determined. We demonstrate empirically that certain distributions of privacy preferences can unintentionally inflate the privacy risk of individuals, even when their formal guarantees are met. Moreover, this excess risk provides an exploitable attack vector. A central adversary or a set of colluding adversaries can deliberately choose privacy budgets to amplify vulnerabilities of targeted individuals. Most importantly, this attack operates entirely within the guarantees of DP, hiding this excess vulnerability. Our empirical evaluation demonstrates successful attacks against 62% of targeted individuals, substantially increasing their membership inference susceptibility. To mitigate this, we propose $(\varepsilon_i,\delta_i,\overline{\Delta})$-iDP a privacy contract that uses $\Delta$-divergences to provide users with a hard upper bound on their excess vulnerability, while offering flexibility to mechanism design. Our findings expose a fundamental challenge to the current paradigm, demanding a re-evaluation of how iDP systems are designed, audited, communicated, and deployed to make excess risks transparent and controllable.</li>
</ul>

<h3>Title: Dual-Stream Collaborative Transformer for Image Captioning</h3>
<ul>
<li><strong>Authors: </strong>Jun Wan, Jun Liu, Zhihui lai, Jie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12926">https://arxiv.org/abs/2601.12926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12926">https://arxiv.org/pdf/2601.12926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12926]] Dual-Stream Collaborative Transformer for Image Captioning(https://arxiv.org/abs/2601.12926)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.</li>
</ul>

<h3>Title: Membership Inference Test: Auditing Training Data in Object Classification Models</h3>
<ul>
<li><strong>Authors: </strong>Gonzalo Mancera, Daniel DeAlcala, Aythami Morales, Ruben Tolosana, Julian Fierrez</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12929">https://arxiv.org/abs/2601.12929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12929">https://arxiv.org/pdf/2601.12929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12929]] Membership Inference Test: Auditing Training Data in Object Classification Models(https://arxiv.org/abs/2601.12929)</code><input type="text"></li>
<li><strong>Keywords: </strong>membership infer</a></li>
<li><strong>Abstract: </strong>In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.</li>
</ul>

<h3>Title: Online Continual Learning for Time Series: a Natural Score-driven Approach</h3>
<ul>
<li><strong>Authors: </strong>Edoardo Urettini, Daniele Atzeni, Ioanna-Yvonni Tsaknaki, Antonio Carta</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12931">https://arxiv.org/abs/2601.12931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12931">https://arxiv.org/pdf/2601.12931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12931]] Online Continual Learning for Time Series: a Natural Score-driven Approach(https://arxiv.org/abs/2601.12931)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Online continual learning (OCL) methods adapt to changing environments without forgetting past knowledge. Similarly, online time series forecasting (OTSF) is a real-world problem where data evolve in time and success depends on both rapid adaptation and long-term memory. Indeed, time-varying and regime-switching forecasting models have been extensively studied, offering a strong justification for the use of OCL in these settings. Building on recent work that applies OCL to OTSF, this paper aims to strengthen the theoretical and practical connections between time series methods and OCL. First, we reframe neural network optimization as a parameter filtering problem, showing that natural gradient descent is a score-driven method and proving its information-theoretic optimality. Then, we show that using a Student's t likelihood in addition to natural gradient induces a bounded update, which improves robustness to outliers. Finally, we introduce Natural Score-driven Replay (NatSR), which combines our robust optimizer with a replay buffer and a dynamic scale heuristic that improves fast adaptation at regime drifts. Empirical results demonstrate that NatSR achieves stronger forecasting performance than more complex state-of-the-art methods.</li>
</ul>

<h3>Title: On the Evidentiary Limits of Membership Inference for Copyright Auditing</h3>
<ul>
<li><strong>Authors: </strong>Murat Bilgehan Ertan, Emirhan Böge, Min Chen, Kaleel Mahmood, Marten van Dijk</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12937">https://arxiv.org/abs/2601.12937</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12937">https://arxiv.org/pdf/2601.12937</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12937]] On the Evidentiary Limits of Membership Inference for Copyright Auditing(https://arxiv.org/abs/2601.12937)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, extraction, membership infer, large language model</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) are trained on increasingly opaque corpora, membership inference attacks (MIAs) have been proposed to audit whether copyrighted texts were used during training, despite growing concerns about their reliability under realistic conditions. We ask whether MIAs can serve as admissible evidence in adversarial copyright disputes where an accused model developer may obfuscate training data while preserving semantic content, and formalize this setting through a judge-prosecutor-accused communication protocol. To test robustness under this protocol, we introduce SAGE (Structure-Aware SAE-Guided Extraction), a paraphrasing framework guided by Sparse Autoencoders (SAEs) that rewrites training data to alter lexical structure while preserving semantic content and downstream utility. Our experiments show that state-of-the-art MIAs degrade when models are fine-tuned on SAGE-generated paraphrases, indicating that their signals are not robust to semantics-preserving transformations. While some leakage remains in certain fine-tuning regimes, these results suggest that MIAs are brittle in adversarial settings and insufficient, on their own, as a standalone mechanism for copyright auditing of LLMs.</li>
</ul>

<h3>Title: A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits</h3>
<ul>
<li><strong>Authors: </strong>Miao Xie, Siguang Chen, Chunli Lv</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12945">https://arxiv.org/abs/2601.12945</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12945">https://arxiv.org/pdf/2601.12945</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12945]] A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits(https://arxiv.org/abs/2601.12945)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at this https URL.</li>
</ul>

<h3>Title: GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation</h3>
<ul>
<li><strong>Authors: </strong>Riccardo Catalini, Davide Di Nucci, Guido Borghi, Davide Davoli, Lorenzo Garattoni, Giampiero Francesca, Yuki Kawana, Roberto Vezzani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12948">https://arxiv.org/abs/2601.12948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12948">https://arxiv.org/pdf/2601.12948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12948]] GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation(https://arxiv.org/abs/2601.12948)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at this https URL.</li>
</ul>

<h3>Title: StyMam: A Mamba-Based Generator for Artistic Style Transfer</h3>
<ul>
<li><strong>Authors: </strong>Zhou Hong, Rongsheng Hu, Yicheng Di, Xiaolong Xu, Ning Dong, Yihua Shao, Run Ling, Yun Wang, Juqin Wang, Zhanjie Zhang, Ao Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12954">https://arxiv.org/abs/2601.12954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12954">https://arxiv.org/pdf/2601.12954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12954]] StyMam: A Mamba-Based Generator for Artistic Style Transfer(https://arxiv.org/abs/2601.12954)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.</li>
</ul>

<h3>Title: Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>John Waithaka, Gustave Bwirayesu, Moise Busogi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12964">https://arxiv.org/abs/2601.12964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12964">https://arxiv.org/pdf/2601.12964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12964]] Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation(https://arxiv.org/abs/2601.12964)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.</li>
</ul>

<h3>Title: Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning</h3>
<ul>
<li><strong>Authors: </strong>Doheon Kim</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12965">https://arxiv.org/abs/2601.12965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12965">https://arxiv.org/pdf/2601.12965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12965]] Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning(https://arxiv.org/abs/2601.12965)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.</li>
</ul>

<h3>Title: Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients</h3>
<ul>
<li><strong>Authors: </strong>Pancheng Niu, Jun Guo, Qiaolin He, Yongming Chen, Yanchao Shi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12971">https://arxiv.org/abs/2601.12971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12971">https://arxiv.org/pdf/2601.12971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12971]] Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients(https://arxiv.org/abs/2601.12971)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.</li>
</ul>

<h3>Title: Pardon? Evaluating Conversational Repair in Large Audio-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shuanghong Huang, Jinlei Xu, Youchao Zhou, Yanghao Zhou, Xuan Zhao, Chong Feng, Wenxuan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12973">https://arxiv.org/abs/2601.12973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12973">https://arxiv.org/pdf/2601.12973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12973]] Pardon? Evaluating Conversational Repair in Large Audio-Language Models(https://arxiv.org/abs/2601.12973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.</li>
</ul>

<h3>Title: Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Hongyang Ma, Tiantian Gu, Huaiyuan Sun, Huilin Zhu, Yongxin Wang, Jie Li, Wubin Sun, Zeliang Lian, Yinghong Zhou, Yi Gao, Shirui Wang, Zhihui Tang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12974">https://arxiv.org/abs/2601.12974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12974">https://arxiv.org/pdf/2601.12974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12974]] Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios(https://arxiv.org/abs/2601.12974)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping "Guideline Adherence" versus "Decision Quality" reveals a prevalent "High Efficacy, Low Safety" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.</li>
</ul>

<h3>Title: Reproducibility in Event-Log Research: A Parametrised Generator and Benchmark for Event-based Signatures</h3>
<ul>
<li><strong>Authors: </strong>Saad Khan, Simon Parkinson, Monika Roopak</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12978">https://arxiv.org/abs/2601.12978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12978">https://arxiv.org/pdf/2601.12978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12978]] Reproducibility in Event-Log Research: A Parametrised Generator and Benchmark for Event-based Signatures(https://arxiv.org/abs/2601.12978)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Event-based datasets are crucial for cybersecurity analysis. A key use case is detecting event-based signatures, which represent attacks spanning multiple events and can only be understood once the relevant events are identified and linked. Analysing event datasets is essential for monitoring system security, but their growing volume and frequency create significant scalability and processing difficulties. Researchers rely on these datasets to develop and test techniques for automatically identifying signatures. However, because real datasets are security-sensitive and rarely shared, it becomes difficult to perform meaningful comparative evaluation between different approaches. This work addresses this evaluation limitation by offering a systematic method for generating event logs with known ground truth, enabling reproducible and comparable research. We present a novel parametrised generation technique capable of producing synthetic event datasets that contain event-based signatures for discovery. To demonstrate the capabilities of the technique, we provide a benchmark in signature detection. Our benchmarking demonstrated the suitability of DBSCAN, achieving a score greater than 0.95 Adjusted Rand Index on most generated datasets. This work enhances the ability of researchers to develop and benchmark new cybersecurity techniques, ultimately contributing to more robust and effective cybersecurity measures.</li>
</ul>

<h3>Title: The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check</h3>
<ul>
<li><strong>Authors: </strong>Qingyu Lu, Liang Ding, Kanjian Zhang, Jinxia Zhang, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12979">https://arxiv.org/abs/2601.12979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12979">https://arxiv.org/pdf/2601.12979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12979]] The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check(https://arxiv.org/abs/2601.12979)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a "bitter lesson": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.</li>
</ul>

<h3>Title: Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers</h3>
<ul>
<li><strong>Authors: </strong>Sulaiman Khan, Md. Rafiul Biswas, Zubair Shah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12981">https://arxiv.org/abs/2601.12981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12981">https://arxiv.org/pdf/2601.12981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12981]] Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers(https://arxiv.org/abs/2601.12981)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population. Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data</li>
</ul>

<h3>Title: ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation</h3>
<ul>
<li><strong>Authors: </strong>Jesus-German Ortiz-Barajas, Jonathan Tonglet, Vivek Gupta, Iryna Gurevych</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12983">https://arxiv.org/abs/2601.12983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12983">https://arxiv.org/pdf/2601.12983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12983]] ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation(https://arxiv.org/abs/2601.12983)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.</li>
</ul>

<h3>Title: KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing</h3>
<ul>
<li><strong>Authors: </strong>Zhenhua Xu, Xiaoning Tian, Wenjun Zeng, Wenpeng Xing, Tianliang Lu, Gaolei Li, Chaochao Chen, Meng Han</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12986">https://arxiv.org/abs/2601.12986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12986">https://arxiv.org/pdf/2601.12986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12986]] KinGuard: Hierarchical Kinship-Aware Fingerprinting to Defend Against Large Language Model Stealing(https://arxiv.org/abs/2601.12986)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, protect, attack, robust, steal, large language model</a></li>
<li><strong>Abstract: </strong>Protecting the intellectual property of large language models requires robust ownership verification. Conventional backdoor fingerprinting, however, is flawed by a stealth-robustness paradox: to be robust, these methods force models to memorize fixed responses to high-perplexity triggers, but this targeted overfitting creates detectable statistical artifacts. We resolve this paradox with KinGuard, a framework that embeds a private knowledge corpus built on structured kinship narratives. Instead of memorizing superficial triggers, the model internalizes this knowledge via incremental pre-training, and ownership is verified by probing its conceptual understanding. Extensive experiments demonstrate KinGuard's superior effectiveness, stealth, and resilience against a battery of attacks including fine-tuning, input perturbation, and model merging. Our work establishes knowledge-based embedding as a practical and secure paradigm for model fingerprinting.</li>
</ul>

<h3>Title: PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient</h3>
<ul>
<li><strong>Authors: </strong>Zijian Wang, Tiancheng Huang, Hanqi Li, Da Ma, Lu Chen, Kai Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12988">https://arxiv.org/abs/2601.12988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12988">https://arxiv.org/pdf/2601.12988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12988]] PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient(https://arxiv.org/abs/2601.12988)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.</li>
</ul>

<h3>Title: AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Shiming Wang, Holger Caesar, Liangliang Nan, Julian F. P. Kooij</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12994">https://arxiv.org/abs/2601.12994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12994">https://arxiv.org/pdf/2601.12994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12994]] AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection(https://arxiv.org/abs/2601.12994)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.</li>
</ul>

<h3>Title: Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Runxuan Liu, Xianhao Ou, Xinyan Ma, Jiyuan Wang, Jiafeng Liang, Jiaqi Li, Tao He, Zheng Chu, Rongchuan Mu, Zekun Wang, Baoxin Wang, Dayong Wu, Ming Liu, Shijin Wang, Guoping Hu, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.12995">https://arxiv.org/abs/2601.12995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.12995">https://arxiv.org/pdf/2601.12995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.12995]] Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models(https://arxiv.org/abs/2601.12995)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.</li>
</ul>

<h3>Title: PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT</h3>
<ul>
<li><strong>Authors: </strong>Safaa Menssouri, El Mehdi Amhoud</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13003">https://arxiv.org/abs/2601.13003</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13003">https://arxiv.org/pdf/2601.13003</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13003]] PrivFly: A Privacy-Preserving Self-Supervised Framework for Rare Attack Detection in IoFT(https://arxiv.org/abs/2601.13003)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>The Internet of Flying Things (IoFT) plays a vital role in modern applications such as aerial surveillance and smart mobility. However, it remains highly vulnerable to cyberattacks that threaten the confidentiality, integrity, and availability of sensitive data. Developing effective intrusion detection systems (IDS) for IoFT networks faces key challenges, including data imbalance, privacy concerns, and the limited capability of traditional models to detect rare but potentially damaging cyber threats. In this work, we propose PrivFly, a privacy-preserving IDS framework that integrates self-supervised representation learning and differential privacy (DP) to enhance detection performance in imbalanced IoFT network traffic. We propose a masked feature reconstruction module for self-supervised pretraining, improving feature representations and boosting rare-class detection. Differential privacy is applied during training to protect sensitive information without significantly compromising model performance. In addition, we conduct a SHapley additive explanations (SHAP)-based analysis to evaluate the impact of DP on feature importance and model behavior. Experimental results on the ECU-IoFT dataset show that PrivFly achieves up to 98% accuracy and 99% F1-score, effectively balancing privacy and detection performance for secure IoFT systems.</li>
</ul>

<h3>Title: HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads</h3>
<ul>
<li><strong>Authors: </strong>Xiaohui Zhao, Xinjian Zhao, Jiahui Zhang, Guoyu Liu, Houzhi Wang, Shu Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13013">https://arxiv.org/abs/2601.13013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13013">https://arxiv.org/pdf/2601.13013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13013]] HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads(https://arxiv.org/abs/2601.13013)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.</li>
</ul>

<h3>Title: Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context</h3>
<ul>
<li><strong>Authors: </strong>Ghislain Dorian Tchuente Mondjo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13018">https://arxiv.org/abs/2601.13018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13018">https://arxiv.org/pdf/2601.13018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13018]] Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context(https://arxiv.org/abs/2601.13018)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.</li>
</ul>

<h3>Title: PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhiyan Hou, Haiyun Guo, Haokai Ma, Yandu Sun, Yonghui Yang, Jinqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13020">https://arxiv.org/abs/2601.13020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13020">https://arxiv.org/pdf/2601.13020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13020]] PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning(https://arxiv.org/abs/2601.13020)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates this http URL address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.</li>
</ul>

<h3>Title: Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis</h3>
<ul>
<li><strong>Authors: </strong>Nataša Petrović, Gabriel Moyà-Alcover, Antoni Jaume-i-Capó, Jose Maria Buades Rubio</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13021">https://arxiv.org/abs/2601.13021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13021">https://arxiv.org/pdf/2601.13021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13021]] Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis(https://arxiv.org/abs/2601.13021)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\% and SDS-score 89.51\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.</li>
</ul>

<h3>Title: Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses</h3>
<ul>
<li><strong>Authors: </strong>Chongyuan Dai, Yaling Shen, Jinpeng Hu, Zihan Gao, Jia Li, Yishun Jiang, Yaxiong Wang, Liu Liu, Zongyuan Ge</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13024">https://arxiv.org/abs/2601.13024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13024">https://arxiv.org/pdf/2601.13024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13024]] Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses(https://arxiv.org/abs/2601.13024)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \underline{\textsc{E}}licited \underline{\textsc{D}}istinct \underline{\textsc{A}}ffective \underline{\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.</li>
</ul>

<h3>Title: Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Bitzer, Maximilian Egger, Mumin Liu, Antonia Wachter-Zeh</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.IT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13031">https://arxiv.org/abs/2601.13031</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13031">https://arxiv.org/pdf/2601.13031</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13031]] Post-Quantum Secure Aggregation via Code-Based Homomorphic Encryption(https://arxiv.org/abs/2601.13031)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Secure aggregation enables aggregation of inputs from multiple parties without revealing individual contributions to the server or other clients. Existing post-quantum approaches based on homomorphic encryption offer practical efficiency but predominantly rely on lattice-based hardness assumptions. We present a code-based alternative for secure aggregation by instantiating a general framework based on key- and message-additive homomorphic encryption under the Learning Parity with Noise (LPN) assumption. Our construction employs a committee-based decryptor realized via secret sharing and incorporates a Chinese Remainder Theorem (CRT)-based optimization to reduce the communication costs of LPN-based instantiations. We analyze the security of the proposed scheme under a new Hint-LPN assumption and show that it is equivalent to standard LPN for suitable parameters. Finally, we evaluate performance and identify regimes in which our approach outperforms information-theoretically secure aggregation protocols.</li>
</ul>

<h3>Title: High-Throughput and Scalable Secure Inference Protocols for Deep Learning with Packed Secret Sharing</h3>
<ul>
<li><strong>Authors: </strong>Qinghui Zhang, Xiaojun Chen, Yansong Zhang, Xudong Chen</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13041">https://arxiv.org/abs/2601.13041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13041">https://arxiv.org/pdf/2601.13041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13041]] High-Throughput and Scalable Secure Inference Protocols for Deep Learning with Packed Secret Sharing(https://arxiv.org/abs/2601.13041)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Most existing secure neural network inference protocols based on secure multi-party computation (MPC) typically support at most four participants, demonstrating severely limited scalability. Liu et al. (USENIX Security'24) presented the first relatively practical approach by utilizing Shamir secret sharing with Mersenne prime fields. However, when processing deeper neural networks such as VGG16, their protocols incur substantial communication overhead, resulting in particularly significant latency in wide-area network (WAN) environments. In this paper, we propose a high-throughput and scalable MPC protocol for neural network inference against semi-honest adversaries in the honest-majority setting. The core of our approach lies in leveraging packed Shamir secret sharing (PSS) to enable parallel computation and reduce communication complexity. The main contributions are three-fold: i) We present a communication-efficient protocol for vector-matrix multiplication, based on our newly defined notion of vector-matrix multiplication-friendly random share tuples. ii) We design the filter packing approach that enables parallel convolution. iii) We further extend all non-linear protocols based on Shamir secret sharing to the PSS-based protocols for achieving parallel non-linear operations. Extensive experiments across various datasets and neural networks demonstrate the superiority of our approach in WAN. Compared to Liu et al. (USENIX Security'24), our scheme reduces the communication upto 5.85x, 11.17x, and 6.83x in offline, online and total communication overhead, respectively. In addition, our scheme is upto 1.59x, 2.61x, and 1.75x faster in offline, online and total running time, respectively.</li>
</ul>

<h3>Title: Analysis of Long Range Dependency Understanding in State Space Models</h3>
<ul>
<li><strong>Authors: </strong>Srividya Ravikumar, Abhinav Anand, Shweta Verma, Mira Mezini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13048">https://arxiv.org/abs/2601.13048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13048">https://arxiv.org/pdf/2601.13048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13048]] Analysis of Long Range Dependency Understanding in State Space Models(https://arxiv.org/abs/2601.13048)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.</li>
</ul>

<h3>Title: Profiling German Text Simplification with Interpretable Model-Fingerprints</h3>
<ul>
<li><strong>Authors: </strong>Lars Klöser, Mika Beele, Bodo Kraft</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13050">https://arxiv.org/abs/2601.13050</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13050">https://arxiv.org/pdf/2601.13050</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13050]] Profiling German Text Simplification with Interpretable Model-Fingerprints(https://arxiv.org/abs/2601.13050)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.</li>
</ul>

<h3>Title: GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure</h3>
<ul>
<li><strong>Authors: </strong>Antoine Carreaud, Shanci Li, Malo De Lacour, Digre Frinde, Jan Skaloud, Adrien Gressin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13052">https://arxiv.org/abs/2601.13052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13052">https://arxiv.org/pdf/2601.13052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13052]] GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure(https://arxiv.org/abs/2601.13052)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: this https URL.</li>
</ul>

<h3>Title: Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures</h3>
<ul>
<li><strong>Authors: </strong>Yulun Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13059">https://arxiv.org/abs/2601.13059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13059">https://arxiv.org/pdf/2601.13059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13059]] Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures(https://arxiv.org/abs/2601.13059)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: this https URL.</li>
</ul>

<h3>Title: Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading</h3>
<ul>
<li><strong>Authors: </strong>Advije Rizvani, Giovanni Apruzzese, Pavel Laskov</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13082">https://arxiv.org/abs/2601.13082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13082">https://arxiv.org/pdf/2601.13082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13082]] Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading(https://arxiv.org/abs/2601.13082)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft "adversarial news" intended to mislead an LLM. In particular, the news headline may include "malicious" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.</li>
</ul>

<h3>Title: Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups</h3>
<ul>
<li><strong>Authors: </strong>Gelei Xu, Yuying Duan, Jun Xia, Ruining Deng, Wei Jin, Yiyu Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13094">https://arxiv.org/abs/2601.13094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13094">https://arxiv.org/pdf/2601.13094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13094]] Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups(https://arxiv.org/abs/2601.13094)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair</a></li>
<li><strong>Abstract: </strong>AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.</li>
</ul>

<h3>Title: Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs</h3>
<ul>
<li><strong>Authors: </strong>Abdellah El Mekki, Samar M. Magdy, Houdaifa Atou, Ruwa AbuHweidi, Baraah Qawasmeh, Omer Nacar, Thikra Al-hibiri, Razan Saadie, Hamzah Alsayadi, Nadia Ghezaiel Hammouda, Alshima Alkhazimi, Aya Hamod, Al-Yas Al-Ghafri, Wesam El-Sayed, Asila Al sharji, Mohamad Ballout, Anas Belfathi, Karim Ghaddar, Serry Sibaee, Alaa Aoun, Areej Asiri, Lina Abureesh, Ahlam Bashiti, Majdal Yousef, Abdulaziz Hafiz, Yehdih Mohamed, Emira Hamedtou, Brakehe Brahim, Rahaf Alhamouri, Youssef Nafea, Aya El Aatar, Walid Al-Dhabyani, Emhemed Hamed, Sara Shatnawi, Fakhraddin Alwajih, Khalid Elkhidir, Ashwag Alasmari, Abdurrahman Gerrio, Omar Alshahri, AbdelRahim A. Elmadany, Ismail Berrada, Amir Azad Adli Alkathiri, Fadi A Zaraket, Mustafa Jarrar, Yahya Mohamed El Hadj, Hassan Alhuzali, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13099">https://arxiv.org/abs/2601.13099</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13099">https://arxiv.org/pdf/2601.13099</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13099]] Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs(https://arxiv.org/abs/2601.13099)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.</li>
</ul>

<h3>Title: Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification</h3>
<ul>
<li><strong>Authors: </strong>Liu Kaipeng, Wu Ling</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13105">https://arxiv.org/abs/2601.13105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13105">https://arxiv.org/pdf/2601.13105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13105]] Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification(https://arxiv.org/abs/2601.13105)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.</li>
</ul>

<h3>Title: CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiaolei Zhang, Xiaojun Jia, Liquan Chen, Songze Li</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13112">https://arxiv.org/abs/2601.13112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13112">https://arxiv.org/pdf/2601.13112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13112]] CODE: A Contradiction-Based Deliberation Extension Framework for Overthinking Attacks on Retrieval-Augmented Generation(https://arxiv.org/abs/2601.13112)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Introducing reasoning models into Retrieval-Augmented Generation (RAG) systems enhances task performance through step-by-step reasoning, logical consistency, and multi-step self-verification. However, recent studies have shown that reasoning models suffer from overthinking attacks, where models are tricked to generate unnecessarily high number of reasoning tokens. In this paper, we reveal that such overthinking risk can be inherited by RAG systems equipped with reasoning models, by proposing an end-to-end attack framework named Contradiction-Based Deliberation Extension (CODE). Specifically, CODE develops a multi-agent architecture to construct poisoning samples that are injected into the knowledge base. These samples 1) are highly correlated with the use query, such that can be retrieved as inputs to the reasoning model; and 2) contain contradiction between the logical and evidence layers that cause models to overthink, and are optimized to exhibit highly diverse styles. Moreover, the inference overhead of CODE is extremely difficult to detect, as no modification is needed on the user query, and the task accuracy remain unaffected. Extensive experiments on two datasets across five commercial reasoning models demonstrate that the proposed attack causes a 5.32x-24.72x increase in reasoning token consumption, without degrading task performance. Finally, we also discuss and evaluate potential countermeasures to mitigate overthinking risks.</li>
</ul>

<h3>Title: Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Fengran Mo, Yifan Gao, Sha Li, Hansi Zeng, Xin Liu, Zhaoxuan Tan, Xian Li, Jianshu Chen, Dakuo Wang, Meng Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13115">https://arxiv.org/abs/2601.13115</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13115">https://arxiv.org/pdf/2601.13115</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13115]] Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning(https://arxiv.org/abs/2601.13115)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.</li>
</ul>

<h3>Title: A Streamlined Attention-Based Network for Descriptor Extraction</h3>
<ul>
<li><strong>Authors: </strong>Mattia D'Urso, Emanuele Santellani, Christian Sormann, Mattia Rossi, Andreas Kuhn, Friedrich Fraundorfer</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13126">https://arxiv.org/abs/2601.13126</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13126">https://arxiv.org/pdf/2601.13126</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13126]] A Streamlined Attention-Based Network for Descriptor Extraction(https://arxiv.org/abs/2601.13126)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description. Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability. Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters. As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.</li>
</ul>

<h3>Title: PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain</h3>
<ul>
<li><strong>Authors: </strong>Sung Ju Lee, Nam Ik Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13128">https://arxiv.org/abs/2601.13128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13128">https://arxiv.org/pdf/2601.13128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13128]] PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain(https://arxiv.org/abs/2601.13128)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, watermark, diffusion</a></li>
<li><strong>Abstract: </strong>The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.</li>
</ul>

<h3>Title: CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks</h3>
<ul>
<li><strong>Authors: </strong>Mingshuang Luo, Ruibing Hou, Bo Chao, Hong Chang, Zimo Liu, Yaowei Wang, Shiguang Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13133">https://arxiv.org/abs/2601.13133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13133">https://arxiv.org/pdf/2601.13133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13133]] CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks(https://arxiv.org/abs/2601.13133)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.</li>
</ul>

<h3>Title: Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains</h3>
<ul>
<li><strong>Authors: </strong>Yuan Gao, Zhigang Liu, Xinyu Yao, Bo Chen, Xiaobing Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13137">https://arxiv.org/abs/2601.13137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13137">https://arxiv.org/pdf/2601.13137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13137]] Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains(https://arxiv.org/abs/2601.13137)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.</li>
</ul>

<h3>Title: FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference</h3>
<ul>
<li><strong>Authors: </strong>Chaeyoung Jung, Youngjoon Jang, Seungwoo Lee, Joon Son Chung</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13143">https://arxiv.org/abs/2601.13143</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13143">https://arxiv.org/pdf/2601.13143</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13143]] FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference(https://arxiv.org/abs/2601.13143)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.</li>
</ul>

<h3>Title: Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference</h3>
<ul>
<li><strong>Authors: </strong>Zimeng Wu, Donghao Wang, Chaozhe Jin, Jiaxin Chen, Yunhong Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13155">https://arxiv.org/abs/2601.13155</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13155">https://arxiv.org/pdf/2601.13155</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13155]] Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference(https://arxiv.org/abs/2601.13155)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\times$ and 2.29$\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.</li>
</ul>

<h3>Title: Training instability in deep learning follows low-dimensional dynamical principles</h3>
<ul>
<li><strong>Authors: </strong>Zhipeng Zhang, Zhenjie Yao, Kai Li, Lei Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13160">https://arxiv.org/abs/2601.13160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13160">https://arxiv.org/pdf/2601.13160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13160]] Training instability in deep learning follows low-dimensional dynamical principles(https://arxiv.org/abs/2601.13160)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability. We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms. Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.</li>
</ul>

<h3>Title: NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness</h3>
<ul>
<li><strong>Authors: </strong>Ali Shafiee Sarvestani, Jason Schmidt, Arman Roohi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13162">https://arxiv.org/abs/2601.13162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13162">https://arxiv.org/pdf/2601.13162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13162]] NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness(https://arxiv.org/abs/2601.13162)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, interpretability, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\ell_\infty$ perturbation budget of $\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\% and 17.35\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.</li>
</ul>

<h3>Title: From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models</h3>
<ul>
<li><strong>Authors: </strong>Pedro M. Gordaliza, Jaume Banus, Benoît Gérin, Maxence Wynen, Nataliia Molchanova, Jonas Richiardi, Meritxell Bach Cuadra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13166">https://arxiv.org/abs/2601.13166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13166">https://arxiv.org/pdf/2601.13166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13166]] From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models(https://arxiv.org/abs/2601.13166)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: this https URL.</li>
</ul>

<h3>Title: LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations</h3>
<ul>
<li><strong>Authors: </strong>Vittoria De Pellegrini, Tariq Alkhalifah</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13190">https://arxiv.org/abs/2601.13190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13190">https://arxiv.org/pdf/2601.13190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13190]] LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations(https://arxiv.org/abs/2601.13190)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.</li>
</ul>

<h3>Title: Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification</h3>
<ul>
<li><strong>Authors: </strong>Aravind B, Anirud R.S., Sai Surya Teja N, Bala Subrahmanya Sriranga Navaneeth A, Karthika R, Mohankumar N</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13197">https://arxiv.org/abs/2601.13197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13197">https://arxiv.org/pdf/2601.13197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13197]] Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification(https://arxiv.org/abs/2601.13197)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, diffusion</a></li>
<li><strong>Abstract: </strong>Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.</li>
</ul>

<h3>Title: GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jinnao Li, Zijian Chen, Tingzhu Chen, Changbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13207">https://arxiv.org/abs/2601.13207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13207">https://arxiv.org/pdf/2601.13207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13207]] GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction(https://arxiv.org/abs/2601.13207)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.</li>
</ul>

<h3>Title: Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising</h3>
<ul>
<li><strong>Authors: </strong>Vikram R Lakkavalli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13208">https://arxiv.org/abs/2601.13208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13208">https://arxiv.org/pdf/2601.13208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13208]] Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising(https://arxiv.org/abs/2601.13208)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels {\sigma} = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.</li>
</ul>

<h3>Title: ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments</h3>
<ul>
<li><strong>Authors: </strong>Igor Vozniak, Philipp Mueller, Nils Lipp, Janis Sprenger, Konstantin Poddubnyy, Davit Hovhannisyan, Christian Mueller, Andreas Bulling, Philipp Slusallek</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13218">https://arxiv.org/abs/2601.13218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13218">https://arxiv.org/pdf/2601.13218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13218]] ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments(https://arxiv.org/abs/2601.13218)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.</li>
</ul>

<h3>Title: Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation</h3>
<ul>
<li><strong>Authors: </strong>Tianqi Du, Lizhe Fang, Weijie Yang, Chenheng Zhang, Zeming Wei, Yifei Wang, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13228">https://arxiv.org/abs/2601.13228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13228">https://arxiv.org/pdf/2601.13228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13228]] Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation(https://arxiv.org/abs/2601.13228)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.</li>
</ul>

<h3>Title: ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection</h3>
<ul>
<li><strong>Authors: </strong>Md. Nishan Khan, Kazi Shahriar Sanjid, Md. Tanzim Hossain, Asib Mostakim Fony, Istiak Ahmed, M. Monir Uddin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13234">https://arxiv.org/abs/2601.13234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13234">https://arxiv.org/pdf/2601.13234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13234]] ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection(https://arxiv.org/abs/2601.13234)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.</li>
</ul>

<h3>Title: A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chengyin Hu, Xiang Chen, Zhe Jia, Weiwen Shi, Fengyu Zhang, Jiujiang Guo, Yiwei Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13238">https://arxiv.org/abs/2601.13238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13238">https://arxiv.org/pdf/2601.13238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13238]] A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models(https://arxiv.org/abs/2601.13238)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.</li>
</ul>

<h3>Title: A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms</h3>
<ul>
<li><strong>Authors: </strong>Yapeng Li, Jiakuo Yu, Zhixin Liu, Xinnan Liu, Jing Yu, Songze Li, Tonghua Su</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13243">https://arxiv.org/abs/2601.13243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13243">https://arxiv.org/pdf/2601.13243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13243]] A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms(https://arxiv.org/abs/2601.13243)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at this https URL.</li>
</ul>

<h3>Title: Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Prateek Munjal, Clement Christophe, Ronnie Rajan, Praveenkumar Kanithi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13244">https://arxiv.org/abs/2601.13244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13244">https://arxiv.org/pdf/2601.13244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13244]] Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks(https://arxiv.org/abs/2601.13244)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.</li>
</ul>

<h3>Title: Aligning Agentic World Models via Knowledgeable Experience Learning</h3>
<ul>
<li><strong>Authors: </strong>Baochang Ren, Yunzhi Yao, Rui Sun, Shuofei Qiao, Ningyu Zhang, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.LG, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13247">https://arxiv.org/abs/2601.13247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13247">https://arxiv.org/pdf/2601.13247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13247]] Aligning Agentic World Models via Knowledgeable Experience Learning(https://arxiv.org/abs/2601.13247)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.</li>
</ul>

<h3>Title: Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph</h3>
<ul>
<li><strong>Authors: </strong>Ebubekir Tosun, Mehmet Emin Buldur, Özay Ezerceli, Mahmoud ElHussieni</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13251">https://arxiv.org/abs/2601.13251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13251">https://arxiv.org/pdf/2601.13251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13251]] Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph(https://arxiv.org/abs/2601.13251)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.</li>
</ul>

<h3>Title: Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sawsan Alqahtani, Mir Tafseer Nayeem, Md Tahmid Rahman Laskar, Tasnim Mohiuddin, M Saiful Bari</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13260">https://arxiv.org/abs/2601.13260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13260">https://arxiv.org/pdf/2601.13260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13260]] Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models(https://arxiv.org/abs/2601.13260)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.</li>
</ul>

<h3>Title: Deep Learning for Semantic Segmentation of 3D Ultrasound Data</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Liu, Marco Cecotti, Harikrishnan Vijayakumar, Patrick Robinson, James Barson, Mihai Caleap</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13263">https://arxiv.org/abs/2601.13263</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13263">https://arxiv.org/pdf/2601.13263</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13263]] Deep Learning for Semantic Segmentation of 3D Ultrasound Data(https://arxiv.org/abs/2601.13263)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.</li>
</ul>

<h3>Title: Unlearning in LLMs: Methods, Evaluation, and Open Challenges</h3>
<ul>
<li><strong>Authors: </strong>Tyler Lizzo, Larry Heck</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13264">https://arxiv.org/abs/2601.13264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13264">https://arxiv.org/pdf/2601.13264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13264]] Unlearning in LLMs: Methods, Evaluation, and Open Challenges(https://arxiv.org/abs/2601.13264)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.</li>
</ul>

<h3>Title: Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving</h3>
<ul>
<li><strong>Authors: </strong>Chao Yin, Zunchen Huang, Chenglu Jin, Marten van Dijk, Fabio Massacci</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13271">https://arxiv.org/abs/2601.13271</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13271">https://arxiv.org/pdf/2601.13271</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13271]] Function Recovery Attacks in Gate-Hiding Garbled Circuits using SAT Solving(https://arxiv.org/abs/2601.13271)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Semi-Private Function Evaluation enables joint computation while protecting both input data and function logic. A practical instantiation is gate-hiding garbled circuits, which conceal gate functionalities while revealing the circuit topology. Existing security definitions intentionally exclude leakage through circuit topology, leaving the concrete impact of such leakage on function privacy insufficiently understood. We analyze the empirical security of gate hiding under two adversarial models that capture realistic computational capabilities. We present a SAT-based function-recovery attack that reconstructs hidden gate operations from a circuit's public topology. To enable recovery on larger and more complex circuits, we develop an incremental SAT-solving framework combined with a set of composable, topology-preserving simplification theorems. These techniques jointly reduce the SAT instance size and progressively constrain the search space across repeated solving iterations. We evaluate our attack on ISCAS benchmarks, representative secure computation circuits, and fault-tolerant sensor fusion circuits under a fixed 24-hour recovery budget. Compared to baseline approaches, our optimized attack achieves up to a 159-fold speedup in recovery time without increasing the number of oracle queries. Our results demonstrate that topology leakage alone can enable effective function recovery in practice.</li>
</ul>

<h3>Title: Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Duygu Nur Yaldiz, Evangelia Spiliopoulou, Zheng Qi, Siddharth Varia, Srikanth Doss, Nikolaos Pappas</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13284">https://arxiv.org/abs/2601.13284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13284">https://arxiv.org/pdf/2601.13284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13284]] Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning(https://arxiv.org/abs/2601.13284)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.</li>
</ul>

<h3>Title: Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams</h3>
<ul>
<li><strong>Authors: </strong>Ethan Seefried, Prahitha Movva, Naga Harshita Marupaka, Tilak Kasturi, Tirthankar Ghosal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13299">https://arxiv.org/abs/2601.13299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13299">https://arxiv.org/pdf/2601.13299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13299]] Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams(https://arxiv.org/abs/2601.13299)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.</li>
</ul>

<h3>Title: OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference</h3>
<ul>
<li><strong>Authors: </strong>Yow-Fu Liou, Yu-Chien Tang, Yu-Hsiang Liu, An-Zi Yen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13300">https://arxiv.org/abs/2601.13300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13300">https://arxiv.org/pdf/2601.13300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13300]] OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference(https://arxiv.org/abs/2601.13300)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.</li>
</ul>

<h3>Title: Verifying Local Robustness of Pruned Safety-Critical Networks</h3>
<ul>
<li><strong>Authors: </strong>Minh Le, Phuong Cao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13303">https://arxiv.org/abs/2601.13303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13303">https://arxiv.org/pdf/2601.13303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13303]] Verifying Local Robustness of Pruned Safety-Critical Networks(https://arxiv.org/abs/2601.13303)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $\alpha,\beta$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.</li>
</ul>

<h3>Title: CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Wenxin Ma, Chenlong Wang, Ruisheng Yuan, Hao Chen, Nanru Dai, S. Kevin Zhou, Yijun Yang, Alan Yuille, Jieneng Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13304">https://arxiv.org/abs/2601.13304</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13304">https://arxiv.org/pdf/2601.13304</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13304]] CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning(https://arxiv.org/abs/2601.13304)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: this https URL</li>
</ul>

<h3>Title: Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse</h3>
<ul>
<li><strong>Authors: </strong>Samantha Sudhoff, Pranav Perumal, Zhaoqing Wu, Tunazzina Islam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13317">https://arxiv.org/abs/2601.13317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13317">https://arxiv.org/pdf/2601.13317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13317]] Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse(https://arxiv.org/abs/2601.13317)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.</li>
</ul>

<h3>Title: MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic</h3>
<ul>
<li><strong>Authors: </strong>Wei Wang, Quoc-Toan Ly, Chong Yu, Jun Bai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13331">https://arxiv.org/abs/2601.13331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13331">https://arxiv.org/pdf/2601.13331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13331]] MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic(https://arxiv.org/abs/2601.13331)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at this https URL.</li>
</ul>

<h3>Title: AfroScope: A Framework for Studying the Linguistic Landscape of Africa</h3>
<ul>
<li><strong>Authors: </strong>Sang Yun Kwon, AbdelRahim Elmadany, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13346">https://arxiv.org/abs/2601.13346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13346">https://arxiv.org/pdf/2601.13346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13346]] AfroScope: A Framework for Studying the Linguistic Landscape of Africa(https://arxiv.org/abs/2601.13346)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.</li>
</ul>

<h3>Title: LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yuxing Lu, J. Ben Tamo, Weichen Zhao, Nan Sun, Yishan Zhong, Wenqi Shi, Jinzhuo Wang, May D. Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13352">https://arxiv.org/abs/2601.13352</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13352">https://arxiv.org/pdf/2601.13352</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13352]] LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction(https://arxiv.org/abs/2601.13352)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.</li>
</ul>

<h3>Title: Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection</h3>
<ul>
<li><strong>Authors: </strong>Asen Dotsinski, Panagiotis Eustratiadis</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13359">https://arxiv.org/abs/2601.13359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13359">https://arxiv.org/pdf/2601.13359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13359]] Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection(https://arxiv.org/abs/2601.13359)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce "sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., "Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.</li>
</ul>

<h3>Title: Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments</h3>
<ul>
<li><strong>Authors: </strong>Zhenan Liu, Yaodong Cui, Amir Khajepour, George Shaker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13364">https://arxiv.org/abs/2601.13364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13364">https://arxiv.org/pdf/2601.13364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13364]] Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments(https://arxiv.org/abs/2601.13364)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.</li>
</ul>

<h3>Title: CausationEntropy: Pythonic Optimal Causation Entropy</h3>
<ul>
<li><strong>Authors: </strong>Kevin Slote, Jeremie Fish, Erik Bollt</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.data-an</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13365">https://arxiv.org/abs/2601.13365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13365">https://arxiv.org/pdf/2601.13365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13365]] CausationEntropy: Pythonic Optimal Causation Entropy(https://arxiv.org/abs/2601.13365)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.</li>
</ul>

<h3>Title: Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhenjiang Mao, Anirudhh Venkat</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13368">https://arxiv.org/abs/2601.13368</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13368">https://arxiv.org/pdf/2601.13368</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13368]] Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models(https://arxiv.org/abs/2601.13368)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.</li>
</ul>

<h3>Title: Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations</h3>
<ul>
<li><strong>Authors: </strong>Junyi Zhang, Yiming Wang, Yunhong Lu, Qichao Wang, Wenzhe Qian, Xiaoyin Xu, David Gu, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13371">https://arxiv.org/abs/2601.13371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13371">https://arxiv.org/pdf/2601.13371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13371]] Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations(https://arxiv.org/abs/2601.13371)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.</li>
</ul>

<h3>Title: A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions</h3>
<ul>
<li><strong>Authors: </strong>Zhenan Liu, Amir Khajepour, George Shaker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13373">https://arxiv.org/abs/2601.13373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13373">https://arxiv.org/pdf/2601.13373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13373]] A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions(https://arxiv.org/abs/2601.13373)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.</li>
</ul>

<h3>Title: Leveraging Transformer Decoder for Automotive Radar Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Changxu Zhang, Zhaoze Wang, Tai Fei, Christopher Grimm, Yi Jin, Claas Tebruegge, Ernst Warsitz, Markus Gardill</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13386">https://arxiv.org/abs/2601.13386</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13386">https://arxiv.org/pdf/2601.13386</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13386]] Leveraging Transformer Decoder for Automotive Radar Object Detection(https://arxiv.org/abs/2601.13386)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.</li>
</ul>

<h3>Title: Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zhenjiang Mao, Anirudhh Venkat, Artem Bisliouk, Akshat Kothiyal, Sindhura Kumbakonam Subramanian, Saithej Singhu, Ivan Ruchkin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13387">https://arxiv.org/abs/2601.13387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13387">https://arxiv.org/pdf/2601.13387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13387]] Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning(https://arxiv.org/abs/2601.13387)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.</li>
</ul>

<h3>Title: Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction</h3>
<ul>
<li><strong>Authors: </strong>Sasha Ronaghi, Prerit Choudhary, David H Rehkopf, Bryant Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13388">https://arxiv.org/abs/2601.13388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13388">https://arxiv.org/pdf/2601.13388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13388]] Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction(https://arxiv.org/abs/2601.13388)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.</li>
</ul>

<h3>Title: Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks</h3>
<ul>
<li><strong>Authors: </strong>Shlok Shelat, Jay Raval, Souvik Roy, Manas Gaur</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.FL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13392">https://arxiv.org/abs/2601.13392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13392">https://arxiv.org/pdf/2601.13392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13392]] Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks(https://arxiv.org/abs/2601.13392)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.</li>
</ul>

<h3>Title: QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems</h3>
<ul>
<li><strong>Authors: </strong>Jonatan Rassekhnia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13399">https://arxiv.org/abs/2601.13399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13399">https://arxiv.org/pdf/2601.13399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13399]] QERS: Quantum Encryption Resilience Score for Post-Quantum Cryptography in Computer, IoT, and IIoT Systems(https://arxiv.org/abs/2601.13399)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Post-quantum cryptography (PQC) is becoming essential for securing Internet of Things (IoT) and Industrial IoT (IIoT) systems against quantum-enabled adversaries. However, existing evaluation approaches primarily focus on isolated performance metrics, offering limited support for holistic security and deployment decisions. This paper introduces QERS (Quantum Encryption Resilience Score), a universal measurement framework that integrates cryptographic performance, system constraints, and multi-criteria decision analysis to assess PQC readiness in computer, IoT, and IIoT environments. QERS combines normalized metrics, weighted aggregation, and machine learning-assisted analysis to produce interpretable resilience scores across heterogeneous devices and communication protocols. Experimental results demonstrate how the framework enables comparative evaluation of post-quantum schemes under realistic resource constraints, supporting informed security design and migration planning. This work is presented as a preprint, with extended statistical validation planned as part of ongoing graduate research.</li>
</ul>

<h3>Title: Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics</h3>
<ul>
<li><strong>Authors: </strong>Peter A. Massih, Eric Cosatto</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13401">https://arxiv.org/abs/2601.13401</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13401">https://arxiv.org/pdf/2601.13401</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13401]] Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics(https://arxiv.org/abs/2601.13401)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.</li>
</ul>

<h3>Title: Local-to-Global Logical Explanations for Deep Vision Models</h3>
<ul>
<li><strong>Authors: </strong>Bhavan Vasu, Giuseppe Raffa, Prasad Tadepalli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13404">https://arxiv.org/abs/2601.13404</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13404">https://arxiv.org/pdf/2601.13404</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13404]] Local-to-Global Logical Explanations for Deep Vision Models(https://arxiv.org/abs/2601.13404)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.</li>
</ul>

<h3>Title: Using deep learning for predicting cleansing quality of colon capsule endoscopy images</h3>
<ul>
<li><strong>Authors: </strong>Puneet Sharma, Kristian Dalsbø Hindberg, Benedicte Schelde-Olesen, Ulrik Deding, Esmaeil S. Nadimi, Jan-Matthias Braun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13412">https://arxiv.org/abs/2601.13412</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13412">https://arxiv.org/pdf/2601.13412</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13412]] Using deep learning for predicting cleansing quality of colon capsule endoscopy images(https://arxiv.org/abs/2601.13412)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, explainability</a></li>
<li><strong>Abstract: </strong>In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.</li>
</ul>

<h3>Title: Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study</h3>
<ul>
<li><strong>Authors: </strong>A. Nieto Juscafresa, Á. Mazcuñán Herreros, J. Sullivan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13416">https://arxiv.org/abs/2601.13416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13416">https://arxiv.org/pdf/2601.13416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13416]] Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study(https://arxiv.org/abs/2601.13416)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.</li>
</ul>

<h3>Title: SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Yujian Xiong, Xuanzhao Dong, Wenhui Zhu, Xin Li, Oana Dumitrascu, Yalin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13417">https://arxiv.org/abs/2601.13417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13417">https://arxiv.org/pdf/2601.13417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13417]] SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement(https://arxiv.org/abs/2601.13417)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.</li>
</ul>

<h3>Title: Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems</h3>
<ul>
<li><strong>Authors: </strong>Jonatan Rassekhnia</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13423">https://arxiv.org/abs/2601.13423</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13423">https://arxiv.org/pdf/2601.13423</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13423]] Quantum Encryption Resilience Score (QERS) for MQTT, HTTP, and HTTPS under Post-Quantum Cryptography in Computer, IoT, and IIoT Systems(https://arxiv.org/abs/2601.13423)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Post-quantum cryptography (PQC) introduces significant computational and communication overhead, which poses challenges for resource-constrained computer systems, Internet of Things (IoT), and Industrial IoT (IIoT) devices. This paper presents an experimental evaluation of the Quantum Encryption Resilience Score (QERS) applied to MQTT, HTTP, and HTTPS communication protocols operating under PQC. Using an ESP32-C6 client and an ARM-based Raspberry Pi CM4 server, latency, CPU utilization, RSSI, energy consumption, key size, and TLS handshake overhead are measured under realistic operating conditions. QERS integrates these heterogeneous metrics into normalized Basic, Tuned, and Fusion scores, enabling systematic comparison of protocol efficiency and security resilience. Experimental results show that MQTT provides the highest efficiency under PQC constraints, while HTTPS achieves the highest security-weighted resilience at the cost of increased latency and resource consumption. The proposed framework supports informed protocol selection and migration planning for PQC-enabled IoT and IIoT deployments.</li>
</ul>

<h3>Title: A Scientific Data Integrity system based on Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Gian Sebastian Mier Bello, Alexander Martinez Mendez, Carlos J. Barrios H., Robinson Rivas, Luis A. Núñez</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13425">https://arxiv.org/abs/2601.13425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13425">https://arxiv.org/pdf/2601.13425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13425]] A Scientific Data Integrity system based on Blockchain(https://arxiv.org/abs/2601.13425)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>In most High Performance Computing (HPC) projects nowadays, there is a lot of data obtained from different sources, depending on the project's objectives. Some of that data is very huge in terms of size, so copying such data sometimes is an unrealistic goal. On the other hand, science requires data used for different purposes to remain unaltered, so different groups of researchers can reproduce results, discuss theories, and validate each other. In this paper, we present a novel approach to help research groups to validate data integrity on such distributed repositories using Blockchain. Originally developed for cryptographic currencies, Blockchain has demonstrated a versatile range of uses. Our proposal ensures 1) secure access to data management, 2) easy validation of data integrity, and 3) an easy way to add new records to the dataset with the same robust integrity policy. A prototype was developed and tested using a subset of a public dataset from a real scientific collaboration, the Latin American Giant Observatory (LAGO) Project.</li>
</ul>

<h3>Title: Techniques of Modern Attacks</h3>
<ul>
<li><strong>Authors: </strong>Alexander Shim</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13427">https://arxiv.org/abs/2601.13427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13427">https://arxiv.org/pdf/2601.13427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13427]] Techniques of Modern Attacks(https://arxiv.org/abs/2601.13427)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal</a></li>
<li><strong>Abstract: </strong>The techniques used in modern attacks have become an important factor for investigation. As we advance further into the digital age, cyber attackers are employing increasingly sophisticated and highly threatening methods. These attacks target not only organizations and governments but also extend to private and corporate sectors. Modern attack techniques, such as lateral movement and ransomware, are designed to infiltrate networks and steal sensitive data. Among these techniques, Advanced Persistent Threats (APTs) represent a complex method of attack aimed at specific targets to steal high-value sensitive information or damage the infrastructure of the targeted organization. In this paper, I will investigate Advanced Persistent Threats (APTs) as a modern attack technique, focusing on both the attack life cycle and cutting-edge detection and defense strategies proposed in recent academic research. I will analyze four representative papers to understand the evolution of APT detection mechanisms, including machine learning-driven behavioral analysis and network-level collaborative defense models. Through this comparative analysis, I aim to highlight the strengths and limitations of each approach and propose more adaptive APT mitigation strategies. The study seeks to analyze the key characteristics of APTs and provide a comprehensive high-level understanding of APTs along with potential solutions to the threats they pose.</li>
</ul>

<h3>Title: Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Priyanka Mary Mammen, Emil Joswin, Shankar Venkitachalam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13433">https://arxiv.org/abs/2601.13433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13433">https://arxiv.org/pdf/2601.13433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13433]] Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models(https://arxiv.org/abs/2601.13433)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.</li>
</ul>

<h3>Title: A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization</h3>
<ul>
<li><strong>Authors: </strong>Shuozhe Li, Du Cheng, Leqi Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13435">https://arxiv.org/abs/2601.13435</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13435">https://arxiv.org/pdf/2601.13435</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13435]] A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization(https://arxiv.org/abs/2601.13435)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \pm 0.045$ and a Sharpe ratio of $2.157 \pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.</li>
</ul>

<h3>Title: Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mohit Kakda, Mirudula Shri Muthukumaran, Uttapreksha Patel, Lawrence Swaminathan Xavier Prince</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13440">https://arxiv.org/abs/2601.13440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13440">https://arxiv.org/pdf/2601.13440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13440]] Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation(https://arxiv.org/abs/2601.13440)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.</li>
</ul>

<h3>Title: BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions</h3>
<ul>
<li><strong>Authors: </strong>Ashish S. Nair, Sandipp Krishnan Ravi, Itzel Salgado, Changjie Sun, Sayan Ghosh, Liping Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13445">https://arxiv.org/abs/2601.13445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13445">https://arxiv.org/pdf/2601.13445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13445]] BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions(https://arxiv.org/abs/2601.13445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.</li>
</ul>

<h3>Title: Fairness-informed Pareto Optimization : An Efficient Bilevel Framework</h3>
<ul>
<li><strong>Authors: </strong>Sofiane Tanji, Samuel Vaiter, Yassine Laguel</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13448">https://arxiv.org/abs/2601.13448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13448">https://arxiv.org/pdf/2601.13448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13448]] Fairness-informed Pareto Optimization : An Efficient Bilevel Framework(https://arxiv.org/abs/2601.13448)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.</li>
</ul>

<h3>Title: PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving</h3>
<ul>
<li><strong>Authors: </strong>Aditya Thole, Anmol Agrawal, Arnav Ramamoorthy, Dhruv Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13453">https://arxiv.org/abs/2601.13453</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13453">https://arxiv.org/pdf/2601.13453</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13453]] PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving(https://arxiv.org/abs/2601.13453)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems</li>
</ul>

<h3>Title: Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay</h3>
<ul>
<li><strong>Authors: </strong>Sahasra Kokkula, Daniel David, Aaditya Baruah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13456">https://arxiv.org/abs/2601.13456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13456">https://arxiv.org/pdf/2601.13456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13456]] Federated Learning Under Temporal Drift -- Mitigating Catastrophic Forgetting via Experience Replay(https://arxiv.org/abs/2601.13456)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.</li>
</ul>

<h3>Title: Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics</h3>
<ul>
<li><strong>Authors: </strong>Brandon B. Le, D. Keller</a></li>
<li><strong>Subjects: </strong>cs.LG, hep-ph, nucl-th, quant-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13463">https://arxiv.org/abs/2601.13463</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13463">https://arxiv.org/pdf/2601.13463</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13463]] Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics(https://arxiv.org/abs/2601.13463)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.</li>
</ul>

<h3>Title: Preconditioning Benefits of Spectral Orthogonalization in Muon</h3>
<ul>
<li><strong>Authors: </strong>Jianhao Ma, Yu Huang, Yuejie Chi, Yuxin Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13474">https://arxiv.org/abs/2601.13474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13474">https://arxiv.org/pdf/2601.13474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13474]] Preconditioning Benefits of Spectral Orthogonalization in Muon(https://arxiv.org/abs/2601.13474)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.</li>
</ul>

<h3>Title: A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model</h3>
<ul>
<li><strong>Authors: </strong>Jinhao Li, Hao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13476">https://arxiv.org/abs/2601.13476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13476">https://arxiv.org/pdf/2601.13476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13476]] A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model(https://arxiv.org/abs/2601.13476)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.</li>
</ul>

<h3>Title: DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities</h3>
<ul>
<li><strong>Authors: </strong>Nhi Kieu, Kien Nguyen, Arnold Wiliem, Clinton Fookes, Sridha Sridharan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13502">https://arxiv.org/abs/2601.13502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13502">https://arxiv.org/pdf/2601.13502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13502]] DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities(https://arxiv.org/abs/2601.13502)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.</li>
</ul>

<h3>Title: Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests</h3>
<ul>
<li><strong>Authors: </strong>Hanlin Zhou, Huah Yong Chan, Jingfei Ni, Mengchun Wu, Qing Deng</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13515">https://arxiv.org/abs/2601.13515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13515">https://arxiv.org/pdf/2601.13515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13515]] Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests(https://arxiv.org/abs/2601.13515)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.</li>
</ul>

<h3>Title: GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Yang Yu, Yunze Deng, Yige Zhang, Yanjie Xiao, Youkun Ou, Wenhao Hu, Mingchao Li, Bin Feng, Wenyu Liu, Dandan Zheng, Jingdong Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13524">https://arxiv.org/abs/2601.13524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13524">https://arxiv.org/pdf/2601.13524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13524]] GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models(https://arxiv.org/abs/2601.13524)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: this https URL.</li>
</ul>

<h3>Title: Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs</h3>
<ul>
<li><strong>Authors: </strong>Jackson Kaunismaa, Avery Griffin, John Hughes, Christina Q. Knight, Mrinank Sharma, Erik Jones</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13528">https://arxiv.org/abs/2601.13528</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13528">https://arxiv.org/pdf/2601.13528</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13528]] Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs(https://arxiv.org/abs/2601.13528)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.</li>
</ul>

<h3>Title: When Wording Steers the Evaluation: Framing Bias in LLM judges</h3>
<ul>
<li><strong>Authors: </strong>Yerin Hwang, Dongryeol Lee, Taegwan Kang, Minwoo Lee, Kyomin Jung</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13537">https://arxiv.org/abs/2601.13537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13537">https://arxiv.org/pdf/2601.13537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13537]] When Wording Steers the Evaluation: Framing Bias in LLM judges(https://arxiv.org/abs/2601.13537)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.</li>
</ul>

<h3>Title: HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations</h3>
<ul>
<li><strong>Authors: </strong>Yujia Hu, Roy Ka-Wei Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13547">https://arxiv.org/abs/2601.13547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13547">https://arxiv.org/pdf/2601.13547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13547]] HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations(https://arxiv.org/abs/2601.13547)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, interpretability</a></li>
<li><strong>Abstract: </strong>Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation. \textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}</li>
</ul>

<h3>Title: Patterning: The Dual of Interpretability</h3>
<ul>
<li><strong>Authors: </strong>George Wang, Daniel Murfet</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13548">https://arxiv.org/abs/2601.13548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13548">https://arxiv.org/pdf/2601.13548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13548]] Patterning: The Dual of Interpretability(https://arxiv.org/abs/2601.13548)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.</li>
</ul>

<h3>Title: DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis</h3>
<ul>
<li><strong>Authors: </strong>Feng Ding, Wenhui Yi, Xinan He, Mengyao Xiao, Jianfeng Xu, Jianqiang Du</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13551">https://arxiv.org/abs/2601.13551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13551">https://arxiv.org/pdf/2601.13551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13551]] DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis(https://arxiv.org/abs/2601.13551)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at this https URL.</li>
</ul>

<h3>Title: Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework</h3>
<ul>
<li><strong>Authors: </strong>Yanheng Li, Zhichen Pu, Lijiang Yang, Zehao Zhou, Yi Qin Gao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.chem-ph, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13564">https://arxiv.org/abs/2601.13564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13564">https://arxiv.org/pdf/2601.13564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13564]] Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework(https://arxiv.org/abs/2601.13564)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.</li>
</ul>

<h3>Title: Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Yu Qin, Shimeng Fan, Fan Yang, Zixuan Xue, Zijie Mai, Wenrui Chen, Kailun Yang, Zhiyong Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13565">https://arxiv.org/abs/2601.13565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13565">https://arxiv.org/pdf/2601.13565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13565]] Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation(https://arxiv.org/abs/2601.13565)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at this https URL.</li>
</ul>

<h3>Title: DRGW: Learning Disentangled Representations for Robust Graph Watermarking</h3>
<ul>
<li><strong>Authors: </strong>Jiasen Li, Yanwei Liu, Zhuoyi Shang, Xiaoyan Gu, Weiping Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13569">https://arxiv.org/abs/2601.13569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13569">https://arxiv.org/pdf/2601.13569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13569]] DRGW: Learning Disentangled Representations for Robust Graph Watermarking(https://arxiv.org/abs/2601.13569)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, extraction, watermark</a></li>
<li><strong>Abstract: </strong>Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.</li>
</ul>

<h3>Title: GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds</h3>
<ul>
<li><strong>Authors: </strong>Tingting Dan, Jiaqi Ding, Guorong Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13570">https://arxiv.org/abs/2601.13570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13570">https://arxiv.org/pdf/2601.13570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13570]] GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds(https://arxiv.org/abs/2601.13570)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.</li>
</ul>

<h3>Title: FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Qian Feng, JiaHang Tu, Mintong Kang, Hanbin Zhao, Chao Zhang, Hui Qian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13578">https://arxiv.org/abs/2601.13578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13578">https://arxiv.org/pdf/2601.13578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13578]] FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning(https://arxiv.org/abs/2601.13578)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\textbf{F}eature-\textbf{G}radient \textbf{Or}thogonality for \textbf{I}ncremental \textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.</li>
</ul>

<h3>Title: Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models</h3>
<ul>
<li><strong>Authors: </strong>Ahmad Al-Zuraiqi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13580">https://arxiv.org/abs/2601.13580</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13580">https://arxiv.org/pdf/2601.13580</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13580]] Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models(https://arxiv.org/abs/2601.13580)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, transformer</a></li>
<li><strong>Abstract: </strong>We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets ("donor organs") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.</li>
</ul>

<h3>Title: TREX: Tokenizer Regression for Optimal Data Mixture</h3>
<ul>
<li><strong>Authors: </strong>Inho Won, Hangyeol Yoo, Minkyung Cho, Jungyeul Park, Hoyun Song, KyungTae Lim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13588">https://arxiv.org/abs/2601.13588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13588">https://arxiv.org/pdf/2601.13588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13588]] TREX: Tokenizer Regression for Optimal Data Mixture(https://arxiv.org/abs/2601.13588)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.</li>
</ul>

<h3>Title: Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions</h3>
<ul>
<li><strong>Authors: </strong>Fan Huang, Haewoon Kwak, Jisun An</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13590">https://arxiv.org/abs/2601.13590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13590">https://arxiv.org/pdf/2601.13590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13590]] Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions(https://arxiv.org/abs/2601.13590)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.</li>
</ul>

<h3>Title: Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Linrui Ma, Yufei Cui, Kai Han, Yunhe Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13599">https://arxiv.org/abs/2601.13599</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13599">https://arxiv.org/pdf/2601.13599</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13599]] Diffusion In Diffusion: Breaking the Autoregressive Bottleneck in Block Diffusion Models(https://arxiv.org/abs/2601.13599)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Block diffusion language models, operating as semi-autoregressive paradigms, combine the strengths of both autoregressive and diffusion paradigms. However, their strict unidirectional block dependencies introduce irreversibility and sacrifice the global planning capabilities for which diffusion models are renowned. In order to address these issues, we propose Diffusion in Diffusion, a draft-then-refine framework designed to overcome the irreversibility and myopia problems inherent in block diffusion models. Our approach first employs block diffusion to generate rapid drafts using small blocks, then refines these drafts through global bidirectional diffusion with a larger bidirectional receptive field. We utilise snapshot confidence remasking to identify the most critical tokens that require modification, and apply mix-scale training to expand the block diffusion model's global capabilities. Empirical results demonstrate that our approach sets a new benchmark for discrete diffusion models on the OpenWebText dataset. Using just 26% of the fine-tuning budget of baseline models, we reduce generative perplexity from 25.7 to 21.9, significantly narrowing the performance gap with autoregressive models.</li>
</ul>

<h3>Title: When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Ruihan Hu, Yu-Ming Shang, Wei Luo, Ye Tao, Xi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13607">https://arxiv.org/abs/2601.13607</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13607">https://arxiv.org/pdf/2601.13607</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13607]] When Reasoning Leaks Membership: Membership Inference Attack on Black-box Large Reasoning Models(https://arxiv.org/abs/2601.13607)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Large Reasoning Models (LRMs) have rapidly gained prominence for their strong performance in solving complex tasks. Many modern black-box LRMs expose the intermediate reasoning traces through APIs to improve transparency (e.g., Gemini-2.5 and Claude-sonnet). Despite their benefits, we find that these traces can leak membership signals, creating a new privacy threat even without access to token logits used in prior attacks. In this work, we initiate the first systematic exploration of Membership Inference Attacks (MIAs) on black-box LRMs. Our preliminary analysis shows that LRMs produce confident, recall-like reasoning traces on familiar training member samples but more hesitant, inference-like reasoning traces on non-members. The representations of these traces are continuously distributed in the semantic latent space, spanning from familiar to unfamiliar samples. Building on this observation, we propose BlackSpectrum, the first membership inference attack framework targeting the black-box LRMs. The key idea is to construct a recall-inference axis in the semantic latent space, based on representations derived from the exposed traces. By locating where a query sample falls along this axis, the attacker can obtain a membership score and predict how likely it is to be a member of the training data. Additionally, to address the limitations of outdated datasets unsuited to modern LRMs, we provide two new datasets to support future research, arXivReasoning and BookReasoning. Empirically, exposing reasoning traces significantly increases the vulnerability of LRMs to membership inference attacks, leading to large gains in attack performance. Our findings highlight the need for LRM companies to balance transparency in intermediate reasoning traces with privacy preservation.</li>
</ul>

<h3>Title: Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data</h3>
<ul>
<li><strong>Authors: </strong>Zhipeng Chang, Ting He, Wenrui Hao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13608">https://arxiv.org/abs/2601.13608</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13608">https://arxiv.org/pdf/2601.13608</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13608]] Fisher-Informed Parameterwise Aggregation for Federated Learning with Heterogeneous Data(https://arxiv.org/abs/2601.13608)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning aggregates model updates from distributed clients, but standard first order methods such as FedAvg apply the same scalar weight to all parameters from each client. Under non-IID data, these uniformly weighted updates can be strongly misaligned across clients, causing client drift and degrading the global model. Here we propose Fisher-Informed Parameterwise Aggregation (FIPA), a second-order aggregation method that replaces client-level scalar weights with parameter-specific Fisher Information Matrix (FIM) weights, enabling true parameter-level scaling that captures how each client's data uniquely influences different parameters. With low-rank approximation, FIPA remains communication- and computation-efficient. Across nonlinear function regression, PDE learning, and image classification, FIPA consistently improves over averaging-based aggregation, and can be effectively combined with state-of-the-art client-side optimization algorithms to further improve image classification accuracy. These results highlight the benefits of FIPA for federated learning under heterogeneous data distributions.</li>
</ul>

<h3>Title: Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures</h3>
<ul>
<li><strong>Authors: </strong>Hansika Weerasena, Matthew Randall, Prabhat Mishra</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13610">https://arxiv.org/abs/2601.13610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13610">https://arxiv.org/pdf/2601.13610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13610]] Secure Multi-Path Routing with All-or-Nothing Transform for Network-on-Chip Architectures(https://arxiv.org/abs/2601.13610)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, steal</a></li>
<li><strong>Abstract: </strong>Ensuring Network-on-Chip (NoC) security is crucial to design trustworthy NoC-based System-on-Chip (SoC) architectures. While there are various threats that exploit on-chip communication vulnerabilities, eavesdropping attacks via malicious nodes are among the most common and stealthy. Although encryption can secure packets for confidentiality, it may introduce unacceptable overhead for resource-constrained SoCs. In this paper, we propose a lightweight confidentiality-preserving framework that utilizes a quasi-group based All-Or-Nothing Transform (AONT) combined with secure multi-path routing in NoC-based SoCs. By applying AONT to each packet and distributing its transformed blocks across multiple non-overlapping routes, we ensure that no intermediate router can reconstruct the original data without all blocks. Extensive experimental evaluation demonstrates that our method effectively mitigates eavesdropping attacks by malicious routers with negligible area and performance overhead. Our results also reveal that AONT-based multi-path routing can provide 7.3x reduction in overhead compared to traditional encryption for securing against eavesdropping attacks.</li>
</ul>

<h3>Title: PINA: Prompt Injection Attack against Navigation Agents</h3>
<ul>
<li><strong>Authors: </strong>Jiani Liu, Yixin He, Lanlan Fan, Qidi Zhong, Yushi Cheng, Meng Zhang, Yanjiao Chen, Wenyuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13612">https://arxiv.org/abs/2601.13612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13612">https://arxiv.org/pdf/2601.13612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13612]] PINA: Prompt Injection Attack against Navigation Agents(https://arxiv.org/abs/2601.13612)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Navigation agents powered by large language models (LLMs) convert natural language instructions into executable plans and actions. Compared to text-based applications, their security is far more critical: a successful prompt injection attack does not just alter outputs but can directly misguide physical navigation, leading to unsafe routes, mission failure, or real-world harm. Despite this high-stakes setting, the vulnerability of navigation agents to prompt injection remains largely unexplored. In this paper, we propose PINA, an adaptive prompt optimization framework tailored to navigation agents under black-box, long-context, and action-executable constraints. Experiments on indoor and outdoor navigation agents show that PINA achieves high attack success rates with an average ASR of 87.5%, surpasses all baselines, and remains robust under ablation and adaptive-attack conditions. This work provides the first systematic investigation of prompt injection attacks in navigation and highlights their urgent security implications for embodied LLM agents.</li>
</ul>

<h3>Title: Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhaopeng Zhang, Pengcheng Sun, Lan Zhang, Chen Tang, Jiewei Lai, Yunhao Wang, Hui Jin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13630">https://arxiv.org/abs/2601.13630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13630">https://arxiv.org/pdf/2601.13630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13630]] Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models(https://arxiv.org/abs/2601.13630)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.</li>
</ul>

<h3>Title: Quadratic Upper Bound for Boosting Robustness</h3>
<ul>
<li><strong>Authors: </strong>Euijin You, Hyang-Won Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13645">https://arxiv.org/abs/2601.13645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13645">https://arxiv.org/pdf/2601.13645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13645]] Quadratic Upper Bound for Boosting Robustness(https://arxiv.org/abs/2601.13645)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Fast adversarial training (FAT) aims to enhance the robustness of models against adversarial attacks with reduced training time, however, FAT often suffers from compromised robustness due to insufficient exploration of adversarial space. In this paper, we develop a loss function to mitigate the problem of degraded robustness under FAT. Specifically, we derive a quadratic upper bound (QUB) on the adversarial training (AT) loss function and propose to utilize the bound with existing FAT methods. Our experimental results show that applying QUB loss to the existing methods yields significant improvement of robustness. Furthermore, using various metrics, we demonstrate that this improvement is likely to result from the smoothened loss landscape of the resulting model.</li>
</ul>

<h3>Title: Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge</h3>
<ul>
<li><strong>Authors: </strong>Xiaolin Zhou, Zheng Luo, Yicheng Gao, Qixuan Chen, Xiyang Hu, Yue Zhao, Ruishan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13649">https://arxiv.org/abs/2601.13649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13649">https://arxiv.org/pdf/2601.13649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13649]] Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge(https://arxiv.org/abs/2601.13649)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.</li>
</ul>

<h3>Title: TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Xingjian Wu, Junkai Lu, Zhengyu Li, Xiangfei Qiu, Jilin Hu, Chenjuan Guo, Christian S. Jensen, Bin Yang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13653">https://arxiv.org/abs/2601.13653</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13653">https://arxiv.org/pdf/2601.13653</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13653]] TimeART: Towards Agentic Time Series Reasoning via Tool-Augmentation(https://arxiv.org/abs/2601.13653)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Time series data widely exist in real-world cyber-physical systems. Though analyzing and interpreting them contributes to significant values, e.g, disaster prediction and financial risk control, current workflows mainly rely on human data scientists, which requires significant labor costs and lacks automation. To tackle this, we introduce TimeART, a framework fusing the analytical capability of strong out-of-the-box tools and the reasoning capability of Large Language Models (LLMs), which serves as a fully agentic data scientist for Time Series Question Answering (TSQA). To teach the LLM-based Time Series Reasoning Models (TSRMs) strategic tool-use, we also collect a 100k expert trajectory corpus called TimeToolBench. To enhance TSRMs' generalization capability, we then devise a four-stage training strategy, which boosts TSRMs through learning from their own early experiences and self-reflections. Experimentally, we train an 8B TSRM on TimeToolBench and equip it with the TimeART framework, and it achieves consistent state-of-the-art performance on multiple TSQA tasks, which pioneers a novel approach towards agentic time series reasoning.</li>
</ul>

<h3>Title: Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Arthur Amalvy, Hen-Hsen Huang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13658">https://arxiv.org/abs/2601.13658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13658">https://arxiv.org/pdf/2601.13658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13658]] Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation(https://arxiv.org/abs/2601.13658)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.</li>
</ul>

<h3>Title: Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Chunlei Meng, Ziyang Zhou, Lucas He, Xiaojing Du, Chun Ouyang, Zhongxue Gan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13659">https://arxiv.org/abs/2601.13659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13659">https://arxiv.org/pdf/2601.13659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13659]] Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis(https://arxiv.org/abs/2601.13659)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.</li>
</ul>

<h3>Title: VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement</h3>
<ul>
<li><strong>Authors: </strong>Tiancheng Fang, Bowen Pan, Lingxi Chen, Jiangjing Lyu, Chengfei Lyu, Chaoyue Niu, Fan Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13664">https://arxiv.org/abs/2601.13664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13664">https://arxiv.org/pdf/2601.13664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13664]] VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement(https://arxiv.org/abs/2601.13664)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.</li>
</ul>

<h3>Title: Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Mounika Kanulla, Rajasree Dadigi, Sailaja Thota, Vivek Yelleti</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13665">https://arxiv.org/abs/2601.13665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13665">https://arxiv.org/pdf/2601.13665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13665]] Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting(https://arxiv.org/abs/2601.13665)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.</li>
</ul>

<h3>Title: CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jiayu Lin, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13669">https://arxiv.org/abs/2601.13669</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13669">https://arxiv.org/pdf/2601.13669</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13669]] CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks(https://arxiv.org/abs/2601.13669)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a "middle ground". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.</li>
</ul>

<h3>Title: Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery</h3>
<ul>
<li><strong>Authors: </strong>Fabian Greifeneder, Wolfgang Fenz, Benedikt Alkin, Johannes Brandstetter, Michael Giretzlehner, Philipp Moser</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13676">https://arxiv.org/abs/2601.13676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13676">https://arxiv.org/pdf/2601.13676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13676]] Autoregressive deep learning for real-time simulation of soft tissue dynamics during virtual neurosurgery(https://arxiv.org/abs/2601.13676)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Accurate simulation of brain deformation is a key component for developing realistic, interactive neurosurgical simulators, as complex nonlinear deformations must be captured to ensure realistic tool-tissue interactions. However, traditional numerical solvers often fall short in meeting real-time performance requirements. To overcome this, we introduce a deep learning-based surrogate model that efficiently simulates transient brain deformation caused by continuous interactions between surgical instruments and the virtual brain geometry. Building on Universal Physics Transformers, our approach operates directly on large-scale mesh data and is trained on an extensive dataset generated from nonlinear finite element simulations, covering a broad spectrum of temporal instrument-tissue interaction scenarios. To reduce the accumulation of errors in autoregressive inference, we propose a stochastic teacher forcing strategy applied during model training. Specifically, training consists of short stochastic rollouts in which the proportion of ground truth inputs is gradually decreased in favor of model-generated predictions. Our results show that the proposed surrogate model achieves accurate and efficient predictions across a range of transient brain deformation scenarios, scaling to meshes with up to 150,000 nodes. The introduced stochastic teacher forcing technique substantially improves long-term rollout stability, reducing the maximum prediction error from 6.7 mm to 3.5 mm. We further integrate the trained surrogate model into an interactive neurosurgical simulation environment, achieving runtimes below 10 ms per simulation step on consumer-grade inference hardware. Our proposed deep learning framework enables rapid, smooth and accurate biomechanical simulations of dynamic brain tissue deformation, laying the foundation for realistic surgical training environments.</li>
</ul>

<h3>Title: Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Carsten T. Lüth, Jeremias Traub, Kim-Celine Kahl, Till J. Bungert, Lukas Klein, Lars Krämer, Paul F. Jäger, Klaus Maier-Hein, Fabian Isensee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13677">https://arxiv.org/abs/2601.13677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13677">https://arxiv.org/pdf/2601.13677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13677]] Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging(https://arxiv.org/abs/2601.13677)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at this https URL.</li>
</ul>

<h3>Title: ORCA -- An Automated Threat Analysis Pipeline for O-RAN Continuous Development</h3>
<ul>
<li><strong>Authors: </strong>Felix Klement, Alessandro Brighente, Michele Polese, Mauro Conti, Stefan Katzenbeisser</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13681">https://arxiv.org/abs/2601.13681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13681">https://arxiv.org/pdf/2601.13681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13681]] ORCA -- An Automated Threat Analysis Pipeline for O-RAN Continuous Development(https://arxiv.org/abs/2601.13681)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>The Open-Radio Access Network (O-RAN) integrates numerous software components in a cloud-like deployment, opening the radio access network to previously unconsidered security threats. With the ever-evolving threat landscape, integrating security practices through a DevSecOps approach is essential for fast and secure releases. Current vulnerability assessment practices often rely on manual, labor-intensive, and subjective investigations, leading to inconsistencies in the threat analysis. To mitigate these issues, we establish an automated pipeline that leverages Natural Language Processing (NLP) to minimize human intervention and associated biases. By mapping real-world vulnerabilities to predefined threat lists with a standardized input format, our approach is the first to enable iterative, quantitative, and efficient assessments, generating reliable threat scores for both individual vulnerabilities and entire system components within O-RAN. We illustrate the effectiveness of our framework through an example implementation for O-RAN, showcasing how continuous security testing can integrate into automated testing pipelines to address the unique security challenges of this paradigm shift in telecommunications.</li>
</ul>

<h3>Title: Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Boyuan Cao, Xingbo Yao, Chenhui Wang, Jiaxin Ye, Yujie Wei, Hongming Shan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13683">https://arxiv.org/abs/2601.13683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13683">https://arxiv.org/pdf/2601.13683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13683]] Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation(https://arxiv.org/abs/2601.13683)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.</li>
</ul>

<h3>Title: Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yue Guo, Fanfu Wang, Jianwei Lv, Xincheng Shi, Yuchen Li, Youya Wang, Yunsheng Zeng, Yujing Liu, Yunhao Qiao, Gen Li, Junfeng Wang, Bo Yuan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13690">https://arxiv.org/abs/2601.13690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13690">https://arxiv.org/pdf/2601.13690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13690]] Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning(https://arxiv.org/abs/2601.13690)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.</li>
</ul>

<h3>Title: OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens</h3>
<ul>
<li><strong>Authors: </strong>Sifan Li, Hongkai Chen, Yujun Cai, Liyang Chen, Qingwen Ye, Yiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13695">https://arxiv.org/abs/2601.13695</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13695">https://arxiv.org/pdf/2601.13695</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13695]] OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens(https://arxiv.org/abs/2601.13695)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.</li>
</ul>

<h3>Title: Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Zhihang Yuan, Chengyu Yue, Long Huang, Litu Ou, Lei Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13697">https://arxiv.org/abs/2601.13697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13697">https://arxiv.org/pdf/2601.13697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13697]] Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning(https://arxiv.org/abs/2601.13697)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.</li>
</ul>

<h3>Title: Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation</h3>
<ul>
<li><strong>Authors: </strong>Arjun Nichani, Hsiang Hsu, Chun-Fu (Richard)Chen, Haewon Jeong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.IT, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13698">https://arxiv.org/abs/2601.13698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13698">https://arxiv.org/pdf/2601.13698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13698]] Does Privacy Always Harm Fairness? Data-Dependent Trade-offs via Chernoff Information Neural Estimation(https://arxiv.org/abs/2601.13698)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Fairness and privacy are two vital pillars of trustworthy machine learning. Despite extensive research on these individual topics, the relationship between fairness and privacy has received significantly less attention. In this paper, we utilize the information-theoretic measure Chernoff Information to highlight the data-dependent nature of the relationship among the triad of fairness, privacy, and accuracy. We first define Noisy Chernoff Difference, a tool that allows us to analyze the relationship among the triad simultaneously. We then show that for synthetic data, this value behaves in 3 distinct ways (depending on the distribution of the data). We highlight the data distributions involved in these cases and explore their fairness and privacy implications. Additionally, we show that Noisy Chernoff Difference acts as a proxy for the steepness of the fairness-accuracy curves. Finally, we propose a method for estimating Chernoff Information on data from unknown distributions and utilize this framework to examine the triad dynamic on real datasets. This work builds towards a unified understanding of the fairness-privacy-accuracy relationship and highlights its data-dependent nature.</li>
</ul>

<h3>Title: ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins</h3>
<ul>
<li><strong>Authors: </strong>Xinhao Liu, Yu Wang, Xiansheng Guo, Gordon Owusu Boateng, Yu Cao, Haonan Si, Xingchen Guo, Nirwan Ansari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13706">https://arxiv.org/abs/2601.13706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13706">https://arxiv.org/pdf/2601.13706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13706]] ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins(https://arxiv.org/abs/2601.13706)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: this https URL</li>
</ul>

<h3>Title: Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction</h3>
<ul>
<li><strong>Authors: </strong>Sayeed Shafayet Chowdhury, Snehasis Mukhopadhyay, Shiaofen Fang, Vijay R. Ramakrishnan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13710">https://arxiv.org/abs/2601.13710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13710">https://arxiv.org/pdf/2601.13710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13710]] Who Should Have Surgery? A Comparative Study of GenAI vs Supervised ML for CRS Surgical Outcome Prediction(https://arxiv.org/abs/2601.13710)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Artificial intelligence has reshaped medical imaging, yet the use of AI on clinical data for prospective decision support remains limited. We study pre-operative prediction of clinically meaningful improvement in chronic rhinosinusitis (CRS), defining success as a more than 8.9-point reduction in SNOT-22 at 6 months (MCID). In a prospectively collected cohort where all patients underwent surgery, we ask whether models using only pre-operative clinical data could have identified those who would have poor outcomes, i.e. those who should have avoided surgery. We benchmark supervised ML (logistic regression, tree ensembles, and an in-house MLP) against generative AI (ChatGPT, Claude, Gemini, Perplexity), giving each the same structured inputs and constraining outputs to binary recommendations with confidence. Our best ML model (MLP) achieves 85 % accuracy with superior calibration and decision-curve net benefit. GenAI models underperform on discrimination and calibration across zero-shot setting. Notably, GenAI justifications align with clinician heuristics and the MLP's feature importance, repeatedly highlighting baseline SNOT-22, CT/endoscopy severity, polyp phenotype, and physchology/pain comorbidities. We provide a reproducible tabular-to-GenAI evaluation protocol and subgroup analyses. Findings support an ML-first, GenAI- augmented workflow: deploy calibrated ML for primary triage of surgical candidacy, with GenAI as an explainer to enhance transparency and shared decision-making.</li>
</ul>

<h3>Title: GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Lotta Kiefer, Christoph Leiter, Sotaro Takeshita, Elena Schmidt, Steffen Eger</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13711">https://arxiv.org/abs/2601.13711</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13711">https://arxiv.org/pdf/2601.13711</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13711]] GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark(https://arxiv.org/abs/2601.13711)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.</li>
</ul>

<h3>Title: OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents</h3>
<ul>
<li><strong>Authors: </strong>Yulin Hu, Zimo Long, Jiahe Guo, Xingyu Sui, Xing Fu, Weixiang Zhao, Yanyan Zhao, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13722">https://arxiv.org/abs/2601.13722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13722">https://arxiv.org/pdf/2601.13722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13722]] OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents(https://arxiv.org/abs/2601.13722)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.</li>
</ul>

<h3>Title: Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement</h3>
<ul>
<li><strong>Authors: </strong>Sam Cantrill, David Ahmedt-Aristizabal, Lars Petersson, Hanna Suominen, Mohammad Ali Armin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13724">https://arxiv.org/abs/2601.13724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13724">https://arxiv.org/pdf/2601.13724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13724]] Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement(https://arxiv.org/abs/2601.13724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at this https URL .</li>
</ul>

<h3>Title: On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Weichuan Wang, Mingyang Liu, Linqi Song, Chen Ma</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13729">https://arxiv.org/abs/2601.13729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13729">https://arxiv.org/pdf/2601.13729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13729]] On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation(https://arxiv.org/abs/2601.13729)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.</li>
</ul>

<h3>Title: Towards robust long-context understanding of large language model via active recap learning</h3>
<ul>
<li><strong>Authors: </strong>Chenyu Hui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13734">https://arxiv.org/abs/2601.13734</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13734">https://arxiv.org/pdf/2601.13734</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13734]] Towards robust long-context understanding of large language model via active recap learning(https://arxiv.org/abs/2601.13734)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM</li>
</ul>

<h3>Title: Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues</h3>
<ul>
<li><strong>Authors: </strong>Arjun Chandra, Kevin Miller, Venkatesh Ravichandran, Constantinos Papayiannis, Venkatesh Saligrama</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13742">https://arxiv.org/abs/2601.13742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13742">https://arxiv.org/pdf/2601.13742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13742]] Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues(https://arxiv.org/abs/2601.13742)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.</li>
</ul>

<h3>Title: EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory</h3>
<ul>
<li><strong>Authors: </strong>Tien-Dat Pham, Xuan-The Tran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13748">https://arxiv.org/abs/2601.13748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13748">https://arxiv.org/pdf/2601.13748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13748]] EEG-Titans: Long-Horizon Seizure Forecasting via Dual-Branch Attention and Neural Memory(https://arxiv.org/abs/2601.13748)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate epileptic seizure prediction from electroencephalography (EEG) remains challenging because pre-ictal dynamics may span long time horizons while clinically relevant signatures can be subtle and transient. Many deep learning models face a persistent trade-off between capturing local spatiotemporal patterns and maintaining informative long-range context when operating on ultralong sequences. We propose EEG-Titans, a dualbranch architecture that incorporates a modern neural memory mechanism for long-context modeling. The model combines sliding-window attention to capture short-term anomalies with a recurrent memory pathway that summarizes slower, progressive trends over time. On the CHB-MIT scalp EEG dataset, evaluated under a chronological holdout protocol, EEG-Titans achieves 99.46% average segment-level sensitivity across 18 subjects. We further analyze safety-first operating points on artifact-prone recordings and show that a hierarchical context strategy extending the receptive field for high-noise subjects can markedly reduce false alarms (down to 0.00 FPR/h in an extreme outlier) without sacrificing sensitivity. These results indicate that memory-augmented long-context modeling can provide robust seizure forecasting under clinically constrained evaluation</li>
</ul>

<h3>Title: Pro-AI Bias in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Benaya Trabelsi, Jonathan Shaki, Sarit Kraus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13749">https://arxiv.org/abs/2601.13749</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13749">https://arxiv.org/pdf/2601.13749</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13749]] Pro-AI Bias in Large Language Models(https://arxiv.org/abs/2601.13749)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.</li>
</ul>

<h3>Title: HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection</h3>
<ul>
<li><strong>Authors: </strong>Daniel Kyselica, Jonáš Herec, Oliver Kutis, Rado Pitoňák</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13751">https://arxiv.org/abs/2601.13751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13751">https://arxiv.org/pdf/2601.13751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13751]] HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection(https://arxiv.org/abs/2601.13751)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at this https URL</li>
</ul>

<h3>Title: The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models</h3>
<ul>
<li><strong>Authors: </strong>Ekleen Kaur</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13757">https://arxiv.org/abs/2601.13757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13757">https://arxiv.org/pdf/2601.13757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13757]] The Limits of Conditional Volatility: Assessing Cryptocurrency VaR under EWMA and IGARCH Models(https://arxiv.org/abs/2601.13757)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The application of the standard static Geometric Brownian Motion (GBM) model for cryptocurrency risk management resulted in a systemic failure, evidenced by a 80.67% chance of loss in the 5% value-at-risk benchmark. This study addresses a critical literature gap by comparatively testing three conditional volatility models the EWMA/IGARCH baseline, an IGARCH model augmented with explicit mean reversion (IGARCH + MR), and a modified EGARCH-style asymmetric shock model within a correlated Monte Carlo VaR framework. Crucially, the analysis is applied specifically to high-beta altcoins (XRP, SOL, ADA), an asset class largely neglected by mainstream GARCH literature. Our results demonstrate that imposing stationarity (IGARCH + MR) drastically underestimates downside risk (5 percent value-at-risk reduced by 50%), while the asymmetric model (Model 3) leads to severe over-penalization. The EWMA/IGARCH baseline, characterized by infinite volatility persistence (alpha + beta = 1), provided the only robust conditional volatility estimate. This finding constitutes a formal rejection of the conventional financial hypotheses of volatility mean reversion and the asymmetric leverage effect in the altcoin asset class, establishing that non-stationary frameworks are a prerequisite for regulatory-grade risk modeling in this domain.</li>
</ul>

<h3>Title: vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Wenzhen Yue, Ruohao Guo, Ji Shi, Zihan Hao, Shiyu Hu, Xianghua Ying</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13768">https://arxiv.org/abs/2601.13768</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13768">https://arxiv.org/pdf/2601.13768</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13768]] vLinear: A Powerful Linear Model for Multivariate Time Series Forecasting(https://arxiv.org/abs/2601.13768)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present \textbf{vLinear}, an effective yet efficient \textbf{linear}-based multivariate time series forecaster featuring two components: the \textbf{v}ecTrans module and the WFMLoss objective. Many state-of-the-art forecasters rely on self-attention or its variants to capture multivariate correlations, typically incurring $\mathcal{O}(N^2)$ computational complexity with respect to the number of variates $N$. To address this, we propose vecTrans, a lightweight module that utilizes a learnable vector to model multivariate correlations, reducing the complexity to $\mathcal{O}(N)$. Notably, vecTrans can be seamlessly integrated into Transformer-based forecasters, delivering up to 5$\times$ inference speedups and consistent performance gains. Furthermore, we introduce WFMLoss (Weighted Flow Matching Loss) as the objective. In contrast to typical \textbf{velocity-oriented} flow matching objectives, we demonstrate that a \textbf{final-series-oriented} formulation yields significantly superior forecasting accuracy. WFMLoss also incorporates path- and horizon-weighted strategies to focus learning on more reliable paths and horizons. Empirically, vLinear achieves state-of-the-art performance across 22 benchmarks and 124 forecasting settings. Moreover, WFMLoss serves as an effective plug-and-play objective, consistently improving existing forecasters. The code is available at this https URL.</li>
</ul>

<h3>Title: Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks</h3>
<ul>
<li><strong>Authors: </strong>Thibaut Boissin (IRIT-MISFIT), Franck Mamalet, Valentin Lafargue (ANITI, IMT), Mathieu Serrurier (IRIT-MISFIT)</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13776">https://arxiv.org/abs/2601.13776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13776">https://arxiv.org/pdf/2601.13776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13776]] Orthogonium : A Unified, Efficient Library of Orthogonal and 1-Lipschitz Building Blocks(https://arxiv.org/abs/2601.13776)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Orthogonal and 1-Lipschitz neural network layers are essential building blocks in robust deep learning architectures, crucial for certified adversarial robustness, stable generative models, and reliable recurrent networks. Despite significant advancements, existing implementations remain fragmented, limited, and computationally demanding. To address these issues, we introduce Orthogonium , a unified, efficient, and comprehensive PyTorch library providing orthogonal and 1-Lipschitz layers. Orthogonium provides access to standard convolution features-including support for strides, dilation, grouping, and transposed-while maintaining strict mathematical guarantees. Its optimized implementations reduce overhead on large scale benchmarks such as ImageNet. Moreover, rigorous testing within the library has uncovered critical errors in existing implementations, emphasizing the importance of standardized and reliable tools. Orthogonium thus significantly lowers adoption barriers, enabling scalable experimentation and integration across diverse applications requiring orthogonality and robust Lipschitz constraints. Orthogonium is available at this https URL.</li>
</ul>

<h3>Title: Principled Latent Diffusion for Graphs via Laplacian Autoencoders</h3>
<ul>
<li><strong>Authors: </strong>Antoine Siraudin, Christopher Morris</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13780">https://arxiv.org/abs/2601.13780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13780">https://arxiv.org/pdf/2601.13780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13780]] Principled Latent Diffusion for Graphs via Laplacian Autoencoders(https://arxiv.org/abs/2601.13780)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Graph diffusion models achieve state-of-the-art performance in graph generation but suffer from quadratic complexity in the number of nodes -- and much of their capacity is wasted modeling the absence of edges in sparse graphs. Inspired by latent diffusion in other modalities, a natural idea is to compress graphs into a low-dimensional latent space and perform diffusion there. However, unlike images or text, graph generation requires nearly lossless reconstruction, as even a single error in decoding an adjacency matrix can render the entire sample invalid. This challenge has remained largely unaddressed. We propose LG-Flow, a latent graph diffusion framework that directly overcomes these obstacles. A permutation-equivariant autoencoder maps each node into a fixed-dimensional embedding from which the full adjacency is provably recoverable, enabling near-lossless reconstruction for both undirected graphs and DAGs. The dimensionality of this latent representation scales linearly with the number of nodes, eliminating the quadratic bottleneck and making it feasible to train larger and more expressive models. In this latent space, we train a Diffusion Transformer with flow matching, enabling efficient and expressive graph generation. Our approach achieves competitive results against state-of-the-art graph diffusion models, while achieving up to $1000\times$ speed-up.</li>
</ul>

<h3>Title: PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Gabriele Serussi, David Vainshtein, Jonathan Kouchly, Dotan Di Castro, Chaim Baskin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13797">https://arxiv.org/abs/2601.13797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13797">https://arxiv.org/pdf/2601.13797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13797]] PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval(https://arxiv.org/abs/2601.13797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.</li>
</ul>

<h3>Title: Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders</h3>
<ul>
<li><strong>Authors: </strong>Kai Wittenmayer, Sukrut Rao, Amin Parchami-Araghi, Bernt Schiele, Jonas Fischer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13798">https://arxiv.org/abs/2601.13798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13798">https://arxiv.org/pdf/2601.13798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13798]] Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders(https://arxiv.org/abs/2601.13798)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at this https URL.</li>
</ul>

<h3>Title: Discriminant Learning-based Colorspace for Blade Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13816">https://arxiv.org/abs/2601.13816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13816">https://arxiv.org/pdf/2601.13816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13816]] Discriminant Learning-based Colorspace for Blade Segmentation(https://arxiv.org/abs/2601.13816)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.</li>
</ul>

<h3>Title: ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks</h3>
<ul>
<li><strong>Authors: </strong>Xiaohong Yang, Tong Xie, Minghui Liwang, Chikai Shang, Yang Lu, Zhenzhen Jiao, Liqun Fu, Seyyedali Hosseinalipour</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13824">https://arxiv.org/abs/2601.13824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13824">https://arxiv.org/pdf/2601.13824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13824]] ELSA: Efficient LLM-Centric Split Aggregation for Privacy-Aware Hierarchical Federated Learning over Resource-Constrained Edge Networks(https://arxiv.org/abs/2601.13824)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>Training large language models (LLMs) at the network edge faces fundamental challenges arising from device resource constraints, severe data heterogeneity, and heightened privacy risks. To address these, we propose ELSA (Efficient LLM-centric Split Aggregation), a novel framework that systematically integrates split learning (SL) and hierarchical federated learning (HFL) for distributed LLM fine-tuning over resource-constrained edge networks. ELSA introduces three key innovations. First, it employs a task-agnostic, behavior-aware client clustering mechanism that constructs semantic fingerprints using public probe inputs and symmetric KL divergence, further enhanced by prediction-consistency-based trust scoring and latency-aware edge assignment to jointly address data heterogeneity, client unreliability, and communication constraints. Second, it splits the LLM into three parts across clients and edge servers, with the cloud used only for adapter aggregation, enabling an effective balance between on-device computation cost and global convergence stability. Third, it incorporates a lightweight communication scheme based on computational sketches combined with semantic subspace orthogonal perturbation (SS-OP) to reduce communication overhead while mitigating privacy leakage during model exchanges. Experiments across diverse NLP tasks demonstrate that ELSA consistently outperforms state-of-the-art methods in terms of adaptability, convergence behavior, and robustness, establishing a scalable and privacy-aware solution for edge-side LLM fine-tuning under resource constraints.</li>
</ul>

<h3>Title: MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System</h3>
<ul>
<li><strong>Authors: </strong>Huadi Zheng, Li Cheng, Yan Ding</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13826">https://arxiv.org/abs/2601.13826</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13826">https://arxiv.org/pdf/2601.13826</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13826]] MirageNet:A Secure, Efficient, and Scalable On-Device Model Protection in Heterogeneous TEE and GPU System(https://arxiv.org/abs/2601.13826)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, defense, robust</a></li>
<li><strong>Abstract: </strong>As edge devices gain stronger computing power, deploying high-performance DNN models on untrusted hardware has become a practical approach to cut inference latency and protect user data privacy. Given high model training costs and user experience requirements, balancing model privacy and low runtime overhead is critical. TEEs offer a viable defense, and prior work has proposed heterogeneous GPU-TEE inference frameworks via parameter obfuscation to balance efficiency and confidentiality. However, recent studies find partial obfuscation defenses ineffective, while robust schemes cause unacceptable latency. To resolve these issues, we propose ConvShatter, a novel obfuscation scheme that achieves low latency and high accuracy while preserving model confidentiality and integrity. It leverages convolution linearity to decompose kernels into critical and common ones, inject confounding decoys, and permute channel/kernel orders. Pre-deployment, it performs kernel decomposition, decoy injection and order obfuscation, storing minimal recovery parameters securely in the TEE. During inference, the TEE reconstructs outputs of obfuscated convolutional layers. Extensive experiments show ConvShatter substantially reduces latency overhead with strong security guarantees; versus comparable schemes, it cuts overhead by 16% relative to GroupCover while maintaining accuracy on par with the original model.</li>
</ul>

<h3>Title: The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations</h3>
<ul>
<li><strong>Authors: </strong>Sam OConnor Russell, Delphine Charuau, Naomi Harte</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13835">https://arxiv.org/abs/2601.13835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13835">https://arxiv.org/pdf/2601.13835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13835]] The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations(https://arxiv.org/abs/2601.13835)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.</li>
</ul>

<h3>Title: FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Qian Chen, Jinlan Fu, Changsong Li, See-Kiong Ng, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13836">https://arxiv.org/abs/2601.13836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13836">https://arxiv.org/pdf/2601.13836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13836]] FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs(https://arxiv.org/abs/2601.13836)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (this https URL) and datasets (this https URL).</li>
</ul>

<h3>Title: FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation</h3>
<ul>
<li><strong>Authors: </strong>Xinya Ji, Sebastian Weiss, Manuel Kansy, Jacek Naruniec, Xun Cao, Barbara Solenthaler, Derek Bradley</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13837">https://arxiv.org/abs/2601.13837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13837">https://arxiv.org/pdf/2601.13837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13837]] FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation(https://arxiv.org/abs/2601.13837)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.</li>
</ul>

<h3>Title: DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes</h3>
<ul>
<li><strong>Authors: </strong>Aisha Al-Mohannadi, Ayisha Firoz, Yin Yang, Muhammad Imran, Ferda Ofli</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13839">https://arxiv.org/abs/2601.13839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13839">https://arxiv.org/pdf/2601.13839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13839]] DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes(https://arxiv.org/abs/2601.13839)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at this https URL.</li>
</ul>

<h3>Title: Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Shen, Wen Yin, Zhaoxia Yin, Wan-Li Lyu, Xinpeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13840">https://arxiv.org/abs/2601.13840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13840">https://arxiv.org/pdf/2601.13840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13840]] Robust Reversible Watermarking in Encrypted Images Based on Dual-MSBs Spiral Embedding(https://arxiv.org/abs/2601.13840)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Robust reversible watermarking in encrypted images (RRWEI) faces an inherent challenge in simultaneously achieving robustness, reversibility, and content privacy under severely constrained embedding capacity. Existing RRWEI schemes often exhibit limited robustness against noise, lossy compression, and cropping attacks due to insufficient redundancy in the encrypted domain. To address this challenge, this paper proposes a novel RRWEI framework that couples dual most significant bit-plane (dual-MSBs) embedding with spatial redundancy and error-correcting coding. By compressing prediction-error bit-planes, sufficient embedding space and auxiliary information for lossless reconstruction are reserved. The dual-MSBs are further reorganized using a spiral embedding strategy to distribute multiple redundant watermark copies across spatially dispersed regions, enhancing robustness against both noise and spatial this http URL results on standard test images demonstrate that the proposed method consistently outperforms under evaluated settings robustness against Gaussian noise, JPEG compression, and diverse cropping attacks, while maintaining perfect reversibility and high embedding capacity. Compared with state-of-the-art RRWEI schemes, the proposed framework achieves substantially lower bit-error rates and more stable performance under a wide range of attack scenarios.</li>
</ul>

<h3>Title: Inverting Self-Organizing Maps: A Unified Activation-Based Framework</h3>
<ul>
<li><strong>Authors: </strong>Alessandro Londei, Matteo Benati, Denise Lanzieri, Vittorio Loreto</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13851">https://arxiv.org/abs/2601.13851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13851">https://arxiv.org/pdf/2601.13851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13851]] Inverting Self-Organizing Maps: A Unified Activation-Based Framework(https://arxiv.org/abs/2601.13851)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Self-Organizing Maps provide topology-preserving projections of high-dimensional data and have been widely used for visualization, clustering, and vector quantization. In this work, we show that the activation pattern of a SOM - the squared distances to its prototypes - can be inverted to recover the exact input under mild geometric conditions. This follows from a classical fact in Euclidean distance geometry: a point in $D$ dimensions is uniquely determined by its distances to $D{+}1$ affinely independent references. We derive the corresponding linear system and characterize the conditions under which the inversion is well-posed. Building upon this mechanism, we introduce the Manifold-Aware Unified SOM Inversion and Control (MUSIC) update rule, which enables controlled, semantically meaningful trajectories in latent space. MUSIC modifies squared distances to selected prototypes while preserving others, resulting in a deterministic geometric flow aligned with the SOM's piecewise-linear structure. Tikhonov regularization stabilizes the update rule and ensures smooth motion on high-dimensional datasets. Unlike variational or probabilistic generative models, MUSIC does not rely on sampling, latent priors, or encoder-decoder architectures. If no perturbation is applied, inversion recovers the exact input; when a target cluster or prototype is specified, MUSIC produces coherent semantic variations while remaining on the data manifold. This leads to a new perspective on data augmentation and controllable latent exploration based solely on prototype geometry. We validate the approach using synthetic Gaussian mixtures, the MNIST and the Faces in the Wild dataset. Across all settings, MUSIC produces smooth, interpretable trajectories that reveal the underlying geometry of the learned manifold, illustrating the advantages of SOM-based inversion over unsupervised clustering.</li>
</ul>

<h3>Title: Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Raül Pérez-Gonzalo, Andreas Espersen, Antonio Agudo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13852">https://arxiv.org/abs/2601.13852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13852">https://arxiv.org/pdf/2601.13852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13852]] Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation(https://arxiv.org/abs/2601.13852)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.</li>
</ul>

<h3>Title: HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Qirui Chen, Jingxian Shuai, Shuangwu Chen, Shenghao Ye, Zijian Wen, Xufei Su, Jie Jin, Jiangming Li, Jun Chen, Xiaobin Tan, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13864">https://arxiv.org/abs/2601.13864</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13864">https://arxiv.org/pdf/2601.13864</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13864]] HardSecBench: Benchmarking the Security Awareness of LLMs for Hardware Code Generation(https://arxiv.org/abs/2601.13864)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are being increasingly integrated into practical hardware and firmware development pipelines for code generation. Existing studies have primarily focused on evaluating the functional correctness of LLM-generated code, yet paid limited attention to its security issues. However, LLM-generated code that appears functionally sound may embed security flaws which could induce catastrophic damages after deployment. This critical research gap motivates us to design a benchmark for assessing security awareness under realistic specifications. In this work, we introduce HardSecBench, a benchmark with 924 tasks spanning Verilog Register Transfer Level (RTL) and firmware-level C, covering 76 hardware-relevant Common Weakness Enumeration (CWE) entries. Each task includes a structured specification, a secure reference implementation, and executable tests. To automate artifact synthesis, we propose a multi-agent pipeline that decouples synthesis from verification and grounds evaluation in execution evidence, enabling reliable evaluation. Using HardSecBench, we evaluate a range of LLMs on hardware and firmware code generation and find that models often satisfy functional requirements while still leaving security risks. We also find that security results vary with prompting. These findings highlight pressing challenges and offer actionable insights for future advancements in LLM-assisted hardware design. Our data and code will be released soon.</li>
</ul>

<h3>Title: Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education</h3>
<ul>
<li><strong>Authors: </strong>Unggi Lee, Jahyun Jeong, Sunyoung Shin, Haeun Park, Jeongsu Moon, Youngchang Song, Jaechang Shim, JaeHwan Lee, Yunju Noh, Seungwon Choi, Ahhyun Kim, TaeHyeon Kim, Kyungtae Joo, Taeyeong Kim, Gyeonggeon Lee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13876">https://arxiv.org/abs/2601.13876</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13876">https://arxiv.org/pdf/2601.13876</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13876]] Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education(https://arxiv.org/abs/2601.13876)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.</li>
</ul>

<h3>Title: OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Unggi Lee, Sookbun Lee, Heungsoo Choi, Jinseo Lee, Haeun Park, Younghoon Jeon, Sungmin Cho, Minju Kang, Junbo Koh, Jiyeong Bae, Minwoo Nam, Juyeon Eun, Yeonji Jung, Yeil Jeong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13882">https://arxiv.org/abs/2601.13882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13882">https://arxiv.org/pdf/2601.13882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13882]] OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models(https://arxiv.org/abs/2601.13882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.</li>
</ul>

<h3>Title: Multi-Objective Hierarchical Optimization with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Andrej Schwanke, Lyubomir Ivanov, David Salinas, Frank Hutter, Arber Zela</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13892">https://arxiv.org/abs/2601.13892</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13892">https://arxiv.org/pdf/2601.13892</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13892]] Multi-Objective Hierarchical Optimization with Large Language Models(https://arxiv.org/abs/2601.13892)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Despite their widespread adoption in various domains, especially due to their powerful reasoning capabilities, Large Language Models (LLMs) are not the off-the-shelf choice to drive multi-objective optimization yet. Conventional strategies rank high in benchmarks due to their intrinsic capabilities to handle numerical inputs and careful modelling choices that balance exploration and Pareto-front exploitation, as well as handle multiple (conflicting) objectives. In this paper, we close this gap by leveraging LLMs as surrogate models and candidate samplers inside a structured hierarchical search strategy. By adaptively partitioning the input space into disjoint hyperrectangular regions and ranking them with a composite score function, we restrict the generative process of the LLM to specific, high-potential sub-spaces, hence making the problem easier to solve as the LLM doesn't have to reason about the global structure of the problem, but only locally instead. We show that under standard regularity assumptions, our algorithm generates candidate solutions that converge to the true Pareto set in Hausdorff distance. Empirically, it consistently outperforms the global LLM-based multi-objective optimizer and is on par with standard evolutionary and Bayesian optimization algorithm on synthetic and real-world benchmarks.</li>
</ul>

<h3>Title: OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3</h3>
<ul>
<li><strong>Authors: </strong>Xu Zhang, Danyang Li, Yingjie Xia, Xiaohang Dong, Hualong Yu, Jianye Wang, Qicheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13895">https://arxiv.org/abs/2601.13895</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13895">https://arxiv.org/pdf/2601.13895</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13895]] OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3(https://arxiv.org/abs/2601.13895)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.</li>
</ul>

<h3>Title: TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography</h3>
<ul>
<li><strong>Authors: </strong>Ankita Joshi, Ashutosh Sharma, Anoushkrit Goel, Ranjeet Ranjan Jha, Chirag Ahuja, Arnav Bhavsar, Aditya Nigam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13897">https://arxiv.org/abs/2601.13897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13897">https://arxiv.org/pdf/2601.13897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13897]] TractRLFusion: A GPT-Based Multi-Critic Policy Fusion Framework for Fiber Tractography(https://arxiv.org/abs/2601.13897)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Tractography plays a pivotal role in the non-invasive reconstruction of white matter fiber pathways, providing vital information on brain connectivity and supporting precise neurosurgical planning. Although traditional methods relied mainly on classical deterministic and probabilistic approaches, recent progress has benefited from supervised deep learning (DL) and deep reinforcement learning (DRL) to improve tract reconstruction. A persistent challenge in tractography is accurately reconstructing white matter tracts while minimizing spurious connections. To address this, we propose TractRLFusion, a novel GPT-based policy fusion framework that integrates multiple RL policies through a data-driven fusion strategy. Our method employs a two-stage training data selection process for effective policy fusion, followed by a multi-critic fine-tuning phase to enhance robustness and generalization. Experiments on HCP, ISMRM, and TractoInferno datasets demonstrate that TractRLFusion outperforms individual RL policies as well as state-of-the-art classical and DRL methods in accuracy and anatomical reliability.</li>
</ul>

<h3>Title: Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Masoumeh Javanbakhat, Piotr Komorowski, Dilyara Bareeva, Wei-Chang Lai, Wojciech Samek, Christoph Lippert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13899">https://arxiv.org/abs/2601.13899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13899">https://arxiv.org/pdf/2601.13899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13899]] Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging(https://arxiv.org/abs/2601.13899)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability</a></li>
<li><strong>Abstract: </strong>Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.</li>
</ul>

<h3>Title: Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain</h3>
<ul>
<li><strong>Authors: </strong>Cosmin-Iulian Irimia</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13907">https://arxiv.org/abs/2601.13907</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13907">https://arxiv.org/pdf/2601.13907</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13907]] Decentralized Infrastructure for Digital Notarizing, Signing and Sharing Files using Blockchain(https://arxiv.org/abs/2601.13907)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>Traditional paper-based document management has long posed challenges related to security, authenticity, and efficiency. Despite advances in digitalization, official documents remain vulnerable to forgery, loss, and unauthorized access. This thesis proposes a decentralized infrastructure for digital notarization, signing, and sharing of documents using blockchain technology. The research addresses key issues of transparency, immutability, and feasibility by defining system requirements, evaluating existing solutions, and proposing a novel architecture based on distributed systems. By combining cryptographic techniques with decentralized storage, this research contributes to the development of a more secure and efficient framework for managing official documents. The findings highlight the potential of blockchain-based digital notarization to streamline bureaucratic processes, mitigate security risks, and enhance user trust in digital document management.</li>
</ul>

<h3>Title: AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization</h3>
<ul>
<li><strong>Authors: </strong>Yusheng Liao, Chuan Xuan, Yutong Cai, Lina Yang, Zhe Chen, Yanfeng Wang, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13918">https://arxiv.org/abs/2601.13918</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13918">https://arxiv.org/pdf/2601.13918</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13918]] AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization(https://arxiv.org/abs/2601.13918)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.</li>
</ul>

<h3>Title: Automatic Prompt Optimization for Dataset-Level Feature Discovery</h3>
<ul>
<li><strong>Authors: </strong>Adrian Cosma, Oleg Szehr, David Kletz, Alessandro Antonucci, Olivier Pelletier</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13922">https://arxiv.org/abs/2601.13922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13922">https://arxiv.org/pdf/2601.13922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13922]] Automatic Prompt Optimization for Dataset-Level Feature Discovery(https://arxiv.org/abs/2601.13922)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability</a></li>
<li><strong>Abstract: </strong>Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.</li>
</ul>

<h3>Title: TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Anoushkrit Goel, Simroop Singh, Ankita Joshi, Ranjeet Ranjan Jha, Chirag Ahuja, Aditya Nigam, Arnav Bhavsar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13935">https://arxiv.org/abs/2601.13935</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13935">https://arxiv.org/pdf/2601.13935</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13935]] TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation(https://arxiv.org/abs/2601.13935)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.</li>
</ul>

<h3>Title: VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content</h3>
<ul>
<li><strong>Authors: </strong>Shengyi Wu, Yan Hong, Shengyao Chen, Zheng Wang, Xianbing Sun, Jiahui Zhan, Jun Lan, Jianfu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13951">https://arxiv.org/abs/2601.13951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13951">https://arxiv.org/pdf/2601.13951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13951]] VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content(https://arxiv.org/abs/2601.13951)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, generative, segmentation</a></li>
<li><strong>Abstract: </strong>With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.</li>
</ul>

<h3>Title: DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging</h3>
<ul>
<li><strong>Authors: </strong>Adrien Meyer, Didier Mutter, Nicolas Padoy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13954">https://arxiv.org/abs/2601.13954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13954">https://arxiv.org/pdf/2601.13954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13954]] DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging(https://arxiv.org/abs/2601.13954)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer</a></li>
<li><strong>Abstract: </strong>Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.</li>
</ul>

<h3>Title: RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Cheol-Hui Lee, Hwa-Yeon Lee, Dong-Joo Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13964">https://arxiv.org/abs/2601.13964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13964">https://arxiv.org/pdf/2601.13964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13964]] RL-BioAug: Label-Efficient Reinforcement Learning for Self-Supervised EEG Representation Learning(https://arxiv.org/abs/2601.13964)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The quality of data augmentation serves as a critical determinant for the performance of contrastive learning in EEG tasks. Although this paradigm is promising for utilizing unlabeled data, static or random augmentation strategies often fail to preserve intrinsic information due to the non-stationarity of EEG signals where statistical properties change over time. To address this, we propose RL-BioAug, a framework that leverages a label-efficient reinforcement learning (RL) agent to autonomously determine optimal augmentation policies. While utilizing only a minimal fraction (10\%) of labeled data to guide the agent's policy, our method enables the encoder to learn robust representations in a strictly self-supervised manner. Experimental results demonstrate that RL-BioAug significantly outperforms the random selection strategy, achieving substantial improvements of 9.69\% and 8.80\% in Macro-F1 score on the Sleep-EDFX and CHB-MIT datasets, respectively. Notably, this agent mainly chose optimal strategies for each task -- for example, Time Masking with a 62\% probability for sleep stage classification and Crop \& Resize with a 77\% probability for seizure detection. Our framework suggests its potential to replace conventional heuristic-based augmentations and establish a new autonomous paradigm for data augmentation. The source code is available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames</h3>
<ul>
<li><strong>Authors: </strong>Shih-Yao Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13974">https://arxiv.org/abs/2601.13974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13974">https://arxiv.org/pdf/2601.13974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13974]] STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames(https://arxiv.org/abs/2601.13974)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content. We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality. Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding. We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.</li>
</ul>

<h3>Title: Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains</h3>
<ul>
<li><strong>Authors: </strong>Marco Piccolo, Qiwei Han, Astrid van Toor, Joachim Vanneste</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13975">https://arxiv.org/abs/2601.13975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13975">https://arxiv.org/pdf/2601.13975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13975]] Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains(https://arxiv.org/abs/2601.13975)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.</li>
</ul>

<h3>Title: FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation</h3>
<ul>
<li><strong>Authors: </strong>Jing Zuo, Lingzhou Mu, Fan Jiang, Chengcheng Ma, Mu Xu, Yonggang Qi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13976">https://arxiv.org/abs/2601.13976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13976">https://arxiv.org/pdf/2601.13976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13976]] FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation(https://arxiv.org/abs/2601.13976)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.</li>
</ul>

<h3>Title: VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation</h3>
<ul>
<li><strong>Authors: </strong>Yilin Tang, Yu Wang, Lanlan Qiu, Wenchang Gao, Yunfei Ma, Baicheng Chen, Tianxing He</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13981">https://arxiv.org/abs/2601.13981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13981">https://arxiv.org/pdf/2601.13981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13981]] VirtualCrime: Evaluating Criminal Potential of Large Language Models via Sandbox Simulation(https://arxiv.org/abs/2601.13981)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown strong capabilities in multi-step decision-making, planning and actions, and are increasingly integrated into various real-world applications. It is concerning whether their strong problem-solving abilities may be misused for crimes. To address this gap, we propose VirtualCrime, a sandbox simulation framework based on a three-agent system to evaluate the criminal capabilities of models. Specifically, this framework consists of an attacker agent acting as the leader of a criminal team, a judge agent determining the outcome of each action, and a world manager agent updating the environment state and entities. Furthermore, we design 40 diverse crime tasks within this framework, covering 11 maps and 13 crime objectives such as theft, robbery, kidnapping, and riot. We also introduce a human player baseline for reference to better interpret the performance of LLM agents. We evaluate 8 strong LLMs and find (1) All agents in the simulation environment compliantly generate detailed plans and execute intelligent crime processes, with some achieving relatively high success rates; (2) In some cases, agents take severe action that inflicts harm to NPCs to achieve their goals. Our work highlights the need for safety alignment when deploying agentic AI in real-world settings.</li>
</ul>

<h3>Title: "The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework</h3>
<ul>
<li><strong>Authors: </strong>Jin Cui, Jiaqi Guo, Jiepeng Zhou, Ruixuan Yang, Jiayi Lu, Jiajun Xu, Jiangcheng Song, Boran Zhao, Pengju Ren</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.13992">https://arxiv.org/abs/2601.13992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.13992">https://arxiv.org/pdf/2601.13992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.13992]] "The Whole Is Greater Than the Sum of Its Parts": A Compatibility-Aware Multi-Teacher CoT Distillation Framework(https://arxiv.org/abs/2601.13992)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect "epiphany moments" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.</li>
</ul>

<h3>Title: Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hengyuan Zhang, Zhihao Zhang, Mingyang Wang, Zunhai Su, Yiwei Wang, Qianli Wang, Shuzhou Yuan, Ercong Nie, Xufeng Duan, Qibo Xue, Zeping Yu, Chenming Shang, Xiao Liang, Jing Xiong, Hui Shen, Chaofan Tao, Zhengwu Liu, Senjie Jin, Zhiheng Xi, Dongdong Zhang, Sophia Ananiadou, Tao Gui, Ruobing Xie, Hayden Kwok-Hay So, Hinrich Schütze, Xuanjing Huang, Qi Zhang, Ngai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14004">https://arxiv.org/abs/2601.14004</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14004">https://arxiv.org/pdf/2601.14004</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14004]] Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models(https://arxiv.org/abs/2601.14004)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: "Locate, Steer, and Improve." We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at this https URL.</li>
</ul>

<h3>Title: BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junyu Zhang, Yipeng Kang, Jiong Guo, Jiayu Zhan, Junqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14007">https://arxiv.org/abs/2601.14007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14007">https://arxiv.org/pdf/2601.14007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14007]] BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models(https://arxiv.org/abs/2601.14007)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.</li>
</ul>

<h3>Title: A Security Framework for Chemical Functions</h3>
<ul>
<li><strong>Authors: </strong>Frederik Walter, Hrishi Narayanan, Jessica Bariffi, Anne Lüscher, Rawad Bitar, Robert Grass, Antonia Wachter-Zeh, Zohar Yakhini</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14019">https://arxiv.org/abs/2601.14019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14019">https://arxiv.org/pdf/2601.14019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14019]] A Security Framework for Chemical Functions(https://arxiv.org/abs/2601.14019)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, extraction</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce chemical functions, a unified framework that models chemical systems as noisy challenge--response primitives, and formalize the associated chemical function infrastructure. Building on the theory of physical functions, we rigorously define robustness, unclonability, and unpredictability for chemical functions in both finite and asymptotic regimes, and specify security games that capture the adversary's power and the security goals. We instantiate the framework with two existing DNA-based constructions (operable random DNA and Genomic Sequence Encryption) and derive quantitative bounds for robustness, unclonability, and unpredictability. Our analysis develops maximum-likelihood verification rules under sequencing noise and partial-edit models, and provides high-precision estimates based on binomial distributions to guide parameter selection. The framework, definitions, and analyses yield a reproducible methodology for designing chemically unclonable authentication mechanisms. We demonstrate applications to in-product authentication and to shared key generation using standard extraction techniques.</li>
</ul>

<h3>Title: OAMAC: Origin-Aware Mandatory Access Control for Practical Post-Compromise Attack Surface Reduction</h3>
<ul>
<li><strong>Authors: </strong>Omer Abdelmajeed Idris Mohammed, Ilhami M. Orak</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.OS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14021">https://arxiv.org/abs/2601.14021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14021">https://arxiv.org/pdf/2601.14021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14021]] OAMAC: Origin-Aware Mandatory Access Control for Practical Post-Compromise Attack Surface Reduction(https://arxiv.org/abs/2601.14021)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Modern operating systems provide powerful mandatory access control mechanisms, yet they largely reason about who executes code rather than how execution originates. As a result, processes launched remotely, locally, or by background services are often treated equivalently once privileges are obtained, complicating security reasoning and enabling post-compromise abuse of sensitive system interfaces. We introduce origin-aware mandatory access control (OAMAC), a kernel-level enforcement model that treats execution origin -- such as physical user presence, remote access, or service execution -- as a first-class security attribute. OAMAC mediates access to security-critical subsystems based on execution provenance rather than identity alone, enabling centralized governance over multiple attack surfaces while significantly reducing policy complexity. We present a deployable prototype implemented entirely using the Linux eBPF LSM framework, requiring no kernel modifications. OAMAC classifies execution origin using kernel-visible metadata, propagates origin across process creation, and enforces origin-aware policies on both sensitive filesystem interfaces and the kernel BPF control plane. Policies are maintained in kernel-resident eBPF maps and can be reconfigured at runtime via a minimal userspace tool. Our evaluation demonstrates that OAMAC effectively restricts common post-compromise actions available to remote attackers while preserving normal local administration and system stability. We argue that execution origin represents a missing abstraction in contemporary operating system security models, and that elevating it to a first-class concept enables practical attack surface reduction without requiring subsystem-specific expertise or heavyweight security frameworks.</li>
</ul>

<h3>Title: Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment</h3>
<ul>
<li><strong>Authors: </strong>Rodrigo Pereira David, Luciano Araujo Dourado Filho, Daniel Marques da Silva, João Alfredo Cal-Braz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14022">https://arxiv.org/abs/2601.14022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14022">https://arxiv.org/pdf/2601.14022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14022]] Credible CO2 Comparisons: A Machine Learning Approach to Vehicle Powertrain Assessment(https://arxiv.org/abs/2601.14022)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Decarbonizing road transport requires consistent and transparent methods for comparing CO2 emissions across vehicle technologies. This paper proposes a machine learning-based framework for like-for-like operational assessment of internal combustion engine vehicles (ICEVs) and electric vehicles (EVs) under identical, real-world driving conditions. The approach isolates technology-specific effects by holding the observed speed profile and environmental context fixed, enabling direct comparison of powertrain performance. Recurrent neural network models are trained independently for each domain to learn the mapping from contextual driving variables (speed, acceleration, temperature) to internal actuation variables (torque, throttle) and instantaneous CO2-equivalent emission rates. This structure allows the construction of counterfactual scenarios that answer: What emissions would an EV have generated if it had followed the same driving profile as an ICEV? By aligning both vehicle types on a unified instantaneous emissions metric, the framework enables fair and reproducible evaluation of powertrain technologies. It offers a scalable foundation for credible, data-driven assessments of vehicle carbon performance under real-world operating conditions.</li>
</ul>

<h3>Title: Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Samuel W. Remedios, Zhangxing Bian, Shuwen Wei, Aaron Carass, Jerry L. Prince, Blake E. Dewey</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14030">https://arxiv.org/abs/2601.14030</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14030">https://arxiv.org/pdf/2601.14030</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14030]] Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution(https://arxiv.org/abs/2601.14030)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.</li>
</ul>

<h3>Title: RM-Distiller: Exploiting Generative LLM for Reward Model Distillation</h3>
<ul>
<li><strong>Authors: </strong>Hongli Zhou, Hui Huang, Wei Liu, Chenglong Wang, Xingyuan Bu, Lvyuan Han, Fuhai Song, Muyun Yang, Wenhao Jiang, Hailong Cao, Tiejun Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14032">https://arxiv.org/abs/2601.14032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14032">https://arxiv.org/pdf/2601.14032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14032]] RM-Distiller: Exploiting Generative LLM for Reward Model Distillation(https://arxiv.org/abs/2601.14032)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.</li>
</ul>

<h3>Title: PAC-Private Responses with Adversarial Composition</h3>
<ul>
<li><strong>Authors: </strong>Xiaochen Zhu, Mayuri Sridhar, Srinivas Devadas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14033">https://arxiv.org/abs/2601.14033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14033">https://arxiv.org/pdf/2601.14033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14033]] PAC-Private Responses with Adversarial Composition(https://arxiv.org/abs/2601.14033)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Modern machine learning models are increasingly deployed behind APIs. This renders standard weight-privatization methods (e.g. DP-SGD) unnecessarily noisy at the cost of utility. While model weights may vary significantly across training datasets, model responses to specific inputs are much lower dimensional and more stable. This motivates enforcing privacy guarantees directly on model outputs. We approach this under PAC privacy, which provides instance-based privacy guarantees for arbitrary black-box functions by controlling mutual information (MI). Importantly, PAC privacy explicitly rewards output stability with reduced noise levels. However, a central challenge remains: response privacy requires composing a large number of adaptively chosen, potentially adversarial queries issued by untrusted users, where existing composition results on PAC privacy are inadequate. We introduce a new algorithm that achieves adversarial composition via adaptive noise calibration and prove that mutual information guarantees accumulate linearly under adaptive and adversarial querying. Experiments across tabular, vision, and NLP tasks show that our method achieves high utility at extremely small per-query privacy budgets. On CIFAR-10, we achieve 87.79% accuracy with a per-step MI budget of $2^{-32}$. This enables serving one million queries while provably bounding membership inference attack (MIA) success rates to 51.08% -- the same guarantee of $(0.04, 10^{-5})$-DP. Furthermore, we show that private responses can be used to label public data to distill a publishable privacy-preserving model; using an ImageNet subset as a public dataset, our model distilled from 210,000 responses achieves 91.86% accuracy on CIFAR-10 with MIA success upper-bounded by 50.49%, which is comparable to $(0.02,10^{-5})$-DP.</li>
</ul>

<h3>Title: Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Wesam Moustafa, Hossam Elsafty, Helen Schneider, Lorenz Sparrenberg, Rafet Sifa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14039">https://arxiv.org/abs/2601.14039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14039">https://arxiv.org/pdf/2601.14039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14039]] Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation(https://arxiv.org/abs/2601.14039)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at this https URL.</li>
</ul>

<h3>Title: Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants</h3>
<ul>
<li><strong>Authors: </strong>Yunhe Wang, Kai Han, Huiling Zhen, Yuchuan Tian, Hanting Chen, Yongbing Huang, Yufei Cui, Yingte Shu, Shan Gao, Ismail Elezi, Roy Vaughan Miles, Songcen Xu, Feng Wen, Chao Xu, Sinan Zeng, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14041">https://arxiv.org/abs/2601.14041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14041">https://arxiv.org/pdf/2601.14041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14041]] Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants(https://arxiv.org/abs/2601.14041)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.</li>
</ul>

<h3>Title: Federated Balanced Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiaze Li, Haoran Xu, Wanyi Wu, Changwei Wang, Shuaiguang Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Youyang Qu, Longxiang Gao, Xudong Yang, Lumin Xing</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14042">https://arxiv.org/abs/2601.14042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14042">https://arxiv.org/pdf/2601.14042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14042]] Federated Balanced Learning(https://arxiv.org/abs/2601.14042)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.</li>
</ul>

<h3>Title: PRiSM: Benchmarking Phone Realization in Speech Models</h3>
<ul>
<li><strong>Authors: </strong>Shikhar Bharadwaj, Chin-Jou Li, Yoonjae Kim, Kwanghee Choi, Eunjung Yeo, Ryan Soh-Eun Shim, Hanyu Zhou, Brendon Boldt, Karen Rosero Jacome, Kalvin Chang, Darsh Agrawal, Keer Xu, Chao-Han Huck Yang, Jian Zhu, Shinji Watanabe, David R. Mortensen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14046">https://arxiv.org/abs/2601.14046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14046">https://arxiv.org/pdf/2601.14046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14046]] PRiSM: Benchmarking Phone Realization in Speech Models(https://arxiv.org/abs/2601.14046)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: this https URL.</li>
</ul>

<h3>Title: Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Haoran Xu, Yanlin Liu, Zizhao Tong, Jiaze Li, Kexue Fu, Yuyang Zhang, Longxiang Gao, Shuaiguang Li, Xingyu Li, Yanran Xu, Changwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14052">https://arxiv.org/abs/2601.14052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14052">https://arxiv.org/pdf/2601.14052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14052]] Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model(https://arxiv.org/abs/2601.14052)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.</li>
</ul>

<h3>Title: LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems</h3>
<ul>
<li><strong>Authors: </strong>Badri N. Patro, Vijay S. Agneeswaran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.MA, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14053">https://arxiv.org/abs/2601.14053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14053">https://arxiv.org/pdf/2601.14053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14053]] LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems(https://arxiv.org/abs/2601.14053)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dimensions, documenting architectural innovations, training methodologies, and efficiency patterns defining modern LLMs, generative AI, and agentic systems. We identify three critical crises: (1) data scarcity (9-27T tokens depleted by 2026-2028), (2) exponential cost growth ($3M to $300M+ in 5 years), and (3) unsustainable energy consumption (22x increase), establishing the scaling wall limiting brute-force approaches. Our analysis reveals six paradigms breaking this wall: (1) test-time compute (o1, DeepSeek-R1 achieve GPT-4 performance with 10x inference compute), (2) quantization (4-8x compression), (3) distributed edge computing (10x cost reduction), (4) model merging, (5) efficient training (ORPO reduces memory 50%), and (6) small specialized models (Phi-4 14B matches larger models). Three paradigm shifts emerge: (1) post-training gains (RLHF, GRPO, pure RL contribute substantially, DeepSeek-R1 achieving 79.8% MATH), (2) efficiency revolution (MoE routing 18x efficiency, Multi-head Latent Attention 8x KV cache compression enables GPT-4-level performance at <$0.30/M tokens), and (3) democratization (open-source Llama 3 88.6% MMLU surpasses GPT-4 86.4%). We provide insights into techniques (RLHF, PPO, DPO, GRPO, ORPO), trace evolution from passive generation to tool-using agents (ReAct, RAG, multi-agent systems), and analyze post-training innovations.</li>
</ul>

<h3>Title: SecureSplit: Mitigating Backdoor Attacks in Split Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhihao Dou, Dongfei Cui, Weida Wang, Anjun Gao, Yueyang Quan, Mengyao Ma, Viet Vo, Guangdong Bai, Zhuqing Liu, Minghong Fang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14054">https://arxiv.org/abs/2601.14054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14054">https://arxiv.org/pdf/2601.14054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14054]] SecureSplit: Mitigating Backdoor Attacks in Split Learning(https://arxiv.org/abs/2601.14054)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>Split Learning (SL) offers a framework for collaborative model training that respects data privacy by allowing participants to share the same dataset while maintaining distinct feature sets. However, SL is susceptible to backdoor attacks, in which malicious clients subtly alter their embeddings to insert hidden triggers that compromise the final trained model. To address this vulnerability, we introduce SecureSplit, a defense mechanism tailored to SL. SecureSplit applies a dimensionality transformation strategy to accentuate subtle differences between benign and poisoned embeddings, facilitating their separation. With this enhanced distinction, we develop an adaptive filtering approach that uses a majority-based voting scheme to remove contaminated embeddings while preserving clean ones. Rigorous experiments across four datasets (CIFAR-10, MNIST, CINIC-10, and ImageNette), five backdoor attack scenarios, and seven alternative defenses confirm the effectiveness of SecureSplit under various challenging conditions.</li>
</ul>

<h3>Title: Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI</h3>
<ul>
<li><strong>Authors: </strong>Andrea Protani, Marc Molina Van Den Bosch, Lorenzo Giusti, Heloisa Barbosa Da Silva, Paolo Cacace, Albert Sund Aillet, Miguel Angel Gonzalez Ballester, Friedhelm Hummel, Luigi Serio</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14055">https://arxiv.org/abs/2601.14055</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14055">https://arxiv.org/pdf/2601.14055</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14055]] Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI(https://arxiv.org/abs/2601.14055)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability, transformer</a></li>
<li><strong>Abstract: </strong>Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.</li>
</ul>

<h3>Title: POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Andrea Rigo, Luca Stornaiuolo, Weijie Wang, Mauro Martino, Bruno Lepri, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14056">https://arxiv.org/abs/2601.14056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14056">https://arxiv.org/pdf/2601.14056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14056]] POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion(https://arxiv.org/abs/2601.14056)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.</li>
</ul>

<h3>Title: Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration</h3>
<ul>
<li><strong>Authors: </strong>Yongcong Ye, Kai Zhang, Yanghai Zhang, Enhong Chen, Longfei Li, Jun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14060">https://arxiv.org/abs/2601.14060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14060">https://arxiv.org/pdf/2601.14060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14060]] Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration(https://arxiv.org/abs/2601.14060)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at this https URL.</li>
</ul>

<h3>Title: XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Mohsinul Kabir, Tasnim Ahmed, Md Mezbaur Rahman, Shaoxiong Ji, Hassan Alhuzali, Sophia Ananiadou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14063">https://arxiv.org/abs/2601.14063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14063">https://arxiv.org/pdf/2601.14063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14063]] XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs(https://arxiv.org/abs/2601.14063)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.</li>
</ul>

<h3>Title: VENI: Variational Encoder for Natural Illumination</h3>
<ul>
<li><strong>Authors: </strong>Paul Walker, James A. D. Gardner, Andreea Ardelean, William A. P. Smith, Bernhard Egger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14079">https://arxiv.org/abs/2601.14079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14079">https://arxiv.org/pdf/2601.14079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14079]] VENI: Variational Encoder for Natural Illumination(https://arxiv.org/abs/2601.14079)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.</li>
</ul>

<h3>Title: Two-Stream temporal transformer for video action classification</h3>
<ul>
<li><strong>Authors: </strong>Nattapong Kurpukdee, Adrian G. Bors</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14086">https://arxiv.org/abs/2601.14086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14086">https://arxiv.org/pdf/2601.14086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14086]] Two-Stream temporal transformer for video action classification(https://arxiv.org/abs/2601.14086)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.</li>
</ul>

<h3>Title: Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition</h3>
<ul>
<li><strong>Authors: </strong>Emily Kim, Allen Wu, Jessica Hodgins</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14101">https://arxiv.org/abs/2601.14101</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14101">https://arxiv.org/pdf/2601.14101</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14101]] Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition(https://arxiv.org/abs/2601.14101)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training. We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures. Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.</li>
</ul>

<h3>Title: Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing</h3>
<ul>
<li><strong>Authors: </strong>Xiaolu Liu, Yicong Li, Qiyuan He, Jiayin Zhu, Wei Ji, Angela Yao, Jianke Zhu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14103">https://arxiv.org/abs/2601.14103</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14103">https://arxiv.org/pdf/2601.14103</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14103]] Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing(https://arxiv.org/abs/2601.14103)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at this https URL.</li>
</ul>

<h3>Title: AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain</h3>
<ul>
<li><strong>Authors: </strong>Max Landauer, Wolfgang Hotwagner, Thorina Boenke, Florian Skopik, Markus Wurzenberger</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14108">https://arxiv.org/abs/2601.14108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14108">https://arxiv.org/pdf/2601.14108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14108]] AttackMate: Realistic Emulation and Automation of Cyber Attack Scenarios Across the Kill Chain(https://arxiv.org/abs/2601.14108)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Adversary emulation tools facilitate scripting and automated execution of cyber attack chains, thereby reducing costs and manual expert effort required for security testing, cyber exercises, and intrusion detection research. However, due to the fact that existing tools typically rely on agents installed on target systems, they leave suspicious traces that make it easy to distinguish their activities from those of real human attackers. Moreover, these tools often lack relevant capabilities, such as handling of interactive prompts, and are unsuitable for emulating specific stages of the kill chain, such as initial access. This paper thus introduces AttackMate, an open-source attack scripting language and execution engine designed to mimic behavior patterns of actual attackers. We validate the tool in a case study covering common attack steps including privilege escalation, information gathering, and lateral movement. Our results indicate that log artifacts resulting from AttackMate's activities resemble those produced by human attackers more closely than those generated by standard adversary emulation tools.</li>
</ul>

<h3>Title: Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns</h3>
<ul>
<li><strong>Authors: </strong>George Mihaila</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14112">https://arxiv.org/abs/2601.14112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14112">https://arxiv.org/pdf/2601.14112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14112]] Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns(https://arxiv.org/abs/2601.14112)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.</li>
</ul>

<h3>Title: NewsRECON: News article REtrieval for image CONtextualization</h3>
<ul>
<li><strong>Authors: </strong>Jonathan Tonglet, Iryna Gurevych, Tinne Tuytelaars, Marie-Francine Moens</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14121">https://arxiv.org/abs/2601.14121</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14121">https://arxiv.org/pdf/2601.14121</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14121]] NewsRECON: News article REtrieval for image CONtextualization(https://arxiv.org/abs/2601.14121)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.</li>
</ul>

<h3>Title: Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic</h3>
<ul>
<li><strong>Authors: </strong>Saad Mankarious, Aya Zirikly</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14124">https://arxiv.org/abs/2601.14124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14124">https://arxiv.org/pdf/2601.14124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14124]] Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic(https://arxiv.org/abs/2601.14124)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.</li>
</ul>

<h3>Title: The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Renmiao Chen, Yida Lu, Shiyao Cui, Xuan Ouyang, Victor Shea-Jay Huang, Shumin Zhang, Chengwei Pan, Han Qiu, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14127">https://arxiv.org/abs/2601.14127</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14127">https://arxiv.org/pdf/2601.14127</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14127]] The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning(https://arxiv.org/abs/2601.14127)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at this https URL.</li>
</ul>

<h3>Title: Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hyunjong Ok, Jaeho Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14152">https://arxiv.org/abs/2601.14152</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14152">https://arxiv.org/pdf/2601.14152</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14152]] Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models(https://arxiv.org/abs/2601.14152)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.</li>
</ul>

<h3>Title: LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery</h3>
<ul>
<li><strong>Authors: </strong>Shubham Pandey, Bhavin Jawade, Srirangaraj Setlur, Venu Govindaraju, Kenneth Seastedt</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14154">https://arxiv.org/abs/2601.14154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14154">https://arxiv.org/pdf/2601.14154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14154]] LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery(https://arxiv.org/abs/2601.14154)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.</li>
</ul>

<h3>Title: Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law</h3>
<ul>
<li><strong>Authors: </strong>Ali Hamza Bashir, Muhammad Rehan Khalid, Kostadin Cvejoski, Jana Birr, Jule Berghaus, Armin Berger, Sandra Halscheidt, Christian Temath, Rafet Sifa, David Berghaus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14160">https://arxiv.org/abs/2601.14160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14160">https://arxiv.org/pdf/2601.14160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14160]] Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law(https://arxiv.org/abs/2601.14160)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.</li>
</ul>

<h3>Title: One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yitong Dong, Qi Zhang, Minchao Jiang, Zhiqiang Wu, Qingnan Fan, Ying Feng, Huaqi Zhang, Hujun Bao, Guofeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14161">https://arxiv.org/abs/2601.14161</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14161">https://arxiv.org/pdf/2601.14161</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14161]] One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion(https://arxiv.org/abs/2601.14161)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.</li>
</ul>

<h3>Title: Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum</h3>
<ul>
<li><strong>Authors: </strong>Víctor Yeste, Paolo Rosso</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14172">https://arxiv.org/abs/2601.14172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14172">https://arxiv.org/pdf/2601.14172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14172]] Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum(https://arxiv.org/abs/2601.14172)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task ("does any value appear?") and show that it is learnable from single sentences (positive-class F1 $\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.</li>
</ul>

<h3>Title: Penalizing Localized Dirichlet Energies in Low Rank Tensor Products</h3>
<ul>
<li><strong>Authors: </strong>Paris A. Karakasis, Nicholas D. Sidiropoulos</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14173">https://arxiv.org/abs/2601.14173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14173">https://arxiv.org/pdf/2601.14173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14173]] Penalizing Localized Dirichlet Energies in Low Rank Tensor Products(https://arxiv.org/abs/2601.14173)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We study low-rank tensor-product B-spline (TPBS) models for regression tasks and investigate Dirichlet energy as a measure of smoothness. We show that TPBS models admit a closed-form expression for the Dirichlet energy, and reveal scenarios where perfect interpolation is possible with exponentially small Dirichlet energy. This renders global Dirichlet energy-based regularization ineffective. To address this limitation, we propose a novel regularization strategy based on local Dirichlet energies defined on small hypercubes centered at the training points. Leveraging pretrained TPBS models, we also introduce two estimators for inference from incomplete samples. Comparative experiments with neural networks demonstrate that TPBS models outperform neural networks in the overfitting regime for most datasets, and maintain competitive performance otherwise. Overall, TPBS models exhibit greater robustness to overfitting and consistently benefit from regularization, while neural networks are more sensitive to overfitting and less effective in leveraging regularization.</li>
</ul>

<h3>Title: A model of errors in transformers</h3>
<ul>
<li><strong>Authors: </strong>Suvrat Raju, Praneeth Netrapalli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, hep-th</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14175">https://arxiv.org/abs/2601.14175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14175">https://arxiv.org/pdf/2601.14175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14175]] A model of errors in transformers(https://arxiv.org/abs/2601.14175)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We study the error rate of LLMs on tasks like arithmetic that require a deterministic output, and repetitive processing of tokens drawn from a small set of alternatives. We argue that incorrect predictions arise when small errors in the attention mechanism accumulate to cross a threshold, and use this insight to derive a quantitative two-parameter relationship between the accuracy and the complexity of the task. The two parameters vary with the prompt and the model; they can be interpreted in terms of an elementary noise rate, and the number of plausible erroneous tokens that can be predicted. Our analysis is inspired by an ``effective field theory'' perspective: the LLM's many raw parameters can be reorganized into just two parameters that govern the error rate. We perform extensive empirical tests, using Gemini 2.5 Flash, Gemini 2.5 Pro and DeepSeek R1, and find excellent agreement between the predicted and observed accuracy for a variety of tasks, although we also identify deviations in some cases. Our model provides an alternative to suggestions that errors made by LLMs on long repetitive tasks indicate the ``collapse of reasoning'', or an inability to express ``compositional'' functions. Finally, we show how to construct prompts to reduce the error rate.</li>
</ul>

<h3>Title: InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Matthew Y. R. Yang, Hao Bai, Ian Wu, Gene Yang, Amrith Setlur, Aviral Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14209">https://arxiv.org/abs/2601.14209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14209">https://arxiv.org/pdf/2601.14209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14209]] InT: Self-Proposed Interventions Enable Credit Assignment in LLM Reasoning(https://arxiv.org/abs/2601.14209)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Outcome-reward reinforcement learning (RL) has proven effective at improving the reasoning capabilities of large language models (LLMs). However, standard RL assigns credit only at the level of the final answer, penalizing entire reasoning traces when the outcome is incorrect and uniformly reinforcing all steps when it is correct. As a result, correct intermediate steps may be discouraged in failed traces, while spurious steps may be reinforced in successful ones. We refer to this failure mode as the problem of credit assignment. While a natural remedy is to train a process reward model, accurately optimizing such models to identify corrective reasoning steps remains challenging. We introduce Intervention Training (InT), a training paradigm in which the model performs fine-grained credit assignment on its own reasoning traces by proposing short, targeted corrections that steer trajectories toward higher reward. Using reference solutions commonly available in mathematical reasoning datasets and exploiting the fact that verifying a model-generated solution is easier than generating a correct one from scratch, the model identifies the first error in its reasoning and proposes a single-step intervention to redirect the trajectory toward the correct solution. We then apply supervised fine-tuning (SFT) to the on-policy rollout up to the point of error concatenated with the intervention, localizing error to the specific step that caused failure. We show that the resulting model serves as a far better initialization for RL training. After running InT and subsequent fine-tuning with RL, we improve accuracy by nearly 14% over a 4B-parameter base model on IMO-AnswerBench, outperforming larger open-source models such as gpt-oss-20b.</li>
</ul>

<h3>Title: HALT: Hallucination Assessment via Latent Testing</h3>
<ul>
<li><strong>Authors: </strong>Rohan Bhatnagar, Youran Sun, Chi Andrew Zhang, Yixin Wen, Haizhao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14210">https://arxiv.org/abs/2601.14210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14210">https://arxiv.org/pdf/2601.14210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14210]] HALT: Hallucination Assessment via Latent Testing(https://arxiv.org/abs/2601.14210)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.</li>
</ul>

<h3>Title: Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment</h3>
<ul>
<li><strong>Authors: </strong>Punit Kumar, Vaibhav Saran, Divyesh Patel, Nitin Kulkarni, Alina Vereshchaka</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14228">https://arxiv.org/abs/2601.14228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14228">https://arxiv.org/pdf/2601.14228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14228]] Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment(https://arxiv.org/abs/2601.14228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups upon ICU admission, using clustering with statistical validation; (2) a synthetic data augmentation pipeline leveraging variational autoencoders (VAE) and diffusion models to enrich underrepresented trajectories such as fluid or vasopressor administration; (3) an offline reinforcement learning (RL) agent trained using Advantage Weighted Regression (AWR) with a lightweight attention encoder and supported by an ensemble models for conservative, safety-aware treatment recommendations; and (4) a rationale generation module powered by a multi-modal large language model (LLM), which produces natural-language justifications grounded in clinical context and retrieved expert knowledge. Evaluated on the MIMIC-III and eICU datasets, our approach achieves high treatment accuracy while providing clinicians with interpretable and robust policy recommendations.</li>
</ul>

<h3>Title: Q-learning with Adjoint Matching</h3>
<ul>
<li><strong>Authors: </strong>Qiyang Li, Sergey Levine</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14234">https://arxiv.org/abs/2601.14234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14234">https://arxiv.org/pdf/2601.14234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14234]] Q-learning with Adjoint Matching(https://arxiv.org/abs/2601.14234)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We propose Q-learning with Adjoint Matching (QAM), a novel TD-based reinforcement learning (RL) algorithm that tackles a long-standing challenge in continuous-action RL: efficient optimization of an expressive diffusion or flow-matching policy with respect to a parameterized Q-function. Effective optimization requires exploiting the first-order information of the critic, but it is challenging to do so for flow or diffusion policies because direct gradient-based optimization via backpropagation through their multi-step denoising process is numerically unstable. Existing methods work around this either by only using the value and discarding the gradient information, or by relying on approximations that sacrifice policy expressivity or bias the learned policy. QAM sidesteps both of these challenges by leveraging adjoint matching, a recently proposed technique in generative modeling, which transforms the critic's action gradient to form a step-wise objective function that is free from unstable backpropagation, while providing an unbiased, expressive policy at the optimum. Combined with temporal-difference backup for critic learning, QAM consistently outperforms prior approaches on hard, sparse reward tasks in both offline and offline-to-online RL.</li>
</ul>

<h3>Title: Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow</h3>
<ul>
<li><strong>Authors: </strong>Haocheng Xi, Charlie Ruan, Peiyuan Liao, Yujun Lin, Han Cai, Yilong Zhao, Shuo Yang, Kurt Keutzer, Song Han, Ligeng Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14243">https://arxiv.org/abs/2601.14243</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14243">https://arxiv.org/pdf/2601.14243</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14243]] Jet-RL: Enabling On-Policy FP8 Reinforcement Learning with Unified Training and Rollout Precision Flow(https://arxiv.org/abs/2601.14243)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) is essential for enhancing the complex reasoning capabilities of large language models (LLMs). However, existing RL training pipelines are computationally inefficient and resource-intensive, with the rollout phase accounting for over 70% of total training time. Quantized RL training, particularly using FP8 precision, offers a promising approach to mitigating this bottleneck. A commonly adopted strategy applies FP8 precision during rollout while retaining BF16 precision for training. In this work, we present the first comprehensive study of FP8 RL training and demonstrate that the widely used BF16-training + FP8-rollout strategy suffers from severe training instability and catastrophic accuracy collapse under long-horizon rollouts and challenging tasks. Our analysis shows that these failures stem from the off-policy nature of the approach, which introduces substantial numerical mismatch between training and inference. Motivated by these observations, we propose Jet-RL, an FP8 RL training framework that enables robust and stable RL optimization. The key idea is to adopt a unified FP8 precision flow for both training and rollout, thereby minimizing numerical discrepancies and eliminating the need for inefficient inter-step calibration. Extensive experiments validate the effectiveness of Jet-RL: our method achieves up to 33% speedup in the rollout phase, up to 41% speedup in the training phase, and a 16% end-to-end speedup over BF16 training, while maintaining stable convergence across all settings and incurring negligible accuracy degradation.</li>
</ul>

<h3>Title: Soft Tail-dropping for Adaptive Visual Tokenization</h3>
<ul>
<li><strong>Authors: </strong>Zeyuan Chen, Kai Zhang, Zhuowen Tu, Yuanjun Xiong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14246">https://arxiv.org/abs/2601.14246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14246">https://arxiv.org/pdf/2601.14246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14246]] Soft Tail-dropping for Adaptive Visual Tokenization(https://arxiv.org/abs/2601.14246)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.</li>
</ul>

<h3>Title: LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR</h3>
<ul>
<li><strong>Authors: </strong>Said Taghadouini, Adrien Cavaillès, Baptiste Aubertin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14251">https://arxiv.org/abs/2601.14251</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14251">https://arxiv.org/pdf/2601.14251</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14251]] LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR(https://arxiv.org/abs/2601.14251)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.</li>
</ul>

<h3>Title: Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Hongyuan Chen, Xingyu Chen, Youjia Zhang, Zexiang Xu, Anpei Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14253">https://arxiv.org/abs/2601.14253</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14253">https://arxiv.org/pdf/2601.14253</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14253]] Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis(https://arxiv.org/abs/2601.14253)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at this https URL.</li>
</ul>

<h3>Title: VideoMaMa: Mask-Guided Video Matting via Generative Prior</h3>
<ul>
<li><strong>Authors: </strong>Sangbeom Lim, Seoung Wug Oh, Jiahui Huang, Heeji Yoon, Seungryong Kim, Joon-Young Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14255">https://arxiv.org/abs/2601.14255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14255">https://arxiv.org/pdf/2601.14255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14255]] VideoMaMa: Mask-Guided Video Matting via Generative Prior(https://arxiv.org/abs/2601.14255)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.</li>
</ul>

<h3>Title: Implicit Neural Representation Facilitates Unified Universal Vision Encoding</h3>
<ul>
<li><strong>Authors: </strong>Matthew Gwilliam, Xiao Wang, Xuefeng Hu, Zhenheng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.14256">https://arxiv.org/abs/2601.14256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.14256">https://arxiv.org/pdf/2601.14256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.14256]] Implicit Neural Representation Facilitates Unified Universal Vision Encoding(https://arxiv.org/abs/2601.14256)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
