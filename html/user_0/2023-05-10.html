<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Energy-Efficient Mining for Blockchain-Enabled IoT Applications. An Optimal Multiple-Stopping Time Approach. (arXiv:2305.05479v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05479">http://arxiv.org/abs/2305.05479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05479] Energy-Efficient Mining for Blockchain-Enabled IoT Applications](http://arxiv.org/abs/2305.05479) #secure</code></li>
<li>Summary: <p>What are the optimal times for an Internet of Things (IoT) device to act as a
blockchain miner? The aim is to minimize the energy consumed by low-power IoT
devices that log their data into a secure (tamper-proof) distributed ledger. We
formulate the energy-efficient blockchain mining for IoT devices as a
multiple-stopping time partially observed Markov decision process (POMDP) to
maximize the probability of adding a block in the blockchain; we also present a
model to optimize the number of stops (mining instants). In general, POMDPs are
computationally intractable to solve, but we show mathematically using
submodularity that the optimal mining policy has a useful structure: 1) it is
monotone in belief space, and 2) it exhibits a threshold structure, which
divides the belief space into two connected sets. Exploiting the structural
results, we formulate a computationally-efficient linear mining policy for the
blockchain-enabled IoT device. We present a policy gradient technique to
optimize the parameters of the linear mining policy. Finally, we use synthetic
and real Bitcoin datasets to study the performance of our proposed mining
policy. We demonstrate the energy efficiency achieved by the optimal linear
mining policy in contrast to other heuristic strategies.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Fooling State-of-the-Art Deepfake Detection with High-Quality Deepfakes. (arXiv:2305.05282v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05282">http://arxiv.org/abs/2305.05282</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05282] Fooling State-of-the-Art Deepfake Detection with High-Quality Deepfakes](http://arxiv.org/abs/2305.05282) #security</code></li>
<li>Summary: <p>Due to the rising threat of deepfakes to security and privacy, it is most
important to develop robust and reliable detectors. In this paper, we examine
the need for high-quality samples in the training datasets of such detectors.
Accordingly, we show that deepfake detectors proven to generalize well on
multiple research datasets still struggle in real-world scenarios with
well-crafted fakes. First, we propose a novel autoencoder for face swapping
alongside an advanced face blending technique, which we utilize to generate 90
high-quality deepfakes. Second, we feed those fakes to a state-of-the-art
detector, causing its performance to decrease drastically. Moreover, we
fine-tune the detector on our fakes and demonstrate that they contain useful
clues for the detection of manipulations. Overall, our results provide insights
into the generalization of deepfake detectors and suggest that their training
datasets should be complemented by high-quality fakes since training on mere
research data is insufficient.
</p></li>
</ul>

<h3>Title: Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model. (arXiv:2305.05499v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05499">http://arxiv.org/abs/2305.05499</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05499] Effects of Real-Life Traffic Sign Alteration on YOLOv7- an Object Recognition Model](http://arxiv.org/abs/2305.05499) #security</code></li>
<li>Summary: <p>The advancement of Image Processing has led to the widespread use of Object
Recognition (OR) models in various applications, such as airport security and
mail sorting. These models have become essential in signifying the capabilities
of AI and supporting vital services like national postal operations. However,
the performance of OR models can be impeded by real-life scenarios, such as
traffic sign alteration. Therefore, this research investigates the effects of
altered traffic signs on the accuracy and performance of object recognition
models. To this end, a publicly available dataset was used to create different
types of traffic sign alterations, including changes to size, shape, color,
visibility, and angles. The impact of these alterations on the YOLOv7 (You Only
Look Once) model's detection and classification abilities were analyzed. It
reveals that the accuracy of object detection models decreases significantly
when exposed to modified traffic signs under unlikely conditions. This study
highlights the significance of enhancing the robustness of object detection
models in real-life scenarios and the need for further investigation in this
area to improve their accuracy and reliability.
</p></li>
</ul>

<h3>Title: A Survey on the Geographic Diversity of Usable Privacy and Security Research. (arXiv:2305.05004v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05004">http://arxiv.org/abs/2305.05004</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05004] A Survey on the Geographic Diversity of Usable Privacy and Security Research](http://arxiv.org/abs/2305.05004) #security</code></li>
<li>Summary: <p>In human factor fields such as human-computer interaction (HCI), psychology,
and behavioral sciences, researchers have been concerned that participant
samples are skewed toward WEIRD, i.e., participants mostly come from Western,
Educated, Industrialized, Rich, and Democratic societies. This WEIRD skew may
affect the generalizability of study results and hinder understanding of
diverse participant populations and their cultural differences. The usable
privacy and security (UPS) field has inherited many research methodologies from
research on human factor fields such as HCI. We conducted a literature review
to understand the extent to which participant samples in UPS papers were WEIRD
and the characteristics of the methodologies and research topics in each user
study recruiting Western or non-Western participants. We found that the skew
toward WEIRD in UPS is greater than that in HCI. Geographic and linguistic
barriers in the study methods and recruitment methods may cause researchers to
conduct a user study locally. In addition, many papers did not report
participant demographics, which could hinder the replication of the reported
studies, leading to low reproducibility. We provide the following suggestions
to improve geographic diversity: facilitate replication studies, improve
reproducibility, address issues of study and recruiting methods, diversify
researchers, and facilitate research on the topics for non-WEIRD populations.
</p></li>
</ul>

<h3>Title: Socio-Technical Security Modelling: Analysis of State-of-the-Art, Application, and Maturity in Critical Industrial Infrastructure Environments/Domains. (arXiv:2305.05108v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05108">http://arxiv.org/abs/2305.05108</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05108] Socio-Technical Security Modelling: Analysis of State-of-the-Art, Application, and Maturity in Critical Industrial Infrastructure Environments/Domains](http://arxiv.org/abs/2305.05108) #security</code></li>
<li>Summary: <p>This study explores the state-of-the-art, application, and maturity of
socio-technical security models for industries and sectors dependent on CI and
investigates the gap between academic research and industry practices
concerning the modelling of both the social and technical aspects of security.
Systematic study and critical analysis of literature show that a steady and
growing on socio-technical security M&amp;S approaches is emerging, possibly
prompted by the growing recognition that digital systems and workplaces do not
only comprise technologies, but also social (human) and sometimes physical
elements.
</p></li>
</ul>

<h3>Title: PSP Framework: A novel risk assessment method in compliance with ISO/SAE-21434. (arXiv:2305.05309v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05309">http://arxiv.org/abs/2305.05309</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05309] PSP Framework: A novel risk assessment method in compliance with ISO/SAE-21434](http://arxiv.org/abs/2305.05309) #security</code></li>
<li>Summary: <p>As more cars connect to the internet and other devices, the automotive market
has become a lucrative target for cyberattacks. This has made the industry more
vulnerable to security threats. As a result, car manufacturers and governments
are working together to reduce risks and prevent cyberattacks in the automotive
sector. However, existing attack feasibility models derived from the
information technology field may not always provide accurate assessments of the
potential risks faced by Vehicle Electronic Control Units in different
operating conditions and domains. This paper introduces the PUNCH Softronix and
Politecnico di Torino (PSP) framework to address this issue. This framework is
designed to provide accurate assessments compatible with the attack feasibility
models defined by the automotive product security standards. The PSP framework
utilizes social sentiment analysis to evaluate the real threat risk levels.
</p></li>
</ul>

<h3>Title: Data Protection and Security Issues With Network Error Logging. (arXiv:2305.05343v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05343">http://arxiv.org/abs/2305.05343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05343] Data Protection and Security Issues With Network Error Logging](http://arxiv.org/abs/2305.05343) #security</code></li>
<li>Summary: <p>Network Error Logging helps web server operators detect operational problems
in real-time to provide fast and reliable services. This paper analyses Network
Error Logging from two angles. Firstly, this paper overviews Network Error
Logging from the data protection view. The ePrivacy Directive requires consent
for non-essential access to the end devices. Nevertheless, the Network Error
Logging design does not allow limiting the tracking to consenting users. Other
issues lay in GDPR requirements for transparency and the obligations in the
contract between controllers and processors of personal data. Secondly, this
paper explains Network Error Logging exploitations to deploy long-time trackers
to the victim devices. Even though users should be able to disable Network
Error Logging, it is not clear how to do so. Web server operators can mitigate
the attack by configuring servers to preventively remove policies that
adversaries might have added.
</p></li>
</ul>

<h3>Title: Balancing Privacy and Security in Federated Learning with FedGT: A Group Testing Framework. (arXiv:2305.05506v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05506">http://arxiv.org/abs/2305.05506</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05506] Balancing Privacy and Security in Federated Learning with FedGT: A Group Testing Framework](http://arxiv.org/abs/2305.05506) #security</code></li>
<li>Summary: <p>We propose FedGT, a novel framework for identifying malicious clients in
federated learning with secure aggregation. Inspired by group testing, the
framework leverages overlapping groups of clients to detect the presence of
malicious clients in the groups and to identify them via a decoding operation.
The identified clients are then removed from the training of the model, which
is performed over the remaining clients. FedGT strikes a balance between
privacy and security, allowing for improved identification capabilities while
still preserving data privacy. Specifically, the server learns the aggregated
model of the clients in each group. The effectiveness of FedGT is demonstrated
through extensive experiments on the MNIST and CIFAR-10 datasets, showing its
ability to identify malicious clients with low misdetection and false alarm
probabilities, resulting in high model utility.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Indoor Localization and Multi-person Tracking Using Privacy Preserving Distributed Camera Network with Edge Computing. (arXiv:2305.05062v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05062">http://arxiv.org/abs/2305.05062</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05062] Indoor Localization and Multi-person Tracking Using Privacy Preserving Distributed Camera Network with Edge Computing](http://arxiv.org/abs/2305.05062) #privacy</code></li>
<li>Summary: <p>Localization of individuals in a built environment is a growing research
topic. Estimating the positions, face orientation (or gaze direction) and
trajectories of people through space has many uses, such as in crowd
management, security, and healthcare. In this work, we present an open-source,
low-cost, scalable and privacy-preserving edge computing framework for
multi-person localization, i.e. estimating the positions, orientations, and
trajectories of multiple people in an indoor space. Our computing framework
consists of 38 Tensor Processing Unit (TPU)-enabled edge computing camera
systems placed in the ceiling of the indoor therapeutic space. The edge compute
systems are connected to an on-premise fog server through a secure and private
network. A multi-person detection algorithm and a pose estimation model run on
the edge TPU in real-time to collect features which are used, instead of raw
images, for downstream computations. This ensures the privacy of individuals in
the space, reduces data transmission/storage and improves scalability. We
implemented a Kalman filter-based multi-person tracking method and a
state-of-the-art body orientation estimation method to determine the positions
and facing orientations of multiple people simultaneously in the indoor space.
For our study site with size of 18,000 square feet, our system demonstrated an
average localization error of 1.41 meters, a multiple-object tracking accuracy
score of 62%, and a mean absolute body orientation error of 29{\deg}, which is
sufficient for understanding group activity behaviors in indoor environments.
Additionally, our study provides practical guidance for deploying the proposed
system by analyzing various elements of the camera installation with respect to
tracking accuracy.
</p></li>
</ul>

<h3>Title: Privacy-preserving Adversarial Facial Features. (arXiv:2305.05391v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05391">http://arxiv.org/abs/2305.05391</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05391] Privacy-preserving Adversarial Facial Features](http://arxiv.org/abs/2305.05391) #privacy</code></li>
<li>Summary: <p>Face recognition service providers protect face privacy by extracting compact
and discriminative facial features (representations) from images, and storing
the facial features for real-time recognition. However, such features can still
be exploited to recover the appearance of the original face by building a
reconstruction network. Although several privacy-preserving methods have been
proposed, the enhancement of face privacy protection is at the expense of
accuracy degradation. In this paper, we propose an adversarial features-based
face privacy protection (AdvFace) approach to generate privacy-preserving
adversarial features, which can disrupt the mapping from adversarial features
to facial images to defend against reconstruction attacks. To this end, we
design a shadow model which simulates the attackers' behavior to capture the
mapping function from facial features to images and generate adversarial latent
noise to disrupt the mapping. The adversarial features rather than the original
features are stored in the server's database to prevent leaked features from
exposing facial information. Moreover, the AdvFace requires no changes to the
face recognition network and can be implemented as a privacy-enhancing plugin
in deployed face recognition systems. Extensive experimental results
demonstrate that AdvFace outperforms the state-of-the-art face
privacy-preserving methods in defending against reconstruction attacks while
maintaining face recognition accuracy.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Collaborative Chinese Text Recognition with Federated Learning. (arXiv:2305.05602v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05602">http://arxiv.org/abs/2305.05602</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05602] Privacy-Preserving Collaborative Chinese Text Recognition with Federated Learning](http://arxiv.org/abs/2305.05602) #privacy</code></li>
<li>Summary: <p>In Chinese text recognition, to compensate for the insufficient local data
and improve the performance of local few-shot character recognition, it is
often necessary for one organization to collect a large amount of data from
similar organizations. However, due to the natural presence of private
information in text data, different organizations are unwilling to share
private data, such as addresses and phone numbers. Therefore, it becomes
increasingly important to design a privacy-preserving collaborative training
framework for the Chinese text recognition task. In this paper, we introduce
personalized federated learning (pFL) into the Chinese text recognition task
and propose the pFedCR algorithm, which significantly improves the model
performance of each client (organization) without sharing private data.
Specifically, based on CRNN, to handle the non-iid problem of client data, we
add several attention layers to the model and design a two-stage training
approach for the client. In addition, we fine-tune the output layer of the
model using a virtual dataset on the server, mitigating the problem of
character imbalance in Chinese documents. The proposed approach is validated on
public benchmarks and two self-built real-world industrial scenario datasets.
The experimental results show that the pFedCR algorithm can improve the
performance of local personalized models while also improving their
generalization performance on other client data domains. Compared to local
training within an organization, pFedCR improves model performance by about
20%. Compared to other state-of-the-art personalized federated learning
methods, pFedCR improves performance by 6%~8%. Moreover, through federated
learning, pFedCR can correct erroneous information in the ground truth.
</p></li>
</ul>

<h3>Title: Leveraging Generative AI Models for Synthetic Data Generation in Healthcare: Balancing Research and Privacy. (arXiv:2305.05247v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05247">http://arxiv.org/abs/2305.05247</a></li>
<li>Code URL: <a href="https://github.com/aryan-jadon/synthetic-data-medical-generative-ai">https://github.com/aryan-jadon/synthetic-data-medical-generative-ai</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05247] Leveraging Generative AI Models for Synthetic Data Generation in Healthcare: Balancing Research and Privacy](http://arxiv.org/abs/2305.05247) #privacy</code></li>
<li>Summary: <p>The widespread adoption of electronic health records and digital healthcare
data has created a demand for data-driven insights to enhance patient outcomes,
diagnostics, and treatments. However, using real patient data presents privacy
and regulatory challenges, including compliance with HIPAA and GDPR. Synthetic
data generation, using generative AI models like GANs and VAEs offers a
promising solution to balance valuable data access and patient privacy
protection. In this paper, we examine generative AI models for creating
realistic, anonymized patient data for research and training, explore synthetic
data applications in healthcare, and discuss its benefits, challenges, and
future research directions. Synthetic data has the potential to revolutionize
healthcare by providing anonymized patient data while preserving privacy and
enabling versatile applications.
</p></li>
</ul>

<h3>Title: Turning Privacy-preserving Mechanisms against Federated Learning. (arXiv:2305.05355v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05355">http://arxiv.org/abs/2305.05355</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05355] Turning Privacy-preserving Mechanisms against Federated Learning](http://arxiv.org/abs/2305.05355) #privacy</code></li>
<li>Summary: <p>Recently, researchers have successfully employed Graph Neural Networks (GNNs)
to build enhanced recommender systems due to their capability to learn patterns
from the interaction between involved entities. In addition, previous studies
have investigated federated learning as the main solution to enable a native
privacy-preserving mechanism for the construction of global GNN models without
collecting sensitive data into a single computation unit. Still, privacy issues
may arise as the analysis of local model updates produced by the federated
clients can return information related to sensitive local data. For this
reason, experts proposed solutions that combine federated learning with
Differential Privacy strategies and community-driven approaches, which involve
combining data from neighbor clients to make the individual local updates less
dependent on local sensitive data. In this paper, we identify a crucial
security flaw in such a configuration, and we design an attack capable of
deceiving state-of-the-art defenses for federated learning. The proposed attack
includes two operating modes, the first one focusing on convergence inhibition
(Adversarial Mode), and the second one aiming at building a deceptive rating
injection on the global federated model (Backdoor Mode). The experimental
results show the effectiveness of our attack in both its modes, returning on
average 60% performance detriment in all the tests on Adversarial Mode and
fully effective backdoors in 93% of cases for the tests performed on Backdoor
Mode.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Probabilistic Detection of GNSS Spoofing using Opportunistic Information. (arXiv:2305.05404v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05404">http://arxiv.org/abs/2305.05404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05404] Probabilistic Detection of GNSS Spoofing using Opportunistic Information](http://arxiv.org/abs/2305.05404) #protect</code></li>
<li>Summary: <p>Global Navigation Satellite Systems (GNSS) are integrated into many devices.
However, civilian GNSS signals are usually not cryptographically protected.
This makes attacks that forge signals relatively easy. Considering modern
devices often have network connections and onboard sensors, the proposed here
Probabilistic Detection of GNSS Spoofing (PDS) scheme is based on such
opportunistic information. PDS has at its core two parts. First, a regression
problem with motion model constraints, which equalizes the noise of all
locations considering the motion model of the device. Second, a Gaussian
process, that analyzes statistical properties of location data to construct
uncertainty. Then, a likelihood function, that fuses the two parts, as a basis
for a Neyman-Pearson lemma (NPL)-based detection strategy. Our experimental
evaluation shows a performance gain over the state-of-the-art, in terms of
attack detection effectiveness.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Generating Phishing Attacks using ChatGPT. (arXiv:2305.05133v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05133">http://arxiv.org/abs/2305.05133</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05133] Generating Phishing Attacks using ChatGPT](http://arxiv.org/abs/2305.05133) #attack</code></li>
<li>Summary: <p>The ability of ChatGPT to generate human-like responses and understand
context has made it a popular tool for conversational agents, content creation,
data analysis, and research and innovation. However, its effectiveness and ease
of accessibility makes it a prime target for generating malicious content, such
as phishing attacks, that can put users at risk. In this work, we identify
several malicious prompts that can be provided to ChatGPT to generate
functional phishing websites. Through an iterative approach, we find that these
phishing websites can be made to imitate popular brands and emulate several
evasive tactics that have been known to avoid detection by anti-phishing
entities. These attacks can be generated using vanilla ChatGPT without the need
of any prior adversarial exploits (jailbreaking).
</p></li>
</ul>

<h3>Title: Attack Named Entity Recognition by Entity Boundary Interference. (arXiv:2305.05253v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05253">http://arxiv.org/abs/2305.05253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05253] Attack Named Entity Recognition by Entity Boundary Interference](http://arxiv.org/abs/2305.05253) #attack</code></li>
<li>Summary: <p>Named Entity Recognition (NER) is a cornerstone NLP task while its robustness
has been given little attention. This paper rethinks the principles of NER
attacks derived from sentence classification, as they can easily violate the
label consistency between the original and adversarial NER examples. This is
due to the fine-grained nature of NER, as even minor word changes in the
sentence can result in the emergence or mutation of any entities, resulting in
invalid adversarial examples. To this end, we propose a novel one-word
modification NER attack based on a key insight, NER models are always
vulnerable to the boundary position of an entity to make their decision. We
thus strategically insert a new boundary into the sentence and trigger the
Entity Boundary Interference that the victim model makes the wrong prediction
either on this boundary word or on other words in the sentence. We call this
attack Virtual Boundary Attack (ViBA), which is shown to be remarkably
effective when attacking both English and Chinese models with a 70%-90% attack
success rate on state-of-the-art language models (e.g. RoBERTa, DeBERTa) and
also significantly faster than previous methods.
</p></li>
</ul>

<h3>Title: Distributed Detection over Blockchain-aided Internet of Things in the Presence of Attacks. (arXiv:2305.05070v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05070">http://arxiv.org/abs/2305.05070</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05070] Distributed Detection over Blockchain-aided Internet of Things in the Presence of Attacks](http://arxiv.org/abs/2305.05070) #attack</code></li>
<li>Summary: <p>Distributed detection over a blockchain-aided Internet of Things (BIoT)
network in the presence of attacks is considered, where the integrated
blockchain is employed to secure data exchanges over the BIoT as well as data
storage at the agents of the BIoT. We consider a general adversary model where
attackers jointly exploit the vulnerability of IoT devices and that of the
blockchain employed in the BIoT. The optimal attacking strategy which minimizes
the Kullback-Leibler divergence is pursued. It can be shown that this
optimization problem is nonconvex, and hence it is generally intractable to
find the globally optimal solution to such a problem. To overcome this issue,
we first propose a relaxation method that can convert the original nonconvex
optimization problem into a convex optimization problem, and then the analytic
expression for the optimal solution to the relaxed convex optimization problem
is derived. The optimal value of the relaxed convex optimization problem
provides a detection performance guarantee for the BIoT in the presence of
attacks. In addition, we develop a coordinate descent algorithm which is based
on a capped water-filling method to solve the relaxed convex optimization
problem, and moreover, we show that the convergence of the proposed coordinate
descent algorithm can be guaranteed.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Crack Detection of Asphalt Concrete Using Combined Fracture Mechanics and Digital Image Correlation. (arXiv:2305.05057v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05057">http://arxiv.org/abs/2305.05057</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05057] Crack Detection of Asphalt Concrete Using Combined Fracture Mechanics and Digital Image Correlation](http://arxiv.org/abs/2305.05057) #robust</code></li>
<li>Summary: <p>Cracking is a common failure mode in asphalt concrete (AC) pavements. Many
tests have been developed to characterize the fracture behavior of AC. Accurate
crack detection during testing is crucial to describe AC fracture behavior.
This paper proposed a framework to detect surface cracks in AC specimens using
two-dimensional digital image correlation (DIC). Two significant drawbacks in
previous research in this field were addressed. First, a multi-seed incremental
reliability-guided DIC was proposed to solve the decorrelation issue due to
large deformation and discontinuities. The method was validated using synthetic
deformed images. A correctly implemented analysis could accurately measure
strains up to 450\%, even with significant discontinuities (cracks) present in
the deformed image. Second, a robust method was developed to detect cracks
based on displacement fields. The proposed method uses critical crack tip
opening displacement ($\delta_c$) to define the onset of cleavage fracture. The
proposed method relies on well-developed fracture mechanics theory. The
proposed threshold $\delta_c$ has a physical meaning and can be easily
determined from DIC measurement. The method was validated using an extended
finite element model. The framework was implemented to measure the crack
propagation rate while conducting the Illinois-flexibility index test on two AC
mixes. The calculated rates could distinguish mixes based on their cracking
potential. The proposed framework could be applied to characterize AC cracking
phenomenon, evaluate its fracture properties, assess asphalt mixture testing
protocols, and develop theoretical models.
</p></li>
</ul>

<h3>Title: Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness. (arXiv:2305.05095v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05095">http://arxiv.org/abs/2305.05095</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05095] Less is More: Removing Text-regions Improves CLIP Training Efficiency and Robustness](http://arxiv.org/abs/2305.05095) #robust</code></li>
<li>Summary: <p>The CLIP (Contrastive Language-Image Pre-training) model and its variants are
becoming the de facto backbone in many applications. However, training a CLIP
model from hundreds of millions of image-text pairs can be prohibitively
expensive. Furthermore, the conventional CLIP model doesn't differentiate
between the visual semantics and meaning of text regions embedded in images.
This can lead to non-robustness when the text in the embedded region doesn't
match the image's visual appearance. In this paper, we discuss two effective
approaches to improve the efficiency and robustness of CLIP training: (1)
augmenting the training dataset while maintaining the same number of
optimization steps, and (2) filtering out samples that contain text regions in
the image. By doing so, we significantly improve the classification and
retrieval accuracy on public benchmarks like ImageNet and CoCo. Filtering out
images with text regions also protects the model from typographic attacks. To
verify this, we build a new dataset named ImageNet with Adversarial Text
Regions (ImageNet-Attr). Our filter-based CLIP model demonstrates a top-1
accuracy of 68.78\%, outperforming previous models whose accuracy was all below
50\%.
</p></li>
</ul>

<h3>Title: FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration. (arXiv:2305.05222v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05222">http://arxiv.org/abs/2305.05222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05222] FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration](http://arxiv.org/abs/2305.05222) #robust</code></li>
<li>Summary: <p>We propose an end-to-end deep learning approach to rectify fisheye images and
simultaneously calibrate camera intrinsic and distortion parameters. Our method
consists of two parts: a Quick Image Rectification Module developed with a
Pix2Pix GAN and Wasserstein GAN (W-Pix2PixGAN), and a Calibration Module with a
CNN architecture. Our Quick Rectification Network performs robust rectification
with good resolution, making it suitable for constant calibration in
camera-based surveillance equipment. To achieve high-quality calibration, we
use the straightened output from the Quick Rectification Module as a
guidance-like semantic feature map for the Calibration Module to learn the
geometric relationship between the straightened feature and the distorted
feature. We train and validate our method with a large synthesized dataset
labeled with well-simulated parameters applied to a perspective image dataset.
Our solution has achieved robust performance in high-resolution with a
significant PSNR value of 22.343.
</p></li>
</ul>

<h3>Title: Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05400">http://arxiv.org/abs/2305.05400</a></li>
<li>Code URL: <a href="https://github.com/georgsiedel/lp-norm-corruption-robustness">https://github.com/georgsiedel/lp-norm-corruption-robustness</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05400] Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions](http://arxiv.org/abs/2305.05400) #robust</code></li>
<li>Summary: <p>Robustness is a fundamental property of machine learning classifiers to
achieve safety and reliability. In the fields of adversarial robustness and
formal robustness verification of image classification models, robustness is
commonly defined as the stability to all input variations within an Lp-norm
distance. However, robustness to random corruptions is usually improved and
evaluated using variations observed in the real-world, while mathematically
defined Lp-norm corruptions are rarely considered. This study investigates the
use of random Lp-norm corruptions to augment the training and test data of
image classifiers. We adapt an approach from the field of adversarial
robustness to assess the model robustness to imperceptible random corruptions.
We empirically and theoretically investigate whether robustness is transferable
across different Lp-norms and derive conclusions on which Lp-norm corruptions a
model should be trained and evaluated on. We find that training data
augmentation with L0-norm corruptions improves corruption robustness while
maintaining accuracy compared to standard training and when applied on top of
selected state-of-the-art data augmentation techniques.
</p></li>
</ul>

<h3>Title: Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust. (arXiv:2305.04989v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.04989">http://arxiv.org/abs/2305.04989</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.04989] Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust](http://arxiv.org/abs/2305.04989) #robust</code></li>
<li>Summary: <p>A fundamental question in natural language processing is - what kind of
language structure and semantics is the language model capturing? Graph formats
such as knowledge graphs are easy to evaluate as they explicitly express
language semantics and structure. This study evaluates the semantics encoded in
the self-attention transformers by leveraging explicit knowledge graph
structures. We propose novel metrics to measure the reconstruction error when
providing graph path sequences from a knowledge graph and trying to
reproduce/reconstruct the same from the outputs of the self-attention
transformer models. The opacity of language models has an immense bearing on
societal issues of trust and explainable decision outcomes. Our findings
suggest that language models are models of stochastic control processes for
plausible language pattern generation. However, they do not ascribe object and
concept-level meaning and semantics to the learned stochastic patterns such as
those described in knowledge graphs. Furthermore, to enable robust evaluation
of concept understanding by language models, we construct and make public an
augmented language understanding benchmark built on the General Language
Understanding Evaluation (GLUE) benchmark. This has significant
application-level user trust implications as stochastic patterns without a
strong sense of meaning cannot be trusted in high-stakes applications.
</p></li>
</ul>

<h3>Title: Explanation-based Finetuning Makes Models More Robust to Spurious Cues. (arXiv:2305.04990v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.04990">http://arxiv.org/abs/2305.04990</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.04990] Explanation-based Finetuning Makes Models More Robust to Spurious Cues](http://arxiv.org/abs/2305.04990) #robust</code></li>
<li>Summary: <p>Large Language Models (LLMs) are so powerful that they sometimes learn
correlations between labels and features that are irrelevant to the task,
leading to poor generalization on out-of-distribution data. We propose
explanation-based finetuning as a novel and general approach to mitigate LLMs'
reliance on spurious correlations. Unlike standard finetuning where the model
only predicts the answer given the input, we finetune the model to additionally
generate a free-text explanation supporting its answer. To evaluate our method,
we finetune the model on artificially constructed training sets containing
different types of spurious cues, and test it on a test set without these cues.
Compared to standard finetuning, our method makes models remarkably more robust
against spurious cues in terms of accuracy drop across four classification
tasks: ComVE (+1.2), CREAK (+9.1), e-SNLI (+15.4), and SBIC (+6.5). Moreover,
our method works equally well with explanations generated by the model,
implying its applicability to more datasets without human-written explanations.
</p></li>
</ul>

<h3>Title: A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution. (arXiv:2305.05079v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05079">http://arxiv.org/abs/2305.05079</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05079] A Unified Evaluation Framework for Novelty Detection and Accommodation in NLP with an Instantiation in Authorship Attribution](http://arxiv.org/abs/2305.05079) #robust</code></li>
<li>Summary: <p>State-of-the-art natural language processing models have been shown to
achieve remarkable performance in 'closed-world' settings where all the labels
in the evaluation set are known at training time. However, in real-world
settings, 'novel' instances that do not belong to any known class are often
observed. This renders the ability to deal with novelties crucial. To initiate
a systematic research in this important area of 'dealing with novelties', we
introduce 'NoveltyTask', a multi-stage task to evaluate a system's performance
on pipelined novelty 'detection' and 'accommodation' tasks. We provide
mathematical formulation of NoveltyTask and instantiate it with the authorship
attribution task that pertains to identifying the correct author of a given
text. We use Amazon reviews corpus and compile a large dataset (consisting of
250k instances across 200 authors/labels) for NoveltyTask. We conduct
comprehensive experiments and explore several baseline methods for the task.
Our results show that the methods achieve considerably low performance making
the task challenging and leaving sufficient room for improvement. Finally, we
believe our work will encourage research in this underexplored area of dealing
with novelties, an important step en route to developing robust systems.
</p></li>
</ul>

<h3>Title: Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages. (arXiv:2305.05214v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05214">http://arxiv.org/abs/2305.05214</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05214] Utilizing Lexical Similarity to Enable Zero-Shot Machine Translation for Extremely Low-resource Languages](http://arxiv.org/abs/2305.05214) #robust</code></li>
<li>Summary: <p>We address the task of machine translation from an extremely low-resource
language (LRL) to English using cross-lingual transfer from a closely related
high-resource language (HRL). For many of these languages, no parallel corpora
are available, even monolingual corpora are limited and representations in
pre-trained sequence-to-sequence models are absent. These factors limit the
benefits of cross-lingual transfer from shared embedding spaces in multilingual
models. However, many extremely LRLs have a high level of lexical similarity
with related HRLs. We utilize this property by injecting character and
character-span noise into the training data of the HRL prior to learning the
vocabulary. This serves as a regularizer which makes the model more robust to
lexical divergences between the HRL and LRL and better facilitates
cross-lingual transfer. On closely related HRL and LRL pairs from multiple
language families, we observe that our method significantly outperforms the
baseline MT as well as approaches proposed previously to address cross-lingual
transfer between closely related languages. We also show that the proposed
character-span noise injection performs better than the unigram-character noise
injection.
</p></li>
</ul>

<h3>Title: Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition. (arXiv:2305.05271v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05271">http://arxiv.org/abs/2305.05271</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05271] Robust Acoustic and Semantic Contextual Biasing in Neural Transducers for Speech Recognition](http://arxiv.org/abs/2305.05271) #robust</code></li>
<li>Summary: <p>Attention-based contextual biasing approaches have shown significant
improvements in the recognition of generic and/or personal rare-words in
End-to-End Automatic Speech Recognition (E2E ASR) systems like neural
transducers. These approaches employ cross-attention to bias the model towards
specific contextual entities injected as bias-phrases to the model. Prior
approaches typically relied on subword encoders for encoding the bias phrases.
However, subword tokenizations are coarse and fail to capture granular
pronunciation information which is crucial for biasing based on acoustic
similarity. In this work, we propose to use lightweight character
representations to encode fine-grained pronunciation features to improve
contextual biasing guided by acoustic similarity between the audio and the
contextual entities (termed acoustic biasing). We further integrate pretrained
neural language model (NLM) based encoders to encode the utterance's semantic
context along with contextual entities to perform biasing informed by the
utterance's semantic context (termed semantic biasing). Experiments using a
Conformer Transducer model on the Librispeech dataset show a 4.62% - 9.26%
relative WER improvement on different biasing list sizes over the baseline
contextual model when incorporating our proposed acoustic and semantic biasing
approach. On a large-scale in-house dataset, we observe 7.91% relative WER
improvement compared to our baseline model. On tail utterances, the
improvements are even more pronounced with 36.80% and 23.40% relative WER
improvements on Librispeech rare words and an in-house testset respectively.
</p></li>
</ul>

<h3>Title: VCSUM: A Versatile Chinese Meeting Summarization Dataset. (arXiv:2305.05280v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05280">http://arxiv.org/abs/2305.05280</a></li>
<li>Code URL: <a href="https://github.com/hahahawu/vcsum">https://github.com/hahahawu/vcsum</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05280] VCSUM: A Versatile Chinese Meeting Summarization Dataset](http://arxiv.org/abs/2305.05280) #robust</code></li>
<li>Summary: <p>Compared to news and chat summarization, the development of meeting
summarization is hugely decelerated by the limited data. To this end, we
introduce a versatile Chinese meeting summarization dataset, dubbed VCSum,
consisting of 239 real-life meetings, with a total duration of over 230 hours.
We claim our dataset is versatile because we provide the annotations of topic
segmentation, headlines, segmentation summaries, overall meeting summaries, and
salient sentences for each meeting transcript. As such, the dataset can adapt
to various summarization tasks or methods, including segmentation-based
summarization, multi-granularity summarization and retrieval-then-generate
summarization. Our analysis confirms the effectiveness and robustness of VCSum.
We also provide a set of benchmark models regarding different downstream
summarization tasks on VCSum to facilitate further research. The dataset and
code will be released at \url{https://github.com/hahahawu/VCSum}.
</p></li>
</ul>

<h3>Title: Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data. (arXiv:2305.05295v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05295">http://arxiv.org/abs/2305.05295</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05295] Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially Code-Switched Data](http://arxiv.org/abs/2305.05295) #robust</code></li>
<li>Summary: <p>Transferring information retrieval (IR) models from a high-resource language
(typically English) to other languages in a zero-shot fashion has become a
widely adopted approach. In this work, we show that the effectiveness of
zero-shot rankers diminishes when queries and documents are present in
different languages. Motivated by this, we propose to train ranking models on
artificially code-switched data instead, which we generate by utilizing
bilingual lexicons. To this end, we experiment with lexicons induced from (1)
cross-lingual word embeddings and (2) parallel Wikipedia page titles. We use
the mMARCO dataset to extensively evaluate reranking models on 36 language
pairs spanning Monolingual IR (MoIR), Cross-lingual IR (CLIR), and Multilingual
IR (MLIR). Our results show that code-switching can yield consistent and
substantial gains of 5.1 MRR@10 in CLIR and 3.9 MRR@10 in MLIR, while
maintaining stable performance in MoIR. Encouragingly, the gains are especially
pronounced for distant languages (up to 2x absolute gain). We further show that
our approach is robust towards the ratio of code-switched tokens and also
extends to unseen languages. Our results demonstrate that training on
code-switched data is a cheap and effective way of generalizing zero-shot
rankers for cross-lingual and multilingual retrieval.
</p></li>
</ul>

<h3>Title: Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation. (arXiv:2305.05116v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05116">http://arxiv.org/abs/2305.05116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05116] Communication-Robust Multi-Agent Learning by Adaptable Auxiliary Multi-Agent Adversary Generation](http://arxiv.org/abs/2305.05116) #robust</code></li>
<li>Summary: <p>Communication can promote coordination in cooperative Multi-Agent
Reinforcement Learning (MARL). Nowadays, existing works mainly focus on
improving the communication efficiency of agents, neglecting that real-world
communication is much more challenging as there may exist noise or potential
attackers. Thus the robustness of the communication-based policies becomes an
emergent and severe issue that needs more exploration. In this paper, we posit
that the ego system trained with auxiliary adversaries may handle this
limitation and propose an adaptable method of Multi-Agent Auxiliary Adversaries
Generation for robust Communication, dubbed MA3C, to obtain a robust
communication-based policy. In specific, we introduce a novel message-attacking
approach that models the learning of the auxiliary attacker as a cooperative
problem under a shared goal to minimize the coordination ability of the ego
system, with which every information channel may suffer from distinct message
attacks. Furthermore, as naive adversarial training may impede the
generalization ability of the ego system, we design an attacker population
generation approach based on evolutionary learning. Finally, the ego system is
paired with an attacker population and then alternatively trained against the
continuously evolving attackers to improve its robustness, meaning that both
the ego system and the attackers are adaptable. Extensive experiments on
multiple benchmarks indicate that our proposed MA3C provides comparable or
better robustness and generalization ability than other baselines.
</p></li>
</ul>

<h3>Title: FedNoRo: Towards Noise-Robust Federated Learning by Addressing Class Imbalance and Label Noise Heterogeneity. (arXiv:2305.05230v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05230">http://arxiv.org/abs/2305.05230</a></li>
<li>Code URL: <a href="https://github.com/wnn2000/fednoro">https://github.com/wnn2000/fednoro</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05230] FedNoRo: Towards Noise-Robust Federated Learning by Addressing Class Imbalance and Label Noise Heterogeneity](http://arxiv.org/abs/2305.05230) #robust</code></li>
<li>Summary: <p>Federated noisy label learning (FNLL) is emerging as a promising tool for
privacy-preserving multi-source decentralized learning. Existing research,
relying on the assumption of class-balanced global data, might be incapable to
model complicated label noise, especially in medical scenarios. In this paper,
we first formulate a new and more realistic federated label noise problem where
global data is class-imbalanced and label noise is heterogeneous, and then
propose a two-stage framework named FedNoRo for noise-robust federated
learning. Specifically, in the first stage of FedNoRo, per-class loss
indicators followed by Gaussian Mixture Model are deployed for noisy client
identification. In the second stage, knowledge distillation and a
distance-aware aggregation function are jointly adopted for noise-robust
federated model updating. Experimental results on the widely-used ICH and
ISIC2019 datasets demonstrate the superiority of FedNoRo against the
state-of-the-art FNLL methods for addressing class imbalance and label noise
heterogeneity in real-world FL scenarios.
</p></li>
</ul>

<h3>Title: On the Relation between Sharpness-Aware Minimization and Adversarial Robustness. (arXiv:2305.05392v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05392">http://arxiv.org/abs/2305.05392</a></li>
<li>Code URL: <a href="https://github.com/weizeming/sam_at">https://github.com/weizeming/sam_at</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05392] On the Relation between Sharpness-Aware Minimization and Adversarial Robustness](http://arxiv.org/abs/2305.05392) #robust</code></li>
<li>Summary: <p>We propose a novel understanding of Sharpness-Aware Minimization (SAM) in the
context of adversarial robustness. In this paper, we point out that both SAM
and adversarial training (AT) can be viewed as specific feature perturbations,
which improve adversarial robustness. However, we note that SAM and AT are
distinct in terms of perturbation strength, leading to different accuracy and
robustness trade-offs. We provide theoretical evidence for these claims in a
simplified model with rigorous mathematical proofs. Furthermore, we conduct
experiment to demonstrate that only utilizing SAM can achieve superior
adversarial robustness compared to standard training, which is an unexpected
benefit. As adversarial training can suffer from a decrease in clean accuracy,
we show that using SAM alone can improve robustness without sacrificing clean
accuracy. Code is available at https://github.com/weizeming/SAM_AT.
</p></li>
</ul>

<h3>Title: Robust Implicit Regularization via Weight Normalization. (arXiv:2305.05448v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05448">http://arxiv.org/abs/2305.05448</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05448] Robust Implicit Regularization via Weight Normalization](http://arxiv.org/abs/2305.05448) #robust</code></li>
<li>Summary: <p>Overparameterized models may have many interpolating solutions; implicit
regularization refers to the hidden preference of a particular optimization
method towards a certain interpolating solution among the many. A by now
established line of work has shown that (stochastic) gradient descent tends to
have an implicit bias towards low rank and/or sparse solutions when used to
train deep linear networks, explaining to some extent why overparameterized
neural network models trained by gradient descent tend to have good
generalization performance in practice. However, existing theory for
square-loss objectives often requires very small initialization of the
trainable weights, which is at odds with the larger scale at which weights are
initialized in practice for faster convergence and better generalization
performance. In this paper, we aim to close this gap by incorporating and
analyzing gradient descent with weight normalization, where the weight vector
is reparamterized in terms of polar coordinates, and gradient descent is
applied to the polar coordinates. By analyzing key invariants of the gradient
flow and using Lojasiewicz's Theorem, we show that weight normalization also
has an implicit bias towards sparse solutions in the diagonal linear model, but
that in contrast to plain gradient descent, weight normalization enables a
robust bias that persists even if the weights are initialized at practically
large scale. Experiments suggest that the gains in both convergence speed and
robustness of the implicit bias are improved dramatically by using weight
normalization in overparameterized diagonal linear network models.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Child Palm-ID: Contactless Palmprint Recognition for Children. (arXiv:2305.05161v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05161">http://arxiv.org/abs/2305.05161</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05161] Child Palm-ID: Contactless Palmprint Recognition for Children](http://arxiv.org/abs/2305.05161) #biometric</code></li>
<li>Summary: <p>Effective distribution of nutritional and healthcare aid for children,
particularly infants and toddlers, in some of the least developed and most
impoverished countries of the world, is a major problem due to the lack of
reliable identification documents. Biometric authentication technology has been
investigated to address child recognition in the absence of reliable ID
documents. We present a mobile-based contactless palmprint recognition system,
called Child Palm-ID, which meets the requirements of usability, hygiene, cost,
and accuracy for child recognition. Using a contactless child palmprint
database, Child-PalmDB1, consisting of 19,158 images from 1,020 unique palms
(in the age range of 6 mos. to 48 mos.), we report a TAR=94.11% @ FAR=0.1%. The
proposed Child Palm-ID system is also able to recognize adults, achieving a
TAR=99.4% on the CASIA contactless palmprint database and a TAR=100% on the
COEP contactless adult palmprint database, both @ FAR=0.1%. These accuracies
are competitive with the SOTA provided by COTS systems. Despite these high
accuracies, we show that the TAR for time-separated child-palmprints is only
78.1% @ FAR=0.1%.
</p></li>
</ul>

<h2>steal</h2>
<h3>Title: On the Limitations of Model Stealing with Uncertainty Quantification Models. (arXiv:2305.05293v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05293">http://arxiv.org/abs/2305.05293</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05293] On the Limitations of Model Stealing with Uncertainty Quantification Models](http://arxiv.org/abs/2305.05293) #steal</code></li>
<li>Summary: <p>Model stealing aims at inferring a victim model's functionality at a fraction
of the original training cost. While the goal is clear, in practice the model's
architecture, weight dimension, and original training data can not be
determined exactly, leading to mutual uncertainty during stealing. In this
work, we explicitly tackle this uncertainty by generating multiple possible
networks and combining their predictions to improve the quality of the stolen
model. For this, we compare five popular uncertainty quantification models in a
model stealing task. Surprisingly, our results indicate that the considered
models only lead to marginal improvements in terms of label agreement (i.e.,
fidelity) to the stolen model. To find the cause of this, we inspect the
diversity of the model's prediction by looking at the prediction variance as a
function of training iterations. We realize that during training, the models
tend to have similar predictions, indicating that the network diversity we
wanted to leverage using uncertainty quantification models is not (high) enough
for improvements on the model stealing task.
</p></li>
</ul>

<h2>extraction</h2>
<h3>Title: LSAS: Lightweight Sub-attention Strategy for Alleviating Attention Bias Problem. (arXiv:2305.05200v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05200">http://arxiv.org/abs/2305.05200</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05200] LSAS: Lightweight Sub-attention Strategy for Alleviating Attention Bias Problem](http://arxiv.org/abs/2305.05200) #extraction</code></li>
<li>Summary: <p>In computer vision, the performance of deep neural networks (DNNs) is highly
related to the feature extraction ability, i.e., the ability to recognize and
focus on key pixel regions in an image. However, in this paper, we
quantitatively and statistically illustrate that DNNs have a serious attention
bias problem on many samples from some popular datasets: (1) Position bias:
DNNs fully focus on label-independent regions; (2) Range bias: The focused
regions from DNN are not completely contained in the ideal region. Moreover, we
find that the existing self-attention modules can alleviate these biases to a
certain extent, but the biases are still non-negligible. To further mitigate
them, we propose a lightweight sub-attention strategy (LSAS), which utilizes
high-order sub-attention modules to improve the original self-attention
modules. The effectiveness of LSAS is demonstrated by extensive experiments on
widely-used benchmark datasets and popular attention networks. We release our
code to help other researchers to reproduce the results of
LSAS~\footnote{https://github.com/Qrange-group/LSAS}.
</p></li>
</ul>

<h3>Title: Mediapipe and CNNs for Real-Time ASL Gesture Recognition. (arXiv:2305.05296v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05296">http://arxiv.org/abs/2305.05296</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05296] Mediapipe and CNNs for Real-Time ASL Gesture Recognition](http://arxiv.org/abs/2305.05296) #extraction</code></li>
<li>Summary: <p>This research paper describes a realtime system for identifying American Sign
Language (ASL) movements that employs modern computer vision and machine
learning approaches. The suggested method makes use of the Mediapipe library
for feature extraction and a Convolutional Neural Network (CNN) for ASL gesture
classification. The testing results show that the suggested system can detect
all ASL alphabets with an accuracy of 99.95%, indicating its potential for use
in communication devices for people with hearing impairments. The proposed
approach can also be applied to additional sign languages with similar hand
motions, potentially increasing the quality of life for people with hearing
loss. Overall, the study demonstrates the effectiveness of using Mediapipe and
CNN for real-time sign language recognition, making a significant contribution
to the field of computer vision and machine learning.
</p></li>
</ul>

<h3>Title: Revisiting Relation Extraction in the era of Large Language Models. (arXiv:2305.05003v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05003">http://arxiv.org/abs/2305.05003</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05003] Revisiting Relation Extraction in the era of Large Language Models](http://arxiv.org/abs/2305.05003) #extraction</code></li>
<li>Summary: <p>Relation extraction (RE) is the core NLP task of inferring semantic
relationships between entities from text. Standard supervised RE techniques
entail training modules to tag tokens comprising entity spans and then predict
the relationship between them. Recent work has instead treated the problem as a
\emph{sequence-to-sequence} task, linearizing relations between entities as
target strings to be generated conditioned on the input. Here we push the
limits of this approach, using larger language models (GPT-3 and Flan-T5 large)
than considered in prior work and evaluating their performance on standard RE
tasks under varying levels of supervision. We address issues inherent to
evaluating generative approaches to RE by doing human evaluations, in lieu of
relying on exact matching. Under this refined evaluation, we find that: (1)
Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly
equivalent to existing fully supervised models; (2) Flan-T5 is not as capable
in the few-shot setting, but supervising and fine-tuning it with
Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA
results. We release this model as a new baseline for RE tasks.
</p></li>
</ul>

<h3>Title: Flexible Job Shop Scheduling via Dual Attention Network Based Reinforcement Learning. (arXiv:2305.05119v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05119">http://arxiv.org/abs/2305.05119</a></li>
<li>Code URL: <a href="https://github.com/wrqccc/fjsp-drl">https://github.com/wrqccc/fjsp-drl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05119] Flexible Job Shop Scheduling via Dual Attention Network Based Reinforcement Learning](http://arxiv.org/abs/2305.05119) #extraction</code></li>
<li>Summary: <p>Flexible manufacturing has given rise to complex scheduling problems such as
the flexible job shop scheduling problem (FJSP). In FJSP, operations can be
processed on multiple machines, leading to intricate relationships between
operations and machines. Recent works have employed deep reinforcement learning
(DRL) to learn priority dispatching rules (PDRs) for solving FJSP. However, the
quality of solutions still has room for improvement relative to that by the
exact methods such as OR-Tools. To address this issue, this paper presents a
novel end-to-end learning framework that weds the merits of self-attention
models for deep feature extraction and DRL for scalable decision-making. The
complex relationships between operations and machines are represented precisely
and concisely, for which a dual-attention network (DAN) comprising several
interconnected operation message attention blocks and machine message attention
blocks is proposed. The DAN exploits the complicated relationships to construct
production-adaptive operation and machine features to support high-quality
decisionmaking. Experimental results using synthetic data as well as public
benchmarks corroborate that the proposed approach outperforms both traditional
PDRs and the state-of-the-art DRL method. Moreover, it achieves results
comparable to exact methods in certain cases and demonstrates favorable
generalization ability to large-scale and real-world unseen FJSP tasks.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Towards Building the Federated GPT: Federated Instruction Tuning. (arXiv:2305.05644v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05644">http://arxiv.org/abs/2305.05644</a></li>
<li>Code URL: <a href="https://github.com/jayzhang42/federatedgpt-shepherd">https://github.com/jayzhang42/federatedgpt-shepherd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05644] Towards Building the Federated GPT: Federated Instruction Tuning](http://arxiv.org/abs/2305.05644) #federate</code></li>
<li>Summary: <p>While ``instruction-tuned" generative large language models (LLMs) have
demonstrated an impressive ability to generalize to new tasks, the training
phases heavily rely on large amounts of diverse and high-quality instruction
data (such as ChatGPT and GPT-4). Unfortunately, acquiring high-quality data,
especially when it comes to human-written data, can pose significant challenges
both in terms of cost and accessibility. Moreover, concerns related to privacy
can further limit access to such data, making the process of obtaining it a
complex and nuanced undertaking. Consequently, this hinders the generality of
the tuned models and may restrict their effectiveness in certain contexts. To
tackle this issue, our study introduces a new approach called Federated
Instruction Tuning (FedIT), which leverages federated learning (FL) as the
learning framework for the instruction tuning of LLMs. This marks the first
exploration of FL-based instruction tuning for LLMs. This is especially
important since text data is predominantly generated by end users. Therefore,
it is imperative to design and adapt FL approaches to effectively leverage
these users' diverse instructions stored on local devices, while preserving
privacy and ensuring data security. In the current paper, by conducting widely
used GPT-4 auto-evaluation, we demonstrate that by exploiting the heterogeneous
and diverse sets of instructions on the client's end with the proposed
framework FedIT, we improved the performance of LLMs compared to centralized
training with only limited local instructions. Further, in this paper, we
developed a Github repository named Shepherd. This repository offers a
foundational framework for exploring federated fine-tuning of LLMs using
heterogeneous instructions across diverse categories.
</p></li>
</ul>

<h3>Title: FedHB: Hierarchical Bayesian Federated Learning. (arXiv:2305.04979v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.04979">http://arxiv.org/abs/2305.04979</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.04979] FedHB: Hierarchical Bayesian Federated Learning](http://arxiv.org/abs/2305.04979) #federate</code></li>
<li>Summary: <p>We propose a novel hierarchical Bayesian approach to Federated Learning (FL),
where our model reasonably describes the generative process of clients' local
data via hierarchical Bayesian modeling: constituting random variables of local
models for clients that are governed by a higher-level global variate.
Interestingly, the variational inference in our Bayesian model leads to an
optimisation problem whose block-coordinate descent solution becomes a
distributed algorithm that is separable over clients and allows them not to
reveal their own private data at all, thus fully compatible with FL. We also
highlight that our block-coordinate algorithm has particular forms that subsume
the well-known FL algorithms including Fed-Avg and Fed-Prox as special cases.
Beyond introducing novel modeling and derivations, we also offer convergence
analysis showing that our block-coordinate FL algorithm converges to an (local)
optimum of the objective at the rate of $O(1/\sqrt{t})$, the same rate as
regular (centralised) SGD, as well as the generalisation error analysis where
we prove that the test error of our model on unseen data is guaranteed to
vanish as we increase the training data size, thus asymptotically optimal.
</p></li>
</ul>

<h3>Title: Performative Federated Learning: A Solution to Model-Dependent and Heterogeneous Distribution Shifts. (arXiv:2305.05090v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05090">http://arxiv.org/abs/2305.05090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05090] Performative Federated Learning: A Solution to Model-Dependent and Heterogeneous Distribution Shifts](http://arxiv.org/abs/2305.05090) #federate</code></li>
<li>Summary: <p>We consider a federated learning (FL) system consisting of multiple clients
and a server, where the clients aim to collaboratively learn a common decision
model from their distributed data. Unlike the conventional FL framework that
assumes the client's data is static, we consider scenarios where the clients'
data distributions may be reshaped by the deployed decision model. In this
work, we leverage the idea of distribution shift mappings in performative
prediction to formalize this model-dependent data distribution shift and
propose a performative federated learning framework. We first introduce
necessary and sufficient conditions for the existence of a unique performative
stable solution and characterize its distance to the performative optimal
solution. Then we propose the performative FedAvg algorithm and show that it
converges to the performative stable solution at a rate of O(1/T) under both
full and partial participation schemes. In particular, we use novel proof
techniques and show how the clients' heterogeneity influences the convergence.
Numerical results validate our analysis and provide valuable insights into
real-world applications.
</p></li>
</ul>

<h3>Title: Semi-Supervised Federated Learning for Keyword Spotting. (arXiv:2305.05110v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05110">http://arxiv.org/abs/2305.05110</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05110] Semi-Supervised Federated Learning for Keyword Spotting](http://arxiv.org/abs/2305.05110) #federate</code></li>
<li>Summary: <p>Keyword Spotting (KWS) is a critical aspect of audio-based applications on
mobile devices and virtual assistants. Recent developments in Federated
Learning (FL) have significantly expanded the ability to train machine learning
models by utilizing the computational and private data resources of numerous
distributed devices. However, existing FL methods typically require that
devices possess accurate ground-truth labels, which can be both expensive and
impractical when dealing with local audio data. In this study, we first
demonstrate the effectiveness of Semi-Supervised Federated Learning (SSL) and
FL for KWS. We then extend our investigation to Semi-Supervised Federated
Learning (SSFL) for KWS, where devices possess completely unlabeled data, while
the server has access to a small amount of labeled data. We perform numerical
analyses using state-of-the-art SSL, FL, and SSFL techniques to demonstrate
that the performance of KWS models can be significantly improved by leveraging
the abundant unlabeled heterogeneous data available on devices.
</p></li>
</ul>

<h3>Title: Federated Learning Operations Made Simple with Flame. (arXiv:2305.05118v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05118">http://arxiv.org/abs/2305.05118</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05118] Federated Learning Operations Made Simple with Flame](http://arxiv.org/abs/2305.05118) #federate</code></li>
<li>Summary: <p>Distributed machine learning approaches, including a broad class of federated
learning techniques, present a number of benefits when deploying machine
learning applications over widely distributed infrastructures. To realize the
expected benefits, however, introduces substantial operational challenges due
to required application and configuration-level changes related to
deployment-specific details. Such complexities can be greatly reduced by
introducing higher-level abstractions -- role and channel -- using which
federated learning applications are described as Topology Abstraction Graphs
(TAGs). TAGs decouple the ML application logic from the underlying deployment
details, making it possible to specialize the application deployment, thus
reducing development effort and paving the way for improved automation and
tuning. We present Flame, the first system that supports these abstractions,
and demonstrate its benefits for several use cases.
</p></li>
</ul>

<h3>Title: BARA: Efficient Incentive Mechanism with Online Reward Budget Allocation in Cross-Silo Federated Learning. (arXiv:2305.05221v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05221">http://arxiv.org/abs/2305.05221</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05221] BARA: Efficient Incentive Mechanism with Online Reward Budget Allocation in Cross-Silo Federated Learning](http://arxiv.org/abs/2305.05221) #federate</code></li>
<li>Summary: <p>Federated learning (FL) is a prospective distributed machine learning
framework that can preserve data privacy. In particular, cross-silo FL can
complete model training by making isolated data islands of different
organizations collaborate with a parameter server (PS) via exchanging model
parameters for multiple communication rounds. In cross-silo FL, an incentive
mechanism is indispensable for motivating data owners to contribute their
models to FL training. However, how to allocate the reward budget among
different rounds is an essential but complicated problem largely overlooked by
existing works. The challenge of this problem lies in the opaque feedback
between reward budget allocation and model utility improvement of FL, making
the optimal reward budget allocation complicated. To address this problem, we
design an online reward budget allocation algorithm using Bayesian optimization
named BARA (\underline{B}udget \underline{A}llocation for \underline{R}everse
\underline{A}uction). Specifically, BARA can model the complicated relationship
between reward budget allocation and final model accuracy in FL based on
historical training records so that the reward budget allocated to each
communication round is dynamically optimized so as to maximize the final model
utility. We further incorporate the BARA algorithm into reverse auction-based
incentive mechanisms to illustrate its effectiveness. Extensive experiments are
conducted on real datasets to demonstrate that BARA significantly outperforms
competitive baselines by improving model utility with the same amount of reward
budget.
</p></li>
</ul>

<h3>Title: Survey of Federated Learning Models for Spatial-Temporal Mobility Applications. (arXiv:2305.05257v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05257">http://arxiv.org/abs/2305.05257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05257] Survey of Federated Learning Models for Spatial-Temporal Mobility Applications](http://arxiv.org/abs/2305.05257) #federate</code></li>
<li>Summary: <p>Federated learning involves training statistical models over edge devices
such as mobile phones such that the training data is kept local. Federated
Learning (FL) can serve as an ideal candidate for training spatial temporal
models that rely on heterogeneous and potentially massive numbers of
participants while preserving the privacy of highly sensitive location data.
However, there are unique challenges involved with transitioning existing
spatial temporal models to decentralized learning. In this survey paper, we
review the existing literature that has proposed FL-based models for predicting
human mobility, traffic prediction, community detection, location-based
recommendation systems, and other spatial-temporal tasks. We describe the
metrics and datasets these works have been using and create a baseline of these
approaches in comparison to the centralized settings. Finally, we discuss the
challenges of applying spatial-temporal models in a decentralized setting and
by highlighting the gaps in the literature we provide a road map and
opportunities for the research community.
</p></li>
</ul>

<h2>fair</h2>
<h2>interpretability</h2>
<h3>Title: CAMIL: Context-Aware Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2305.05314v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05314">http://arxiv.org/abs/2305.05314</a></li>
<li>Code URL: <a href="https://github.com/olgafour1/camil">https://github.com/olgafour1/camil</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05314] CAMIL: Context-Aware Multiple Instance Learning for Whole Slide Image Classification](http://arxiv.org/abs/2305.05314) #interpretability</code></li>
<li>Summary: <p>Cancer diagnoses typically involve human pathologists examining whole slide
images (WSIs) of tissue section biopsies to identify tumor cells and their
subtypes. However, artificial intelligence (AI)-based models, particularly
weakly supervised approaches, have recently emerged as viable alternatives.
Weakly supervised approaches often use image subsections or tiles as input,
with the overall classification of the WSI based on attention scores assigned
to each tile. However, this method overlooks the potential for false
positives/negatives because tumors can be heterogeneous, with cancer and normal
cells growing in patterns larger than a single tile. Such errors at the tile
level could lead to misclassification at the tumor level. To address this
limitation, we developed a novel deep learning pooling operator called CHARM
(Contrastive Histopathology Attention Resolved Models). CHARM leverages the
dependencies among single tiles within a WSI and imposes contextual constraints
as prior knowledge to multiple instance learning models. We tested CHARM on the
subtyping of non-small cell lung cancer (NSLC) and lymph node (LN) metastasis,
and the results demonstrated its superiority over other state-of-the-art weakly
supervised classification algorithms. Furthermore, CHARM facilitates
interpretability by visualizing regions of attention.
</p></li>
</ul>

<h3>Title: Towards the Characterization of Representations Learned via Capsule-based Network Architectures. (arXiv:2305.05349v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05349">http://arxiv.org/abs/2305.05349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05349] Towards the Characterization of Representations Learned via Capsule-based Network Architectures](http://arxiv.org/abs/2305.05349) #interpretability</code></li>
<li>Summary: <p>Capsule Networks (CapsNets) have been re-introduced as a more compact and
interpretable alternative to standard deep neural networks. While recent
efforts have proved their compression capabilities, to date, their
interpretability properties have not been fully assessed. Here, we conduct a
systematic and principled study towards assessing the interpretability of these
types of networks. Moreover, we pay special attention towards analyzing the
level to which part-whole relationships are indeed encoded within the learned
representation. Our analysis in the MNIST, SVHN, PASCAL-part and CelebA
datasets suggest that the representations encoded in CapsNets might not be as
disentangled nor strictly related to parts-whole relationships as is commonly
stated in the literature.
</p></li>
</ul>

<h3>Title: Recursions Are All You Need: Towards Efficient Deep Unfolding Networks. (arXiv:2305.05505v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05505">http://arxiv.org/abs/2305.05505</a></li>
<li>Code URL: <a href="https://github.com/rawwad-alhejaili/recursions-are-all-you-need">https://github.com/rawwad-alhejaili/recursions-are-all-you-need</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05505] Recursions Are All You Need: Towards Efficient Deep Unfolding Networks](http://arxiv.org/abs/2305.05505) #interpretability</code></li>
<li>Summary: <p>The use of deep unfolding networks in compressive sensing (CS) has seen wide
success as they provide both simplicity and interpretability. However, since
most deep unfolding networks are iterative, this incurs significant
redundancies in the network. In this work, we propose a novel recursion-based
framework to enhance the efficiency of deep unfolding models. First, recursions
are used to effectively eliminate the redundancies in deep unfolding networks.
Secondly, we randomize the number of recursions during training to decrease the
overall training time. Finally, to effectively utilize the power of recursions,
we introduce a learnable unit to modulate the features of the model based on
both the total number of iterations and the current iteration index. To
evaluate the proposed framework, we apply it to both ISTA-Net+ and COAST.
Extensive testing shows that our proposed framework allows the network to cut
down as much as 75% of its learnable parameters while mostly maintaining its
performance, and at the same time, it cuts around 21% and 42% from the training
time for ISTA-Net+ and COAST respectively. Moreover, when presented with a
limited training dataset, the recursive models match or even outperform their
respective non-recursive baseline. Codes and pretrained models are available at
https://github.com/Rawwad-Alhejaili/Recursions-Are-All-You-Need .
</p></li>
</ul>

<h3>Title: When a CBR in Hand is Better than Twins in the Bush. (arXiv:2305.05111v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05111">http://arxiv.org/abs/2305.05111</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05111] When a CBR in Hand is Better than Twins in the Bush](http://arxiv.org/abs/2305.05111) #interpretability</code></li>
<li>Summary: <p>AI methods referred to as interpretable are often discredited as inaccurate
by supporters of the existence of a trade-off between interpretability and
accuracy. In many problem contexts however this trade-off does not hold. This
paper discusses a regression problem context to predict flight take-off delays
where the most accurate data regression model was trained via the XGBoost
implementation of gradient boosted decision trees. While building an XGB-CBR
Twin and converting the XGBoost feature importance into global weights in the
CBR model, the resultant CBR model alone provides the most accurate local
prediction, maintains the global importance to provide a global explanation of
the model, and offers the most interpretable representation for local
explanations. This resultant CBR model becomes a benchmark of accuracy and
interpretability for this problem context, and hence it is used to evaluate the
two additive feature attribute methods SHAP and LIME to explain the XGBoost
regression model. The results with respect to local accuracy and feature
attribution lead to potentially valuable future work.
</p></li>
</ul>

<h3>Title: SkelEx and BoundEx: Natural Visualization of ReLU Neural Networks. (arXiv:2305.05562v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05562">http://arxiv.org/abs/2305.05562</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05562] SkelEx and BoundEx: Natural Visualization of ReLU Neural Networks](http://arxiv.org/abs/2305.05562) #interpretability</code></li>
<li>Summary: <p>Despite their limited interpretability, weights and biases are still the most
popular encoding of the functions learned by ReLU Neural Networks (ReLU NNs).
That is why we introduce SkelEx, an algorithm to extract a skeleton of the
membership functions learned by ReLU NNs, making those functions easier to
interpret and analyze. To the best of our knowledge, this is the first work
that considers linear regions from the perspective of critical points. As a
natural follow-up, we also introduce BoundEx, which is the first analytical
method known to us to extract the decision boundary from the realization of a
ReLU NN. Both of those methods introduce very natural visualization tool for
ReLU NNs trained on low-dimensional data.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Atmospheric Turbulence Correction via Variational Deep Diffusion. (arXiv:2305.05077v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05077">http://arxiv.org/abs/2305.05077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05077] Atmospheric Turbulence Correction via Variational Deep Diffusion](http://arxiv.org/abs/2305.05077) #diffusion</code></li>
<li>Summary: <p>Atmospheric Turbulence (AT) correction is a challenging restoration task as
it consists of two distortions: geometric distortion and spatially variant
blur. Diffusion models have shown impressive accomplishments in photo-realistic
image synthesis and beyond. In this paper, we propose a novel deep conditional
diffusion model under a variational inference framework to solve the AT
correction problem. We use this framework to improve performance by learning
latent prior information from the input and degradation processes. We use the
learned information to further condition the diffusion model. Experiments are
conducted in a comprehensive synthetic AT dataset. We show that the proposed
framework achieves good quantitative and qualitative results.
</p></li>
</ul>

<h3>Title: SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models. (arXiv:2305.05189v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05189">http://arxiv.org/abs/2305.05189</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05189] SUR-adapter: Enhancing Text-to-Image Pre-trained Diffusion Models with Large Language Models](http://arxiv.org/abs/2305.05189) #diffusion</code></li>
<li>Summary: <p>Diffusion models, which have emerged to become popular text-to-image
generation models, can produce high-quality and content-rich images guided by
textual prompts. However, there are limitations to semantic understanding and
commonsense reasoning in existing models when the input prompts are concise
narrative, resulting in low-quality image generation. To improve the capacities
for narrative prompts, we propose a simple-yet-effective parameter-efficient
fine-tuning approach called the Semantic Understanding and Reasoning adapter
(SUR-adapter) for pre-trained diffusion models. To reach this goal, we first
collect and annotate a new dataset SURD which consists of more than 57,000
semantically corrected multi-modal samples. Each sample contains a simple
narrative prompt, a complex keyword-based prompt, and a high-quality image.
Then, we align the semantic representation of narrative prompts to the complex
prompts and transfer knowledge of large language models (LLMs) to our
SUR-adapter via knowledge distillation so that it can acquire the powerful
semantic understanding and reasoning capabilities to build a high-quality
textual semantic representation for text-to-image generation. We conduct
experiments by integrating multiple LLMs and popular pre-trained diffusion
models to show the effectiveness of our approach in enabling diffusion models
to understand and reason concise natural language without image quality
degradation. Our approach can make text-to-image diffusion models easier to use
with better user experience, which demonstrates our approach has the potential
for further advancing the development of user-friendly text-to-image generation
models by bridging the semantic gap between simple narrative prompts and
complex keyword-based prompts.
</p></li>
</ul>

<h3>Title: Style-A-Video: Agile Diffusion for Arbitrary Text-based Video Style Transfer. (arXiv:2305.05464v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05464">http://arxiv.org/abs/2305.05464</a></li>
<li>Code URL: <a href="https://github.com/haha-lisa/style-a-video">https://github.com/haha-lisa/style-a-video</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05464] Style-A-Video: Agile Diffusion for Arbitrary Text-based Video Style Transfer](http://arxiv.org/abs/2305.05464) #diffusion</code></li>
<li>Summary: <p>Large-scale text-to-video diffusion models have demonstrated an exceptional
ability to synthesize diverse videos. However, due to the lack of extensive
text-to-video datasets and the necessary computational resources for training,
directly applying these models for video stylization remains difficult. Also,
given that the noise addition process on the input content is random and
destructive, fulfilling the style transfer task's content preservation criteria
is challenging. This paper proposes a zero-shot video stylization method named
Style-A-Video, which utilizes a generative pre-trained transformer with an
image latent diffusion model to achieve a concise text-controlled video
stylization. We improve the guidance condition in the denoising process,
establishing a balance between artistic expression and structure preservation.
Furthermore, to decrease inter-frame flicker and avoid the formation of
additional artifacts, we employ a sampling optimization and a temporal
consistency module. Extensive experiments show that we can attain superior
content preservation and stylistic performance while incurring less consumption
than previous solutions. Code will be available at
https://github.com/haha-lisa/Style-A-Video.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Joint Moment Retrieval and Highlight Detection Via Natural Language Queries. (arXiv:2305.04961v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.04961">http://arxiv.org/abs/2305.04961</a></li>
<li>Code URL: <a href="https://github.com/skyline-9/visionary-vids">https://github.com/skyline-9/visionary-vids</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.04961] Joint Moment Retrieval and Highlight Detection Via Natural Language Queries](http://arxiv.org/abs/2305.04961) #transformer</code></li>
<li>Summary: <p>Video summarization has become an increasingly important task in the field of
computer vision due to the vast amount of video content available on the
internet. In this project, we propose a new method for natural language query
based joint video summarization and highlight detection using multi-modal
transformers. This approach will use both visual and audio cues to match a
user's natural language query to retrieve the most relevant and interesting
moments from a video. Our approach employs multiple recent techniques used in
Vision Transformers (ViTs) to create a transformer-like encoder-decoder model.
We evaluated our approach on multiple datasets such as YouTube Highlights and
TVSum to demonstrate the flexibility of our proposed method.
</p></li>
</ul>

<h3>Title: Hybrid Transformer and CNN Attention Network for Stereo Image Super-resolution. (arXiv:2305.05177v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05177">http://arxiv.org/abs/2305.05177</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05177] Hybrid Transformer and CNN Attention Network for Stereo Image Super-resolution](http://arxiv.org/abs/2305.05177) #transformer</code></li>
<li>Summary: <p>Multi-stage strategies are frequently employed in image restoration tasks.
While transformer-based methods have exhibited high efficiency in single-image
super-resolution tasks, they have not yet shown significant advantages over
CNN-based methods in stereo super-resolution tasks. This can be attributed to
two key factors: first, current single-image super-resolution transformers are
unable to leverage the complementary stereo information during the process;
second, the performance of transformers is typically reliant on sufficient
data, which is absent in common stereo-image super-resolution algorithms. To
address these issues, we propose a Hybrid Transformer and CNN Attention Network
(HTCAN), which utilizes a transformer-based network for single-image
enhancement and a CNN-based network for stereo information fusion. Furthermore,
we employ a multi-patch training strategy and larger window sizes to activate
more input pixels for super-resolution. We also revisit other advanced
techniques, such as data augmentation, data ensemble, and model ensemble to
reduce overfitting and data bias. Finally, our approach achieved a score of
23.90dB and emerged as the winner in Track 1 of the NTIRE 2023 Stereo Image
Super-Resolution Challenge.
</p></li>
</ul>

<h3>Title: Integrating Holistic and Local Information to Estimate Emotional Reaction Intensity. (arXiv:2305.05534v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05534">http://arxiv.org/abs/2305.05534</a></li>
<li>Code URL: <a href="https://github.com/hkust-nisl/abaw5">https://github.com/hkust-nisl/abaw5</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05534] Integrating Holistic and Local Information to Estimate Emotional Reaction Intensity](http://arxiv.org/abs/2305.05534) #transformer</code></li>
<li>Summary: <p>Video-based Emotional Reaction Intensity (ERI) estimation measures the
intensity of subjects' reactions to stimuli along several emotional dimensions
from videos of the subject as they view the stimuli. We propose a multi-modal
architecture for video-based ERI combining video and audio information. Video
input is encoded spatially first, frame-by-frame, combining features encoding
holistic aspects of the subjects' facial expressions and features encoding
spatially localized aspects of their expressions. Input is then combined across
time: from frame-to-frame using gated recurrent units (GRUs), then globally by
a transformer. We handle variable video length with a regression token that
accumulates information from all frames into a fixed-dimensional vector
independent of video length. Audio information is handled similarly: spectral
information extracted within each frame is integrated across time by a cascade
of GRUs and a transformer with regression token. The video and audio regression
tokens' outputs are merged by concatenation, then input to a final fully
connected layer producing intensity estimates. Our architecture achieved
excellent performance on the Hume-Reaction dataset in the ERI Esimation
Challenge of the Fifth Competition on Affective Behavior Analysis in-the-Wild
(ABAW5). The Pearson Correlation Coefficients between estimated and subject
self-reported scores, averaged across all emotions, were 0.455 on the
validation dataset and 0.4547 on the test dataset, well above the baselines.
The transformer's self-attention mechanism enables our architecture to focus on
the most critical video frames regardless of length. Ablation experiments
establish the advantages of combining holistic/local features and of
multi-modal integration. Code available at https://github.com/HKUST-NISL/ABAW5.
</p></li>
</ul>

<h3>Title: ColonMapper: topological mapping and localization for colonoscopy. (arXiv:2305.05546v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05546">http://arxiv.org/abs/2305.05546</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05546] ColonMapper: topological mapping and localization for colonoscopy](http://arxiv.org/abs/2305.05546) #transformer</code></li>
<li>Summary: <p>Mapping and localization in endoluminal cavities from colonoscopies or
gastroscopies has to overcome the challenge of significant shape and
illumination changes between reobservations of the same endoluminal location.
Instead of geometrical maps that strongly rely on a fixed scene geometry,
topological maps are more adequate because they focus on visual place
recognition, i.e. the capability to determine if two video shots are imaging
the same location. We propose a topological mapping and localization system
able to operate on real human colonoscopies. The map is a graph where each node
codes a colon location by a set of real images of that location. The edges
represent traversability between two nodes. For close-in-time images, where
scene changes are minor, place recognition can be successfully managed with the
recent transformers-based image-matching algorithms. However, under long-term
changes -- such as different colonoscopies of the same patient -- feature-based
matching fails. To address this, we propose a GeM global descriptor able to
achieve high recall with significant changes in the scene. The addition of a
Bayesian filter processing the map graph boosts the accuracy of the long-term
place recognition, enabling relocalization in a previously built map. In the
experiments, we construct a map during the withdrawal phase of a first
colonoscopy. Subsequently, we prove the ability to relocalize within this map
during a second colonoscopy of the same patient two weeks later. Code and
models will be available upon acceptance.
</p></li>
</ul>

<h3>Title: Group Activity Recognition via Dynamic Composition and Interaction. (arXiv:2305.05583v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05583">http://arxiv.org/abs/2305.05583</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05583] Group Activity Recognition via Dynamic Composition and Interaction](http://arxiv.org/abs/2305.05583) #transformer</code></li>
<li>Summary: <p>Previous group activity recognition approaches were limited to reasoning
using human relations or finding important subgroups and tended to ignore
indispensable group composition and human-object interactions. This absence
makes a partial interpretation of the scene and increases the interference of
irrelevant actions on the results. Therefore, we propose our DynamicFormer with
Dynamic composition Module (DcM) and Dynamic interaction Module (DiM) to model
relations and locations of persons and discriminate the contribution of
participants, respectively. Our findings on group composition and human-object
interaction inspire our core idea. Group composition tells us the location of
people and their relations inside the group, while interaction reflects the
relation between humans and objects outside the group. We utilize spatial and
temporal encoders in DcM to model our dynamic composition and build DiM to
explore interaction with a novel GCN, which has a transformer inside to
consider the temporal neighbors of human/object. Also, a Multi-level Dynamic
Integration is employed to integrate features from different levels. We conduct
extensive experiments on two public datasets and show that our method achieves
state-of-the-art.
</p></li>
</ul>

<h3>Title: SwinIA: Self-Supervised Blind-Spot Image Denoising with Zero Convolutions. (arXiv:2305.05651v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05651">http://arxiv.org/abs/2305.05651</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05651] SwinIA: Self-Supervised Blind-Spot Image Denoising with Zero Convolutions](http://arxiv.org/abs/2305.05651) #transformer</code></li>
<li>Summary: <p>The essence of self-supervised image denoising is to restore the signal from
the noisy image alone. State-of-the-art solutions for this task rely on the
idea of masking pixels and training a fully-convolutional neural network to
impute them. This most often requires multiple forward passes, information
about the noise model, and intricate regularization functions. In this paper,
we propose a Swin Transformer-based Image Autoencoder (SwinIA), the first
convolution-free architecture for self-supervised denoising. It can be trained
end-to-end with a simple mean squared error loss without masking and does not
require any prior knowledge about clean data or noise distribution. Despite its
simplicity, SwinIA establishes state-of-the-art on several common benchmarks.
</p></li>
</ul>

<h3>Title: A transformer-based method for zero and few-shot biomedical named entity recognition. (arXiv:2305.04928v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.04928">http://arxiv.org/abs/2305.04928</a></li>
<li>Code URL: <a href="https://github.com/br-ai-ns-institute/zero-shotner">https://github.com/br-ai-ns-institute/zero-shotner</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.04928] A transformer-based method for zero and few-shot biomedical named entity recognition](http://arxiv.org/abs/2305.04928) #transformer</code></li>
<li>Summary: <p>Supervised named entity recognition (NER) in the biomedical domain is
dependent on large sets of annotated texts with the given named entities, whose
creation can be time-consuming and expensive. Furthermore, the extraction of
new entities often requires conducting additional annotation tasks and
retraining the model. To address these challenges, this paper proposes a
transformer-based method for zero- and few-shot NER in the biomedical domain.
The method is based on transforming the task of multi-class token
classification into binary token classification (token contains the searched
entity or does not contain the searched entity) and pre-training on a larger
amount of datasets and biomedical entities, from where the method can learn
semantic relations between the given and potential classes. We have achieved
average F1 scores of 35.44% for zero-shot NER, 50.10% for one-shot NER, 69.94%
for 10-shot NER, and 79.51% for 100-shot NER on 9 diverse evaluated biomedical
entities with PubMedBERT fine-tuned model. The results demonstrate the
effectiveness of the proposed method for recognizing new entities with limited
examples, with comparable or better results from the state-of-the-art zero- and
few-shot NER methods.
</p></li>
</ul>

<h3>Title: Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer. (arXiv:2305.05061v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05061">http://arxiv.org/abs/2305.05061</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05061] Coherent Wave Dynamics and Language Generation of a Generative Pre-trained Transformer](http://arxiv.org/abs/2305.05061) #transformer</code></li>
<li>Summary: <p>Large Language Models (LLMs), such as the Generative Pretrained Transformer
(GPT), have achieved tremendous success in various language tasks, but their
emergent abilities have also raised many questions, concerns, and challenges
that need to be addressed. To gain a better understanding of the models' inner
mechanisms, we analyze the hidden state and channel wave dynamics in a small
GPT, focusing on the coherence of wave patterns in terms of cross-channel
correlation and individual auto-correlation. Our findings suggest that wave
dynamics offer consistent and repeatable intrinsic oscillation modes, along
with context-aware plasticity and expressiveness in language generation. By
analyzing wave patterns, coherence, and clustering, we provide a systematic way
to identify and interpret the functionality of the hidden state channels,
paving the way to understand and control higher-level language pattern
formation. In addition, we investigate the Poisson statistics of spelling
errors in text sequence generation across various levels of model training and
observe a phase-transition-like process. As coherence builds up, there is a
competition between the generation of correct and misspelled words. However,
once the model is adequately trained and significant coherence has emerged, the
coherent process becomes strong enough to effectively suppress spelling errors,
preventing the cascade amplification of defects. The distribution of correct
spellings transitions from Poissonian to Sub-Poissonian, while the distribution
of misspellings shows the opposite trend. By leveraging concepts and techniques
from quantum physics, we gain novel insights into the dynamics of the small
GPT. This approach can be extended to larger language models that exhibit more
complex coherent language patterns, opening up opportunities to interpret their
emergent capabilities and develop more specialized models.
</p></li>
</ul>

<h3>Title: Detection of depression on social networks using transformers and ensembles. (arXiv:2305.05325v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05325">http://arxiv.org/abs/2305.05325</a></li>
<li>Code URL: <a href="https://gitlab.com/teletton/diploma">https://gitlab.com/teletton/diploma</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05325] Detection of depression on social networks using transformers and ensembles](http://arxiv.org/abs/2305.05325) #transformer</code></li>
<li>Summary: <p>As the impact of technology on our lives is increasing, we witness increased
use of social media that became an essential tool not only for communication
but also for sharing information with community about our thoughts and
feelings. This can be observed also for people with mental health disorders
such as depression where they use social media for expressing their thoughts
and asking for help. This opens a possibility to automatically process social
media posts and detect signs of depression. We build several large pre-trained
language model based classifiers for depression detection from social media
posts. Besides fine-tuning BERT, RoBERTA, BERTweet, and mentalBERT were also
construct two types of ensembles. We analyze the performance of our models on
two data sets of posts from social platforms Reddit and Twitter, and
investigate also the performance of transfer learning across the two data sets.
The results show that transformer ensembles improve over the single
transformer-based classifiers.
</p></li>
</ul>

<h3>Title: Investigating the effect of sub-word segmentation on the performance of transformer language models. (arXiv:2305.05480v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05480">http://arxiv.org/abs/2305.05480</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05480] Investigating the effect of sub-word segmentation on the performance of transformer language models](http://arxiv.org/abs/2305.05480) #transformer</code></li>
<li>Summary: <p>We would like to explore how morphemes can affect the performance of a
language model. We trained GPT-2 and Bert model with StateMorph for both
Finnish and Russian, which is a morpheme segmenting algorithm. As a comparison,
we also trained a model with BPE and Morfessor. Our preliminary result shows
that StateMorph can help the model to converge more efficiently and achieve a
better validation score.
</p></li>
</ul>

<h3>Title: The emergence of clusters in self-attention dynamics. (arXiv:2305.05465v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05465">http://arxiv.org/abs/2305.05465</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05465] The emergence of clusters in self-attention dynamics](http://arxiv.org/abs/2305.05465) #transformer</code></li>
<li>Summary: <p>Viewing Transformers as interacting particle systems, we describe the
geometry of learned representations when the weights are not time dependent. We
show that particles, representing tokens, tend to cluster toward particular
limiting objects as time tends to infinity. The type of limiting object that
emerges depends on the spectrum of the value matrix. Additionally, in the
one-dimensional case we prove that the self-attention matrix converges to a
low-rank Boolean matrix. The combination of these results mathematically
confirms the empirical observation made by Vaswani et al.
\cite{vaswani2017attention} that \emph{leaders} appear in a sequence of tokens
when processed by Transformers.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model. (arXiv:2305.05351v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05351">http://arxiv.org/abs/2305.05351</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05351] GPT-NAS: Neural Architecture Search with the Generative Pre-Trained Model](http://arxiv.org/abs/2305.05351) #generative</code></li>
<li>Summary: <p>Neural Architecture Search (NAS) has emerged as one of the effective methods
to design the optimal neural network architecture automatically. Although
neural architectures have achieved human-level performances in several tasks,
few of them are obtained from the NAS method. The main reason is the huge
search space of neural architectures, making NAS algorithms inefficient. This
work presents a novel architecture search algorithm, called GPT-NAS, that
optimizes neural architectures by Generative Pre-Trained (GPT) model. In
GPT-NAS, we assume that a generative model pre-trained on a large-scale corpus
could learn the fundamental law of building neural architectures. Therefore,
GPT-NAS leverages the generative pre-trained (GPT) model to propose reasonable
architecture components given the basic one. Such an approach can largely
reduce the search space by introducing prior knowledge in the search process.
Extensive experimental results show that our GPT-NAS method significantly
outperforms seven manually designed neural architectures and thirteen
architectures provided by competing NAS methods. In addition, our ablation
study indicates that the proposed algorithm improves the performance of finely
tuned neural architectures by up to about 12% compared to those without GPT,
further demonstrating its effectiveness in searching neural architectures.
</p></li>
</ul>

<h3>Title: Fashion CUT: Unsupervised domain adaptation for visual pattern classification in clothes using synthetic data and pseudo-labels. (arXiv:2305.05580v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05580">http://arxiv.org/abs/2305.05580</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05580] Fashion CUT: Unsupervised domain adaptation for visual pattern classification in clothes using synthetic data and pseudo-labels](http://arxiv.org/abs/2305.05580) #generative</code></li>
<li>Summary: <p>Accurate product information is critical for e-commerce stores to allow
customers to browse, filter, and search for products. Product data quality is
affected by missing or incorrect information resulting in poor customer
experience. While machine learning can be used to correct inaccurate or missing
information, achieving high performance on fashion image classification tasks
requires large amounts of annotated data, but it is expensive to generate due
to labeling costs. One solution can be to generate synthetic data which
requires no manual labeling. However, training a model with a dataset of solely
synthetic images can lead to poor generalization when performing inference on
real-world data because of the domain shift. We introduce a new unsupervised
domain adaptation technique that converts images from the synthetic domain into
the real-world domain. Our approach combines a generative neural network and a
classifier that are jointly trained to produce realistic images while
preserving the synthetic label information. We found that using real-world
pseudo-labels during training helps the classifier to generalize in the
real-world domain, reducing the synthetic bias. We successfully train a visual
pattern classification model in the fashion domain without real-world
annotations. Experiments show that our method outperforms other unsupervised
domain adaptation algorithms.
</p></li>
</ul>

<h3>Title: Consistent Text Categorization using Data Augmentation in e-Commerce. (arXiv:2305.05402v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05402">http://arxiv.org/abs/2305.05402</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05402] Consistent Text Categorization using Data Augmentation in e-Commerce](http://arxiv.org/abs/2305.05402) #generative</code></li>
<li>Summary: <p>The categorization of massive e-Commerce data is a crucial, well-studied
task, which is prevalent in industrial settings. In this work, we aim to
improve an existing product categorization model that is already in use by a
major web company, serving multiple applications. At its core, the product
categorization model is a text classification model that takes a product title
as an input and outputs the most suitable category out of thousands of
available candidates. Upon a closer inspection, we found inconsistencies in the
labeling of similar items. For example, minor modifications of the product
title pertaining to colors or measurements majorly impacted the model's output.
This phenomenon can negatively affect downstream recommendation or search
applications, leading to a sub-optimal user experience.
</p></li>
</ul>

<p>To address this issue, we propose a new framework for consistent text
categorization. Our goal is to improve the model's consistency while
maintaining its production-level performance. We use a semi-supervised approach
for data augmentation and presents two different methods for utilizing
unlabeled samples. One method relies directly on existing catalogs, while the
other uses a generative model. We compare the pros and cons of each approach
and present our experimental results.
</p>

<h2>large language model</h2>
<h3>Title: GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning. (arXiv:2305.05001v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05001">http://arxiv.org/abs/2305.05001</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05001] GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from Doctor-Patient Conversations through Fine-tuning and In-context Learning](http://arxiv.org/abs/2305.05001) #large language model</code></li>
<li>Summary: <p>This paper presents our contribution to the MEDIQA-2023 Dialogue2Note shared
task, encompassing both subtask A and subtask B. We approach the task as a
dialogue summarization problem and implement two distinct pipelines: (a) a
fine-tuning of a pre-trained dialogue summarization model and GPT-3, and (b)
few-shot in-context learning (ICL) using a large language model, GPT-4. Both
methods achieve excellent results in terms of ROUGE-1 F1, BERTScore F1
(deberta-xlarge-mnli), and BLEURT, with scores of 0.4011, 0.7058, and 0.5421,
respectively. Additionally, we predict the associated section headers using
RoBERTa and SciBERT based classification models. Our team ranked fourth among
all teams, while each team is allowed to submit three runs as part of their
submission. We also utilize expert annotations to demonstrate that the notes
generated through the ICL GPT-4 are better than all other baselines. The code
for our submission is available.
</p></li>
</ul>

<h3>Title: Web Content Filtering through knowledge distillation of Large Language Models. (arXiv:2305.05027v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05027">http://arxiv.org/abs/2305.05027</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05027] Web Content Filtering through knowledge distillation of Large Language Models](http://arxiv.org/abs/2305.05027) #large language model</code></li>
<li>Summary: <p>We introduce a state-of-the-art approach for URL categorization that
leverages the power of Large Language Models (LLMs) to address the primary
objectives of web content filtering: safeguarding organizations from legal and
ethical risks, limiting access to high-risk or suspicious websites, and
fostering a secure and professional work environment. Our method utilizes LLMs
to generate accurate classifications and then employs established knowledge
distillation techniques to create smaller, more specialized student models
tailored for web content filtering. Distillation results in a student model
with a 9\% accuracy rate improvement in classifying websites, sourced from
customer telemetry data collected by a large security vendor, into 30 distinct
content categories based on their URLs, surpassing the current state-of-the-art
approach. Our student model matches the performance of the teacher LLM with 175
times less parameters, allowing the model to be used for in-line scanning of
large volumes of URLs, and requires 3 orders of magnitude less manually labeled
training data than the current state-of-the-art approach. Depending on the
specific use case, the output generated by our approach can either be directly
returned or employed as a pre-filter for more resource-intensive operations
involving website images or HTML.
</p></li>
</ul>

<h3>Title: ANALOGICAL -- A New Benchmark for Analogy of Long Text for Large Language Models. (arXiv:2305.05050v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05050">http://arxiv.org/abs/2305.05050</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05050] ANALOGICAL -- A New Benchmark for Analogy of Long Text for Large Language Models](http://arxiv.org/abs/2305.05050) #large language model</code></li>
<li>Summary: <p>Over the past decade, analogies, in the form of word-level analogies, have
played a significant role as an intrinsic measure of evaluating the quality of
word embedding methods such as word2vec. Modern large language models (LLMs),
however, are primarily evaluated on extrinsic measures based on benchmarks such
as GLUE and SuperGLUE, and there are only a few investigations on whether LLMs
can draw analogies between long texts. In this paper, we present ANALOGICAL, a
new benchmark to intrinsically evaluate LLMs across a taxonomy of analogies of
long text with six levels of complexity -- (i) word, (ii) word vs. sentence,
(iii) syntactic, (iv) negation, (v) entailment, and (vi) metaphor. Using
thirteen datasets and three different distance measures, we evaluate the
abilities of eight LLMs in identifying analogical pairs in the semantic vector
space (e.g., "I can speak two languages" should be closer to "I am bilingual"
while "I like chocolate" and "I do not like chocolate" should be orthogonal).
Our evaluation finds that it is increasingly challenging for LLMs to identify
analogies when going up the analogy taxonomy.
</p></li>
</ul>

<h3>Title: Dreams Are More "Predictable'' Than You Think. (arXiv:2305.05054v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05054">http://arxiv.org/abs/2305.05054</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05054] Dreams Are More "Predictable'' Than You Think](http://arxiv.org/abs/2305.05054) #large language model</code></li>
<li>Summary: <p>A consistent body of evidence suggests that dream reports significantly vary
from other types of textual transcripts with respect to semantic content.
Furthermore, it appears to be a widespread belief in the dream/sleep research
community that dream reports constitute rather ``unique'' strings of text. This
might be a notable issue for the growing amount of approaches using natural
language processing (NLP) tools to automatically analyse dream reports, as they
largely rely on neural models trained on non-dream corpora scraped from the
web. In this work, I will adopt state-of-the-art (SotA) large language models
(LLMs), to study if and how dream reports deviate from other human-generated
text strings, such as Wikipedia. Results show that, taken as a whole, DreamBank
does not deviate from Wikipedia. Moreover, on average, single dream reports are
significantly more predictable than Wikipedia articles. Preliminary evidence
suggests that word count, gender, and visual impairment can significantly shape
how predictable a dream report can appear to the model.
</p></li>
</ul>

<h3>Title: FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance. (arXiv:2305.05176v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05176">http://arxiv.org/abs/2305.05176</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05176] FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance](http://arxiv.org/abs/2305.05176) #large language model</code></li>
<li>Summary: <p>There is a rapidly growing number of large language models (LLMs) that users
can query for a fee. We review the cost associated with querying popular LLM
APIs, e.g. GPT-4, ChatGPT, J1-Jumbo, and find that these models have
heterogeneous pricing structures, with fees that can differ by two orders of
magnitude. In particular, using LLMs on large collections of queries and text
can be expensive. Motivated by this, we outline and discuss three types of
strategies that users can exploit to reduce the inference cost associated with
using LLMs: 1) prompt adaptation, 2) LLM approximation, and 3) LLM cascade. As
an example, we propose FrugalGPT, a simple yet flexible instantiation of LLM
cascade which learns which combinations of LLMs to use for different queries in
order to reduce cost and improve accuracy. Our experiments show that FrugalGPT
can match the performance of the best individual LLM (e.g. GPT-4) with up to
98% cost reduction or improve the accuracy over GPT-4 by 4% with the same cost.
The ideas and findings presented here lay a foundation for using LLMs
sustainably and efficiently.
</p></li>
</ul>

<h3>Title: MoT: Pre-thinking and Recalling Enable ChatGPT to Self-Improve with Memory-of-Thoughts. (arXiv:2305.05181v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05181">http://arxiv.org/abs/2305.05181</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05181] MoT: Pre-thinking and Recalling Enable ChatGPT to Self-Improve with Memory-of-Thoughts](http://arxiv.org/abs/2305.05181) #large language model</code></li>
<li>Summary: <p>Large Language Models have shown impressive abilities on various tasks.
However, fundamentally improving them depends on high-quality datasets or
computationally expensive fine-tuning. On the contrary, human can easily
improve themselves by thinking and memory, without external resources. In this
paper, we propose a framework, MoT, to let the LLM self-improve through Memory
of Thoughts, without annotated datasets and parameter updates. Specifically,
the framework is divided into two stages: 1. before the test stage, we let the
LLM pre-think on the unlabeled dataset and save the high-confidence thoughts as
external memory; 2. during inference, given a test question, we let the LLM
recall relevant memory to help itself reason and answer it. Experimental
results show that the proposed framework can help ChatGPT significantly improve
its abilities in math reasoning, commonsense reasoning, factual reasoning and
natural language inference. Further analyses show that each component
contributes critically to the improvements.
</p></li>
</ul>

<h3>Title: Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05252">http://arxiv.org/abs/2305.05252</a></li>
<li>Code URL: <a href="https://github.com/siyuyuan/coscript">https://github.com/siyuyuan/coscript</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05252] Distilling Script Knowledge from Large Language Models for Constrained Language Planning](http://arxiv.org/abs/2305.05252) #large language model</code></li>
<li>Summary: <p>In everyday life, humans often plan their actions by following step-by-step
instructions in the form of goal-oriented scripts. Previous work has exploited
language models (LMs) to plan for abstract goals of stereotypical activities
(e.g., "make a cake"), but leaves more specific goals with multi-facet
constraints understudied (e.g., "make a cake for diabetics"). In this paper, we
define the task of constrained language planning for the first time. We propose
an overgenerate-then-filter approach to improve large language models (LLMs) on
this task, and use it to distill a novel constrained language planning dataset,
CoScript, which consists of 55,000 scripts. Empirical results demonstrate that
our method significantly improves the constrained language planning ability of
LLMs, especially on constraint faithfulness. Furthermore, CoScript is
demonstrated to be quite effective in endowing smaller LMs with constrained
language planning ability.
</p></li>
</ul>

<h3>Title: Large Language Model Programs. (arXiv:2305.05364v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05364">http://arxiv.org/abs/2305.05364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05364] Large Language Model Programs](http://arxiv.org/abs/2305.05364) #large language model</code></li>
<li>Summary: <p>In recent years, large pre-trained language models (LLMs) have demonstrated
the ability to follow instructions and perform novel tasks from a few examples.
The possibility to parameterise an LLM through such in-context examples widens
their capability at a much lower cost than finetuning. We extend this line of
reasoning and present a method which further expands the capabilities of an LLM
by embedding it within an algorithm or program. To demonstrate the benefits of
this approach, we present an illustrative example of evidence-supported
question-answering. We obtain a 6.4\% improvement over the chain of thought
baseline through a more algorithmic approach without any finetuning.
Furthermore, we highlight recent work from this perspective and discuss the
advantages and disadvantages in comparison to the standard approaches.
</p></li>
</ul>

<h3>Title: Large Language Models Need Holistically Thought in Medical Conversational QA. (arXiv:2305.05410v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05410">http://arxiv.org/abs/2305.05410</a></li>
<li>Code URL: <a href="https://github.com/wengsyx/hot">https://github.com/wengsyx/hot</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05410] Large Language Models Need Holistically Thought in Medical Conversational QA](http://arxiv.org/abs/2305.05410) #large language model</code></li>
<li>Summary: <p>The medical conversational question answering (CQA) system aims at providing
a series of professional medical services to improve the efficiency of medical
care. Despite the success of large language models (LLMs) in complex reasoning
tasks in various fields, such as mathematics, logic, and commonsense QA, they
still need to improve with the increased complexity and specialization of the
medical field. This is because medical CQA tasks require not only strong
medical reasoning, but also the ability to think broadly and deeply. In this
paper, to address these challenges in medical CQA tasks that need to be
considered and understood in many aspects, we propose the Holistically Thought
(HoT) method, which is designed to guide the LLMs to perform the diffused and
focused thinking for generating high-quality medical responses. The proposed
HoT method has been evaluated through automated and manual assessments in three
different medical CQA datasets containing the English and Chinese languages.
The extensive experimental results show that our method can produce more
correctness, professional, and considerate answers than several
state-of-the-art (SOTA) methods, manifesting its effectiveness. Our code in
https://github.com/WENGSYX/HoT.
</p></li>
</ul>

<h3>Title: The Case Records of ChatGPT: Language Models and Complex Clinical Questions. (arXiv:2305.05609v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05609">http://arxiv.org/abs/2305.05609</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05609] The Case Records of ChatGPT: Language Models and Complex Clinical Questions](http://arxiv.org/abs/2305.05609) #large language model</code></li>
<li>Summary: <p>Background: Artificial intelligence language models have shown promise in
various applications, including assisting with clinical decision-making as
demonstrated by strong performance of large language models on medical
licensure exams. However, their ability to solve complex, open-ended cases,
which may be representative of clinical practice, remains unexplored. Methods:
In this study, the accuracy of large language AI models GPT4 and GPT3.5 in
diagnosing complex clinical cases was investigated using published Case Records
of the Massachusetts General Hospital. A total of 50 cases requiring a
diagnosis and diagnostic test published from January 1, 2022 to April 16, 2022
were identified. For each case, models were given a prompt requesting the top
three specific diagnoses and associated diagnostic tests, followed by case
text, labs, and figure legends. Model outputs were assessed in comparison to
the final clinical diagnosis and whether the model-predicted test would result
in a correct diagnosis. Results: GPT4 and GPT3.5 accurately provided the
correct diagnosis in 26% and 22% of cases in one attempt, and 46% and 42%
within three attempts, respectively. GPT4 and GPT3.5 provided a correct
essential diagnostic test in 28% and 24% of cases in one attempt, and 44% and
50% within three attempts, respectively. No significant differences were found
between the two models, and multiple trials with identical prompts using the
GPT3.5 model provided similar results. Conclusions: In summary, these models
demonstrate potential usefulness in generating differential diagnoses but
remain limited in their ability to provide a single unifying diagnosis in
complex, open-ended cases. Future research should focus on evaluating model
performance in larger datasets of open-ended clinical challenges and exploring
potential human-AI collaboration strategies to enhance clinical
decision-making.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Dual flow fusion model for concrete surface crack segmentation. (arXiv:2305.05132v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05132">http://arxiv.org/abs/2305.05132</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05132] Dual flow fusion model for concrete surface crack segmentation](http://arxiv.org/abs/2305.05132) #segmentation</code></li>
<li>Summary: <p>Cracks and other diseases are important factors that threaten the safe
operation of transportation infrastructure. Traditional manual detection and
ultrasonic instrument detection consume a lot of time and resource costs. With
the development of deep learning technology, many deep learning models are
widely used in actual visual segmentation tasks. The detection method based on
the deep learning model has the advantages of high detection accuracy, fast
detection speed and simple operation. However, the crack segmentation based on
deep learning has problems such as sensitivity to background noise, rough
edges, and lack of robustness. Therefore, this paper proposes a fissure
segmentation model based on two-stream fusion, which simultaneously inputs
images into two designed processing streams to independently extract
long-distance dependent and local detail features, and realizes adaptive
prediction through a dual-head mechanism. At the same time, a new interactive
fusion mechanism is proposed to guide the complementarity of different levels
of features to realize the location and identification of cracks in complex
backgrounds. Finally, we propose an edge optimization method to improve
segmentation accuracy. Experiments have proved that the F1 value of the
segmentation results on the DeepCrack[1] public dataset reached 93.7%, and the
IOU value reached 86.6%; the F1 value of the segmentation results on the
CRACK500[2] dataset reached 78.1%, and the IOU value reached 66.0%.
</p></li>
</ul>

<h3>Title: Multi-Granularity Denoising and Bidirectional Alignment for Weakly Supervised Semantic Segmentation. (arXiv:2305.05154v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05154">http://arxiv.org/abs/2305.05154</a></li>
<li>Code URL: <a href="https://github.com/nust-machine-intelligence-laboratory/mdba">https://github.com/nust-machine-intelligence-laboratory/mdba</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05154] Multi-Granularity Denoising and Bidirectional Alignment for Weakly Supervised Semantic Segmentation](http://arxiv.org/abs/2305.05154) #segmentation</code></li>
<li>Summary: <p>Weakly supervised semantic segmentation (WSSS) models relying on class
activation maps (CAMs) have achieved desirable performance comparing to the
non-CAMs-based counterparts. However, to guarantee WSSS task feasible, we need
to generate pseudo labels by expanding the seeds from CAMs which is complex and
time-consuming, thus hindering the design of efficient end-to-end
(single-stage) WSSS approaches. To tackle the above dilemma, we resort to the
off-the-shelf and readily accessible saliency maps for directly obtaining
pseudo labels given the image-level class labels. Nevertheless, the salient
regions may contain noisy labels and cannot seamlessly fit the target objects,
and saliency maps can only be approximated as pseudo labels for simple images
containing single-class objects. As such, the achieved segmentation model with
these simple images cannot generalize well to the complex images containing
multi-class objects. To this end, we propose an end-to-end multi-granularity
denoising and bidirectional alignment (MDBA) model, to alleviate the noisy
label and multi-class generalization issues. Specifically, we propose the
online noise filtering and progressive noise detection modules to tackle
image-level and pixel-level noise, respectively. Moreover, a bidirectional
alignment mechanism is proposed to reduce the data distribution gap at both
input and output space with simple-to-complex image synthesis and
complex-to-simple adversarial learning. MDBA can reach the mIoU of 69.5\% and
70.2\% on validation and test sets for the PASCAL VOC 2012 dataset. The source
codes and models have been made available at
\url{https://github.com/NUST-Machine-Intelligence-Laboratory/MDBA}.
</p></li>
</ul>

<h3>Title: DC3DCD: unsupervised learning for multiclass 3D point cloud change detection. (arXiv:2305.05421v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05421">http://arxiv.org/abs/2305.05421</a></li>
<li>Code URL: <a href="https://github.com/idegelis/torch-points3d-dc3dcd">https://github.com/idegelis/torch-points3d-dc3dcd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05421] DC3DCD: unsupervised learning for multiclass 3D point cloud change detection](http://arxiv.org/abs/2305.05421) #segmentation</code></li>
<li>Summary: <p>In a constant evolving world, change detection is of prime importance to keep
updated maps. To better sense areas with complex geometry (urban areas in
particular), considering 3D data appears to be an interesting alternative to
classical 2D images. In this context, 3D point clouds (PCs) obtained by LiDAR
or photogrammetry are very interesting. While recent studies showed the
considerable benefit of using deep learning-based methods to detect and
characterize changes into raw 3D PCs, these studies rely on large annotated
training data to obtain accurate results. The collection of these annotations
are tricky and time-consuming. The availability of unsupervised or weakly
supervised approaches is then of prime interest. In this paper, we propose an
unsupervised method, called DeepCluster 3D Change Detection (DC3DCD), to detect
and categorize multiclass changes at point level. We classify our approach in
the unsupervised family given the fact that we extract in a completely
unsupervised way a number of clusters associated with potential changes. Let us
precise that in the end of the process, the user has only to assign a label to
each of these clusters to derive the final change map. Our method builds upon
the DeepCluster approach, originally designed for image classification, to
handle complex raw 3D PCs and perform change segmentation task. An assessment
of the method on both simulated and real public dataset is provided. The
proposed method allows to outperform fully-supervised traditional machine
learning algorithm and to be competitive with fully-supervised deep learning
networks applied on rasterization of 3D PCs with a mean of IoU over classes of
change of 57.06% and 66.69% for the simulated and the real datasets,
respectively.
</p></li>
</ul>

<h3>Title: Real-time instance segmentation with polygons using an Intersection-over-Union loss. (arXiv:2305.05490v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05490">http://arxiv.org/abs/2305.05490</a></li>
<li>Code URL: <a href="https://github.com/katiajdl/centerpoly-v2">https://github.com/katiajdl/centerpoly-v2</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05490] Real-time instance segmentation with polygons using an Intersection-over-Union loss](http://arxiv.org/abs/2305.05490) #segmentation</code></li>
<li>Summary: <p>Predicting a binary mask for an object is more accurate but also more
computationally expensive than a bounding box. Polygonal masks as developed in
CenterPoly can be a good compromise. In this paper, we improve over CenterPoly
by enhancing the classical regression L1 loss with a novel region-based loss
and a novel order loss, as well as with a new training process for the vertices
prediction head. Moreover, the previous methods that predict polygonal masks
use different coordinate systems, but it is not clear if one is better than
another, if we abstract the architecture requirement. We therefore investigate
their impact on the prediction. We also use a new evaluation protocol with
oracle predictions for the detection head, to further isolate the segmentation
process and better compare the polygonal masks with binary masks. Our instance
segmentation method is trained and tested with challenging datasets containing
urban scenes, with a high density of road users. Experiments show, in
particular, that using a combination of a regression loss and a region-based
loss allows significant improvements on the Cityscapes and IDD test set
compared to CenterPoly. Moreover the inference stage remains fast enough to
reach real-time performance with an average of 0.045 s per frame for
2048$\times$1024 images on a single RTX 2070 GPU. The code is available
$\href{https://github.com/KatiaJDL/CenterPoly-v2}{\text{here}}$.
</p></li>
</ul>

<h3>Title: Self-supervised dense representation learning for live-cell microscopy with time arrow prediction. (arXiv:2305.05511v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05511">http://arxiv.org/abs/2305.05511</a></li>
<li>Code URL: <a href="https://github.com/weigertlab/tarrow">https://github.com/weigertlab/tarrow</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05511] Self-supervised dense representation learning for live-cell microscopy with time arrow prediction](http://arxiv.org/abs/2305.05511) #segmentation</code></li>
<li>Summary: <p>State-of-the-art object detection and segmentation methods for microscopy
images rely on supervised machine learning, which requires laborious manual
annotation of training data. Here we present a self-supervised method based on
time arrow prediction pre-training that learns dense image representations from
raw, unlabeled live-cell microscopy videos. Our method builds upon the task of
predicting the correct order of time-flipped image regions via a single-image
feature extractor and a subsequent time arrow prediction head. We show that the
resulting dense representations capture inherently time-asymmetric biological
processes such as cell divisions on a pixel-level. We furthermore demonstrate
the utility of these representations on several live-cell microscopy datasets
for detection and segmentation of dividing cells, as well as for cell state
classification. Our method outperforms supervised methods, particularly when
only limited ground truth annotations are available as is commonly the case in
practice. We provide code at https://github.com/weigertlab/tarrow.
</p></li>
</ul>

<h3>Title: Can point cloud networks learn statistical shape models of anatomies?. (arXiv:2305.05610v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2305.05610">http://arxiv.org/abs/2305.05610</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2305.05610] Can point cloud networks learn statistical shape models of anatomies?](http://arxiv.org/abs/2305.05610) #segmentation</code></li>
<li>Summary: <p>Statistical Shape Modeling (SSM) is a valuable tool for investigating and
quantifying anatomical variations within populations of anatomies. However,
traditional correspondence-based SSM generation methods require a
time-consuming re-optimization process each time a new subject is added to the
cohort, making the inference process prohibitive for clinical research.
Additionally, they require complete geometric proxies (e.g., high-resolution
binary volumes or surface meshes) as input shapes to construct the SSM.
Unordered 3D point cloud representations of shapes are more easily acquired
from various medical imaging practices (e.g., thresholded images and surface
scanning). Point cloud deep networks have recently achieved remarkable success
in learning permutation-invariant features for different point cloud tasks
(e.g., completion, semantic segmentation, classification). However, their
application to learning SSM from point clouds is to-date unexplored. In this
work, we demonstrate that existing point cloud encoder-decoder-based completion
networks can provide an untapped potential for SSM, capturing population-level
statistical representations of shapes while reducing the inference burden and
relaxing the input requirement. We discuss the limitations of these techniques
to the SSM application and suggest future improvements. Our work paves the way
for further exploration of point cloud deep learning for SSM, a promising
avenue for advancing shape analysis literature and broadening SSM to diverse
use cases.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
