<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-04-21</h1>
<h3>Title: Benchmarking Large Language Models for Calculus Problem-Solving: A Comparative Analysis</h3>
<ul>
<li><strong>Authors: </strong>In Hak Moon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13187">https://arxiv.org/abs/2504.13187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13187">https://arxiv.org/pdf/2504.13187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13187]] Benchmarking Large Language Models for Calculus Problem-Solving: A Comparative Analysis(https://arxiv.org/abs/2504.13187)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study presents a comprehensive evaluation of five leading large language models (LLMs) - Chat GPT 4o, Copilot Pro, Gemini Advanced, Claude Pro, and Meta AI - on their performance in solving calculus differentiation problems. The investigation assessed these models across 13 fundamental problem types, employing a systematic cross-evaluation framework where each model solved problems generated by all models. Results revealed significant performance disparities, with Chat GPT 4o achieving the highest success rate (94.71%), followed by Claude Pro (85.74%), Gemini Advanced (84.42%), Copilot Pro (76.30%), and Meta AI (56.75%). All models excelled at procedural differentiation tasks but showed varying limitations with conceptual understanding and algebraic manipulation. Notably, problems involving increasing/decreasing intervals and optimization word problems proved most challenging across all models. The cross-evaluation matrix revealed that Claude Pro generated the most difficult problems, suggesting distinct capabilities between problem generation and problem-solving. These findings have significant implications for educational applications, highlighting both the potential and limitations of LLMs as calculus learning tools. While they demonstrate impressive procedural capabilities, their conceptual understanding remains limited compared to human mathematical reasoning, emphasizing the continued importance of human instruction for developing deeper mathematical comprehension.</li>
</ul>

<h3>Title: CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent</h3>
<ul>
<li><strong>Authors: </strong>Liang-bo Ning, Shijie Wang, Wenqi Fan, Qing Li, Xin Xu, Hao Chen, Feiran Huang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13192">https://arxiv.org/abs/2504.13192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13192">https://arxiv.org/pdf/2504.13192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13192]] CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent(https://arxiv.org/abs/2504.13192)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.</li>
</ul>

<h3>Title: Investigating cybersecurity incidents using large language models in latest-generation wireless networks</h3>
<ul>
<li><strong>Authors: </strong>Leonid Legashev, Arthur Zhigalov</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13196">https://arxiv.org/abs/2504.13196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13196">https://arxiv.org/pdf/2504.13196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13196]] Investigating cybersecurity incidents using large language models in latest-generation wireless networks(https://arxiv.org/abs/2504.13196)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, explainability, generative, large language model</a></li>
<li><strong>Abstract: </strong>The purpose of research: Detection of cybersecurity incidents and analysis of decision support and assessment of the effectiveness of measures to counter information security threats based on modern generative models. The methods of research: Emulation of signal propagation data in MIMO systems, synthesis of adversarial examples, execution of adversarial attacks on machine learning models, fine tuning of large language models for detecting adversarial attacks, explainability of decisions on detecting cybersecurity incidents based on the prompts technique. Scientific novelty: A binary classification of data poisoning attacks was performed using large language models, and the possibility of using large language models for investigating cybersecurity incidents in the latest generation wireless networks was investigated. The result of research: Fine-tuning of large language models was performed on the prepared data of the emulated wireless network segment. Six large language models were compared for detecting adversarial attacks, and the capabilities of explaining decisions made by a large language model were investigated. The Gemma-7b model showed the best results according to the metrics Precision = 0.89, Recall = 0.89 and F1-Score = 0.89. Based on various explainability prompts, the Gemma-7b model notes inconsistencies in the compromised data under study, performs feature importance analysis and provides various recommendations for mitigating the consequences of adversarial attacks. Large language models integrated with binary classifiers of network threats have significant potential for practical application in the field of cybersecurity incident investigation, decision support and assessing the effectiveness of measures to counter information security threats.</li>
</ul>

<h3>Title: Overcoming Bottlenecks in Homomorphic Encryption for the 2024 Mexican Federal Election</h3>
<ul>
<li><strong>Authors: </strong>Eric Landquist, Nimit Sawhney, Simer Sawhney</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, math.NT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13198">https://arxiv.org/abs/2504.13198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13198">https://arxiv.org/pdf/2504.13198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13198]] Overcoming Bottlenecks in Homomorphic Encryption for the 2024 Mexican Federal Election(https://arxiv.org/abs/2504.13198)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>On June 2, 2024, Mexico held its federal elections. The majority of Mexican citizens voted in person at the polls in this historic election. For the first time though, Mexican citizens living outside their country were able to vote online via a web app, either on a personal device or using an electronic voting kiosk at one of 23 embassies and consulates in the U.S., Canada, and Europe. In total, 144,734 people voted outside of Mexico: 122,496 on a personal device and 22,238 in-person at a kiosk. Voting was open for remote voting from 8PM, May 18, 2024 to 6PM, June 2, 2024 and was open for in-person voting from 8AM-6PM on June 2, 2024. This article describes the technical and cryptographic tools applied to secure the ex-patriate component of the election and to enable INE (Mexico's National Electoral Institute) to generate provable election results within minutes of the close of the election. This article will also describe how the solutions we present scale to elections on a national level.</li>
</ul>

<h3>Title: Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Saleha, Azadeh Tabatabaeib</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13199">https://arxiv.org/abs/2504.13199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13199">https://arxiv.org/pdf/2504.13199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13199]] Building Trustworthy Multimodal AI: A Review of Fairness, Transparency, and Ethics in Vision-Language Tasks(https://arxiv.org/abs/2504.13199)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, explainability</a></li>
<li><strong>Abstract: </strong>Objective: This review explores the trustworthiness of multimodal artificial intelligence (AI) systems, specifically focusing on vision-language tasks. It addresses critical challenges related to fairness, transparency, and ethical implications in these systems, providing a comparative analysis of key tasks such as Visual Question Answering (VQA), image captioning, and visual dialogue. Background: Multimodal models, particularly vision-language models, enhance artificial intelligence (AI) capabilities by integrating visual and textual data, mimicking human learning processes. Despite significant advancements, the trustworthiness of these models remains a crucial concern, particularly as AI systems increasingly confront issues regarding fairness, transparency, and ethics. Methods: This review examines research conducted from 2017 to 2024 focusing on forenamed core vision-language tasks. It employs a comparative approach to analyze these tasks through the lens of trustworthiness, underlining fairness, explainability, and ethics. This study synthesizes findings from recent literature to identify trends, challenges, and state-of-the-art solutions. Results: Several key findings were highlighted. Transparency: Explainability of vision language tasks is important for user trust. Techniques, such as attention maps and gradient-based methods, have successfully addressed this issue. Fairness: Bias mitigation in VQA and visual dialogue systems is essential for ensuring unbiased outcomes across diverse demographic groups. Ethical Implications: Addressing biases in multilingual models and ensuring ethical data handling is critical for the responsible deployment of vision-language systems. Conclusion: This study underscores the importance of integrating fairness, transparency, and ethical considerations in developing vision-language models within a unified framework.</li>
</ul>

<h3>Title: Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI</h3>
<ul>
<li><strong>Authors: </strong>Jirui Yang, Zheyu Lin, Shuhan Yang, Zhihui Lu, Xin Du</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13201">https://arxiv.org/abs/2504.13201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13201">https://arxiv.org/pdf/2504.13201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13201]] Concept Enhancement Engineering: A Lightweight and Efficient Robust Defense Against Jailbreak Attacks in Embodied AI(https://arxiv.org/abs/2504.13201)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Embodied Intelligence (EI) systems integrated with large language models (LLMs) face significant security risks, particularly from jailbreak attacks that manipulate models into generating harmful outputs or executing unsafe physical actions. Traditional defense strategies, such as input filtering and output monitoring, often introduce high computational overhead or interfere with task performance in real-time embodied scenarios. To address these challenges, we propose Concept Enhancement Engineering (CEE), a novel defense framework that leverages representation engineering to enhance the safety of embodied LLMs by dynamically steering their internal activations. CEE operates by (1) extracting multilingual safety patterns from model activations, (2) constructing control directions based on safety-aligned concept subspaces, and (3) applying subspace concept rotation to reinforce safe behavior during inference. Our experiments demonstrate that CEE effectively mitigates jailbreak attacks while maintaining task performance, outperforming existing defense methods in both robustness and efficiency. This work contributes a scalable and interpretable safety mechanism for embodied AI, bridging the gap between theoretical representation engineering and practical security applications. Our findings highlight the potential of latent-space interventions as a viable defense paradigm against emerging adversarial threats in physically grounded AI systems.</li>
</ul>

<h3>Title: X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents</h3>
<ul>
<li><strong>Authors: </strong>Salman Rahman, Liwei Jiang, James Shiffer, Genglin Liu, Sheriff Issaka, Md Rizwan Parvez, Hamid Palangi, Kai-Wei Chang, Yejin Choi, Saadia Gabriel</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13203">https://arxiv.org/abs/2504.13203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13203">https://arxiv.org/pdf/2504.13203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13203]] X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents(https://arxiv.org/abs/2504.13203)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-teaming. To address these challenges, we present X-Teaming, a scalable framework that systematically explores how seemingly harmless interactions escalate into harmful outcomes and generates corresponding attack scenarios. X-Teaming employs collaborative agents for planning, attack optimization, and verification, achieving state-of-the-art multi-turn jailbreak effectiveness and diversity with success rates up to 98.1% across representative leading open-weight and closed-source models. In particular, X-Teaming achieves a 96.2% attack success rate against the latest Claude 3.7 Sonnet model, which has been considered nearly immune to single-turn attacks. Building on X-Teaming, we introduce XGuard-Train, an open-source multi-turn safety training dataset that is 20x larger than the previous best resource, comprising 30K interactive jailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our work offers essential tools and insights for mitigating sophisticated conversational attacks, advancing the multi-turn safety of LMs.</li>
</ul>

<h3>Title: On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Houssam Kherraz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13205">https://arxiv.org/abs/2504.13205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13205">https://arxiv.org/pdf/2504.13205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13205]] On-Device Watermarking: A Socio-Technical Imperative For Authenticity In The Age of Generative AI(https://arxiv.org/abs/2504.13205)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, watermark, generative</a></li>
<li><strong>Abstract: </strong>As generative AI models produce increasingly realistic output, both academia and industry are focusing on the ability to detect whether an output was generated by an AI model or not. Many of the research efforts and policy discourse are centered around robust watermarking of AI outputs. While plenty of progress has been made, all watermarking and AI detection techniques face severe limitations. In this position paper, we argue that we are adopting the wrong approach, and should instead focus on watermarking via cryptographic signatures trustworthy content rather than AI generated ones. For audio-visual content, in particular, all real content is grounded in the physical world and captured via hardware sensors. This presents a unique opportunity to watermark at the hardware layer, and we lay out a socio-technical framework and draw parallels with HTTPS certification and Blu-Ray verification protocols. While acknowledging implementation challenges, we contend that hardware-based authentication offers a more tractable path forward, particularly from a policy perspective. As generative models approach perceptual indistinguishability, the research community should be wary of being overly optimistic with AI watermarking, and we argue that AI watermarking research efforts are better spent in the text and LLM space, which are ultimately not traceable to a physical sensor.</li>
</ul>

<h3>Title: Intelligent road crack detection and analysis based on improved YOLOv8</h3>
<ul>
<li><strong>Authors: </strong>Haomin Zuo, Zhengyang Li, Jiangchuan Gong, Zhen Tian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13208">https://arxiv.org/abs/2504.13208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13208">https://arxiv.org/pdf/2504.13208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13208]] Intelligent road crack detection and analysis based on improved YOLOv8(https://arxiv.org/abs/2504.13208)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>As urbanization speeds up and traffic flow increases, the issue of pavement distress is becoming increasingly pronounced, posing a severe threat to road safety and service life. Traditional methods of pothole detection rely on manual inspection, which is not only inefficient but also costly. This paper proposes an intelligent road crack detection and analysis system, based on the enhanced YOLOv8 deep learning framework. A target segmentation model has been developed through the training of 4029 images, capable of efficiently and accurately recognizing and segmenting crack regions in roads. The model also analyzes the segmented regions to precisely calculate the maximum and minimum widths of cracks and their exact locations. Experimental results indicate that the incorporation of ECA and CBAM attention mechanisms substantially enhances the model's detection accuracy and efficiency, offering a novel solution for road maintenance and safety monitoring.</li>
</ul>

<h3>Title: On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks</h3>
<ul>
<li><strong>Authors: </strong>Ting Bi, Chenghang Ye, Zheyu Yang, Ziyi Zhou, Cui Tang, Jun Zhang, Zui Tao, Kailong Wang, Liting Zhou, Yang Yang, Tianlong Yu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13209">https://arxiv.org/abs/2504.13209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13209">https://arxiv.org/pdf/2504.13209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13209]] On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks(https://arxiv.org/abs/2504.13209)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Augmented Reality (AR) and Multimodal Large Language Models (LLMs) are rapidly evolving, providing unprecedented capabilities for human-computer interaction. However, their integration introduces a new attack surface for social engineering. In this paper, we systematically investigate the feasibility of orchestrating AR-driven Social Engineering attacks using Multimodal LLM for the first time, via our proposed SEAR framework, which operates through three key phases: (1) AR-based social context synthesis, which fuses Multimodal inputs (visual, auditory and environmental cues); (2) role-based Multimodal RAG (Retrieval-Augmented Generation), which dynamically retrieves and integrates contextual data while preserving character differentiation; and (3) ReInteract social engineering agents, which execute adaptive multiphase attack strategies through inference interaction loops. To verify SEAR, we conducted an IRB-approved study with 60 participants in three experimental configurations (unassisted, AR+LLM, and full SEAR pipeline) compiling a new dataset of 180 annotated conversations in simulated social scenarios. Our results show that SEAR is highly effective at eliciting high-risk behaviors (e.g., 93.3% of participants susceptible to email phishing). The framework was particularly effective in building trust, with 85% of targets willing to accept an attacker's call after an interaction. Also, we identified notable limitations such as ``occasionally artificial'' due to perceived authenticity gaps. This work provides proof-of-concept for AR-LLM driven social engineering attacks and insights for developing defensive countermeasures against next-generation augmented reality threats.</li>
</ul>

<h3>Title: Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance</h3>
<ul>
<li><strong>Authors: </strong>Subin Kim, Hoonrae Kim, Jihyun Lee, Yejin Jeon, Gary Geunbae Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13211">https://arxiv.org/abs/2504.13211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13211">https://arxiv.org/pdf/2504.13211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13211]] Mirror: Multimodal Cognitive Reframing Therapy for Rolling with Resistance(https://arxiv.org/abs/2504.13211)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies have explored the use of large language models (LLMs) in psychotherapy; however, text-based cognitive behavioral therapy (CBT) models often struggle with client resistance, which can weaken therapeutic alliance. To address this, we propose a multimodal approach that incorporates nonverbal cues, allowing the AI therapist to better align its responses with the client's negative emotional state. Specifically, we introduce a new synthetic dataset, Multimodal Interactive Rolling with Resistance (Mirror), which is a novel synthetic dataset that pairs client statements with corresponding facial images. Using this dataset, we train baseline Vision-Language Models (VLMs) that can analyze facial cues, infer emotions, and generate empathetic responses to effectively manage resistance. They are then evaluated in terms of both the therapist's counseling skills and the strength of the therapeutic alliance in the presence of client resistance. Our results demonstrate that Mirror significantly enhances the AI therapist's ability to handle resistance, which outperforms existing text-based CBT approaches.</li>
</ul>

<h3>Title: I Know What You Bought Last Summer: Investigating User Data Leakage in E-Commerce Platforms</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Vlachogiannakis, Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Nicolas Kourtellis, Evangelos Markatos</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13212">https://arxiv.org/abs/2504.13212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13212">https://arxiv.org/pdf/2504.13212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13212]] I Know What You Bought Last Summer: Investigating User Data Leakage in E-Commerce Platforms(https://arxiv.org/abs/2504.13212)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy</a></li>
<li><strong>Abstract: </strong>In the digital age, e-commerce has transformed the way consumers shop, offering convenience and accessibility. Nevertheless, concerns about the privacy and security of personal information shared on these platforms have risen. In this work, we investigate user privacy violations, noting the risks of data leakage to third-party entities. Utilizing a semi-automated data collection approach, we examine a selection of popular online e-shops, revealing that nearly 30% of them violate user privacy by disclosing personal information to third parties. We unveil how minimal user interaction across multiple e-commerce websites can result in a comprehensive privacy breach. We observe significant data-sharing patterns with platforms like Facebook, which use personal information to build user profiles and link them to social media accounts.</li>
</ul>

<h3>Title: Wavelet-based Variational Autoencoders for High-Resolution Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Andrew Kiruluta</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13214">https://arxiv.org/abs/2504.13214</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13214">https://arxiv.org/pdf/2504.13214</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13214]] Wavelet-based Variational Autoencoders for High-Resolution Image Generation(https://arxiv.org/abs/2504.13214)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Variational Autoencoders (VAEs) are powerful generative models capable of learning compact latent representations. However, conventional VAEs often generate relatively blurry images due to their assumption of an isotropic Gaussian latent space and constraints in capturing high-frequency details. In this paper, we explore a novel wavelet-based approach (Wavelet-VAE) in which the latent space is constructed using multi-scale Haar wavelet coefficients. We propose a comprehensive method to encode the image features into multi-scale detail and approximation coefficients and introduce a learnable noise parameter to maintain stochasticity. We thoroughly discuss how to reformulate the reparameterization trick, address the KL divergence term, and integrate wavelet sparsity principles into the training objective. Our experimental evaluation on CIFAR-10 and other high-resolution datasets demonstrates that the Wavelet-VAE improves visual fidelity and recovers higher-resolution details compared to conventional VAEs. We conclude with a discussion of advantages, potential limitations, and future research directions for wavelet-based generative modeling.</li>
</ul>

<h3>Title: KFinEval-Pilot: A Comprehensive Benchmark Suite for Korean Financial Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Bokwang Hwang, Seonkyu Lim, Taewoong Kim, Yongjae Geun, Sunghyun Bang, Sohyun Park, Jihyun Park, Myeonggyu Lee, Jinwoo Lee, Yerin Kim, Jinsun Yoo, Jingyeong Hong, Jina Park, Yongchan Kim, Suhyun Kim, Younggyun Hahm, Yiseul Lee, Yejee Kang, Chanhyuk Yoon, Chansu Lee, Heeyewon Jeong, Jiyeon Lee, Seonhye Gu, Hyebin Kang, Yousang Cho, Hangyeol Yoo, KyungTae Lim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13216">https://arxiv.org/abs/2504.13216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13216">https://arxiv.org/pdf/2504.13216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13216]] KFinEval-Pilot: A Comprehensive Benchmark Suite for Korean Financial Language Understanding(https://arxiv.org/abs/2504.13216)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce KFinEval-Pilot, a benchmark suite specifically designed to evaluate large language models (LLMs) in the Korean financial domain. Addressing the limitations of existing English-centric benchmarks, KFinEval-Pilot comprises over 1,000 curated questions across three critical areas: financial knowledge, legal reasoning, and financial toxicity. The benchmark is constructed through a semi-automated pipeline that combines GPT-4-generated prompts with expert validation to ensure domain relevance and factual accuracy. We evaluate a range of representative LLMs and observe notable performance differences across models, with trade-offs between task accuracy and output safety across different model families. These results highlight persistent challenges in applying LLMs to high-stakes financial applications, particularly in reasoning and safety. Grounded in real-world financial use cases and aligned with the Korean regulatory and linguistic context, KFinEval-Pilot serves as an early diagnostic tool for developing safer and more reliable financial AI systems.</li>
</ul>

<h3>Title: Sustainability via LLM Right-sizing</h3>
<ul>
<li><strong>Authors: </strong>Jennifer Haase, Finn Klessascheck, Jan Mendling, Sebastian Pokutta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13217">https://arxiv.org/abs/2504.13217</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13217">https://arxiv.org/pdf/2504.13217</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13217]] Sustainability via LLM Right-sizing(https://arxiv.org/abs/2504.13217)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become increasingly embedded in organizational workflows. This has raised concerns over their energy consumption, financial costs, and data sovereignty. While performance benchmarks often celebrate cutting-edge models, real-world deployment decisions require a broader perspective: when is a smaller, locally deployable model "good enough"? This study offers an empirical answer by evaluating eleven proprietary and open-weight LLMs across ten everyday occupational tasks, including summarizing texts, generating schedules, and drafting emails and proposals. Using a dual-LLM-based evaluation framework, we automated task execution and standardized evaluation across ten criteria related to output quality, factual accuracy, and ethical responsibility. Results show that GPT-4o delivers consistently superior performance but at a significantly higher cost and environmental footprint. Notably, smaller models like Gemma-3 and Phi-4 achieved strong and reliable results on most tasks, suggesting their viability in contexts requiring cost-efficiency, local deployment, or privacy. A cluster analysis revealed three model groups -- premium all-rounders, competent generalists, and limited but safe performers -- highlighting trade-offs between quality, control, and sustainability. Significantly, task type influenced model effectiveness: conceptual tasks challenged most models, while aggregation and transformation tasks yielded better performances. We argue for a shift from performance-maximizing benchmarks to task- and context-aware sufficiency assessments that better reflect organizational priorities. Our approach contributes a scalable method to evaluate AI models through a sustainability lens and offers actionable guidance for responsible LLM deployment in practice.</li>
</ul>

<h3>Title: SSTAF: Spatial-Spectral-Temporal Attention Fusion Transformer for Motor Imagery Classification</h3>
<ul>
<li><strong>Authors: </strong>Ummay Maria Muna, Md. Mehedi Hasan Shawon, Md Jobayer, Sumaiya Akter, Saifur Rahman Sabuj</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13220">https://arxiv.org/abs/2504.13220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13220">https://arxiv.org/pdf/2504.13220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13220]] SSTAF: Spatial-Spectral-Temporal Attention Fusion Transformer for Motor Imagery Classification(https://arxiv.org/abs/2504.13220)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Brain-computer interfaces (BCI) in electroencephalography (EEG)-based motor imagery classification offer promising solutions in neurorehabilitation and assistive technologies by enabling communication between the brain and external devices. However, the non-stationary nature of EEG signals and significant inter-subject variability cause substantial challenges for developing robust cross-subject classification models. This paper introduces a novel Spatial-Spectral-Temporal Attention Fusion (SSTAF) Transformer specifically designed for upper-limb motor imagery classification. Our architecture consists of a spectral transformer and a spatial transformer, followed by a transformer block and a classifier network. Each module is integrated with attention mechanisms that dynamically attend to the most discriminative patterns across multiple domains, such as spectral frequencies, spatial electrode locations, and temporal dynamics. The short-time Fourier transform is incorporated to extract features in the time-frequency domain to make it easier for the model to obtain a better feature distinction. We evaluated our SSTAF Transformer model on two publicly available datasets, the EEGMMIDB dataset, and BCI Competition IV-2a. SSTAF Transformer achieves an accuracy of 76.83% and 68.30% in the data sets, respectively, outperforms traditional CNN-based architectures and a few existing transformer-based approaches.</li>
</ul>

<h3>Title: ICAS: IP Adapter and ControlNet-based Attention Structure for Multi-Subject Style Transfer Optimization</h3>
<ul>
<li><strong>Authors: </strong>Fuwei Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13224">https://arxiv.org/abs/2504.13224</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13224">https://arxiv.org/pdf/2504.13224</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13224]] ICAS: IP Adapter and ControlNet-based Attention Structure for Multi-Subject Style Transfer Optimization(https://arxiv.org/abs/2504.13224)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generating multi-subject stylized images remains a significant challenge due to the ambiguity in defining style attributes (e.g., color, texture, atmosphere, and structure) and the difficulty in consistently applying them across multiple subjects. Although recent diffusion-based text-to-image models have achieved remarkable progress, existing methods typically rely on computationally expensive inversion procedures or large-scale stylized datasets. Moreover, these methods often struggle with maintaining multi-subject semantic fidelity and are limited by high inference costs. To address these limitations, we propose ICAS (IP-Adapter and ControlNet-based Attention Structure), a novel framework for efficient and controllable multi-subject style transfer. Instead of full-model tuning, ICAS adaptively fine-tunes only the content injection branch of a pre-trained diffusion model, thereby preserving identity-specific semantics while enhancing style controllability. By combining IP-Adapter for adaptive style injection with ControlNet for structural conditioning, our framework ensures faithful global layout preservation alongside accurate local style synthesis. Furthermore, ICAS introduces a cyclic multi-subject content embedding mechanism, which enables effective style transfer under limited-data settings without the need for extensive stylized corpora. Extensive experiments show that ICAS achieves superior performance in structure preservation, style consistency, and inference efficiency, establishing a new paradigm for multi-subject style transfer in real-world applications.</li>
</ul>

<h3>Title: DIDS: Domain Impact-aware Data Sampling for Large Language Model Training</h3>
<ul>
<li><strong>Authors: </strong>Weijie Shi, Jipeng Zhang, Yaguang Wu, Jingzhi Fang, Ruiyuan Zhang, Jiajie Xu, Jia Zhu, Hao Chen, Yao Zhao, Sirui Han, Xiaofang Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13227">https://arxiv.org/abs/2504.13227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13227">https://arxiv.org/pdf/2504.13227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13227]] DIDS: Domain Impact-aware Data Sampling for Large Language Model Training(https://arxiv.org/abs/2504.13227)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are commonly trained on multi-domain datasets, where domain sampling strategies significantly impact model performance due to varying domain importance across downstream tasks. Existing approaches for optimizing domain-level sampling strategies struggle with maintaining intra-domain consistency and accurately measuring domain impact. In this paper, we present Domain Impact-aware Data Sampling (DIDS). To ensure intra-domain consistency, a gradient clustering algorithm is proposed to group training data based on their learning effects, where a proxy language model and dimensionality reduction are employed to reduce computational overhead. To accurately measure domain impact, we develop a Fisher Information Matrix (FIM) guided metric that quantifies how domain-specific parameter updates affect the model's output distributions on downstream tasks, with theoretical guarantees. Furthermore, to determine optimal sampling ratios, DIDS combines both the FIM-guided domain impact assessment and loss learning trajectories that indicate domain-specific potential, while accounting for diminishing marginal returns. Extensive experiments demonstrate that DIDS achieves 3.4% higher average performance while maintaining comparable training efficiency.</li>
</ul>

<h3>Title: Modelling Mean-Field Games with Neural Ordinary Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Anna C.M. Th√∂ni, Yoram Bachrach, Tal Kachman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13228">https://arxiv.org/abs/2504.13228</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13228">https://arxiv.org/pdf/2504.13228</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13228]] Modelling Mean-Field Games with Neural Ordinary Differential Equations(https://arxiv.org/abs/2504.13228)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Mean-field game theory relies on approximating games that would otherwise have been intractable to model. While the games can be solved analytically via the associated system of partial derivatives, this approach is not model-free, can lead to the loss of the existence or uniqueness of solutions and may suffer from modelling bias. To reduce the dependency between the model and the game, we combine mean-field game theory with deep learning in the form of neural ordinary differential equations. The resulting model is data-driven, lightweight and can learn extensive strategic interactions that are hard to capture using mean-field theory alone. In addition, the model is based on automatic differentiation, making it more robust and objective than approaches based on finite differences. We highlight the efficiency and flexibility of our approach by solving three mean-field games that vary in their complexity, observability and the presence of noise. Using these results, we show that the model is flexible, lightweight and requires few observations to learn the distribution underlying the data.</li>
</ul>

<h3>Title: PSG-MAE: Robust Multitask Sleep Event Monitoring using Multichannel PSG Reconstruction and Inter-channel Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Yifei Wang, Qi Liu, Fuli Min, Honghao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13229">https://arxiv.org/abs/2504.13229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13229">https://arxiv.org/pdf/2504.13229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13229]] PSG-MAE: Robust Multitask Sleep Event Monitoring using Multichannel PSG Reconstruction and Inter-channel Contrastive Learning(https://arxiv.org/abs/2504.13229)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Polysomnography (PSG) signals are essential for studying sleep processes and diagnosing sleep disorders. Analyzing PSG data through deep neural networks (DNNs) for automated sleep monitoring has become increasingly feasible. However, the limited availability of datasets for certain sleep events often leads to DNNs focusing on a single task with a single-sourced training dataset. As a result, these models struggle to transfer to new sleep events and lack robustness when applied to new datasets. To address these challenges, we propose PSG-MAE, a mask autoencoder (MAE) based pre-training framework. By performing self-supervised learning on a large volume of unlabeled PSG data, PSG-MAE develops a robust feature extraction network that can be broadly applied to various sleep event monitoring tasks. Unlike conventional MAEs, PSG-MAE generates complementary masks across PSG channels, integrates a multichannel signal reconstruction method, and employs a self-supervised inter-channel contrastive learning (ICCL) strategy. This approach enables the encoder to capture temporal features from each channel while simultaneously learning latent relationships between channels, thereby enhancing the utilization of multichannel information. Experimental results show that PSG-MAE effectively captures both temporal details and inter-channel information from PSG signals. When the encoder pre-trained through PSG-MAE is fine-tuned with downstream feature decomposition networks, it achieves an accuracy of 83.7% for sleep staging and 90.45% for detecting obstructive sleep apnea, which highlights the framework's robustness and broad applicability.</li>
</ul>

<h3>Title: Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms</h3>
<ul>
<li><strong>Authors: </strong>Alireza Rafiei, Gari D. Clifford, Nasim Katebi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13233">https://arxiv.org/abs/2504.13233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13233">https://arxiv.org/pdf/2504.13233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13233]] Auto-FEDUS: Autoregressive Generative Modeling of Doppler Ultrasound Signals from Fetal Electrocardiograms(https://arxiv.org/abs/2504.13233)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Fetal health monitoring through one-dimensional Doppler ultrasound (DUS) signals offers a cost-effective and accessible approach that is increasingly gaining interest. Despite its potential, the development of machine learning based techniques to assess the health condition of mothers and fetuses using DUS signals remains limited. This scarcity is primarily due to the lack of extensive DUS datasets with a reliable reference for interpretation and data imbalance across different gestational ages. In response, we introduce a novel autoregressive generative model designed to map fetal electrocardiogram (FECG) signals to corresponding DUS waveforms (Auto-FEDUS). By leveraging a neural temporal network based on dilated causal convolutions that operate directly on the waveform level, the model effectively captures both short and long-range dependencies within the signals, preserving the integrity of generated data. Cross-subject experiments demonstrate that Auto-FEDUS outperforms conventional generative architectures across both time and frequency domain evaluations, producing DUS signals that closely resemble the morphology of their real counterparts. The realism of these synthesized signals was further gauged using a quality assessment model, which classified all as good quality, and a heart rate estimation model, which produced comparable results for generated and real data, with a Bland-Altman limit of 4.5 beats per minute. This advancement offers a promising solution for mitigating limited data availability and enhancing the training of DUS-based fetal models, making them more effective and generalizable.</li>
</ul>

<h3>Title: Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanyu Zhang, Zhen Xing, Wenxuan Yang, Chenxi Ma, Weimin Tan, Bo Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13234">https://arxiv.org/abs/2504.13234</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13234">https://arxiv.org/pdf/2504.13234</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13234]] Non-Uniform Class-Wise Coreset Selection: Characterizing Category Difficulty for Data-Efficient Transfer Learning(https://arxiv.org/abs/2504.13234)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>As transfer learning models and datasets grow larger, efficient adaptation and storage optimization have become critical needs. Coreset selection addresses these challenges by identifying and retaining the most informative samples, constructing a compact subset for target domain training. However, current methods primarily rely on instance-level difficulty assessments, overlooking crucial category-level characteristics and consequently under-representing minority classes. To overcome this limitation, we propose Non-Uniform Class-Wise Coreset Selection (NUCS), a novel framework that integrates both class-level and instance-level criteria. NUCS automatically allocates data selection budgets for each class based on intrinsic category difficulty and adaptively selects samples within optimal difficulty ranges. By explicitly incorporating category-specific insights, our approach achieves a more balanced and representative coreset, addressing key shortcomings of prior methods. Comprehensive theoretical analysis validates the rationale behind adaptive budget allocation and sample selection, while extensive experiments across 14 diverse datasets and model architectures demonstrate NUCS's consistent improvements over state-of-the-art methods, achieving superior accuracy and computational efficiency. Notably, on CIFAR100 and Food101, NUCS matches full-data training accuracy while retaining just 30% of samples and reducing computation time by 60%. Our work highlights the importance of characterizing category difficulty in coreset selection, offering a robust and data-efficient solution for transfer learning.</li>
</ul>

<h3>Title: NNTile: a machine learning framework capable of training extremely large GPT language models on a single node</h3>
<ul>
<li><strong>Authors: </strong>Aleksandr Mikhalev, Aleksandr Katrutsa, Konstantin Sozykin, Ivan Oseledets</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13236">https://arxiv.org/abs/2504.13236</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13236">https://arxiv.org/pdf/2504.13236</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13236]] NNTile: a machine learning framework capable of training extremely large GPT language models on a single node(https://arxiv.org/abs/2504.13236)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study presents an NNTile framework for training large deep neural networks in heterogeneous clusters. The NNTile is based on a StarPU library, which implements task-based parallelism and schedules all provided tasks onto all available processing units (CPUs and GPUs). It means that a particular operation, necessary to train a large neural network, can be performed on any of the CPU cores or GPU devices, depending on automatic scheduling decisions. Such an approach shifts the burden of deciding where to compute and when to communicate from a human being to an automatic decision maker, whether a simple greedy heuristic or a complex AI-based software. The performance of the presented tool for training large language models is demonstrated in extensive numerical experiments.</li>
</ul>

<h3>Title: ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yan Yang, Yixia Li, Hongru Wang, Xuetao Wei, Jianqiao Yu, Yun Chen, Guanhua Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13237">https://arxiv.org/abs/2504.13237</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13237">https://arxiv.org/pdf/2504.13237</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13237]] ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs(https://arxiv.org/abs/2504.13237)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the proliferation of task-specific large language models, delta compression has emerged as a method to mitigate the resource challenges of deploying numerous such models by effectively compressing the delta model parameters. Previous delta-sparsification methods either remove parameters randomly or truncate singular vectors directly after singular value decomposition (SVD). However, these methods either disregard parameter importance entirely or evaluate it with too coarse a granularity. In this work, we introduce ImPart, a novel importance-aware delta sparsification approach. Leveraging SVD, it dynamically adjusts sparsity ratios of different singular vectors based on their importance, effectively retaining crucial task-specific knowledge even at high sparsity ratios. Experiments show that ImPart achieves state-of-the-art delta sparsification performance, demonstrating $2\times$ higher compression ratio than baselines at the same performance level. When integrated with existing methods, ImPart sets a new state-of-the-art on delta quantization and model merging.</li>
</ul>

<h3>Title: Recursive Deep Inverse Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Paul Ghanem, Michael Potter, Owen Howell, Pau Closas, Alireza Ramezani, Deniz Erdogmus, Robert Platt, Tales Imbiriba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13241">https://arxiv.org/abs/2504.13241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13241">https://arxiv.org/pdf/2504.13241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13241]] Recursive Deep Inverse Reinforcement Learning(https://arxiv.org/abs/2504.13241)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.</li>
</ul>

<h3>Title: Dynamic Memory-enhanced Transformer for Hyperspectral Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ahmad, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13242">https://arxiv.org/abs/2504.13242</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13242">https://arxiv.org/pdf/2504.13242</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13242]] Dynamic Memory-enhanced Transformer for Hyperspectral Image Classification(https://arxiv.org/abs/2504.13242)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Hyperspectral image (HSI) classification remains a challenging task due to the intricate spatial-spectral correlations. Existing transformer models excel in capturing long-range dependencies but often suffer from information redundancy and attention inefficiencies, limiting their ability to model fine-grained relationships crucial for HSI classification. To overcome these limitations, this work proposes MemFormer, a lightweight and memory-enhanced transformer. MemFormer introduces a memory-enhanced multi-head attention mechanism that iteratively refines a dynamic memory module, enhancing feature extraction while reducing redundancy across layers. Additionally, a dynamic memory enrichment strategy progressively captures complex spatial and spectral dependencies, leading to more expressive feature representations. To further improve structural consistency, we incorporate a spatial-spectral positional encoding (SSPE) tailored for HSI data, ensuring continuity without the computational burden of convolution-based approaches. Extensive experiments on benchmark datasets demonstrate that MemFormer achieves superior classification accuracy, outperforming state-of-the-art methods.</li>
</ul>

<h3>Title: CPG-EVAL: A Multi-Tiered Benchmark for Evaluating the Chinese Pedagogical Grammar Competence of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Dong Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13261">https://arxiv.org/abs/2504.13261</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13261">https://arxiv.org/pdf/2504.13261</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13261]] CPG-EVAL: A Multi-Tiered Benchmark for Evaluating the Chinese Pedagogical Grammar Competence of Large Language Models(https://arxiv.org/abs/2504.13261)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Purpose: The rapid emergence of large language models (LLMs) such as ChatGPT has significantly impacted foreign language education, yet their pedagogical grammar competence remains under-assessed. This paper introduces CPG-EVAL, the first dedicated benchmark specifically designed to evaluate LLMs' knowledge of pedagogical grammar within the context of foreign language instruction. Methodology: The benchmark comprises five tasks designed to assess grammar recognition, fine-grained grammatical distinction, categorical discrimination, and resistance to linguistic interference. Findings: Smaller-scale models can succeed in single language instance tasks, but struggle with multiple instance tasks and interference from confusing instances. Larger-scale models show better resistance to interference but still have significant room for accuracy improvement. The evaluation indicates the need for better instructional alignment and more rigorous benchmarks, to effectively guide the deployment of LLMs in educational contexts. Value: This study offers the first specialized, theory-driven, multi-tiered benchmark framework for systematically evaluating LLMs' pedagogical grammar competence in Chinese language teaching contexts. CPG-EVAL not only provides empirical insights for educators, policymakers, and model developers to better gauge AI's current abilities in educational settings, but also lays the groundwork for future research on improving model alignment, enhancing educational suitability, and ensuring informed decision-making concerning LLM integration in foreign language instruction.</li>
</ul>

<h3>Title: Leveraging Functional Encryption and Deep Learning for Privacy-Preserving Traffic Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Isaac Adom, Mohammmad Iqbal Hossain, Hassan Mahmoud, Ahmad Alsharif, Mahmoud Nabil Mahmoud, Yang Xiao</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13267">https://arxiv.org/abs/2504.13267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13267">https://arxiv.org/pdf/2504.13267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13267]] Leveraging Functional Encryption and Deep Learning for Privacy-Preserving Traffic Forecasting(https://arxiv.org/abs/2504.13267)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, protect</a></li>
<li><strong>Abstract: </strong>Over the past few years, traffic congestion has continuously plagued the nation's transportation system creating several negative impacts including longer travel times, increased pollution rates, and higher collision risks. To overcome these challenges, Intelligent Transportation Systems (ITS) aim to improve mobility and vehicular systems, ensuring higher levels of safety by utilizing cutting-edge technologies, sophisticated sensing capabilities, and innovative algorithms. Drivers' participatory sensing, current/future location reporting, and machine learning algorithms have considerably improved real-time congestion monitoring and future traffic management. However, each driver's sensitive spatiotemporal location information can create serious privacy concerns. To address these challenges, we propose in this paper a secure, privacy-preserving location reporting and traffic forecasting system that guarantees privacy protection of driver data while maintaining high traffic forecasting accuracy. Our novel k-anonymity scheme utilizes functional encryption to aggregate encrypted location information submitted by drivers while ensuring the privacy of driver location data. Additionally, using the aggregated encrypted location information as input, this research proposes a deep learning model that incorporates a Convolutional-Long Short-Term Memory (Conv-LSTM) module to capture spatial and short-term temporal features and a Bidirectional Long Short-Term Memory (Bi-LSTM) module to recover long-term periodic patterns for traffic forecasting. With extensive evaluation on real datasets, we demonstrate the effectiveness of the proposed scheme with less than 10% mean absolute error for a 60-minute forecasting horizon, all while protecting driver privacy.</li>
</ul>

<h3>Title: Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model</h3>
<ul>
<li><strong>Authors: </strong>Zhiwei Xu, Zhiyu Ni, Yixin Wang, Wei Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13292">https://arxiv.org/abs/2504.13292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13292">https://arxiv.org/pdf/2504.13292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13292]] Let Me Grok for You: Accelerating Grokking via Embedding Transfer from a Weaker Model(https://arxiv.org/abs/2504.13292)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>''Grokking'' is a phenomenon where a neural network first memorizes training data and generalizes poorly, but then suddenly transitions to near-perfect generalization after prolonged training. While intriguing, this delayed generalization phenomenon compromises predictability and efficiency. Ideally, models should generalize directly without delay. To this end, this paper proposes GrokTransfer, a simple and principled method for accelerating grokking in training neural networks, based on the key observation that data embedding plays a crucial role in determining whether generalization is delayed. GrokTransfer first trains a smaller, weaker model to reach a nontrivial (but far from optimal) test performance. Then, the learned input embedding from this weaker model is extracted and used to initialize the embedding in the target, stronger model. We rigorously prove that, on a synthetic XOR task where delayed generalization always occurs in normal training, GrokTransfer enables the target model to generalize directly without delay. Moreover, we demonstrate that, across empirical studies of different tasks, GrokTransfer effectively reshapes the training dynamics and eliminates delayed generalization, for both fully-connected neural networks and Transformers.</li>
</ul>

<h3>Title: DYNAMITE: Dynamic Defense Selection for Enhancing Machine Learning-based Intrusion Detection Against Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jing Chen, Onat Gungor, Zhengli Shang, Elvin Li, Tajana Rosing</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13301">https://arxiv.org/abs/2504.13301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13301">https://arxiv.org/pdf/2504.13301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13301]] DYNAMITE: Dynamic Defense Selection for Enhancing Machine Learning-based Intrusion Detection Against Adversarial Attacks(https://arxiv.org/abs/2504.13301)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of the Internet of Things (IoT) has introduced substantial security vulnerabilities, highlighting the need for robust Intrusion Detection Systems (IDS). Machine learning-based intrusion detection systems (ML-IDS) have significantly improved threat detection capabilities; however, they remain highly susceptible to adversarial attacks. While numerous defense mechanisms have been proposed to enhance ML-IDS resilience, a systematic approach for selecting the most effective defense against a specific adversarial attack remains absent. To address this challenge, we propose Dynamite, a dynamic defense selection framework that enhances ML-IDS by intelligently identifying and deploying the most suitable defense using a machine learning-driven selection mechanism. Our results demonstrate that Dynamite achieves a 96.2% reduction in computational time compared to the Oracle, significantly decreasing computational overhead while preserving strong prediction performance. Dynamite also demonstrates an average F1-score improvement of 76.7% over random defense and 65.8% over the best static state-of-the-art defense.</li>
</ul>

<h3>Title: SAR Object Detection with Self-Supervised Pretraining and Curriculum-Aware Sampling</h3>
<ul>
<li><strong>Authors: </strong>Yasin Almalioglu, Andrzej Kucik, Geoffrey French, Dafni Antotsiou, Alexander Adam, Cedric Archambeau</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13310">https://arxiv.org/abs/2504.13310</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13310">https://arxiv.org/pdf/2504.13310</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13310]] SAR Object Detection with Self-Supervised Pretraining and Curriculum-Aware Sampling(https://arxiv.org/abs/2504.13310)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Object detection in satellite-borne Synthetic Aperture Radar (SAR) imagery holds immense potential in tasks such as urban monitoring and disaster response. However, the inherent complexities of SAR data and the scarcity of annotations present significant challenges in the advancement of object detection in this domain. Notably, the detection of small objects in satellite-borne SAR images poses a particularly intricate problem, because of the technology's relatively low spatial resolution and inherent noise. Furthermore, the lack of large labelled SAR datasets hinders the development of supervised deep learning-based object detection models. In this paper, we introduce TRANSAR, a novel self-supervised end-to-end vision transformer-based SAR object detection model that incorporates masked image pre-training on an unlabeled SAR image dataset that spans more than $25,700$ km\textsuperscript{2} ground area. Unlike traditional object detection formulation, our approach capitalises on auxiliary binary semantic segmentation, designed to segregate objects of interest during the post-tuning, especially the smaller ones, from the background. In addition, to address the innate class imbalance due to the disproportion of the object to the image size, we introduce an adaptive sampling scheduler that dynamically adjusts the target class distribution during training based on curriculum learning and model feedback. This approach allows us to outperform conventional supervised architecture such as DeepLabv3 or UNet, and state-of-the-art self-supervised learning-based arhitectures such as DPT, SegFormer or UperNet, as shown by extensive evaluations on benchmark SAR datasets.</li>
</ul>

<h3>Title: GraphQLer: Enhancing GraphQL Security with Context-Aware API Testing</h3>
<ul>
<li><strong>Authors: </strong>Omar Tsai, Jianing Li, Tsz Tung Cheung, Lejing Huang, Hao Zhu, Jianrui Xiao, Iman Sharafaldin, Mohammad A. Tayebi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13358">https://arxiv.org/abs/2504.13358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13358">https://arxiv.org/pdf/2504.13358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13358]] GraphQLer: Enhancing GraphQL Security with Context-Aware API Testing(https://arxiv.org/abs/2504.13358)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>GraphQL is an open-source data query and manipulation language for web applications, offering a flexible alternative to RESTful APIs. However, its dynamic execution model and lack of built-in security mechanisms expose it to vulnerabilities such as unauthorized data access, denial-of-service (DoS) attacks, and injections. Existing testing tools focus on functional correctness, often overlooking security risks stemming from query interdependencies and execution context. This paper presents GraphQLer, the first context-aware security testing framework for GraphQL APIs. GraphQLer constructs a dependency graph to analyze relationships among mutations, queries, and objects, capturing critical interdependencies. It chains related queries and mutations to reveal authentication and authorization flaws, access control bypasses, and resource misuse. Additionally, GraphQLer tracks internal resource usage to uncover data leakage, privilege escalation, and replay attack vectors. We assess GraphQLer on various GraphQL APIs, demonstrating improved testing coverage - averaging a 35% increase, with up to 84% in some cases - compared to top-performing baselines. Remarkably, this is achieved in less time, making GraphQLer suitable for time-sensitive contexts. GraphQLer also successfully detects a known CVE and potential vulnerabilities in large-scale production APIs. These results underline GraphQLer's utility in proactively securing GraphQL APIs through automated, context-aware vulnerability detection.</li>
</ul>

<h3>Title: VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture</h3>
<ul>
<li><strong>Authors: </strong>Long Li, Jiajia Li, Dong Chen, Lina Pu, Haibo Yao, Yanbo Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13365">https://arxiv.org/abs/2504.13365</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13365">https://arxiv.org/pdf/2504.13365</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13365]] VLLFL: A Vision-Language Model Based Lightweight Federated Learning Framework for Smart Agriculture(https://arxiv.org/abs/2504.13365)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>In modern smart agriculture, object detection plays a crucial role by enabling automation, precision farming, and monitoring of resources. From identifying crop health and pest infestations to optimizing harvesting processes, accurate object detection enhances both productivity and sustainability. However, training object detection models often requires large-scale data collection and raises privacy concerns, particularly when sensitive agricultural data is distributed across farms. To address these challenges, we propose VLLFL, a vision-language model-based lightweight federated learning framework (VLLFL). It harnesses the generalization and context-aware detection capabilities of the vision-language model (VLM) and leverages the privacy-preserving nature of federated learning. By training a compact prompt generator to boost the performance of the VLM deployed across different farms, VLLFL preserves privacy while reducing communication overhead. Experimental results demonstrate that VLLFL achieves 14.53% improvement in the performance of VLM while reducing 99.3% communication overhead. Spanning tasks from identifying a wide variety of fruits to detecting harmful animals in agriculture, the proposed framework offers an efficient, scalable, and privacy-preserving solution specifically tailored to agricultural applications.</li>
</ul>

<h3>Title: The Impact of AI on the Cyber Offense-Defense Balance and the Character of Cyber Conflict</h3>
<ul>
<li><strong>Authors: </strong>Andrew J. Lohn</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13371">https://arxiv.org/abs/2504.13371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13371">https://arxiv.org/pdf/2504.13371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13371]] The Impact of AI on the Cyber Offense-Defense Balance and the Character of Cyber Conflict(https://arxiv.org/abs/2504.13371)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>Unlike other domains of conflict, and unlike other fields with high anticipated risk from AI, the cyber domain is intrinsically digital with a tight feedback loop between AI training and cyber application. Cyber may have some of the largest and earliest impacts from AI, so it is important to understand how the cyber domain may change as AI continues to advance. Our approach reviewed the literature, collecting nine arguments that have been proposed for offensive advantage in cyber conflict and nine proposed arguments for defensive advantage. We include an additional forty-eight arguments that have been proposed to give cyber conflict and competition its character as collected separately by Healey, Jervis, and Nandrajog. We then consider how each of those arguments and propositions might change with varying degrees of AI advancement. We find that the cyber domain is too multifaceted for a single answer to whether AI will enhance offense or defense broadly. AI will improve some aspects, hinder others, and leave some aspects unchanged. We collect and present forty-four ways that we expect AI to impact the cyber offense-defense balance and the character of cyber conflict and competition.</li>
</ul>

<h3>Title: EXAM: Exploiting Exclusive System-Level Cache in Apple M-Series SoCs for Enhanced Cache Occupancy Attacks</h3>
<ul>
<li><strong>Authors: </strong>Tianhong Xu, Aidong Adam Ding, Yunsi Fei</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13385">https://arxiv.org/abs/2504.13385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13385">https://arxiv.org/pdf/2504.13385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13385]] EXAM: Exploiting Exclusive System-Level Cache in Apple M-Series SoCs for Enhanced Cache Occupancy Attacks(https://arxiv.org/abs/2504.13385)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, steal</a></li>
<li><strong>Abstract: </strong>Cache occupancy attacks exploit the shared nature of cache hierarchies to infer a victim's activities by monitoring overall cache usage, unlike access-driven cache attacks that focus on specific cache lines or sets. There exists some prior work that target the last-level cache (LLC) of Intel processors, which is inclusive of higher-level caches, and L2 caches of ARM systems. In this paper, we target the System-Level Cache (SLC) of Apple M-series SoCs, which is exclusive to higher-level CPU caches. We address the challenges of the exclusiveness and propose a suite of SLC-cache occupancy attacks, the first of its kind, where an adversary can monitor GPU and other CPU cluster activities from their own CPU cluster. We first discover the structure of SLC in Apple M1 SOC and various policies pertaining to access and sharing through reverse engineering. We propose two attacks against websites. One is a coarse-grained fingerprinting attack, recognizing which website is accessed based on their different GPU memory access patterns monitored through the SLC occupancy channel. The other attack is a fine-grained pixel stealing attack, which precisely monitors the GPU memory usage for rendering different pixels, through the SLC occupancy channel. Third, we introduce a novel screen capturing attack which works beyond webpages, with the monitoring granularity of 57 rows of pixels (there are 1600 rows for the screen). This significantly expands the attack surface, allowing the adversary to retrieve any screen display, posing a substantial new threat to system security. Our findings reveal critical vulnerabilities in Apple's M-series SoCs and emphasize the urgent need for effective countermeasures against cache occupancy attacks in heterogeneous computing environments.</li>
</ul>

<h3>Title: POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Evans Xu Han, Alice Qian Zhang, Hong Shen, Haiyi Zhu, Paul Pu Liang, Jane Hsieh</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13392">https://arxiv.org/abs/2504.13392</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13392">https://arxiv.org/pdf/2504.13392</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13392]] POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation(https://arxiv.org/abs/2504.13392)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>State-of-the-art visual generative AI tools hold immense potential to assist users in the early ideation stages of creative tasks -- offering the ability to generate (rather than search for) novel and unprecedented (instead of existing) images of considerable quality that also adhere to boundless combinations of user specifications. However, many large-scale text-to-image systems are designed for broad applicability, yielding conventional output that may limit creative exploration. They also employ interaction methods that may be difficult for beginners. Given that creative end users often operate in diverse, context-specific ways that are often unpredictable, more variation and personalization are necessary. We introduce POET, a real-time interactive tool that (1) automatically discovers dimensions of homogeneity in text-to-image generative models, (2) expands these dimensions to diversify the output space of generated images, and (3) learns from user feedback to personalize expansions. An evaluation with 28 users spanning four creative task domains demonstrated POET's ability to generate results with higher perceived diversity and help users reach satisfaction in fewer prompts during creative tasks, thereby prompting them to deliberate and reflect more on a wider range of possible produced results during the co-creative process. Focusing on visual creativity, POET offers a first glimpse of how interaction techniques of future text-to-image generation tools may support and align with more pluralistic values and the needs of end users during the ideation stages of their work.</li>
</ul>

<h3>Title: BeetleVerse: A study on taxonomic classification of ground beetles</h3>
<ul>
<li><strong>Authors: </strong>S M Rayeed, Alyson East, Samuel Stevens, Sydne Record, Charles V Stewart</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13393">https://arxiv.org/abs/2504.13393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13393">https://arxiv.org/pdf/2504.13393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13393]] BeetleVerse: A study on taxonomic classification of ground beetles(https://arxiv.org/abs/2504.13393)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Ground beetles are a highly sensitive and speciose biological indicator, making them vital for monitoring biodiversity. However, they are currently an underutilized resource due to the manual effort required by taxonomic experts to perform challenging species differentiations based on subtle morphological differences, precluding widespread applications. In this paper, we evaluate 12 vision models on taxonomic classification across four diverse, long-tailed datasets spanning over 230 genera and 1769 species, with images ranging from controlled laboratory settings to challenging field-collected (in-situ) photographs. We further explore taxonomic classification in two important real-world contexts: sample efficiency and domain adaptation. Our results show that the Vision and Language Transformer combined with an MLP head is the best performing model, with 97\% accuracy at genus and 94\% at species level. Sample efficiency analysis shows that we can reduce train data requirements by up to 50\% with minimal compromise in performance. The domain adaptation experiments reveal significant challenges when transferring models from lab to in-situ images, highlighting a critical domain gap. Overall, our study lays a foundation for large-scale automated taxonomic classification of beetles, and beyond that, advances sample-efficient learning and cross-domain adaptation for diverse long-tailed ecological datasets.</li>
</ul>

<h3>Title: Insecurity Through Obscurity: Veiled Vulnerabilities in Closed-Source Contracts</h3>
<ul>
<li><strong>Authors: </strong>Sen Yang, Kaihua Qin, Aviv Yaish, Fan Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13398">https://arxiv.org/abs/2504.13398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13398">https://arxiv.org/pdf/2504.13398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13398]] Insecurity Through Obscurity: Veiled Vulnerabilities in Closed-Source Contracts(https://arxiv.org/abs/2504.13398)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Most blockchains cannot hide the binary code of programs (i.e., smart contracts) running on them. To conceal proprietary business logic and to potentially deter attacks, many smart contracts are closed-source and employ layers of obfuscation. However, we demonstrate that such obfuscation can obscure critical vulnerabilities rather than enhance security, a phenomenon we term insecurity through obscurity. To systematically analyze these risks on a large scale, we present SKANF, a novel EVM bytecode analysis tool tailored for closed-source and obfuscated contracts. SKANF combines control-flow deobfuscation, symbolic execution, and concolic execution based on historical transactions to identify and exploit asset management vulnerabilities. Our evaluation on real-world Maximal Extractable Value (MEV) bots reveals that SKANF detects vulnerabilities in 1,028 contracts and successfully generates exploits for 373 of them, with potential losses exceeding \$9.0M. Additionally, we uncover 40 real-world MEV bot attacks that collectively resulted in \$900K in losses.</li>
</ul>

<h3>Title: Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety</h3>
<ul>
<li><strong>Authors: </strong>Shashank Shriram, Srinivasa Perisetla, Aryan Keskar, Harsha Krishnaswamy, Tonko Emil Westerhof Bossen, Andreas M√∏gelmose, Ross Greer</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13399">https://arxiv.org/abs/2504.13399</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13399">https://arxiv.org/pdf/2504.13399</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13399]] Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety(https://arxiv.org/abs/2504.13399)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Detecting anomalous hazards in visual data, particularly in video streams, is a critical challenge in autonomous driving. Existing models often struggle with unpredictable, out-of-label hazards due to their reliance on predefined object categories. In this paper, we propose a multimodal approach that integrates vision-language reasoning with zero-shot object detection to improve hazard identification and explanation. Our pipeline consists of a Vision-Language Model (VLM), a Large Language Model (LLM), in order to detect hazardous objects within a traffic scene. We refine object detection by incorporating OpenAI's CLIP model to match predicted hazards with bounding box annotations, improving localization accuracy. To assess model performance, we create a ground truth dataset by denoising and extending the foundational COOOL (Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete natural language descriptions for hazard annotations. We define a means of hazard detection and labeling evaluation on the extended dataset using cosine similarity. This evaluation considers the semantic similarity between the predicted hazard description and the annotated ground truth for each video. Additionally, we release a set of tools for structuring and managing large-scale hazard detection datasets. Our findings highlight the strengths and limitations of current vision-language-based approaches, offering insights into future improvements in autonomous hazard detection systems. Our models, scripts, and data can be found at this https URL</li>
</ul>

<h3>Title: CytoFM: The first cytology foundation model</h3>
<ul>
<li><strong>Authors: </strong>Vedrana Iveziƒá, Ashwath Radhachandran, Ekaterina Redekop, Shreeram Athreya, Dongwoo Lee, Vivek Sant, Corey Arnold, William Speier</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13402">https://arxiv.org/abs/2504.13402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13402">https://arxiv.org/pdf/2504.13402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13402]] CytoFM: The first cytology foundation model(https://arxiv.org/abs/2504.13402)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Cytology is essential for cancer diagnostics and screening due to its minimally invasive nature. However, the development of robust deep learning models for digital cytology is challenging due to the heterogeneity in staining and preparation methods of samples, differences across organs, and the limited availability of large, diverse, annotated datasets. Developing a task-specific model for every cytology application is impractical and non-cytology-specific foundation models struggle to generalize to tasks in this domain where the emphasis is on cell morphology. To address these challenges, we introduce CytoFM, the first cytology self-supervised foundation model. Using iBOT, a self-supervised Vision Transformer (ViT) training framework incorporating masked image modeling and self-distillation, we pretrain CytoFM on a diverse collection of cytology datasets to learn robust, transferable representations. We evaluate CytoFM on multiple downstream cytology tasks, including breast cancer classification and cell type identification, using an attention-based multiple instance learning framework. Our results demonstrate that CytoFM performs better on two out of three downstream tasks than existing foundation models pretrained on histopathology (UNI) or natural images (iBOT-Imagenet). Visualizations of learned representations demonstrate our model is able to attend to cytologically relevant features. Despite a small pre-training dataset, CytoFM's promising results highlight the ability of task-agnostic pre-training approaches to learn robust and generalizable features from cytology data.</li>
</ul>

<h3>Title: LoRA-Based Continual Learning with Constraints on Critical Parameter Changes</h3>
<ul>
<li><strong>Authors: </strong>Shimou Ling, Liang Zhang, Jiangwei Zhao, Lili Pan, Hongliang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13407">https://arxiv.org/abs/2504.13407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13407">https://arxiv.org/pdf/2504.13407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13407]] LoRA-Based Continual Learning with Constraints on Critical Parameter Changes(https://arxiv.org/abs/2504.13407)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>LoRA-based continual learning represents a promising avenue for leveraging pre-trained models in downstream continual learning tasks. Recent studies have shown that orthogonal LoRA tuning effectively mitigates forgetting. However, this work unveils that under orthogonal LoRA tuning, the critical parameters for pre-tasks still change notably after learning post-tasks. To address this problem, we directly propose freezing the most critical parameter matrices in the Vision Transformer (ViT) for pre-tasks before learning post-tasks. In addition, building on orthogonal LoRA tuning, we propose orthogonal LoRA composition (LoRAC) based on QR decomposition, which may further enhance the plasticity of our method. Elaborate ablation studies and extensive comparisons demonstrate the effectiveness of our proposed method. Our results indicate that our method achieves state-of-the-art (SOTA) performance on several well-known continual learning benchmarks. For instance, on the Split CIFAR-100 dataset, our method shows a 6.35\% improvement in accuracy and a 3.24\% reduction in forgetting compared to previous methods. Our code is available at this https URL.</li>
</ul>

<h3>Title: OpCode-Based Malware Classification Using Machine Learning and Deep Learning Techniques</h3>
<ul>
<li><strong>Authors: </strong>Varij Saini, Rudraksh Gupta, Neel Soni</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13408">https://arxiv.org/abs/2504.13408</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13408">https://arxiv.org/pdf/2504.13408</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13408]] OpCode-Based Malware Classification Using Machine Learning and Deep Learning Techniques(https://arxiv.org/abs/2504.13408)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This technical report presents a comprehensive analysis of malware classification using OpCode sequences. Two distinct approaches are evaluated: traditional machine learning using n-gram analysis with Support Vector Machine (SVM), K-Nearest Neighbors (KNN), and Decision Tree classifiers; and a deep learning approach employing a Convolutional Neural Network (CNN). The traditional machine learning approach establishes a baseline using handcrafted 1-gram and 2-gram features from disassembled malware samples. The deep learning methodology builds upon the work proposed in "Deep Android Malware Detection" by McLaughlin et al. and evaluates the performance of a CNN model trained to automatically extract features from raw OpCode data. Empirical results are compared using standard performance metrics (accuracy, precision, recall, and F1-score). While the SVM classifier outperforms other traditional techniques, the CNN model demonstrates competitive performance with the added benefit of automated feature extraction.</li>
</ul>

<h3>Title: A Model-Based Approach to Imitation Learning through Multi-Step Predictions</h3>
<ul>
<li><strong>Authors: </strong>Haldun Balim, Yang Hu, Yuyang Zhang, Na Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13413">https://arxiv.org/abs/2504.13413</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13413">https://arxiv.org/pdf/2504.13413</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13413]] A Model-Based Approach to Imitation Learning through Multi-Step Predictions(https://arxiv.org/abs/2504.13413)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Imitation learning is a widely used approach for training agents to replicate expert behavior in complex decision-making tasks. However, existing methods often struggle with compounding errors and limited generalization, due to the inherent challenge of error correction and the distribution shift between training and deployment. In this paper, we present a novel model-based imitation learning framework inspired by model predictive control, which addresses these limitations by integrating predictive modeling through multi-step state predictions. Our method outperforms traditional behavior cloning numerical benchmarks, demonstrating superior robustness to distribution shift and measurement noise both in available data and during execution. Furthermore, we provide theoretical guarantees on the sample complexity and error bounds of our method, offering insights into its convergence properties.</li>
</ul>

<h3>Title: STAMP Your Content: Proving Dataset Membership via Watermarked Rephrasings</h3>
<ul>
<li><strong>Authors: </strong>Saksham Rastogi, Pratyush Maini, Danish Pruthi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13416">https://arxiv.org/abs/2504.13416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13416">https://arxiv.org/pdf/2504.13416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13416]] STAMP Your Content: Proving Dataset Membership via Watermarked Rephrasings(https://arxiv.org/abs/2504.13416)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>Given how large parts of publicly available text are crawled to pretrain large language models (LLMs), data creators increasingly worry about the inclusion of their proprietary data for model training without attribution or licensing. Their concerns are also shared by benchmark curators whose test-sets might be compromised. In this paper, we present STAMP, a framework for detecting dataset membership-i.e., determining the inclusion of a dataset in the pretraining corpora of LLMs. Given an original piece of content, our proposal involves first generating multiple rephrases, each embedding a watermark with a unique secret key. One version is to be released publicly, while others are to be kept private. Subsequently, creators can compare model likelihoods between public and private versions using paired statistical tests to prove membership. We show that our framework can successfully detect contamination across four benchmarks which appear only once in the training data and constitute less than 0.001% of the total tokens, outperforming several contamination detection and dataset inference baselines. We verify that STAMP preserves both the semantic meaning and the utility of the original data in comparing different models. We apply STAMP to two real-world scenarios to confirm the inclusion of paper abstracts and blog articles in the pretraining corpora.</li>
</ul>

<h3>Title: Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Wenyu Li, Sidun Liu, Peng Qiao, Yong Dou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13419">https://arxiv.org/abs/2504.13419</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13419">https://arxiv.org/pdf/2504.13419</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13419]] Mono3R: Exploiting Monocular Cues for Geometric 3D Reconstruction(https://arxiv.org/abs/2504.13419)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Recent advances in data-driven geometric multi-view 3D reconstruction foundation models (e.g., DUSt3R) have shown remarkable performance across various 3D vision tasks, facilitated by the release of large-scale, high-quality 3D datasets. However, as we observed, constrained by their matching-based principles, the reconstruction quality of existing models suffers significant degradation in challenging regions with limited matching cues, particularly in weakly textured areas and low-light conditions. To mitigate these limitations, we propose to harness the inherent robustness of monocular geometry estimation to compensate for the inherent shortcomings of matching-based methods. Specifically, we introduce a monocular-guided refinement module that integrates monocular geometric priors into multi-view reconstruction frameworks. This integration substantially enhances the robustness of multi-view reconstruction systems, leading to high-quality feed-forward reconstructions. Comprehensive experiments across multiple benchmarks demonstrate that our method achieves substantial improvements in both mutli-view camera pose estimation and point cloud accuracy.</li>
</ul>

<h3>Title: Equilibrium Conserving Neural Operators for Super-Resolution Learning</h3>
<ul>
<li><strong>Authors: </strong>Vivek Oommen, Andreas E. Robertson, Daniel Diaz, Coleman Alleman, Zhen Zhang, Anthony D. Rollett, George E. Karniadakis, R√©mi Dingreville</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13422">https://arxiv.org/abs/2504.13422</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13422">https://arxiv.org/pdf/2504.13422</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13422]] Equilibrium Conserving Neural Operators for Super-Resolution Learning(https://arxiv.org/abs/2504.13422)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural surrogate solvers can estimate solutions to partial differential equations in physical problems more efficiently than standard numerical methods, but require extensive high-resolution training data. In this paper, we break this limitation; we introduce a framework for super-resolution learning in solid mechanics problems. Our approach allows one to train a high-resolution neural network using only low-resolution data. Our Equilibrium Conserving Operator (ECO) architecture embeds known physics directly into the network to make up for missing high-resolution information during training. We evaluate this ECO-based super-resolution framework that strongly enforces conservation-laws in the predicted solutions on two working examples: embedded pores in a homogenized matrix and randomly textured polycrystalline materials. ECO eliminates the reliance on high-fidelity data and reduces the upfront cost of data collection by two orders of magnitude, offering a robust pathway for resource-efficient surrogate modeling in materials modeling. ECO is readily generalizable to other physics-based problems.</li>
</ul>

<h3>Title: Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering</h3>
<ul>
<li><strong>Authors: </strong>Grace Byun, Shinsun Lee, Nayoung Choi, Jinho Choi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13425">https://arxiv.org/abs/2504.13425</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13425">https://arxiv.org/pdf/2504.13425</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13425]] Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering(https://arxiv.org/abs/2504.13425)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Existing Retrieval-Augmented Generation (RAG) systems face challenges in enterprise settings due to limited retrieval scope and data security risks. When relevant internal documents are unavailable, the system struggles to generate accurate and complete responses. Additionally, using closed-source Large Language Models (LLMs) raises concerns about exposing proprietary information. To address these issues, we propose the Secure Multifaceted-RAG (SecMulti-RAG) framework, which retrieves not only from internal documents but also from two supplementary sources: pre-generated expert knowledge for anticipated queries and on-demand external LLM-generated knowledge. To mitigate security risks, we adopt a local open-source generator and selectively utilize external LLMs only when prompts are deemed safe by a filtering mechanism. This approach enhances completeness, prevents data leakage, and reduces costs. In our evaluation on a report generation task in the automotive industry, SecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9 percent win rates across correctness, richness, and helpfulness in LLM-based evaluation, and 56.3 to 70.4 percent in human evaluation. This highlights SecMulti-RAG as a practical and secure solution for enterprise RAG.</li>
</ul>

<h3>Title: Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs</h3>
<ul>
<li><strong>Authors: </strong>Shenzhi Yang, Bin Liang, An Liu, Lin Gui, Xingkai Yao, Xiaofang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13429">https://arxiv.org/abs/2504.13429</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13429">https://arxiv.org/pdf/2504.13429</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13429]] Bounded and Uniform Energy-based Out-of-distribution Detection for Graphs(https://arxiv.org/abs/2504.13429)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Given the critical role of graphs in real-world applications and their high-security requirements, improving the ability of graph neural networks (GNNs) to detect out-of-distribution (OOD) data is an urgent research problem. The recent work GNNSAFE proposes a framework based on the aggregation of negative energy scores that significantly improves the performance of GNNs to detect node-level OOD data. However, our study finds that score aggregation among nodes is susceptible to extreme values due to the unboundedness of the negative energy scores and logit shifts, which severely limits the accuracy of GNNs in detecting node-level OOD data. In this paper, we propose NODESAFE: reducing the generation of extreme scores of nodes by adding two optimization terms that make the negative energy scores bounded and mitigate the logit shift. Experimental results show that our approach dramatically improves the ability of GNNs to detect OOD data at the node level, e.g., in detecting OOD data induced by Structure Manipulation, the metric of FPR95 (lower is better) in scenarios without (with) OOD data exposure are reduced from the current SOTA by 28.4% (22.7%).</li>
</ul>

<h3>Title: D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Model</h3>
<ul>
<li><strong>Authors: </strong>Grace Byun, Jinho Choi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13439">https://arxiv.org/abs/2504.13439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13439">https://arxiv.org/pdf/2504.13439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13439]] D-GEN: Automatic Distractor Generation and Evaluation for Reliable Assessment of Generative Model(https://arxiv.org/abs/2504.13439)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Evaluating generative models with open-ended generation is challenging due to inconsistencies in response formats. Multiple-choice (MC) evaluation mitigates this issue, but generating high-quality distractors is time-consuming and labor-intensive. We introduce D-GEN, the first open-source distractor generator model that transforms open-ended data into an MC format. To evaluate distractor quality, we propose two novel methods: (1) ranking alignment, ensuring generated distractors retain the discriminatory power of ground-truth distractors, and (2) entropy analysis, comparing model confidence distributions. Our results show that D-GEN preserves ranking consistency (Spearman's rho 0.99, Kendall's tau 0.94) and closely matches the entropy distribution of ground-truth distractors. Human evaluation further confirms the fluency, coherence, distractiveness, and incorrectness. Our work advances robust and efficient distractor generation with automated evaluation, setting a new standard for MC evaluation.</li>
</ul>

<h3>Title: Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Cheng Yuan, Yutong Ban</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13440">https://arxiv.org/abs/2504.13440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13440">https://arxiv.org/pdf/2504.13440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13440]] Temporal Propagation of Asymmetric Feature Pyramid for Surgical Scene Segmentation(https://arxiv.org/abs/2504.13440)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, segmentation</a></li>
<li><strong>Abstract: </strong>Surgical scene segmentation is crucial for robot-assisted laparoscopic surgery understanding. Current approaches face two challenges: (i) static image limitations including ambiguous local feature similarities and fine-grained structural details, and (ii) dynamic video complexities arising from rapid instrument motion and persistent visual occlusions. While existing methods mainly focus on spatial feature extraction, they fundamentally overlook temporal dependencies in surgical video streams. To address this, we present temporal asymmetric feature propagation network, a bidirectional attention architecture enabling cross-frame feature propagation. The proposed method contains a temporal query propagator that integrates multi-directional consistency constraints to enhance frame-specific feature representation, and an aggregated asymmetric feature pyramid module that preserves discriminative features for anatomical structures and surgical instruments. Our framework uniquely enables both temporal guidance and contextual reasoning for surgical scene understanding. Comprehensive evaluations on two public benchmarks show the proposed method outperforms the current SOTA methods by a large margin, with +16.4\% mIoU on EndoVis2018 and +3.3\% mAP on Endoscapes2023. The code will be publicly available after paper acceptance.</li>
</ul>

<h3>Title: SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion</h3>
<ul>
<li><strong>Authors: </strong>Zhenyu Yu, Mohd. Yamani Idna Idris, Pei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13442">https://arxiv.org/abs/2504.13442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13442">https://arxiv.org/pdf/2504.13442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13442]] SatelliteCalculator: A Multi-Task Vision Foundation Model for Quantitative Remote Sensing Inversion(https://arxiv.org/abs/2504.13442)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Quantitative remote sensing inversion plays a critical role in environmental monitoring, enabling the estimation of key ecological variables such as vegetation indices, canopy structure, and carbon stock. Although vision foundation models have achieved remarkable progress in classification and segmentation tasks, their application to physically interpretable regression remains largely unexplored. Furthermore, the multi-spectral nature and geospatial heterogeneity of remote sensing data pose significant challenges for generalization and transferability. To address these issues, we introduce SatelliteCalculator, the first vision foundation model tailored for quantitative remote sensing inversion. By leveraging physically defined index formulas, we automatically construct a large-scale dataset of over one million paired samples across eight core ecological indicators. The model integrates a frozen Swin Transformer backbone with a prompt-guided architecture, featuring cross-attentive adapters and lightweight task-specific MLP decoders. Experiments on the Open-Canopy benchmark demonstrate that SatelliteCalculator achieves competitive accuracy across all tasks while significantly reducing inference cost. Our results validate the feasibility of applying foundation models to quantitative inversion, and provide a scalable framework for task-adaptive remote sensing estimation.</li>
</ul>

<h3>Title: Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping</h3>
<ul>
<li><strong>Authors: </strong>Wang Liu, Zhiyu Wang, Xin Guo, Puhong Duan, Xudong Kang, Shutao Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13458">https://arxiv.org/abs/2504.13458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13458">https://arxiv.org/pdf/2504.13458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13458]] Learning from Noisy Pseudo-labels for All-Weather Land Cover Mapping(https://arxiv.org/abs/2504.13458)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semantic segmentation of SAR images has garnered significant attention in remote sensing due to the immunity of SAR sensors to cloudy weather and light conditions. Nevertheless, SAR imagery lacks detailed information and is plagued by significant speckle noise, rendering the annotation or segmentation of SAR images a formidable task. Recent efforts have resorted to annotating paired optical-SAR images to generate pseudo-labels through the utilization of an optical image segmentation network. However, these pseudo-labels are laden with noise, leading to suboptimal performance in SAR image segmentation. In this study, we introduce a more precise method for generating pseudo-labels by incorporating semi-supervised learning alongside a novel image resolution alignment augmentation. Furthermore, we introduce a symmetric cross-entropy loss to mitigate the impact of noisy pseudo-labels. Additionally, a bag of training and testing tricks is utilized to generate better land-cover mapping results. Our experiments on the GRSS data fusion contest indicate the effectiveness of the proposed method, which achieves first place. The code is available at this https URL.</li>
</ul>

<h3>Title: Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization</h3>
<ul>
<li><strong>Authors: </strong>Hongwei Ji, Wulian Yun, Mengshi Qi, Huadong Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13460">https://arxiv.org/abs/2504.13460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13460">https://arxiv.org/pdf/2504.13460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13460]] Chain-of-Thought Textual Reasoning for Few-shot Temporal Action Localization(https://arxiv.org/abs/2504.13460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional temporal action localization (TAL) methods rely on large amounts of detailed annotated data, whereas few-shot TAL reduces this dependence by using only a few training samples to identify unseen action categories. However, existing few-shot TAL methods typically focus solely on video-level information, neglecting textual information, which can provide valuable semantic support for the localization task. Therefore, we propose a new few-shot temporal action localization method by Chain-of-Thought textual reasoning to improve localization performance. Specifically, we design a novel few-shot learning framework that leverages textual semantic information to enhance the model's ability to capture action commonalities and variations, which includes a semantic-aware text-visual alignment module designed to align the query and support videos at different levels. Meanwhile, to better express the temporal dependencies and causal relationships between actions at the textual level to assist action localization, we design a Chain of Thought (CoT)-like reasoning method that progressively guides the Vision Language Model (VLM) and Large Language Model (LLM) to generate CoT-like text descriptions for videos. The generated texts can capture more variance of action than visual features. We conduct extensive experiments on the publicly available ActivityNet1.3 and THUMOS14 datasets. We introduce the first dataset named Human-related Anomaly Localization and explore the application of the TAL task in human anomaly detection. The experimental results demonstrate that our proposed method significantly outperforms existing methods in single-instance and multi-instance scenarios. We will release our code, data and benchmark.</li>
</ul>

<h3>Title: Stratify: Rethinking Federated Learning for Non-IID Data through Balanced Sampling</h3>
<ul>
<li><strong>Authors: </strong>Hui Yeok Wong, Chee Kau Lim, Chee Seng Chan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13462">https://arxiv.org/abs/2504.13462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13462">https://arxiv.org/pdf/2504.13462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13462]] Stratify: Rethinking Federated Learning for Non-IID Data through Balanced Sampling(https://arxiv.org/abs/2504.13462)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) on non-independently and identically distributed (non-IID) data remains a critical challenge, as existing approaches struggle with severe data heterogeneity. Current methods primarily address symptoms of non-IID by applying incremental adjustments to Federated Averaging (FedAvg), rather than directly resolving its inherent design limitations. Consequently, performance significantly deteriorates under highly heterogeneous conditions, as the fundamental issue of imbalanced exposure to diverse class and feature distributions remains unresolved. This paper introduces Stratify, a novel FL framework designed to systematically manage class and feature distributions throughout training, effectively tackling the root cause of non-IID challenges. Inspired by classical stratified sampling, our approach employs a Stratified Label Schedule (SLS) to ensure balanced exposure across labels, significantly reducing bias and variance in aggregated gradients. Complementing SLS, we propose a label-aware client selection strategy, restricting participation exclusively to clients possessing data relevant to scheduled labels. Additionally, Stratify incorporates a fine-grained, high-frequency update scheme, accelerating convergence and further mitigating data heterogeneity. To uphold privacy, we implement a secure client selection protocol leveraging homomorphic encryption, enabling precise global label statistics without disclosing sensitive client information. Extensive evaluations on MNIST, CIFAR-10, CIFAR-100, Tiny-ImageNet, COVTYPE, PACS, and Digits-DG demonstrate that Stratify attains performance comparable to IID baselines, accelerates convergence, and reduces client-side computation compared to state-of-the-art methods, underscoring its practical effectiveness in realistic federated learning scenarios.</li>
</ul>

<h3>Title: Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation</h3>
<ul>
<li><strong>Authors: </strong>Duy A. Nguyen, Quan Huu Do, Khoa D. Doan, Minh N. Do</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13465">https://arxiv.org/abs/2504.13465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13465">https://arxiv.org/pdf/2504.13465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13465]] Are you SURE? Enhancing Multimodal Pretraining with Missing Modalities through Uncertainty Estimation(https://arxiv.org/abs/2504.13465)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Multimodal learning has demonstrated incredible successes by integrating diverse data sources, yet it often relies on the availability of all modalities - an assumption that rarely holds in real-world applications. Pretrained multimodal models, while effective, struggle when confronted with small-scale and incomplete datasets (i.e., missing modalities), limiting their practical applicability. Previous studies on reconstructing missing modalities have overlooked the reconstruction's potential unreliability, which could compromise the quality of the final outputs. We present SURE (Scalable Uncertainty and Reconstruction Estimation), a novel framework that extends the capabilities of pretrained multimodal models by introducing latent space reconstruction and uncertainty estimation for both reconstructed modalities and downstream tasks. Our method is architecture-agnostic, reconstructs missing modalities, and delivers reliable uncertainty estimates, improving both interpretability and performance. SURE introduces a unique Pearson Correlation-based loss and applies statistical error propagation in deep networks for the first time, allowing precise quantification of uncertainties from missing data and model predictions. Extensive experiments across tasks such as sentiment analysis, genre classification, and action recognition show that SURE consistently achieves state-of-the-art performance, ensuring robust predictions even in the presence of incomplete data.</li>
</ul>

<h3>Title: HMPE:HeatMap Embedding for Efficient Transformer-Based Small Object Detection</h3>
<ul>
<li><strong>Authors: </strong>YangChen Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13469">https://arxiv.org/abs/2504.13469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13469">https://arxiv.org/pdf/2504.13469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13469]] HMPE:HeatMap Embedding for Efficient Transformer-Based Small Object Detection(https://arxiv.org/abs/2504.13469)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Current Transformer-based methods for small object detection continue emerging, yet they have still exhibited significant shortcomings. This paper introduces HeatMap Position Embedding (HMPE), a novel Transformer Optimization technique that enhances object detection performance by dynamically integrating positional encoding with semantic detection information through heatmap-guided adaptive this http URL also innovatively visualize the HMPE method, offering clear visualization of embedded information for parameter this http URL then create Multi-Scale ObjectBox-Heatmap Fusion Encoder (MOHFE) and HeatMap Induced High-Quality Queries for Decoder (HIDQ) modules. These are designed for the encoder and decoder, respectively, to generate high-quality queries and reduce background noise this http URL both heatmap embedding and Linear-Snake Conv(LSConv) feature engineering, we enhance the embedding of massively diverse small object categories and reduced the decoder multihead layers, thereby accelerating both inference and this http URL the generalization experiments, our approach outperforme the baseline mAP by 1.9% on the small object dataset (NWPU VHR-10) and by 1.2% on the general dataset (PASCAL VOC). By employing HMPE-enhanced embedding, we are able to reduce the number of decoder layers from eight to a minimum of three, significantly decreasing both inference and training costs.</li>
</ul>

<h3>Title: From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jiliang Ni, Jiachen Pu, Zhongyi Yang, Kun Zhou, Hui Wang, Xiaoliang Xiao, Dakui Wang, Xin Li, Jingfeng Luo, Conggang Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13471">https://arxiv.org/abs/2504.13471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13471">https://arxiv.org/pdf/2504.13471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13471]] From Large to Super-Tiny: End-to-End Optimization for Cost-Efficient LLMs(https://arxiv.org/abs/2504.13471)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In recent years, Large Language Models (LLMs) have significantly advanced artificial intelligence by optimizing traditional Natural Language Processing (NLP) pipelines, improving performance and generalization. This has spurred their integration into various systems. Many NLP systems, including ours, employ a "one-stage" pipeline directly incorporating LLMs. While effective, this approach incurs substantial costs and latency due to the need for large model parameters to achieve satisfactory outcomes. This paper introduces a three-stage cost-efficient end-to-end LLM deployment pipeline-including prototyping, knowledge transfer, and model compression-to tackle the cost-performance dilemma in LLM-based frameworks. Our approach yields a super tiny model optimized for cost and performance in online systems, simplifying the system architecture. Initially, by transforming complex tasks into a function call-based LLM-driven pipeline, an optimal performance prototype system is constructed to produce high-quality data as a teacher model. The second stage combine techniques like rejection fine-tuning, reinforcement learning and knowledge distillation to transfer knowledge to a smaller 0.5B student model, delivering effective performance at minimal cost. The final stage applies quantization and pruning to extremely compress model to 0.4B, achieving ultra-low latency and cost. The framework's modular design and cross-domain capabilities suggest potential applicability in other NLP areas.</li>
</ul>

<h3>Title: Everything You Wanted to Know About LLM-based Vulnerability Detection But Were Afraid to Ask</h3>
<ul>
<li><strong>Authors: </strong>Yue Li, Xiao Li, Hao Wu, Minghui Xu, Yue Zhang, Xiuzhen Cheng, Fengyuan Xu, Sheng Zhong</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13474">https://arxiv.org/abs/2504.13474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13474">https://arxiv.org/pdf/2504.13474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13474]] Everything You Wanted to Know About LLM-based Vulnerability Detection But Were Afraid to Ask(https://arxiv.org/abs/2504.13474)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models are a promising tool for automated vulnerability detection, thanks to their success in code generation and repair. However, despite widespread adoption, a critical question remains: Are LLMs truly effective at detecting real-world vulnerabilities? Current evaluations, which often assess models on isolated functions or files, ignore the broader execution and data-flow context essential for understanding vulnerabilities. This oversight leads to two types of misleading outcomes: incorrect conclusions and flawed rationales, collectively undermining the reliability of prior assessments. Therefore, in this paper, we challenge three widely held community beliefs: that LLMs are (i) unreliable, (ii) insensitive to code patches, and (iii) performance-plateaued across model scales. We argue that these beliefs are artifacts of context-deprived evaluations. To address this, we propose CORRECT (Context-Rich Reasoning Evaluation of Code with Trust), a new evaluation framework that systematically incorporates contextual information into LLM-based vulnerability detection. We construct a context-rich dataset of 2,000 vulnerable-patched program pairs spanning 99 CWEs and evaluate 13 LLMs across four model families. Our framework elicits both binary predictions and natural-language rationales, which are further validated using LLM-as-a-judge techniques. Our findings overturn existing misconceptions. When provided with sufficient context, SOTA LLMs achieve significantly improved performance (e.g., 0.7 F1-score on key CWEs), with 0.8 precision. We show that most false positives stem from reasoning errors rather than misclassification, and that while model and test-time scaling improve performance, they introduce diminishing returns and trade-offs in recall. Finally, we uncover new flaws in current LLM-based detection systems, such as limited generalization and overthinking biases.</li>
</ul>

<h3>Title: LLM Sensitivity Evaluation Framework for Clinical Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Chenwei Yan, Xiangling Fu, Yuxuan Xiong, Tianyi Wang, Siu Cheung Hui, Ji Wu, Xien Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13475">https://arxiv.org/abs/2504.13475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13475">https://arxiv.org/pdf/2504.13475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13475]] LLM Sensitivity Evaluation Framework for Clinical Diagnosis(https://arxiv.org/abs/2504.13475)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive performance across various domains. However, for clinical diagnosis, higher expectations are required for LLM's reliability and sensitivity: thinking like physicians and remaining sensitive to key medical information that affects diagnostic reasoning, as subtle variations can lead to different diagnosis results. Yet, existing works focus mainly on investigating the sensitivity of LLMs to irrelevant context and overlook the importance of key information. In this paper, we investigate the sensitivity of LLMs, i.e. GPT-3.5, GPT-4, Gemini, Claude3 and LLaMA2-7b, to key medical information by introducing different perturbation strategies. The evaluation results highlight the limitations of current LLMs in remaining sensitive to key medical information for diagnostic decision-making. The evolution of LLMs must focus on improving their reliability, enhancing their ability to be sensitive to key information, and effectively utilizing this information. These improvements will enhance human trust in LLMs and facilitate their practical application in real-world scenarios. Our code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Safety Monitoring for Learning-Enabled Cyber-Physical Systems in Out-of-Distribution Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Vivian Lin, Ramneet Kaur, Yahan Yang, Souradeep Dutta, Yiannis Kantaros, Anirban Roy, Susmit Jha, Oleg Sokolsky, Insup Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13478">https://arxiv.org/abs/2504.13478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13478">https://arxiv.org/pdf/2504.13478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13478]] Safety Monitoring for Learning-Enabled Cyber-Physical Systems in Out-of-Distribution Scenarios(https://arxiv.org/abs/2504.13478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The safety of learning-enabled cyber-physical systems is compromised by the well-known vulnerabilities of deep neural networks to out-of-distribution (OOD) inputs. Existing literature has sought to monitor the safety of such systems by detecting OOD data. However, such approaches have limited utility, as the presence of an OOD input does not necessarily imply the violation of a desired safety property. We instead propose to directly monitor safety in a manner that is itself robust to OOD data. To this end, we predict violations of signal temporal logic safety specifications based on predicted future trajectories. Our safety monitor additionally uses a novel combination of adaptive conformal prediction and incremental learning. The former obtains probabilistic prediction guarantees even on OOD data, and the latter prevents overly conservative predictions. We evaluate the efficacy of the proposed approach in two case studies on safety monitoring: 1) predicting collisions of an F1Tenth car with static obstacles, and 2) predicting collisions of a race car with multiple dynamic obstacles. We find that adaptive conformal prediction obtains theoretical guarantees where other uncertainty quantification methods fail to do so. Additionally, combining adaptive conformal prediction and incremental learning for safety monitoring achieves high recall and timeliness while reducing loss in precision. We achieve these results even in OOD settings and outperform alternative methods.</li>
</ul>

<h3>Title: Integrating Locality-Aware Attention with Transformers for General Geometry PDEs</h3>
<ul>
<li><strong>Authors: </strong>Minsu Koh, Beom-Chul Park, Heejo Kong, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13480">https://arxiv.org/abs/2504.13480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13480">https://arxiv.org/pdf/2504.13480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13480]] Integrating Locality-Aware Attention with Transformers for General Geometry PDEs(https://arxiv.org/abs/2504.13480)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural operators have emerged as promising frameworks for learning mappings governed by partial differential equations (PDEs), serving as data-driven alternatives to traditional numerical methods. While methods such as the Fourier neural operator (FNO) have demonstrated notable performance, their reliance on uniform grids restricts their applicability to complex geometries and irregular meshes. Recently, Transformer-based neural operators with linear attention mechanisms have shown potential in overcoming these limitations for large-scale PDE simulations. However, these approaches predominantly emphasize global feature aggregation, often overlooking fine-scale dynamics and localized PDE behaviors essential for accurate solutions. To address these challenges, we propose the Locality-Aware Attention Transformer (LA2Former), which leverages K-nearest neighbors for dynamic patchifying and integrates global-local attention for enhanced PDE modeling. By combining linear attention for efficient global context encoding with pairwise attention for capturing intricate local interactions, LA2Former achieves an optimal balance between computational efficiency and predictive accuracy. Extensive evaluations across six benchmark datasets demonstrate that LA2Former improves predictive accuracy by over 50% relative to existing linear attention methods, while also outperforming full pairwise attention under optimal conditions. This work underscores the critical importance of localized feature learning in advancing Transformer-based neural operators for solving PDEs on complex and irregular domains.</li>
</ul>

<h3>Title: Monitor and Recover: A Paradigm for Future Research on Distribution Shift in Learning-Enabled Cyber-Physical Systems</h3>
<ul>
<li><strong>Authors: </strong>Vivian Lin, Insup Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13484">https://arxiv.org/abs/2504.13484</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13484">https://arxiv.org/pdf/2504.13484</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13484]] Monitor and Recover: A Paradigm for Future Research on Distribution Shift in Learning-Enabled Cyber-Physical Systems(https://arxiv.org/abs/2504.13484)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>With the known vulnerability of neural networks to distribution shift, maintaining reliability in learning-enabled cyber-physical systems poses a salient challenge. In response, many existing methods adopt a detect and abstain methodology, aiming to detect distribution shift at inference time so that the learning-enabled component can abstain from decision-making. This approach, however, has limited use in real-world applications. We instead propose a monitor and recover paradigm as a promising direction for future research. This philosophy emphasizes 1) robust safety monitoring instead of distribution shift detection and 2) distribution shift recovery instead of abstention. We discuss two examples from our recent work.</li>
</ul>

<h3>Title: Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing</h3>
<ul>
<li><strong>Authors: </strong>Joowon Kim, Ziseok Lee, Donghyeon Cho, Sanghyun Jo, Yeonsung Jung, Kyungsu Kim, Eunho Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13490">https://arxiv.org/abs/2504.13490</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13490">https://arxiv.org/pdf/2504.13490</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13490]] Early Timestep Zero-Shot Candidate Selection for Instruction-Guided Image Editing(https://arxiv.org/abs/2504.13490)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite recent advances in diffusion models, achieving reliable image generation and editing remains challenging due to the inherent diversity induced by stochastic noise in the sampling process. Instruction-guided image editing with diffusion models offers user-friendly capabilities, yet editing failures, such as background distortion, frequently occur. Users often resort to trial and error, adjusting seeds or prompts to achieve satisfactory results, which is inefficient. While seed selection methods exist for Text-to-Image (T2I) generation, they depend on external verifiers, limiting applicability, and evaluating multiple seeds increases computational complexity. To address this, we first establish a multiple-seed-based image editing baseline using background consistency scores, achieving Best-of-N performance without supervision. Building on this, we introduce ELECT (Early-timestep Latent Evaluation for Candidate Selection), a zero-shot framework that selects reliable seeds by estimating background mismatches at early diffusion timesteps, identifying the seed that retains the background while modifying only the foreground. ELECT ranks seed candidates by a background inconsistency score, filtering unsuitable samples early based on background consistency while preserving editability. Beyond standalone seed selection, ELECT integrates into instruction-guided editing pipelines and extends to Multimodal Large-Language Models (MLLMs) for joint seed and prompt selection, further improving results when seed selection alone is insufficient. Experiments show that ELECT reduces computational costs (by 41 percent on average and up to 61 percent) while improving background consistency and instruction adherence, achieving around 40 percent success rates in previously failed cases - without any external supervision or training.</li>
</ul>

<h3>Title: U-Shape Mamba: State Space Model for faster diffusion</h3>
<ul>
<li><strong>Authors: </strong>Alex Ergasti, Filippo Botti, Tomaso Fontanini, Claudio Ferrari, Massimo Bertozzi, Andrea Prati</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13499">https://arxiv.org/abs/2504.13499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13499">https://arxiv.org/pdf/2504.13499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13499]] U-Shape Mamba: State Space Model for faster diffusion(https://arxiv.org/abs/2504.13499)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have become the most popular approach for high-quality image generation, but their high computational cost still remains a significant challenge. To address this problem, we propose U-Shape Mamba (USM), a novel diffusion model that leverages Mamba-based layers within a U-Net-like hierarchical structure. By progressively reducing sequence length in the encoder and restoring it in the decoder through Mamba blocks, USM significantly lowers computational overhead while maintaining strong generative capabilities. Experimental results against Zigma, which is currently the most efficient Mamba-based diffusion model, demonstrate that USM achieves one-third the GFlops, requires less memory and is faster, while outperforming Zigma in image quality. Frechet Inception Distance (FID) is improved by 15.3, 0.84 and 2.7 points on AFHQ, CelebAHQ and COCO datasets, respectively. These findings highlight USM as a highly efficient and scalable solution for diffusion-based generative models, making high-quality image synthesis more accessible to the research community while reducing computational costs.</li>
</ul>

<h3>Title: Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jianing Wang, Jin Jiang, Yang Liu, Mengdi Zhang, Xunliang Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13500">https://arxiv.org/abs/2504.13500</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13500">https://arxiv.org/pdf/2504.13500</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13500]] Prejudge-Before-Think: Enhancing Large Language Models at Test-Time by Process Prejudge Reasoning(https://arxiv.org/abs/2504.13500)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In this paper, we introduce a new \emph{process prejudge} strategy in LLM reasoning to demonstrate that bootstrapping with process prejudge allows the LLM to adaptively anticipate the errors encountered when advancing the subsequent reasoning steps, similar to people sometimes pausing to think about what mistakes may occur and how to avoid them, rather than relying solely on trial and error. Specifically, we define a prejudge node in the rationale, which represents a reasoning step, with at least one step that follows the prejudge node that has no paths toward the correct answer. To synthesize the prejudge reasoning process, we present an automated reasoning framework with a dynamic tree-searching strategy. This framework requires only one LLM to perform answer judging, response critiquing, prejudge generation, and thought completion. Furthermore, we develop a two-phase training mechanism with supervised fine-tuning (SFT) and reinforcement learning (RL) to further enhance the reasoning capabilities of LLMs. Experimental results from competition-level complex reasoning demonstrate that our method can teach the model to prejudge before thinking and significantly enhance the reasoning ability of LLMs. Code and data is released at this https URL.</li>
</ul>

<h3>Title: Cross-Modal Temporal Fusion for Financial Market Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Yunhua Pei, John Cartlidge, Anandadeep Mandal, Daniel Gold, Enrique Marcilio, Riccardo Mazzon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13522">https://arxiv.org/abs/2504.13522</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13522">https://arxiv.org/pdf/2504.13522</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13522]] Cross-Modal Temporal Fusion for Financial Market Forecasting(https://arxiv.org/abs/2504.13522)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Accurate financial market forecasting requires diverse data sources, including historical price trends, macroeconomic indicators, and financial news, each contributing unique predictive signals. However, existing methods often process these modalities independently or fail to effectively model their interactions. In this paper, we introduce Cross-Modal Temporal Fusion (CMTF), a novel transformer-based framework that integrates heterogeneous financial data to improve predictive accuracy. Our approach employs attention mechanisms to dynamically weight the contribution of different modalities, along with a specialized tensor interpretation module for feature extraction. To facilitate rapid model iteration in industry applications, we incorporate a mature auto-training scheme that streamlines optimization. When applied to real-world financial datasets, CMTF demonstrates improvements over baseline models in forecasting stock price movements and provides a scalable and effective solution for cross-modal integration in financial market prediction.</li>
</ul>

<h3>Title: OBIFormer: A Fast Attentive Denoising Framework for Oracle Bone Inscriptions</h3>
<ul>
<li><strong>Authors: </strong>Jinhao Li, Zijian Chen, Tingzhu Chen, Zhiji Liu, Changbo Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13524">https://arxiv.org/abs/2504.13524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13524">https://arxiv.org/pdf/2504.13524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13524]] OBIFormer: A Fast Attentive Denoising Framework for Oracle Bone Inscriptions(https://arxiv.org/abs/2504.13524)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Oracle bone inscriptions (OBIs) are the earliest known form of Chinese characters and serve as a valuable resource for research in anthropology and archaeology. However, most excavated fragments are severely degraded due to thousands of years of natural weathering, corrosion, and man-made destruction, making automatic OBI recognition extremely challenging. Previous methods either focus on pixel-level information or utilize vanilla transformers for glyph-based OBI denoising, which leads to tremendous computational overhead. Therefore, this paper proposes a fast attentive denoising framework for oracle bone inscriptions, i.e., OBIFormer. It leverages channel-wise self-attention, glyph extraction, and selective kernel feature fusion to reconstruct denoised images precisely while being computationally efficient. Our OBIFormer achieves state-of-the-art denoising performance for PSNR and SSIM metrics on synthetic and original OBI datasets. Furthermore, comprehensive experiments on a real oracle dataset demonstrate the great potential of our OBIFormer in assisting automatic OBI recognition. The code will be made available at this https URL.</li>
</ul>

<h3>Title: Multi-class Item Mining under Local Differential Privacy</h3>
<ul>
<li><strong>Authors: </strong>Yulian Mao, Qingqing Ye, Rong Du, Qi Wang, Kai Huang, Haibo Hu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13526">https://arxiv.org/abs/2504.13526</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13526">https://arxiv.org/pdf/2504.13526</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13526]] Multi-class Item Mining under Local Differential Privacy(https://arxiv.org/abs/2504.13526)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Item mining, a fundamental task for collecting statistical data from users, has raised increasing privacy concerns. To address these concerns, local differential privacy (LDP) was proposed as a privacy-preserving technique. Existing LDP item mining mechanisms primarily concentrate on global statistics, i.e., those from the entire dataset. Nevertheless, they fall short of user-tailored tasks such as personalized recommendations, whereas classwise statistics can improve task accuracy with fine-grained information. Meanwhile, the introduction of class labels brings new challenges. Label perturbation may result in invalid items for aggregation. To this end, we propose frameworks for multi-class item mining, along with two mechanisms: validity perturbation to reduce the impact of invalid data, and correlated perturbation to preserve the relationship between labels and items. We also apply these optimized methods to two multi-class item mining queries: frequency estimation and top-$k$ item mining. Through theoretical analysis and extensive experiments, we verify the effectiveness and superiority of these methods.</li>
</ul>

<h3>Title: Designing a reliable lateral movement detector using a graph foundation model</h3>
<ul>
<li><strong>Authors: </strong>Corentin Larroche</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13527">https://arxiv.org/abs/2504.13527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13527">https://arxiv.org/pdf/2504.13527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13527]] Designing a reliable lateral movement detector using a graph foundation model(https://arxiv.org/abs/2504.13527)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Foundation models have recently emerged as a new paradigm in machine learning (ML). These models are pre-trained on large and diverse datasets and can subsequently be applied to various downstream tasks with little or no retraining. This allows people without advanced ML expertise to build ML applications, accelerating innovation across many fields. However, the adoption of foundation models in cybersecurity is hindered by their inability to efficiently process data such as network traffic captures or binary executables. The recent introduction of graph foundation models (GFMs) could make a significant difference, as graphs are well-suited to representing these types of data. We study the usability of GFMs in cybersecurity through the lens of one specific use case, namely lateral movement detection. Using a pre-trained GFM, we build a detector that reaches state-of-the-art performance without requiring any training on domain-specific data. This case study thus provides compelling evidence of the potential of GFMs for cybersecurity.</li>
</ul>

<h3>Title: CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Feiyang Li, Peng Fang, Zhan Shi, Arijit Khan, Fang Wang, Dan Feng, Weihao Wang, Xin Zhang, Yongjian Cui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13534">https://arxiv.org/abs/2504.13534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13534">https://arxiv.org/pdf/2504.13534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13534]] CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models(https://arxiv.org/abs/2504.13534)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While chain-of-thought (CoT) reasoning improves the performance of large language models (LLMs) in complex tasks, it still has two main challenges: the low reliability of relying solely on LLMs to generate reasoning chains and the interference of natural language reasoning chains on the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation, featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to execute reasoning tasks in pseudo-programs with greater logical rigor. We conduct a comprehensive evaluation on nine public datasets, covering three reasoning problems. Compared with the-state-of-the-art methods, CoT-RAG exhibits a significant accuracy improvement, ranging from 4.0% to 23.0%. Furthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable accuracy and efficient execution, highlighting its strong practical applicability and scalability.</li>
</ul>

<h3>Title: Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content</h3>
<ul>
<li><strong>Authors: </strong>Azmarah Rizvi, Navojith Thamindu, A.M.N.H. Adhikari, W.P.U. Senevirathna, Dharshana Kasthurirathna, Lakmini Abeywardhana</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13545">https://arxiv.org/abs/2504.13545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13545">https://arxiv.org/pdf/2504.13545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13545]] Enhancing Multilingual Sentiment Analysis with Explainability for Sinhala, English, and Code-Mixed Content(https://arxiv.org/abs/2504.13545)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability, transformer</a></li>
<li><strong>Abstract: </strong>Sentiment analysis is crucial for brand reputation management in the banking sector, where customer feedback spans English, Sinhala, Singlish, and code-mixed text. Existing models struggle with low-resource languages like Sinhala and lack interpretability for practical use. This research develops a hybrid aspect-based sentiment analysis framework that enhances multilingual capabilities with explainable outputs. Using cleaned banking customer reviews, we fine-tune XLM-RoBERTa for Sinhala and code-mixed text, integrate domain-specific lexicon correction, and employ BERT-base-uncased for English. The system classifies sentiment (positive, neutral, negative) with confidence scores, while SHAP and LIME improve interpretability by providing real-time sentiment explanations. Experimental results show that our approaches outperform traditional transformer-based classifiers, achieving 92.3 percent accuracy and an F1-score of 0.89 in English and 88.4 percent in Sinhala and code-mixed content. An explainability analysis reveals key sentiment drivers, improving trust and transparency. A user-friendly interface delivers aspect-wise sentiment insights, ensuring accessibility for businesses. This research contributes to robust, transparent sentiment analysis for financial applications by bridging gaps in multilingual, low-resource NLP and explainability.</li>
</ul>

<h3>Title: Version-level Third-Party Library Detection in Android Applications via Class Structural Similarity</h3>
<ul>
<li><strong>Authors: </strong>Bolin Zhou, Jingzheng Wu, Xiang Ling, Tianyue Luo, Jingkun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13547">https://arxiv.org/abs/2504.13547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13547">https://arxiv.org/pdf/2504.13547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13547]] Version-level Third-Party Library Detection in Android Applications via Class Structural Similarity(https://arxiv.org/abs/2504.13547)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Android applications (apps) integrate reusable and well-tested third-party libraries (TPLs) to enhance functionality and shorten development cycles. However, recent research reveals that TPLs have become the largest attack surface for Android apps, where the use of insecure TPLs can compromise both developer and user interests. To mitigate such threats, researchers have proposed various tools to detect TPLs used by apps, supporting further security analyses such as vulnerable TPLs identification. Although existing tools achieve notable library-level TPL detection performance in the presence of obfuscation, they struggle with version-level TPL detection due to a lack of sensitivity to differences between versions. This limitation results in a high version-level false positive rate, significantly increasing the manual workload for security analysts. To resolve this issue, we propose SAD, a TPL detection tool with high version-level detection performance. SAD generates a candidate app class list for each TPL class based on the feature of nodes in class dependency graphs (CDGs). It then identifies the unique corresponding app class for each TPL class by performing class matching based on the similarity of their class summaries. Finally, SAD identifies TPL versions by evaluating the structural similarity of the sub-graph formed by matched classes within the CDGs of the TPL and the app. Extensive evaluation on three datasets demonstrates the effectiveness of SAD and its components. SAD achieves F1 scores of 97.64% and 84.82% for library-level and version-level detection on obfuscated apps, respectively, surpassing existing state-of-the-art tools. The version-level false positives reported by the best tool is 1.61 times that of SAD. We further evaluate the degree to which TPLs identified by detection tools correspond to actual TPL classes.</li>
</ul>

<h3>Title: Beyond One-Hot Labels: Semantic Mixing for Model Calibration</h3>
<ul>
<li><strong>Authors: </strong>Haoyang Luo, Linwei Tao, Minjing Dong, Chang Xu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13548">https://arxiv.org/abs/2504.13548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13548">https://arxiv.org/pdf/2504.13548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13548]] Beyond One-Hot Labels: Semantic Mixing for Model Calibration(https://arxiv.org/abs/2504.13548)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Model calibration seeks to ensure that models produce confidence scores that accurately reflect the true likelihood of their predictions being correct. However, existing calibration approaches are fundamentally tied to datasets of one-hot labels implicitly assuming full certainty in all the annotations. Such datasets are effective for classification but provides insufficient knowledge of uncertainty for model calibration, necessitating the curation of datasets with numerically rich ground-truth confidence values. However, due to the scarcity of uncertain visual examples, such samples are not easily available as real datasets. In this paper, we introduce calibration-aware data augmentation to create synthetic datasets of diverse samples and their ground-truth uncertainty. Specifically, we present Calibration-aware Semantic Mixing (CSM), a novel framework that generates training samples with mixed class characteristics and annotates them with distinct confidence scores via diffusion models. Based on this framework, we propose calibrated reannotation to tackle the misalignment between the annotated confidence score and the mixing ratio during the diffusion reverse process. Besides, we explore the loss functions that better fit the new data representation paradigm. Experimental results demonstrate that CSM achieves superior calibration compared to the state-of-the-art calibration approaches. Code is available at this http URL.</li>
</ul>

<h3>Title: Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation</h3>
<ul>
<li><strong>Authors: </strong>CheolWon Na, YunSeok Choi, Jee-Hyong Lee</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13551">https://arxiv.org/abs/2504.13551</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13551">https://arxiv.org/pdf/2504.13551</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13551]] Q-FAKER: Query-free Hard Black-box Attack via Controlled Generation(https://arxiv.org/abs/2504.13551)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Many adversarial attack approaches are proposed to verify the vulnerability of language models. However, they require numerous queries and the information on the target model. Even black-box attack methods also require the target model's output information. They are not applicable in real-world scenarios, as in hard black-box settings where the target model is closed and inaccessible. Even the recently proposed hard black-box attacks still require many queries and demand extremely high costs for training adversarial generators. To address these challenges, we propose Q-faker (Query-free Hard Black-box Attacker), a novel and efficient method that generates adversarial examples without accessing the target model. To avoid accessing the target model, we use a surrogate model instead. The surrogate model generates adversarial sentences for a target-agnostic attack. During this process, we leverage controlled generation techniques. We evaluate our proposed method on eight datasets. Experimental results demonstrate our method's effectiveness including high transferability and the high quality of the generated adversarial examples, and prove its practical in hard black-box settings.</li>
</ul>

<h3>Title: Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yuling Jiao, Yanming Lai, Yang Wang, Bokai Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13558">https://arxiv.org/abs/2504.13558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13558">https://arxiv.org/pdf/2504.13558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13558]] Transformers Can Overcome the Curse of Dimensionality: A Theoretical Study from an Approximation Perspective(https://arxiv.org/abs/2504.13558)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The Transformer model is widely used in various application areas of machine learning, such as natural language processing. This paper investigates the approximation of the H√∂lder continuous function class $\mathcal{H}_{Q}^{\beta}\left([0,1]^{d\times n},\mathbb{R}^{d\times n}\right)$ by Transformers and constructs several Transformers that can overcome the curse of dimensionality. These Transformers consist of one self-attention layer with one head and the softmax function as the activation function, along with several feedforward layers. For example, to achieve an approximation accuracy of $\epsilon$, if the activation functions of the feedforward layers in the Transformer are ReLU and floor, only $\mathcal{O}\left(\log\frac{1}{\epsilon}\right)$ layers of feedforward layers are needed, with widths of these layers not exceeding $\mathcal{O}\left(\frac{1}{\epsilon^{2/\beta}}\log\frac{1}{\epsilon}\right)$. If other activation functions are allowed in the feedforward layers, the width of the feedforward layers can be further reduced to a constant. These results demonstrate that Transformers have a strong expressive capability. The construction in this paper is based on the Kolmogorov-Arnold Representation Theorem and does not require the concept of contextual mapping, hence our proof is more intuitively clear compared to previous Transformer approximation works. Additionally, the translation technique proposed in this paper helps to apply the previous approximation results of feedforward neural networks to Transformer research.</li>
</ul>

<h3>Title: Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation</h3>
<ul>
<li><strong>Authors: </strong>SoYoung Park, Hyewon Lee, Mingyu Choi, Seunghoon Han, Jong-Ryul Lee, Sungsu Lim, Tae-Ho Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13560">https://arxiv.org/abs/2504.13560</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13560">https://arxiv.org/pdf/2504.13560</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13560]] Zero-Shot Industrial Anomaly Segmentation with Image-Aware Prompt Generation(https://arxiv.org/abs/2504.13560)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Anomaly segmentation is essential for industrial quality, maintenance, and stability. Existing text-guided zero-shot anomaly segmentation models are effective but rely on fixed prompts, limiting adaptability in diverse industrial scenarios. This highlights the need for flexible, context-aware prompting strategies. We propose Image-Aware Prompt Anomaly Segmentation (IAP-AS), which enhances anomaly segmentation by generating dynamic, context-aware prompts using an image tagging model and a large language model (LLM). IAP-AS extracts object attributes from images to generate context-aware prompts, improving adaptability and generalization in dynamic and unstructured industrial environments. In our experiments, IAP-AS improves the F1-max metric by up to 10%, demonstrating superior adaptability and generalization. It provides a scalable solution for anomaly segmentation across industries</li>
</ul>

<h3>Title: WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Yang Wu, Yun Zhu, Kaihua Zhang, Jianjun Qian, Jin Xie, Jian Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13561">https://arxiv.org/abs/2504.13561</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13561">https://arxiv.org/pdf/2504.13561</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13561]] WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion(https://arxiv.org/abs/2504.13561)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D scene perception demands a large amount of adverse-weather LiDAR data, yet the cost of LiDAR data collection presents a significant scaling-up challenge. To this end, a series of LiDAR simulators have been proposed. Yet, they can only simulate a single adverse weather with a single physical model, and the fidelity of the generated data is quite limited. This paper presents WeatherGen, the first unified diverse-weather LiDAR data diffusion generation framework, significantly improving fidelity. Specifically, we first design a map-based data producer, which can provide a vast amount of high-quality diverse-weather data for training purposes. Then, we utilize the diffusion-denoising paradigm to construct a diffusion model. Among them, we propose a spider mamba generator to restore the disturbed diverse weather data gradually. The spider mamba models the feature interactions by scanning the LiDAR beam circle or central ray, excellently maintaining the physical structure of the LiDAR data. Subsequently, following the generator to transfer real-world knowledge, we design a latent feature aligner. Afterward, we devise a contrastive learning-based controller, which equips weather control signals with compact semantic knowledge through language supervision, guiding the diffusion model to generate more discriminative data. Extensive evaluations demonstrate the high generation quality of WeatherGen. Through WeatherGen, we construct the mini-weather dataset, promoting the performance of the downstream task under adverse weather conditions. Code is available: this https URL</li>
</ul>

<h3>Title: DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification</h3>
<ul>
<li><strong>Authors: </strong>Yu Li, Han Jiang, Zhihua Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13562">https://arxiv.org/abs/2504.13562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13562">https://arxiv.org/pdf/2504.13562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13562]] DETAM: Defending LLMs Against Jailbreak Attacks via Targeted Attention Modification(https://arxiv.org/abs/2504.13562)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>With the widespread adoption of Large Language Models (LLMs), jailbreak attacks have become an increasingly pressing safety concern. While safety-aligned LLMs can effectively defend against normal harmful queries, they remain vulnerable to such attacks. Existing defense methods primarily rely on fine-tuning or input modification, which often suffer from limited generalization and reduced utility. To address this, we introduce DETAM, a finetuning-free defense approach that improves the defensive capabilities against jailbreak attacks of LLMs via targeted attention modification. Specifically, we analyze the differences in attention scores between successful and unsuccessful defenses to identify the attention heads sensitive to jailbreak attacks. During inference, we reallocate attention to emphasize the user's core intention, minimizing interference from attack tokens. Our experimental results demonstrate that DETAM outperforms various baselines in jailbreak defense and exhibits robust generalization across different attacks and models, maintaining its effectiveness even on in-the-wild jailbreak data. Furthermore, in evaluating the model's utility, we incorporated over-defense datasets, which further validate the superior performance of our approach. The code will be released immediately upon acceptance.</li>
</ul>

<h3>Title: Bayesian continual learning and forgetting in neural networks</h3>
<ul>
<li><strong>Authors: </strong>Djohan Bonnet, Kellian Cottart, Tifenn Hirtzlin, Tarcisius Januel, Thomas Dalgaty, Elisa Vianello, Damien Querlioz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13569">https://arxiv.org/abs/2504.13569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13569">https://arxiv.org/pdf/2504.13569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13569]] Bayesian continual learning and forgetting in neural networks(https://arxiv.org/abs/2504.13569)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Biological synapses effortlessly balance memory retention and flexibility, yet artificial neural networks still struggle with the extremes of catastrophic forgetting and catastrophic remembering. Here, we introduce Metaplasticity from Synaptic Uncertainty (MESU), a Bayesian framework that updates network parameters according their uncertainty. This approach allows a principled combination of learning and forgetting that ensures that critical knowledge is preserved while unused or outdated information is gradually released. Unlike standard Bayesian approaches -- which risk becoming overly constrained, and popular continual-learning methods that rely on explicit task boundaries, MESU seamlessly adapts to streaming data. It further provides reliable epistemic uncertainty estimates, allowing out-of-distribution detection, the only computational cost being to sample the weights multiple times to provide proper output statistics. Experiments on image-classification benchmarks demonstrate that MESU mitigates catastrophic forgetting, while maintaining plasticity for new tasks. When training 200 sequential permuted MNIST tasks, MESU outperforms established continual learning techniques in terms of accuracy, capability to learn additional tasks, and out-of-distribution data detection. Additionally, due to its non-reliance on task boundaries, MESU outperforms conventional learning techniques on the incremental training of CIFAR-100 tasks consistently in a wide range of scenarios. Our results unify ideas from metaplasticity, Bayesian inference, and Hessian-based regularization, offering a biologically-inspired pathway to robust, perpetual learning.</li>
</ul>

<h3>Title: Cybersquatting in Web3: The Case of NFT</h3>
<ul>
<li><strong>Authors: </strong>Kai Ma, Ningyu He, Jintao Huang, Bosi Zhang, Ping Wu, Haoyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13573">https://arxiv.org/abs/2504.13573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13573">https://arxiv.org/pdf/2504.13573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13573]] Cybersquatting in Web3: The Case of NFT(https://arxiv.org/abs/2504.13573)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Cybersquatting refers to the practice where attackers register a domain name similar to a legitimate one to confuse users for illegal gains. With the growth of the Non-Fungible Token (NFT) ecosystem, there are indications that cybersquatting tactics have evolved from targeting domain names to NFTs. This paper presents the first in-depth measurement study of NFT cybersquatting. By analyzing over 220K NFT collections with over 150M NFT tokens, we have identified 8,019 cybersquatting NFT collections targeting 654 popular NFT projects. Through systematic analysis, we discover and characterize seven distinct squatting tactics employed by scammers. We further conduct a comprehensive measurement study of these cybersquatting NFT collections, examining their metadata, associated digital asset content, and social media status. Our analysis reveals that these NFT cybersquatting activities have resulted in a significant financial impact, with over 670K victims affected by these scams, leading to a total financial exploitation of $59.26 million. Our findings demonstrate the urgency to identify and prevent NFT squatting abuses.</li>
</ul>

<h3>Title: MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework</h3>
<ul>
<li><strong>Authors: </strong>Zhenkai Qin, Feng Zhu, Huan Zeng, Xunyi Nong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13574">https://arxiv.org/abs/2504.13574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13574">https://arxiv.org/pdf/2504.13574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13574]] MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework(https://arxiv.org/abs/2504.13574)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The demand for lightweight models in image classification tasks under resource-constrained environments necessitates a balance between computational efficiency and robust feature representation. Traditional attention mechanisms, despite their strong feature modeling capability, often struggle with high computational complexity and structural rigidity, limiting their applicability in scenarios with limited computational resources (e.g., edge devices or real-time systems). To address this, we propose the Multi-Agent Aggregation Module (MAAM), a lightweight attention architecture integrated with the MindSpore framework. MAAM employs three parallel agent branches with independently parameterized operations to extract heterogeneous features, adaptively fused via learnable scalar weights, and refined through a convolutional compression layer. Leveraging MindSpore's dynamic computational graph and operator fusion, MAAM achieves 87.0% accuracy on the CIFAR-10 dataset, significantly outperforming conventional CNN (58.3%) and MLP (49.6%) models, while improving training efficiency by 30%. Ablation studies confirm the critical role of agent attention (accuracy drops to 32.0% if removed) and compression modules (25.5% if omitted), validating their necessity for maintaining discriminative feature learning. The framework's hardware acceleration capabilities and minimal memory footprint further demonstrate its practicality, offering a deployable solution for image classification in resource-constrained scenarios without compromising accuracy.</li>
</ul>

<h3>Title: HDBFormer: Efficient RGB-D Semantic Segmentation with A Heterogeneous Dual-Branch Framework</h3>
<ul>
<li><strong>Authors: </strong>Shuobin Wei, Zhuang Zhou, Zhengan Lu, Zizhao Yuan, Binghua Su</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13579">https://arxiv.org/abs/2504.13579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13579">https://arxiv.org/pdf/2504.13579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13579]] HDBFormer: Efficient RGB-D Semantic Segmentation with A Heterogeneous Dual-Branch Framework(https://arxiv.org/abs/2504.13579)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>In RGB-D semantic segmentation for indoor scenes, a key challenge is effectively integrating the rich color information from RGB images with the spatial distance information from depth images. However, most existing methods overlook the inherent differences in how RGB and depth images express information. Properly distinguishing the processing of RGB and depth images is essential to fully exploiting their unique and significant characteristics. To address this, we propose a novel heterogeneous dual-branch framework called HDBFormer, specifically designed to handle these modality differences. For RGB images, which contain rich detail, we employ both a basic and detail encoder to extract local and global features. For the simpler depth images, we propose LDFormer, a lightweight hierarchical encoder that efficiently extracts depth features with fewer parameters. Additionally, we introduce the Modality Information Interaction Module (MIIM), which combines transformers with large kernel convolutions to interact global and local information across modalities efficiently. Extensive experiments show that HDBFormer achieves state-of-the-art performance on the NYUDepthv2 and SUN-RGBD datasets. The code is available at: this https URL.</li>
</ul>

<h3>Title: HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering</h3>
<ul>
<li><strong>Authors: </strong>Alexander Rusnak, Fr√©d√©ric Kaplan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13590">https://arxiv.org/abs/2504.13590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13590">https://arxiv.org/pdf/2504.13590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13590]] HAECcity: Open-Vocabulary Scene Understanding of City-Scale Point Clouds with Superpoint Graph Clustering(https://arxiv.org/abs/2504.13590)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Traditional 3D scene understanding techniques are generally predicated on hand-annotated label sets, but in recent years a new class of open-vocabulary 3D scene understanding techniques has emerged. Despite the success of this paradigm on small scenes, existing approaches cannot scale efficiently to city-scale 3D datasets. In this paper, we present Hierarchical vocab-Agnostic Expert Clustering (HAEC), after the latin word for 'these', a superpoint graph clustering based approach which utilizes a novel mixture of experts graph transformer for its backbone. We administer this highly scalable approach to the first application of open-vocabulary scene understanding on the SensatUrban city-scale dataset. We also demonstrate a synthetic labeling pipeline which is derived entirely from the raw point clouds with no hand-annotation. Our technique can help unlock complex operations on dense urban 3D scenes and open a new path forward in the processing of digital twins.</li>
</ul>

<h3>Title: KAN or MLP? Point Cloud Shows the Way Forward</h3>
<ul>
<li><strong>Authors: </strong>Yan Shi, Qingdong He, Yijun Liu, Xiaoyu Liu, Jingyong Su</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13593">https://arxiv.org/abs/2504.13593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13593">https://arxiv.org/pdf/2504.13593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13593]] KAN or MLP? Point Cloud Shows the Way Forward(https://arxiv.org/abs/2504.13593)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-Layer Perceptrons (MLPs) have become one of the fundamental architectural component in point cloud analysis due to its effective feature learning mechanism. However, when processing complex geometric structures in point clouds, MLPs' fixed activation functions struggle to efficiently capture local geometric features, while suffering from poor parameter efficiency and high model redundancy. In this paper, we propose PointKAN, which applies Kolmogorov-Arnold Networks (KANs) to point cloud analysis tasks to investigate their efficacy in hierarchical feature representation. First, we introduce a Geometric Affine Module (GAM) to transform local features, improving the model's robustness to geometric variations. Next, in the Local Feature Processing (LFP), a parallel structure extracts both group-level features and global context, providing a rich representation of both fine details and overall structure. Finally, these features are combined and processed in the Global Feature Processing (GFP). By repeating these operations, the receptive field gradually expands, enabling the model to capture complete geometric information of the point cloud. To overcome the high parameter counts and computational inefficiency of standard KANs, we develop Efficient-KANs in the PointKAN-elite variant, which significantly reduces parameters while maintaining accuracy. Experimental results demonstrate that PointKAN outperforms PointMLP on benchmark datasets such as ModelNet40, ScanObjectNN, and ShapeNetPart, with particularly strong performance in Few-shot Learning task. Additionally, PointKAN achieves substantial reductions in parameter counts and computational complexity (FLOPs). This work highlights the potential of KANs-based architectures in 3D vision and opens new avenues for research in point cloud understanding.</li>
</ul>

<h3>Title: Bitcoin's Edge: Embedded Sentiment in Blockchain Transactional Data</h3>
<ul>
<li><strong>Authors: </strong>Charalampos Kleitsikas, Nikolaos Korfiatis, Stefanos Leonardos, Carmine Ventre</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13598">https://arxiv.org/abs/2504.13598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13598">https://arxiv.org/pdf/2504.13598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13598]] Bitcoin's Edge: Embedded Sentiment in Blockchain Transactional Data(https://arxiv.org/abs/2504.13598)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Cryptocurrency blockchains, beyond their primary role as distributed payment systems, are increasingly used to store and share arbitrary content, such as text messages and files. Although often non-financial, this hidden content can impact price movements by conveying private information, shaping sentiment, and influencing public opinion. However, current analyses of such data are limited in scope and scalability, primarily relying on manual classification or hand-crafted heuristics. In this work, we address these limitations by employing Natural Language Processing techniques to analyze, detect patterns, and extract public sentiment encoded within blockchain transactional data. Using a variety of Machine Learning techniques, we showcase for the first time the predictive power of blockchain-embedded sentiment in forecasting cryptocurrency price movements on the Bitcoin and Ethereum blockchains. Our findings shed light on a previously underexplored source of freely available, transparent, and immutable data and introduce blockchain sentiment analysis as a novel and robust framework for enhancing financial predictions in cryptocurrency markets. Incidentally, we discover an asymmetry between cryptocurrencies; Bitcoin has an informational advantage over Ethereum in that the sentiment embedded into transactional data is sufficient to predict its price movement.</li>
</ul>

<h3>Title: Continual Pre-Training is (not) What You Need in Domain Adaption</h3>
<ul>
<li><strong>Authors: </strong>Pin-Er Chen, Da-Chen Lian, Shu-Kai Hsieh, Sieh-Chuen Huang, Hsuan-Lei Shao, Jun-Wei Chiu, Yang-Hsien Lin, Zih-Ching Chen, Cheng-Kuang, Eddie TC Huang, Simon See</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13603">https://arxiv.org/abs/2504.13603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13603">https://arxiv.org/pdf/2504.13603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13603]] Continual Pre-Training is (not) What You Need in Domain Adaption(https://arxiv.org/abs/2504.13603)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The recent advances in Legal Large Language Models (LLMs) have transformed the landscape of legal research and practice by automating tasks, enhancing research precision, and supporting complex decision-making processes. However, effectively adapting LLMs to the legal domain remains challenging due to the complexity of legal reasoning, the need for precise interpretation of specialized language, and the potential for hallucinations. This paper examines the efficacy of Domain-Adaptive Continual Pre-Training (DACP) in improving the legal reasoning capabilities of LLMs. Through a series of experiments on legal reasoning tasks within the Taiwanese legal framework, we demonstrate that while DACP enhances domain-specific knowledge, it does not uniformly improve performance across all legal tasks. We discuss the trade-offs involved in DACP, particularly its impact on model generalization and performance in prompt-based tasks, and propose directions for future research to optimize domain adaptation strategies in legal AI.</li>
</ul>

<h3>Title: Fairness and Robustness in Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Khoa Tran, Simon S. Woo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13610">https://arxiv.org/abs/2504.13610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13610">https://arxiv.org/pdf/2504.13610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13610]] Fairness and Robustness in Machine Unlearning(https://arxiv.org/abs/2504.13610)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, fair</a></li>
<li><strong>Abstract: </strong>Machine unlearning poses the challenge of ``how to eliminate the influence of specific data from a pretrained model'' in regard to privacy concerns. While prior research on approximated unlearning has demonstrated accuracy and efficiency in time complexity, we claim that it falls short of achieving exact unlearning, and we are the first to focus on fairness and robustness in machine unlearning algorithms. Our study presents fairness Conjectures for a well-trained model, based on the variance-bias trade-off characteristic, and considers their relevance to robustness. Our Conjectures are supported by experiments conducted on the two most widely used model architectures, ResNet and ViT, demonstrating the correlation between fairness and robustness: \textit{the higher fairness-gap is, the more the model is sensitive and vulnerable}. In addition, our experiments demonstrate the vulnerability of current state-of-the-art approximated unlearning algorithms to adversarial attacks, where their unlearned models suffer a significant drop in accuracy compared to the exact-unlearned models. We claim that our fairness-gap measurement and robustness metric should be used to evaluate the unlearning algorithm. Furthermore, we demonstrate that unlearning in the intermediate and last layers is sufficient and cost-effective for time and memory complexity.</li>
</ul>

<h3>Title: Entropic Time Schedulers for Generative Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Dejan Stancevic, Luca Ambrogioni</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13612">https://arxiv.org/abs/2504.13612</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13612">https://arxiv.org/pdf/2504.13612</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13612]] Entropic Time Schedulers for Generative Diffusion Models(https://arxiv.org/abs/2504.13612)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The practical performance of generative diffusion models depends on the appropriate choice of the noise scheduling function, which can also be equivalently expressed as a time reparameterization. In this paper, we present a time scheduler that selects sampling points based on entropy rather than uniform time spacing, ensuring that each point contributes an equal amount of information to the final generation. We prove that this time reparameterization does not depend on the initial choice of time. Furthermore, we provide a tractable exact formula to estimate this \emph{entropic time} for a trained model using the training loss without substantial overhead. Alongside the entropic time, inspired by the optimality results, we introduce a rescaled entropic time. In our experiments with mixtures of Gaussian distributions and ImageNet, we show that using the (rescaled) entropic times greatly improves the inference performance of trained models. In particular, we found that the image quality in pretrained EDM2 models, as evaluated by FID and FD-DINO scores, can be substantially increased by the rescaled entropic time reparameterization without increasing the number of function evaluations, with greater improvements in the few NFEs regime.</li>
</ul>

<h3>Title: Long-context Non-factoid Question Answering in Indic Languages</h3>
<ul>
<li><strong>Authors: </strong>Ritwik Mishra, Rajiv Ratn Shah, Ponnurangam Kumaraguru</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13615">https://arxiv.org/abs/2504.13615</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13615">https://arxiv.org/pdf/2504.13615</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13615]] Long-context Non-factoid Question Answering in Indic Languages(https://arxiv.org/abs/2504.13615)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, explainability, large language model</a></li>
<li><strong>Abstract: </strong>Question Answering (QA) tasks, which involve extracting answers from a given context, are relatively straightforward for modern Large Language Models (LLMs) when the context is short. However, long contexts pose challenges due to the quadratic complexity of the self-attention mechanism. This challenge is compounded in Indic languages, which are often low-resource. This study explores context-shortening techniques, including Open Information Extraction (OIE), coreference resolution, Answer Paragraph Selection (APS), and their combinations, to improve QA performance. Compared to the baseline of unshortened (long) contexts, our experiments on four Indic languages (Hindi, Tamil, Telugu, and Urdu) demonstrate that context-shortening techniques yield an average improvement of 4\% in semantic scores and 47\% in token-level scores when evaluated on three popular LLMs without fine-tuning. Furthermore, with fine-tuning, we achieve an average increase of 2\% in both semantic and token-level scores. Additionally, context-shortening reduces computational overhead. Explainability techniques like LIME and SHAP reveal that when the APS model confidently identifies the paragraph containing the answer, nearly all tokens within the selected text receive high relevance scores. However, the study also highlights the limitations of LLM-based QA systems in addressing non-factoid questions, particularly those requiring reasoning or debate. Moreover, verbalizing OIE-generated triples does not enhance system performance. These findings emphasize the potential of context-shortening techniques to improve the efficiency and effectiveness of LLM-based QA systems, especially for low-resource languages. The source code and resources are available at this https URL.</li>
</ul>

<h3>Title: Compile Scene Graphs with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Zuyao Chen, Jinlin Wu, Zhen Lei, Marc Pollefeys, Chang Wen Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13617">https://arxiv.org/abs/2504.13617</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13617">https://arxiv.org/pdf/2504.13617</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13617]] Compile Scene Graphs with Reinforcement Learning(https://arxiv.org/abs/2504.13617)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Next token prediction is the fundamental principle for training large language models (LLMs), and reinforcement learning (RL) further enhances their reasoning performance. As an effective way to model language, image, video, and other modalities, the use of LLMs for end-to-end extraction of structured visual representations, such as scene graphs, remains underexplored. It requires the model to accurately produce a set of objects and relationship triplets, rather than generating text token by token. To achieve this, we introduce R1-SGG, a multimodal LLM (M-LLM) initially trained via supervised fine-tuning (SFT) on the scene graph dataset and subsequently refined using reinforcement learning to enhance its ability to generate scene graphs in an end-to-end manner. The SFT follows a conventional prompt-response paradigm, while RL requires the design of effective reward signals. Given the structured nature of scene graphs, we design a graph-centric reward function that integrates node-level rewards, edge-level rewards, and a format consistency reward. Our experiments demonstrate that rule-based RL substantially enhances model performance in the SGG task, achieving a zero failure rate--unlike supervised fine-tuning (SFT), which struggles to generalize effectively. Our code is available at this https URL.</li>
</ul>

<h3>Title: Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing</h3>
<ul>
<li><strong>Authors: </strong>Cong William Lin, Wu Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13629">https://arxiv.org/abs/2504.13629</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13629">https://arxiv.org/pdf/2504.13629</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13629]] Divergent LLM Adoption and Heterogeneous Convergence Paths in Research Writing(https://arxiv.org/abs/2504.13629)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs), such as ChatGPT, are reshaping content creation and academic writing. This study investigates the impact of AI-assisted generative revisions on research manuscripts, focusing on heterogeneous adoption patterns and their influence on writing convergence. Leveraging a dataset of over 627,000 academic papers from arXiv, we develop a novel classification framework by fine-tuning prompt- and discipline-specific large language models to detect the style of ChatGPT-revised texts. Our findings reveal substantial disparities in LLM adoption across academic disciplines, gender, native language status, and career stage, alongside a rapid evolution in scholarly writing styles. Moreover, LLM usage enhances clarity, conciseness, and adherence to formal writing conventions, with improvements varying by revision type. Finally, a difference-in-differences analysis shows that while LLMs drive convergence in academic writing, early adopters, male researchers, non-native speakers, and junior scholars exhibit the most pronounced stylistic shifts, aligning their writing more closely with that of established researchers.</li>
</ul>

<h3>Title: DenSe-AdViT: A novel Vision Transformer for Dense SAR Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Yang Zhang, Jingyi Cao, Yanan You, Yuanyuan Qiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13638">https://arxiv.org/abs/2504.13638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13638">https://arxiv.org/pdf/2504.13638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13638]] DenSe-AdViT: A novel Vision Transformer for Dense SAR Object Detection(https://arxiv.org/abs/2504.13638)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>Vision Transformer (ViT) has achieved remarkable results in object detection for synthetic aperture radar (SAR) images, owing to its exceptional ability to extract global features. However, it struggles with the extraction of multi-scale local features, leading to limited performance in detecting small targets, especially when they are densely arranged. Therefore, we propose Density-Sensitive Vision Transformer with Adaptive Tokens (DenSe-AdViT) for dense SAR target detection. We design a Density-Aware Module (DAM) as a preliminary component that generates a density tensor based on target distribution. It is guided by a meticulously crafted objective metric, enabling precise and effective capture of the spatial distribution and density of objects. To integrate the multi-scale information enhanced by convolutional neural networks (CNNs) with the global features derived from the Transformer, Density-Enhanced Fusion Module (DEFM) is proposed. It effectively refines attention toward target-survival regions with the assist of density mask and the multiple sources features. Notably, our DenSe-AdViT achieves 79.8% mAP on the RSDD dataset and 92.5% on the SIVED dataset, both of which feature a large number of densely distributed vehicle targets.</li>
</ul>

<h3>Title: Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning</h3>
<ul>
<li><strong>Authors: </strong>Tao He, Lizi Liao, Ming Liu, Bing Qin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13643">https://arxiv.org/abs/2504.13643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13643">https://arxiv.org/pdf/2504.13643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13643]] Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning(https://arxiv.org/abs/2504.13643)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements in dialogue policy planning have emphasized optimizing system agent policies to achieve predefined goals, focusing on strategy design, trajectory acquisition, and efficient training paradigms. However, these approaches often overlook the critical role of user characteristics, which are essential in real-world scenarios like conversational search and recommendation, where interactions must adapt to individual user traits such as personality, preferences, and goals. To address this gap, we first conduct a comprehensive study utilizing task-specific user personas to systematically assess dialogue policy planning under diverse user behaviors. By leveraging realistic user profiles for different tasks, our study reveals significant limitations in existing approaches, highlighting the need for user-tailored dialogue policy planning. Building on this foundation, we present the User-Tailored Dialogue Policy Planning (UDP) framework, which incorporates an Intrinsic User World Model to model user traits and feedback. UDP operates in three stages: (1) User Persona Portraying, using a diffusion model to dynamically infer user profiles; (2) User Feedback Anticipating, leveraging a Brownian Bridge-inspired anticipator to predict user reactions; and (3) User-Tailored Policy Planning, integrating these insights to optimize response strategies. To ensure robust performance, we further propose an active learning approach that prioritizes challenging user personas during training. Comprehensive experiments on benchmarks, including collaborative and non-collaborative settings, demonstrate the effectiveness of UDP in learning user-specific dialogue strategies. Results validate the protocol's utility and highlight UDP's robustness, adaptability, and potential to advance user-centric dialogue systems.</li>
</ul>

<h3>Title: Efficient Parameter Adaptation for Multi-Modal Medical Image Segmentation and Prognosis</h3>
<ul>
<li><strong>Authors: </strong>Numan Saeed, Shahad Hardan, Muhammad Ridzuan, Nada Saadi, Karthik Nandakumar, Mohammad Yaqub</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13645">https://arxiv.org/abs/2504.13645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13645">https://arxiv.org/pdf/2504.13645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13645]] Efficient Parameter Adaptation for Multi-Modal Medical Image Segmentation and Prognosis(https://arxiv.org/abs/2504.13645)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Cancer detection and prognosis relies heavily on medical imaging, particularly CT and PET scans. Deep Neural Networks (DNNs) have shown promise in tumor segmentation by fusing information from these modalities. However, a critical bottleneck exists: the dependency on CT-PET data concurrently for training and inference, posing a challenge due to the limited availability of PET scans. Hence, there is a clear need for a flexible and efficient framework that can be trained with the widely available CT scans and can be still adapted for PET scans when they become available. In this work, we propose a parameter-efficient multi-modal adaptation (PEMMA) framework for lightweight upgrading of a transformer-based segmentation model trained only on CT scans such that it can be efficiently adapted for use with PET scans when they become available. This framework is further extended to perform prognosis task maintaining the same efficient cross-modal fine-tuning approach. The proposed approach is tested with two well-known segementation backbones, namely UNETR and Swin UNETR. Our approach offers two main advantages. Firstly, we leverage the inherent modularity of the transformer architecture and perform low-rank adaptation (LoRA) as well as decomposed low-rank adaptation (DoRA) of the attention weights to achieve parameter-efficient adaptation. Secondly, by minimizing cross-modal entanglement, PEMMA allows updates using only one modality without causing catastrophic forgetting in the other. Our method achieves comparable performance to early fusion, but with only 8% of the trainable parameters, and demonstrates a significant +28% Dice score improvement on PET scans when trained with a single modality. Furthermore, in prognosis, our method improves the concordance index by +10% when adapting a CT-pretrained model to include PET scans, and by +23% when adapting for both PET and EHR data.</li>
</ul>

<h3>Title: Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems</h3>
<ul>
<li><strong>Authors: </strong>Uthman Baroudi, Alala BaHamid, Yasser Elalfy, Ziad Al Alami</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13648">https://arxiv.org/abs/2504.13648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13648">https://arxiv.org/pdf/2504.13648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13648]] Enhancing Pothole Detection and Characterization: Integrated Segmentation and Depth Estimation in Road Anomaly Systems(https://arxiv.org/abs/2504.13648)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Road anomaly detection plays a crucial role in road maintenance and in enhancing the safety of both drivers and vehicles. Recent machine learning approaches for road anomaly detection have overcome the tedious and time-consuming process of manual analysis and anomaly counting; however, they often fall short in providing a complete characterization of road potholes. In this paper, we leverage transfer learning by adopting a pre-trained YOLOv8-seg model for the automatic characterization of potholes using digital images captured from a dashboard-mounted camera. Our work includes the creation of a novel dataset, comprising both images and their corresponding depth maps, collected from diverse road environments in Al-Khobar city and the KFUPM campus in Saudi Arabia. Our approach performs pothole detection and segmentation to precisely localize potholes and calculate their area. Subsequently, the segmented image is merged with its depth map to extract detailed depth information about the potholes. This integration of segmentation and depth data offers a more comprehensive characterization compared to previous deep learning-based road anomaly detection systems. Overall, this method not only has the potential to significantly enhance autonomous vehicle navigation by improving the detection and characterization of road hazards but also assists road maintenance authorities in responding more effectively to road damage.</li>
</ul>

<h3>Title: Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction</h3>
<ul>
<li><strong>Authors: </strong>Felix M√§chtle, Nils Loose, Tim Schulz, Florian Sieck, Jan-Niclas Serr, Ralf M√∂ller, Thomas Eisenbarth</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13676">https://arxiv.org/abs/2504.13676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13676">https://arxiv.org/pdf/2504.13676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13676]] Trace Gadgets: Minimizing Code Context for Machine Learning-Based Vulnerability Prediction(https://arxiv.org/abs/2504.13676)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>As the number of web applications and API endpoints exposed to the Internet continues to grow, so does the number of exploitable vulnerabilities. Manually identifying such vulnerabilities is tedious. Meanwhile, static security scanners tend to produce many false positives. While machine learning-based approaches are promising, they typically perform well only in scenarios where training and test data are closely related. A key challenge for ML-based vulnerability detection is providing suitable and concise code context, as excessively long contexts negatively affect the code comprehension capabilities of machine learning models, particularly smaller ones. This work introduces Trace Gadgets, a novel code representation that minimizes code context by removing non-related code. Trace Gadgets precisely capture the statements that cover the path to the vulnerability. As input for ML models, Trace Gadgets provide a minimal but complete context, thereby improving the detection performance. Moreover, we collect a large-scale dataset generated from real-world applications with manually curated labels to further improve the performance of ML-based vulnerability detectors. Our results show that state-of-the-art machine learning models perform best when using Trace Gadgets compared to previous code representations, surpassing the detection capabilities of industry-standard static scanners such as GitHub's CodeQL by at least 4% on a fully unseen dataset. By applying our framework to real-world applications, we identify and report previously unknown vulnerabilities in widely deployed software.</li>
</ul>

<h3>Title: Deep literature reviews: an application of fine-tuned language models to migration research</h3>
<ul>
<li><strong>Authors: </strong>Stefano M. Iacus, Haodong Qi, Jiyoung Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.AP, stat.CO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13685">https://arxiv.org/abs/2504.13685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13685">https://arxiv.org/pdf/2504.13685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13685]] Deep literature reviews: an application of fine-tuned language models to migration research(https://arxiv.org/abs/2504.13685)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a hybrid framework for literature reviews that augments traditional bibliometric methods with large language models (LLMs). By fine-tuning open-source LLMs, our approach enables scalable extraction of qualitative insights from large volumes of research content, enhancing both the breadth and depth of knowledge synthesis. To improve annotation efficiency and consistency, we introduce an error-focused validation process in which LLMs generate initial labels and human reviewers correct misclassifications. Applying this framework to over 20000 scientific articles about human migration, we demonstrate that a domain-adapted LLM can serve as a "specialist" model - capable of accurately selecting relevant studies, detecting emerging trends, and identifying critical research gaps. Notably, the LLM-assisted review reveals a growing scholarly interest in climate-induced migration. However, existing literature disproportionately centers on a narrow set of environmental hazards (e.g., floods, droughts, sea-level rise, and land degradation), while overlooking others that more directly affect human health and well-being, such as air and water pollution or infectious diseases. This imbalance highlights the need for more comprehensive research that goes beyond physical environmental changes to examine their ecological and societal consequences, particularly in shaping migration as an adaptive response. Overall, our proposed framework demonstrates the potential of fine-tuned LLMs to conduct more efficient, consistent, and insightful literature reviews across disciplines, ultimately accelerating knowledge synthesis and scientific discovery.</li>
</ul>

<h3>Title: Analysing the Robustness of Vision-Language-Models to Common Corruptions</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Usama, Syeda Aisha Asim, Syed Bilal Ali, Syed Talal Wasim, Umair Bin Mansoor</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13690">https://arxiv.org/abs/2504.13690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13690">https://arxiv.org/pdf/2504.13690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13690]] Analysing the Robustness of Vision-Language-Models to Common Corruptions(https://arxiv.org/abs/2504.13690)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have demonstrated impressive capabilities in understanding and reasoning about visual and textual content. However, their robustness to common image corruptions remains under-explored. In this work, we present the first comprehensive analysis of VLM robustness across 19 corruption types from the ImageNet-C benchmark, spanning four categories: noise, blur, weather, and digital distortions. We introduce two new benchmarks, TextVQA-C and GQA-C, to systematically evaluate how corruptions affect scene text understanding and object-based reasoning, respectively. Our analysis reveals that transformer-based VLMs exhibit distinct vulnerability patterns across tasks: text recognition deteriorates most severely under blur and snow corruptions, while object reasoning shows higher sensitivity to corruptions such as frost and impulse noise. We connect these observations to the frequency-domain characteristics of different corruptions, revealing how transformers' inherent bias toward low-frequency processing explains their differential robustness patterns. Our findings provide valuable insights for developing more corruption-robust vision-language models for real-world applications.</li>
</ul>

<h3>Title: Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching</h3>
<ul>
<li><strong>Authors: </strong>Heng Liu, Guanghui Li, Mingqi Gao, Xiantong Zhen, Feng Zheng, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13710">https://arxiv.org/abs/2504.13710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13710">https://arxiv.org/pdf/2504.13710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13710]] Few-Shot Referring Video Single- and Multi-Object Segmentation via Cross-Modal Affinity with Instance Sequence Matching(https://arxiv.org/abs/2504.13710)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Referring video object segmentation (RVOS) aims to segment objects in videos guided by natural language descriptions. We propose FS-RVOS, a Transformer-based model with two key components: a cross-modal affinity module and an instance sequence matching strategy, which extends FS-RVOS to multi-object segmentation (FS-RVMOS). Experiments show FS-RVOS and FS-RVMOS outperform state-of-the-art methods across diverse benchmarks, demonstrating superior robustness and accuracy.</li>
</ul>

<h3>Title: Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Carloni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, eess.IV, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13717">https://arxiv.org/abs/2504.13717</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13717">https://arxiv.org/pdf/2504.13717</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13717]] Human-aligned Deep Learning: Explainability, Causality, and Biological Inspiration(https://arxiv.org/abs/2504.13717)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, explainability</a></li>
<li><strong>Abstract: </strong>This work aligns deep learning (DL) with human reasoning capabilities and needs to enable more efficient, interpretable, and robust image classification. We approach this from three perspectives: explainability, causality, and biological vision. Introduction and background open this work before diving into operative chapters. First, we assess neural networks' visualization techniques for medical images and validate an explainable-by-design method for breast mass classification. A comprehensive review at the intersection of XAI and causality follows, where we introduce a general scaffold to organize past and future research, laying the groundwork for our second perspective. In the causality direction, we propose novel modules that exploit feature co-occurrence in medical images, leading to more effective and explainable predictions. We further introduce CROCODILE, a general framework that integrates causal concepts, contrastive learning, feature disentanglement, and prior knowledge to enhance generalization. Lastly, we explore biological vision, examining how humans recognize objects, and propose CoCoReco, a connectivity-inspired network with context-aware attention mechanisms. Overall, our key findings include: (i) simple activation maximization lacks insight for medical imaging DL models; (ii) prototypical-part learning is effective and radiologically aligned; (iii) XAI and causal ML are deeply connected; (iv) weak causal signals can be leveraged without a priori information to improve performance and interpretability; (v) our framework generalizes across medical domains and out-of-distribution data; (vi) incorporating biological circuit motifs improves human-aligned recognition. This work contributes toward human-aligned DL and highlights pathways to bridge the gap between research and clinical adoption, with implications for improved trust, diagnostic accuracy, and safe deployment.</li>
</ul>

<h3>Title: MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Lin Yuan, Xiaowan Li, Yan Zhang, Jiawei Zhang, Hongbo Li, Xinbo Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13726">https://arxiv.org/abs/2504.13726</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13726">https://arxiv.org/pdf/2504.13726</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13726]] MLEP: Multi-granularity Local Entropy Patterns for Universal AI-generated Image Detection(https://arxiv.org/abs/2504.13726)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Advancements in image generation technologies have raised significant concerns about their potential misuse, such as producing misinformation and deepfakes. Therefore, there is an urgent need for effective methods to detect AI-generated images (AIGI). Despite progress in AIGI detection, achieving reliable performance across diverse generation models and scenes remains challenging due to the lack of source-invariant features and limited generalization capabilities in existing methods. In this work, we explore the potential of using image entropy as a cue for AIGI detection and propose Multi-granularity Local Entropy Patterns (MLEP), a set of entropy feature maps computed across shuffled small patches over multiple image scaled. MLEP comprehensively captures pixel relationships across dimensions and scales while significantly disrupting image semantics, reducing potential content bias. Leveraging MLEP, a robust CNN-based classifier for AIGI detection can be trained. Extensive experiments conducted in an open-world scenario, evaluating images synthesized by 32 distinct generative models, demonstrate significant improvements over state-of-the-art methods in both accuracy and generalization.</li>
</ul>

<h3>Title: Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Paul K. Mandal, Cole Leo, Connor Hurley</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13730">https://arxiv.org/abs/2504.13730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13730">https://arxiv.org/pdf/2504.13730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13730]] Controlled Territory and Conflict Tracking (CONTACT): (Geo-)Mapping Occupied Territory from Open Source Intelligence(https://arxiv.org/abs/2504.13730)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, generative, large language model</a></li>
<li><strong>Abstract: </strong>Open-source intelligence provides a stream of unstructured textual data that can inform assessments of territorial control. We present CONTACT, a framework for territorial control prediction using large language models (LLMs) and minimal supervision. We evaluate two approaches: SetFit, an embedding-based few-shot classifier, and a prompt tuning method applied to BLOOMZ-560m, a multilingual generative LLM. Our model is trained on a small hand-labeled dataset of news articles covering ISIS activity in Syria and Iraq, using prompt-conditioned extraction of control-relevant signals such as military operations, casualties, and location references. We show that the BLOOMZ-based model outperforms the SetFit baseline, and that prompt-based supervision improves generalization in low-resource settings. CONTACT demonstrates that LLMs fine-tuned using few-shot methods can reduce annotation burdens and support structured inference from open-ended OSINT streams. Our code is available at this https URL.</li>
</ul>

<h3>Title: Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects</h3>
<ul>
<li><strong>Authors: </strong>Yichen Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13733">https://arxiv.org/abs/2504.13733</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13733">https://arxiv.org/pdf/2504.13733</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13733]] Dynamic Regularized CBDT: Variance-Calibrated Causal Boosting for Interpretable Heterogeneous Treatment Effects(https://arxiv.org/abs/2504.13733)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Heterogeneous treatment effect estimation in high-stakes applications demands models that simultaneously optimize precision, interpretability, and calibration. Many existing tree-based causal inference techniques, however, exhibit high estimation errors when applied to observational data because they struggle to capture complex interactions among factors and rely on static regularization schemes. In this work, we propose Dynamic Regularized Causal Boosted Decision Trees (CBDT), a novel framework that integrates variance regularization and average treatment effect calibration into the loss function of gradient boosted decision trees. Our approach dynamically updates the regularization parameters using gradient statistics to better balance the bias-variance tradeoff. Extensive experiments on standard benchmark datasets and real-world clinical data demonstrate that the proposed method significantly improves estimation accuracy while maintaining reliable coverage of true treatment effects. In an intensive care unit patient triage study, the method successfully identified clinically actionable rules and achieved high accuracy in treatment effect estimation. The results validate that dynamic regularization can effectively tighten error bounds and enhance both predictive performance and model interpretability.</li>
</ul>

<h3>Title: Breaking ECDSA with Two Affinely Related Nonces</h3>
<ul>
<li><strong>Authors: </strong>Jamie Gilchrist, William J. Buchanan, Keir Finlow-Bates</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13737">https://arxiv.org/abs/2504.13737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13737">https://arxiv.org/pdf/2504.13737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13737]] Breaking ECDSA with Two Affinely Related Nonces(https://arxiv.org/abs/2504.13737)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>The security of the Elliptic Curve Digital Signature Algorithm (ECDSA) depends on the uniqueness and secrecy of the nonce, which is used in each signature. While it is well understood that nonce $k$ reuse across two distinct messages can leak the private key, we show that even if a distinct value is used for $k_2$, where an affine relationship exists in the form of: \(k_m = a \cdot k_n + b\), we can also recover the private key. Our method requires only two signatures (even over the same message) and relies purely on algebra, with no need for lattice reduction or brute-force search(if the relationship, or offset, is known). To our knowledge, this is the first closed-form derivation of the ECDSA private key from only two signatures over the same message, under a known affine relationship between nonces.</li>
</ul>

<h3>Title: ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Andrea Rigo, Luca Stornaiuolo, Mauro Martino, Bruno Lepri, Nicu Sebe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13745">https://arxiv.org/abs/2504.13745</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13745">https://arxiv.org/pdf/2504.13745</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13745]] ESPLoRA: Enhanced Spatial Precision with Low-Rank Adaption in Text-to-Image Diffusion Models for High-Definition Synthesis(https://arxiv.org/abs/2504.13745)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have revolutionized text-to-image (T2I) synthesis, producing high-quality, photorealistic images. However, they still struggle to properly render the spatial relationships described in text prompts. To address the lack of spatial information in T2I generations, existing methods typically use external network conditioning and predefined layouts, resulting in higher computational costs and reduced flexibility. Our approach builds upon a curated dataset of spatially explicit prompts, meticulously extracted and synthesized from LAION-400M to ensure precise alignment between textual descriptions and spatial layouts. Alongside this dataset, we present ESPLoRA, a flexible fine-tuning framework based on Low-Rank Adaptation, specifically designed to enhance spatial consistency in generative models without increasing generation time or compromising the quality of the outputs. In addition to ESPLoRA, we propose refined evaluation metrics grounded in geometric constraints, capturing 3D spatial relations such as \textit{in front of} or \textit{behind}. These metrics also expose spatial biases in T2I models which, even when not fully mitigated, can be strategically exploited by our TORE algorithm to further improve the spatial consistency of generated images. Our method outperforms the current state-of-the-art framework, CoMPaSS, by 13.33% on established spatial consistency benchmarks.</li>
</ul>

<h3>Title: DAM-Net: Domain Adaptation Network with Micro-Labeled Fine-Tuning for Change Detection</h3>
<ul>
<li><strong>Authors: </strong>Hongjia Chen, Xin Xu, Fangling Pu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13748">https://arxiv.org/abs/2504.13748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13748">https://arxiv.org/pdf/2504.13748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13748]] DAM-Net: Domain Adaptation Network with Micro-Labeled Fine-Tuning for Change Detection(https://arxiv.org/abs/2504.13748)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Change detection (CD) in remote sensing imagery plays a crucial role in various applications such as urban planning, damage assessment, and resource management. While deep learning approaches have significantly advanced CD performance, current methods suffer from poor domain adaptability, requiring extensive labeled data for retraining when applied to new scenarios. This limitation severely restricts their practical applications across different datasets. In this work, we propose DAM-Net: a Domain Adaptation Network with Micro-Labeled Fine-Tuning for CD. Our network introduces adversarial domain adaptation to CD for, utilizing a specially designed segmentation-discriminator and alternating training strategy to enable effective transfer between domains. Additionally, we propose a novel Micro-Labeled Fine-Tuning approach that strategically selects and labels a minimal amount of samples (less than 1%) to enhance domain adaptation. The network incorporates a Multi-Temporal Transformer for feature fusion and optimized backbone structure based on previous research. Experiments conducted on the LEVIR-CD and WHU-CD datasets demonstrate that DAM-Net significantly outperforms existing domain adaptation methods, achieving comparable performance to semi-supervised approaches that require 10% labeled data while using only 0.3% labeled samples. Our approach significantly advances cross-dataset CD applications and provides a new paradigm for efficient domain adaptation in remote sensing. The source code of DAM-Net will be made publicly available upon publication.</li>
</ul>

<h3>Title: Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Zhu Zhu, Shuo Jiang, Jingyuan Zheng, Yawen Li, Yifei Chen, Manli Zhao, Weizhong Gu, Feiwei Qin, Jinhu Wang, Gang Yu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13754">https://arxiv.org/abs/2504.13754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13754">https://arxiv.org/pdf/2504.13754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13754]] Towards Accurate and Interpretable Neuroblastoma Diagnosis via Contrastive Multi-scale Pathological Image Analysis(https://arxiv.org/abs/2504.13754)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Neuroblastoma, adrenal-derived, is among the most common pediatric solid malignancies, characterized by significant clinical heterogeneity. Timely and accurate pathological diagnosis from hematoxylin and eosin-stained whole slide images is critical for patient prognosis. However, current diagnostic practices primarily rely on subjective manual examination by pathologists, leading to inconsistent accuracy. Existing automated whole slide image classification methods encounter challenges such as poor interpretability, limited feature extraction capabilities, and high computational costs, restricting their practical clinical deployment. To overcome these limitations, we propose CMSwinKAN, a contrastive-learning-based multi-scale feature fusion model tailored for pathological image classification, which enhances the Swin Transformer architecture by integrating a Kernel Activation Network within its multilayer perceptron and classification head modules, significantly improving both interpretability and accuracy. By fusing multi-scale features and leveraging contrastive learning strategies, CMSwinKAN mimics clinicians' comprehensive approach, effectively capturing global and local tissue characteristics. Additionally, we introduce a heuristic soft voting mechanism guided by clinical insights to seamlessly bridge patch-level predictions to whole slide image-level classifications. We validate CMSwinKAN on the PpNTs dataset, which was collaboratively established with our partner hospital and the publicly accessible BreakHis dataset. Results demonstrate that CMSwinKAN performs better than existing state-of-the-art pathology-specific models pre-trained on large datasets. Our source code is available at this https URL.</li>
</ul>

<h3>Title: Scaling sparse feature circuit finding for in-context learning</h3>
<ul>
<li><strong>Authors: </strong>Dmitrii Kharlapenko, Stepan Shabalin, Fazl Barez, Arthur Conmy, Neel Nanda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13756">https://arxiv.org/abs/2504.13756</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13756">https://arxiv.org/pdf/2504.13756</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13756]] Scaling sparse feature circuit finding for in-context learning(https://arxiv.org/abs/2504.13756)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are a popular tool for interpreting large language model activations, but their utility in addressing open questions in interpretability remains unclear. In this work, we demonstrate their effectiveness by using SAEs to deepen our understanding of the mechanism behind in-context learning (ICL). We identify abstract SAE features that (i) encode the model's knowledge of which task to execute and (ii) whose latent vectors causally induce the task zero-shot. This aligns with prior work showing that ICL is mediated by task vectors. We further demonstrate that these task vectors are well approximated by a sparse sum of SAE latents, including these task-execution features. To explore the ICL mechanism, we adapt the sparse feature circuits methodology of Marks et al. (2024) to work for the much larger Gemma-1 2B model, with 30 times as many parameters, and to the more complex task of ICL. Through circuit finding, we discover task-detecting features with corresponding SAE latents that activate earlier in the prompt, that detect when tasks have been performed. They are causally linked with task-execution features through the attention and MLP sublayers.</li>
</ul>

<h3>Title: Fragile Watermarking for Image Certification Using Deep Steganographic Embedding</h3>
<ul>
<li><strong>Authors: </strong>Davide Ghiani, Jefferson David Rodriguez Chivata, Stefano Lilliu, Simone Maurizio La Cava, Marco Micheletto, Giulia Orr√π, Federico Lama, Gian Luca Marcialis</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13759">https://arxiv.org/abs/2504.13759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13759">https://arxiv.org/pdf/2504.13759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13759]] Fragile Watermarking for Image Certification Using Deep Steganographic Embedding(https://arxiv.org/abs/2504.13759)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, biometric, watermark</a></li>
<li><strong>Abstract: </strong>Modern identity verification systems increasingly rely on facial images embedded in biometric documents such as electronic passports. To ensure global interoperability and security, these images must comply with strict standards defined by the International Civil Aviation Organization (ICAO), which specify acquisition, quality, and format requirements. However, once issued, these images may undergo unintentional degradations (e.g., compression, resizing) or malicious manipulations (e.g., morphing) and deceive facial recognition systems. In this study, we explore fragile watermarking, based on deep steganographic embedding as a proactive mechanism to certify the authenticity of ICAO-compliant facial images. By embedding a hidden image within the official photo at the time of issuance, we establish an integrity marker that becomes sensitive to any post-issuance modification. We assess how a range of image manipulations affects the recovered hidden image and show that degradation artifacts can serve as robust forensic cues. Furthermore, we propose a classification framework that analyzes the revealed content to detect and categorize the type of manipulation applied. Our experiments demonstrate high detection accuracy, including cross-method scenarios with multiple deep steganography-based models. These findings support the viability of fragile watermarking via steganographic embedding as a valuable tool for biometric document integrity verification.</li>
</ul>

<h3>Title: Decoding Vision Transformers: the Diffusion Steering Lens</h3>
<ul>
<li><strong>Authors: </strong>Ryota Takatsuki, Sonia Joseph, Ippei Fujisawa, Ryota Kanai</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13763">https://arxiv.org/abs/2504.13763</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13763">https://arxiv.org/pdf/2504.13763</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13763]] Decoding Vision Transformers: the Diffusion Steering Lens(https://arxiv.org/abs/2504.13763)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Logit Lens is a widely adopted method for mechanistic interpretability of transformer-based language models, enabling the analysis of how internal representations evolve across layers by projecting them into the output vocabulary space. Although applying Logit Lens to Vision Transformers (ViTs) is technically straightforward, its direct use faces limitations in capturing the richness of visual representations. Building on the work of Toker et al. (2024)~\cite{Toker2024-ve}, who introduced Diffusion Lens to visualize intermediate representations in the text encoders of text-to-image diffusion models, we demonstrate that while Diffusion Lens can effectively visualize residual stream representations in image encoders, it fails to capture the direct contributions of individual submodules. To overcome this limitation, we propose \textbf{Diffusion Steering Lens} (DSL), a novel, training-free approach that steers submodule outputs and patches subsequent indirect contributions. We validate our method through interventional studies, showing that DSL provides an intuitive and reliable interpretation of the internal processing in ViTs.</li>
</ul>

<h3>Title: Access control for Data Spaces</h3>
<ul>
<li><strong>Authors: </strong>Nikos Fotiou, Vasilios A. Siris, George C. Polyzos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13767">https://arxiv.org/abs/2504.13767</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13767">https://arxiv.org/pdf/2504.13767</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13767]] Access control for Data Spaces(https://arxiv.org/abs/2504.13767)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Data spaces represent an emerging paradigm that facilitates secure and trusted data exchange through foundational elements of data interoperability, sovereignty, and trust. Within a data space, data items, potentially owned by different entities, can be interconnected. Concurrently, data consumers can execute advanced data lookup operations and subscribe to data-driven events. Achieving fine-grained access control without compromising functionality presents a significant challenge. In this paper, we design and implement an access control mechanism that ensures continuous evaluation of access control policies, is data semantics aware, and supports subscriptions to data events. We present a construction where access control policies are stored in a centralized location, which we extend to allow data owners to maintain their own Policy Administration Points. This extension builds upon W3C Verifiable Credentials.</li>
</ul>

<h3>Title: DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Tamim Al Mahmud, Najeeb Jebreel, Josep Domingo-Ferrer, David Sanchez</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13774">https://arxiv.org/abs/2504.13774</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13774">https://arxiv.org/pdf/2504.13774</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13774]] DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs(https://arxiv.org/abs/2504.13774)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have recently revolutionized language processing tasks but have also brought ethical and legal issues. LLMs have a tendency to memorize potentially private or copyrighted information present in the training data, which might then be delivered to end users at inference time. When this happens, a naive solution is to retrain the model from scratch after excluding the undesired data. Although this guarantees that the target data have been forgotten, it is also prohibitively expensive for LLMs. Approximate unlearning offers a more efficient alternative, as it consists of ex post modifications of the trained model itself to prevent undesirable results, but it lacks forgetting guarantees because it relies solely on empirical evidence. In this work, we present DP2Unlearning, a novel LLM unlearning framework that offers formal forgetting guarantees at a significantly lower cost than retraining from scratch on the data to be retained. DP2Unlearning involves training LLMs on textual data protected using {\epsilon}-differential privacy (DP), which later enables efficient unlearning with the guarantees against disclosure associated with the chosen {\epsilon}. Our experiments demonstrate that DP2Unlearning achieves similar model performance post-unlearning, compared to an LLM retraining from scratch on retained data -- the gold standard exact unlearning -- but at approximately half the unlearning cost. In addition, with a reasonable computational cost, it outperforms approximate unlearning methods at both preserving the utility of the model post-unlearning and effectively forgetting the targeted information.</li>
</ul>

<h3>Title: BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhengxian Wu, Juan Wen, Wanli Peng, Ziwei Zhang, Yinghan Zhou, Yiming Xue</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13775">https://arxiv.org/abs/2504.13775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13775">https://arxiv.org/pdf/2504.13775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13775]] BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models(https://arxiv.org/abs/2504.13775)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Previous insertion-based and paraphrase-based backdoors have achieved great success in attack efficacy, but they ignore the text quality and semantic consistency between poisoned and clean texts. Although recent studies introduce LLMs to generate poisoned texts and improve the stealthiness, semantic consistency, and text quality, their hand-crafted prompts rely on expert experiences, facing significant challenges in prompt adaptability and attack performance after defenses. In this paper, we propose a novel backdoor attack based on adaptive optimization mechanism of black-box large language models (BadApex), which leverages a black-box LLM to generate poisoned text through a refined prompt. Specifically, an Adaptive Optimization Mechanism is designed to refine an initial prompt iteratively using the generation and modification agents. The generation agent generates the poisoned text based on the initial prompt. Then the modification agent evaluates the quality of the poisoned text and refines a new prompt. After several iterations of the above process, the refined prompt is used to generate poisoned texts through LLMs. We conduct extensive experiments on three dataset with six backdoor attacks and two defenses. Extensive experimental results demonstrate that BadApex significantly outperforms state-of-the-art attacks. It improves prompt adaptability, semantic consistency, and text quality. Furthermore, when two defense methods are applied, the average attack success rate (ASR) still up to 96.75%.</li>
</ul>

<h3>Title: Fighting Fires from Space: Leveraging Vision Transformers for Enhanced Wildfire Detection and Characterization</h3>
<ul>
<li><strong>Authors: </strong>Aman Agarwal, James Gearon, Raksha Rank, Etienne Chenevert</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13776">https://arxiv.org/abs/2504.13776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13776">https://arxiv.org/pdf/2504.13776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13776]] Fighting Fires from Space: Leveraging Vision Transformers for Enhanced Wildfire Detection and Characterization(https://arxiv.org/abs/2504.13776)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Wildfires are increasing in intensity, frequency, and duration across large parts of the world as a result of anthropogenic climate change. Modern hazard detection and response systems that deal with wildfires are under-equipped for sustained wildfire seasons. Recent work has proved automated wildfire detection using Convolutional Neural Networks (CNNs) trained on satellite imagery are capable of high-accuracy results. However, CNNs are computationally expensive to train and only incorporate local image context. Recently, Vision Transformers (ViTs) have gained popularity for their efficient training and their ability to include both local and global contextual information. In this work, we show that ViT can outperform well-trained and specialized CNNs to detect wildfires on a previously published dataset of LandSat-8 imagery. One of our ViTs outperforms the baseline CNN comparison by 0.92%. However, we find our own implementation of CNN-based UNet to perform best in every category, showing their sustained utility in image tasks. Overall, ViTs are comparably capable in detecting wildfires as CNNs, though well-tuned CNNs are still the best technique for detecting wildfire with our UNet providing an IoU of 93.58%, better than the baseline UNet by some 4.58%.</li>
</ul>

<h3>Title: On the Relationship Between Robustness and Expressivity of Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Lorenz Kummer, Wilfried N. Gansterer, Nils M. Kriege</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13786">https://arxiv.org/abs/2504.13786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13786">https://arxiv.org/pdf/2504.13786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13786]] On the Relationship Between Robustness and Expressivity of Graph Neural Networks(https://arxiv.org/abs/2504.13786)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>We investigate the vulnerability of Graph Neural Networks (GNNs) to bit-flip attacks (BFAs) by introducing an analytical framework to study the influence of architectural features, graph properties, and their interaction. The expressivity of GNNs refers to their ability to distinguish non-isomorphic graphs and depends on the encoding of node neighborhoods. We examine the vulnerability of neural multiset functions commonly used for this purpose and establish formal criteria to characterize a GNN's susceptibility to losing expressivity due to BFAs. This enables an analysis of the impact of homophily, graph structural variety, feature encoding, and activation functions on GNN robustness. We derive theoretical bounds for the number of bit flips required to degrade GNN expressivity on a dataset, identifying ReLU-activated GNNs operating on highly homophilous graphs with low-dimensional or one-hot encoded features as particularly susceptible. Empirical results using ten real-world datasets confirm the statistical significance of our key theoretical insights and offer actionable results to mitigate BFA risks in expressivity-critical applications.</li>
</ul>

<h3>Title: Probabilistic Stability Guarantees for Feature Attributions</h3>
<ul>
<li><strong>Authors: </strong>Helen Jin, Anton Xue, Weiqiu You, Surbhi Goel, Eric Wong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13787">https://arxiv.org/abs/2504.13787</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13787">https://arxiv.org/pdf/2504.13787</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13787]] Probabilistic Stability Guarantees for Feature Attributions(https://arxiv.org/abs/2504.13787)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Stability guarantees are an emerging tool for evaluating feature attributions, but existing certification methods rely on smoothed classifiers and often yield conservative guarantees. To address these limitations, we introduce soft stability and propose a simple, model-agnostic, and sample-efficient stability certification algorithm (SCA) that provides non-trivial and interpretable guarantees for any attribution. Moreover, we show that mild smoothing enables a graceful tradeoff between accuracy and stability, in contrast to prior certification methods that require a more aggressive compromise. Using Boolean function analysis, we give a novel characterization of stability under smoothing. We evaluate SCA on vision and language tasks, and demonstrate the effectiveness of soft stability in measuring the robustness of explanation methods.</li>
</ul>

<h3>Title: Transformer Encoder and Multi-features Time2Vec for Financial Prediction</h3>
<ul>
<li><strong>Authors: </strong>Nguyen Kim Hai Bui, Nguyen Duy Chien, P√©ter Kov√°cs, Gerg≈ë Bogn√°r</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13801">https://arxiv.org/abs/2504.13801</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13801">https://arxiv.org/pdf/2504.13801</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13801]] Transformer Encoder and Multi-features Time2Vec for Financial Prediction(https://arxiv.org/abs/2504.13801)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Financial prediction is a complex and challenging task of time series analysis and signal processing, expected to model both short-term fluctuations and long-term temporal dependencies. Transformers have remarkable success mostly in natural language processing using attention mechanism, which also influenced the time series community. The ability to capture both short and long-range dependencies helps to understand the financial market and to recognize price patterns, leading to successful applications of Transformers in stock prediction. Although, the previous research predominantly focuses on individual features and singular predictions, that limits the model's ability to understand broader market trends. In reality, within sectors such as finance and technology, companies belonging to the same industry often exhibit correlated stock price movements. In this paper, we develop a novel neural network architecture by integrating Time2Vec with the Encoder of the Transformer model. Based on the study of different markets, we propose a novel correlation feature selection method. Through a comprehensive fine-tuning of multiple hyperparameters, we conduct a comparative analysis of our results against benchmark models. We conclude that our method outperforms other state-of-the-art encoding methods such as positional encoding, and we also conclude that selecting correlation features enhance the accuracy of predicting multiple stock prices.</li>
</ul>

<h3>Title: Can LLMs handle WebShell detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework</h3>
<ul>
<li><strong>Authors: </strong>Feijiang Han, Jiaming Zhang, Chuyi Deng, Jianheng Tang, Yunhuai Liu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13811">https://arxiv.org/abs/2504.13811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13811">https://arxiv.org/pdf/2504.13811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13811]] Can LLMs handle WebShell detection? Overcoming Detection Challenges with Behavioral Function-Aware Framework(https://arxiv.org/abs/2504.13811)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, extraction, large language model</a></li>
<li><strong>Abstract: </strong>WebShell attacks, in which malicious scripts are injected into web servers, are a major cybersecurity threat. Traditional machine learning and deep learning methods are hampered by issues such as the need for extensive training data, catastrophic forgetting, and poor generalization. Recently, Large Language Models (LLMs) have gained attention for code-related tasks, but their potential in WebShell detection remains underexplored. In this paper, we make two major contributions: (1) a comprehensive evaluation of seven LLMs, including GPT-4, LLaMA 3.1 70B, and Qwen 2.5 variants, benchmarked against traditional sequence- and graph-based methods using a dataset of 26.59K PHP scripts, and (2) the Behavioral Function-Aware Detection (BFAD) framework, designed to address the specific challenges of applying LLMs to this domain. Our framework integrates three components: a Critical Function Filter that isolates malicious PHP function calls, a Context-Aware Code Extraction strategy that captures the most behaviorally indicative code segments, and Weighted Behavioral Function Profiling (WBFP) that enhances in-context learning by prioritizing the most relevant demonstrations based on discriminative function-level profiles. Our results show that larger LLMs achieve near-perfect precision but lower recall, while smaller models exhibit the opposite trade-off. However, all models lag behind previous State-Of-The-Art (SOTA) methods. With BFAD, the performance of all LLMs improved, with an average F1 score increase of 13.82%. Larger models such as GPT-4, LLaMA 3.1 70B, and Qwen 2.5 14B outperform SOTA methods, while smaller models such as Qwen 2.5 3B achieve performance competitive with traditional methods. This work is the first to explore the feasibility and limitations of LLMs for WebShell detection, and provides solutions to address the challenges in this task.</li>
</ul>

<h3>Title: Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Yixuan Even Xu, Yash Savani, Fei Fang, Zico Kolter</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13818">https://arxiv.org/abs/2504.13818</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13818">https://arxiv.org/pdf/2504.13818</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13818]] Not All Rollouts are Useful: Down-Sampling Rollouts in LLM Reinforcement Learning(https://arxiv.org/abs/2504.13818)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has emerged as a powerful paradigm for enhancing reasoning capabilities in large language models, but faces a fundamental asymmetry in computation and memory requirements: inference is embarrassingly parallel with a minimal memory footprint, while policy updates require extensive synchronization and are memory-intensive. To address this asymmetry, we introduce PODS (Policy Optimization with Down-Sampling), a framework that strategically decouples these phases by generating numerous rollouts in parallel but updating only on an informative subset. Within this framework, we develop max-variance down-sampling, a theoretically motivated method that selects rollouts with maximally diverse reward signals. We prove that this approach has an efficient algorithmic solution, and empirically demonstrate that GRPO with PODS using max-variance down-sampling achieves superior performance over standard GRPO on the GSM8K benchmark.</li>
</ul>

<h3>Title: CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Yang Yue, Yulin Wang, Chenxin Tao, Pan Liu, Shiji Song, Gao Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13820">https://arxiv.org/abs/2504.13820</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13820">https://arxiv.org/pdf/2504.13820</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13820]] CheXWorld: Exploring Image World Modeling for Radiograph Representation Learning(https://arxiv.org/abs/2504.13820)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Humans can develop internal world models that encode common sense knowledge, telling them how the world works and predicting the consequences of their actions. This concept has emerged as a promising direction for establishing general-purpose machine-learning models in recent preliminary works, e.g., for visual representation learning. In this paper, we present CheXWorld, the first effort towards a self-supervised world model for radiographic images. Specifically, our work develops a unified framework that simultaneously models three aspects of medical knowledge essential for qualified radiologists, including 1) local anatomical structures describing the fine-grained characteristics of local tissues (e.g., architectures, shapes, and textures); 2) global anatomical layouts describing the global organization of the human body (e.g., layouts of organs and skeletons); and 3) domain variations that encourage CheXWorld to model the transitions across different appearance domains of radiographs (e.g., varying clarity, contrast, and exposure caused by collecting radiographs from different hospitals, devices, or patients). Empirically, we design tailored qualitative and quantitative analyses, revealing that CheXWorld successfully captures these three dimensions of medical knowledge. Furthermore, transfer learning experiments across eight medical image classification and segmentation benchmarks showcase that CheXWorld significantly outperforms existing SSL methods and large-scale medical foundation models. Code & pre-trained models are available at this https URL.</li>
</ul>

<h3>Title: Feature Alignment and Representation Transfer in Knowledge Distillation for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junjie Yang, Junhao Song, Xudong Han, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Xinyuan Song, Yichao Zhang, Qian Niu, Benji Peng, Keyu Chen, Ming Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13825">https://arxiv.org/abs/2504.13825</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13825">https://arxiv.org/pdf/2504.13825</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13825]] Feature Alignment and Representation Transfer in Knowledge Distillation for Large Language Models(https://arxiv.org/abs/2504.13825)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Knowledge distillation (KD) is a technique for transferring knowledge from complex teacher models to simpler student models, significantly enhancing model efficiency and accuracy. It has demonstrated substantial advancements in various applications including image classification, object detection, language modeling, text classification, and sentiment analysis. Recent innovations in KD methods, such as attention-based approaches, block-wise logit distillation, and decoupling distillation, have notably improved student model performance. These techniques focus on stimulus complexity, attention mechanisms, and global information capture to optimize knowledge transfer. In addition, KD has proven effective in compressing large language models while preserving accuracy, reducing computational overhead, and improving inference speed. This survey synthesizes the latest literature, highlighting key findings, contributions, and future directions in knowledge distillation to provide insights for researchers and practitioners on its evolving role in artificial intelligence and machine learning.</li>
</ul>

<h3>Title: Generative AI Act II: Test Time Scaling Drives Cognition Engineering</h3>
<ul>
<li><strong>Authors: </strong>Shijie Xia, Yiwei Qin, Xuefeng Li, Yan Ma, Run-Ze Fan, Steffi Chern, Haoyang Zou, Fan Zhou, Xiangkun Hu, Jiahe Jin, Yanheng He, Yixin Ye, Yixiu Liu, Pengfei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13828">https://arxiv.org/abs/2504.13828</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13828">https://arxiv.org/pdf/2504.13828</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13828]] Generative AI Act II: Test Time Scaling Drives Cognition Engineering(https://arxiv.org/abs/2504.13828)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The first generation of Large Language Models - what might be called "Act I" of generative AI (2020-2023) - achieved remarkable success through massive parameter and data scaling, yet exhibited fundamental limitations in knowledge latency, shallow reasoning, and constrained cognitive processes. During this era, prompt engineering emerged as our primary interface with AI, enabling dialogue-level communication through natural language. We now witness the emergence of "Act II" (2024-present), where models are transitioning from knowledge-retrieval systems (in latent space) to thought-construction engines through test-time scaling techniques. This new paradigm establishes a mind-level connection with AI through language-based thoughts. In this paper, we clarify the conceptual foundations of cognition engineering and explain why this moment is critical for its development. We systematically break down these advanced approaches through comprehensive tutorials and optimized implementations, democratizing access to cognition engineering and enabling every practitioner to participate in AI's second act. We provide a regularly updated collection of papers on test-time scaling in the GitHub Repository: this https URL</li>
</ul>

<h3>Title: Science Hierarchography: Hierarchical Organization of Science Literature</h3>
<ul>
<li><strong>Authors: </strong>Muhan Gao, Jash Shah, Weiqi Wang, Daniel Khashabi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13834">https://arxiv.org/abs/2504.13834</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13834">https://arxiv.org/pdf/2504.13834</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13834]] Science Hierarchography: Hierarchical Organization of Science Literature(https://arxiv.org/abs/2504.13834)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Scientific knowledge is growing rapidly, making it challenging to track progress and high-level conceptual links across broad disciplines. While existing tools like citation networks and search engines make it easy to access a few related papers, they fundamentally lack the flexible abstraction needed to represent the density of activity in various scientific subfields. We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific literature into a high-quality hierarchical structure that allows for the categorization of scientific work across varying levels of abstraction, from very broad fields to very specific studies. Such a representation can provide insights into which fields are well-explored and which are under-explored. To achieve the goals of SCIENCE HIERARCHOGRAPHY, we develop a range of algorithms. Our primary approach combines fast embedding-based clustering with LLM-based prompting to balance the computational efficiency of embedding methods with the semantic precision offered by LLM prompting. We demonstrate that this approach offers the best trade-off between quality and speed compared to methods that heavily rely on LLM prompting, such as iterative tree construction with LLMs. To better reflect the interdisciplinary and multifaceted nature of research papers, our hierarchy captures multiple dimensions of categorization beyond simple topic labels. We evaluate the utility of our framework by assessing how effectively an LLM-based agent can locate target papers using the hierarchy. Results show that this structured approach enhances interpretability, supports trend discovery, and offers an alternative pathway for exploring scientific literature beyond traditional search methods. Code, data and demo: $\href{this https URL}{this https URL}$</li>
</ul>

<h3>Title: Outlier-Robust Multi-Model Fitting on Quantum Annealers</h3>
<ul>
<li><strong>Authors: </strong>Saurabh Pandey, Luca Magri, Federica Arrigoni, Vladislav Golyanik</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2504.13836">https://arxiv.org/abs/2504.13836</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2504.13836">https://arxiv.org/pdf/2504.13836</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2504.13836]] Outlier-Robust Multi-Model Fitting on Quantum Annealers(https://arxiv.org/abs/2504.13836)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multi-model fitting (MMF) presents a significant challenge in Computer Vision, particularly due to its combinatorial nature. While recent advancements in quantum computing offer promise for addressing NP-hard problems, existing quantum-based approaches for model fitting are either limited to a single model or consider multi-model scenarios within outlier-free datasets. This paper introduces a novel approach, the robust quantum multi-model fitting (R-QuMF) algorithm, designed to handle outliers effectively. Our method leverages the intrinsic capabilities of quantum hardware to tackle combinatorial challenges inherent in MMF tasks, and it does not require prior knowledge of the exact number of models, thereby enhancing its practical applicability. By formulating the problem as a maximum set coverage task for adiabatic quantum computers (AQC), R-QuMF outperforms existing quantum techniques, demonstrating superior performance across various synthetic and real-world 3D datasets. Our findings underscore the potential of quantum computing in addressing the complexities of MMF, especially in real-world scenarios with noisy and outlier-prone data.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
