<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h2>security</h2>
<h3>Title: Injective Rank Metric Trapdoor Functions with Homogeneous Errors. (arXiv:2310.08962v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08962">http://arxiv.org/abs/2310.08962</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08962]] Injective Rank Metric Trapdoor Functions with Homogeneous Errors(http://arxiv.org/abs/2310.08962)</code></li>
<li>Summary: <p>In rank-metric cryptography, a vector from a finite dimensional linear space
over a finite field is viewed as the linear space spanned by its entries. The
rank decoding problem which is the analogue of the problem of decoding a random
linear code consists in recovering a basis of a random noise vector that was
used to perturb a set of random linear equations sharing a secret solution.
Assuming the intractability of this problem, we introduce a new construction of
injective one-way trapdoor functions. Our solution departs from the frequent
way of building public key primitives from error-correcting codes where, to
establish the security, ad hoc assumptions about a hidden structure are made.
Our method produces a hard-to-distinguish linear code together with low weight
vectors which constitute the secret that helps recover the inputs.The key idea
is to focus on trapdoor functions that take sufficiently enough input vectors
sharing the same support. Applying then the error correcting algorithm designed
for Low Rank Parity Check (LRPC) codes, we obtain an inverting algorithm that
recovers the inputs with overwhelming probability.
</p></li>
</ul>

<h3>Title: Tikuna: An Ethereum Blockchain Network Security Monitoring System. (arXiv:2310.09193v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09193">http://arxiv.org/abs/2310.09193</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09193]] Tikuna: An Ethereum Blockchain Network Security Monitoring System(http://arxiv.org/abs/2310.09193)</code></li>
<li>Summary: <p>Blockchain security is becoming increasingly relevant in today's cyberspace
as it extends its influence in many industries. This paper focuses on
protecting the lowest level layer in the blockchain, particularly the P2P
network that allows the nodes to communicate and share information. The P2P
network layer may be vulnerable to several families of attacks, such as
Distributed Denial of Service (DDoS), eclipse attacks, or Sybil attacks. This
layer is prone to threats inherited from traditional P2P networks, and it must
be analyzed and understood by collecting data and extracting insights from the
network behavior to reduce those risks. We introduce Tikuna, an open-source
tool for monitoring and detecting potential attacks on the Ethereum blockchain
P2P network, at an early stage. Tikuna employs an unsupervised Long Short-Term
Memory (LSTM) method based on Recurrent Neural Network (RNN) to detect attacks
and alert users. Empirical results indicate that the proposed approach
significantly improves detection performance, with the ability to detect and
classify attacks, including eclipse attacks, Covert Flash attacks, and others
that target the Ethereum blockchain P2P network layer, with high accuracy. Our
research findings demonstrate that Tikuna is a valuable security tool for
assisting operators to efficiently monitor and safeguard the status of Ethereum
validators and the wider P2P network
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: SIDE: Self-supervised Intermediate Domain Exploration for Source-free Domain Adaptation. (arXiv:2310.08928v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08928">http://arxiv.org/abs/2310.08928</a></li>
<li>Code URL: https://github.com/se111/side</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08928]] SIDE: Self-supervised Intermediate Domain Exploration for Source-free Domain Adaptation(http://arxiv.org/abs/2310.08928)</code></li>
<li>Summary: <p>Domain adaptation aims to alleviate the domain shift when transferring the
knowledge learned from the source domain to the target domain. Due to privacy
issues, source-free domain adaptation (SFDA), where source data is unavailable
during adaptation, has recently become very demanding yet challenging. Existing
SFDA methods focus on either self-supervised learning of target samples or
reconstruction of virtual source data. The former overlooks the transferable
knowledge in the source model, whilst the latter introduces even more
uncertainty. To address the above issues, this paper proposes self-supervised
intermediate domain exploration (SIDE) that effectively bridges the domain gap
with an intermediate domain, where samples are cyclically filtered out in a
self-supervised fashion. First, we propose cycle intermediate domain filtering
(CIDF) to cyclically select intermediate samples with similar distributions
over source and target domains. Second, with the aid of those intermediate
samples, an inter-domain gap transition (IDGT) module is developed to mitigate
possible distribution mismatches between the source and target data. Finally,
we introduce cross-view consistency learning (CVCL) to maintain the intrinsic
class discriminability whilst adapting the model to the target domain.
Extensive experiments on three popular benchmarks, i.e. Office-31, Office-Home
and VisDA-C, show that our proposed SIDE achieves competitive performance
against state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Privacy-Preserving Encrypted Low-Dose CT Denoising. (arXiv:2310.09101v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09101">http://arxiv.org/abs/2310.09101</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09101]] Privacy-Preserving Encrypted Low-Dose CT Denoising(http://arxiv.org/abs/2310.09101)</code></li>
<li>Summary: <p>Deep learning (DL) has made significant advancements in tomographic imaging,
particularly in low-dose computed tomography (LDCT) denoising. A recent trend
involves servers training powerful models with large amounts of self-collected
private data and providing application programming interfaces (APIs) for users,
such as Chat-GPT. To avoid model leakage, users are required to upload their
data to the server model, but this way raises public concerns about the
potential risk of privacy disclosure, especially for medical data. Hence, to
alleviate related concerns, in this paper, we propose to directly denoise LDCT
in the encrypted domain to achieve privacy-preserving cloud services without
exposing private data to the server. To this end, we employ homomorphic
encryption to encrypt private LDCT data, which is then transferred to the
server model trained with plaintext LDCT for further denoising. However, since
traditional operations, such as convolution and linear transformation, in DL
methods cannot be directly used in the encrypted domain, we transform the
fundamental mathematic operations in the plaintext domain into the operations
in the encrypted domain. In addition, we present two interactive frameworks for
linear and nonlinear models in this paper, both of which can achieve lossless
operating. In this way, the proposed methods can achieve two merits, the data
privacy is well protected and the server model is free from the risk of model
leakage. Moreover, we provide theoretical proof to validate the lossless
property of our framework. Finally, experiments were conducted to demonstrate
that the transferred contents are well protected and cannot be reconstructed.
The code will be released once the paper is accepted.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Fed-Safe: Securing Federated Learning in Healthcare Against Adversarial Attacks. (arXiv:2310.08681v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08681">http://arxiv.org/abs/2310.08681</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08681]] Fed-Safe: Securing Federated Learning in Healthcare Against Adversarial Attacks(http://arxiv.org/abs/2310.08681)</code></li>
<li>Summary: <p>This paper explores the security aspects of federated learning applications
in medical image analysis. Current robustness-oriented methods like adversarial
training, secure aggregation, and homomorphic encryption often risk privacy
compromises. The central aim is to defend the network against potential privacy
breaches while maintaining model robustness against adversarial manipulations.
We show that incorporating distributed noise, grounded in the privacy
guarantees in federated settings, enables the development of a adversarially
robust model that also meets federated privacy standards. We conducted
comprehensive evaluations across diverse attack scenarios, parameters, and use
cases in cancer imaging, concentrating on pathology, meningioma, and glioma.
The results reveal that the incorporation of distributed noise allows for the
attainment of security levels comparable to those of conventional adversarial
training while requiring fewer retraining samples to establish a robust model.
</p></li>
</ul>

<h3>Title: User Inference Attacks on Large Language Models. (arXiv:2310.09266v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09266">http://arxiv.org/abs/2310.09266</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09266]] User Inference Attacks on Large Language Models(http://arxiv.org/abs/2310.09266)</code></li>
<li>Summary: <p>Fine-tuning is a common and effective method for tailoring large language
models (LLMs) to specialized tasks and applications. In this paper, we study
the privacy implications of fine-tuning LLMs on user data. To this end, we
define a realistic threat model, called user inference, wherein an attacker
infers whether or not a user's data was used for fine-tuning. We implement
attacks for this threat model that require only a small set of samples from a
user (possibly different from the samples used for training) and black-box
access to the fine-tuned LLM. We find that LLMs are susceptible to user
inference attacks across a variety of fine-tuning datasets, at times with near
perfect attack success rates. Further, we investigate which properties make
users vulnerable to user inference, finding that outlier users (i.e. those with
data distributions sufficiently different from other users) and users who
contribute large quantities of data are most susceptible to attack. Finally, we
explore several heuristics for mitigating privacy attacks. We find that
interventions in the training algorithm, such as batch or per-example gradient
clipping and early stopping fail to prevent user inference. However, limiting
the number of fine-tuning samples from a single user can reduce attack
effectiveness, albeit at the cost of reducing the total amount of fine-tuning
data.
</p></li>
</ul>

<h3>Title: Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks on DFL. (arXiv:2310.08739v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08739">http://arxiv.org/abs/2310.08739</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08739]] Voyager: MTD-Based Aggregation Protocol for Mitigating Poisoning Attacks on DFL(http://arxiv.org/abs/2310.08739)</code></li>
<li>Summary: <p>The growing concern over malicious attacks targeting the robustness of both
centralized and decentralized federated learning (FL) necessitates novel
defensive strategies. In contrast to the centralized approach, decentralized FL
(DFL) has the advantage of utilizing network topology and local dataset,
enabling the exploration of moving target defense (MTD) based approaches. This
work presents a theoretical analysis of the influence of network topology on
the rubostness of DFL models. Drawing inspiration from these findings, a
three-stage MTD-based aggregation protocol, called as Voyager, is proposed to
improve the resilience of DFL against poisoning attacks through the
manipulation of network topology connectivity. Voyager has three main
components: an anomaly detector, a network topology explorer, and a connection
deployer. When an abnormal model is detected in the network, the topology
explorer responds strategically by forming connections with more trustworthy
participants to secure the model. Experimental evaluations show that Voyager
effectively mitigates various poisoning attacks without imposing significant
resource and computational burdens on participants. These findings highlight
the proposed reactive MTD as a potent defense mechanism in the context of DFL.
</p></li>
</ul>

<h3>Title: Attacks Meet Interpretability (AmI) Evaluation and Findings. (arXiv:2310.08808v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08808">http://arxiv.org/abs/2310.08808</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08808]] Attacks Meet Interpretability (AmI) Evaluation and Findings(http://arxiv.org/abs/2310.08808)</code></li>
<li>Summary: <p>To investigate the effectiveness of the model explanation in detecting
adversarial examples, we reproduce the results of two papers, Attacks Meet
Interpretability: Attribute-steered Detection of Adversarial Samples and Is AmI
(Attacks Meet Interpretability) Robust to Adversarial Examples. And then
conduct experiments and case studies to identify the limitations of both works.
We find that Attacks Meet Interpretability(AmI) is highly dependent on the
selection of hyperparameters. Therefore, with a different hyperparameter
choice, AmI is still able to detect Nicholas Carlini's attack. Finally, we
propose recommendations for future work on the evaluation of defense techniques
such as AmI.
</p></li>
</ul>

<h3>Title: Electrical Grid Anomaly Detection via Tensor Decomposition. (arXiv:2310.08650v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08650">http://arxiv.org/abs/2310.08650</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08650]] Electrical Grid Anomaly Detection via Tensor Decomposition(http://arxiv.org/abs/2310.08650)</code></li>
<li>Summary: <p>Supervisory Control and Data Acquisition (SCADA) systems often serve as the
nervous system for substations within power grids. These systems facilitate
real-time monitoring, data acquisition, control of equipment, and ensure smooth
and efficient operation of the substation and its connected devices. Previous
work has shown that dimensionality reduction-based approaches, such as
Principal Component Analysis (PCA), can be used for accurate identification of
anomalies in SCADA systems. While not specifically applied to SCADA,
non-negative matrix factorization (NMF) has shown strong results at detecting
anomalies in wireless sensor networks. These unsupervised approaches model the
normal or expected behavior and detect the unseen types of attacks or anomalies
by identifying the events that deviate from the expected behavior. These
approaches; however, do not model the complex and multi-dimensional
interactions that are naturally present in SCADA systems. Differently,
non-negative tensor decomposition is a powerful unsupervised machine learning
(ML) method that can model the complex and multi-faceted activity details of
SCADA events. In this work, we novelly apply the tensor decomposition method
Canonical Polyadic Alternating Poisson Regression (CP-APR) with a probabilistic
framework, which has previously shown state-of-the-art anomaly detection
results on cyber network data, to identify anomalies in SCADA systems. We
showcase that the use of statistical behavior analysis of SCADA communication
with tensor decomposition improves the specificity and accuracy of identifying
anomalies in electrical grid systems. In our experiments, we model real-world
SCADA system data collected from the electrical grid operated by Los Alamos
National Laboratory (LANL) which provides transmission and distribution service
through a partnership with Los Alamos County, and detect synthetically
generated anomalies.
</p></li>
</ul>

<h3>Title: When Machine Learning Models Leak: An Exploration of Synthetic Training Data. (arXiv:2310.08775v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08775">http://arxiv.org/abs/2310.08775</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08775]] When Machine Learning Models Leak: An Exploration of Synthetic Training Data(http://arxiv.org/abs/2310.08775)</code></li>
<li>Summary: <p>We investigate an attack on a machine learning model that predicts whether a
person or household will relocate in the next two years, i.e., a
propensity-to-move classifier. The attack assumes that the attacker can query
the model to obtain predictions and that the marginal distribution of the data
on which the model was trained is publicly available. The attack also assumes
that the attacker has obtained the values of non-sensitive attributes for a
certain number of target individuals. The objective of the attack is to infer
the values of sensitive attributes for these target individuals. We explore how
replacing the original data with synthetic data when training the model impacts
how successfully the attacker can infer sensitive attributes.\footnote{Original
paper published at PSD 2022. The paper was subsequently updated.}
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Defect Analysis of 3D Printed Cylinder Object Using Transfer Learning Approaches. (arXiv:2310.08645v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08645">http://arxiv.org/abs/2310.08645</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08645]] Defect Analysis of 3D Printed Cylinder Object Using Transfer Learning Approaches(http://arxiv.org/abs/2310.08645)</code></li>
<li>Summary: <p>Additive manufacturing (AM) is gaining attention across various industries
like healthcare, aerospace, and automotive. However, identifying defects early
in the AM process can reduce production costs and improve productivity - a key
challenge. This study explored the effectiveness of machine learning (ML)
approaches, specifically transfer learning (TL) models, for defect detection in
3D-printed cylinders. Images of cylinders were analyzed using models including
VGG16, VGG19, ResNet50, ResNet101, InceptionResNetV2, and MobileNetV2.
Performance was compared across two datasets using accuracy, precision, recall,
and F1-score metrics. In the first study, VGG16, InceptionResNetV2, and
MobileNetV2 achieved perfect scores. In contrast, ResNet50 had the lowest
performance, with an average F1-score of 0.32. Similarly, in the second study,
MobileNetV2 correctly classified all instances, while ResNet50 struggled with
more false positives and fewer true positives, resulting in an F1-score of
0.75. Overall, the findings suggest certain TL models like MobileNetV2 can
deliver high accuracy for AM defect classification, although performance varies
across algorithms. The results provide insights into model optimization and
integration needs for reliable automated defect analysis during 3D printing. By
identifying the top-performing TL techniques, this study aims to enhance AM
product quality through robust image-based monitoring and inspection.
</p></li>
</ul>

<h3>Title: Investigating the Robustness and Properties of Detection Transformers (DETR) Toward Difficult Images. (arXiv:2310.08772v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08772">http://arxiv.org/abs/2310.08772</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08772]] Investigating the Robustness and Properties of Detection Transformers (DETR) Toward Difficult Images(http://arxiv.org/abs/2310.08772)</code></li>
<li>Summary: <p>Transformer-based object detectors (DETR) have shown significant performance
across machine vision tasks, ultimately in object detection. This detector is
based on a self-attention mechanism along with the transformer encoder-decoder
architecture to capture the global context in the image. The critical issue to
be addressed is how this model architecture can handle different image
nuisances, such as occlusion and adversarial perturbations. We studied this
issue by measuring the performance of DETR with different experiments and
benchmarking the network with convolutional neural network (CNN) based
detectors like YOLO and Faster-RCNN. We found that DETR performs well when it
comes to resistance to interference from information loss in occlusion images.
Despite that, we found that the adversarial stickers put on the image require
the network to produce a new unnecessary set of keys, queries, and values,
which in most cases, results in a misdirection of the network. DETR also
performed poorer than YOLOv5 in the image corruption benchmark. Furthermore, we
found that DETR depends heavily on the main query when making a prediction,
which leads to imbalanced contributions between queries since the main query
receives most of the gradient flow.
</p></li>
</ul>

<h3>Title: pose-format: Library for Viewing, Augmenting, and Handling .pose Files. (arXiv:2310.09066v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09066">http://arxiv.org/abs/2310.09066</a></li>
<li>Code URL: https://github.com/sign-language-processing/pose</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09066]] pose-format: Library for Viewing, Augmenting, and Handling (http://arxiv.org/abs/2310.09066)</code></li>
<li>Summary: <p>Managing and analyzing pose data is a complex task, with challenges ranging
from handling diverse file structures and data types to facilitating effective
data manipulations such as normalization and augmentation. This paper presents
\texttt{pose-format}, a comprehensive toolkit designed to address these
challenges by providing a unified, flexible, and easy-to-use interface. The
library includes a specialized file format that encapsulates various types of
pose data, accommodating multiple individuals and an indefinite number of time
frames, thus proving its utility for both image and video data. Furthermore, it
offers seamless integration with popular numerical libraries such as NumPy,
PyTorch, and TensorFlow, thereby enabling robust machine-learning applications.
Through benchmarking, we demonstrate that our \texttt{.pose} file format offers
vastly superior performance against prevalent formats like OpenPose, with added
advantages like self-contained pose specification. Additionally, the library
includes features for data normalization, augmentation, and easy-to-use
visualization capabilities, both in Python and Browser environments.
\texttt{pose-format} emerges as a one-stop solution, streamlining the
complexities of pose data management and analysis.
</p></li>
</ul>

<h3>Title: iPUNet:Iterative Cross Field Guided Point Cloud Upsampling. (arXiv:2310.09092v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09092">http://arxiv.org/abs/2310.09092</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09092]] iPUNet:Iterative Cross Field Guided Point Cloud Upsampling(http://arxiv.org/abs/2310.09092)</code></li>
<li>Summary: <p>Point clouds acquired by 3D scanning devices are often sparse, noisy, and
non-uniform, causing a loss of geometric features. To facilitate the usability
of point clouds in downstream applications, given such input, we present a
learning-based point upsampling method, i.e., iPUNet, which generates dense and
uniform points at arbitrary ratios and better captures sharp features. To
generate feature-aware points, we introduce cross fields that are aligned to
sharp geometric features by self-supervision to guide point generation. Given
cross field defined frames, we enable arbitrary ratio upsampling by learning at
each input point a local parameterized surface. The learned surface consumes
the neighboring points and 2D tangent plane coordinates as input, and maps onto
a continuous surface in 3D where arbitrary ratios of output points can be
sampled. To solve the non-uniformity of input points, on top of the cross field
guided upsampling, we further introduce an iterative strategy that refines the
point distribution by moving sparse points onto the desired continuous 3D
surface in each iteration. Within only a few iterations, the sparse points are
evenly distributed and their corresponding dense samples are more uniform and
better capture geometric features. Through extensive evaluations on diverse
scans of objects and scenes, we demonstrate that iPUNet is robust to handle
noisy and non-uniformly distributed inputs, and outperforms state-of-the-art
point cloud upsampling methods.
</p></li>
</ul>

<h3>Title: PerturbScore: Connecting Discrete and Continuous Perturbations in NLP. (arXiv:2310.08889v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08889">http://arxiv.org/abs/2310.08889</a></li>
<li>Code URL: https://github.com/renke999/perturbscore</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08889]] PerturbScore: Connecting Discrete and Continuous Perturbations in NLP(http://arxiv.org/abs/2310.08889)</code></li>
<li>Summary: <p>With the rapid development of neural network applications in NLP, model
robustness problem is gaining more attention. Different from computer vision,
the discrete nature of texts makes it more challenging to explore robustness in
NLP. Therefore, in this paper, we aim to connect discrete perturbations with
continuous perturbations, therefore we can use such connections as a bridge to
help understand discrete perturbations in NLP models. Specifically, we first
explore how to connect and measure the correlation between discrete
perturbations and continuous perturbations. Then we design a regression task as
a PerturbScore to learn the correlation automatically. Through experimental
results, we find that we can build a connection between discrete and continuous
perturbations and use the proposed PerturbScore to learn such correlation,
surpassing previous methods used in discrete perturbation measuring. Further,
the proposed PerturbScore can be well generalized to different datasets,
perturbation methods, indicating that we can use it as a powerful tool to study
model robustness in NLP.
</p></li>
</ul>

<h3>Title: Provably Robust Cost-Sensitive Learning via Randomized Smoothing. (arXiv:2310.08732v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08732">http://arxiv.org/abs/2310.08732</a></li>
<li>Code URL: https://github.com/trustmlrg/cs-rs</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08732]] Provably Robust Cost-Sensitive Learning via Randomized Smoothing(http://arxiv.org/abs/2310.08732)</code></li>
<li>Summary: <p>We focus on learning adversarially robust classifiers under a cost-sensitive
scenario, where the potential harm of different classwise adversarial
transformations is encoded in a binary cost matrix. Existing methods are either
empirical that cannot certify robustness or suffer from inherent scalability
issues. In this work, we study whether randomized smoothing, a more scalable
robustness certification framework, can be leveraged to certify cost-sensitive
robustness. Built upon a notion of cost-sensitive certified radius, we show how
to adapt the standard randomized smoothing certification pipeline to produce
tight robustness guarantees for any cost matrix. In addition, with fine-grained
certified radius optimization schemes specifically designed for different data
subgroups, we propose an algorithm to train smoothed classifiers that are
optimized for cost-sensitive robustness. Extensive experiments on image
benchmarks and a real-world medical dataset demonstrate the superiority of our
method in achieving significantly improved performance of certified
cost-sensitive robustness while having a negligible impact on overall accuracy.
</p></li>
</ul>

<h3>Title: Analyzing Textual Data for Fatality Classification in Afghanistan's Armed Conflicts: A BERT Approach. (arXiv:2310.08653v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08653">http://arxiv.org/abs/2310.08653</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08653]] Analyzing Textual Data for Fatality Classification in Afghanistan's Armed Conflicts: A BERT Approach(http://arxiv.org/abs/2310.08653)</code></li>
<li>Summary: <p>Afghanistan has witnessed many armed conflicts throughout history, especially
in the past 20 years; these events have had a significant impact on human
lives, including military and civilians, with potential fatalities. In this
research, we aim to leverage state-of-the-art machine learning techniques to
classify the outcomes of Afghanistan armed conflicts to either fatal or
non-fatal based on their textual descriptions provided by the Armed Conflict
Location &amp; Event Data Project (ACLED) dataset. The dataset contains
comprehensive descriptions of armed conflicts in Afghanistan that took place
from August 2021 to March 2023. The proposed approach leverages the power of
BERT (Bidirectional Encoder Representations from Transformers), a cutting-edge
language representation model in natural language processing. The classifier
utilizes the raw textual description of an event to estimate the likelihood of
the event resulting in a fatality. The model achieved impressive performance on
the test set with an accuracy of 98.8%, recall of 98.05%, precision of 99.6%,
and an F1 score of 98.82%. These results highlight the model's robustness and
indicate its potential impact in various areas such as resource allocation,
policymaking, and humanitarian aid efforts in Afghanistan. The model indicates
a machine learning-based text classification approach using the ACLED dataset
to accurately classify fatality in Afghanistan armed conflicts, achieving
robust performance with the BERT model and paving the way for future endeavors
in predicting event severity in Afghanistan.
</p></li>
</ul>

<h3>Title: Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning. (arXiv:2310.08746v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08746">http://arxiv.org/abs/2310.08746</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08746]] Robustness to Multi-Modal Environment Uncertainty in MARL using Curriculum Learning(http://arxiv.org/abs/2310.08746)</code></li>
<li>Summary: <p>Multi-agent reinforcement learning (MARL) plays a pivotal role in tackling
real-world challenges. However, the seamless transition of trained policies
from simulations to real-world requires it to be robust to various
environmental uncertainties. Existing works focus on finding Nash Equilibrium
or the optimal policy under uncertainty in one environment variable (i.e.
action, state or reward). This is because a multi-agent system itself is highly
complex and unstationary. However, in real-world situation uncertainty can
occur in multiple environment variables simultaneously. This work is the first
to formulate the generalised problem of robustness to multi-modal environment
uncertainty in MARL. To this end, we propose a general robust training approach
for multi-modal uncertainty based on curriculum learning techniques. We handle
two distinct environmental uncertainty simultaneously and present extensive
results across both cooperative and competitive MARL environments,
demonstrating that our approach achieves state-of-the-art levels of robustness.
</p></li>
</ul>

<h3>Title: Search-Adaptor: Text Embedding Customization for Information Retrieval. (arXiv:2310.08750v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08750">http://arxiv.org/abs/2310.08750</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08750]] Search-Adaptor: Text Embedding Customization for Information Retrieval(http://arxiv.org/abs/2310.08750)</code></li>
<li>Summary: <p>Text embeddings extracted by pre-trained Large Language Models (LLMs) have
significant potential to improve information retrieval and search. Beyond the
zero-shot setup in which they are being conventionally used, being able to take
advantage of the information from the relevant query-corpus paired data has the
power to further boost the LLM capabilities. In this paper, we propose a novel
method, Search-Adaptor, for customizing LLMs for information retrieval in an
efficient and robust way. Search-Adaptor modifies the original text embedding
generated by pre-trained LLMs, and can be integrated with any LLM, including
those only available via APIs. On multiple real-world English and multilingual
retrieval datasets, we show consistent and significant performance benefits for
Search-Adaptor -- e.g., more than 5.2% improvements over the Google Embedding
APIs in nDCG@10 averaged over 13 BEIR datasets.
</p></li>
</ul>

<h3>Title: Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints. (arXiv:2310.08751v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08751">http://arxiv.org/abs/2310.08751</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08751]] Constrained Bayesian Optimization with Adaptive Active Learning of Unknown Constraints(http://arxiv.org/abs/2310.08751)</code></li>
<li>Summary: <p>Optimizing objectives under constraints, where both the objectives and
constraints are black box functions, is a common scenario in real-world
applications such as scientific experimental design, design of medical
therapies, and industrial process optimization. One popular approach to
handling these complex scenarios is Bayesian Optimization (BO). In terms of
theoretical behavior, BO is relatively well understood in the unconstrained
setting, where its principles have been well explored and validated. However,
when it comes to constrained Bayesian optimization (CBO), the existing
framework often relies on heuristics or approximations without the same level
of theoretical guarantees.
</p>
<p>In this paper, we delve into the theoretical and practical aspects of
constrained Bayesian optimization, where the objective and constraints can be
independently evaluated and are subject to noise. By recognizing that both the
objective and constraints can help identify high-confidence regions of interest
(ROI), we propose an efficient CBO framework that intersects the ROIs
identified from each aspect to determine the general ROI. The ROI, coupled with
a novel acquisition function that adaptively balances the optimization of the
objective and the identification of feasible regions, enables us to derive
rigorous theoretical justifications for its performance. We showcase the
efficiency and robustness of our proposed CBO framework through empirical
evidence and discuss the fundamental challenge of deriving practical regret
bounds for CBO algorithms.
</p></li>
</ul>

<h3>Title: On the Over-Memorization During Natural, Robust and Catastrophic Overfitting. (arXiv:2310.08847v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08847">http://arxiv.org/abs/2310.08847</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08847]] On the Over-Memorization During Natural, Robust and Catastrophic Overfitting(http://arxiv.org/abs/2310.08847)</code></li>
<li>Summary: <p>Overfitting negatively impacts the generalization ability of deep neural
networks (DNNs) in both natural and adversarial training. Existing methods
struggle to consistently address different types of overfitting, typically
designing strategies that focus separately on either natural or adversarial
patterns. In this work, we adopt a unified perspective by solely focusing on
natural patterns to explore different types of overfitting. Specifically, we
examine the memorization effect in DNNs and reveal a shared behaviour termed
over-memorization, which impairs their generalization capacity. This behaviour
manifests as DNNs suddenly becoming high-confidence in predicting certain
training patterns and retaining a persistent memory for them. Furthermore, when
DNNs over-memorize an adversarial pattern, they tend to simultaneously exhibit
high-confidence prediction for the corresponding natural pattern. These
findings motivate us to holistically mitigate different types of overfitting by
hindering the DNNs from over-memorization natural patterns. To this end, we
propose a general framework, Distraction Over-Memorization (DOM), which
explicitly prevents over-memorization by either removing or augmenting the
high-confidence natural patterns. Extensive experiments demonstrate the
effectiveness of our proposed method in mitigating overfitting across various
training paradigms.
</p></li>
</ul>

<h3>Title: Online Relocating and Matching of Ride-Hailing Services: A Model-Based Modular Approach. (arXiv:2310.09071v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09071">http://arxiv.org/abs/2310.09071</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09071]] Online Relocating and Matching of Ride-Hailing Services: A Model-Based Modular Approach(http://arxiv.org/abs/2310.09071)</code></li>
<li>Summary: <p>This study proposes an innovative model-based modular approach (MMA) to
dynamically optimize order matching and vehicle relocation in a ride-hailing
platform. MMA utilizes a two-layer and modular modeling structure. The upper
layer determines the spatial transfer patterns of vehicle flow within the
system to maximize the total revenue of the current and future stages. With the
guidance provided by the upper layer, the lower layer performs rapid
vehicle-to-order matching and vehicle relocation. MMA is interpretable, and
equipped with the customized and polynomial-time algorithm, which, as an online
order-matching and vehicle-relocation algorithm, can scale past thousands of
vehicles. We theoretically prove that the proposed algorithm can achieve the
global optimum in stylized networks, while the numerical experiments based on
both the toy network and realistic dataset demonstrate that MMA is capable of
achieving superior systematic performance compared to batch matching and
reinforcement-learning based methods. Moreover, its modular and lightweight
modeling structure further enables it to achieve a high level of robustness
against demand variation while maintaining a relatively low computational cost.
</p></li>
</ul>

<h3>Title: SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection. (arXiv:2310.09203v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09203">http://arxiv.org/abs/2310.09203</a></li>
<li>Code URL: https://github.com/chengstark/siamaf</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09203]] SiamAF: Learning Shared Information from ECG and PPG Signals for Robust Atrial Fibrillation Detection(http://arxiv.org/abs/2310.09203)</code></li>
<li>Summary: <p>Atrial fibrillation (AF) is the most common type of cardiac arrhythmia. It is
associated with an increased risk of stroke, heart failure, and other
cardiovascular complications, but can be clinically silent. Passive AF
monitoring with wearables may help reduce adverse clinical outcomes related to
AF. Detecting AF in noisy wearable data poses a significant challenge, leading
to the emergence of various deep learning techniques. Previous deep learning
models learn from a single modality, either electrocardiogram (ECG) or
photoplethysmography (PPG) signals. However, deep learning models often
struggle to learn generalizable features and rely on features that are more
susceptible to corruption from noise, leading to sub-optimal performances in
certain scenarios, especially with low-quality signals. Given the increasing
availability of ECG and PPG signal pairs from wearables and bedside monitors,
we propose a new approach, SiamAF, leveraging a novel Siamese network
architecture and joint learning loss function to learn shared information from
both ECG and PPG signals. At inference time, the proposed model is able to
predict AF from either PPG or ECG and outperforms baseline methods on three
external test sets. It learns medically relevant features as a result of our
novel architecture design. The proposed model also achieves comparable
performance to traditional learning regimes while requiring much fewer training
labels, providing a potential approach to reduce future reliance on manual
labeling.
</p></li>
</ul>

<h3>Title: Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning. (arXiv:2310.09278v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09278">http://arxiv.org/abs/2310.09278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09278]] Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning(http://arxiv.org/abs/2310.09278)</code></li>
<li>Summary: <p>In deep learning, auxiliary objectives are often used to facilitate learning
in situations where data is scarce, or the principal task is extremely complex.
This idea is primarily inspired by the improved generalization capability
induced by solving multiple tasks simultaneously, which leads to a more robust
shared representation. Nevertheless, finding optimal auxiliary tasks that give
rise to the desired improvement is a crucial problem that often requires
hand-crafted solutions or expensive meta-learning approaches. In this paper, we
propose a novel framework, dubbed Detaux, whereby a weakly supervised
disentanglement procedure is used to discover new unrelated classification
tasks and the associated labels that can be exploited with the principal task
in any Multi-Task Learning (MTL) model. The disentanglement procedure works at
a representation level, isolating a subspace related to the principal task,
plus an arbitrary number of orthogonal subspaces. In the most disentangled
subspaces, through a clustering procedure, we generate the additional
classification tasks, and the associated labels become their representatives.
Subsequently, the original data, the labels associated with the principal task,
and the newly discovered ones can be fed into any MTL framework. Extensive
validation on both synthetic and real data, along with various ablation
studies, demonstrate promising results, revealing the potential in what has
been, so far, an unexplored connection between learning disentangled
representations and MTL. The code will be made publicly available upon
acceptance.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: BibRank: Automatic Keyphrase Extraction Platform Using~Metadata. (arXiv:2310.09151v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09151">http://arxiv.org/abs/2310.09151</a></li>
<li>Code URL: https://github.com/dallal9/bibrank</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09151]] BibRank: Automatic Keyphrase Extraction Platform Using~Metadata(http://arxiv.org/abs/2310.09151)</code></li>
<li>Summary: <p>Automatic Keyphrase Extraction involves identifying essential phrases in a
document. These keyphrases are crucial in various tasks such as document
classification, clustering, recommendation, indexing, searching, summarization,
and text simplification. This paper introduces a platform that integrates
keyphrase datasets and facilitates the evaluation of keyphrase extraction
algorithms. The platform includes BibRank, an automatic keyphrase extraction
algorithm that leverages a rich dataset obtained by parsing bibliographic data
in BibTeX format. BibRank combines innovative weighting techniques with
positional, statistical, and word co-occurrence information to extract
keyphrases from documents. The platform proves valuable for researchers and
developers seeking to enhance their keyphrase extraction algorithms and advance
the field of natural language processing.
</p></li>
</ul>

<h3>Title: PromptRE: Weakly-Supervised Document-Level Relation Extraction via Prompting-Based Data Programming. (arXiv:2310.09265v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09265">http://arxiv.org/abs/2310.09265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09265]] PromptRE: Weakly-Supervised Document-Level Relation Extraction via Prompting-Based Data Programming(http://arxiv.org/abs/2310.09265)</code></li>
<li>Summary: <p>Relation extraction aims to classify the relationships between two entities
into pre-defined categories. While previous research has mainly focused on
sentence-level relation extraction, recent studies have expanded the scope to
document-level relation extraction. Traditional relation extraction methods
heavily rely on human-annotated training data, which is time-consuming and
labor-intensive. To mitigate the need for manual annotation, recent
weakly-supervised approaches have been developed for sentence-level relation
extraction while limited work has been done on document-level relation
extraction. Weakly-supervised document-level relation extraction faces
significant challenges due to an imbalanced number "no relation" instances and
the failure of directly probing pretrained large language models for document
relation extraction. To address these challenges, we propose PromptRE, a novel
weakly-supervised document-level relation extraction method that combines
prompting-based techniques with data programming. Furthermore, PromptRE
incorporates the label distribution and entity types as prior knowledge to
improve the performance. By leveraging the strengths of both prompting and data
programming, PromptRE achieves improved performance in relation classification
and effectively handles the "no relation" problem. Experimental results on
ReDocRED, a benchmark dataset for document-level relation extraction,
demonstrate the superiority of PromptRE over baseline approaches.
</p></li>
</ul>

<h3>Title: Polynomial Time Cryptanalytic Extraction of Neural Network Models. (arXiv:2310.08708v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08708">http://arxiv.org/abs/2310.08708</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08708]] Polynomial Time Cryptanalytic Extraction of Neural Network Models(http://arxiv.org/abs/2310.08708)</code></li>
<li>Summary: <p>Billions of dollars and countless GPU hours are currently spent on training
Deep Neural Networks (DNNs) for a variety of tasks. Thus, it is essential to
determine the difficulty of extracting all the parameters of such neural
networks when given access to their black-box implementations. Many versions of
this problem have been studied over the last 30 years, and the best current
attack on ReLU-based deep neural networks was presented at Crypto 2020 by
Carlini, Jagielski, and Mironov. It resembles a differential chosen plaintext
attack on a cryptosystem, which has a secret key embedded in its black-box
implementation and requires a polynomial number of queries but an exponential
amount of time (as a function of the number of neurons). In this paper, we
improve this attack by developing several new techniques that enable us to
extract with arbitrarily high precision all the real-valued parameters of a
ReLU-based DNN using a polynomial number of queries and a polynomial amount of
time. We demonstrate its practical efficiency by applying it to a full-sized
neural network for classifying the CIFAR10 dataset, which has 3072 inputs, 8
hidden layers with 256 neurons each, and over million neuronal parameters. An
attack following the approach by Carlini et al. requires an exhaustive search
over 2 to the power 256 possibilities. Our attack replaces this with our new
techniques, which require only 30 minutes on a 256-core computer.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Class-Incremental Learning with Prompting. (arXiv:2310.08948v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08948">http://arxiv.org/abs/2310.08948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08948]] Federated Class-Incremental Learning with Prompting(http://arxiv.org/abs/2310.08948)</code></li>
<li>Summary: <p>As Web technology continues to develop, it has become increasingly common to
use data stored on different clients. At the same time, federated learning has
received widespread attention due to its ability to protect data privacy when
let models learn from data which is distributed across various clients.
However, most existing works assume that the client's data are fixed. In
real-world scenarios, such an assumption is most likely not true as data may be
continuously generated and new classes may also appear. To this end, we focus
on the practical and challenging federated class-incremental learning (FCIL)
problem. For FCIL, the local and global models may suffer from catastrophic
forgetting on old classes caused by the arrival of new classes and the data
distributions of clients are non-independent and identically distributed
(non-iid).
</p>
<p>In this paper, we propose a novel method called Federated Class-Incremental
Learning with PrompTing (FCILPT). Given the privacy and limited memory, FCILPT
does not use a rehearsal-based buffer to keep exemplars of old data. We choose
to use prompts to ease the catastrophic forgetting of the old classes.
Specifically, we encode the task-relevant and task-irrelevant knowledge into
prompts, preserving the old and new knowledge of the local clients and solving
the problem of catastrophic forgetting. We first sort the task information in
the prompt pool in the local clients to align the task information on different
clients before global aggregation. It ensures that the same task's knowledge
are fully integrated, solving the problem of non-iid caused by the lack of
classes among different clients in the same incremental task. Experiments on
CIFAR-100, Mini-ImageNet, and Tiny-ImageNet demonstrate that FCILPT achieves
significant accuracy improvements over the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction. (arXiv:2310.08670v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08670">http://arxiv.org/abs/2310.08670</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08670]] Every Parameter Matters: Ensuring the Convergence of Federated Learning with Dynamic Heterogeneous Models Reduction(http://arxiv.org/abs/2310.08670)</code></li>
<li>Summary: <p>Cross-device Federated Learning (FL) faces significant challenges where
low-end clients that could potentially make unique contributions are excluded
from training large models due to their resource bottlenecks. Recent research
efforts have focused on model-heterogeneous FL, by extracting reduced-size
models from the global model and applying them to local clients accordingly.
Despite the empirical success, general theoretical guarantees of convergence on
this method remain an open question. In this paper, we present a unifying
framework for heterogeneous FL algorithms with online model extraction and
provide a general convergence analysis. In particular, we prove that under
certain sufficient conditions and for both IID and non-IID data, these
algorithms converge to a stationary point of standard FL for general smooth
cost functions. Moreover, we illuminate two key factors impacting its
convergence: model-extraction noise and minimum coverage index, advocating a
joint design of local model extraction for efficient heterogeneous FL.
</p></li>
</ul>

<h3>Title: Price of Stability in Quality-Aware Federated Learning. (arXiv:2310.08790v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08790">http://arxiv.org/abs/2310.08790</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08790]] Price of Stability in Quality-Aware Federated Learning(http://arxiv.org/abs/2310.08790)</code></li>
<li>Summary: <p>Federated Learning (FL) is a distributed machine learning scheme that enables
clients to train a shared global model without exchanging local data. The
presence of label noise can severely degrade the FL performance, and some
existing studies have focused on algorithm design for label denoising. However,
they ignored the important issue that clients may not apply costly label
denoising strategies due to them being self-interested and having heterogeneous
valuations on the FL performance. To fill this gap, we model the clients'
interactions as a novel label denoising game and characterize its equilibrium.
We also analyze the price of stability, which quantifies the difference in the
system performance (e.g., global model accuracy, social welfare) between the
equilibrium outcome and the socially optimal solution. We prove that the
equilibrium outcome always leads to a lower global model accuracy than the
socially optimal solution does. We further design an efficient algorithm to
compute the socially optimal solution. Numerical experiments on MNIST dataset
show that the price of stability increases as the clients' data become noisier,
calling for an effective incentive mechanism.
</p></li>
</ul>

<h3>Title: PAGE: Equilibrate Personalization and Generalization in Federated Learning. (arXiv:2310.08961v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08961">http://arxiv.org/abs/2310.08961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08961]] PAGE: Equilibrate Personalization and Generalization in Federated Learning(http://arxiv.org/abs/2310.08961)</code></li>
<li>Summary: <p>Federated learning (FL) is becoming a major driving force behind machine
learning as a service, where customers (clients) collaboratively benefit from
shared local updates under the orchestration of the service provider (server).
Representing clients' current demands and the server's future demand, local
model personalization and global model generalization are separately
investigated, as the ill-effects of data heterogeneity enforce the community to
focus on one over the other. However, these two seemingly competing goals are
of equal importance rather than black and white issues, and should be achieved
simultaneously. In this paper, we propose the first algorithm to balance
personalization and generalization on top of game theory, dubbed PAGE, which
reshapes FL as a co-opetition game between clients and the server. To explore
the equilibrium, PAGE further formulates the game as Markov decision processes,
and leverages the reinforcement learning algorithm, which simplifies the
solving complexity. Extensive experiments on four widespread datasets show that
PAGE outperforms state-of-the-art FL baselines in terms of global and local
prediction accuracy simultaneously, and the accuracy can be improved by up to
35.20% and 39.91%, respectively. In addition, biased variants of PAGE imply
promising adaptiveness to demand shifts in practice.
</p></li>
</ul>

<h3>Title: Federated Meta-Learning for Few-Shot Fault Diagnosis with Representation Encoding. (arXiv:2310.09002v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09002">http://arxiv.org/abs/2310.09002</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09002]] Federated Meta-Learning for Few-Shot Fault Diagnosis with Representation Encoding(http://arxiv.org/abs/2310.09002)</code></li>
<li>Summary: <p>Deep learning-based fault diagnosis (FD) approaches require a large amount of
training data, which are difficult to obtain since they are located across
different entities. Federated learning (FL) enables multiple clients to
collaboratively train a shared model with data privacy guaranteed. However, the
domain discrepancy and data scarcity problems among clients deteriorate the
performance of the global FL model. To tackle these issues, we propose a novel
framework called representation encoding-based federated meta-learning (REFML)
for few-shot FD. First, a novel training strategy based on representation
encoding and meta-learning is developed. It harnesses the inherent
heterogeneity among training clients, effectively transforming it into an
advantage for out-of-distribution generalization on unseen working conditions
or equipment types. Additionally, an adaptive interpolation method that
calculates the optimal combination of local and global models as the
initialization of local training is proposed. This helps to further utilize
local information to mitigate the negative effects of domain discrepancy. As a
result, high diagnostic accuracy can be achieved on unseen working conditions
or equipment types with limited training data. Compared with the
state-of-the-art methods, such as FedProx, the proposed REFML framework
achieves an increase in accuracy by 2.17%-6.50% when tested on unseen working
conditions of the same equipment type and 13.44%-18.33% when tested on totally
unseen equipment types, respectively.
</p></li>
</ul>

<h3>Title: PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning. (arXiv:2310.09183v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09183">http://arxiv.org/abs/2310.09183</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09183]] PRIOR: Personalized Prior for Reactivating the Information Overlooked in Federated Learning(http://arxiv.org/abs/2310.09183)</code></li>
<li>Summary: <p>Classical federated learning (FL) enables training machine learning models
without sharing data for privacy preservation, but heterogeneous data
characteristic degrades the performance of the localized model. Personalized FL
(PFL) addresses this by synthesizing personalized models from a global model
via training on local data. Such a global model may overlook the specific
information that the clients have been sampled. In this paper, we propose a
novel scheme to inject personalized prior knowledge into the global model in
each client, which attempts to mitigate the introduced incomplete information
problem in PFL. At the heart of our proposed approach is a framework, the PFL
with Bregman Divergence (pFedBreD), decoupling the personalized prior from the
local objective function regularized by Bregman divergence for greater
adaptability in personalized scenarios. We also relax the mirror descent (RMD)
to extract the prior explicitly to provide optional strategies. Additionally,
our pFedBreD is backed up by a convergence analysis. Sufficient experiments
demonstrate that our method reaches the state-of-the-art performances on 5
datasets and outperforms other methods by up to 3.5% across 8 benchmarks.
Extensive analyses verify the robustness and necessity of proposed designs.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning. (arXiv:2310.08923v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08923">http://arxiv.org/abs/2310.08923</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08923]] Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning(http://arxiv.org/abs/2310.08923)</code></li>
<li>Summary: <p>Large Language models (LLMs) possess the capability to engage In-context
Learning (ICL) by leveraging a few demonstrations pertaining to a new
downstream task as conditions. However, this particular learning paradigm
suffers from high instability stemming from substantial variances induced by
factors such as the input distribution of selected examples, their ordering,
and prompt formats. In this work, we demonstrate that even when all these
factors are held constant, the random selection of examples still results in
high variance. Consequently, we aim to explore the informative ability of data
examples by quantifying the Information Gain (IG) obtained in prediction after
observing a given example candidate. Then we propose to sample those with
maximum IG. Additionally, we identify the presence of template bias, which can
lead to unfair evaluations of IG during the sampling process. To mitigate this
bias, we introduce Calibration Before Sampling strategy. The experimental
results illustrate that our proposed method can yield an average relative
improvement of 14.3% across six classification tasks using three LLMs.
</p></li>
</ul>

<h3>Title: "Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters. (arXiv:2310.09219v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09219">http://arxiv.org/abs/2310.09219</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09219]] "Kelly is a Warm Person, Joseph is a Role Model": Gender Biases in LLM-Generated Reference Letters(http://arxiv.org/abs/2310.09219)</code></li>
<li>Summary: <p>As generative language models advance, users have started to utilize Large
Language Models (LLMs) to assist in writing various types of content, including
professional documents such as recommendation letters. Despite their
convenience, these applications introduce unprecedented fairness concerns. As
generated reference letters might be directly utilized by users in professional
or academic scenarios, they have the potential to cause direct social harms,
such as lowering success rates for female applicants. Therefore, it is imminent
and necessary to comprehensively study fairness issues and associated harms in
such real-world use cases for future mitigation and monitoring. In this paper,
we critically examine gender bias in LLM-generated reference letters. Inspired
by findings in social science, we design evaluation methods to manifest gender
biases in LLM-generated letters through 2 dimensions: biases in language style
and biases in lexical content. Furthermore, we investigate the extent of bias
propagation by separately analyze bias amplification in model-hallucinated
contents, which we define to be the hallucination bias of model-generated
documents. Through benchmarking evaluation on 4 popular LLMs, including
ChatGPT, Alpaca, Vicuna and StableLM, our study reveals significant gender
biases in LLM-generated recommendation letters. Our findings further point
towards the importance and imminence to recognize biases in LLM-generated
professional documents.
</p></li>
</ul>

<h3>Title: Question Answering for Electronic Health Records: A Scoping Review of datasets and models. (arXiv:2310.08759v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08759">http://arxiv.org/abs/2310.08759</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08759]] Question Answering for Electronic Health Records: A Scoping Review of datasets and models(http://arxiv.org/abs/2310.08759)</code></li>
<li>Summary: <p>Question Answering (QA) systems on patient-related data can assist both
clinicians and patients. They can, for example, assist clinicians in
decision-making and enable patients to have a better understanding of their
medical history. Significant amounts of patient data are stored in Electronic
Health Records (EHRs), making EHR QA an important research area. In EHR QA, the
answer is obtained from the medical record of the patient. Because of the
differences in data format and modality, this differs greatly from other
medical QA tasks that employ medical websites or scientific papers to retrieve
answers, making it critical to research EHR question answering. This study
aimed to provide a methodological review of existing works on QA over EHRs. We
searched for articles from January 1st, 2005 to September 30th, 2023 in four
digital sources including Google Scholar, ACL Anthology, ACM Digital Library,
and PubMed to collect relevant publications on EHR QA. 4111 papers were
identified for our study, and after screening based on our inclusion criteria,
we obtained a total of 47 papers for further study. Out of the 47 papers, 25
papers were about EHR QA datasets, and 37 papers were about EHR QA models. It
was observed that QA on EHRs is relatively new and unexplored. Most of the
works are fairly recent. Also, it was observed that emrQA is by far the most
popular EHR QA dataset, both in terms of citations and usage in other papers.
Furthermore, we identified the different models used in EHR QA along with the
evaluation metrics used for these models.
</p></li>
</ul>

<h3>Title: Adaptivity and Modularity for Efficient Generalization Over Task Complexity. (arXiv:2310.08866v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08866">http://arxiv.org/abs/2310.08866</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08866]] Adaptivity and Modularity for Efficient Generalization Over Task Complexity(http://arxiv.org/abs/2310.08866)</code></li>
<li>Summary: <p>Can transformers generalize efficiently on problems that require dealing with
examples with different levels of difficulty? We introduce a new task tailored
to assess generalization over different complexities and present results that
indicate that standard transformers face challenges in solving these tasks.
These tasks are variations of pointer value retrieval previously introduced by
Zhang et al. (2021). We investigate how the use of a mechanism for adaptive and
modular computation in transformers facilitates the learning of tasks that
demand generalization over the number of sequential computation steps (i.e.,
the depth of the computation graph). Based on our observations, we propose a
transformer-based architecture called Hyper-UT, which combines dynamic function
generation from hyper networks with adaptive depth from Universal Transformers.
This model demonstrates higher accuracy and a fairer allocation of
computational resources when generalizing to higher numbers of computation
steps. We conclude that mechanisms for adaptive depth and modularity complement
each other in improving efficient generalization concerning example complexity.
Additionally, to emphasize the broad applicability of our findings, we
illustrate that in a standard image recognition task, Hyper- UT's performance
matches that of a ViT model but with considerably reduced computational demands
(achieving over 70\% average savings by effectively using fewer layers).
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Towards Interpretable Controllability in Object-Centric Learning. (arXiv:2310.08929v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08929">http://arxiv.org/abs/2310.08929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08929]] Towards Interpretable Controllability in Object-Centric Learning(http://arxiv.org/abs/2310.08929)</code></li>
<li>Summary: <p>The binding problem in artificial neural networks is actively explored with
the goal of achieving human-level recognition skills through the comprehension
of the world in terms of symbol-like entities. Especially in the field of
computer vision, object-centric learning (OCL) is extensively researched to
better understand complex scenes by acquiring object representations or slots.
While recent studies in OCL have made strides with complex images or videos,
the interpretability and interactivity over object representation remain
largely uncharted, still holding promise in the field of OCL. In this paper, we
introduce a novel method, Slot Attention with Image Augmentation (SlotAug), to
explore the possibility of learning interpretable controllability over slots in
a self-supervised manner by utilizing an image augmentation strategy. We also
devise the concept of sustainability in controllable slots by introducing
iterative and reversible controls over slots with two proposed submethods:
Auxiliary Identity Manipulation and Slot Consistency Loss. Extensive empirical
studies and theoretical validation confirm the effectiveness of our approach,
offering a novel capability for interpretable and sustainable control of object
representations. Code will be available soon.
</p></li>
</ul>

<h3>Title: A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check. (arXiv:2310.09119v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09119">http://arxiv.org/abs/2310.09119</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09119]] A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check(http://arxiv.org/abs/2310.09119)</code></li>
<li>Summary: <p>In recent years, Chinese Spelling Check (CSC) has been greatly improved by
designing task-specific pre-training methods or introducing auxiliary tasks,
which mostly solve this task in an end-to-end fashion. In this paper, we
propose to decompose the CSC workflow into detection, reasoning, and searching
subtasks so that the rich external knowledge about the Chinese language can be
leveraged more directly and efficiently. Specifically, we design a
plug-and-play detection-and-reasoning module that is compatible with existing
SOTA non-autoregressive CSC models to further boost their performance. We find
that the detection-and-reasoning module trained for one model can also benefit
other models. We also study the primary interpretability provided by the task
decomposition. Extensive experiments and detailed analyses demonstrate the
effectiveness and competitiveness of the proposed module.
</p></li>
</ul>

<h3>Title: Divorce Prediction with Machine Learning: Insights and LIME Interpretability. (arXiv:2310.08620v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08620">http://arxiv.org/abs/2310.08620</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08620]] Divorce Prediction with Machine Learning: Insights and LIME Interpretability(http://arxiv.org/abs/2310.08620)</code></li>
<li>Summary: <p>Divorce is one of the most common social issues in developed countries like
in the United States. Almost 50% of the recent marriages turn into an
involuntary divorce or separation. While it is evident that people vary to a
different extent, and even over time, an incident like Divorce does not
interrupt the individual's daily activities; still, Divorce has a severe effect
on the individual's mental health, and personal life. Within the scope of this
research, the divorce prediction was carried out by evaluating a dataset named
by the 'divorce predictor dataset' to correctly classify between married and
Divorce people using six different machine learning algorithms- Logistic
Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN),
Classification and Regression Trees (CART), Gaussian Na\"ive Bayes (NB), and,
Support Vector Machines (SVM). Preliminary computational results show that
algorithms such as SVM, KNN, and LDA, can perform that task with an accuracy of
98.57%. This work's additional novel contribution is the detailed and
comprehensive explanation of prediction probabilities using Local Interpretable
Model-Agnostic Explanations (LIME). Utilizing LIME to analyze test results
illustrates the possibility of differentiating between divorced and married
couples. Finally, we have developed a divorce predictor app considering ten
most important features that potentially affect couples in making decisions in
their divorce, such tools can be used by any one in order to identify their
relationship condition.
</p></li>
</ul>

<h3>Title: Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality. (arXiv:2310.09222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09222">http://arxiv.org/abs/2310.09222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09222]] Fast & Efficient Learning of Bayesian Networks from Data: Knowledge Discovery and Causality(http://arxiv.org/abs/2310.09222)</code></li>
<li>Summary: <p>Structure learning is essential for Bayesian networks (BNs) as it uncovers
causal relationships, and enables knowledge discovery, predictions, inferences,
and decision-making under uncertainty. Two novel algorithms, FSBN and SSBN,
based on the PC algorithm, employ local search strategy and conditional
independence tests to learn the causal network structure from data. They
incorporate d-separation to infer additional topology information, prioritize
conditioning sets, and terminate the search immediately and efficiently. FSBN
achieves up to 52% computation cost reduction, while SSBN surpasses it with a
remarkable 72% reduction for a 200-node network. SSBN demonstrates further
efficiency gains due to its intelligent strategy. Experimental studies show
that both algorithms match the induction quality of the PC algorithm while
significantly reducing computation costs. This enables them to offer
interpretability and adaptability while reducing the computational burden,
making them valuable for various applications in big data analytics.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h3>Title: Embarrassingly Simple Text Watermarks. (arXiv:2310.08920v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08920">http://arxiv.org/abs/2310.08920</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08920]] Embarrassingly Simple Text Watermarks(http://arxiv.org/abs/2310.08920)</code></li>
<li>Summary: <p>We propose Easymark, a family of embarrassingly simple yet effective
watermarks. Text watermarking is becoming increasingly important with the
advent of Large Language Models (LLM). LLMs can generate texts that cannot be
distinguished from human-written texts. This is a serious problem for the
credibility of the text. Easymark is a simple yet effective solution to this
problem. Easymark can inject a watermark without changing the meaning of the
text at all while a validator can detect if a text was generated from a system
that adopted Easymark or not with high credibility. Easymark is extremely easy
to implement so that it only requires a few lines of code. Easymark does not
require access to LLMs, so it can be implemented on the user-side when the LLM
providers do not offer watermarked LLMs. In spite of its simplicity, it
achieves higher detection accuracy and BLEU scores than the state-of-the-art
text watermarking methods. We also prove the impossibility theorem of perfect
watermarking, which is valuable in its own right. This theorem shows that no
matter how sophisticated a watermark is, a malicious user could remove it from
the text, which motivate us to use a simple watermark such as Easymark. We
carry out experiments with LLM-generated texts and confirm that Easymark can be
detected reliably without any degradation of BLEU and perplexity, and
outperform state-of-the-art watermarks in terms of both quality and
reliability.
</p></li>
</ul>

<h2>diffusion</h2>
<h3>Title: Histogram- and Diffusion-Based Medical Out-of-Distribution Detection. (arXiv:2310.08654v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08654">http://arxiv.org/abs/2310.08654</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08654]] Histogram- and Diffusion-Based Medical Out-of-Distribution Detection(http://arxiv.org/abs/2310.08654)</code></li>
<li>Summary: <p>Out-of-distribution (OOD) detection is crucial for the safety and reliability
of artificial intelligence algorithms, especially in the medical domain. In the
context of the Medical OOD (MOOD) detection challenge 2023, we propose a
pipeline that combines a histogram-based method and a diffusion-based method.
The histogram-based method is designed to accurately detect homogeneous
anomalies in the toy examples of the challenge, such as blobs with constant
intensity values. The diffusion-based method is based on one of the latest
methods for unsupervised anomaly detection, called DDPM-OOD. We explore this
method and propose extensive post-processing steps for pixel-level and
sample-level anomaly detection on brain MRI and abdominal CT data provided by
the challenge. Our results show that the proposed DDPM method is sensitive to
blur and bias field samples, but faces challenges with anatomical deformation,
black slice, and swapped patches. These findings suggest that further research
is needed to improve the performance of DDPM for OOD detection in medical
images.
</p></li>
</ul>

<h3>Title: DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing. (arXiv:2310.08785v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08785">http://arxiv.org/abs/2310.08785</a></li>
<li>Code URL: https://github.com/yueming6568/deltaedit</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08785]] DeltaSpace: A Semantic-aligned Feature Space for Flexible Text-guided Image Editing(http://arxiv.org/abs/2310.08785)</code></li>
<li>Summary: <p>Text-guided image editing faces significant challenges to training and
inference flexibility. Much literature collects large amounts of annotated
image-text pairs to train text-conditioned generative models from scratch,
which is expensive and not efficient. After that, some approaches that leverage
pre-trained vision-language models are put forward to avoid data collection,
but they are also limited by either per text-prompt optimization or
inference-time hyper-parameters tuning. To address these issues, we investigate
and identify a specific space, referred to as CLIP DeltaSpace, where the CLIP
visual feature difference of two images is semantically aligned with the CLIP
textual feature difference of their corresponding text descriptions. Based on
DeltaSpace, we propose a novel framework called DeltaEdit, which maps the CLIP
visual feature differences to the latent space directions of a generative model
during the training phase, and predicts the latent space directions from the
CLIP textual feature differences during the inference phase. And this design
endows DeltaEdit with two advantages: (1) text-free training; (2)
generalization to various text prompts for zero-shot inference. Extensive
experiments validate the effectiveness and versatility of DeltaEdit with
different generative models, including both the GAN model and the diffusion
model, in achieving flexible text-guided image editing. Code is available at
https://github.com/Yueming6568/DeltaEdit.
</p></li>
</ul>

<h3>Title: R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation. (arXiv:2310.08872v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08872">http://arxiv.org/abs/2310.08872</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08872]] R&B: Region and Boundary Aware Zero-shot Grounded Text-to-image Generation(http://arxiv.org/abs/2310.08872)</code></li>
<li>Summary: <p>Recent text-to-image (T2I) diffusion models have achieved remarkable progress
in generating high-quality images given text-prompts as input. However, these
models fail to convey appropriate spatial composition specified by a layout
instruction. In this work, we probe into zero-shot grounded T2I generation with
diffusion models, that is, generating images corresponding to the input layout
information without training auxiliary modules or finetuning diffusion models.
We propose a Region and Boundary (R&amp;B) aware cross-attention guidance approach
that gradually modulates the attention maps of diffusion model during
generative process, and assists the model to synthesize images (1) with high
fidelity, (2) highly compatible with textual input, and (3) interpreting layout
instructions accurately. Specifically, we leverage the discrete sampling to
bridge the gap between consecutive attention maps and discrete layout
constraints, and design a region-aware loss to refine the generative layout
during diffusion process. We further propose a boundary-aware loss to
strengthen object discriminability within the corresponding regions.
Experimental results show that our method outperforms existing state-of-the-art
zero-shot grounded T2I generation methods by a large margin both qualitatively
and quantitatively on several benchmarks.
</p></li>
</ul>

<h3>Title: Unseen Image Synthesis with Diffusion Models. (arXiv:2310.09213v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09213">http://arxiv.org/abs/2310.09213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09213]] Unseen Image Synthesis with Diffusion Models(http://arxiv.org/abs/2310.09213)</code></li>
<li>Summary: <p>While the current trend in the generative field is scaling up towards larger
models and more training data for generalized domain representations, we go the
opposite direction in this work by synthesizing unseen domain images without
additional training. We do so via latent sampling and geometric optimization
using pre-trained and frozen Denoising Diffusion Probabilistic Models (DDPMs)
on single-domain datasets. Our key observation is that DDPMs pre-trained even
just on single-domain images are already equipped with sufficient
representation abilities to reconstruct arbitrary images from the inverted
latent encoding following bi-directional deterministic diffusion and denoising
trajectories. This motivates us to investigate the statistical and geometric
behaviors of the Out-Of-Distribution (OOD) samples from unseen image domains in
the latent spaces along the denoising chain. Notably, we theoretically and
empirically show that the inverted OOD samples also establish Gaussians that
are distinguishable from the original In-Domain (ID) samples in the
intermediate latent spaces, which allows us to sample from them directly.
Geometrical domain-specific and model-dependent information of the unseen
subspace (e.g., sample-wise distance and angles) is used to further optimize
the sampled OOD latent encodings from the estimated Gaussian prior. We conduct
extensive analysis and experiments using pre-trained diffusion models (DDPM,
iDDPM) on different datasets (AFHQ, CelebA-HQ, LSUN-Church, and LSUN-Bedroom),
proving the effectiveness of this novel perspective to explore and re-think the
diffusion models' data synthesis generalization ability.
</p></li>
</ul>

<h3>Title: Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy. (arXiv:2310.09247v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09247">http://arxiv.org/abs/2310.09247</a></li>
<li>Code URL: https://github.com/yandex-research/text-to-img-hypernymy</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09247]] Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy(http://arxiv.org/abs/2310.09247)</code></li>
<li>Summary: <p>Text-to-image synthesis has recently attracted widespread attention due to
rapidly improving quality and numerous practical applications. However, the
language understanding capabilities of text-to-image models are still poorly
understood, which makes it difficult to reason about prompt formulations that a
given model would understand well. In this work, we measure the capability of
popular text-to-image models to understand $\textit{hypernymy}$, or the "is-a"
relation between words. We design two automatic metrics based on the WordNet
semantic hierarchy and existing image classifiers pretrained on ImageNet. These
metrics both enable broad quantitative comparison of linguistic capabilities
for text-to-image models and offer a way of finding fine-grained qualitative
differences, such as words that are unknown to models and thus are difficult
for them to draw. We comprehensively evaluate popular text-to-image models,
including GLIDE, Latent Diffusion, and Stable Diffusion, showing how our
metrics can provide a better understanding of the individual strengths and
weaknesses of these models.
</p></li>
</ul>

<h3>Title: DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection. (arXiv:2310.08800v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08800">http://arxiv.org/abs/2310.08800</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08800]] DDMT: Denoising Diffusion Mask Transformer Models for Multivariate Time Series Anomaly Detection(http://arxiv.org/abs/2310.08800)</code></li>
<li>Summary: <p>Anomaly detection in multivariate time series has emerged as a crucial
challenge in time series research, with significant research implications in
various fields such as fraud detection, fault diagnosis, and system state
estimation. Reconstruction-based models have shown promising potential in
recent years for detecting anomalies in time series data. However, due to the
rapid increase in data scale and dimensionality, the issues of noise and Weak
Identity Mapping (WIM) during time series reconstruction have become
increasingly pronounced. To address this, we introduce a novel Adaptive Dynamic
Neighbor Mask (ADNM) mechanism and integrate it with the Transformer and
Denoising Diffusion Model, creating a new framework for multivariate time
series anomaly detection, named Denoising Diffusion Mask Transformer (DDMT).
The ADNM module is introduced to mitigate information leakage between input and
output features during data reconstruction, thereby alleviating the problem of
WIM during reconstruction. The Denoising Diffusion Transformer (DDT) employs
the Transformer as an internal neural network structure for Denoising Diffusion
Model. It learns the stepwise generation process of time series data to model
the probability distribution of the data, capturing normal data patterns and
progressively restoring time series data by removing noise, resulting in a
clear recovery of anomalies. To the best of our knowledge, this is the first
model that combines Denoising Diffusion Model and the Transformer for
multivariate time series anomaly detection. Experimental evaluations were
conducted on five publicly available multivariate time series anomaly detection
datasets. The results demonstrate that the model effectively identifies
anomalies in time series data, achieving state-of-the-art performance in
anomaly detection.
</p></li>
</ul>

<h3>Title: MINDE: Mutual Information Neural Diffusion Estimation. (arXiv:2310.09031v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09031">http://arxiv.org/abs/2310.09031</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09031]] MINDE: Mutual Information Neural Diffusion Estimation(http://arxiv.org/abs/2310.09031)</code></li>
<li>Summary: <p>In this work we present a new method for the estimation of Mutual Information
(MI) between random variables. Our approach is based on an original
interpretation of the Girsanov theorem, which allows us to use score-based
diffusion models to estimate the Kullback Leibler divergence between two
densities as a difference between their score functions. As a by-product, our
method also enables the estimation of the entropy of random variables. Armed
with such building blocks, we present a general recipe to measure MI, which
unfolds in two directions: one uses conditional diffusion process, whereas the
other uses joint diffusion processes that allow simultaneous modelling of two
random variables. Our results, which derive from a thorough experimental
protocol over all the variants of our approach, indicate that our method is
more accurate than the main alternatives from the literature, especially for
challenging distributions. Furthermore, our methods pass MI self-consistency
tests, including data processing and additivity under independence, which
instead are a pain-point of existing methods.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h3>Title: Extending Multi-modal Contrastive Representations. (arXiv:2310.08884v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08884">http://arxiv.org/abs/2310.08884</a></li>
<li>Code URL: https://github.com/mcr-peft/ex-mcr</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08884]] Extending Multi-modal Contrastive Representations(http://arxiv.org/abs/2310.08884)</code></li>
<li>Summary: <p>Multi-modal contrastive representation (MCR) of more than three modalities is
critical in multi-modal learning. Although recent methods showcase impressive
achievements, the high dependence on large-scale, high-quality paired data and
the expensive training costs limit their further development. Inspired by
recent C-MCR, this paper proposes Extending Multimodal Contrastive
Representation (Ex-MCR), a training-efficient and paired-data-free method to
flexibly learn unified contrastive representation space for more than three
modalities by integrating the knowledge of existing MCR spaces. Specifically,
Ex-MCR aligns multiple existing MCRs into the same based MCR, which can
effectively preserve the original semantic alignment of the based MCR. Besides,
we comprehensively enhance the entire learning pipeline for aligning MCR spaces
from the perspectives of training data, architecture, and learning objectives.
With the preserved original modality alignment and the enhanced space
alignment, Ex-MCR shows superior representation learning performance and
excellent modality extensibility. To demonstrate the effectiveness of Ex-MCR,
we align the MCR spaces of CLAP (audio-text) and ULIP (3D-vision) into the CLIP
(vision-text), leveraging the overlapping text and image modality,
respectively. Remarkably, without using any paired data, Ex-MCR learns a
3D-image-text-audio unified contrastive representation, and it achieves
state-of-the-art performance on audio-visual, 3D-image, audio-text, visual-text
retrieval, and 3D object classification tasks. More importantly, extensive
qualitative results further demonstrate the emergent semantic alignment between
the extended modalities (e.g., audio and 3D), which highlights the great
potential of modality extensibility.
</p></li>
</ul>

<h2>transformer</h2>
<h3>Title: Rank-DETR for High Quality Object Detection. (arXiv:2310.08854v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08854">http://arxiv.org/abs/2310.08854</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08854]] Rank-DETR for High Quality Object Detection(http://arxiv.org/abs/2310.08854)</code></li>
<li>Summary: <p>Modern detection transformers (DETRs) use a set of object queries to predict
a list of bounding boxes, sort them by their classification confidence scores,
and select the top-ranked predictions as the final detection results for the
given input image. A highly performant object detector requires accurate
ranking for the bounding box predictions. For DETR-based detectors, the
top-ranked bounding boxes suffer from less accurate localization quality due to
the misalignment between classification scores and localization accuracy, thus
impeding the construction of high-quality detectors. In this work, we introduce
a simple and highly performant DETR-based object detector by proposing a series
of rank-oriented designs, combinedly called Rank-DETR. Our key contributions
include: (i) a rank-oriented architecture design that can prompt positive
predictions and suppress the negative ones to ensure lower false positive
rates, as well as (ii) a rank-oriented loss function and matching cost design
that prioritizes predictions of more accurate localization accuracy during
ranking to boost the AP under high IoU thresholds. We apply our method to
improve the recent SOTA methods (e.g., H-DETR and DINO-DETR) and report strong
COCO object detection results when using different backbones such as
ResNet-$50$, Swin-T, and Swin-L, demonstrating the effectiveness of our
approach. Code is available at \url{https://github.com/LeapLabTHU/Rank-DETR}.
</p></li>
</ul>

<h3>Title: PaLI-3 Vision Language Models: Smaller, Faster, Stronger. (arXiv:2310.09199v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09199">http://arxiv.org/abs/2310.09199</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09199]] PaLI-3 Vision Language Models: Smaller, Faster, Stronger(http://arxiv.org/abs/2310.09199)</code></li>
<li>Summary: <p>This paper presents PaLI-3, a smaller, faster, and stronger vision language
model (VLM) that compares favorably to similar models that are 10x larger. As
part of arriving at this strong performance, we compare Vision Transformer
(ViT) models pretrained using classification objectives to contrastively
(SigLIP) pretrained ones. We find that, while slightly underperforming on
standard image classification benchmarks, SigLIP-based PaLI shows superior
performance across various multimodal benchmarks, especially on localization
and visually-situated text understanding. We scale the SigLIP image encoder up
to 2 billion parameters, and achieves a new state-of-the-art on multilingual
cross-modal retrieval. We hope that PaLI-3, at only 5B parameters, rekindles
research on fundamental pieces of complex VLMs, and could fuel a new generation
of scaled-up models.
</p></li>
</ul>

<h3>Title: Transformer-based Multimodal Change Detection with Multitask Consistency Constraints. (arXiv:2310.09276v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09276">http://arxiv.org/abs/2310.09276</a></li>
<li>Code URL: https://github.com/qaz670756/mmcd</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09276]] Transformer-based Multimodal Change Detection with Multitask Consistency Constraints(http://arxiv.org/abs/2310.09276)</code></li>
<li>Summary: <p>Change detection plays a fundamental role in Earth observation for analyzing
temporal iterations over time. However, recent studies have largely neglected
the utilization of multimodal data that presents significant practical and
technical advantages compared to single-modal approaches. This research focuses
on leveraging digital surface model (DSM) data and aerial images captured at
different times for detecting change beyond 2D. We observe that the current
change detection methods struggle with the multitask conflicts between semantic
and height change detection tasks. To address this challenge, we propose an
efficient Transformer-based network that learns shared representation between
cross-dimensional inputs through cross-attention. It adopts a consistency
constraint to establish the multimodal relationship, which involves obtaining
pseudo change through height change thresholding and minimizing the difference
between semantic and pseudo change within their overlapping regions. A
DSM-to-image multimodal dataset encompassing three cities in the Netherlands
was constructed. It lays a new foundation for beyond-2D change detection from
cross-dimensional inputs. Compared to five state-of-the-art change detection
methods, our model demonstrates consistent multitask superiority in terms of
semantic and height change detection. Furthermore, the consistency strategy can
be seamlessly adapted to the other methods, yielding promising improvements.
</p></li>
</ul>

<h3>Title: Circuit Component Reuse Across Tasks in Transformer Language Models. (arXiv:2310.08744v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08744">http://arxiv.org/abs/2310.08744</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08744]] Circuit Component Reuse Across Tasks in Transformer Language Models(http://arxiv.org/abs/2310.08744)</code></li>
<li>Summary: <p>Recent work in mechanistic interpretability has shown that behaviors in
language models can be successfully reverse-engineered through circuit
analysis. A common criticism, however, is that each circuit is task-specific,
and thus such analysis cannot contribute to understanding the models at a
higher level. In this work, we present evidence that insights (both low-level
findings about specific heads and higher-level findings about general
algorithms) can indeed generalize across tasks. Specifically, we study the
circuit discovered in Wang et al. (2022) for the Indirect Object Identification
(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that
it is mostly reused to solve a seemingly different task: Colored Objects
(Ippolito &amp; Callison-Burch, 2023). We provide evidence that the process
underlying both tasks is functionally very similar, and contains about a 78%
overlap in in-circuit attention heads. We further present a proof-of-concept
intervention experiment, in which we adjust four attention heads in middle
layers in order to 'repair' the Colored Objects circuit and make it behave like
the IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the
Colored Objects task and explain most sources of error. The intervention
affects downstream attention heads in specific ways predicted by their
interactions in the IOI circuit, indicating that this subcircuit behavior is
invariant to the different task inputs. Overall, our results provide evidence
that it may yet be possible to explain large language models' behavior in terms
of a relatively small number of interpretable task-general algorithmic building
blocks and computational components.
</p></li>
</ul>

<h3>Title: A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models. (arXiv:2310.08797v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08797">http://arxiv.org/abs/2310.08797</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08797]] A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models(http://arxiv.org/abs/2310.08797)</code></li>
<li>Summary: <p>Large language models have become a vital component in modern NLP, achieving
state of the art performance in a variety of tasks. However, they are often
inefficient for real-world deployment due to their expensive inference costs.
Knowledge distillation is a promising technique to improve their efficiency
while retaining most of their effectiveness. In this paper, we reproduce,
compare and analyze several representative methods for task-agnostic
(general-purpose) distillation of Transformer language models. Our target of
study includes Output Distribution (OD) transfer, Hidden State (HS) transfer
with various layer mapping strategies, and Multi-Head Attention (MHA) transfer
based on MiniLMv2. Through our extensive experiments, we study the
effectiveness of each method for various student architectures in both
monolingual (English) and multilingual settings. Overall, we show that MHA
transfer based on MiniLMv2 is generally the best option for distillation and
explain the potential reasons behind its success. Moreover, we show that HS
transfer remains as a competitive baseline, especially under a sophisticated
layer mapping strategy, while OD transfer consistently lags behind other
approaches. Findings from this study helped us deploy efficient yet effective
student models for latency-critical applications.
</p></li>
</ul>

<h3>Title: Exploration with Principles for Diverse AI Supervision. (arXiv:2310.08899v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08899">http://arxiv.org/abs/2310.08899</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08899]] Exploration with Principles for Diverse AI Supervision(http://arxiv.org/abs/2310.08899)</code></li>
<li>Summary: <p>Training large transformers using next-token prediction has given rise to
groundbreaking advancements in AI. While this generative AI approach has
produced impressive results, it heavily leans on human supervision. Even
state-of-the-art AI models like ChatGPT depend on fine-tuning through human
demonstrations, demanding extensive human input and domain expertise. This
strong reliance on human oversight poses a significant hurdle to the
advancement of AI innovation. To address this limitation, we propose a novel
paradigm termed Exploratory AI (EAI) aimed at autonomously generating
high-quality training data. Drawing inspiration from unsupervised reinforcement
learning (RL) pretraining, EAI achieves exploration within the natural language
space. We accomplish this by harnessing large language models to assess the
novelty of generated content. Our approach employs two key components: an actor
that generates novel content following exploration principles and a critic that
evaluates the generated content, offering critiques to guide the actor.
Empirical evaluations demonstrate that EAI significantly boosts model
performance on complex reasoning tasks, addressing the limitations of
human-intensive supervision.
</p></li>
</ul>

<h3>Title: Towards Example-Based NMT with Multi-Levenshtein Transformers. (arXiv:2310.08967v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08967">http://arxiv.org/abs/2310.08967</a></li>
<li>Code URL: https://github.com/maxwell1447/fairseq</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08967]] Towards Example-Based NMT with Multi-Levenshtein Transformers(http://arxiv.org/abs/2310.08967)</code></li>
<li>Summary: <p>Retrieval-Augmented Machine Translation (RAMT) is attracting growing
attention. This is because RAMT not only improves translation metrics, but is
also assumed to implement some form of domain adaptation. In this contribution,
we study another salient trait of RAMT, its ability to make translation
decisions more transparent by allowing users to go back to examples that
contributed to these decisions.
</p>
<p>For this, we propose a novel architecture aiming to increase this
transparency. This model adapts a retrieval-augmented version of the
Levenshtein Transformer and makes it amenable to simultaneously edit multiple
fuzzy matches found in memory. We discuss how to perform training and inference
in this model, based on multi-way alignment algorithms and imitation learning.
Our experiments show that editing several examples positively impacts
translation scores, notably increasing the number of target spans that are
copied from existing instances.
</p></li>
</ul>

<h3>Title: BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts. (arXiv:2310.09238v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09238">http://arxiv.org/abs/2310.09238</a></li>
<li>Code URL: https://github.com/Saumajit/BanglaNLP/tree/main/Task_2</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09238]] BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts(http://arxiv.org/abs/2310.09238)</code></li>
<li>Summary: <p>Bangla is the 7th most widely spoken language globally, with a staggering 234
million native speakers primarily hailing from India and Bangladesh. This
morphologically rich language boasts a rich literary tradition, encompassing
diverse dialects and language-specific challenges. Despite its linguistic
richness and history, Bangla remains categorized as a low-resource language
within the natural language processing (NLP) and speech community. This paper
presents our submission to Task 2 (Sentiment Analysis of Bangla Social Media
Posts) of the BLP Workshop. We experiment with various Transformer-based
architectures to solve this task. Our quantitative results show that transfer
learning really helps in better learning of the models in this low-resource
language scenario. This becomes evident when we further finetune a model which
has already been finetuned on twitter data for sentiment analysis task and that
finetuned model performs the best among all other models. We also perform a
detailed error analysis where we find some instances where ground truth labels
need to be relooked at. We obtain a micro-F1 of 67.02\% on the test set and our
performance in this shared task is ranked at 21 in the leaderboard.
</p></li>
</ul>

<h3>Title: Counting and Algorithmic Generalization with Transformers. (arXiv:2310.08661v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08661">http://arxiv.org/abs/2310.08661</a></li>
<li>Code URL: https://github.com/simonouellette35/countingwithtransformers</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08661]] Counting and Algorithmic Generalization with Transformers(http://arxiv.org/abs/2310.08661)</code></li>
<li>Summary: <p>Algorithmic generalization in machine learning refers to the ability to learn
the underlying algorithm that generates data in a way that generalizes
out-of-distribution. This is generally considered a difficult task for most
machine learning algorithms. Here, we analyze algorithmic generalization when
counting is required, either implicitly or explicitly. We show that standard
Transformers are based on architectural decisions that hinder
out-of-distribution performance for such tasks. In particular, we discuss the
consequences of using layer normalization and of normalizing the attention
weights via softmax. With ablation of the problematic operations, we
demonstrate that a modified transformer can exhibit a good algorithmic
generalization performance on counting while using a very lightweight
architecture.
</p></li>
</ul>

<h3>Title: Kernel-Elastic Autoencoder for Molecular Design. (arXiv:2310.08685v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08685">http://arxiv.org/abs/2310.08685</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08685]] Kernel-Elastic Autoencoder for Molecular Design(http://arxiv.org/abs/2310.08685)</code></li>
<li>Summary: <p>We introduce the Kernel-Elastic Autoencoder (KAE), a self-supervised
generative model based on the transformer architecture with enhanced
performance for molecular design. KAE is formulated based on two novel loss
functions: modified maximum mean discrepancy and weighted reconstruction. KAE
addresses the long-standing challenge of achieving valid generation and
accurate reconstruction at the same time. KAE achieves remarkable diversity in
molecule generation while maintaining near-perfect reconstructions on the
independent testing dataset, surpassing previous molecule-generating models.
KAE enables conditional generation and allows for decoding based on beam search
resulting in state-of-the-art performance in constrained optimizations.
Furthermore, KAE can generate molecules conditional to favorable binding
affinities in docking applications as confirmed by AutoDock Vina and Glide
scores, outperforming all existing candidates from the training dataset. Beyond
molecular design, we anticipate KAE could be applied to solve problems by
generation in a wide range of applications.
</p></li>
</ul>

<h3>Title: Transformer Choice Net: A Transformer Neural Network for Choice Prediction. (arXiv:2310.08716v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08716">http://arxiv.org/abs/2310.08716</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08716]] Transformer Choice Net: A Transformer Neural Network for Choice Prediction(http://arxiv.org/abs/2310.08716)</code></li>
<li>Summary: <p>Discrete-choice models, such as Multinomial Logit, Probit, or Mixed-Logit,
are widely used in Marketing, Economics, and Operations Research: given a set
of alternatives, the customer is modeled as choosing one of the alternatives to
maximize a (latent) utility function. However, extending such models to
situations where the customer chooses more than one item (such as in e-commerce
shopping) has proven problematic. While one can construct reasonable models of
the customer's behavior, estimating such models becomes very challenging
because of the combinatorial explosion in the number of possible subsets of
items. In this paper we develop a transformer neural network architecture, the
Transformer Choice Net, that is suitable for predicting multiple choices.
Transformer networks turn out to be especially suitable for this task as they
take into account not only the features of the customer and the items but also
the context, which in this case could be the assortment as well as the
customer's past choices. On a range of benchmark datasets, our architecture
shows uniformly superior out-of-sample prediction performance compared to the
leading models in the literature, without requiring any custom modeling or
tuning for each instance.
</p></li>
</ul>

<h3>Title: Detection and prediction of clopidogrel treatment failures using longitudinal structured electronic health records. (arXiv:2310.08757v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08757">http://arxiv.org/abs/2310.08757</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08757]] Detection and prediction of clopidogrel treatment failures using longitudinal structured electronic health records(http://arxiv.org/abs/2310.08757)</code></li>
<li>Summary: <p>We propose machine learning algorithms to automatically detect and predict
clopidogrel treatment failure using longitudinal structured electronic health
records (EHR). By drawing analogies between natural language and structured
EHR, we introduce various machine learning algorithms used in natural language
processing (NLP) applications to build models for treatment failure detection
and prediction. In this regard, we generated a cohort of patients with
clopidogrel prescriptions from UK Biobank and annotated if the patients had
treatment failure events within one year of the first clopidogrel prescription;
out of 502,527 patients, 1,824 patients were identified as treatment failure
cases, and 6,859 patients were considered as control cases. From the dataset,
we gathered diagnoses, prescriptions, and procedure records together per
patient and organized them into visits with the same date to build models. The
models were built for two different tasks, i.e., detection and prediction, and
the experimental results showed that time series models outperform bag-of-words
approaches in both tasks. In particular, a Transformer-based model, namely
BERT, could reach 0.928 AUC in detection tasks and 0.729 AUC in prediction
tasks. BERT also showed competence over other time series models when there is
not enough training data, because it leverages the pre-training procedure using
large unlabeled data.
</p></li>
</ul>

<h3>Title: Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement Learning with Sub-optimal Demonstrations. (arXiv:2310.08823v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08823">http://arxiv.org/abs/2310.08823</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08823]] Distance-rank Aware Sequential Reward Learning for Inverse Reinforcement Learning with Sub-optimal Demonstrations(http://arxiv.org/abs/2310.08823)</code></li>
<li>Summary: <p>Inverse reinforcement learning (IRL) aims to explicitly infer an underlying
reward function based on collected expert demonstrations. Considering that
obtaining expert demonstrations can be costly, the focus of current IRL
techniques is on learning a better-than-demonstrator policy using a reward
function derived from sub-optimal demonstrations. However, existing IRL
algorithms primarily tackle the challenge of trajectory ranking ambiguity when
learning the reward function. They overlook the crucial role of considering the
degree of difference between trajectories in terms of their returns, which is
essential for further removing reward ambiguity. Additionally, it is important
to note that the reward of a single transition is heavily influenced by the
context information within the trajectory. To address these issues, we
introduce the Distance-rank Aware Sequential Reward Learning (DRASRL)
framework. Unlike existing approaches, DRASRL takes into account both the
ranking of trajectories and the degrees of dissimilarity between them to
collaboratively eliminate reward ambiguity when learning a sequence of
contextually informed reward signals. Specifically, we leverage the distance
between policies, from which the trajectories are generated, as a measure to
quantify the degree of differences between traces. This distance-aware
information is then used to infer embeddings in the representation space for
reward learning, employing the contrastive learning technique. Meanwhile, we
integrate the pairwise ranking loss function to incorporate ranking information
into the latent features. Moreover, we resort to the Transformer architecture
to capture the contextual dependencies within the trajectories in the latent
space, leading to more accurate reward estimation. Through extensive
experimentation, our DRASRL framework demonstrates significant performance
improvements over previous SOTA methods.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: A Benchmarking Protocol for SAR Colorization: From Regression to Deep Learning Approaches. (arXiv:2310.08705v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08705">http://arxiv.org/abs/2310.08705</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08705]] A Benchmarking Protocol for SAR Colorization: From Regression to Deep Learning Approaches(http://arxiv.org/abs/2310.08705)</code></li>
<li>Summary: <p>Synthetic aperture radar (SAR) images are widely used in remote sensing.
Interpreting SAR images can be challenging due to their intrinsic speckle noise
and grayscale nature. To address this issue, SAR colorization has emerged as a
research direction to colorize gray scale SAR images while preserving the
original spatial information and radiometric information. However, this
research field is still in its early stages, and many limitations can be
highlighted. In this paper, we propose a full research line for supervised
learning-based approaches to SAR colorization. Our approach includes a protocol
for generating synthetic color SAR images, several baselines, and an effective
method based on the conditional generative adversarial network (cGAN) for SAR
colorization. We also propose numerical assessment metrics for the problem at
hand. To our knowledge, this is the first attempt to propose a research line
for SAR colorization that includes a protocol, a benchmark, and a complete
performance evaluation. Our extensive tests demonstrate the effectiveness of
our proposed cGAN-based network for SAR colorization. The code will be made
publicly available.
</p></li>
</ul>

<h3>Title: Vision-by-Language for Training-Free Compositional Image Retrieval. (arXiv:2310.09291v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09291">http://arxiv.org/abs/2310.09291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09291]] Vision-by-Language for Training-Free Compositional Image Retrieval(http://arxiv.org/abs/2310.09291)</code></li>
<li>Summary: <p>Given an image and a target modification (e.g an image of the Eiffel tower
and the text "without people and at night-time"), Compositional Image Retrieval
(CIR) aims to retrieve the relevant target image in a database. While
supervised approaches rely on annotating triplets that is costly (i.e. query
image, textual modification, and target image), recent research sidesteps this
need by using large-scale vision-language models (VLMs), performing Zero-Shot
CIR (ZS-CIR). However, state-of-the-art approaches in ZS-CIR still require
training task-specific, customized models over large amounts of image-text
pairs. In this work, we propose to tackle CIR in a training-free manner via our
Compositional Image Retrieval through Vision-by-Language (CIReVL), a simple,
yet human-understandable and scalable pipeline that effectively recombines
large-scale VLMs with large language models (LLMs). By captioning the reference
image using a pre-trained generative VLM and asking a LLM to recompose the
caption based on the textual target modification for subsequent retrieval via
e.g. CLIP, we achieve modular language reasoning. In four ZS-CIR benchmarks, we
find competitive, in-part state-of-the-art performance - improving over
supervised methods. Moreover, the modularity of CIReVL offers simple
scalability without re-training, allowing us to both investigate scaling laws
and bottlenecks for ZS-CIR while easily scaling up to in parts more than double
of previously reported results. Finally, we show that CIReVL makes CIR
human-understandable by composing image and text in a modular fashion in the
language domain, thereby making it intervenable, allowing to post-hoc re-align
failure cases. Code will be released upon acceptance.
</p></li>
</ul>

<h3>Title: Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System. (arXiv:2310.08877v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08877">http://arxiv.org/abs/2310.08877</a></li>
<li>Code URL: https://github.com/shenwzh3/mk-tod</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08877]] Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System(http://arxiv.org/abs/2310.08877)</code></li>
<li>Summary: <p>Developing an efficient retriever to retrieve knowledge from a large-scale
knowledge base (KB) is critical for task-oriented dialogue systems to
effectively handle localized and specialized tasks. However, widely used
generative models such as T5 and ChatGPT often struggle to differentiate subtle
differences among the retrieved KB records when generating responses, resulting
in suboptimal quality of generated responses. In this paper, we propose the
application of maximal marginal likelihood to train a perceptive retriever by
utilizing signals from response generation for supervision. In addition, our
approach goes beyond considering solely retrieved entities and incorporates
various meta knowledge to guide the generator, thus improving the utilization
of knowledge. We evaluate our approach on three task-oriented dialogue datasets
using T5 and ChatGPT as the backbone models. The results demonstrate that when
combined with meta knowledge, the response generator can effectively leverage
high-quality knowledge records from the retriever and enhance the quality of
generated responses. The codes and models of this paper are available at
https://github.com/shenwzh3/MK-TOD.
</p></li>
</ul>

<h3>Title: Optimal Sample Complexity for Average Reward Markov Decision Processes. (arXiv:2310.08833v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08833">http://arxiv.org/abs/2310.08833</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08833]] Optimal Sample Complexity for Average Reward Markov Decision Processes(http://arxiv.org/abs/2310.08833)</code></li>
<li>Summary: <p>We settle the sample complexity of policy learning for the maximization of
the long run average reward associated with a uniformly ergodic Markov decision
process (MDP), assuming a generative model. In this context, the existing
literature provides a sample complexity upper bound of $\widetilde
O(|S||A|t_{\text{mix}}^2 \epsilon^{-2})$ and a lower bound of
$\Omega(|S||A|t_{\text{mix}} \epsilon^{-2})$. In these expressions, $|S|$ and
$|A|$ denote the cardinalities of the state and action spaces respectively,
$t_{\text{mix}}$ serves as a uniform upper limit for the total variation mixing
times, and $\epsilon$ signifies the error tolerance. Therefore, a notable gap
of $t_{\text{mix}}$ still remains to be bridged. Our primary contribution is to
establish an estimator for the optimal policy of average reward MDPs with a
sample complexity of $\widetilde O(|S||A|t_{\text{mix}}\epsilon^{-2})$,
effectively reaching the lower bound in the literature. This is achieved by
combining algorithmic ideas in Jin and Sidford (2021) with those of Li et al.
(2020).
</p></li>
</ul>

<h3>Title: Towards End-to-end 4-Bit Inference on Generative Large Language Models. (arXiv:2310.09259v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09259">http://arxiv.org/abs/2310.09259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09259]] Towards End-to-end 4-Bit Inference on Generative Large Language Models(http://arxiv.org/abs/2310.09259)</code></li>
<li>Summary: <p>We show that the majority of the inference computations for large generative
models such as LLaMA and OPT can be performed with both weights and activations
being cast to 4 bits, in a way that leads to practical speedups while at the
same time maintaining good accuracy. We achieve this via a hybrid quantization
strategy called QUIK, which compresses most of the weights and activations to
4-bit, while keeping some outlier weights and activations in higher-precision.
Crucially, our scheme is designed with computational efficiency in mind: we
provide GPU kernels with highly-efficient layer-wise runtimes, which lead to
practical end-to-end throughput improvements of up to 3.1x relative to FP16
execution. Code and models are provided at https://github.com/IST-DASLab/QUIK.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Multimodal Large Language Model for Visual Navigation. (arXiv:2310.08669v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08669">http://arxiv.org/abs/2310.08669</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08669]] Multimodal Large Language Model for Visual Navigation(http://arxiv.org/abs/2310.08669)</code></li>
<li>Summary: <p>Recent efforts to enable visual navigation using large language models have
mainly focused on developing complex prompt systems. These systems incorporate
instructions, observations, and history into massive text prompts, which are
then combined with pre-trained large language models to facilitate visual
navigation. In contrast, our approach aims to fine-tune large language models
for visual navigation without extensive prompt engineering. Our design involves
a simple text prompt, current observations, and a history collector model that
gathers information from previous observations as input. For output, our design
provides a probability distribution of possible actions that the agent can take
during navigation. We train our model using human demonstrations and collision
signals from the Habitat-Matterport 3D Dataset (HM3D). Experimental results
demonstrate that our method outperforms state-of-the-art behavior cloning
methods and effectively reduces collision rates.
</p></li>
</ul>

<h3>Title: From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models. (arXiv:2310.08825v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08825">http://arxiv.org/abs/2310.08825</a></li>
<li>Code URL: https://github.com/yuchenliu98/comm</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08825]] From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models(http://arxiv.org/abs/2310.08825)</code></li>
<li>Summary: <p>Multi-modal Large Language Models (MLLMs) have made significant strides in
expanding the capabilities of Large Language Models (LLMs) through the
incorporation of visual perception interfaces. Despite the emergence of
exciting applications and the availability of diverse instruction tuning data,
existing approaches often rely on CLIP or its variants as the visual branch,
and merely extract features from the deep layers. However, these methods lack a
comprehensive analysis of the visual encoders in MLLMs. In this paper, we
conduct an extensive investigation into the effectiveness of different vision
encoders within MLLMs. Our findings reveal that the shallow layer features of
CLIP offer particular advantages for fine-grained tasks such as grounding and
region understanding. Surprisingly, the vision-only model DINO, which is not
pretrained with text-image alignment, demonstrates promising performance as a
visual branch within MLLMs. By simply equipping it with an MLP layer for
alignment, DINO surpasses CLIP in fine-grained related perception tasks.
Building upon these observations, we propose a simple yet effective feature
merging strategy, named COMM, that integrates CLIP and DINO with Multi-level
features Merging, to enhance the visual capabilities of MLLMs. We evaluate COMM
through comprehensive experiments on a wide range of benchmarks, including
image captioning, visual question answering, visual grounding, and object
hallucination. Experimental results demonstrate the superior performance of
COMM compared to existing methods, showcasing its enhanced visual capabilities
within MLLMs. Code will be made available at
https://github.com/YuchenLiu98/COMM.
</p></li>
</ul>

<h3>Title: LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08659">http://arxiv.org/abs/2310.08659</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08659]] LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models(http://arxiv.org/abs/2310.08659)</code></li>
<li>Summary: <p>Quantization is an indispensable technique for serving Large Language Models
(LLMs) and has recently found its way into LoRA fine-tuning. In this work we
focus on the scenario where quantization and LoRA fine-tuning are applied
together on a pre-trained model. In such cases it is common to observe a
consistent gap in the performance on downstream tasks between full fine-tuning
and quantization plus LoRA fine-tuning approach. In response, we propose LoftQ
(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that
simultaneously quantizes an LLM and finds a proper low-rank initialization for
LoRA fine-tuning. Such an initialization alleviates the discrepancy between the
quantized and full-precision model and significantly improves the
generalization in downstream tasks. We evaluate our method on natural language
understanding, question answering, summarization, and natural language
generation tasks. Experiments show that our method is highly effective and
outperforms existing quantization methods, especially in the challenging 2-bit
and 2/4-bit mixed precision regimes. We will release our code.
</p></li>
</ul>

<h3>Title: Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams. (arXiv:2310.08678v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08678">http://arxiv.org/abs/2310.08678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08678]] Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams(http://arxiv.org/abs/2310.08678)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated remarkable performance on a
wide range of Natural Language Processing (NLP) tasks, often matching or even
beating state-of-the-art task-specific models. This study aims at assessing the
financial reasoning capabilities of LLMs. We leverage mock exam questions of
the Chartered Financial Analyst (CFA) Program to conduct a comprehensive
evaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot
(ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an
in-depth analysis of the models' performance and limitations, and estimate
whether they would have a chance at passing the CFA exams. Finally, we outline
insights into potential strategies and improvements to enhance the
applicability of LLMs in finance. In this perspective, we hope this work paves
the way for future studies to continue enhancing LLMs for financial reasoning
through rigorous evaluation.
</p></li>
</ul>

<h3>Title: A Zero-Shot Language Agent for Computer Control with Structured Reflection. (arXiv:2310.08740v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08740">http://arxiv.org/abs/2310.08740</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08740]] A Zero-Shot Language Agent for Computer Control with Structured Reflection(http://arxiv.org/abs/2310.08740)</code></li>
<li>Summary: <p>Large language models (LLMs) have shown increasing capacity at planning and
executing a high-level goal in a live computer environment (e.g. MiniWoB++). To
perform a task, recent works often require a model to learn from trace examples
of the task via either supervised learning or few/many-shot prompting. Without
these trace examples, it remains a challenge how an agent can autonomously
learn and improve its control on a computer, which limits the ability of an
agent to perform a new task. We approach this problem with a zero-shot agent
that requires no given expert traces. Our agent plans for executable actions on
a partially observed environment, and iteratively progresses a task by
identifying and learning from its mistakes via self-reflection and structured
thought management. On the easy tasks of MiniWoB++, we show that our zero-shot
agent often outperforms recent SoTAs, with more efficient reasoning. For tasks
with more complexity, our reflective agent performs on par with prior best
models, even though previous works had the advantages of accessing expert
traces or additional screen information.
</p></li>
</ul>

<h3>Title: "Im not Racist but...": Discovering Bias in the Internal Knowledge of Large Language Models. (arXiv:2310.08780v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08780">http://arxiv.org/abs/2310.08780</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08780]] "Im not Racist but(http://arxiv.org/abs/2310.08780)</code></li>
<li>Summary: <p>Large language models (LLMs) have garnered significant attention for their
remarkable performance in a continuously expanding set of natural language
processing tasks. However, these models have been shown to harbor inherent
societal biases, or stereotypes, which can adversely affect their performance
in their many downstream applications. In this paper, we introduce a novel,
purely prompt-based approach to uncover hidden stereotypes within any arbitrary
LLM. Our approach dynamically generates a knowledge representation of internal
stereotypes, enabling the identification of biases encoded within the LLM's
internal knowledge. By illuminating the biases present in LLMs and offering a
systematic methodology for their analysis, our work contributes to advancing
transparency and promoting fairness in natural language processing systems.
</p></li>
</ul>

<h3>Title: Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue. (arXiv:2310.08840v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08840">http://arxiv.org/abs/2310.08840</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08840]] Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue(http://arxiv.org/abs/2310.08840)</code></li>
<li>Summary: <p>Open-domain dialogue system usually requires different sources of knowledge
to generate more informative and evidential responses. However, existing
knowledge-grounded dialogue systems either focus on a single knowledge source
or overlook the dependency between multiple sources of knowledge, which may
result in generating inconsistent or even paradoxical responses. To incorporate
multiple knowledge sources and dependencies between them, we propose SAFARI, a
novel framework that leverages the exceptional capabilities of large language
models (LLMs) in planning, understanding, and incorporating under both
supervised and unsupervised settings. Specifically, SAFARI decouples the
knowledge grounding into multiple sources and response generation, which allows
easy extension to various knowledge sources including the possibility of not
using any sources. To study the problem, we construct a personalized
knowledge-grounded dialogue dataset \textit{\textbf{K}nowledge \textbf{B}ehind
\textbf{P}ersona}~(\textbf{KBP}), which is the first to consider the dependency
between persona and implicit knowledge. Experimental results on the KBP dataset
demonstrate that the SAFARI framework can effectively produce
persona-consistent and knowledge-enhanced responses.
</p></li>
</ul>

<h3>Title: InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems. (arXiv:2310.08885v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08885">http://arxiv.org/abs/2310.08885</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08885]] InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems(http://arxiv.org/abs/2310.08885)</code></li>
<li>Summary: <p>Large language models (LLMs) have been used for diverse tasks in natural
language processing (NLP), yet remain under-explored for task-oriented dialogue
systems (TODS), especially for end-to-end TODS. We present InstructTODS, a
novel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue
systems that can adapt to diverse domains without fine-tuning. By leveraging
LLMs, InstructTODS generates a proxy belief state that seamlessly translates
user intentions into dynamic queries for efficient interaction with any KB. Our
extensive experiments demonstrate that InstructTODS achieves comparable
performance to fully fine-tuned TODS in guiding dialogues to successful
completion without prior knowledge or task-specific data. Furthermore, a
rigorous human evaluation of end-to-end TODS shows that InstructTODS produces
dialogue responses that notably outperform both the gold responses and the
state-of-the-art TODS in terms of helpfulness, informativeness, and humanness.
Moreover, the effectiveness of LLMs in TODS is further supported by our
comprehensive evaluations on TODS subtasks: dialogue state tracking, intent
classification, and response generation. Code and implementations could be
found here https://github.com/WillyHC22/InstructTODS/
</p></li>
</ul>

<h3>Title: SeqXGPT: Sentence-Level AI-Generated Text Detection. (arXiv:2310.08903v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08903">http://arxiv.org/abs/2310.08903</a></li>
<li>Code URL: https://github.com/jihuai-wpy/seqxgpt</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08903]] SeqXGPT: Sentence-Level AI-Generated Text Detection(http://arxiv.org/abs/2310.08903)</code></li>
<li>Summary: <p>Widely applied large language models (LLMs) can generate human-like content,
raising concerns about the abuse of LLMs. Therefore, it is important to build
strong AI-generated text (AIGT) detectors. Current works only consider
document-level AIGT detection, therefore, in this paper, we first introduce a
sentence-level detection challenge by synthesizing a dataset that contains
documents that are polished with LLMs, that is, the documents contain sentences
written by humans and sentences modified by LLMs. Then we propose
\textbf{Seq}uence \textbf{X} (Check) \textbf{GPT}, a novel method that utilizes
log probability lists from white-box LLMs as features for sentence-level AIGT
detection. These features are composed like \textit{waves} in speech processing
and cannot be studied by LLMs. Therefore, we build SeqXGPT based on convolution
and self-attention networks. We test it in both sentence and document-level
detection challenges. Experimental results show that previous methods struggle
in solving sentence-level AIGT detection, while our method not only
significantly surpasses baseline methods in both sentence and document-level
detection challenges but also exhibits strong generalization capabilities.
</p></li>
</ul>

<h3>Title: Human-in-the-loop Machine Translation with Large Language Model. (arXiv:2310.08908v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08908">http://arxiv.org/abs/2310.08908</a></li>
<li>Code URL: https://github.com/nlp2ct/hil-mt</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08908]] Human-in-the-loop Machine Translation with Large Language Model(http://arxiv.org/abs/2310.08908)</code></li>
<li>Summary: <p>The large language model (LLM) has garnered significant attention due to its
in-context learning mechanisms and emergent capabilities. The research
community has conducted several pilot studies to apply LLMs to machine
translation tasks and evaluate their performance from diverse perspectives.
However, previous research has primarily focused on the LLM itself and has not
explored human intervention in the inference process of LLM. The
characteristics of LLM, such as in-context learning and prompt engineering,
closely mirror human cognitive abilities in language tasks, offering an
intuitive solution for human-in-the-loop generation. In this study, we propose
a human-in-the-loop pipeline that guides LLMs to produce customized outputs
with revision instructions. The pipeline initiates by prompting the LLM to
produce a draft translation, followed by the utilization of automatic retrieval
or human feedback as supervision signals to enhance the LLM's translation
through in-context learning. The human-machine interactions generated in this
pipeline are also stored in an external database to expand the in-context
retrieval database, enabling us to leverage human supervision in an offline
setting. We evaluate the proposed pipeline using GPT-3.5-turbo API on five
domain-specific benchmarks for German-English translation. The results
demonstrate the effectiveness of the pipeline in tailoring in-domain
translations and improving translation performance compared to direct
translation. Additionally, we discuss the results from the following
perspectives: 1) the effectiveness of different in-context retrieval methods;
2) the construction of a retrieval database under low-resource scenarios; 3)
the observed domains differences; 4) the quantitative analysis of linguistic
statistics; and 5) the qualitative analysis of translation cases. The code and
data are available at https://github.com/NLP2CT/HIL-MT/.
</p></li>
</ul>

<h3>Title: xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark. (arXiv:2310.08958v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08958">http://arxiv.org/abs/2310.08958</a></li>
<li>Code URL: https://github.com/e0397123/xdial-eval</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08958]] xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark(http://arxiv.org/abs/2310.08958)</code></li>
<li>Summary: <p>Recent advancements in reference-free learned metrics for open-domain
dialogue evaluation have been driven by the progress in pre-trained language
models and the availability of dialogue data with high-quality human
annotations. However, current studies predominantly concentrate on English
dialogues, and the generalization of these metrics to other languages has not
been fully examined. This is largely due to the absence of a multilingual
dialogue evaluation benchmark. To address the issue, we introduce xDial-Eval,
built on top of open-source English dialogue evaluation datasets. xDial-Eval
includes 12 turn-level and 6 dialogue-level English datasets, comprising 14930
annotated turns and 8691 annotated dialogues respectively. The English dialogue
data are extended to nine other languages with commercial machine translation
systems. On xDial-Eval, we conduct comprehensive analyses of previous
BERT-based metrics and the recently-emerged large language models. Lastly, we
establish strong self-supervised and multilingual baselines. In terms of
average Pearson correlations over all datasets and languages, the best baseline
outperforms OpenAI's ChatGPT by absolute improvements of 6.5% and 4.6% at the
turn and dialogue levels respectively, albeit with much fewer parameters. The
data and code are publicly available at https://github.com/e0397123/xDial-Eval.
</p></li>
</ul>

<h3>Title: ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models. (arXiv:2310.08975v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08975">http://arxiv.org/abs/2310.08975</a></li>
<li>Code URL: https://github.com/lhrlab/chatkbqa</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08975]] ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models(http://arxiv.org/abs/2310.08975)</code></li>
<li>Summary: <p>Knowledge Base Question Answering (KBQA) aims to derive answers to natural
language questions over large-scale knowledge bases (KBs), which are generally
divided into two research components: knowledge retrieval and semantic parsing.
However, three core challenges remain, including inefficient knowledge
retrieval, retrieval errors adversely affecting semantic parsing, and the
complexity of previous KBQA methods. In the era of large language models
(LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework
built on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2.
ChatKBQA proposes generating the logical form with fine-tuned LLMs first, then
retrieving and replacing entities and relations through an unsupervised
retrieval method, which improves both generation and retrieval more
straightforwardly. Experimental results reveal that ChatKBQA achieves new
state-of-the-art performance on standard KBQA datasets, WebQSP, and
ComplexWebQuestions (CWQ). This work also provides a new paradigm for combining
LLMs with knowledge graphs (KGs) for interpretable and knowledge-required
question answering. Our code is publicly available.
</p></li>
</ul>

<h3>Title: MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks. (arXiv:2310.09036v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09036">http://arxiv.org/abs/2310.09036</a></li>
<li>Code URL: https://github.com/declare-lab/mm-bigbench</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09036]] MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks(http://arxiv.org/abs/2310.09036)</code></li>
<li>Summary: <p>The popularity of multimodal large language models (MLLMs) has triggered a
recent surge in research efforts dedicated to evaluating these models.
Nevertheless, existing evaluation studies of MLLMs primarily focus on the
comprehension and reasoning of unimodal (vision) content, neglecting
performance evaluations in the domain of multimodal (vision-language) content
understanding. Beyond multimodal reasoning, tasks related to multimodal content
comprehension necessitate a profound understanding of multimodal contexts,
achieved through the multimodal interaction to obtain a final answer. In this
paper, we introduce a comprehensive assessment framework called MM-BigBench,
which incorporates a diverse range of metrics to offer an extensive evaluation
of the performance of various models and instructions across a wide spectrum of
diverse multimodal content comprehension tasks. Consequently, our work
complements research on the performance of MLLMs in multimodal comprehension
tasks, achieving a more comprehensive and holistic evaluation of MLLMs. To
begin, we employ the Best Performance metric to ascertain each model's
performance upper bound on different datasets. Subsequently, the Mean Relative
Gain metric offers an assessment of the overall performance of various models
and instructions, while the Stability metric measures their sensitivity.
Furthermore, previous research centers on evaluating models independently or
solely assessing instructions, neglecting the adaptability between models and
instructions. We propose the Adaptability metric to quantify the adaptability
between models and instructions. Our paper evaluates a total of 20 language
models (14 MLLMs) on 14 multimodal datasets spanning 6 tasks, with 10
instructions for each task, and derives novel insights. Our code will be
released at https://github.com/declare-lab/MM-BigBench.
</p></li>
</ul>

<h3>Title: KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection. (arXiv:2310.09044v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09044">http://arxiv.org/abs/2310.09044</a></li>
<li>Code URL: https://github.com/hkust-knowcomp/knowledge-constrained-decoding</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09044]] KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection(http://arxiv.org/abs/2310.09044)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated remarkable human-level natural
language generation capabilities. However, their potential to generate
misinformation, often called the hallucination problem, poses a significant
risk to their deployment. A common approach to address this issue is to
retrieve relevant knowledge and fine-tune the LLM with the knowledge in its
input. Unfortunately, this method incurs high training costs and may cause
catastrophic forgetting for multi-tasking models. To overcome these
limitations, we propose a knowledge-constrained decoding method called KCTS
(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text
aligned with the reference knowledge at each decoding step using a knowledge
classifier score and MCTS (Monte-Carlo Tree Search). To adapt the
sequence-level knowledge classifier to token-level guidance, we also propose a
novel token-level hallucination detection method called RIPA (Reward Inflection
Point Approximation). Our empirical results on knowledge-grounded dialogue and
abstractive summarization demonstrate the strength of KCTS as a plug-and-play,
model-agnostic decoding method that can effectively reduce hallucinations in
natural language generation.
</p></li>
</ul>

<h3>Title: Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model. (arXiv:2310.09089v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09089">http://arxiv.org/abs/2310.09089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09089]] Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model(http://arxiv.org/abs/2310.09089)</code></li>
<li>Summary: <p>Integrating large language models (LLMs) into healthcare presents potential
but faces challenges. Directly pre-training LLMs for domains like medicine is
resource-heavy and sometimes unfeasible. Sole reliance on Supervised
Fine-tuning (SFT) can result in overconfident predictions and may not tap into
domain specific insights. Addressing these challenges, we present a multi-stage
training method combining Domain-specific Continued Pre-training (DCPT), SFT,
and Direct Preference Optimization (DPO). A notable contribution of our study
is the introduction of a 3Gb Chinese Medicine (ChiMed) dataset, encompassing
medical question answering, plain texts, knowledge graphs, and dialogues,
segmented into three training stages. The medical LLM trained with our
pipeline, Qilin-Med, exhibits significant performance boosts. In the CPT and
SFT phases, it achieves 38.4% and 40.0% accuracy on the CMExam, surpassing
Baichuan-7B's 33.5%. In the DPO phase, on the Huatuo-26M test set, it scores
16.66 in BLEU-1 and 27.44 in ROUGE1, outperforming the SFT's 12.69 and 24.21.
This highlights the strength of our training approach in refining LLMs for
medical applications.
</p></li>
</ul>

<h3>Title: GLoRE: Evaluating Logical Reasoning of Large Language Models. (arXiv:2310.09107v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09107">http://arxiv.org/abs/2310.09107</a></li>
<li>Code URL: https://github.com/csitfun/glore</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09107]] GLoRE: Evaluating Logical Reasoning of Large Language Models(http://arxiv.org/abs/2310.09107)</code></li>
<li>Summary: <p>Recently, large language models (LLMs), including notable models such as
GPT-4 and burgeoning community models, have showcased significant general
language understanding abilities. However, there has been a scarcity of
attempts to assess the logical reasoning capacities of these LLMs, an essential
facet of natural language understanding. To encourage further investigation in
this area, we introduce GLoRE, a meticulously assembled General Logical
Reasoning Evaluation benchmark comprised of 12 datasets that span three
different types of tasks. Our experimental results show that compared to the
performance of human and supervised fine-tuning, the logical reasoning
capabilities of open LLM models necessitate additional improvement; ChatGPT and
GPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing
ChatGPT by a large margin. We propose a self-consistency probing method to
enhance the accuracy of ChatGPT and a fine-tuned method to boost the
performance of an open LLM. We release the datasets and evaluation programs to
facilitate future research.
</p></li>
</ul>

<h3>Title: Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation. (arXiv:2310.09223v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09223">http://arxiv.org/abs/2310.09223</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09223]] Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation(http://arxiv.org/abs/2310.09223)</code></li>
<li>Summary: <p>In today's digital era, the rapid spread of misinformation poses threats to
public well-being and societal trust. As online misinformation proliferates,
manual verification by fact checkers becomes increasingly challenging. We
introduce FACT-GPT (Fact-checking Augmentation with Claim matching
Task-oriented Generative Pre-trained Transformer), a framework designed to
automate the claim matching phase of fact-checking using Large Language Models
(LLMs). This framework identifies new social media content that either supports
or contradicts claims previously debunked by fact-checkers. Our approach
employs GPT-4 to generate a labeled dataset consisting of simulated social
media posts. This data set serves as a training ground for fine-tuning more
specialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media
content related to public health. The results indicate that our fine-tuned LLMs
rival the performance of larger pre-trained LLMs in claim matching tasks,
aligning closely with human annotations. This study achieves three key
milestones: it provides an automated framework for enhanced fact-checking;
demonstrates the potential of LLMs to complement human expertise; offers public
resources, including datasets and models, to further research and applications
in the fact-checking domain.
</p></li>
</ul>

<h3>Title: Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration. (arXiv:2310.09241v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09241">http://arxiv.org/abs/2310.09241</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09241]] Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration(http://arxiv.org/abs/2310.09241)</code></li>
<li>Summary: <p>Legal Judgment Prediction (LJP) has become an increasingly crucial task in
Legal AI, i.e., predicting the judgment of the case in terms of case fact
description. Precedents are the previous legal cases with similar facts, which
are the basis for the judgment of the subsequent case in national legal
systems. Thus, it is worthwhile to explore the utilization of precedents in the
LJP. Recent advances in deep learning have enabled a variety of techniques to
be used to solve the LJP task. These can be broken down into two categories:
large language models (LLMs) and domain-specific models. LLMs are capable of
interpreting and generating complex natural language, while domain models are
efficient in learning task-specific information. In this paper, we propose the
precedent-enhanced LJP framework (PLJP), a system that leverages the strength
of both LLM and domain models in the context of precedents. Specifically, the
domain models are designed to provide candidate labels and find the proper
precedents efficiently, and the large models will make the final prediction
with an in-context precedents comprehension. Experiments on the real-world
dataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a
promising direction for LLM and domain-model collaboration that can be
generalized to other vertical domains.
</p></li>
</ul>

<h3>Title: In-Context Learning for Few-Shot Molecular Property Prediction. (arXiv:2310.08863v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08863">http://arxiv.org/abs/2310.08863</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08863]] In-Context Learning for Few-Shot Molecular Property Prediction(http://arxiv.org/abs/2310.08863)</code></li>
<li>Summary: <p>In-context learning has become an important approach for few-shot learning in
Large Language Models because of its ability to rapidly adapt to new tasks
without fine-tuning model parameters. However, it is restricted to applications
in natural language and inapplicable to other domains. In this paper, we adapt
the concepts underpinning in-context learning to develop a new algorithm for
few-shot molecular property prediction. Our approach learns to predict
molecular properties from a context of (molecule, property measurement) pairs
and rapidly adapts to new properties without fine-tuning. On the FS-Mol and
BACE molecular property prediction benchmarks, we find this method surpasses
the performance of recent meta-learning algorithms at small support sizes and
is competitive with the best methods at large support sizes.
</p></li>
</ul>

<h3>Title: LLaMA Rider: Spurring Large Language Models to Explore the Open World. (arXiv:2310.08922v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08922">http://arxiv.org/abs/2310.08922</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08922]] LLaMA Rider: Spurring Large Language Models to Explore the Open World(http://arxiv.org/abs/2310.08922)</code></li>
<li>Summary: <p>Recently, various studies have leveraged Large Language Models (LLMs) to help
decision-making and planning in environments, and try to align the LLMs'
knowledge with the world conditions. Nonetheless, the capacity of LLMs to
continuously acquire environmental knowledge and adapt in an open world remains
uncertain. In this paper, we propose an approach to spur LLMs to explore the
open world, gather experiences, and learn to improve their task-solving
capabilities. In this approach, a multi-round feedback-revision mechanism is
utilized to encourage LLMs to actively select appropriate revision actions
guided by feedback information from the environment. This facilitates
exploration and enhances the model's performance. Besides, we integrate
sub-task relabeling to assist LLMs in maintaining consistency in sub-task
planning and help the model learn the combinatorial nature between tasks,
enabling it to complete a wider range of tasks through training based on the
acquired exploration experiences. By evaluation in Minecraft, an open-ended
sandbox world, we demonstrate that our approach LLaMA-Rider enhances the
efficiency of the LLM in exploring the environment, and effectively improves
the LLM's ability to accomplish more tasks through fine-tuning with merely 1.3k
instances of collected data, showing minimal training costs compared to the
baseline using reinforcement learning.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: SSG2: A new modelling paradigm for semantic segmentation. (arXiv:2310.08671v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08671">http://arxiv.org/abs/2310.08671</a></li>
<li>Code URL: https://github.com/feevos/ssg2</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08671]] SSG2: A new modelling paradigm for semantic segmentation(http://arxiv.org/abs/2310.08671)</code></li>
<li>Summary: <p>State-of-the-art models in semantic segmentation primarily operate on single,
static images, generating corresponding segmentation masks. This one-shot
approach leaves little room for error correction, as the models lack the
capability to integrate multiple observations for enhanced accuracy. Inspired
by work on semantic change detection, we address this limitation by introducing
a methodology that leverages a sequence of observables generated for each
static input image. By adding this "temporal" dimension, we exploit strong
signal correlations between successive observations in the sequence to reduce
error rates. Our framework, dubbed SSG2 (Semantic Segmentation Generation 2),
employs a dual-encoder, single-decoder base network augmented with a sequence
model. The base model learns to predict the set intersection, union, and
difference of labels from dual-input images. Given a fixed target input image
and a set of support images, the sequence model builds the predicted mask of
the target by synthesizing the partial views from each sequence step and
filtering out noise. We evaluate SSG2 across three diverse datasets:
UrbanMonitor, featuring orthoimage tiles from Darwin, Australia with five
spectral bands and 0.2m spatial resolution; ISPRS Potsdam, which includes true
orthophoto images with multiple spectral bands and a 5cm ground sampling
distance; and ISIC2018, a medical dataset focused on skin lesion segmentation,
particularly melanoma. The SSG2 model demonstrates rapid convergence within the
first few tens of epochs and significantly outperforms UNet-like baseline
models with the same number of gradient updates. However, the addition of the
temporal dimension results in an increased memory footprint. While this could
be a limitation, it is offset by the advent of higher-memory GPUs and coding
optimizations.
</p></li>
</ul>

<h3>Title: SAM-guided Unsupervised Domain Adaptation for 3D Segmentation. (arXiv:2310.08820v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08820">http://arxiv.org/abs/2310.08820</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08820]] SAM-guided Unsupervised Domain Adaptation for 3D Segmentation(http://arxiv.org/abs/2310.08820)</code></li>
<li>Summary: <p>Unsupervised domain adaptation (UDA) in 3D segmentation tasks presents a
formidable challenge, primarily stemming from the sparse and unordered nature
of point cloud data. Especially for LiDAR point clouds, the domain discrepancy
becomes obvious across varying capture scenes, fluctuating weather conditions,
and the diverse array of LiDAR devices in use. While previous UDA methodologies
have often sought to mitigate this gap by aligning features between source and
target domains, this approach falls short when applied to 3D segmentation due
to the substantial domain variations. Inspired by the remarkable generalization
capabilities exhibited by the vision foundation model, SAM, in the realm of
image segmentation, our approach leverages the wealth of general knowledge
embedded within SAM to unify feature representations across diverse 3D domains
and further solves the 3D domain adaptation problem. Specifically, we harness
the corresponding images associated with point clouds to facilitate knowledge
transfer and propose an innovative hybrid feature augmentation methodology,
which significantly enhances the alignment between the 3D feature space and
SAM's feature space, operating at both the scene and instance levels. Our
method is evaluated on many widely-recognized datasets and achieves
state-of-the-art performance.
</p></li>
</ul>

<h3>Title: Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous Driving. (arXiv:2310.08826v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08826">http://arxiv.org/abs/2310.08826</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08826]] Revisiting Multi-modal 3D Semantic Segmentation in Real-world Autonomous Driving(http://arxiv.org/abs/2310.08826)</code></li>
<li>Summary: <p>LiDAR and camera are two critical sensors for multi-modal 3D semantic
segmentation and are supposed to be fused efficiently and robustly to promise
safety in various real-world scenarios. However, existing multi-modal methods
face two key challenges: 1) difficulty with efficient deployment and real-time
execution; and 2) drastic performance degradation under weak calibration
between LiDAR and cameras. To address these challenges, we propose CPGNet-LCF,
a new multi-modal fusion framework extending the LiDAR-only CPGNet. CPGNet-LCF
solves the first challenge by inheriting the easy deployment and real-time
capabilities of CPGNet. For the second challenge, we introduce a novel weak
calibration knowledge distillation strategy during training to improve the
robustness against the weak calibration. CPGNet-LCF achieves state-of-the-art
performance on the nuScenes and SemanticKITTI benchmarks. Remarkably, it can be
easily deployed to run in 20ms per frame on a single Tesla V100 GPU using
TensorRT TF16 mode. Furthermore, we benchmark performance over four weak
calibration levels, demonstrating the robustness of our proposed approach.
</p></li>
</ul>

<h3>Title: Re-initialization-free Level Set Method via Molecular Beam Epitaxy Equation Regularization for Image Segmentation. (arXiv:2310.08861v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08861">http://arxiv.org/abs/2310.08861</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08861]] Re-initialization-free Level Set Method via Molecular Beam Epitaxy Equation Regularization for Image Segmentation(http://arxiv.org/abs/2310.08861)</code></li>
<li>Summary: <p>Variational level set method has become a powerful tool in image segmentation
due to its ability to handle complex topological changes and maintain
continuity and smoothness in the process of evolution. However its evolution
process can be unstable, which results in over flatted or over sharpened
contours and segmentation failure. To improve the accuracy and stability of
evolution, we propose a high-order level set variational segmentation method
integrated with molecular beam epitaxy (MBE) equation regularization. This
method uses the crystal growth in the MBE process to limit the evolution of the
level set function, and thus can avoid the re-initialization in the evolution
process and regulate the smoothness of the segmented curve. It also works for
noisy images with intensity inhomogeneity, which is a challenge in image
segmentation. To solve the variational model, we derive the gradient flow and
design scalar auxiliary variable (SAV) scheme coupled with fast Fourier
transform (FFT), which can significantly improve the computational efficiency
compared with the traditional semi-implicit and semi-explicit scheme. Numerical
experiments show that the proposed method can generate smooth segmentation
curves, retain fine segmentation targets and obtain robust segmentation results
of small objects. Compared to existing level set methods, this model is
state-of-the-art in both accuracy and efficiency.
</p></li>
</ul>

<h3>Title: UniParser: Multi-Human Parsing with Unified Correlation Representation Learning. (arXiv:2310.08984v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08984">http://arxiv.org/abs/2310.08984</a></li>
<li>Code URL: https://github.com/cjm-sfw/Uniparser</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08984]] UniParser: Multi-Human Parsing with Unified Correlation Representation Learning(http://arxiv.org/abs/2310.08984)</code></li>
<li>Summary: <p>Multi-human parsing is an image segmentation task necessitating both
instance-level and fine-grained category-level information. However, prior
research has typically processed these two types of information through
separate branches and distinct output formats, leading to inefficient and
redundant frameworks. This paper introduces UniParser, which integrates
instance-level and category-level representations in three key aspects: 1) we
propose a unified correlation representation learning approach, allowing our
network to learn instance and category features within the cosine space; 2) we
unify the form of outputs of each modules as pixel-level segmentation results
while supervising instance and category features using a homogeneous label
accompanied by an auxiliary loss; and 3) we design a joint optimization
procedure to fuse instance and category representations. By virtual of unifying
instance-level and category-level output, UniParser circumvents manually
designed post-processing techniques and surpasses state-of-the-art methods,
achieving 49.3% AP on MHPv2.0 and 60.4% AP on CIHP. We will release our source
code, pretrained models, and online demos to facilitate future studies.
</p></li>
</ul>

<h3>Title: Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport. (arXiv:2310.09114v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09114">http://arxiv.org/abs/2310.09114</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09114]] Timestamp-supervised Wearable-based Activity Segmentation and Recognition with Contrastive Learning and Order-Preserving Optimal Transport(http://arxiv.org/abs/2310.09114)</code></li>
<li>Summary: <p>Human activity recognition (HAR) with wearables is one of the serviceable
technologies in ubiquitous and mobile computing applications. The
sliding-window scheme is widely adopted while suffering from the multi-class
windows problem. As a result, there is a growing focus on joint segmentation
and recognition with deep-learning methods, aiming at simultaneously dealing
with HAR and time-series segmentation issues. However, obtaining the full
activity annotations of wearable data sequences is resource-intensive or
time-consuming, while unsupervised methods yield poor performance. To address
these challenges, we propose a novel method for joint activity segmentation and
recognition with timestamp supervision, in which only a single annotated sample
is needed in each activity segment. However, the limited information of sparse
annotations exacerbates the gap between recognition and segmentation tasks,
leading to sub-optimal model performance. Therefore, the prototypes are
estimated by class-activation maps to form a sample-to-prototype contrast
module for well-structured embeddings. Moreover, with the optimal transport
theory, our approach generates the sample-level pseudo-labels that take
advantage of unlabeled data between timestamp annotations for further
performance improvement. Comprehensive experiments on four public HAR datasets
demonstrate that our model trained with timestamp supervision is superior to
the state-of-the-art weakly-supervised methods and achieves comparable
performance to the fully-supervised approaches.
</p></li>
</ul>

<h3>Title: Equirectangular image construction method for standard CNNs for Semantic Segmentation. (arXiv:2310.09122v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.09122">http://arxiv.org/abs/2310.09122</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.09122]] Equirectangular image construction method for standard CNNs for Semantic Segmentation(http://arxiv.org/abs/2310.09122)</code></li>
<li>Summary: <p>360{\deg} spherical images have advantages of wide view field, and are
typically projected on a planar plane for processing, which is known as
equirectangular image. The object shape in equirectangular images can be
distorted and lack translation invariance. In addition, there are few publicly
dataset of equirectangular images with labels, which presents a challenge for
standard CNNs models to process equirectangular images effectively. To tackle
this problem, we propose a methodology for converting a perspective image into
equirectangular image. The inverse transformation of the spherical center
projection and the equidistant cylindrical projection are employed. This
enables the standard CNNs to learn the distortion features at different
positions in the equirectangular image and thereby gain the ability to
semantically the equirectangular image. The parameter, {\phi}, which determines
the projection position of the perspective image, has been analyzed using
various datasets and models, such as UNet, UNet++, SegNet, PSPNet, and DeepLab
v3+. The experiments demonstrate that an optimal value of {\phi} for effective
semantic segmentation of equirectangular images is 6{\pi}/16 for standard CNNs.
Compared with the other three types of methods (supervised learning,
unsupervised learning and data augmentation), the method proposed in this paper
has the best average IoU value of 43.76%. This value is 23.85%, 10.7% and
17.23% higher than those of other three methods, respectively.
</p></li>
</ul>

<h3>Title: Virtual Augmented Reality for Atari Reinforcement Learning. (arXiv:2310.08683v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2310.08683">http://arxiv.org/abs/2310.08683</a></li>
<li>Code URL: https://github.com/c-a-schiller/var4arl</li>
<li>Copy Paste: <code><input type="checkbox">[[2310.08683]] Virtual Augmented Reality for Atari Reinforcement Learning(http://arxiv.org/abs/2310.08683)</code></li>
<li>Summary: <p>Reinforcement Learning (RL) has achieved significant milestones in the gaming
domain, most notably Google DeepMind's AlphaGo defeating human Go champion Ken
Jie. This victory was also made possible through the Atari Learning Environment
(ALE): The ALE has been foundational in RL research, facilitating significant
RL algorithm developments such as AlphaGo and others. In current Atari video
game RL research, RL agents' perceptions of its environment is based on raw
pixel data from the Atari video game screen with minimal image preprocessing.
Contrarily, cutting-edge ML research, external to the Atari video game RL
research domain, is focusing on enhancing image perception. A notable example
is Meta Research's "Segment Anything Model" (SAM), a foundation model capable
of segmenting images without prior training (zero-shot). This paper addresses a
novel methodical question: Can state-of-the-art image segmentation models such
as SAM improve the performance of RL agents playing Atari video games? The
results suggest that SAM can serve as a "virtual augmented reality" for the RL
agent, boosting its Atari video game playing performance under certain
conditions. Comparing RL agent performance results from raw and augmented pixel
inputs provides insight into these conditions. Although this paper was limited
by computational constraints, the findings show improved RL agent performance
for augmented pixel inputs and can inform broader research agendas in the
domain of "virtual augmented reality for video game playing RL agents".
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
