<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-08-12</h1>
<h3>Title: APE: Active Learning-based Tooling for Finding Informative Few-shot Examples for LLM-based Entity Matching</h3>
<ul>
<li><strong>Authors: </strong>Kun Qian, Yisi Sang, Farima Fatahi Bayat, Anton Belyi, Xianqi Chu, Yash Govind, Samira Khorshidi, Rahul Khot, Katherine Luna, Azadeh Nikfarjam, Xiaoguang Qi, Fei Wu, Xianhan Zhang, Yunyao Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04637">https://arxiv.org/abs/2408.04637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04637">https://arxiv.org/pdf/2408.04637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04637]] APE: Active Learning-based Tooling for Finding Informative Few-shot Examples for LLM-based Entity Matching(https://arxiv.org/abs/2408.04637)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompt engineering is an iterative procedure often requiring extensive manual effort to formulate suitable instructions for effectively directing large language models (LLMs) in specific tasks. Incorporating few-shot examples is a vital and effective approach to providing LLMs with precise instructions, leading to improved LLM performance. Nonetheless, identifying the most informative demonstrations for LLMs is labor-intensive, frequently entailing sifting through an extensive search space. In this demonstration, we showcase a human-in-the-loop tool called APE (Active Prompt Engineering) designed for refining prompts through active learning. Drawing inspiration from active learning, APE iteratively selects the most ambiguous examples for human feedback, which will be transformed into few-shot examples within the prompt. The demo recording can be found with the submission or be viewed at this https URL.</li>
</ul>

<h3>Title: Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective</h3>
<ul>
<li><strong>Authors: </strong>Yiqun Zhang, Xiaocui Yang, Xingle Xu, Zeran Gao, Yijie Huang, Shiyi Mu, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song, Ge Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04638">https://arxiv.org/abs/2408.04638</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04638">https://arxiv.org/pdf/2408.04638</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04638]] Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective(https://arxiv.org/abs/2408.04638)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Affective Computing (AC), integrating computer science, psychology, and cognitive science knowledge, aims to enable machines to recognize, interpret, and simulate human this http URL create more value, AC can be applied to diverse scenarios, including social media, finance, healthcare, education, etc. Affective Computing (AC) includes two mainstream tasks, i.e., Affective Understanding (AU) and Affective Generation (AG). Fine-tuning Pre-trained Language Models (PLMs) for AU tasks has succeeded considerably. However, these models lack generalization ability, requiring specialized models for specific tasks. Additionally, traditional PLMs face challenges in AG, particularly in generating diverse and emotionally rich responses. The emergence of Large Language Models (LLMs), such as the ChatGPT series and LLaMA models, brings new opportunities and challenges, catalyzing a paradigm shift in AC. LLMs possess capabilities of in-context learning, common sense reasoning, and advanced sequence generation, which present unprecedented opportunities for AU. To provide a comprehensive overview of AC in the LLMs era from an NLP perspective, we summarize the development of LLMs research in this field, aiming to offer new insights. Specifically, we first summarize the traditional tasks related to AC and introduce the preliminary study based on LLMs. Subsequently, we outline the relevant techniques of popular LLMs to improve AC tasks, including Instruction Tuning and Prompt Engineering. For Instruction Tuning, we discuss full parameter fine-tuning and parameter-efficient methods such as LoRA, P-Tuning, and Prompt Tuning. In Prompt Engineering, we examine Zero-shot, Few-shot, Chain of Thought (CoT), and Agent-based methods for AU and AG. To clearly understand the performance of LLMs on different Affective Computing tasks, we further summarize the existing benchmarks and evaluation methods.</li>
</ul>

<h3>Title: Abstractive summarization from Audio Transcription</h3>
<ul>
<li><strong>Authors: </strong>Ilia Derkach</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR, cs.LG, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04639">https://arxiv.org/abs/2408.04639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04639">https://arxiv.org/pdf/2408.04639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04639]] Abstractive summarization from Audio Transcription(https://arxiv.org/abs/2408.04639)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Currently, large language models are gaining popularity, their achievements are used in many areas, ranging from text translation to generating answers to queries. However, the main problem with these new machine learning algorithms is that training such models requires large computing resources that only large IT companies have. To avoid this problem, a number of methods (LoRA, quantization) have been proposed so that existing models can be effectively fine-tuned for specific tasks. In this paper, we propose an E2E (end to end) audio summarization model using these techniques. In addition, this paper examines the effectiveness of these approaches to the problem under consideration and draws conclusions about the applicability of these methods.</li>
</ul>

<h3>Title: LLMs for Enhanced Agricultural Meteorological Recommendations</h3>
<ul>
<li><strong>Authors: </strong>Ji-jun Park, Soo-joon Choi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04640">https://arxiv.org/abs/2408.04640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04640">https://arxiv.org/pdf/2408.04640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04640]] LLMs for Enhanced Agricultural Meteorological Recommendations(https://arxiv.org/abs/2408.04640)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Agricultural meteorological recommendations are crucial for enhancing crop productivity and sustainability by providing farmers with actionable insights based on weather forecasts, soil conditions, and crop-specific data. This paper presents a novel approach that leverages large language models (LLMs) and prompt engineering to improve the accuracy and relevance of these recommendations. We designed a multi-round prompt framework to iteratively refine recommendations using updated data and feedback, implemented on ChatGPT, Claude2, and GPT-4. Our method was evaluated against baseline models and a Chain-of-Thought (CoT) approach using manually collected datasets. The results demonstrate significant improvements in accuracy and contextual relevance, with our approach achieving up to 90\% accuracy and high GPT-4 scores. Additional validation through real-world pilot studies further confirmed the practical benefits of our method, highlighting its potential to transform agricultural practices and decision-making.</li>
</ul>

<h3>Title: GPT-3 Powered Information Extraction for Building Robust Knowledge Bases</h3>
<ul>
<li><strong>Authors: </strong>Ritabrata Roy Choudhury, Soumik Dey</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04641">https://arxiv.org/abs/2408.04641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04641">https://arxiv.org/pdf/2408.04641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04641]] GPT-3 Powered Information Extraction for Building Robust Knowledge Bases(https://arxiv.org/abs/2408.04641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>This work uses the state-of-the-art language model GPT-3 to offer a novel method of information extraction for knowledge base development. The suggested method attempts to solve the difficulties associated with obtaining relevant entities and relationships from unstructured text in order to extract structured information. We conduct experiments on a huge corpus of text from diverse fields to assess the performance of our suggested technique. The evaluation measures, which are frequently employed in information extraction tasks, include precision, recall, and F1-score. The findings demonstrate that GPT-3 can be used to efficiently and accurately extract pertinent and correct information from text, hence increasing the precision and productivity of knowledge base creation. We also assess how well our suggested approach performs in comparison to the most advanced information extraction techniques already in use. The findings show that by utilizing only a small number of instances in in-context learning, our suggested strategy yields competitive outcomes with notable savings in terms of data annotation and engineering expense. Additionally, we use our proposed method to retrieve Biomedical information, demonstrating its practicality in a real-world setting. All things considered, our suggested method offers a viable way to overcome the difficulties involved in obtaining structured data from unstructured text in order to create knowledge bases. It can greatly increase the precision and effectiveness of information extraction, which is necessary for many applications including chatbots, recommendation engines, and question-answering systems.</li>
</ul>

<h3>Title: Risks, Causes, and Mitigations of Widespread Deployments of Large Language Models (LLMs): A Survey</h3>
<ul>
<li><strong>Authors: </strong>Md Nazmus Sakib, Md Athikul Islam, Royal Pathak, Md Mashrur Arifin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04643">https://arxiv.org/abs/2408.04643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04643">https://arxiv.org/pdf/2408.04643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04643]] Risks, Causes, and Mitigations of Widespread Deployments of Large Language Models (LLMs): A Survey(https://arxiv.org/abs/2408.04643)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs), such as ChatGPT and LLaMA, have significantly transformed Natural Language Processing (NLP) with their outstanding abilities in text generation, summarization, and classification. Nevertheless, their widespread adoption introduces numerous challenges, including issues related to academic integrity, copyright, environmental impacts, and ethical considerations such as data bias, fairness, and privacy. The rapid evolution of LLMs also raises concerns regarding the reliability and generalizability of their evaluations. This paper offers a comprehensive survey of the literature on these subjects, systematically gathered and synthesized from Google Scholar. Our study provides an in-depth analysis of the risks associated with specific LLMs, identifying sub-risks, their causes, and potential solutions. Furthermore, we explore the broader challenges related to LLMs, detailing their causes and proposing mitigation strategies. Through this literature analysis, our survey aims to deepen the understanding of the implications and complexities surrounding these powerful models.</li>
</ul>

<h3>Title: Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Kahl, Felix LÃ¶ffler, Martin Maciol, Fabian Ridder, Marius Schmitz, Jennifer Spanagel, Jens Wienkamp, Christopher Burgahn, Malte Schilling</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04645">https://arxiv.org/abs/2408.04645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04645">https://arxiv.org/pdf/2408.04645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04645]] Evaluating the Impact of Advanced LLM Techniques on AI-Lecture Tutors for a Robotics Course(https://arxiv.org/abs/2408.04645)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study evaluates the performance of Large Language Models (LLMs) as an Artificial Intelligence-based tutor for a university course. In particular, different advanced techniques are utilized, such as prompt engineering, Retrieval-Augmented-Generation (RAG), and fine-tuning. We assessed the different models and applied techniques using common similarity metrics like BLEU-4, ROUGE, and BERTScore, complemented by a small human evaluation of helpfulness and trustworthiness. Our findings indicate that RAG combined with prompt engineering significantly enhances model responses and produces better factual answers. In the context of education, RAG appears as an ideal technique as it is based on enriching the input of the model with additional information and material which usually is already present for a university course. Fine-tuning, on the other hand, can produce quite small, still strong expert models, but poses the danger of overfitting. Our study further asks how we measure performance of LLMs and how well current measurements represent correctness or relevance? We find high correlation on similarity metrics and a bias of most of these metrics towards shorter responses. Overall, our research points to both the potential and challenges of integrating LLMs in educational settings, suggesting a need for balanced training approaches and advanced evaluation frameworks.</li>
</ul>

<h3>Title: Efficacy of Large Language Models in Systematic Reviews</h3>
<ul>
<li><strong>Authors: </strong>Aaditya Shah, Shridhar Mehendale, Siddha Kanthi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04646">https://arxiv.org/abs/2408.04646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04646">https://arxiv.org/pdf/2408.04646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04646]] Efficacy of Large Language Models in Systematic Reviews(https://arxiv.org/abs/2408.04646)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study investigates the effectiveness of Large Language Models (LLMs) in interpreting existing literature through a systematic review of the relationship between Environmental, Social, and Governance (ESG) factors and financial performance. The primary objective is to assess how LLMs can replicate a systematic review on a corpus of ESG-focused papers. We compiled and hand-coded a database of 88 relevant papers published from March 2020 to May 2024. Additionally, we used a set of 238 papers from a previous systematic review of ESG literature from January 2015 to February 2020. We evaluated two current state-of-the-art LLMs, Meta AI's Llama 3 8B and OpenAI's GPT-4o, on the accuracy of their interpretations relative to human-made classifications on both sets of papers. We then compared these results to a "Custom GPT" and a fine-tuned GPT-4o Mini model using the corpus of 238 papers as training data. The fine-tuned GPT-4o Mini model outperformed the base LLMs by 28.3% on average in overall accuracy on prompt 1. At the same time, the "Custom GPT" showed a 3.0% and 15.7% improvement on average in overall accuracy on prompts 2 and 3, respectively. Our findings reveal promising results for investors and agencies to leverage LLMs to summarize complex evidence related to ESG investing, thereby enabling quicker decision-making and a more efficient market.</li>
</ul>

<h3>Title: Distinguishing Chatbot from Human</h3>
<ul>
<li><strong>Authors: </strong>Gauri Anil Godghase, Rishit Agrawal, Tanush Obili, Mark Stamp</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04647">https://arxiv.org/abs/2408.04647</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04647">https://arxiv.org/pdf/2408.04647</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04647]] Distinguishing Chatbot from Human(https://arxiv.org/abs/2408.04647)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative, large language model</a></li>
<li><strong>Abstract: </strong>There have been many recent advances in the fields of generative Artificial Intelligence (AI) and Large Language Models (LLM), with the Generative Pre-trained Transformer (GPT) model being a leading "chatbot." LLM-based chatbots have become so powerful that it may seem difficult to differentiate between human-written and machine-generated text. To analyze this problem, we have developed a new dataset consisting of more than 750,000 human-written paragraphs, with a corresponding chatbot-generated paragraph for each. Based on this dataset, we apply Machine Learning (ML) techniques to determine the origin of text (human or chatbot). Specifically, we consider two methodologies for tackling this issue: feature analysis and embeddings. Our feature analysis approach involves extracting a collection of features from the text for classification. We also explore the use of contextual embeddings and transformer-based architectures to train classification models. Our proposed solutions offer high classification accuracy and serve as useful tools for textual analysis, resulting in a better understanding of chatbot-generated text in this era of advanced AI technology.</li>
</ul>

<h3>Title: PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Alexey Tikhonov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04648">https://arxiv.org/abs/2408.04648</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04648">https://arxiv.org/pdf/2408.04648</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04648]] PLUGH: A Benchmark for Spatial Understanding and Reasoning in Large Language Models(https://arxiv.org/abs/2408.04648)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present PLUGH (this https URL), a modern benchmark that currently consists of 5 tasks, each with 125 input texts extracted from 48 different games and representing 61 different (non-isomorphic) spatial graphs to assess the abilities of Large Language Models (LLMs) for spatial understanding and reasoning. Our evaluation of API-based and open-sourced LLMs shows that while some commercial LLMs exhibit strong reasoning abilities, open-sourced competitors can demonstrate almost the same level of quality; however, all models still have significant room for improvement. We identify typical reasons for LLM failures and discuss possible ways to deal with them. Datasets and evaluation code are released (this https URL).</li>
</ul>

<h3>Title: Chain of Stance: Stance Detection with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Junxia Ma, Changjiang Wang, Hanwen Xing, Dongming Zhao, Yazhou Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04649">https://arxiv.org/abs/2408.04649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04649">https://arxiv.org/pdf/2408.04649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04649]] Chain of Stance: Stance Detection with Large Language Models(https://arxiv.org/abs/2408.04649)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stance detection is an active task in natural language processing (NLP) that aims to identify the author's stance towards a particular target within a text. Given the remarkable language understanding capabilities and encyclopedic prior knowledge of large language models (LLMs), how to explore the potential of LLMs in stance detection has received significant attention. Unlike existing LLM-based approaches that focus solely on fine-tuning with large-scale datasets, we propose a new prompting method, called \textit{Chain of Stance} (CoS). In particular, it positions LLMs as expert stance detectors by decomposing the stance detection process into a series of intermediate, stance-related assertions that culminate in the final judgment. This approach leads to significant improvements in classification performance. We conducted extensive experiments using four SOTA LLMs on the SemEval 2016 dataset, covering the zero-shot and few-shot learning setups. The results indicate that the proposed method achieves state-of-the-art results with an F1 score of 79.84 in the few-shot setting.</li>
</ul>

<h3>Title: Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools</h3>
<ul>
<li><strong>Authors: </strong>Jung In Park, Mahyar Abbasian, Iman Azimi, Dawn Bounds, Angela Jun, Jaesu Han, Robert McCarron, Jessica Borelli, Jia Li, Mona Mahmoudi, Carmen Wiedenhoeft, Amir Rahmani</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04650">https://arxiv.org/abs/2408.04650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04650">https://arxiv.org/pdf/2408.04650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04650]] Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools(https://arxiv.org/abs/2408.04650)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Objective: This study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots, which are increasingly popular due to their accessibility, human-like interactions, and context-aware support. Materials and Methods: We created an evaluation framework with 100 benchmark questions and ideal responses, and five guideline questions for chatbot responses. This framework, validated by mental health experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation methods explored included large language model (LLM)-based scoring, an agentic approach using real-time data, and embedding models to compare chatbot responses against ground truth standards. Results: The results highlight the importance of guidelines and ground truth for improving LLM evaluation accuracy. The agentic method, dynamically accessing reliable information, demonstrated the best alignment with human assessments. Adherence to a standardized, expert-validated framework significantly enhanced chatbot response safety and reliability. Discussion: Our findings emphasize the need for comprehensive, expert-tailored safety evaluation metrics for mental health chatbots. While LLMs have significant potential, careful implementation is necessary to mitigate risks. The superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. Conclusion: The study validated an evaluation framework for mental health chatbots, proving its effectiveness in improving safety and reliability. Future work should extend evaluations to accuracy, bias, empathy, and privacy to ensure holistic assessment and responsible integration into healthcare. Standardized evaluations will build trust among users and professionals, facilitating broader adoption and improved mental health support through technology.</li>
</ul>

<h3>Title: Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding</h3>
<ul>
<li><strong>Authors: </strong>Balaji Muralidharan, Hayden Beadles, Reza Marzban, Kalyan Sashank Mupparaju</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04651">https://arxiv.org/abs/2408.04651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04651">https://arxiv.org/pdf/2408.04651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04651]] Knowledge AI: Fine-tuning NLP Models for Facilitating Scientific Knowledge Extraction and Understanding(https://arxiv.org/abs/2408.04651)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>This project investigates the efficacy of Large Language Models (LLMs) in understanding and extracting scientific knowledge across specific domains and to create a deep learning framework: Knowledge AI. As a part of this framework, we employ pre-trained models and fine-tune them on datasets in the scientific domain. The models are adapted for four key Natural Language Processing (NLP) tasks: summarization, text generation, question answering, and named entity recognition. Our results indicate that domain-specific fine-tuning significantly enhances model performance in each of these tasks, thereby improving their applicability for scientific contexts. This adaptation enables non-experts to efficiently query and extract information within targeted scientific fields, demonstrating the potential of fine-tuned LLMs as a tool for knowledge discovery in the sciences.</li>
</ul>

<h3>Title: Leveraging Large Language Models with Chain-of-Thought and Prompt Engineering for Traffic Crash Severity Analysis and Inference</h3>
<ul>
<li><strong>Authors: </strong>Hao Zhen, Yucheng Shi, Yongcan Huang, Jidong J. Yang, Ninghao Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04652">https://arxiv.org/abs/2408.04652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04652">https://arxiv.org/pdf/2408.04652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04652]] Leveraging Large Language Models with Chain-of-Thought and Prompt Engineering for Traffic Crash Severity Analysis and Inference(https://arxiv.org/abs/2408.04652)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Harnessing the power of Large Language Models (LLMs), this study explores the use of three state-of-the-art LLMs, specifically GPT-3.5-turbo, LLaMA3-8B, and LLaMA3-70B, for crash severity inference, framing it as a classification task. We generate textual narratives from original traffic crash tabular data using a pre-built template infused with domain knowledge. Additionally, we incorporated Chain-of-Thought (CoT) reasoning to guide the LLMs in analyzing the crash causes and then inferring the severity. This study also examine the impact of prompt engineering specifically designed for crash severity inference. The LLMs were tasked with crash severity inference to: (1) evaluate the models' capabilities in crash severity analysis, (2) assess the effectiveness of CoT and domain-informed prompt engineering, and (3) examine the reasoning abilities with the CoT framework. Our results showed that LLaMA3-70B consistently outperformed the other models, particularly in zero-shot settings. The CoT and Prompt Engineering techniques significantly enhanced performance, improving logical reasoning and addressing alignment issues. Notably, the CoT offers valuable insights into LLMs' reasoning processes, unleashing their capacity to consider diverse factors such as environmental conditions, driver behavior, and vehicle characteristics in severity analysis and inference.</li>
</ul>

<h3>Title: Strong and weak alignment of large language models with human values</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Khamassi, Marceau Nahon, Raja Chatila</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04655">https://arxiv.org/abs/2408.04655</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04655">https://arxiv.org/pdf/2408.04655</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04655]] Strong and weak alignment of large language models with human values(https://arxiv.org/abs/2408.04655)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Minimizing negative impacts of Artificial Intelligent (AI) systems on human societies without human supervision requires them to be able to align with human values. However, most current work only addresses this issue from a technical point of view, e.g., improving current methods relying on reinforcement learning from human feedback, neglecting what it means and is required for alignment to occur. Here, we propose to distinguish strong and weak value alignment. Strong alignment requires cognitive abilities (either human-like or different from humans) such as understanding and reasoning about agents' intentions and their ability to causally produce desired effects. We argue that this is required for AI systems like large language models (LLMs) to be able to recognize situations presenting a risk that human values may be flouted. To illustrate this distinction, we present a series of prompts showing ChatGPT's, Gemini's and Copilot's failures to recognize some of these situations. We moreover analyze word embeddings to show that the nearest neighbors of some human values in LLMs differ from humans' semantic representations. We then propose a new thought experiment that we call "the Chinese room with a word transition dictionary", in extension of John Searle's famous proposal. We finally mention current promising research directions towards a weak alignment, which could produce statistically satisfying answers in a number of common situations, however so far without ensuring any truth value.</li>
</ul>

<h3>Title: Winning Amazon KDD Cup'24</h3>
<ul>
<li><strong>Authors: </strong>Chris Deotte, Ivan Sorokin, Ahmet Erdem, Benedikt Schifferer, Gilberto Titericz Jr, Simon Jegou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04658">https://arxiv.org/abs/2408.04658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04658">https://arxiv.org/pdf/2408.04658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04658]] Winning Amazon KDD Cup'24(https://arxiv.org/abs/2408.04658)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper describes the winning solution of all 5 tasks for the Amazon KDD Cup 2024 Multi Task Online Shopping Challenge for LLMs. The challenge was to build a useful assistant, answering questions in the domain of online shopping. The competition contained 57 diverse tasks, covering 5 different task types (e.g. multiple choice) and across 4 different tracks (e.g. multi-lingual). Our solution is a single model per track. We fine-tune Qwen2-72B-Instruct on our own training dataset. As the competition released only 96 example questions, we developed our own training dataset by processing multiple public datasets or using Large Language Models for data augmentation and synthetic data generation. We apply wise-ft to account for distribution shifts and ensemble multiple LoRA adapters in one model. We employed Logits Processors to constrain the model output on relevant tokens for the tasks. AWQ 4-bit Quantization and vLLM are used during inference to predict the test dataset in the time constraints of 20 to 140 minutes depending on the track. Our solution achieved the first place in each individual track and is the first place overall of Amazons KDD Cup 2024.</li>
</ul>

<h3>Title: XMainframe: A Large Language Model for Mainframe Modernization</h3>
<ul>
<li><strong>Authors: </strong>Anh T. V. Dau, Hieu Trung Dao, Anh Tuan Nguyen, Hieu Trung Tran, Phong X. Nguyen, Nghi D. Q. Bui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04660">https://arxiv.org/abs/2408.04660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04660">https://arxiv.org/pdf/2408.04660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04660]] XMainframe: A Large Language Model for Mainframe Modernization(https://arxiv.org/abs/2408.04660)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mainframe operating systems, despite their inception in the 1940s, continue to support critical sectors like finance and government. However, these systems are often viewed as outdated, requiring extensive maintenance and modernization. Addressing this challenge necessitates innovative tools that can understand and interact with legacy codebases. To this end, we introduce XMainframe, a state-of-the-art large language model (LLM) specifically designed with knowledge of mainframe legacy systems and COBOL codebases. Our solution involves the creation of an extensive data collection pipeline to produce high-quality training datasets, enhancing XMainframe's performance in this specialized domain. Additionally, we present MainframeBench, a comprehensive benchmark for assessing mainframe knowledge, including multiple-choice questions, question answering, and COBOL code summarization. Our empirical evaluations demonstrate that XMainframe consistently outperforms existing state-of-the-art LLMs across these tasks. Specifically, XMainframe achieves 30% higher accuracy than DeepSeek-Coder on multiple-choice questions, doubles the BLEU score of Mixtral-Instruct 8x7B on question answering, and scores six times higher than GPT-3.5 on COBOL summarization. Our work highlights the potential of XMainframe to drive significant advancements in managing and modernizing legacy systems, thereby enhancing productivity and saving time for software developers.</li>
</ul>

<h3>Title: MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities</h3>
<ul>
<li><strong>Authors: </strong>Ali Riza Durmaz, Akhil Thomas, Lokesh Mishra, Rachana Niranjan Murthy, Thomas Straub</a></li>
<li><strong>Subjects: </strong>cs.CL, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04661">https://arxiv.org/abs/2408.04661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04661">https://arxiv.org/pdf/2408.04661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04661]] MaterioMiner -- An ontology-based text mining dataset for extraction of process-structure-property entities(https://arxiv.org/abs/2408.04661)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>While large language models learn sound statistical representations of the language and information therein, ontologies are symbolic knowledge representations that can complement the former ideally. Research at this critical intersection relies on datasets that intertwine ontologies and text corpora to enable training and comprehensive benchmarking of neurosymbolic models. We present the MaterioMiner dataset and the linked materials mechanics ontology where ontological concepts from the mechanics of materials domain are associated with textual entities within the literature corpus. Another distinctive feature of the dataset is its eminently fine-granular annotation. Specifically, 179 distinct classes are manually annotated by three raters within four publications, amounting to a total of 2191 entities that were annotated and curated. Conceptual work is presented for the symbolic representation of causal composition-process-microstructure-property relationships. We explore the annotation consistency between the three raters and perform fine-tuning of pre-trained models to showcase the feasibility of named-entity recognition model training. Reusing the dataset can foster training and benchmarking of materials language models, automated ontology construction, and knowledge graph generation from textual data.</li>
</ul>

<h3>Title: Citekit: A Modular Toolkit for Large Language Model Citation Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Shen, Tong Zhou, Suifeng Zhao, Yubo Chen, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04662">https://arxiv.org/abs/2408.04662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04662">https://arxiv.org/pdf/2408.04662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04662]] Citekit: A Modular Toolkit for Large Language Model Citation Generation(https://arxiv.org/abs/2408.04662)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>Enabling Large Language Models (LLMs) to generate citations in Question-Answering (QA) tasks is an emerging paradigm aimed at enhancing the verifiability of their responses when LLMs are utilizing external references to generate an answer. However, there is currently no unified framework to standardize and fairly compare different citation generation methods, leading to difficulties in reproducing different methods and a comprehensive assessment. To cope with the problems above, we introduce \name, an open-source and modular toolkit designed to facilitate the implementation and evaluation of existing citation generation methods, while also fostering the development of new approaches to improve citation quality in LLM outputs. This tool is highly extensible, allowing users to utilize 4 main modules and 14 components to construct a pipeline, evaluating an existing method or innovative designs. Our experiments with two state-of-the-art LLMs and 11 citation generation baselines demonstrate varying strengths of different modules in answer accuracy and citation quality improvement, as well as the challenge of enhancing granularity. Based on our analysis of the effectiveness of components, we propose a new method, self-RAG \snippet, obtaining a balanced answer accuracy and citation quality. Citekit is released at this https URL.</li>
</ul>

<h3>Title: Dopamin: Transformer-based Comment Classifiers through Domain Post-Training and Multi-level Layer Aggregation</h3>
<ul>
<li><strong>Authors: </strong>Nam Le Hai, Nghi D. Q. Bui</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04663">https://arxiv.org/abs/2408.04663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04663">https://arxiv.org/pdf/2408.04663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04663]] Dopamin: Transformer-based Comment Classifiers through Domain Post-Training and Multi-level Layer Aggregation(https://arxiv.org/abs/2408.04663)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Code comments provide important information for understanding the source code. They can help developers understand the overall purpose of a function or class, as well as identify bugs and technical debt. However, an overabundance of comments is meaningless and counterproductive. As a result, it is critical to automatically filter out these comments for specific purposes. In this paper, we present Dopamin, a Transformer-based tool for dealing with this issue. Our model excels not only in presenting knowledge sharing of common categories across multiple languages, but also in achieving robust performance in comment classification by improving comment representation. As a result, it outperforms the STACC baseline by 3% on the NLBSE'24 Tool Competition dataset in terms of average F1-score, while maintaining a comparable inference time for practical use. The source code is publicity available at this https URL.</li>
</ul>

<h3>Title: Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)</h3>
<ul>
<li><strong>Authors: </strong>Avshalom Manevich, Reut Tsarfaty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04664">https://arxiv.org/abs/2408.04664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04664">https://arxiv.org/pdf/2408.04664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04664]] Mitigating Hallucinations in Large Vision-Language Models (LVLMs) via Language-Contrastive Decoding (LCD)(https://arxiv.org/abs/2408.04664)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) are an extension of Large Language Models (LLMs) that facilitate processing both image and text inputs, expanding AI capabilities. However, LVLMs struggle with object hallucinations due to their reliance on text cues and learned object co-occurrence biases. While most research quantifies these hallucinations, mitigation strategies are still lacking. Our study introduces a Language Contrastive Decoding (LCD) algorithm that adjusts LVLM outputs based on LLM distribution confidence levels, effectively reducing object hallucinations. We demonstrate the advantages of LCD in leading LVLMs, showing up to %4 improvement in POPE F1 scores and up to %36 reduction in CHAIR scores on the COCO validation set, while also improving captioning quality scores. Our method effectively improves LVLMs without needing complex post-processing or retraining, and is easily applicable to different models. Our findings highlight the potential of further exploration of LVLM-specific decoding algorithms.</li>
</ul>

<h3>Title: LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations</h3>
<ul>
<li><strong>Authors: </strong>Lei Shi, Zhimeng Liu, Yi Yang, Weize Wu, Yuyang Zhang, Hongbo Zhang, Jing Lin, Siyu Wu, Zihan Chen, Ruiming Li, Nan Wang, Zipeng Liu, Huobin Tan, Hongyi Gao, Yue Zhang, Ge Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04665">https://arxiv.org/abs/2408.04665</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04665">https://arxiv.org/pdf/2408.04665</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04665]] LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations(https://arxiv.org/abs/2408.04665)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, extraction, large language model</a></li>
<li><strong>Abstract: </strong>The extraction of Metal-Organic Frameworks (MOFs) synthesis conditions from literature text has been challenging but crucial for the logical design of new MOFs with desirable functionality. The recent advent of large language models (LLMs) provides disruptively new solution to this long-standing problem and latest researches have reported over 90% F1 in extracting correct conditions from MOFs literature. We argue in this paper that most existing synthesis extraction practices with LLMs stay with the primitive zero-shot learning, which could lead to downgraded extraction and application performance due to the lack of specialized knowledge. This work pioneers and optimizes the few-shot in-context learning paradigm for LLM extraction of material synthesis conditions. First, we propose a human-AI joint data curation process to secure high-quality ground-truth demonstrations for few-shot learning. Second, we apply a BM25 algorithm based on the retrieval-augmented generation (RAG) technique to adaptively select few-shot demonstrations for each MOF's extraction. Over a dataset randomly sampled from 84,898 well-defined MOFs, the proposed few-shot method achieves much higher average F1 performance (0.93 vs. 0.81, +14.8%) than the native zero-shot LLM using the same GPT-4 model, under fully automatic evaluation that are more objective than the previous human evaluation. The proposed method is further validated through real-world material experiments: compared with the baseline zero-shot LLM, the proposed few-shot approach increases the MOFs structural inference performance (R^2) by 29.4% in average.</li>
</ul>

<h3>Title: Forecasting Live Chat Intent from Browsing History</h3>
<ul>
<li><strong>Authors: </strong>Se-eun Yoon, Ahmad Bin Rabiah, Zaid Alibadi, Surya Kallumadi, Julian McAuley</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04668">https://arxiv.org/abs/2408.04668</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04668">https://arxiv.org/pdf/2408.04668</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04668]] Forecasting Live Chat Intent from Browsing History(https://arxiv.org/abs/2408.04668)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Customers reach out to online live chat agents with various intents, such as asking about product details or requesting a return. In this paper, we propose the problem of predicting user intent from browsing history and address it through a two-stage approach. The first stage classifies a user's browsing history into high-level intent categories. Here, we represent each browsing history as a text sequence of page attributes and use the ground-truth class labels to fine-tune pretrained Transformers. The second stage provides a large language model (LLM) with the browsing history and predicted intent class to generate fine-grained intents. For automatic evaluation, we use a separate LLM to judge the similarity between generated and ground-truth intents, which closely aligns with human judgments. Our two-stage approach yields significant performance gains compared to generating intents without the classification stage.</li>
</ul>

<h3>Title: Prompt and Prejudice</h3>
<ul>
<li><strong>Authors: </strong>Lorenzo Berlincioni, Luca Cultrera, Federico Becattini, Marco Bertini, Alberto Del Bimbo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04671">https://arxiv.org/abs/2408.04671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04671">https://arxiv.org/pdf/2408.04671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04671]] Prompt and Prejudice(https://arxiv.org/abs/2408.04671)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates the impact of using first names in Large Language Models (LLMs) and Vision Language Models (VLMs), particularly when prompted with ethical decision-making tasks. We propose an approach that appends first names to ethically annotated text scenarios to reveal demographic biases in model outputs. Our study involves a curated list of more than 300 names representing diverse genders and ethnic backgrounds, tested across thousands of moral scenarios. Following the auditing methodologies from social sciences we propose a detailed analysis involving popular LLMs/VLMs to contribute to the field of responsible AI by emphasizing the importance of recognizing and mitigating biases in these systems. Furthermore, we introduce a novel benchmark, the Pratical Scenarios Benchmark (PSB), designed to assess the presence of biases involving gender or demographic prejudices in everyday decision-making scenarios as well as practical scenarios where an LLM might be used to make sensible decisions (e.g., granting mortgages or insurances). This benchmark allows for a comprehensive comparison of model behaviors across different demographic categories, highlighting the risks and biases that may arise in practical applications of LLMs and VLMs.</li>
</ul>

<h3>Title: AutoFAIR : Automatic Data FAIRification via Machine Reading</h3>
<ul>
<li><strong>Authors: </strong>Tingyan Ma, Wei Liu, Bin Lu, Xiaoying Gan, Yunqiang Zhu, Luoyi Fu, Chenghu Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04673">https://arxiv.org/abs/2408.04673</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04673">https://arxiv.org/pdf/2408.04673</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04673]] AutoFAIR : Automatic Data FAIRification via Machine Reading(https://arxiv.org/abs/2408.04673)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>The explosive growth of data fuels data-driven research, facilitating progress across diverse domains. The FAIR principles emerge as a guiding standard, aiming to enhance the findability, accessibility, interoperability, and reusability of data. However, current efforts primarily focus on manual data FAIRification, which can only handle targeted data and lack efficiency. To address this issue, we propose AutoFAIR, an architecture designed to enhance data FAIRness automately. Firstly, We align each data and metadata operation with specific FAIR indicators to guide machine-executable actions. Then, We utilize Web Reader to automatically extract metadata based on language models, even in the absence of structured data webpage schemas. Subsequently, FAIR Alignment is employed to make metadata comply with FAIR principles by ontology guidance and semantic matching. Finally, by applying AutoFAIR to various data, especially in the field of mountain hazards, we observe significant improvements in findability, accessibility, interoperability, and reusability of data. The FAIRness scores before and after applying AutoFAIR indicate enhanced data value.</li>
</ul>

<h3>Title: Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings</h3>
<ul>
<li><strong>Authors: </strong>Jinzhao Zhou, Yiqun Duan, Ziyi Zhao, Yu-Cheng Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04679">https://arxiv.org/abs/2408.04679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04679">https://arxiv.org/pdf/2408.04679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04679]] Towards Linguistic Neural Representation Learning and Sentence Retrieval from Electroencephalogram Recordings(https://arxiv.org/abs/2408.04679)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Decoding linguistic information from non-invasive brain signals using EEG has gained increasing research attention due to its vast applicational potential. Recently, a number of works have adopted a generative-based framework to decode electroencephalogram (EEG) signals into sentences by utilizing the power generative capacity of pretrained large language models (LLMs). However, this approach has several drawbacks that hinder the further development of linguistic applications for brain-computer interfaces (BCIs). Specifically, the ability of the EEG encoder to learn semantic information from EEG data remains questionable, and the LLM decoder's tendency to generate sentences based on its training memory can be hard to avoid. These issues necessitate a novel approach for converting EEG signals into sentences. In this paper, we propose a novel two-step pipeline that addresses these limitations and enhances the validity of linguistic EEG decoding research. We first confirm that word-level semantic information can be learned from EEG data recorded during natural reading by training a Conformer encoder via a masked contrastive objective for word-level classification. To achieve sentence decoding results, we employ a training-free retrieval method to retrieve sentences based on the predictions from the EEG encoder. Extensive experiments and ablation studies were conducted in this paper for a comprehensive evaluation of the proposed approach. Visualization of the top prediction candidates reveals that our model effectively groups EEG segments into semantic categories with similar meanings, thereby validating its ability to learn patterns from unspoken EEG recordings. Despite the exploratory nature of this work, these results suggest that our method holds promise for providing more reliable solutions for converting EEG signals into text.</li>
</ul>

<h3>Title: Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications</h3>
<ul>
<li><strong>Authors: </strong>Philipp Zagar, Vishnu Ravi, Lauren Aalami, Stephan Krusche, Oliver Aalami, Paul Schmiedmayer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04680">https://arxiv.org/abs/2408.04680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04680">https://arxiv.org/pdf/2408.04680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04680]] Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications(https://arxiv.org/abs/2408.04680)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, large language model</a></li>
<li><strong>Abstract: </strong>The ability of large language models (LLMs) to transform, interpret, and comprehend vast quantities of heterogeneous data presents a significant opportunity to enhance data-driven care delivery. However, the sensitive nature of protected health information (PHI) raises valid concerns about data privacy and trust in remote LLM platforms. In addition, the cost associated with cloud-based artificial intelligence (AI) services continues to impede widespread adoption. To address these challenges, we propose a shift in the LLM execution environment from opaque, centralized cloud providers to a decentralized and dynamic fog computing architecture. By executing open-weight LLMs in more trusted environments, such as the user's edge device or a fog layer within a local network, we aim to mitigate the privacy, trust, and financial challenges associated with cloud-based LLMs. We further present SpeziLLM, an open-source framework designed to facilitate rapid and seamless leveraging of different LLM execution layers and lowering barriers to LLM integration in digital health applications. We demonstrate SpeziLLM's broad applicability across six digital health applications, showcasing its versatility in various healthcare settings.</li>
</ul>

<h3>Title: Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews</h3>
<ul>
<li><strong>Authors: </strong>Samantha Chan, Pat Pataranutaporn, Aditya Suri, Wazeer Zulfikar, Pattie Maes, Elizabeth F. Loftus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04681">https://arxiv.org/abs/2408.04681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04681">https://arxiv.org/pdf/2408.04681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04681]] Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews(https://arxiv.org/abs/2408.04681)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>This study examines the impact of AI on human false memories -- recollections of events that did not occur or deviate from actual occurrences. It explores false memory induction through suggestive questioning in Human-AI interactions, simulating crime witness interviews. Four conditions were tested: control, survey-based, pre-scripted chatbot, and generative chatbot using a large language model (LLM). Participants (N=200) watched a crime video, then interacted with their assigned AI interviewer or survey, answering questions including five misleading ones. False memories were assessed immediately and after one week. Results show the generative chatbot condition significantly increased false memory formation, inducing over 3 times more immediate false memories than the control and 1.7 times more than the survey method. 36.4% of users' responses to the generative chatbot were misled through the interaction. After one week, the number of false memories induced by generative chatbots remained constant. However, confidence in these false memories remained higher than the control after one week. Moderating factors were explored: users who were less familiar with chatbots but more familiar with AI technology, and more interested in crime investigations, were more susceptible to false memories. These findings highlight the potential risks of using advanced AI in sensitive contexts, like police interviews, emphasizing the need for ethical considerations.</li>
</ul>

<h3>Title: ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities</h3>
<ul>
<li><strong>Authors: </strong>Jiarui Lu, Thomas Holleis, Yizhe Zhang, Bernhard Aumayer, Feng Nan, Felix Bai, Shuang Ma, Shen Ma, Mengyu Li, Guoli Yin, Zirui Wang, Ruoming Pang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04682">https://arxiv.org/abs/2408.04682</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04682">https://arxiv.org/pdf/2408.04682</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04682]] ToolSandbox: A Stateful, Conversational, Interactive Evaluation Benchmark for LLM Tool Use Capabilities(https://arxiv.org/abs/2408.04682)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) advancements sparked a growing research interest in tool assisted LLMs solving real-world challenges, which calls for comprehensive evaluation of tool-use capabilities. While previous works focused on either evaluating over stateless web services (RESTful API), based on a single turn user prompt, or an off-policy dialog trajectory, ToolSandbox includes stateful tool execution, implicit state dependencies between tools, a built-in user simulator supporting on-policy conversational evaluation and a dynamic evaluation strategy for intermediate and final milestones over an arbitrary trajectory. We show that open source and proprietary models have a significant performance gap, and complex tasks like State Dependency, Canonicalization and Insufficient Information defined in ToolSandbox are challenging even the most capable SOTA LLMs, providing brand-new insights into tool-use LLM capabilities. ToolSandbox evaluation framework is released at this https URL</li>
</ul>

<h3>Title: Eliminating Backdoors in Neural Code Models via Trigger Inversion</h3>
<ul>
<li><strong>Authors: </strong>Weisong Sun, Yuchen Chen, Chunrong Fang, Yebo Feng, Yuan Xiao, An Guo, Quanjun Zhang, Yang Liu, Baowen Xu, Zhenyu Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04683">https://arxiv.org/abs/2408.04683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04683">https://arxiv.org/pdf/2408.04683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04683]] Eliminating Backdoors in Neural Code Models via Trigger Inversion(https://arxiv.org/abs/2408.04683)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, defense, attack</a></li>
<li><strong>Abstract: </strong>Neural code models (NCMs) have been widely used for addressing various code understanding tasks, such as defect detection and clone detection. However, numerous recent studies reveal that such models are vulnerable to backdoor attacks. Backdoored NCMs function normally on normal code snippets, but exhibit adversary-expected behavior on poisoned code snippets injected with the adversary-crafted trigger. It poses a significant security threat. For example, a backdoored defect detection model may misclassify user-submitted defective code as non-defective. If this insecure code is then integrated into critical systems, like autonomous driving systems, it could lead to life safety. However, there is an urgent need for effective defenses against backdoor attacks targeting NCMs. To address this issue, in this paper, we innovatively propose a backdoor defense technique based on trigger inversion, called EliBadCode. EliBadCode first filters the model vocabulary for trigger tokens to reduce the search space for trigger inversion, thereby enhancing the efficiency of the trigger inversion. Then, EliBadCode introduces a sample-specific trigger position identification method, which can reduce the interference of adversarial perturbations for subsequent trigger inversion, thereby producing effective inverted triggers efficiently. Subsequently, EliBadCode employs a Greedy Coordinate Gradient algorithm to optimize the inverted trigger and designs a trigger anchoring method to purify the inverted trigger. Finally, EliBadCode eliminates backdoors through model unlearning. We evaluate the effectiveness of EliBadCode in eliminating backdoor attacks against multiple NCMs used for three safety-critical code understanding tasks. The results demonstrate that EliBadCode can effectively eliminate backdoors while having minimal adverse effects on the normal functionality of the model.</li>
</ul>

<h3>Title: Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles</h3>
<ul>
<li><strong>Authors: </strong>Xiongtao Sun, Deyue Zhang, Dongdong Yang, Quanchen Zou, Hui Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04686">https://arxiv.org/abs/2408.04686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04686">https://arxiv.org/pdf/2408.04686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04686]] Multi-Turn Context Jailbreak Attack on Large Language Models From First Principles(https://arxiv.org/abs/2408.04686)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have significantly enhanced the performance of numerous applications, from intelligent conversations to text generation. However, their inherent security vulnerabilities have become an increasingly significant challenge, especially with respect to jailbreak attacks. Attackers can circumvent the security mechanisms of these LLMs, breaching security constraints and causing harmful outputs. Focusing on multi-turn semantic jailbreak attacks, we observe that existing methods lack specific considerations for the role of multiturn dialogues in attack strategies, leading to semantic deviations during continuous interactions. Therefore, in this paper, we establish a theoretical foundation for multi-turn attacks by considering their support in jailbreak attacks, and based on this, propose a context-based contextual fusion black-box jailbreak attack method, named Context Fusion Attack (CFA). This method approach involves filtering and extracting key terms from the target, constructing contextual scenarios around these terms, dynamically integrating the target into the scenarios, replacing malicious key terms within the target, and thereby concealing the direct malicious intent. Through comparisons on various mainstream LLMs and red team datasets, we have demonstrated CFA's superior success rate, divergence, and harmfulness compared to other multi-turn attack strategies, particularly showcasing significant advantages on Llama3 and GPT-4.</li>
</ul>

<h3>Title: Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance</h3>
<ul>
<li><strong>Authors: </strong>Niklas Wretblad, Oskar HolmstrÃ¶m, Erik Larsson, Axel WiksÃ¤ter, Oscar SÃ¶derlund, Hjalmar Ãhman, Ture PontÃ©n, Martin Forsberg, Martin SÃ¶rme, Fredrik Heintz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04691">https://arxiv.org/abs/2408.04691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04691">https://arxiv.org/pdf/2408.04691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04691]] Improving Relational Database Interactions with Large Language Models: Column Descriptions and Their Impact on Text-to-SQL Performance(https://arxiv.org/abs/2408.04691)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Relational databases often suffer from uninformative descriptors of table contents, such as ambiguous columns and hard-to-interpret values, impacting both human users and Text-to-SQL models. This paper explores the use of large language models (LLMs) to generate informative column descriptions as a semantic layer for relational databases. Using the BIRD-Bench development set, we created \textsc{ColSQL}, a dataset with gold-standard column descriptions generated and refined by LLMs and human annotators. We evaluated several instruction-tuned models, finding that GPT-4o and Command R+ excelled in generating high-quality descriptions. Additionally, we applied an LLM-as-a-judge to evaluate model performance. Although this method does not align well with human evaluations, we included it to explore its potential and to identify areas for improvement. More work is needed to improve the reliability of automatic evaluations for this task. We also find that detailed column descriptions significantly improve Text-to-SQL execution accuracy, especially when columns are uninformative. This study establishes LLMs as effective tools for generating detailed metadata, enhancing the usability of relational databases.</li>
</ul>

<h3>Title: Understanding the Performance and Estimating the Cost of LLM Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Yuchen Xia, Jiho Kim, Yuhan Chen, Haojie Ye, Souvik Kundu, Cong (Callie)Hao, Nishil Talati</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04693">https://arxiv.org/abs/2408.04693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04693">https://arxiv.org/pdf/2408.04693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04693]] Understanding the Performance and Estimating the Cost of LLM Fine-Tuning(https://arxiv.org/abs/2408.04693)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Due to the cost-prohibitive nature of training Large Language Models (LLMs), fine-tuning has emerged as an attractive alternative for specializing LLMs for specific tasks using limited compute resources in a cost-effective manner. In this paper, we characterize sparse Mixture of Experts (MoE) based LLM fine-tuning to understand their accuracy and runtime performance on a single GPU. Our evaluation provides unique insights into the training efficacy of sparse and dense versions of MoE models, as well as their runtime characteristics, including maximum batch size, execution time breakdown, end-to-end throughput, GPU hardware utilization, and load distribution. Our study identifies the optimization of the MoE layer as crucial for further improving the performance of LLM fine-tuning. Using our profiling results, we also develop and validate an analytical model to estimate the cost of LLM fine-tuning on the cloud. This model, based on parameters of the model and GPU architecture, estimates LLM throughput and the cost of training, aiding practitioners in industry and academia to budget the cost of fine-tuning a specific model.</li>
</ul>

<h3>Title: Overlay-based Decentralized Federated Learning in Bandwidth-limited Networks</h3>
<ul>
<li><strong>Authors: </strong>Yudi Huang, Tingyang Sun, Ting He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04705">https://arxiv.org/abs/2408.04705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04705">https://arxiv.org/pdf/2408.04705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04705]] Overlay-based Decentralized Federated Learning in Bandwidth-limited Networks(https://arxiv.org/abs/2408.04705)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>The emerging machine learning paradigm of decentralized federated learning (DFL) has the promise of greatly boosting the deployment of artificial intelligence (AI) by directly learning across distributed agents without centralized coordination. Despite significant efforts on improving the communication efficiency of DFL, most existing solutions were based on the simplistic assumption that neighboring agents are physically adjacent in the underlying communication network, which fails to correctly capture the communication cost when learning over a general bandwidth-limited network, as encountered in many edge networks. In this work, we address this gap by leveraging recent advances in network tomography to jointly design the communication demands and the communication schedule for overlay-based DFL in bandwidth-limited networks without requiring explicit cooperation from the underlying network. By carefully analyzing the structure of our problem, we decompose it into a series of optimization problems that can each be solved efficiently, to collectively minimize the total training time. Extensive data-driven simulations show that our solution can significantly accelerate DFL in comparison with state-of-the-art designs.</li>
</ul>

<h3>Title: Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models</h3>
<ul>
<li><strong>Authors: </strong>Dule Shu, Amir Barati Farimani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04718">https://arxiv.org/abs/2408.04718</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04718">https://arxiv.org/pdf/2408.04718</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04718]] Zero-Shot Uncertainty Quantification using Diffusion Probabilistic Models(https://arxiv.org/abs/2408.04718)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The success of diffusion probabilistic models in generative tasks, such as text-to-image generation, has motivated the exploration of their application to regression problems commonly encountered in scientific computing and various other domains. In this context, the use of diffusion regression models for ensemble prediction is becoming a practice with increasing popularity. Under such background, we conducted a study to quantitatively evaluate the effectiveness of ensemble methods on solving different regression problems using diffusion models. We consider the ensemble prediction of a diffusion model as a means for zero-shot uncertainty quantification, since the diffusion models in our study are not trained with a loss function containing any uncertainty estimation. Through extensive experiments on 1D and 2D data, we demonstrate that ensemble methods consistently improve model prediction accuracy across various regression tasks. Notably, we observed a larger accuracy gain in auto-regressive prediction compared with point-wise prediction, and that enhancements take place in both the mean-square error and the physics-informed loss. Additionally, we reveal a statistical correlation between ensemble prediction error and ensemble variance, offering insights into balancing computational complexity with prediction accuracy and monitoring prediction confidence in practical applications where the ground truth is unknown. Our study provides a comprehensive view of the utility of diffusion ensembles, serving as a useful reference for practitioners employing diffusion models in regression problem-solving.</li>
</ul>

<h3>Title: Counter Denial of Service for Next-Generation Networks within the Artificial Intelligence and Post-Quantum Era</h3>
<ul>
<li><strong>Authors: </strong>Saleh Darzi, Attila A. Yavuz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04725">https://arxiv.org/abs/2408.04725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04725">https://arxiv.org/pdf/2408.04725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04725]] Counter Denial of Service for Next-Generation Networks within the Artificial Intelligence and Post-Quantum Era(https://arxiv.org/abs/2408.04725)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, defense, attack, federate</a></li>
<li><strong>Abstract: </strong>Given the rise in cyber threats to networked systems, coupled with the proliferation of AI techniques and enhanced processing capabilities, Denial of Service (DoS) attacks are becoming increasingly sophisticated and easily executable. They target system availability, compromising entire systems without breaking underlying security protocols. Consequently, numerous studies have focused on preventing, detecting, and mitigating DoS attacks. However, state-of-the-art systematization efforts have limitations such as isolated DoS countermeasures, shortcomings of AI-based studies, and a lack of DoS integration features like privacy, anonymity, authentication, and transparency. Additionally, the emergence of quantum computers is a game changer for DoS from attack and defense perspectives, yet it has remained largely unexplored. This study aims to address these gaps by examining (counter)-DoS in the AI era while also considering post-quantum (PQ) security when it applies. We highlight the deficiencies in the current literature and provide insights into synergistic techniques to bridge these gaps. We explore AI mechanisms for DoS intrusion detection, evaluate cybersecurity properties in cutting-edge machine learning models, and analyze weaponized AI in the context of DoS. We also investigate collaborative and distributed counter-DoS frameworks via federated learning and blockchains. Finally, we assess proactive approaches such as honeypots, puzzles, and authentication schemes that can be integrated into next-generation network systems for DoS prevention and mitigation.</li>
</ul>

<h3>Title: Novel adaptation of video segmentation to 3D MRI: efficient zero-shot knee segmentation with SAM2</h3>
<ul>
<li><strong>Authors: </strong>Andrew Seohwan Yu, Mohsen Hariri, Xuecen Zhang, Mingrui Yang, Vipin Chaudhary, Xiaojuan Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04762">https://arxiv.org/abs/2408.04762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04762">https://arxiv.org/pdf/2408.04762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04762]] Novel adaptation of video segmentation to 3D MRI: efficient zero-shot knee segmentation with SAM2(https://arxiv.org/abs/2408.04762)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Intelligent medical image segmentation methods are rapidly evolving and being increasingly applied, yet they face the challenge of domain transfer, where algorithm performance degrades due to different data distributions between source and target domains. To address this, we introduce a method for zero-shot, single-prompt segmentation of 3D knee MRI by adapting Segment Anything Model 2 (SAM2), a general-purpose segmentation model designed to accept prompts and retain memory across frames of a video. By treating slices from 3D medical volumes as individual video frames, we leverage SAM2's advanced capabilities to generate motion- and spatially-aware predictions. We demonstrate that SAM2 can efficiently perform segmentation tasks in a zero-shot manner with no additional training or fine-tuning, accurately delineating structures in knee MRI scans using only a single prompt. Our experiments on the Osteoarthritis Initiative Zuse Institute Berlin (OAI-ZIB) dataset reveal that SAM2 achieves high accuracy on 3D knee bone segmentation, with a testing Dice similarity coefficient of 0.9643 on tibia. We also present results generated using different SAM2 model sizes, different prompt schemes, as well as comparative results from the SAM1 model deployed on the same dataset. This breakthrough has the potential to revolutionize medical image analysis by providing a scalable, cost-effective solution for automated segmentation, paving the way for broader clinical applications and streamlined workflows.</li>
</ul>

<h3>Title: Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction</h3>
<ul>
<li><strong>Authors: </strong>Reza Khanmohammadi, Ahmed I. Ghanem, Kyle Verdecchia, Ryan Hall, Mohamed Elshaikh, Benjamin Movsas, Hassan Bagher-Ebadian, Bing Luo, Indrin J. Chetty, Tuka Alhanai, Kundan Thind, Mohammad M. Ghassemi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04775">https://arxiv.org/abs/2408.04775</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04775">https://arxiv.org/pdf/2408.04775</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04775]] Hybrid Student-Teacher Large Language Model Refinement for Cancer Toxicity Symptom Extraction(https://arxiv.org/abs/2408.04775)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, extraction, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) offer significant potential for clinical symptom extraction, but their deployment in healthcare settings is constrained by privacy concerns, computational limitations, and operational costs. This study investigates the optimization of compact LLMs for cancer toxicity symptom extraction using a novel iterative refinement approach. We employ a student-teacher architecture, utilizing Zephyr-7b-beta and Phi3-mini-128 as student models and GPT-4o as the teacher, to dynamically select between prompt refinement, Retrieval-Augmented Generation (RAG), and fine-tuning strategies. Our experiments on 294 clinical notes covering 12 post-radiotherapy toxicity symptoms demonstrate the effectiveness of this approach. The RAG method proved most efficient, improving average accuracy scores from 0.32 to 0.73 for Zephyr-7b-beta and from 0.40 to 0.87 for Phi3-mini-128 during refinement. In the test set, both models showed an approximate 0.20 increase in accuracy across symptoms. Notably, this improvement was achieved at a cost 45 times lower than GPT-4o for Zephyr and 79 times lower for Phi-3. These results highlight the potential of iterative refinement techniques in enhancing the capabilities of compact LLMs for clinical applications, offering a balance between performance, cost-effectiveness, and privacy preservation in healthcare settings.</li>
</ul>

<h3>Title: BRAT: Bonus oRthogonAl Token for Architecture Agnostic Textual Inversion</h3>
<ul>
<li><strong>Authors: </strong>James Baker</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04785">https://arxiv.org/abs/2408.04785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04785">https://arxiv.org/pdf/2408.04785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04785]] BRAT: Bonus oRthogonAl Token for Architecture Agnostic Textual Inversion(https://arxiv.org/abs/2408.04785)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Textual Inversion remains a popular method for personalizing diffusion models, in order to teach models new subjects and styles. We note that textual inversion has been underexplored using alternatives to the UNet, and experiment with textual inversion with a vision transformer. We also seek to optimize textual inversion using a strategy that does not require explicit use of the UNet and its idiosyncratic layers, so we add bonus tokens and enforce orthogonality. We find the use of the bonus token improves adherence to the source images and the use of the vision transformer improves adherence to the prompt. Code is available at this https URL.</li>
</ul>

<h3>Title: SOD-YOLOv8 -- Enhancing YOLOv8 for Small Object Detection in Traffic Scenes</h3>
<ul>
<li><strong>Authors: </strong>Boshra Khalili, Andrew W.Smyth</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04786">https://arxiv.org/abs/2408.04786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04786">https://arxiv.org/pdf/2408.04786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04786]] SOD-YOLOv8 -- Enhancing YOLOv8 for Small Object Detection in Traffic Scenes(https://arxiv.org/abs/2408.04786)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Object detection as part of computer vision can be crucial for traffic management, emergency response, autonomous vehicles, and smart cities. Despite significant advances in object detection, detecting small objects in images captured by distant cameras remains challenging due to their size, distance from the camera, varied shapes, and cluttered backgrounds. To address these challenges, we propose Small Object Detection YOLOv8 (SOD-YOLOv8), a novel model specifically designed for scenarios involving numerous small objects. Inspired by Efficient Generalized Feature Pyramid Networks (GFPN), we enhance multi-path fusion within YOLOv8 to integrate features across different levels, preserving details from shallower layers and improving small object detection accuracy. Also, A fourth detection layer is added to leverage high-resolution spatial information effectively. The Efficient Multi-Scale Attention Module (EMA) in the C2f-EMA module enhances feature extraction by redistributing weights and prioritizing relevant features. We introduce Powerful-IoU (PIoU) as a replacement for CIoU, focusing on moderate-quality anchor boxes and adding a penalty based on differences between predicted and ground truth bounding box corners. This approach simplifies calculations, speeds up convergence, and enhances detection accuracy. SOD-YOLOv8 significantly improves small object detection, surpassing widely used models in various metrics, without substantially increasing computational cost or latency compared to YOLOv8s. Specifically, it increases recall from 40.1\% to 43.9\%, precision from 51.2\% to 53.9\%, $\text{mAP}_{0.5}$ from 40.6\% to 45.1\%, and $\text{mAP}_{0.5:0.95}$ from 24\% to 26.6\%. In dynamic real-world traffic scenes, SOD-YOLOv8 demonstrated notable improvements in diverse conditions, proving its reliability and effectiveness in detecting small objects even in challenging environments.</li>
</ul>

<h3>Title: FewShotNeRF: Meta-Learning-based Novel View Synthesis for Rapid Scene-Specific Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Piraveen Sivakumar, Paul Janson, Jathushan Rajasegaran, Thanuja Ambegoda</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04803">https://arxiv.org/abs/2408.04803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04803">https://arxiv.org/pdf/2408.04803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04803]] FewShotNeRF: Meta-Learning-based Novel View Synthesis for Rapid Scene-Specific Adaptation(https://arxiv.org/abs/2408.04803)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this paper, we address the challenge of generating novel views of real-world objects with limited multi-view images through our proposed approach, FewShotNeRF. Our method utilizes meta-learning to acquire optimal initialization, facilitating rapid adaptation of a Neural Radiance Field (NeRF) to specific scenes. The focus of our meta-learning process is on capturing shared geometry and textures within a category, embedded in the weight initialization. This approach expedites the learning process of NeRFs and leverages recent advancements in positional encodings to reduce the time required for fitting a NeRF to a scene, thereby accelerating the inner loop optimization of meta-learning. Notably, our method enables meta-learning on a large number of 3D scenes to establish a robust 3D prior for various categories. Through extensive evaluations on the Common Objects in 3D open source dataset, we empirically demonstrate the efficacy and potential of meta-learning in generating high-quality novel views of objects.</li>
</ul>

<h3>Title: Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation</h3>
<ul>
<li><strong>Authors: </strong>Yifan Feng, Jiangang Huang, Shaoyi Du, Shihui Ying, Jun-Hai Yong, Yipeng Li, Guiguang Ding, Rongrong Ji, Yue Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04804">https://arxiv.org/abs/2408.04804</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04804">https://arxiv.org/pdf/2408.04804</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04804]] Hyper-YOLO: When Visual Object Detection Meets Hypergraph Computation(https://arxiv.org/abs/2408.04804)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>We introduce Hyper-YOLO, a new object detection method that integrates hypergraph computations to capture the complex high-order correlations among visual features. Traditional YOLO models, while powerful, have limitations in their neck designs that restrict the integration of cross-level features and the exploitation of high-order feature interrelationships. To address these challenges, we propose the Hypergraph Computation Empowered Semantic Collecting and Scattering (HGC-SCS) framework, which transposes visual feature maps into a semantic space and constructs a hypergraph for high-order message propagation. This enables the model to acquire both semantic and structural information, advancing beyond conventional feature-focused learning. Hyper-YOLO incorporates the proposed Mixed Aggregation Network (MANet) in its backbone for enhanced feature extraction and introduces the Hypergraph-Based Cross-Level and Cross-Position Representation Network (HyperC2Net) in its neck. HyperC2Net operates across five scales and breaks free from traditional grid structures, allowing for sophisticated high-order interactions across levels and positions. This synergy of components positions Hyper-YOLO as a state-of-the-art architecture in various scale models, as evidenced by its superior performance on the COCO dataset. Specifically, Hyper-YOLO-N significantly outperforms the advanced YOLOv8-N and YOLOv9-T with 12\% $\text{AP}^{val}$ and 9\% $\text{AP}^{val}$ improvements. The source codes are at ttps://github.com/iMoonLab/Hyper-YOLO.</li>
</ul>

<h3>Title: h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment</h3>
<ul>
<li><strong>Authors: </strong>Moussa Koulako Bala Doumbouya, Ananjan Nandi, Gabriel Poesia, Davide Ghilardi, Anna Goldie, Federico Bianchi, Dan Jurafsky, Christopher D. Manning</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04811">https://arxiv.org/abs/2408.04811</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04811">https://arxiv.org/pdf/2408.04811</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04811]] h4rm3l: A Dynamic Benchmark of Composable Jailbreak Attacks for LLM Safety Assessment(https://arxiv.org/abs/2408.04811)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The safety of Large Language Models (LLMs) remains a critical concern due to a lack of adequate benchmarks for systematically evaluating their ability to resist generating harmful content. Previous efforts towards automated red teaming involve static or templated sets of illicit requests and adversarial prompts which have limited utility given jailbreak attacks' evolving and composable nature. We propose a novel dynamic benchmark of composable jailbreak attacks to move beyond static datasets and taxonomies of attacks and harms. Our approach consists of three components collectively called h4rm3l: (1) a domain-specific language that formally expresses jailbreak attacks as compositions of parameterized prompt transformation primitives, (2) bandit-based few-shot program synthesis algorithms that generate novel attacks optimized to penetrate the safety filters of a target black box LLM, and (3) open-source automated red-teaming software employing the previous two components. We use h4rm3l to generate a dataset of 2656 successful novel jailbreak attacks targeting 6 state-of-the-art (SOTA) open-source and proprietary LLMs. Several of our synthesized attacks are more effective than previously reported ones, with Attack Success Rates exceeding 90% on SOTA closed language models such as claude-3-haiku and GPT4-o. By generating datasets of jailbreak attacks in a unified formal representation, h4rm3l enables reproducible benchmarking and automated red-teaming, contributes to understanding LLM safety limitations, and supports the development of robust defenses in an increasingly LLM-integrated world. Warning: This paper and related research artifacts contain offensive and potentially disturbing prompts and model-generated content.</li>
</ul>

<h3>Title: FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers</h3>
<ul>
<li><strong>Authors: </strong>Joshua Nathaniel Williams, J. Zico Kolter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04816">https://arxiv.org/abs/2408.04816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04816">https://arxiv.org/pdf/2408.04816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04816]] FUSE-ing Language Models: Zero-Shot Adapter Discovery for Prompt Optimization Across Tokenizers(https://arxiv.org/abs/2408.04816)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The widespread use of large language models has resulted in a multitude of tokenizers and embedding spaces, making knowledge transfer in prompt discovery tasks difficult. In this work, we propose FUSE (Flexible Unification of Semantic Embeddings), an inexpensive approach to approximating an adapter layer that maps from one model's textual embedding space to another, even across different tokenizers. We introduce a third-order tensor-based representation of a model's embedding space that aligns semantic embeddings that have been split apart by different tokenizers, and use this representation to derive an approximation of the gradient of one model's outputs with respect to another model's embedding space. We show the efficacy of our approach via multi-objective optimization over vision-language and causal language models for image captioning and sentiment-based image captioning.</li>
</ul>

<h3>Title: Interventional Causal Structure Discovery over Graphical Models with Convergence and Optimality Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Qiu Chengbo, Yang Kai</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04819">https://arxiv.org/abs/2408.04819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04819">https://arxiv.org/pdf/2408.04819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04819]] Interventional Causal Structure Discovery over Graphical Models with Convergence and Optimality Guarantees(https://arxiv.org/abs/2408.04819)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Learning causal structure from sampled data is a fundamental problem with applications in various fields, including healthcare, machine learning and artificial intelligence. Traditional methods predominantly rely on observational data, but there exist limits regarding the identifiability of causal structures with only observational data. Interventional data, on the other hand, helps establish a cause-and-effect relationship by breaking the influence of confounding variables. It remains to date under-explored to develop a mathematical framework that seamlessly integrates both observational and interventional data in causal structure learning. Furthermore, existing studies often focus on centralized approaches, necessitating the transfer of entire datasets to a single server, which lead to considerable communication overhead and heightened risks to privacy. To tackle these challenges, we develop a bilevel polynomial optimization (Bloom) framework. Bloom not only provides a powerful mathematical modeling framework, underpinned by theoretical support, for causal structure discovery from both interventional and observational data, but also aspires to an efficient causal discovery algorithm with convergence and optimality guarantees. We further extend Bloom to a distributed setting to reduce the communication overhead and mitigate data privacy risks. It is seen through experiments on both synthetic and real-world datasets that Bloom markedly surpasses other leading learning algorithms.</li>
</ul>

<h3>Title: One Shot is Enough for Sequential Infrared Small Target Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Bingbing Dan, Meihui Li, Tao Tang, Jing Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04823">https://arxiv.org/abs/2408.04823</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04823">https://arxiv.org/pdf/2408.04823</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04823]] One Shot is Enough for Sequential Infrared Small Target Segmentation(https://arxiv.org/abs/2408.04823)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Infrared small target sequences exhibit strong similarities between frames and contain rich contextual information, which motivates us to achieve sequential infrared small target segmentation with minimal data. Inspired by the success of large segmentation models led by Segment Anything Model (SAM) across various downstream tasks, we propose a one-shot and training-free method that perfectly adapts SAM's zero-shot generalization capabilities to sequential infrared small target segmentation. Given one annotated frame as a reference, our method can accurately segment small targets in other frames of the sequence. Specifically, we first obtain a confidence map through local feature matching between reference image and test image. Then, the highest point in the confidence map is as a prompt, and we design the Point Prompt-Centric Focusing (PPCF) module to address the over-segmentation of small targets with blurry boundaries. Subsequently, to prevent miss and false detections, we introduce the Triple-Level Ensemble (TLE) module that ensembles the masks obtained at different levels from the first two steps to produce the final mask. Experiments demonstrate that our method requires only one shot to achieve comparable performance to state-of-the-art methods based on traditional many-shot supervision and even superior performance in a few-shot setting. Moreover, ablation studies confirm the robustness of our approach to variations in one-shot samples, changes in scenes, and the presence of multiple targets.</li>
</ul>

<h3>Title: Self-augmented Gaussian Splatting with Structure-aware Masks for Sparse-view 3D Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Lingbei Meng, Bi'an Du, Wei Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04831">https://arxiv.org/abs/2408.04831</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04831">https://arxiv.org/pdf/2408.04831</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04831]] Self-augmented Gaussian Splatting with Structure-aware Masks for Sparse-view 3D Reconstruction(https://arxiv.org/abs/2408.04831)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sparse-view 3D reconstruction stands as a formidable challenge in computer vision, aiming to build complete three-dimensional models from a limited array of viewing perspectives. This task confronts several difficulties: 1) the limited number of input images that lack consistent information; 2) dependence on the quality of input images; and 3) the substantial size of model parameters. To address these challenges, we propose a self-augmented coarse-to-fine Gaussian splatting paradigm, enhanced with a structure-aware mask, for sparse-view 3D reconstruction. In particular, our method initially employs a coarse Gaussian model to obtain a basic 3D representation from sparse-view inputs. Subsequently, we develop a fine Gaussian network to enhance consistent and detailed representation of the output with both 3D geometry augmentation and perceptual view augmentation. During training, we design a structure-aware masking strategy to further improve the model's robustness against sparse inputs and noise.Experimental results on the MipNeRF360 and OmniObject3D datasets demonstrate that the proposed method achieves state-of-the-art performances for sparse input views in both perceptual quality and efficiency.</li>
</ul>

<h3>Title: Dual-Channel Latent Factor Analysis Enhanced Graph Contrastive Learning for Recommendation</h3>
<ul>
<li><strong>Authors: </strong>Junfeng Long, Hao Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04838">https://arxiv.org/abs/2408.04838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04838">https://arxiv.org/pdf/2408.04838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04838]] Dual-Channel Latent Factor Analysis Enhanced Graph Contrastive Learning for Recommendation(https://arxiv.org/abs/2408.04838)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph Neural Networks (GNNs) are powerful learning methods for recommender systems owing to their robustness in handling complicated user-item interactions. Recently, the integration of contrastive learning with GNNs has demonstrated remarkable performance in recommender systems to handle the issue of highly sparse user-item interaction data. Yet, some available graph contrastive learning (GCL) techniques employ stochastic augmentation, i.e., nodes or edges are randomly perturbed on the user-item bipartite graph to construct contrastive views. Such a stochastic augmentation strategy not only brings noise perturbation but also cannot utilize global collaborative signals effectively. To address it, this study proposes a latent factor analysis (LFA) enhanced GCL approach, named LFA-GCL. Our model exclusively incorporates LFA to implement the unconstrained structural refinement, thereby obtaining an augmented global collaborative graph accurately without introducing noise signals. Experiments on four public datasets show that the proposed LFA-GCL outperforms the state-of-the-art models.</li>
</ul>

<h3>Title: Adversarially Robust Industrial Anomaly Detection Through Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Yuanpu Cao, Lu Lin, Jinghui Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04839">https://arxiv.org/abs/2408.04839</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04839">https://arxiv.org/pdf/2408.04839</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04839]] Adversarially Robust Industrial Anomaly Detection Through Diffusion Model(https://arxiv.org/abs/2408.04839)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Deep learning-based industrial anomaly detection models have achieved remarkably high accuracy on commonly used benchmark datasets. However, the robustness of those models may not be satisfactory due to the existence of adversarial examples, which pose significant threats to the practical deployment of deep anomaly detectors. Recently, it has been shown that diffusion models can be used to purify the adversarial noises and thus build a robust classifier against adversarial attacks. Unfortunately, we found that naively applying this strategy in anomaly detection (i.e., placing a purifier before an anomaly detector) will suffer from a high anomaly miss rate since the purifying process can easily remove both the anomaly signal and the adversarial perturbations, causing the later anomaly detector failed to detect anomalies. To tackle this issue, we explore the possibility of performing anomaly detection and adversarial purification simultaneously. We propose a simple yet effective adversarially robust anomaly detection method, \textit{AdvRAD}, that allows the diffusion model to act both as an anomaly detector and adversarial purifier. We also extend our proposed method for certified robustness to $l_2$ norm bounded perturbations. Through extensive experiments, we show that our proposed method exhibits outstanding (certified) adversarial robustness while also maintaining equally strong anomaly detection performance on par with the state-of-the-art methods on industrial anomaly detection benchmark datasets.</li>
</ul>

<h3>Title: mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiabo Ye, Haiyang Xu, Haowei Liu, Anwen Hu, Ming Yan, Qi Qian, Ji Zhang, Fei Huang, Jingren Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04840">https://arxiv.org/abs/2408.04840</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04840">https://arxiv.org/pdf/2408.04840</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04840]] mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models(https://arxiv.org/abs/2408.04840)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal Large Language Models (MLLMs) have demonstrated remarkable capabilities in executing instructions for a variety of single-image tasks. Despite this progress, significant challenges remain in modeling long image sequences. In this work, we introduce the versatile multi-modal large language model, mPLUG-Owl3, which enhances the capability for long image-sequence understanding in scenarios that incorporate retrieved image-text knowledge, interleaved image-text, and lengthy videos. Specifically, we propose novel hyper attention blocks to efficiently integrate vision and language into a common language-guided semantic space, thereby facilitating the processing of extended multi-image scenarios. Extensive experimental results suggest that mPLUG-Owl3 achieves state-of-the-art performance among models with a similar size on single-image, multi-image, and video benchmarks. Moreover, we propose a challenging long visual sequence evaluation named Distractor Resistance to assess the ability of models to maintain focus amidst distractions. Finally, with the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance on ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to the development of more efficient and powerful multimodal large language models.</li>
</ul>

<h3>Title: Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change</h3>
<ul>
<li><strong>Authors: </strong>Ignacy StÄpka, Mateusz Lango, Jerzy Stefanowski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04842">https://arxiv.org/abs/2408.04842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04842">https://arxiv.org/pdf/2408.04842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04842]] Counterfactual Explanations with Probabilistic Guarantees on their Robustness to Model Change(https://arxiv.org/abs/2408.04842)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Counterfactual explanations (CFEs) guide users on how to adjust inputs to machine learning models to achieve desired outputs. While existing research primarily addresses static scenarios, real-world applications often involve data or model changes, potentially invalidating previously generated CFEs and rendering user-induced input changes ineffective. Current methods addressing this issue often support only specific models or change types, require extensive hyperparameter tuning, or fail to provide probabilistic guarantees on CFE robustness to model changes. This paper proposes a novel approach for generating CFEs that provides probabilistic guarantees for any model and change type, while offering interpretable and easy-to-select hyperparameters. We establish a theoretical framework for probabilistically defining robustness to model change and demonstrate how our BetaRCE method directly stems from it. BetaRCE is a post-hoc method applied alongside a chosen base CFE generation method to enhance the quality of the explanation beyond robustness. It facilitates a transition from the base explanation to a more robust one with user-adjusted probability bounds. Through experimental comparisons with baselines, we show that BetaRCE yields robust, most plausible, and closest to baseline counterfactual explanations.</li>
</ul>

<h3>Title: Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture</h3>
<ul>
<li><strong>Authors: </strong>Kai Jiang, Honghao Yang, Yuexian Wang, Qianru Chen, Yiming Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04849">https://arxiv.org/abs/2408.04849</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04849">https://arxiv.org/pdf/2408.04849</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04849]] Ensemble BERT: A student social network text sentiment classification model based on ensemble learning and BERT architecture(https://arxiv.org/abs/2408.04849)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>The mental health assessment of middle school students has always been one of the focuses in the field of education. This paper introduces a new ensemble learning network based on BERT, employing the concept of enhancing model performance by integrating multiple classifiers. We trained a range of BERT-based learners, which combined using the majority voting method. We collect social network text data of middle school students through China's Weibo and apply the method to the task of classifying emotional tendencies in middle school students' social network texts. Experimental results suggest that the ensemble learning network has a better performance than the base model and the performance of the ensemble learning model, consisting of three single-layer BERT models, is barely the same as a three-layer BERT model but requires 11.58% more training time. Therefore, in terms of balancing prediction effect and efficiency, the deeper BERT network should be preferred for training. However, for interpretability, network ensembles can provide acceptable solutions.</li>
</ul>

<h3>Title: MSG-Chart: Multimodal Scene Graph for ChartQA</h3>
<ul>
<li><strong>Authors: </strong>Yue Dai, Soyeon Caren Han, Wei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04852">https://arxiv.org/abs/2408.04852</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04852">https://arxiv.org/pdf/2408.04852</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04852]] MSG-Chart: Multimodal Scene Graph for ChartQA(https://arxiv.org/abs/2408.04852)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Automatic Chart Question Answering (ChartQA) is challenging due to the complex distribution of chart elements with patterns of the underlying data not explicitly displayed in charts. To address this challenge, we design a joint multimodal scene graph for charts to explicitly represent the relationships between chart elements and their patterns. Our proposed multimodal scene graph includes a visual graph and a textual graph to jointly capture the structural and semantical knowledge from the chart. This graph module can be easily integrated with different vision transformers as inductive bias. Our experiments demonstrate that incorporating the proposed graph module enhances the understanding of charts' elements' structure and semantics, thereby improving performance on publicly available benchmarks, ChartQA and OpenCQA.</li>
</ul>

<h3>Title: An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Rui Cao, Qiao Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04867">https://arxiv.org/abs/2408.04867</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04867">https://arxiv.org/pdf/2408.04867</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04867]] An Evaluation of Standard Statistical Models and LLMs on Time Series Forecasting(https://arxiv.org/abs/2408.04867)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This research examines the use of Large Language Models (LLMs) in predicting time series, with a specific focus on the LLMTIME model. Despite the established effectiveness of LLMs in tasks such as text generation, language translation, and sentiment analysis, this study highlights the key challenges that large language models encounter in the context of time series prediction. We assess the performance of LLMTIME across multiple datasets and introduce classical almost periodic functions as time series to gauge its effectiveness. The empirical results indicate that while large language models can perform well in zero-shot forecasting for certain datasets, their predictive accuracy diminishes notably when confronted with diverse time series data and traditional signals. The primary finding of this study is that the predictive capacity of LLMTIME, similar to other LLMs, significantly deteriorates when dealing with time series data that contain both periodic and trend components, as well as when the signal comprises complex frequency components.</li>
</ul>

<h3>Title: ChatGPT Meets Iris Biometrics</h3>
<ul>
<li><strong>Authors: </strong>Parisa Farmanifard, Arun Ross</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04868">https://arxiv.org/abs/2408.04868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04868">https://arxiv.org/pdf/2408.04868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04868]] ChatGPT Meets Iris Biometrics(https://arxiv.org/abs/2408.04868)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, biometric, large language model</a></li>
<li><strong>Abstract: </strong>This study utilizes the advanced capabilities of the GPT-4 multimodal Large Language Model (LLM) to explore its potential in iris recognition - a field less common and more specialized than face recognition. By focusing on this niche yet crucial area, we investigate how well AI tools like ChatGPT can understand and analyze iris images. Through a series of meticulously designed experiments employing a zero-shot learning approach, the capabilities of ChatGPT-4 was assessed across various challenging conditions including diverse datasets, presentation attacks, occlusions such as glasses, and other real-world variations. The findings convey ChatGPT-4's remarkable adaptability and precision, revealing its proficiency in identifying distinctive iris features, while also detecting subtle effects like makeup on iris recognition. A comparative analysis with Gemini Advanced - Google's AI model - highlighted ChatGPT-4's better performance and user experience in complex iris analysis tasks. This research not only validates the use of LLMs for specialized biometric applications but also emphasizes the importance of nuanced query framing and interaction design in extracting significant insights from biometric data. Our findings suggest a promising path for future research and the development of more adaptable, efficient, robust and interactive biometric security solutions.</li>
</ul>

<h3>Title: ConfusedPilot: Compromising Enterprise Information Integrity and Confidentiality with Copilot for Microsoft 365</h3>
<ul>
<li><strong>Authors: </strong>Ayush RoyChowdhury, Mulong Luo, Prateek Sahu, Sarbartha Banerjee, Mohit Tiwari</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04870">https://arxiv.org/abs/2408.04870</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04870">https://arxiv.org/pdf/2408.04870</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04870]] ConfusedPilot: Compromising Enterprise Information Integrity and Confidentiality with Copilot for Microsoft 365(https://arxiv.org/abs/2408.04870)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval augmented generation (RAG) is a process where a large language model (LLM) retrieves useful information from a database and then generates the responses. It is becoming popular in enterprise settings for daily business operations. For example, Copilot for Microsoft 365 has accumulated millions of businesses. However, the security implications of adopting such RAG-based systems are unclear. In this paper, we introduce ConfusedPilot, a class of security vulnerabilities of RAG systems that confuse Copilot and cause integrity and confidentiality violations in its responses. First, we investigate a vulnerability that embeds malicious text in the modified prompt in RAG, corrupting the responses generated by the LLM. Second, we demonstrate a vulnerability that leaks secret data, which leverages the caching mechanism during retrieval. Third, we investigate how both vulnerabilities can be exploited to propagate misinformation within the enterprise and ultimately impact its operations, such as sales and manufacturing. We also discuss the root cause of these attacks by investigating the architecture of a RAG-based system. This study highlights the security vulnerabilities in today's RAG-based systems and proposes design guidelines to secure future RAG-based systems.</li>
</ul>

<h3>Title: SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation</h3>
<ul>
<li><strong>Authors: </strong>Chenming Tang, Zhixiang Wang, Yunfang Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04872">https://arxiv.org/abs/2408.04872</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04872">https://arxiv.org/pdf/2408.04872</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04872]] SCOI: Syntax-augmented Coverage-based In-context Example Selection for Machine Translation(https://arxiv.org/abs/2408.04872)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In-context learning (ICL) greatly improves the performance of large language models (LLMs) on various down-stream tasks, where the improvement highly depends on the quality of demonstrations. In this work, we introduce syntactic knowledge to select better in-context examples for machine translation (MT). We propose a new strategy, namely Syntax-augmented COverage-based In-context example selection (SCOI), leveraging the deep syntactic structure beyond conventional word matching. Specifically, we measure the set-level syntactic coverage by computing the coverage of polynomial terms with the help of a simplified tree-to-polynomial algorithm, and lexical coverage using word overlap. Furthermore, we devise an alternate selection approach to combine both coverage measures, taking advantage of syntactic and lexical information. We conduct experiments with two multi-lingual LLMs on six translation directions. Empirical results show that our proposed SCOI obtains the highest average COMET score among all learning-free methods, indicating that combining syntactic and lexical coverage successfully helps to select better in-context examples for MT.</li>
</ul>

<h3>Title: Unsupervised Episode Detection for Large-Scale News Events</h3>
<ul>
<li><strong>Authors: </strong>Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04873">https://arxiv.org/abs/2408.04873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04873">https://arxiv.org/pdf/2408.04873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04873]] Unsupervised Episode Detection for Large-Scale News Events(https://arxiv.org/abs/2408.04873)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Episodic structures are inherently interpretable and adaptable to evolving large-scale key events. However, state-of-the-art automatic event detection methods overlook event episodes and, therefore, struggle with these crucial characteristics. This paper introduces a novel task, episode detection, aimed at identifying episodes from a news corpus containing key event articles. An episode describes a cohesive cluster of core entities (e.g., "protesters", "police") performing actions at a specific time and location. Furthermore, an episode is a significant part of a larger group of episodes under a particular key event. Automatically detecting episodes is challenging because, unlike key events and atomic actions, we cannot rely on explicit mentions of times and locations to distinguish between episodes or use semantic similarity to merge inconsistent episode co-references. To address these challenges, we introduce EpiMine, an unsupervised episode detection framework that (1) automatically identifies the most salient, key-event-relevant terms and segments, (2) determines candidate episodes in an article based on natural episodic partitions estimated through shifts in discriminative term combinations, and (3) refines and forms final episode clusters using large language model-based reasoning on the candidate episodes. We construct three diverse, real-world event datasets annotated at the episode level. EpiMine outperforms all baselines on these datasets by an average 59.2% increase across all metrics.</li>
</ul>

<h3>Title: ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mengcheng Lan, Chaofeng Chen, Yiping Ke, Xinjiang Wang, Litong Feng, Wayne Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04883">https://arxiv.org/abs/2408.04883</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04883">https://arxiv.org/pdf/2408.04883</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04883]] ProxyCLIP: Proxy Attention Improves CLIP for Open-Vocabulary Segmentation(https://arxiv.org/abs/2408.04883)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Open-vocabulary semantic segmentation requires models to effectively integrate visual representations with open-vocabulary semantic labels. While Contrastive Language-Image Pre-training (CLIP) models shine in recognizing visual concepts from text, they often struggle with segment coherence due to their limited localization ability. In contrast, Vision Foundation Models (VFMs) excel at acquiring spatially consistent local visual representations, yet they fall short in semantic understanding. This paper introduces ProxyCLIP, an innovative framework designed to harmonize the strengths of both CLIP and VFMs, facilitating enhanced open-vocabulary semantic segmentation. ProxyCLIP leverages the spatial feature correspondence from VFMs as a form of proxy attention to augment CLIP, thereby inheriting the VFMs' robust local consistency and maintaining CLIP's exceptional zero-shot transfer capacity. We propose an adaptive normalization and masking strategy to get the proxy attention from VFMs, allowing for adaptation across different VFMs. Remarkably, as a training-free approach, ProxyCLIP significantly improves the average mean Intersection over Union (mIoU) across eight benchmarks from 40.3 to 44.4, showcasing its exceptional efficacy in bridging the gap between spatial precision and semantic richness for the open-vocabulary segmentation task.</li>
</ul>

<h3>Title: GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhibo Zhang, Wuxia Bai, Yuxi Li, Mark Huasong Meng, Kailong Wang, Ling Shi, Li Li, Jun Wang, Haoyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04905">https://arxiv.org/abs/2408.04905</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04905">https://arxiv.org/pdf/2408.04905</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04905]] GlitchProber: Advancing Effective Detection and Mitigation of Glitch Tokens in Large Language Models(https://arxiv.org/abs/2408.04905)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved unprecedented success in the field of natural language processing. However, the black-box nature of their internal mechanisms has brought many concerns about their trustworthiness and interpretability. Recent research has discovered a class of abnormal tokens in the model's vocabulary space and named them "glitch tokens". Those tokens, once included in the input, may induce the model to produce incorrect, irrelevant, or even harmful results, drastically undermining the reliability and practicality of LLMs. In this work, we aim to enhance the understanding of glitch tokens and propose techniques for their detection and mitigation. We first reveal the characteristic features induced by glitch tokens on LLMs, which are evidenced by significant deviations in the distributions of attention patterns and dynamic information from intermediate model layers. Based on the insights, we develop GlitchProber, a tool for efficient glitch token detection and mitigation. GlitchProber utilizes small-scale sampling, principal component analysis for accelerated feature extraction, and a simple classifier for efficient vocabulary screening. Taking one step further, GlitchProber rectifies abnormal model intermediate layer values to mitigate the destructive effects of glitch tokens. Evaluated on five mainstream open-source LLMs, GlitchProber demonstrates higher efficiency, precision, and recall compared to existing approaches, with an average F1 score of 0.86 and an average repair rate of 50.06%. GlitchProber unveils a novel path to address the challenges posed by glitch tokens and inspires future research toward more robust and interpretable LLMs.</li>
</ul>

<h3>Title: Towards a Generative Approach for Emotion Detection and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ankita Bhaumik, Tomek Strzalkowski</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04906">https://arxiv.org/abs/2408.04906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04906">https://arxiv.org/pdf/2408.04906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04906]] Towards a Generative Approach for Emotion Detection and Reasoning(https://arxiv.org/abs/2408.04906)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated impressive performance in mathematical and commonsense reasoning tasks using chain-of-thought (CoT) prompting techniques. But can they perform emotional reasoning by concatenating `Let's think step-by-step' to the input prompt? In this paper we investigate this question along with introducing a novel approach to zero-shot emotion detection and emotional reasoning using LLMs. Existing state of the art zero-shot approaches rely on textual entailment models to choose the most appropriate emotion label for an input text. We argue that this strongly restricts the model to a fixed set of labels which may not be suitable or sufficient for many applications where emotion analysis is required. Instead, we propose framing the problem of emotion analysis as a generative question-answering (QA) task. Our approach uses a two step methodology of generating relevant context or background knowledge to answer the emotion detection question step-by-step. Our paper is the first work on using a generative approach to jointly address the tasks of emotion detection and emotional reasoning for texts. We evaluate our approach on two popular emotion detection datasets and also release the fine-grained emotion labels and explanations for further training and fine-tuning of emotional reasoning systems.</li>
</ul>

<h3>Title: GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data Guide Unlabeled Data</h3>
<ul>
<li><strong>Authors: </strong>Haochen Zhao, Hui Meng, Deqian Yang, Xiaozheng Xie, Xiaoze Wu, Qingfeng Li, Jianwei Niu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04914">https://arxiv.org/abs/2408.04914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04914">https://arxiv.org/pdf/2408.04914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04914]] GuidedNet: Semi-Supervised Multi-Organ Segmentation via Labeled Data Guide Unlabeled Data(https://arxiv.org/abs/2408.04914)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised multi-organ medical image segmentation aids physicians in improving disease diagnosis and treatment planning and reduces the time and effort required for organ annotation.Existing state-of-the-art methods train the labeled data with ground truths and train the unlabeled data with pseudo-labels. However, the two training flows are separate, which does not reflect the interrelationship between labeled and unlabeled this http URL address this issue, we propose a semi-supervised multi-organ segmentation method called GuidedNet, which leverages the knowledge from labeled data to guide the training of unlabeled data. The primary goals of this study are to improve the quality of pseudo-labels for unlabeled data and to enhance the network's learning capability for both small and complex organs.A key concept is that voxel features from labeled and unlabeled data that are close to each other in the feature space are more likely to belong to the same class.On this basis, a 3D Consistent Gaussian Mixture Model (3D-CGMM) is designed to leverage the feature distributions from labeled data to rectify the generated pseudo-labels.Furthermore, we introduce a Knowledge Transfer Cross Pseudo Supervision (KT-CPS) strategy, which leverages the prior knowledge obtained from the labeled data to guide the training of the unlabeled data, thereby improving the segmentation accuracy for both small and complex organs. Extensive experiments on two public datasets, FLARE22 and AMOS, demonstrated that GuidedNet is capable of achieving state-of-the-art performance.</li>
</ul>

<h3>Title: PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba</h3>
<ul>
<li><strong>Authors: </strong>Yan Lin, Yichen Liu, Zeyu Zhou, Haomin Wen, Erwen Zheng, Shengnan Guo, Youfang Lin, Huaiyu Wan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04916">https://arxiv.org/abs/2408.04916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04916">https://arxiv.org/pdf/2408.04916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04916]] PTrajM: Efficient and Semantic-rich Trajectory Learning with Pretrained Trajectory-Mamba(https://arxiv.org/abs/2408.04916)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Vehicle trajectories provide crucial movement information for various real-world applications. To better utilize vehicle trajectories, it is essential to develop a trajectory learning approach that can effectively and efficiently extract rich semantic information, including movement behavior and travel purposes, to support accurate downstream applications. However, creating such an approach presents two significant challenges. First, movement behavior are inherently spatio-temporally continuous, making them difficult to extract efficiently from irregular and discrete trajectory points. Second, travel purposes are related to the functionalities of areas and road segments traversed by vehicles. These functionalities are not available from the raw spatio-temporal trajectory features and are hard to extract directly from complex textual features associated with these areas and road segments. To address these challenges, we propose PTrajM, a novel method capable of efficient and semantic-rich vehicle trajectory learning. To support efficient modeling of movement behavior, we introduce Trajectory-Mamba as the learnable model of PTrajM, which effectively extracts continuous movement behavior while being more computationally efficient than existing structures. To facilitate efficient extraction of travel purposes, we propose a travel purpose-aware pre-training procedure, which enables PTrajM to discern the travel purposes of trajectories without additional computational resources during its embedding process. Extensive experiments on two real-world datasets and comparisons with several state-of-the-art trajectory learning methods demonstrate the effectiveness of PTrajM. Code is available at https://anonymous.4open.science/r/PTrajM-C973.</li>
</ul>

<h3>Title: Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data</h3>
<ul>
<li><strong>Authors: </strong>Ren Ozeki, Haruki Yonekura, Hamada Rizk, Hirozumi Yamaguchi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04931">https://arxiv.org/abs/2408.04931</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04931">https://arxiv.org/pdf/2408.04931</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04931]] Privacy-Preserved Taxi Demand Prediction System Utilizing Distributed Data(https://arxiv.org/abs/2408.04931)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, federate</a></li>
<li><strong>Abstract: </strong>Accurate taxi-demand prediction is essential for optimizing taxi operations and enhancing urban transportation services. However, using customers' data in these systems raises significant privacy and security concerns. Traditional federated learning addresses some privacy issues by enabling model training without direct data exchange but often struggles with accuracy due to varying data distributions across different regions or service providers. In this paper, we propose CC-Net: a novel approach using collaborative learning enhanced with contrastive learning for taxi-demand prediction. Our method ensures high performance by enabling multiple parties to collaboratively train a demand-prediction model through hierarchical federated learning. In this approach, similar parties are clustered together, and federated learning is applied within each cluster. The similarity is defined without data exchange, ensuring privacy and security. We evaluated our approach using real-world data from five taxi service providers in Japan over fourteen months. The results demonstrate that CC-Net maintains the privacy of customers' data while improving prediction accuracy by at least 2.2% compared to existing techniques.</li>
</ul>

<h3>Title: Demystifying and Detecting Cryptographic Defects in Ethereum Smart Contracts</h3>
<ul>
<li><strong>Authors: </strong>Jiashuo Zhang, Yiming Shen, Jiachi Chen, Jianzhong Su, Yanlin Wang, Ting Chen, Jianbo Gao, Zhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04939">https://arxiv.org/abs/2408.04939</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04939">https://arxiv.org/pdf/2408.04939</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04939]] Demystifying and Detecting Cryptographic Defects in Ethereum Smart Contracts(https://arxiv.org/abs/2408.04939)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Ethereum has officially provided a set of system-level cryptographic APIs to enhance smart contracts with cryptographic capabilities. These APIs have been utilized in over 10% of Ethereum transactions, motivating developers to implement various on-chain cryptographic tasks, such as digital signatures. However, since developers may not always be cryptographic experts, their ad-hoc and potentially defective implementations could compromise the theoretical guarantees of cryptography, leading to real-world security issues. To mitigate this threat, we conducted the first study aimed at demystifying and detecting cryptographic defects in smart contracts. Through the analysis of 2,406 real-world security reports, we defined nine types of cryptographic defects in smart contracts with detailed descriptions and practical detection patterns. Based on this categorization, we proposed CrySol, a fuzzing-based tool to automate the detection of cryptographic defects in smart contracts. It combines transaction replaying and dynamic taint analysis to extract fine-grained crypto-related semantics and employs crypto-specific strategies to guide the test case generation process. Furthermore, we collected a large-scale dataset containing 25,745 real-world crypto-related smart contracts and evaluated CrySol's effectiveness on it. The result demonstrated that CrySol achieves an overall precision of 95.4% and a recall of 91.2%. Notably, CrySol revealed that 5,847 (22.7%) out of 25,745 smart contracts contain at least one cryptographic defect, highlighting the prevalence of these defects.</li>
</ul>

<h3>Title: Quantitative Information Extraction from Humanitarian Documents</h3>
<ul>
<li><strong>Authors: </strong>Daniele Liberatore, Kyriaki Kalimeri, Derya Sever, Yelena Mejova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04941">https://arxiv.org/abs/2408.04941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04941">https://arxiv.org/pdf/2408.04941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04941]] Quantitative Information Extraction from Humanitarian Documents(https://arxiv.org/abs/2408.04941)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Humanitarian action is accompanied by a mass of reports, summaries, news, and other documents. To guide its activities, important information must be quickly extracted from such free-text resources. Quantities, such as the number of people affected, amount of aid distributed, or the extent of infrastructure damage, are central to emergency response and anticipatory action. In this work, we contribute an annotated dataset for the humanitarian domain for the extraction of such quantitative information, along side its important context, including units it refers to, any modifiers, and the relevant event. Further, we develop a custom Natural Language Processing pipeline to extract the quantities alongside their units, and evaluate it in comparison to baseline and recent literature. The proposed model achieves a consistent improvement in the performance, especially in the documents pertaining to the Dominican Republic and select African countries. We make the dataset and code available to the research community to continue the improvement of NLP tools for the humanitarian domain.</li>
</ul>

<h3>Title: HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction</h3>
<ul>
<li><strong>Authors: </strong>Bhaskarjit Sarmah, Benika Hall, Rohan Rao, Sunil Patel, Stefano Pasquali, Dhagash Mehta</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, q-fin.ST, stat.AP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04948">https://arxiv.org/abs/2408.04948</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04948">https://arxiv.org/pdf/2408.04948</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04948]] HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction(https://arxiv.org/abs/2408.04948)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain</li>
</ul>

<h3>Title: Model Debiasing by Learnable Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Pietro Morerio, Ruggero Ragonesi, Vittorio Murino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04955">https://arxiv.org/abs/2408.04955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04955">https://arxiv.org/pdf/2408.04955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04955]] Model Debiasing by Learnable Data Augmentation(https://arxiv.org/abs/2408.04955)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep Neural Networks are well known for efficiently fitting training data, yet experiencing poor generalization capabilities whenever some kind of bias dominates over the actual task labels, resulting in models learning "shortcuts". In essence, such models are often prone to learn spurious correlations between data and labels. In this work, we tackle the problem of learning from biased data in the very realistic unsupervised scenario, i.e., when the bias is unknown. This is a much harder task as compared to the supervised case, where auxiliary, bias-related annotations, can be exploited in the learning process. This paper proposes a novel 2-stage learning pipeline featuring a data augmentation strategy able to regularize the training. First, biased/unbiased samples are identified by training over-biased models. Second, such subdivision (typically noisy) is exploited within a data augmentation framework, properly combining the original samples while learning mixing parameters, which has a regularization effect. Experiments on synthetic and realistic biased datasets show state-of-the-art classification accuracy, outperforming competing methods, ultimately proving robust performance on both biased and unbiased examples. Notably, being our training method totally agnostic to the level of bias, it also positively affects performance for any, even apparently unbiased, dataset, thus improving the model generalization regardless of the level of bias (or its absence) in the data.</li>
</ul>

<h3>Title: LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description</h3>
<ul>
<li><strong>Authors: </strong>Yizhang Jin, Jian Li, Jiangning Zhang, Jianlong Hu, Zhenye Gan, Xin Tan, Yong Liu, Yabiao Wang, Chengjie Wang, Lizhuang Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04957">https://arxiv.org/abs/2408.04957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04957">https://arxiv.org/pdf/2408.04957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04957]] LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description(https://arxiv.org/abs/2408.04957)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Visual Spatial Description (VSD) aims to generate texts that describe the spatial relationships between objects within images. Traditional visual spatial relationship classification (VSRC) methods typically output the spatial relationship between two objects in an image, often neglecting world knowledge and lacking general language capabilities. In this paper, we propose a Large Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD, which is designed for the classification, description, and open-ended description of visual spatial relationships. Specifically, the model first constructs a VSD instruction-following dataset using given figure-caption pairs for the three tasks. It then employs LoRA to fine-tune a Large Language and Vision Assistant for VSD, which has 13 billion parameters and supports high-resolution images. Finally, a large language model (Qwen-2) is used to refine the generated sentences, enhancing their diversity and accuracy. LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can follow open-ended instructions to assist with inquiries about object relationships in images.</li>
</ul>

<h3>Title: Surgical-VQLA++: Adversarial Contrastive Learning for Calibrated Robust Visual Question-Localized Answering in Robotic Surgery</h3>
<ul>
<li><strong>Authors: </strong>Long Bai, Guankun Wang, Mobarakol Islam, Lalithkumar Seenivasan, An Wang, Hongliang Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04958">https://arxiv.org/abs/2408.04958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04958">https://arxiv.org/pdf/2408.04958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04958]] Surgical-VQLA++: Adversarial Contrastive Learning for Calibrated Robust Visual Question-Localized Answering in Robotic Surgery(https://arxiv.org/abs/2408.04958)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Medical visual question answering (VQA) bridges the gap between visual information and clinical decision-making, enabling doctors to extract understanding from clinical images and videos. In particular, surgical VQA can enhance the interpretation of surgical data, aiding in accurate diagnoses, effective education, and clinical interventions. However, the inability of VQA models to visually indicate the regions of interest corresponding to the given questions results in incomplete comprehension of the surgical scene. To tackle this, we propose the surgical visual question localized-answering (VQLA) for precise and context-aware responses to specific queries regarding surgical images. Furthermore, to address the strong demand for safety in surgical scenarios and potential corruptions in image acquisition and transmission, we propose a novel approach called Calibrated Co-Attention Gated Vision-Language (C$^2$G-ViL) embedding to integrate and align multimodal information effectively. Additionally, we leverage the adversarial sample-based contrastive learning strategy to boost our performance and robustness. We also extend our EndoVis-18-VQLA and EndoVis-17-VQLA datasets to broaden the scope and application of our data. Extensive experiments on the aforementioned datasets demonstrate the remarkable performance and robustness of our solution. Our solution can effectively combat real-world image corruption. Thus, our proposed approach can serve as an effective tool for assisting surgical education, patient care, and enhancing surgical outcomes.</li>
</ul>

<h3>Title: In Defense of Lazy Visual Grounding for Open-Vocabulary Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Dahyun Kang, Minsu Cho</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04961">https://arxiv.org/abs/2408.04961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04961">https://arxiv.org/pdf/2408.04961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04961]] In Defense of Lazy Visual Grounding for Open-Vocabulary Semantic Segmentation(https://arxiv.org/abs/2408.04961)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, segmentation</a></li>
<li><strong>Abstract: </strong>We present lazy visual grounding, a two-stage approach of unsupervised object mask discovery followed by object grounding, for open-vocabulary semantic segmentation. Plenty of the previous art casts this task as pixel-to-text classification without object-level comprehension, leveraging the image-to-text classification capability of pretrained vision-and-language models. We argue that visual objects are distinguishable without the prior text information as segmentation is essentially a vision task. Lazy visual grounding first discovers object masks covering an image with iterative Normalized cuts and then later assigns text on the discovered objects in a late interaction manner. Our model requires no additional training yet shows great performance on five public datasets: Pascal VOC, Pascal Context, COCO-object, COCO-stuff, and ADE 20K. Especially, the visually appealing segmentation results demonstrate the model capability to localize objects precisely. Paper homepage: this https URL</li>
</ul>

<h3>Title: DAFT-GAN: Dual Affine Transformation Generative Adversarial Network for Text-Guided Image Inpainting</h3>
<ul>
<li><strong>Authors: </strong>Jihoon Lee, Yunhong Min, Hwidong Kim, Sangtae Ahn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04962">https://arxiv.org/abs/2408.04962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04962">https://arxiv.org/pdf/2408.04962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04962]] DAFT-GAN: Dual Affine Transformation Generative Adversarial Network for Text-Guided Image Inpainting(https://arxiv.org/abs/2408.04962)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In recent years, there has been a significant focus on research related to text-guided image inpainting. However, the task remains challenging due to several constraints, such as ensuring alignment between the image and the text, and maintaining consistency in distribution between corrupted and uncorrupted regions. In this paper, thus, we propose a dual affine transformation generative adversarial network (DAFT-GAN) to maintain the semantic consistency for text-guided inpainting. DAFT-GAN integrates two affine transformation networks to combine text and image features gradually for each decoding block. Moreover, we minimize information leakage of uncorrupted features for fine-grained image generation by encoding corrupted and uncorrupted regions of the masked image separately. Our proposed model outperforms the existing GAN-based models in both qualitative and quantitative assessments with three benchmark datasets (MS-COCO, CUB, and Oxford) for text-guided image inpainting.</li>
</ul>

<h3>Title: LiD-FL: Towards List-Decodable Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Hong Liu, Liren Shan, Han Bao, Ronghui You, Yuhao Yi, Jiancheng Lv</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04963">https://arxiv.org/abs/2408.04963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04963">https://arxiv.org/pdf/2408.04963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04963]] LiD-FL: Towards List-Decodable Federated Learning(https://arxiv.org/abs/2408.04963)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is often used in environments with many unverified participants. Therefore, federated learning under adversarial attacks receives significant attention. This paper proposes an algorithmic framework for list-decodable federated learning, where a central server maintains a list of models, with at least one guaranteed to perform well. The framework has no strict restriction on the fraction of honest workers, extending the applicability of Byzantine federated learning to the scenario with more than half adversaries. Under proper assumptions on the loss function, we prove a convergence theorem for our method. Experimental results, including image classification tasks with both convex and non-convex losses, demonstrate that the proposed algorithm can withstand the malicious majority under various attacks.</li>
</ul>

<h3>Title: Towards aerodynamic surrogate modeling based on $\beta$-variational autoencoders</h3>
<ul>
<li><strong>Authors: </strong>VÃ­ctor FrancÃ©s-Belda, Alberto Solera-Rico, Javier Nieto-Centenero, Esther AndrÃ©s, Carlos Sanmiguel Vila, Rodrigo Castellanos</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04969">https://arxiv.org/abs/2408.04969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04969">https://arxiv.org/pdf/2408.04969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04969]] Towards aerodynamic surrogate modeling based on $\beta$-variational autoencoders(https://arxiv.org/abs/2408.04969)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Surrogate models combining dimensionality reduction and regression techniques are essential to reduce the need for costly high-fidelity CFD data. New approaches using $\beta$-Variational Autoencoder ($\beta$-VAE) architectures have shown promise in obtaining high-quality low-dimensional representations of high-dimensional flow data while enabling physical interpretation of their latent spaces. We propose a surrogate model based on latent space regression to predict pressure distributions on a transonic wing given the flight conditions: Mach number and angle of attack. The $\beta$-VAE model, enhanced with Principal Component Analysis (PCA), maps high-dimensional data to a low-dimensional latent space, showing a direct correlation with flight conditions. Regularization through $\beta$ requires careful tuning to improve the overall performance, while PCA pre-processing aids in constructing an effective latent space, improving autoencoder training and performance. Gaussian Process Regression is used to predict latent space variables from flight conditions, showing robust behavior independent of $\beta$, and the decoder reconstructs the high-dimensional pressure field data. This pipeline provides insight into unexplored flight conditions. Additionally, a fine-tuning process of the decoder further refines the model, reducing dependency on $\beta$ and enhancing accuracy. The structured latent space, robust regression performance, and significant improvements from fine-tuning collectively create a highly accurate and efficient surrogate model. Our methodology demonstrates the effectiveness of $\beta$-VAEs for aerodynamic surrogate modeling, offering a rapid, cost-effective, and reliable alternative for aerodynamic data prediction.</li>
</ul>

<h3>Title: XNN: Paradigm Shift in Mitigating Identity Leakage within Cloud-Enabled Deep Learning</h3>
<ul>
<li><strong>Authors: </strong>Kaixin Liu, Huixin Xiong, Bingyu Duan, Zexuan Cheng, Xinyu Zhou, Wanqian Zhang, Xiangyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04974">https://arxiv.org/abs/2408.04974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04974">https://arxiv.org/pdf/2408.04974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04974]] XNN: Paradigm Shift in Mitigating Identity Leakage within Cloud-Enabled Deep Learning(https://arxiv.org/abs/2408.04974)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, extraction, generative</a></li>
<li><strong>Abstract: </strong>In the domain of cloud-based deep learning, the imperative for external computational resources coexists with acute privacy concerns, particularly identity leakage. To address this challenge, we introduce XNN and XNN-d, pioneering methodologies that infuse neural network features with randomized perturbations, striking a harmonious balance between utility and privacy. XNN, designed for the training phase, ingeniously blends random permutation with matrix multiplication techniques to obfuscate feature maps, effectively shielding private data from potential breaches without compromising training integrity. Concurrently, XNN-d, devised for the inference phase, employs adversarial training to integrate generative adversarial noise. This technique effectively counters black-box access attacks aimed at identity extraction, while a distilled face recognition network adeptly processes the perturbed features, ensuring accurate identification. Our evaluation demonstrates XNN's effectiveness, significantly outperforming existing methods in reducing identity leakage while maintaining a high model accuracy.</li>
</ul>

<h3>Title: Exploiting the Lock: Leveraging MiG-V's Logic Locking for Secret-Data Extraction</h3>
<ul>
<li><strong>Authors: </strong>Lennart M. Reimann, Yadu Madhukumar Variyar, Lennet Huelser, Chiara Ghinami, Dominik Germek, Rainer Leupers</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04976">https://arxiv.org/abs/2408.04976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04976">https://arxiv.org/pdf/2408.04976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04976]] Exploiting the Lock: Leveraging MiG-V's Logic Locking for Secret-Data Extraction(https://arxiv.org/abs/2408.04976)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect, attack, extraction</a></li>
<li><strong>Abstract: </strong>The MiG-V was designed for high-security applications and is the first commercially available logic-locked RISC-V processor on the market. In this context logic locking was used to protect the RISC-V processor design during the untrusted manufacturing process by using key-driven logic gates to obfuscate the original design. Although this method defends against malicious modifications, such as hardware Trojans, logic locking's impact on the RISC-V processor's data confidentiality during runtime has not been thoroughly examined. In this study, we evaluate the impact of logic locking on data confidentiality. By altering the logic locking key of the MiG-V while running SSL cryptographic algorithms, we identify data leakages resulting from the exploitation of the logic locking hardware. We show that changing a single bit of the logic locking key can expose 100% of the cryptographic encryption key. This research reveals a critical security flaw in logic locking, highlighting the need for comprehensive security assessments beyond logic locking key-recovery attacks.</li>
</ul>

<h3>Title: Conceptual Design and Implementation of FIDO2 compatible Smart Card for Decentralized Financial Transaction System</h3>
<ul>
<li><strong>Authors: </strong>Anisha Ghosh, Aditya Mitra, Sibi Chakkaravarthy Sethuraman, Aswani Kumar Cherukuri</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04977">https://arxiv.org/abs/2408.04977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04977">https://arxiv.org/pdf/2408.04977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04977]] Conceptual Design and Implementation of FIDO2 compatible Smart Card for Decentralized Financial Transaction System(https://arxiv.org/abs/2408.04977)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>With challenges and limitations associated with security in the fintech industry, the rise to the need for data protection increases. However, the current existing passwordless and password-based peer to peer transactions in online banking systems are vulnerable to advanced forms of digital attacks. The influx of modern data protection methods keeps better records of the transactions, but it still does not address the issue of authentication and account takeovers during transactions. To the address the mentioned issue, this paper proposes a novel and robust peer to peer transaction system which employs best cloud security practices, proper use of cryptography and trusted computing to mitigate common vulnerabilities. We will be implementing FIDO2 compatible Smart Card to securely authenticate the user using physical smart cards and store the records in the cloud which enables access control by allowing access only when an access is requested. The standard incorporates multiple layers of security on cloud computing models to ensure secrecy of the said data. Services of the standard adhere to regulations provides by the government and assures privacy to the information of the payee or the end-user. The whole system has been implemented in the Internet of Things scenario.</li>
</ul>

<h3>Title: Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization</h3>
<ul>
<li><strong>Authors: </strong>Zhaohan Zhang, Ziquan Liu, Ioannis Patras</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04983">https://arxiv.org/abs/2408.04983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04983">https://arxiv.org/pdf/2408.04983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04983]] Get Confused Cautiously: Textual Sequence Memorization Erasure with Selective Entropy Maximization(https://arxiv.org/abs/2408.04983)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been found to memorize and recite some of the textual sequences from their training set verbatim, raising broad concerns about privacy and copyright issues when using LLMs. This Textual Sequence Memorization (TSM) phenomenon leads to a high demand to regulate LLM output to prevent it from generating certain memorized text to meet user requirements. However, our empirical study reveals that existing methods for TSM erasure fail to forget massive memorized samples without substantially jeopardizing the model utility. To achieve a better trade-off between the effectiveness of TSM erasure and model utility in LLMs, our paper proposes a new framework based on Entropy Maximization with Selective Optimization (EMSO), where the updated weights are chosen with a novel contrastive gradient metric without any participation of additional model or data. Our analysis shows that training with the entropy maximization loss has a more stable optimization process and better keeps model utility than existing methods. The contrastive gradient metric localizes the most influential weight for TSM erasure by taking both the gradient magnitude and direction into consideration. Extensive experiments across three model scales demonstrate that our method excels in handling large-scale forgetting requests while preserving model ability in language generation and reasoning.</li>
</ul>

<h3>Title: ProFuser: Progressive Fusion of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tianyuan Shi, Fanqi Wan, Canbin Huang, Xiaojun Quan, Chenliang Li, Ming Yan, Ji Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.04998">https://arxiv.org/abs/2408.04998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.04998">https://arxiv.org/pdf/2408.04998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.04998]] ProFuser: Progressive Fusion of Large Language Models(https://arxiv.org/abs/2408.04998)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While fusing the capacities and advantages of various large language models (LLMs) offers a pathway to construct more powerful and versatile models, a fundamental challenge is to properly select advantageous model during the training. Existing fusion methods primarily focus on the training mode that uses cross entropy on ground truth in a teacher-forcing setup to measure a model's advantage, which may provide limited insight towards model advantage. In this paper, we introduce a novel approach that enhances the fusion process by incorporating both the training and inference modes. Our method evaluates model advantage not only through cross entropy during training but also by considering inference outputs, providing a more comprehensive assessment. To combine the two modes effectively, we introduce ProFuser to progressively transition from inference mode to training mode. To validate ProFuser's effectiveness, we fused three models, including vicuna-7b-v1.5, Llama-2-7b-chat, and mpt-7b-8k-chat, and demonstrated the improved performance in knowledge, reasoning, and safety compared to baseline methods.</li>
</ul>

<h3>Title: A Formal Approach For Modelling And Analysing Surgical Procedures (Extended Version)</h3>
<ul>
<li><strong>Authors: </strong>Ioana Sandu, Rita Borgo, Prokar Dasgupta, Ramesh Thurairaja, Luca ViganÃ²</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05001">https://arxiv.org/abs/2408.05001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05001">https://arxiv.org/pdf/2408.05001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05001]] A Formal Approach For Modelling And Analysing Surgical Procedures (Extended Version)(https://arxiv.org/abs/2408.05001)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Surgical procedures are often not "standardised" (i.e., defined in a unique and unambiguous way), but rather exist as implicit knowledge in the minds of the surgeon and the surgical team. This reliance extends to pre-surgery planning and effective communication during the procedure. We introduce a novel approach for the formal and automated analysis of surgical procedures, which we model as security ceremonies, leveraging well-established techniques developed for the analysis of such ceremonies. Mutations of a procedure are used to model variants and mistakes that members of the surgical team might make. Our approach allows us to automatically identify violations of the intended properties of a surgical procedure.</li>
</ul>

<h3>Title: DreamCouple: Exploring High Quality Text-to-3D Generation Via Rectified Flow</h3>
<ul>
<li><strong>Authors: </strong>Hangyu Li, Xiangxiang Chu, Dingyuan Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05008">https://arxiv.org/abs/2408.05008</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05008">https://arxiv.org/pdf/2408.05008</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05008]] DreamCouple: Exploring High Quality Text-to-3D Generation Via Rectified Flow(https://arxiv.org/abs/2408.05008)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The Score Distillation Sampling (SDS), which exploits pretrained text-to-image model diffusion models as priors to 3D model training, has achieved significant success. Currently, the flow-based diffusion model has become a new trend for generations. Yet, adapting SDS to flow-based diffusion models in 3D generation remains unexplored. Our work is aimed to bridge this gap. In this paper, we adapt SDS to rectified flow and re-examine the over-smoothing issue under this novel framework. The issue can be explained that the model learns an average of multiple ODE trajectories. Then we propose DreamCouple, which instead of randomly sampling noise, uses a rectified flow model to find the coupled noise. Its Unique Couple Matching (UCM) loss guides the model to learn different trajectories and thus solves the over-smoothing issue. We apply our method to both NeRF and 3D Gaussian splatting and achieve state-of-the-art performances. We also identify some other interesting open questions such as initialization issues for NeRF and faster training convergence. Our code will be released soon.</li>
</ul>

<h3>Title: Instruction Tuning-free Visual Token Complement for Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Dongsheng Wang, Jiequan Cui, Miaoge Li, Wang Lin, Bo Chen, Hanwang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05019">https://arxiv.org/abs/2408.05019</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05019">https://arxiv.org/pdf/2408.05019</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05019]] Instruction Tuning-free Visual Token Complement for Multimodal LLMs(https://arxiv.org/abs/2408.05019)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As the open community of large language models (LLMs) matures, multimodal LLMs (MLLMs) have promised an elegant bridge between vision and language. However, current research is inherently constrained by challenges such as the need for high-quality instruction pairs and the loss of visual information in image-to-text training objectives. To this end, we propose a Visual Token Complement framework (VTC) that helps MLLMs regain the missing visual features and thus improve response accuracy. Specifically, our VTC integrates text-to-image generation as a guide to identifying the text-irrelevant features, and a visual selector is then developed to generate complementary visual tokens to enrich the original visual input. Moreover, an iterative strategy is further designed to extract more visual information by iteratively using the visual selector without any additional training. Notably, the training pipeline requires no additional image-text pairs, resulting in a desired instruction tuning-free property. Both qualitative and quantitative experiments demonstrate the superiority and efficiency of our VTC.</li>
</ul>

<h3>Title: RadarPillars: Efficient Object Detection from 4D Radar Point Clouds</h3>
<ul>
<li><strong>Authors: </strong>Alexander Musiat, Laurenz Reichardt, Michael Schulze, Oliver WasenmÃ¼ller</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05020">https://arxiv.org/abs/2408.05020</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05020">https://arxiv.org/pdf/2408.05020</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05020]] RadarPillars: Efficient Object Detection from 4D Radar Point Clouds(https://arxiv.org/abs/2408.05020)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Automotive radar systems have evolved to provide not only range, azimuth and Doppler velocity, but also elevation data. This additional dimension allows for the representation of 4D radar as a 3D point cloud. As a result, existing deep learning methods for 3D object detection, which were initially developed for LiDAR data, are often applied to these radar point clouds. However, this neglects the special characteristics of 4D radar data, such as the extreme sparsity and the optimal utilization of velocity information. To address these gaps in the state-of-the-art, we present RadarPillars, a pillar-based object detection network. By decomposing radial velocity data, introducing PillarAttention for efficient feature extraction, and studying layer scaling to accommodate radar sparsity, RadarPillars significantly outperform state-of-the-art detection results on the View-of-Delft dataset. Importantly, this comes at a significantly reduced parameter count, surpassing existing methods in terms of efficiency and enabling real-time performance on edge devices.</li>
</ul>

<h3>Title: Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks</h3>
<ul>
<li><strong>Authors: </strong>Gianluca De Stefano, Giancarlo Pellegrino, Lea SchÃ¶nherr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05025">https://arxiv.org/abs/2408.05025</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05025">https://arxiv.org/pdf/2408.05025</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05025]] Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks(https://arxiv.org/abs/2408.05025)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Retrieval Augmented Generation (RAG) is a technique commonly used to equip models with out of distribution knowledge. This process involves collecting, indexing, retrieving, and providing information to an LLM for generating responses. Despite its growing popularity due to its flexibility and low cost, the security implications of RAG have not been extensively studied. The data for such systems are often collected from public sources, providing an attacker a gateway for indirect prompt injections to manipulate the responses of the model. In this paper, we investigate the security of RAG systems against end-to-end indirect prompt manipulations. First, we review existing RAG framework pipelines deriving a prototypical architecture and identifying potentially critical configuration parameters. We then examine prior works searching for techniques that attackers can use to perform indirect prompt manipulations. Finally, implemented Rag n Roll, a framework to determine the effectiveness of attacks against end-to-end RAG applications. Our results show that existing attacks are mostly optimized to boost the ranking of malicious documents during the retrieval phase. However, a higher rank does not immediately translate into a reliable attack. Most attacks, against various configurations, settle around a 40% success rate, which could rise to 60% when considering ambiguous answers as successful attacks (those that include the expected benign one as well). Additionally, when using unoptimized documents, attackers deploying two of them (or more) for a target query can achieve similar results as those using optimized ones. Finally, exploration of the configuration space of a RAG showed limited impact in thwarting the attacks, where the most successful combination severely undermines functionality.</li>
</ul>

<h3>Title: Livestock Fish Larvae Counting using DETR and YOLO based Deep Networks</h3>
<ul>
<li><strong>Authors: </strong>Daniel Ortega de Carvalho, Luiz Felipe Teodoro Monteiro, Fernanda Marques Bazilio, Gabriel Toshio Hirokawa Higa, Hemerson Pistori</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05032">https://arxiv.org/abs/2408.05032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05032">https://arxiv.org/pdf/2408.05032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05032]] Livestock Fish Larvae Counting using DETR and YOLO based Deep Networks(https://arxiv.org/abs/2408.05032)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Counting fish larvae is an important, yet demanding and time consuming, task in aquaculture. In order to address this problem, in this work, we evaluate four neural network architectures, including convolutional neural networks and transformers, in different sizes, in the task of fish larvae counting. For the evaluation, we present a new annotated image dataset with less data collection requirements than preceding works, with images of spotted sorubim and dourado larvae. By using image tiling techniques, we achieve a MAPE of 4.46% ($\pm 4.70$) with an extra large real time detection transformer, and 4.71% ($\pm 4.98$) with a medium-sized YOLOv8.</li>
</ul>

<h3>Title: Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil</h3>
<ul>
<li><strong>Authors: </strong>Marcelo Sartori Locatelli, Matheus Prado Miranda, Igor Joaquim da Silva Costa, Matheus Torres Prates, Victor ThomÃ©, Mateus Zaparoli Monteiro, Tomas Lacerda, Adriana Pagano, Eduardo Rios Neto, Wagner Meira Jr., Virgilio Almeida</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05035">https://arxiv.org/abs/2408.05035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05035">https://arxiv.org/pdf/2408.05035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05035]] Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil(https://arxiv.org/abs/2408.05035)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The Exame Nacional do Ensino MÃ©dio (ENEM) is a pivotal test for Brazilian students, required for admission to a significant number of universities in Brazil. The test consists of four objective high-school level tests on Math, Humanities, Natural Sciences and Languages, and one writing essay. Students' answers to the test and to the accompanying socioeconomic status questionnaire are made public every year (albeit anonymized) due to transparency policies from the Brazilian Government. In the context of large language models (LLMs), these data lend themselves nicely to comparing different groups of humans with AI, as we can have access to human and machine answer distributions. We leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4, and MariTalk, a model trained using Portuguese data, to humans, aiming to ascertain how their answers relate to real societal groups and what that may reveal about the model biases. We divide the human groups by using socioeconomic status (SES), and compare their answer distribution with LLMs for each question and for the essay. We find no significant biases when comparing LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as the distance between model and human answers is mostly determined by the human accuracy. A similar conclusion is found by looking at the generated text as, when analyzing the essays, we observe that human and LLM essays differ in a few key factors, one being the choice of words where model essays were easily separable from human ones. The texts also differ syntactically, with LLM generated essays exhibiting, on average, smaller sentences and less thought units, among other differences. These results suggest that, for Brazilian Portuguese in the ENEM context, LLM outputs represent no group of humans, being significantly different from the answers from Brazilian students across all tests.</li>
</ul>

<h3>Title: GLEAMS: Bridging the Gap Between Local and Global Explanations</h3>
<ul>
<li><strong>Authors: </strong>Giorgio Visani, Vincenzo Stanzione, Damien Garreau</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05060">https://arxiv.org/abs/2408.05060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05060">https://arxiv.org/pdf/2408.05060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05060]] GLEAMS: Bridging the Gap Between Local and Global Explanations(https://arxiv.org/abs/2408.05060)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>The explainability of machine learning algorithms is crucial, and numerous methods have emerged recently. Local, post-hoc methods assign an attribution score to each feature, indicating its importance for the prediction. However, these methods require recalculating explanations for each example. On the other side, while there exist global approaches they often produce explanations that are either overly simplistic and unreliable or excessively complex. To bridge this gap, we propose GLEAMS, a novel method that partitions the input space and learns an interpretable model within each sub-region, thereby providing both faithful local and global surrogates. We demonstrate GLEAMS' effectiveness on both synthetic and real-world data, highlighting its desirable properties and human-understandable insights.</li>
</ul>

<h3>Title: A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares</h3>
<ul>
<li><strong>Authors: </strong>Stav Cohen, Ron Bitton, Ben Nassi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05061">https://arxiv.org/abs/2408.05061</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05061">https://arxiv.org/pdf/2408.05061</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05061]] A Jailbroken GenAI Model Can Cause Substantial Harm: GenAI-powered Applications are Vulnerable to PromptWares(https://arxiv.org/abs/2408.05061)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>In this paper we argue that a jailbroken GenAI model can cause substantial harm to GenAI-powered applications and facilitate PromptWare, a new type of attack that flips the GenAI model's behavior from serving an application to attacking it. PromptWare exploits user inputs to jailbreak a GenAI model to force/perform malicious activity within the context of a GenAI-powered application. First, we introduce a naive implementation of PromptWare that behaves as malware that targets Plan & Execute architectures (a.k.a., ReAct, function calling). We show that attackers could force a desired execution flow by creating a user input that produces desired outputs given that the logic of the GenAI-powered application is known to attackers. We demonstrate the application of a DoS attack that triggers the execution of a GenAI-powered assistant to enter an infinite loop that wastes money and computational resources on redundant API calls to a GenAI engine, preventing the application from providing service to a user. Next, we introduce a more sophisticated implementation of PromptWare that we name Advanced PromptWare Threat (APwT) that targets GenAI-powered applications whose logic is unknown to attackers. We show that attackers could create user input that exploits the GenAI engine's advanced AI capabilities to launch a kill chain in inference time consisting of six steps intended to escalate privileges, analyze the application's context, identify valuable assets, reason possible malicious activities, decide on one of them, and execute it. We demonstrate the application of APwT against a GenAI-powered e-commerce chatbot and show that it can trigger the modification of SQL tables, potentially leading to unauthorized discounts on the items sold to the user.</li>
</ul>

<h3>Title: RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records</h3>
<ul>
<li><strong>Authors: </strong>Sangjoon Park, Chan Woo Wee, Seo Hee Choi, Kyung Hwan Kim, Jee Suk Chang, Hong In Yoon, Ik Jae Lee, Yong Bae Kim, Jaeho Cho, Ki Chang Keum, Chang Geol Lee, Hwa Kyung Byun, Woong Sub Koom</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05074">https://arxiv.org/abs/2408.05074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05074">https://arxiv.org/pdf/2408.05074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05074]] RT-Surv: Improving Mortality Prediction After Radiotherapy with Large Language Model Structuring of Large-Scale Unstructured Electronic Health Records(https://arxiv.org/abs/2408.05074)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Accurate patient selection is critical in radiotherapy (RT) to prevent ineffective treatments. Traditional survival prediction models, relying on structured data, often lack precision. This study explores the potential of large language models (LLMs) to structure unstructured electronic health record (EHR) data, thereby improving survival prediction accuracy through comprehensive clinical information integration. Data from 34,276 patients treated with RT at Yonsei Cancer Center between 2013 and 2023 were analyzed, encompassing both structured and unstructured data. An open-source LLM was used to structure the unstructured EHR data via single-shot learning, with its performance compared against a domain-specific medical LLM and a smaller variant. Survival prediction models were developed using statistical, machine learning, and deep learning approaches, incorporating both structured and LLM-structured data. Clinical experts evaluated the accuracy of the LLM-structured data. The open-source LLM achieved 87.5% accuracy in structuring unstructured EHR data without additional training, significantly outperforming the domain-specific medical LLM, which reached only 35.8% accuracy. Larger LLMs were more effective, particularly in extracting clinically relevant features like general condition and disease extent, which closely correlated with patient survival. Incorporating LLM-structured clinical features into survival prediction models significantly improved accuracy, with the C-index of deep learning models increasing from 0.737 to 0.820. These models also became more interpretable by emphasizing clinically significant factors. This study shows that general-domain LLMs, even without specific medical training, can effectively structure large-scale unstructured EHR data, substantially enhancing the accuracy and interpretability of clinical predictive models.</li>
</ul>

<h3>Title: DeepInteraction++: Multi-Modality Interaction for Autonomous Driving</h3>
<ul>
<li><strong>Authors: </strong>Zeyu Yang, Nan Song, Wei Li, Xiatian Zhu, Li Zhang, Philip H.S. Torr</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05075">https://arxiv.org/abs/2408.05075</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05075">https://arxiv.org/pdf/2408.05075</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05075]] DeepInteraction++: Multi-Modality Interaction for Autonomous Driving(https://arxiv.org/abs/2408.05075)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Existing top-performance autonomous driving systems typically rely on the multi-modal fusion strategy for reliable scene understanding. This design is however fundamentally restricted due to overlooking the modality-specific strengths and finally hampering the model performance. To address this limitation, in this work, we introduce a novel modality interaction strategy that allows individual per-modality representations to be learned and maintained throughout, enabling their unique characteristics to be exploited during the whole perception pipeline. To demonstrate the effectiveness of the proposed strategy, we design DeepInteraction++, a multi-modal interaction framework characterized by a multi-modal representational interaction encoder and a multi-modal predictive interaction decoder. Specifically, the encoder is implemented as a dual-stream Transformer with specialized attention operation for information exchange and integration between separate modality-specific representations. Our multi-modal representational learning incorporates both object-centric, precise sampling-based feature alignment and global dense information spreading, essential for the more challenging planning task. The decoder is designed to iteratively refine the predictions by alternately aggregating information from separate representations in a unified modality-agnostic manner, realizing multi-modal predictive interaction. Extensive experiments demonstrate the superior performance of the proposed framework on both 3D object detection and end-to-end autonomous driving tasks. Our code is available at this https URL.</li>
</ul>

<h3>Title: Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yangdi Wang, Zhi-Hai Zhang, Su Xiu Xu, Wenming Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05082">https://arxiv.org/abs/2408.05082</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05082">https://arxiv.org/pdf/2408.05082</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05082]] Generalizing Few Data to Unseen Domains Flexibly Based on Label Smoothing Integrated with Distributionally Robust Optimization(https://arxiv.org/abs/2408.05082)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Overfitting commonly occurs when applying deep neural networks (DNNs) on small-scale datasets, where DNNs do not generalize well from existing data to unseen data. The main reason resulting in overfitting is that small-scale datasets cannot reflect the situations of the real world. Label smoothing (LS) is an effective regularization method to prevent overfitting, avoiding it by mixing one-hot labels with uniform label vectors. However, LS only focuses on labels while ignoring the distribution of existing data. In this paper, we introduce the distributionally robust optimization (DRO) to LS, achieving shift the existing data distribution flexibly to unseen domains when training DNNs. Specifically, we prove that the regularization of LS can be extended to a regularization term for the DNNs parameters when integrating DRO. The regularization term can be utilized to shift existing data to unseen domains and generate new data. Furthermore, we propose an approximate gradient-iteration label smoothing algorithm (GI-LS) to achieve the findings and train DNNs. We prove that the shift for the existing data does not influence the convergence of GI-LS. Since GI-LS incorporates a series of hyperparameters, we further consider using Bayesian optimization (BO) to find the relatively optimal combinations of these hyperparameters. Taking small-scale anomaly classification tasks as a case, we evaluate GI-LS, and the results clearly demonstrate its superior performance.</li>
</ul>

<h3>Title: PreciseControl: Enhancing Text-To-Image Diffusion Models with Fine-Grained Attribute Control</h3>
<ul>
<li><strong>Authors: </strong>Rishubh Parihar, Sachidanand VS, Sabariswaran Mani, Tejan Karmali, R. Venkatesh Babu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05083">https://arxiv.org/abs/2408.05083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05083">https://arxiv.org/pdf/2408.05083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05083]] PreciseControl: Enhancing Text-To-Image Diffusion Models with Fine-Grained Attribute Control(https://arxiv.org/abs/2408.05083)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recently, we have seen a surge of personalization methods for text-to-image (T2I) diffusion models to learn a concept using a few images. Existing approaches, when used for face personalization, suffer to achieve convincing inversion with identity preservation and rely on semantic text-based editing of the generated face. However, a more fine-grained control is desired for facial attribute editing, which is challenging to achieve solely with text prompts. In contrast, StyleGAN models learn a rich face prior and enable smooth control towards fine-grained attribute editing by latent manipulation. This work uses the disentangled $\mathcal{W+}$ space of StyleGANs to condition the T2I model. This approach allows us to precisely manipulate facial attributes, such as smoothly introducing a smile, while preserving the existing coarse text-based control inherent in T2I models. To enable conditioning of the T2I model on the $\mathcal{W+}$ space, we train a latent mapper to translate latent codes from $\mathcal{W+}$ to the token embedding space of the T2I model. The proposed approach excels in the precise inversion of face images with attribute preservation and facilitates continuous control for fine-grained attribute editing. Furthermore, our approach can be readily extended to generate compositions involving multiple individuals. We perform extensive experiments to validate our method for face personalization and fine-grained attribute editing.</li>
</ul>

<h3>Title: PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Yamin Sepehri, Pedram Pad, Pascal Frossard, L. Andrea Dunbar</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR, cs.DC, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05092">https://arxiv.org/abs/2408.05092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05092">https://arxiv.org/pdf/2408.05092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05092]] PriPHiT: Privacy-Preserving Hierarchical Training of Deep Neural Networks(https://arxiv.org/abs/2408.05092)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, defense, attack</a></li>
<li><strong>Abstract: </strong>The training phase of deep neural networks requires substantial resources and as such is often performed on cloud servers. However, this raises privacy concerns when the training dataset contains sensitive content, e.g., face images. In this work, we propose a method to perform the training phase of a deep learning model on both an edge device and a cloud server that prevents sensitive content being transmitted to the cloud while retaining the desired information. The proposed privacy-preserving method uses adversarial early exits to suppress the sensitive content at the edge and transmits the task-relevant information to the cloud. This approach incorporates noise addition during the training phase to provide a differential privacy guarantee. We extensively test our method on different facial datasets with diverse face attributes using various deep learning architectures, showcasing its outstanding performance. We also demonstrate the effectiveness of privacy preservation through successful defenses against different white-box and deep reconstruction attacks.</li>
</ul>

<h3>Title: Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models</h3>
<ul>
<li><strong>Authors: </strong>Zikai Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05093">https://arxiv.org/abs/2408.05093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05093">https://arxiv.org/pdf/2408.05093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05093]] Order Matters in Hallucination: Reasoning Order as Benchmark and Reflexive Prompting for Large-Language-Models(https://arxiv.org/abs/2408.05093)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have generated significant attention since their inception, finding applications across various academic and industrial domains. However, these models often suffer from the "hallucination problem", where outputs, though grammatically and logically coherent, lack factual accuracy or are entirely fabricated. A particularly troubling issue discovered and widely discussed recently is the numerical comparison error where multiple LLMs incorrectly infer that "9.11$>$9.9". We discovered that the order in which LLMs generate answers and reasoning impacts their consistency. Specifically, results vary significantly when an LLM generates an answer first and then provides the reasoning versus generating the reasoning process first and then the conclusion. Inspired by this, we propose a new benchmark method for assessing LLM consistency: comparing responses generated through these two different approaches. This benchmark effectively identifies instances where LLMs fabricate answers and subsequently generate justifications. Furthermore, we introduce a novel and straightforward prompt strategy designed to mitigate this issue. Experimental results demonstrate that this strategy improves performance across various LLMs compared to direct questioning. This work not only sheds light on a critical flaw in LLMs but also offers a practical solution to enhance their reliability.</li>
</ul>

<h3>Title: Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts</h3>
<ul>
<li><strong>Authors: </strong>Tingchen Fu, Yupeng Hou, Julian McAuley, Rui Yan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05094">https://arxiv.org/abs/2408.05094</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05094">https://arxiv.org/pdf/2408.05094</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05094]] Unlocking Decoding-time Controllability: Gradient-Free Multi-Objective Alignment with Contrastive Prompts(https://arxiv.org/abs/2408.05094)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The task of multi-objective alignment aims at balancing and controlling the different alignment objectives (e.g., helpfulness, harmlessness and honesty) of large language models to meet the personalized requirements of different users. However, previous methods tend to train multiple models to deal with various user preferences, with the number of trained models growing linearly with the number of alignment objectives and the number of different preferences. Meanwhile, existing methods are generally poor in extensibility and require significant re-training for each new alignment objective considered. Considering the limitation of previous approaches, we propose MCA (Multi-objective Contrastive Alignemnt), which constructs an expert prompt and an adversarial prompt for each objective to contrast at the decoding time and balances the objectives through combining the contrast. Our approach is verified to be superior to previous methods in obtaining a well-distributed Pareto front among different alignment objectives.</li>
</ul>

<h3>Title: Hyperbolic Learning with Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Paolo Mandica, Luca Franco, Konstantinos Kallidromitis, Suzanne Petryk, Fabio Galasso</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05097">https://arxiv.org/abs/2408.05097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05097">https://arxiv.org/pdf/2408.05097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05097]] Hyperbolic Learning with Multimodal Large Language Models(https://arxiv.org/abs/2408.05097)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Hyperbolic embeddings have demonstrated their effectiveness in capturing measures of uncertainty and hierarchical relationships across various deep-learning tasks, including image segmentation and active learning. However, their application in modern vision-language models (VLMs) has been limited. A notable exception is MERU, which leverages the hierarchical properties of hyperbolic space in the CLIP ViT-large model, consisting of hundreds of millions parameters. In our work, we address the challenges of scaling multi-modal hyperbolic models by orders of magnitude in terms of parameters (billions) and training complexity using the BLIP-2 architecture. Although hyperbolic embeddings offer potential insights into uncertainty not present in Euclidean embeddings, our analysis reveals that scaling these models is particularly difficult. We propose a novel training strategy for a hyperbolic version of BLIP-2, which allows to achieve comparable performance to its Euclidean counterpart, while maintaining stability throughout the training process and showing a meaningful indication of uncertainty with each embedding.</li>
</ul>

<h3>Title: How Well Do LLMs Identify Cultural Unity in Diversity?</h3>
<ul>
<li><strong>Authors: </strong>Jialin Li, Junli Wang, Junjie Hu, Ming Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05102">https://arxiv.org/abs/2408.05102</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05102">https://arxiv.org/pdf/2408.05102</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05102]] How Well Do LLMs Identify Cultural Unity in Diversity?(https://arxiv.org/abs/2408.05102)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Much work on the cultural awareness of large language models (LLMs) focuses on the models' sensitivity to geo-cultural diversity. However, in addition to cross-cultural differences, there also exists common ground across cultures. For instance, a bridal veil in the United States plays a similar cultural-relevant role as a honggaitou in China. In this study, we introduce a benchmark dataset CUNIT for evaluating decoder-only LLMs in understanding the cultural unity of concepts. Specifically, CUNIT consists of 1,425 evaluation examples building upon 285 traditional cultural-specific concepts across 10 countries. Based on a systematic manual annotation of cultural-relevant features per concept, we calculate the cultural association between any pair of cross-cultural concepts. Built upon this dataset, we design a contrastive matching task to evaluate the LLMs' capability to identify highly associated cross-cultural concept pairs. We evaluate 3 strong LLMs, using 3 popular prompting strategies, under the settings of either giving all extracted concept features or no features at all on CUNIT Interestingly, we find that cultural associations across countries regarding clothing concepts largely differ from food. Our analysis shows that LLMs are still limited to capturing cross-cultural associations between concepts compared to humans. Moreover, geo-cultural proximity shows a weak influence on model performance in capturing cross-cultural associations.</li>
</ul>

<h3>Title: Semantic Successive Refinement: A Generative AI-aided Semantic Communication Framework</h3>
<ul>
<li><strong>Authors: </strong>Kexin Zhang, Lixin Li, Wensheng Lin, Yuna Yan, Rui Li, Wenchi Cheng, Zhu Han</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05112">https://arxiv.org/abs/2408.05112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05112">https://arxiv.org/pdf/2408.05112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05112]] Semantic Successive Refinement: A Generative AI-aided Semantic Communication Framework(https://arxiv.org/abs/2408.05112)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Semantic Communication (SC) is an emerging technology aiming to surpass the Shannon limit. Traditional SC strategies often minimize signal distortion between the original and reconstructed data, neglecting perceptual quality, especially in low Signal-to-Noise Ratio (SNR) environments. To address this issue, we introduce a novel Generative AI Semantic Communication (GSC) system for single-user scenarios. This system leverages deep generative models to establish a new paradigm in SC. Specifically, At the transmitter end, it employs a joint source-channel coding mechanism based on the Swin Transformer for efficient semantic feature extraction and compression. At the receiver end, an advanced Diffusion Model (DM) reconstructs high-quality images from degraded signals, enhancing perceptual details. Additionally, we present a Multi-User Generative Semantic Communication (MU-GSC) system utilizing an asynchronous processing model. This model effectively manages multiple user requests and optimally utilizes system resources for parallel processing. Simulation results on public datasets demonstrate that our generative AI semantic communication systems achieve superior transmission efficiency and enhanced communication content quality across various channel conditions. Compared to CNN-based DeepJSCC, our methods improve the Peak Signal-to-Noise Ratio (PSNR) by 17.75% in Additive White Gaussian Noise (AWGN) channels and by 20.86% in Rayleigh channels.</li>
</ul>

<h3>Title: Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Youqian Zhang, Michael Cheung, Chunxi Yang, Xinwei Zhai, Zitong Shen, Xinyu Ji, Eugene Y. Fu, Sze-Yiu Chau, Xiapu Luo</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05124">https://arxiv.org/abs/2408.05124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05124">https://arxiv.org/pdf/2408.05124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05124]] Modeling Electromagnetic Signal Injection Attacks on Camera-based Smart Systems: Applications and Mitigation(https://arxiv.org/abs/2408.05124)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Numerous safety- or security-critical systems depend on cameras to perceive their surroundings, further allowing artificial intelligence (AI) to analyze the captured images to make important decisions. However, a concerning attack vector has emerged, namely, electromagnetic waves, which pose a threat to the integrity of these systems. Such attacks enable attackers to manipulate the images remotely, leading to incorrect AI decisions, e.g., autonomous vehicles missing detecting obstacles ahead resulting in collisions. The lack of understanding regarding how different systems react to such attacks poses a significant security risk. Furthermore, no effective solutions have been demonstrated to mitigate this threat. To address these gaps, we modeled the attacks and developed a simulation method for generating adversarial images. Through rigorous analysis, we confirmed that the effects of the simulated adversarial images are indistinguishable from those from real attacks. This method enables researchers and engineers to rapidly assess the susceptibility of various AI vision applications to these attacks, without the need for constructing complicated attack devices. In our experiments, most of the models demonstrated vulnerabilities to these attacks, emphasizing the need to enhance their robustness. Fortunately, our modeling and simulation method serves as a stepping stone toward developing more resilient models. We present a pilot study on adversarial training to improve their robustness against attacks, and our results demonstrate a significant improvement by recovering up to 91% performance, offering a promising direction for mitigating this threat.</li>
</ul>

<h3>Title: Range Membership Inference Attacks</h3>
<ul>
<li><strong>Authors: </strong>Jiashu Tao, Reza Shokri</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05131">https://arxiv.org/abs/2408.05131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05131">https://arxiv.org/pdf/2408.05131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05131]] Range Membership Inference Attacks(https://arxiv.org/abs/2408.05131)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>Machine learning models can leak private information about their training data, but the standard methods to measure this risk, based on membership inference attacks (MIAs), have a major limitation. They only check if a given data point \textit{exactly} matches a training point, neglecting the potential of similar or partially overlapping data revealing the same private information. To address this issue, we introduce the class of range membership inference attacks (RaMIAs), testing if the model was trained on any data in a specified range (defined based on the semantics of privacy). We formulate the RaMIAs game and design a principled statistical test for its complex hypotheses. We show that RaMIAs can capture privacy loss more accurately and comprehensively than MIAs on various types of data, such as tabular, image, and language. RaMIA paves the way for a more comprehensive and meaningful privacy auditing of machine learning algorithms.</li>
</ul>

<h3>Title: A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Ye Yuan, Chengwu Liu, Jingyang Yuan, Gongbo Sun, Siqi Li, Ming Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05141">https://arxiv.org/abs/2408.05141</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05141">https://arxiv.org/pdf/2408.05141</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05141]] A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning(https://arxiv.org/abs/2408.05141)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) is a framework enabling large language models (LLMs) to enhance their accuracy and reduce hallucinations by integrating external knowledge bases. In this paper, we introduce a hybrid RAG system enhanced through a comprehensive suite of optimizations that significantly improve retrieval quality, augment reasoning capabilities, and refine numerical computation ability. We refined the text chunks and tables in web pages, added attribute predictors to reduce hallucinations, conducted LLM Knowledge Extractor and Knowledge Graph Extractor, and finally built a reasoning strategy with all the references. We evaluated our system on the CRAG dataset through the Meta CRAG KDD Cup 2024 Competition. Both the local and online evaluations demonstrate that our system significantly enhances complex reasoning capabilities. In local evaluations, we have significantly improved accuracy and reduced error rates compared to the baseline model, achieving a notable increase in scores. In the meanwhile, we have attained outstanding results in online assessments, demonstrating the performance and generalization capabilities of the proposed system. The source code for our system is released in \url{this https URL}.</li>
</ul>

<h3>Title: Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2</h3>
<ul>
<li><strong>Authors: </strong>Tom Lieberum, Senthooran Rajamanoharan, Arthur Conmy, Lewis Smith, Nicolas Sonnerat, Vikrant Varma, JÃ¡nos KramÃ¡r, Anca Dragan, Rohin Shah, Neel Nanda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05147">https://arxiv.org/abs/2408.05147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05147">https://arxiv.org/pdf/2408.05147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05147]] Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2(https://arxiv.org/abs/2408.05147)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse decomposition of a neural network's latent representations into seemingly interpretable features. Despite recent excitement about their potential, research applications outside of industry are limited by the high cost of training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope, an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2 2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs on the Gemma 2 pre-trained models, but additionally release SAEs trained on instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each SAE on standard metrics and release these results. We hope that by releasing these SAE weights, we can help make more ambitious safety and interpretability research easier for the community. Weights and a tutorial can be found at this https URL and an interactive demo can be found at this https URL</li>
</ul>

<h3>Title: AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset</h3>
<ul>
<li><strong>Authors: </strong>Pritam Deka, Sampath Rajapaksha, Ruby Rani, Amirah Almutairi, Erisa Karafili</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05149">https://arxiv.org/abs/2408.05149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05149">https://arxiv.org/pdf/2408.05149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05149]] AttackER: Towards Enhancing Cyber-Attack Attribution with a Named Entity Recognition Dataset(https://arxiv.org/abs/2408.05149)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Cyber-attack attribution is an important process that allows experts to put in place attacker-oriented countermeasures and legal actions. The analysts mainly perform attribution manually, given the complex nature of this task. AI and, more specifically, Natural Language Processing (NLP) techniques can be leveraged to support cybersecurity analysts during the attribution process. However powerful these techniques are, they need to deal with the lack of datasets in the attack attribution domain. In this work, we will fill this gap and will provide, to the best of our knowledge, the first dataset on cyber-attack attribution. We designed our dataset with the primary goal of extracting attack attribution information from cybersecurity texts, utilizing named entity recognition (NER) methodologies from the field of NLP. Unlike other cybersecurity NER datasets, ours offers a rich set of annotations with contextual details, including some that span phrases and sentences. We conducted extensive experiments and applied NLP techniques to demonstrate the dataset's effectiveness for attack attribution. These experiments highlight the potential of Large Language Models (LLMs) capabilities to improve the NER tasks in cybersecurity datasets for cyber-attack attribution.</li>
</ul>

<h3>Title: Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification</h3>
<ul>
<li><strong>Authors: </strong>Xiaoyang Hao, Zhixi Feng, Tongqing Peng, Shuyuan Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05151">https://arxiv.org/abs/2408.05151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05151">https://arxiv.org/pdf/2408.05151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05151]] Meta-Learning Guided Label Noise Distillation for Robust Signal Modulation Classification(https://arxiv.org/abs/2408.05151)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Automatic modulation classification (AMC) is an effective way to deal with physical layer threats of the internet of things (IoT). However, there is often label mislabeling in practice, which significantly impacts the performance and robustness of deep neural networks (DNNs). In this paper, we propose a meta-learning guided label noise distillation method for robust AMC. Specifically, a teacher-student heterogeneous network (TSHN) framework is proposed to distill and reuse label noise. Based on the idea that labels are representations, the teacher network with trusted meta-learning divides and conquers untrusted label samples and then guides the student network to learn better by reassessing and correcting labels. Furthermore, we propose a multi-view signal (MVS) method to further improve the performance of hard-to-classify categories with few-shot trusted label samples. Extensive experimental results show that our methods can significantly improve the performance and robustness of signal AMC in various and complex label noise scenarios, which is crucial for securing IoT applications.</li>
</ul>

<h3>Title: Federated Hypergraph Learning with Hyperedge Completion</h3>
<ul>
<li><strong>Authors: </strong>Linfeng Luo, Fengxiao Tang, Xiyu Liu, Zhiqi Guo, Zihao Qiu, Ming Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05160">https://arxiv.org/abs/2408.05160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05160">https://arxiv.org/pdf/2408.05160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05160]] Federated Hypergraph Learning with Hyperedge Completion(https://arxiv.org/abs/2408.05160)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, federate</a></li>
<li><strong>Abstract: </strong>Hypergraph neural networks enhance conventional graph neural networks by capturing high-order relationships among nodes, which proves vital in data-rich environments where interactions are not merely pairwise. As data complexity and interconnectivity grow, it is common for graph-structured data to be split and stored in a distributed manner, underscoring the necessity of federated learning on subgraphs. In this work, we propose FedHGN, a novel algorithm for federated hypergraph learning. Our algorithm utilizes subgraphs of a hypergraph stored on distributed devices to train local HGNN models in a federated manner:by collaboratively developing an effective global HGNN model through sharing model parameters while preserving client privacy. Additionally, considering that hyperedges may span multiple clients, a pre-training step is employed before the training process in which cross-client hyperedge feature gathering is performed at the central server. In this way, the missing cross-client information can be supplemented from the central server during the node feature aggregation phase. Experimental results on seven real-world datasets confirm the effectiveness of our approach and demonstrate its performance advantages over traditional federated graph learning methods.</li>
</ul>

<h3>Title: ECG-FM: An Open Electrocardiogram Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Kaden McKeen, Laura Oliva, Sameer Masood, Augustin Toma, Barry Rubin, Bo Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05178">https://arxiv.org/abs/2408.05178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05178">https://arxiv.org/pdf/2408.05178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05178]] ECG-FM: An Open Electrocardiogram Foundation Model(https://arxiv.org/abs/2408.05178)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>The electrocardiogram (ECG) is a ubiquitous diagnostic test. Conventional task-specific ECG analysis models require large numbers of expensive ECG annotations or associated labels to train. Transfer learning techniques have been shown to improve generalization and reduce reliance on labeled data. We present ECG-FM, an open foundation model for ECG analysis, and conduct a comprehensive study performed on a dataset of 1.66 million ECGs sourced from both publicly available and private institutional sources. ECG-FM adopts a transformer-based architecture and is pretrained on 2.5 million samples using ECG-specific augmentations and contrastive learning, as well as a continuous signal masking objective. Our transparent evaluation includes a diverse range of downstream tasks, where we predict ECG interpretation labels, reduced left ventricular ejection fraction, and abnormal cardiac troponin. Affirming ECG-FM's effectiveness as a foundation model, we demonstrate how its command of contextual information results in strong performance, rich pretrained embeddings, and reliable interpretability. Due to a lack of open-weight practices, we highlight how ECG analysis is lagging behind other medical machine learning subfields in terms of foundation model adoption. Our code is available at this https URL.</li>
</ul>

<h3>Title: Cross-Domain Learning for Video Anomaly Detection with Limited Supervision</h3>
<ul>
<li><strong>Authors: </strong>Yashika Jain, Ali Dabouei, Min Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05191">https://arxiv.org/abs/2408.05191</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05191">https://arxiv.org/pdf/2408.05191</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05191]] Cross-Domain Learning for Video Anomaly Detection with Limited Supervision(https://arxiv.org/abs/2408.05191)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Video Anomaly Detection (VAD) automates the identification of unusual events, such as security threats in surveillance videos. In real-world applications, VAD models must effectively operate in cross-domain settings, identifying rare anomalies and scenarios not well-represented in the training data. However, existing cross-domain VAD methods focus on unsupervised learning, resulting in performance that falls short of real-world expectations. Since acquiring weak supervision, i.e., video-level labels, for the source domain is cost-effective, we conjecture that combining it with external unlabeled data has notable potential to enhance cross-domain performance. To this end, we introduce a novel weakly-supervised framework for Cross-Domain Learning (CDL) in VAD that incorporates external data during training by estimating its prediction bias and adaptively minimizing that using the predicted uncertainty. We demonstrate the effectiveness of the proposed CDL framework through comprehensive experiments conducted in various configurations on two large-scale VAD datasets: UCF-Crime and XD-Violence. Our method significantly surpasses the state-of-the-art works in cross-domain evaluations, achieving an average absolute improvement of 19.6% on UCF-Crime and 12.87% on XD-Violence.</li>
</ul>

<h3>Title: Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation</h3>
<ul>
<li><strong>Authors: </strong>Steven Fincke, Elizabeth Boschee</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05192">https://arxiv.org/abs/2408.05192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05192">https://arxiv.org/pdf/2408.05192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05192]] Separating Style from Substance: Enhancing Cross-Genre Authorship Attribution through Data Selection and Presentation(https://arxiv.org/abs/2408.05192)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The task of deciding whether two documents are written by the same author is challenging for both machines and humans. This task is even more challenging when the two documents are written about different topics (e.g. baseball vs. politics) or in different genres (e.g. a blog post vs. an academic article). For machines, the problem is complicated by the relative lack of real-world training examples that cross the topic boundary and the vanishing scarcity of cross-genre data. We propose targeted methods for training data selection and a novel learning curriculum that are designed to discourage a model's reliance on topic information for authorship attribution and correspondingly force it to incorporate information more robustly indicative of style no matter the topic. These refinements yield a 62.7% relative improvement in average cross-genre authorship attribution, as well as 16.6% in the per-genre condition.</li>
</ul>

<h3>Title: HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling</h3>
<ul>
<li><strong>Authors: </strong>Piotr Keller, Muhammad Dawood, Brinder Singh Chohan, Fayyaz ul Amir Afsar Minhas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05195">https://arxiv.org/abs/2408.05195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05195">https://arxiv.org/pdf/2408.05195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05195]] HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling(https://arxiv.org/abs/2408.05195)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Machine learning in computational pathology (CPath) often aggregates patch-level predictions from multi-gigapixel Whole Slide Images (WSIs) to generate WSI-level prediction scores for crucial tasks such as survival prediction and drug effect prediction. However, current methods do not explicitly characterize distributional differences between patch sets within WSIs. We introduce HistoKernel, a novel Maximum Mean Discrepancy (MMD) kernel that measures distributional similarity between WSIs for enhanced prediction performance on downstream prediction tasks. Our comprehensive analysis demonstrates HistoKernel's effectiveness across various machine learning tasks, including retrieval (n = 9,362), drug sensitivity regression (n = 551), point mutation classification (n = 3,419), and survival analysis (n = 2,291), outperforming existing deep learning methods. Additionally, HistoKernel seamlessly integrates multi-modal data and offers a novel perturbation-based method for patch-level explainability. This work pioneers the use of kernel-based methods for WSI-level predictive modeling, opening new avenues for research. Code is available at this https URL.</li>
</ul>

<h3>Title: Cell Morphology-Guided Small Molecule Generation with GFlowNets</h3>
<ul>
<li><strong>Authors: </strong>Stephen Zhewen Lu, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Yoshua Bengio, Gabriele Scalia, MichaÅ Koziarski</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05196">https://arxiv.org/abs/2408.05196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05196">https://arxiv.org/pdf/2408.05196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05196]] Cell Morphology-Guided Small Molecule Generation with GFlowNets(https://arxiv.org/abs/2408.05196)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>High-content phenotypic screening, including high-content imaging (HCI), has gained popularity in the last few years for its ability to characterize novel therapeutics without prior knowledge of the protein target. When combined with deep learning techniques to predict and represent molecular-phenotype interactions, these advancements hold the potential to significantly accelerate and enhance drug discovery applications. This work focuses on the novel task of HCI-guided molecular design. Generative models for molecule design could be guided by HCI data, for example with a supervised model that links molecules to phenotypes of interest as a reward function. However, limited labeled data, combined with the high-dimensional readouts, can make training these methods challenging and impractical. We consider an alternative approach in which we leverage an unsupervised multimodal joint embedding to define a latent similarity as a reward for GFlowNets. The proposed model learns to generate new molecules that could produce phenotypic effects similar to those of the given image target, without relying on pre-annotated phenotypic labels. We demonstrate that the proposed method generates molecules with high morphological and structural similarity to the target, increasing the likelihood of similar biological activity, as confirmed by an independent oracle model.</li>
</ul>

<h3>Title: TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Yujie Feng, Xu Chu, Yongxin Xu, Zexin Lu, Bo Liu, Philip S. Yu, Xiao-Ming Wu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05200">https://arxiv.org/abs/2408.05200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05200">https://arxiv.org/pdf/2408.05200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05200]] TaSL: Task Skill Localization and Consolidation for Language Model Continual Learning(https://arxiv.org/abs/2408.05200)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Language model continual learning (CL) has recently garnered significant interest due to its potential to adapt large language models (LLMs) to dynamic real-world environments without re-training. A key challenge in this field is catastrophic forgetting, where models lose previously acquired knowledge when learning new tasks. Existing methods commonly employ multiple parameter-efficient fine-tuning (PEFT) blocks to acquire task-specific knowledge for each task, but these approaches lack efficiency and overlook the potential for knowledge transfer through task interaction. In this paper, we present a novel CL framework for language models called Task Skill Localization and Consolidation (TaSL), which enhances knowledge transfer without relying on memory replay. TaSL first divides the model into `skill units' based on parameter dependencies, enabling more granular control. It then employs a novel group-wise skill localization technique to identify the importance distribution of skill units for a new task. By comparing this importance distribution with those from previous tasks, we implement a fine-grained skill consolidation strategy that retains task-specific knowledge, thereby preventing forgetting, and updates task-shared knowledge, which facilitates bi-directional knowledge transfer. As a result, TaSL achieves a superior balance between retaining previous knowledge and excelling in new tasks. TaSL also shows strong generalizability, suitable for general models and customizable for PEFT methods like LoRA. Additionally, it demonstrates notable extensibility, allowing integration with memory replay to further enhance performance. Extensive experiments on two CL benchmarks, with varying model sizes (from 220M to 7B), demonstrate the effectiveness of TaSL and its variants across different settings.</li>
</ul>

<h3>Title: Multi-Garment Customized Model Generation</h3>
<ul>
<li><strong>Authors: </strong>Yichen Liu, Penghui Du, Yi Liu Quanwei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05206">https://arxiv.org/abs/2408.05206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05206">https://arxiv.org/pdf/2408.05206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05206]] Multi-Garment Customized Model Generation(https://arxiv.org/abs/2408.05206)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This paper introduces Multi-Garment Customized Model Generation, a unified framework based on Latent Diffusion Models (LDMs) aimed at addressing the unexplored task of synthesizing images with free combinations of multiple pieces of clothing. The method focuses on generating customized models wearing various targeted outfits according to different text prompts. The primary challenge lies in maintaining the natural appearance of the dressed model while preserving the complex textures of each piece of clothing, ensuring that the information from different garments does not interfere with each other. To tackle these challenges, we first developed a garment encoder, which is a trainable UNet copy with shared weights, capable of extracting detailed features of garments in parallel. Secondly, our framework supports the conditional generation of multiple garments through decoupled multi-garment feature fusion, allowing multiple clothing features to be injected into the backbone network, significantly alleviating conflicts between garment information. Additionally, the proposed garment encoder is a plug-and-play module that can be combined with other extension modules such as IP-Adapter and ControlNet, enhancing the diversity and controllability of the generated models. Extensive experiments demonstrate the superiority of our approach over existing alternatives, opening up new avenues for the task of generating images with multiple-piece clothing combinations</li>
</ul>

<h3>Title: VITA: Towards Open-Source Interactive Omni Multimodal LLM</h3>
<ul>
<li><strong>Authors: </strong>Chaoyou Fu, Haojia Lin, Zuwei Long, Yunhang Shen, Meng Zhao, Yifan Zhang, Xiong Wang, Di Yin, Long Ma, Xiawu Zheng, Ran He, Rongrong Ji, Yunsheng Wu, Caifeng Shan, Xing Sun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05211">https://arxiv.org/abs/2408.05211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05211">https://arxiv.org/pdf/2408.05211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05211]] VITA: Towards Open-Source Interactive Omni Multimodal LLM(https://arxiv.org/abs/2408.05211)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>The remarkable multimodal capabilities and interactive experience of GPT-4o underscore their necessity in practical applications, yet open-source models rarely excel in both areas. In this paper, we introduce VITA, the first-ever open-source Multimodal Large Language Model (MLLM) adept at simultaneous processing and analysis of Video, Image, Text, and Audio modalities, and meanwhile has an advanced multimodal interactive experience. Starting from Mixtral 8x7B as a language foundation, we expand its Chinese vocabulary followed by bilingual instruction tuning. We further endow the language model with visual and audio capabilities through two-stage multi-task learning of multimodal alignment and instruction tuning. VITA demonstrates robust foundational capabilities of multilingual, vision, and audio understanding, as evidenced by its strong performance across a range of both unimodal and multimodal benchmarks. Beyond foundational capabilities, we have made considerable progress in enhancing the natural multimodal human-computer interaction experience. To the best of our knowledge, we are the first to exploit non-awakening interaction and audio interrupt in MLLM. VITA is the first step for the open-source community to explore the seamless integration of multimodal understanding and interaction. While there is still lots of work to be done on VITA to get close to close-source counterparts, we hope that its role as a pioneer can serve as a cornerstone for subsequent research. Project Page: this https URL.</li>
</ul>

<h3>Title: Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions</h3>
<ul>
<li><strong>Authors: </strong>Michele Miranda, Elena Sofia Ruzzetti, Andrea Santilli, Fabio Massimo Zanzotto, SÃ©bastien BratiÃ¨res, Emanuele RodolÃ </a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2408.05212">https://arxiv.org/abs/2408.05212</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2408.05212">https://arxiv.org/pdf/2408.05212</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2408.05212]] Preserving Privacy in Large Language Models: A Survey on Current Threats and Solutions(https://arxiv.org/abs/2408.05212)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) represent a significant advancement in artificial intelligence, finding applications across various domains. However, their reliance on massive internet-sourced datasets for training brings notable privacy issues, which are exacerbated in critical domains (e.g., healthcare). Moreover, certain application-specific scenarios may require fine-tuning these models on private data. This survey critically examines the privacy threats associated with LLMs, emphasizing the potential for these models to memorize and inadvertently reveal sensitive information. We explore current threats by reviewing privacy attacks on LLMs and propose comprehensive solutions for integrating privacy mechanisms throughout the entire learning pipeline. These solutions range from anonymizing training datasets to implementing differential privacy during training or inference and machine unlearning after training. Our comprehensive review of existing literature highlights ongoing challenges, available tools, and future directions for preserving privacy in LLMs. This work aims to guide the development of more secure and trustworthy AI systems by providing a thorough understanding of privacy preservation methods and their effectiveness in mitigating risks.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
