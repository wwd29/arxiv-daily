<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-10-21</h1>
<h3>Title: Lyapunov-Stable Adaptive Control for Multimodal Concept Drift</h3>
<ul>
<li><strong>Authors: </strong>Tianyu Bell Pan, Mengdi Zhu, Alexa Jordyn Cole, Ronald Wilson, Damon L. Woodard</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15944">https://arxiv.org/abs/2510.15944</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15944">https://arxiv.org/pdf/2510.15944</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15944]] Lyapunov-Stable Adaptive Control for Multimodal Concept Drift(https://arxiv.org/abs/2510.15944)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal learning systems often struggle in non-stationary environments due to concept drift, where changing data distributions can degrade performance. Modality-specific drifts and the lack of mechanisms for continuous, stable adaptation compound this challenge. This paper introduces LS-OGD, a novel adaptive control framework for robust multimodal learning in the presence of concept drift. LS-OGD uses an online controller that dynamically adjusts the model's learning rate and the fusion weights between different data modalities in response to detected drift and evolving prediction errors. We prove that under bounded drift conditions, the LS-OGD system's prediction error is uniformly ultimately bounded and converges to zero if the drift ceases. Additionally, we demonstrate that the adaptive fusion strategy effectively isolates and mitigates the impact of severe modality-specific drift, thereby ensuring system resilience and fault tolerance. These theoretical guarantees establish a principled foundation for developing reliable and continuously adapting multimodal learning systems.</li>
</ul>

<h3>Title: Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics</h3>
<ul>
<li><strong>Authors: </strong>Arianna Francesconi, Donato Cappetta, Fabio Rebecchi, Paolo Soda, Valerio Guarrasi, Rosa Sicilia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15950">https://arxiv.org/abs/2510.15950</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15950">https://arxiv.org/pdf/2510.15950</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15950]] Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics(https://arxiv.org/abs/2510.15950)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Parkinson's disease (PD) presents a growing global challenge, affecting over 10 million individuals, with prevalence expected to double by 2040. Early diagnosis remains difficult due to the late emergence of motor symptoms and limitations of traditional clinical assessments. In this study, we propose a novel pipeline that leverages keystroke dynamics as a non-invasive and scalable biomarker for remote PD screening and telemonitoring. Our methodology involves three main stages: (i) preprocessing of data from four distinct datasets, extracting four temporal signals and addressing class imbalance through the comparison of three methods; (ii) pre-training eight state-of-the-art deep-learning architectures on the two largest datasets, optimizing temporal windowing, stride, and other hyperparameters; (iii) fine-tuning on an intermediate-sized dataset and performing external validation on a fourth, independent cohort. Our results demonstrate that hybrid convolutional-recurrent and transformer-based models achieve strong external validation performance, with AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal convolutional model attains an AUC-ROC of 91.14% in external validation, outperforming existing methods that rely solely on internal validation. These findings underscore the potential of keystroke dynamics as a reliable digital biomarker for PD, offering a promising avenue for early detection and continuous monitoring.</li>
</ul>

<h3>Title: Hierarchical Multi-Modal Threat Intelligence Fusion Without Aligned Data: A Practical Framework for Real-World Security Operations</h3>
<ul>
<li><strong>Authors: </strong>Sisir Doppalapudi</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15953">https://arxiv.org/abs/2510.15953</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15953">https://arxiv.org/pdf/2510.15953</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15953]] Hierarchical Multi-Modal Threat Intelligence Fusion Without Aligned Data: A Practical Framework for Real-World Security Operations(https://arxiv.org/abs/2510.15953)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Multi-modal threat detection faces a fundamental challenge that involves security tools operating in isolation, and this creates streams of network, email, and system data with no natural alignment or correlation. We present Hierarchical Multi-Modal Threat Intelligence Fusion (HM-TIF), a framework explicitly designed for this realistic scenario where naturally aligned multi-modal attack data does not exist. Unlike prior work that assumes or creates artificial alignment, we develop principled methods for correlating independent security data streams while maintaining operational validity. Our architecture employs hierarchical cross-attention with dynamic weighting that adapts to data availability and threat context, coupled with a novel temporal correlation protocol that preserves statistical independence. Evaluation on UNSW-NB15, CSE-CIC-IDS2018, and CICBell-DNS2021 datasets demonstrates that HM-TIF achieves 88.7% accuracy with a critical 32% reduction in false positive rates, even without true multi-modal training data. The framework maintains robustness when modalities are missing, making it immediately deployable in real security operations where data streams frequently have gaps. Our contributions include: (i) the first multi-modal security framework explicitly designed for non-aligned data, (ii) a temporal correlation protocol that avoids common data leakage pitfalls, (iii) empirical validation that multi-modal fusion provides operational benefits even without perfect alignment, and (iv) practical deployment guidelines for security teams facing heterogeneous, uncoordinated data sources. Index Terms: multi-modal learning, threat intelligence, non-aligned data, operational security, cross-attention mechanisms, practical deployment</li>
</ul>

<h3>Title: Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter</h3>
<ul>
<li><strong>Authors: </strong>Hongzheng Shi, Yuhang Wang, Xiao Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15954">https://arxiv.org/abs/2510.15954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15954">https://arxiv.org/pdf/2510.15954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15954]] Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter(https://arxiv.org/abs/2510.15954)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>As wildfires become increasingly destructive and expensive to control, effective management of active wildfires requires accurate, real-time fire spread predictions. To enhance the forecasting accuracy of active fires, data assimilation plays a vital role by integrating observations (such as remote-sensing data) and fire predictions generated from numerical models. This paper provides a comprehensive investigation on the application of a recently proposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter (EnSF) -- to the data assimilation problem for real-time active wildfire spread predictions. Leveraging a score-based generative diffusion model, EnSF has been shown to have superior accuracy for high-dimensional nonlinear filtering problems, making it an ideal candidate for the filtering problems of wildfire spread models. Technical details are provided, and our numerical investigations demonstrate that EnSF provides superior accuracy, stability, and computational efficiency, establishing it as a robust and practical method for wildfire data assimilation. Our code has been made publicly available.</li>
</ul>

<h3>Title: How Good Are LLMs at Processing Tool Outputs?</h3>
<ul>
<li><strong>Authors: </strong>Kiran Kate, Yara Rizk, Poulami Ghosh, Ashu Gulati, Tathagata Chakraborti, Zidane Wright, Mayank Agarwal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15955">https://arxiv.org/abs/2510.15955</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15955">https://arxiv.org/pdf/2510.15955</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15955]] How Good Are LLMs at Processing Tool Outputs?(https://arxiv.org/abs/2510.15955)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Most realistic task automation problems require large language models (LLMs) to call tools, which often return complex JSON responses. These responses must be further processed to derive the information necessary for task completion. The ability of LLMs to do so is under-studied. In this paper, we study the tool response processing task and LLMs' abilities to process structured (JSON) responses. We created a dataset for this task, and evaluated 15 open and closed weight models using multiple prompting approaches. Our results show that JSON processing remains a difficult task even for frontier models across multiple prompting strategies. The optimal response processing strategy depends on both the nature and size of the tool outputs, as well as the complexity of the required reasoning. Variations in processing approaches can lead to performance differences ranging from 3\% to 50\%.</li>
</ul>

<h3>Title: Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Li, Zehong Wang, Zhengqing Yuan, Zheyuan Zhang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15961">https://arxiv.org/abs/2510.15961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15961">https://arxiv.org/pdf/2510.15961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15961]] Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use(https://arxiv.org/abs/2510.15961)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Illicit drug use among teenagers and young adults (TYAs) remains a pressing public health concern, with rising prevalence and long-term impacts on health and well-being. To detect illicit drug use among TYAs, researchers analyze large-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the National Survey on Drug Use and Health (NSDUH), which preserve rich demographic, psychological, and environmental factors related to substance use. However, existing modeling methods treat survey variables independently, overlooking latent and interconnected structures among them. To address this limitation, we propose LAMI (LAtent relation Mining with bi-modal Interpretability), a novel joint graph-language modeling framework for detecting illicit drug use and interpreting behavioral risk factors among TYAs. LAMI represents individual responses as relational graphs, learns latent connections through a specialized graph structure learning layer, and integrates a large language model to generate natural language explanations grounded in both graph structures and survey semantics. Experiments on the YRBS and NSDUH datasets show that LAMI outperforms competitive baselines in predictive accuracy. Interpretability analyses further demonstrate that LAMI reveals meaningful behavioral substructures and psychosocial pathways, such as family dynamics, peer influence, and school-related distress, that align with established risk factors for substance use.</li>
</ul>

<h3>Title: CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhuxuanzi Wang, Mingqiao Mo, Xi Xiao, Chen Liu, Chenrui Ma, Yunbei Zhang, Xiao Wang, Smita Krishnaswamy, Tianyang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15962">https://arxiv.org/abs/2510.15962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15962">https://arxiv.org/pdf/2510.15962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15962]] CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models(https://arxiv.org/abs/2510.15962)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Parameter-efficient fine-tuning (PEFT) has become the standard approach for adapting large language models under limited compute and memory budgets. Although previous methods improve efficiency through low-rank updates, quantization, or heuristic budget reallocation, they often decouple the allocation of capacity from the way updates evolve during training. In this work, we introduce CTR-LoRA, a framework guided by curvature trust region that integrates rank scheduling with stability-aware optimization. CTR-LoRA allocates parameters based on marginal utility derived from lightweight second-order proxies and constrains updates using a Fisher/Hessian-metric trust region. Experiments on multiple open-source backbones (7B-13B), evaluated on both in-distribution and out-of-distribution benchmarks, show consistent improvements over strong PEFT baselines. In addition to increased accuracy, CTR-LoRA enhances training stability, reduces memory requirements, and achieves higher throughput, positioning it on the Pareto frontier of performance and efficiency. These results highlight a principled path toward more robust and deployable PEFT.</li>
</ul>

<h3>Title: ESCA: Contextualizing Embodied Agents via Scene-Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Jiani Huang, Amish Sethi, Matthew Kuo, Mayank Keoliya, Neelay Velingker, JungHo Jung, Ser-Nam Lim, Ziyang Li, Mayur Naik</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15963">https://arxiv.org/abs/2510.15963</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15963">https://arxiv.org/pdf/2510.15963</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15963]] ESCA: Contextualizing Embodied Agents via Scene-Graph Generation(https://arxiv.org/abs/2510.15963)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multi-modal large language models (MLLMs) are making rapid progress toward general-purpose embodied agents. However, current training pipelines primarily rely on high-level vision-sound-text pairs and lack fine-grained, structured alignment between pixel-level visual content and textual semantics. To overcome this challenge, we propose ESCA, a new framework for contextualizing embodied agents through structured spatial-temporal understanding. At its core is SGClip, a novel CLIP-based, open-domain, and promptable model for generating scene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic learning pipeline, which harnesses model-driven self-supervision from video-caption pairs and structured reasoning, thereby eliminating the need for human-labeled scene graph annotations. We demonstrate that SGClip supports both prompt-based inference and task-specific fine-tuning, excelling in scene graph generation and action localization benchmarks. ESCA with SGClip consistently improves both open-source and commercial MLLMs, achieving state-of-the-art performance across two embodied environments. Notably, it significantly reduces agent perception errors and enables open-source models to surpass proprietary baselines.</li>
</ul>

<h3>Title: Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Tuowei Wang, Kun Li, Zixu Hao, Donglin Bai, Ju Ren, Yaoxue Zhang, Ting Cao, Mao Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15964">https://arxiv.org/abs/2510.15964</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15964">https://arxiv.org/pdf/2510.15964</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15964]] Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity(https://arxiv.org/abs/2510.15964)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The adaptation of pre-trained large language models (LLMs) to diverse downstream tasks via fine-tuning is critical for numerous applications. However, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques presents significant challenges in terms of time investments and operational costs. In this paper, we first introduce a nuanced form of sparsity, termed Shadowy Sparsity, which is distinctive in fine-tuning and has not been adequately addressed for acceleration. Under Shadowy Sparsity, we propose Long Exposure, an efficient system to accelerate PEFT for LLMs. Long Exposure comprises three key components: Shadowy-sparsity Exposer employs a prolonged sensing range to capture more sparsity details under shadowy sparsity; Sequence-oriented Predictor provides efficient yet accurate predictions to handle large sequence inputs and constantly-evolving parameters; and Dynamic-aware Operator facilitates more structured computational patterns and coalesced memory accesses, addressing dynamic sparse operations. Extensive evaluations show that Long Exposure outperforms state-of-the-arts with up to a $2.49\times$ speedup in end-to-end fine-tuning, offering promising advancements in accelerating PEFT for LLMs.</li>
</ul>

<h3>Title: One Token Embedding Is Enough to Deadlock Your Large Reasoning Model</h3>
<ul>
<li><strong>Authors: </strong>Mohan Zhang, Yihua Zhang, Jinghan Jia, Zhangyang Wang, Sijia Liu, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15965">https://arxiv.org/abs/2510.15965</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15965">https://arxiv.org/pdf/2510.15965</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15965]] One Token Embedding Is Enough to Deadlock Your Large Reasoning Model(https://arxiv.org/abs/2510.15965)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, steal, generative</a></li>
<li><strong>Abstract: </strong>Modern large reasoning models (LRMs) exhibit impressive multi-step problem-solving via chain-of-thought (CoT) reasoning. However, this iterative thinking mechanism introduces a new vulnerability surface. We present the Deadlock Attack, a resource exhaustion method that hijacks an LRM's generative control flow by training a malicious adversarial embedding to induce perpetual reasoning loops. Specifically, the optimized embedding encourages transitional tokens (e.g., "Wait", "But") after reasoning steps, preventing the model from concluding its answer. A key challenge we identify is the continuous-to-discrete projection gap: naïve projections of adversarial embeddings to token sequences nullify the attack. To overcome this, we introduce a backdoor implantation strategy, enabling reliable activation through specific trigger tokens. Our method achieves a 100% attack success rate across four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three math reasoning benchmarks, forcing models to generate up to their maximum token limits. The attack is also stealthy (in terms of causing negligible utility loss on benign user inputs) and remains robust against existing strategies trying to mitigate the overthinking issue. Our findings expose a critical and underexplored security vulnerability in LRMs from the perspective of reasoning (in)efficiency.</li>
</ul>

<h3>Title: Gains: Fine-grained Federated Domain Adaptation in Open Set</h3>
<ul>
<li><strong>Authors: </strong>Zhengyi Zhong, Wenzheng Jiang, Weidong Bao, Ji Wang, Cheems Wang, Guanbo Wang, Yongheng Deng, Ju Ren</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15967">https://arxiv.org/abs/2510.15967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15967">https://arxiv.org/pdf/2510.15967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15967]] Gains: Fine-grained Federated Domain Adaptation in Open Set(https://arxiv.org/abs/2510.15967)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Conventional federated learning (FL) assumes a closed world with a fixed total number of clients. In contrast, new clients continuously join the FL process in real-world scenarios, introducing new knowledge. This raises two critical demands: detecting new knowledge, i.e., knowledge discovery, and integrating it into the global model, i.e., knowledge adaptation. Existing research focuses on coarse-grained knowledge discovery, and often sacrifices source domain performance and adaptation efficiency. To this end, we propose a fine-grained federated domain adaptation approach in open set (Gains). Gains splits the model into an encoder and a classifier, empirically revealing features extracted by the encoder are sensitive to domain shifts while classifier parameters are sensitive to class increments. Based on this, we develop fine-grained knowledge discovery and contribution-driven aggregation techniques to identify and incorporate new knowledge. Additionally, an anti-forgetting mechanism is designed to preserve source domain performance, ensuring balanced adaptation. Experimental results on multi-domain datasets across three typical data-shift scenarios demonstrate that Gains significantly outperforms other baselines in performance for both source-domain and target-domain clients. Code is available at: this https URL.</li>
</ul>

<h3>Title: LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems</h3>
<ul>
<li><strong>Authors: </strong>Paul-Niklas Ken Kandora, Simon Caspar Zeller, Aaron Jeremias Elsing, Elena Kuss, Steffen Rebennack</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15969">https://arxiv.org/abs/2510.15969</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15969">https://arxiv.org/pdf/2510.15969</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15969]] LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems(https://arxiv.org/abs/2510.15969)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Reformulating nonlinear optimization problems is largely manual and expertise-intensive, yet it remains essential for solving such problems with linear optimization solvers or applying special-purpose algorithms. We introduce \textit{LinearizeLLM}, an agent-based framework that solves this task by leveraging Large Language Models (LLMs). The framework assigns each nonlinear pattern to a \textit{reformulation agent} that is explicitly instructed to derive an exact linear reformulation for its nonlinearity pattern, for instance, absolute-value terms or bilinear products of decision variables. The agents then coordinate to assemble a solver-ready linear model equivalent to the original problem. To benchmark the approach, we create a dataset of 20 real-world nonlinear optimization problems derived from the established ComplexOR dataset of linear optimization problems. We evaluate our approach with several LLMs. Our results indicate that specialized LLM agents can automate linearization tasks, opening a path toward fully conversational modeling pipelines for nonlinear optimization.</li>
</ul>

<h3>Title: A Graph-Attentive LSTM Model for Malicious URL Detection</h3>
<ul>
<li><strong>Authors: </strong>Md. Ifthekhar Hossain, Kazi Abdullah Al Arafat, Bryce Shepard, Kayd Craig, Imtiaz Parvez</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15971">https://arxiv.org/abs/2510.15971</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15971">https://arxiv.org/pdf/2510.15971</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15971]] A Graph-Attentive LSTM Model for Malicious URL Detection(https://arxiv.org/abs/2510.15971)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Malicious URLs pose significant security risks as they facilitate phishing attacks, distribute malware, and empower attackers to deface websites. Blacklist detection methods fail to identify new or obfuscated URLs because they depend on pre-existing patterns. This work presents a hybrid deep learning model named GNN-GAT-LSTM that combines Graph Neural Networks (GNNs) with Graph Attention Networks (GATs) and Long Short-Term Memory (LSTM) networks. The proposed architecture extracts both the structural and sequential patterns of the features from data. The model transforms URLs into graphs through a process where characters become nodes that connect through edges. It applies one-hot encoding to represent node features. The model received training and testing data from a collection of 651,191 URLs, which were classified into benign, phishing, defacement, and malware categories. The preprocessing stage included both feature engineering and data balancing techniques, which addressed the class imbalance issue to enhance model learning. The GNN-GAT-LSTM model achieved outstanding performance through its test accuracy of 0.9806 and its weighted F1-score of 0.9804. It showed excellent precision and recall performance across most classes, particularly for benign and defacement URLs. Overall, the model provides an efficient and scalable system for detecting malicious URLs while demonstrating strong potential for real-world cybersecurity applications.</li>
</ul>

<h3>Title: Quantum NLP models on Natural Language Inference</h3>
<ul>
<li><strong>Authors: </strong>Ling Sun, Peter Sullivan, Michael Martin, Yun Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15972">https://arxiv.org/abs/2510.15972</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15972">https://arxiv.org/pdf/2510.15972</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15972]] Quantum NLP models on Natural Language Inference(https://arxiv.org/abs/2510.15972)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Quantum natural language processing (QNLP) offers a novel approach to semantic modeling by embedding compositional structure directly into quantum circuits. This paper investigates the application of QNLP models to the task of Natural Language Inference (NLI), comparing quantum, hybrid, and classical transformer-based models under a constrained few-shot setting. Using the lambeq library and the DisCoCat framework, we construct parameterized quantum circuits for sentence pairs and train them for both semantic relatedness and inference classification. To assess efficiency, we introduce a novel information-theoretic metric, Information Gain per Parameter (IGPP), which quantifies learning dynamics independent of model size. Our results demonstrate that quantum models achieve performance comparable to classical baselines while operating with dramatically fewer parameters. The Quantum-based models outperform randomly initialized transformers in inference and achieve lower test error on relatedness tasks. Moreover, quantum models exhibit significantly higher per-parameter learning efficiency (up to five orders of magnitude more than classical counterparts), highlighting the promise of QNLP in low-resource, structure-sensitive settings. To address circuit-level isolation and promote parameter sharing, we also propose a novel cluster-based architecture that improves generalization by tying gate parameters to learned word clusters rather than individual tokens.</li>
</ul>

<h3>Title: Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts</h3>
<ul>
<li><strong>Authors: </strong>Tiarnaigh Downey-Webb, Olamide Jogunola, Oluwaseun Ajao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15973">https://arxiv.org/abs/2510.15973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15973">https://arxiv.org/pdf/2510.15973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15973]] Safeguarding Efficacy in Large Language Models: Evaluating Resistance to Human-Written and Algorithmic Adversarial Prompts(https://arxiv.org/abs/2510.15973)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a systematic security assessment of four prominent Large Language Models (LLMs) against diverse adversarial attack vectors. We evaluate Phi-2, Llama-2-7B-Chat, GPT-3.5-Turbo, and GPT-4 across four distinct attack categories: human-written prompts, AutoDAN, Greedy Coordinate Gradient (GCG), and Tree-of-Attacks-with-pruning (TAP). Our comprehensive evaluation employs 1,200 carefully stratified prompts from the SALAD-Bench dataset, spanning six harm categories. Results demonstrate significant variations in model robustness, with Llama-2 achieving the highest overall security (3.4% average attack success rate) while Phi-2 exhibits the greatest vulnerability (7.0% average attack success rate). We identify critical transferability patterns where GCG and TAP attacks, though ineffective against their target model (Llama-2), achieve substantially higher success rates when transferred to other models (up to 17% for GPT-4). Statistical analysis using Friedman tests reveals significant differences in vulnerability across harm categories ($p < 0.001$), with malicious use prompts showing the highest attack success rates (10.71% average). Our findings contribute to understanding cross-model security vulnerabilities and provide actionable insights for developing targeted defense mechanisms</li>
</ul>

<h3>Title: Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity</h3>
<ul>
<li><strong>Authors: </strong>Zaixi Zhang, Souradip Chakraborty, Amrit Singh Bedi, Emilin Mathew, Varsha Saravanan, Le Cong, Alvaro Velasquez, Sheng Lin-Gibson, Megan Blewett, Dan Hendrycs, Alex John London, Ellen Zhong, Ben Raphael, Jian Ma, Eric Xing, Russ Altman, George Church, Mengdi Wang</a></li>
<li><strong>Subjects: </strong>cs.CR, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15975">https://arxiv.org/abs/2510.15975</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15975">https://arxiv.org/pdf/2510.15975</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15975]] Generative AI for Biosciences: Emerging Threats and Roadmap to Biosecurity(https://arxiv.org/abs/2510.15975)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense, attack, generative</a></li>
<li><strong>Abstract: </strong>The rapid adoption of generative artificial intelligence (GenAI) in the biosciences is transforming biotechnology, medicine, and synthetic biology. Yet this advancement is intrinsically linked to new vulnerabilities, as GenAI lowers the barrier to misuse and introduces novel biosecurity threats, such as generating synthetic viral proteins or toxins. These dual-use risks are often overlooked, as existing safety guardrails remain fragile and can be circumvented through deceptive prompts or jailbreak techniques. In this Perspective, we first outline the current state of GenAI in the biosciences and emerging threat vectors ranging from jailbreak attacks and privacy risks to the dual-use challenges posed by autonomous AI agents. We then examine urgent gaps in regulation and oversight, drawing on insights from 130 expert interviews across academia, government, industry, and policy. A large majority ($\approx 76$\%) expressed concern over AI misuse in biology, and 74\% called for the development of new governance frameworks. Finally, we explore technical pathways to mitigation, advocating a multi-layered approach to GenAI safety. These defenses include rigorous data filtering, alignment with ethical principles during development, and real-time monitoring to block harmful requests. Together, these strategies provide a blueprint for embedding security throughout the GenAI lifecycle. As GenAI becomes integrated into the biosciences, safeguarding this frontier requires an immediate commitment to both adaptive governance and secure-by-design technologies.</li>
</ul>

<h3>Title: Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization</h3>
<ul>
<li><strong>Authors: </strong>Chenrui Wang, Junyi Shu, Billy Chiu, Yu Li, Saleh Alharbi, Min Zhang, Jing Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15976">https://arxiv.org/abs/2510.15976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15976">https://arxiv.org/pdf/2510.15976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15976]] Learning to Watermark: A Selective Watermarking Framework for Large Language Models via Multi-Objective Optimization(https://arxiv.org/abs/2510.15976)</code><input type="text"></li>
<li><strong>Keywords: </strong>watermark, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of LLMs has raised concerns about their potential misuse, leading to various watermarking schemes that typically offer high detectability. However, existing watermarking techniques often face trade-off between watermark detectability and generated text quality. In this paper, we introduce Learning to Watermark (LTW), a novel selective watermarking framework that leverages multi-objective optimization to effectively balance these competing goals. LTW features a lightweight network that adaptively decides when to apply the watermark by analyzing sentence embeddings, token entropy, and current watermarking ratio. Training of the network involves two specifically constructed loss functions that guide the model toward Pareto-optimal solutions, thereby harmonizing watermark detectability and text quality. By integrating LTW with two baseline watermarking methods, our experimental evaluations demonstrate that LTW significantly enhances text quality without compromising detectability. Our selective watermarking approach offers a new perspective for designing watermarks for LLMs and a way to preserve high text quality for watermarks. The code is publicly available at: this https URL</li>
</ul>

<h3>Title: Bolster Hallucination Detection via Prompt-Guided Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Wenyun Li, Zheng Zhang, Dongmei Jiang, Xiangyuan Lan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15977">https://arxiv.org/abs/2510.15977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15977">https://arxiv.org/pdf/2510.15977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15977]] Bolster Hallucination Detection via Prompt-Guided Data Augmentation(https://arxiv.org/abs/2510.15977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have garnered significant interest in AI community. Despite their impressive generation capabilities, they have been found to produce misleading or fabricated information, a phenomenon known as hallucinations. Consequently, hallucination detection has become critical to ensure the reliability of LLM-generated content. One primary challenge in hallucination detection is the scarcity of well-labeled datasets containing both truthful and hallucinated outputs. To address this issue, we introduce Prompt-guided data Augmented haLlucination dEtection (PALE), a novel framework that leverages prompt-guided responses from LLMs as data augmentation for hallucination detection. This strategy can generate both truthful and hallucinated data under prompt guidance at a relatively low cost. To more effectively evaluate the truthfulness of the sparse intermediate embeddings produced by LLMs, we introduce an estimation metric called the Contrastive Mahalanobis Score (CM Score). This score is based on modeling the distributions of truthful and hallucinated data in the activation space. CM Score employs a matrix decomposition approach to more accurately capture the underlying structure of these distributions. Importantly, our framework does not require additional human annotations, offering strong generalizability and practicality for real-world applications. Extensive experiments demonstrate that PALE achieves superior hallucination detection performance, outperforming the competitive baseline by a significant margin of 6.55%.</li>
</ul>

<h3>Title: DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space</h3>
<ul>
<li><strong>Authors: </strong>Junchao Gong, Jingyi Xu, Ben Fei, Fenghua Ling, Wenlong Zhang, Kun Chen, Wanghan Xu, Weidong Yang, Xiaokang Yang, Lei Bai</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15978">https://arxiv.org/abs/2510.15978</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15978">https://arxiv.org/pdf/2510.15978</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15978]] DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space(https://arxiv.org/abs/2510.15978)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Weather prediction is a critical task for human society, where impressive progress has been made by training artificial intelligence weather prediction (AIWP) methods with reanalysis data. However, reliance on reanalysis data limits the AIWPs with shortcomings, including data assimilation biases and temporal discrepancies. To liberate AIWPs from the reanalysis data, observation forecasting emerges as a transformative paradigm for weather prediction. One of the key challenges in observation forecasting is learning spatiotemporal dynamics across disparate measurement systems with irregular high-resolution observation data, which constrains the design and prediction of AIWPs. To this end, we propose our DAWP as an innovative framework to enable AIWPs to operate in a complete observation space by initialization with an artificial intelligence data assimilation (AIDA) module. Specifically, our AIDA module applies a mask multi-modality autoencoder(MMAE)for assimilating irregular satellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a spatiotemporal decoupling transformer with cross-regional boundary conditioning (CBC), learning the dynamics in observation space, to enable sub-image-based global observation forecasting. Comprehensive experiments demonstrate that AIDA initialization significantly improves the roll out and efficiency of AIWP. Additionally, we show that DAWP holds promising potential to be applied in global precipitation forecasting.</li>
</ul>

<h3>Title: Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zexu Sun, Yongcheng Zeng, Erxue Min, Heyang Gao, Bokai Ji, Xu Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15979">https://arxiv.org/abs/2510.15979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15979">https://arxiv.org/pdf/2510.15979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15979]] Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning(https://arxiv.org/abs/2510.15979)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Contemporary progress in large language models (LLMs) has revealed notable inferential capacities via reinforcement learning (RL) employing verifiable reward, facilitating the development of O1 and R1-like reasoning models. Directly training from base models with RL is called zero-RL. However, previous works rely upon activating LLMs' inherent capacities through fixed prompt templates. This strategy introduces substantial sampling inefficiencies for weak LLMs, as the majority of problems generate invalid outputs during accuracy-driven filtration in reasoning tasks, which causes a waste of samples. To solve this issue, we propose Cog-Rethinker, a novel hierarchical metacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses on the rollout procedure in RL training. After the direct rollout, our Cog-Rethinker improves sample utilization in a hierarchical metacognitive two-stage framework. By leveraging human cognition during solving problems, firstly, it prompts policy to decompose zero-accuracy problems into subproblems to produce final reasoning results. Secondly, with zero-accuracy problems in previous rollout stage, it further prompts policy to refine these answers by referencing previous wrong solutions. Moreover, to enable cold-start of the two new reasoning patterns and maintain train-test consistency across prompt templates, our Cog-Rethinker applies supervised fine-tuning on the policy using correct samples of the two stages with direct rollout template. Experimental results demonstrate Cog-Rethinker's superior performance on various mathematical reasoning benchmarks, we also analyzed its improved sample efficiency that accelerates convergence compared to baseline methods.</li>
</ul>

<h3>Title: AMiD: Knowledge Distillation for LLMs with $α$-mixture Assistant Distribution</h3>
<ul>
<li><strong>Authors: </strong>Donghyeok Shin, Yeongmin Kim, Suhyeon Jo, Byeonghu Na, Il-Chul Moon</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15982">https://arxiv.org/abs/2510.15982</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15982">https://arxiv.org/pdf/2510.15982</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15982]] AMiD: Knowledge Distillation for LLMs with $α$-mixture Assistant Distribution(https://arxiv.org/abs/2510.15982)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autoregressive large language models (LLMs) have achieved remarkable improvement across many tasks but incur high computational and memory costs. Knowledge distillation (KD) mitigates this issue by transferring knowledge from a large teacher to a smaller student through distributional alignment. Previous studies have proposed various discrepancy metrics, but the capacity gap and training instability caused by near-zero probabilities, stemming from the high-dimensional output of LLMs, remain fundamental limitations. To overcome these challenges, several approaches implicitly or explicitly incorporating assistant distribution have recently been proposed. However, the past proposals of assistant distributions have been a fragmented approach without a systematic investigation of the interpolation path and the divergence. This paper proposes $\alpha$-mixture assistant distribution, a novel generalized family of assistant distributions, and $\alpha$-mixture distillation, coined AMiD, a unified framework for KD using the assistant distribution. The $\alpha$-mixture assistant distribution provides a continuous extension of the assistant distribution by introducing a new distribution design variable $\alpha$, which has been fixed in all previous approaches. Furthermore, AMiD generalizes the family of divergences used with the assistant distributions based on optimality, which has also been restricted in previous works. Through extensive experiments, we demonstrate that AMiD offers superior performance and training stability by leveraging a broader and theoretically grounded assistant distribution space.</li>
</ul>

<h3>Title: Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Samuel Lippl, Thomas McGee, Kimberly Lopez, Ziwen Pan, Pierce Zhang, Salma Ziadi, Oliver Eberle, Ida Momennejad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15987">https://arxiv.org/abs/2510.15987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15987">https://arxiv.org/pdf/2510.15987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15987]] Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models(https://arxiv.org/abs/2510.15987)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>How do latent and inference time computations enable large language models (LLMs) to solve multi-step reasoning? We introduce a framework for tracing and steering algorithmic primitives that underlie model reasoning. Our approach links reasoning traces to internal activation patterns and evaluates algorithmic primitives by injecting them into residual streams and measuring their effect on reasoning steps and task performance. We consider four benchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph navigation. We operationalize primitives by clustering neural activations and labeling their matched reasoning traces. We then apply function vector methods to derive primitive vectors as reusable compositional building blocks of reasoning. Primitive vectors can be combined through addition, subtraction, and scalar operations, revealing a geometric logic in activation space. Cross-task and cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both shared and task-specific primitives. Notably, comparing Phi-4 with its reasoning-finetuned variant highlights compositional generalization after finetuning: Phi-4-Reasoning exhibits more systematic use of verification and path-generation primitives. Injecting the associated primitive vectors in Phi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning. Together, these findings demonstrate that reasoning in LLMs may be supported by a compositional geometry of algorithmic primitives, that primitives transfer cross-task and cross-model, and that reasoning finetuning strengthens algorithmic generalization across domains.</li>
</ul>

<h3>Title: Meta-Guardian: An Early Evaluation of an On-device Application to Mitigate Psychography Data Leakage in Immersive Technologies</h3>
<ul>
<li><strong>Authors: </strong>Keshav Sood, Sanjay Selvaraj, Youyang Qu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.ET</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15989">https://arxiv.org/abs/2510.15989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15989">https://arxiv.org/pdf/2510.15989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15989]] Meta-Guardian: An Early Evaluation of an On-device Application to Mitigate Psychography Data Leakage in Immersive Technologies(https://arxiv.org/abs/2510.15989)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, biometric</a></li>
<li><strong>Abstract: </strong>The use of Immersive Technologies has shown its potential to revolutionize many sectors such as health, entertainment, education, and industrial sectors. Immersive technologies such as Virtual Reality (VR), Augmented reality (AR), and Mixed Reality (MR) have redefined user interaction through real-time biometric and behavioral tracking. Although Immersive Technologies (XR) essentially need the collection of the biometric data which acts as a baseline to create immersive experience, however, this ongoing feedback information (includes biometrics) poses critical privacy concerns due to the sensitive nature of the data collected. A comprehensive review of recent literature explored the technical dimensions of related problem; however, they largely overlook the challenge particularly the intricacies of real-time biometric data filtering within head-mounted display system. Motivated from this, in this work, we propose a novel privacy-preserving system architecture that identifies and filters biometric signals (within the VR headset) in real-time before transmission or storage. Implemented as a modular Unity Software-development Kit (SDK) compatible with major immersive platforms, our solution (named Meta-Guardian) employs machine learning models for signal classification and a filtering mechanism to block sensitive data. This framework aims to enable developers to embed privacy-by-design principles into immersive experiences on various headsets and applications.</li>
</ul>

<h3>Title: Can GRPO Help LLMs Transcend Their Pretraining Origin?</h3>
<ul>
<li><strong>Authors: </strong>Kangqi Ni, Zhen Tan, Zijie Liu, Pingzhi Li, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15990">https://arxiv.org/abs/2510.15990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15990">https://arxiv.org/pdf/2510.15990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15990]] Can GRPO Help LLMs Transcend Their Pretraining Origin?(https://arxiv.org/abs/2510.15990)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by the Group Relative Policy Optimization (GRPO) algorithm, is a leading approach for enhancing the reasoning abilities of Large Language Models (LLMs). Despite its wide adoption, GRPO's gains are often inconsistent; for instance, a model may show significant improvement in one reasoning domain, like mathematics, yet remain stagnant in another, such as medicine. This inconsistency raises a critical question: under what conditions does GRPO improve reasoning and generalize out-of-distribution (OOD)? We investigate this from a data distribution perspective. We first prove theoretically that GRPO is a conservative reweighting scheme, bounded by the base model's distribution and thus unable to discover completely novel solutions. We further validate this in carefully designed controlled studies by training transformers from scratch, evaluating generalization across reasoning depth, input length, token representation, and compositionality. Our results provide a principled explanation for GRPO's boundaries: OOD improvement emerges only when the target task aligns with the model's pretrained biases, while gains on in-distribution (ID) tasks diminish as performance saturates. This reframes GRPO not as a universal reasoning enhancer but as a tool that sharpens pretraining biases. Our findings motivate future development of algorithms that can expand a model's capabilities beyond its pretraining origin.</li>
</ul>

<h3>Title: CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection</h3>
<ul>
<li><strong>Authors: </strong>Huiming Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15991">https://arxiv.org/abs/2510.15991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15991">https://arxiv.org/pdf/2510.15991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15991]] CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection(https://arxiv.org/abs/2510.15991)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The sparse cross-modality detector offers more advantages than its counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of adaptability for downstream tasks and computational cost savings. However, existing sparse detectors overlook the quality of token representation, leaving it with a sub-optimal foreground quality and limited performance. In this paper, we identify that the geometric structure preserved and the class distribution are the key to improving the performance of the sparse detector, and propose a Sparse Selector (SS). The core module of SS is Ray-Aware Supervision (RAS), which preserves rich geometric information during the training stage, and Class-Balanced Supervision, which adaptively reweights the salience of class semantics, ensuring that tokens associated with small objects are retained during token sampling. Thereby, outperforming other sparse multi-modal detectors in the representation of tokens. Additionally, we design Ray Positional Encoding (Ray PE) to address the distribution differences between the LiDAR modality and the image. Finally, we integrate the aforementioned module into an end-to-end sparse multi-modality detector, dubbed CrossRay3D. Experiments show that, on the challenging nuScenes benchmark, CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS, while running 1.84 faster than other leading methods. Moreover, CrossRay3D demonstrates strong robustness even in scenarios where LiDAR or camera data are partially or entirely missing.</li>
</ul>

<h3>Title: Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments</h3>
<ul>
<li><strong>Authors: </strong>Ziming Dai, Tuo Zhang, Fei Gao, Xingyi Cai, Xiaofei Wang, Cheng Zhang, Wenyu Wang, Chengjie Zang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15992">https://arxiv.org/abs/2510.15992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15992">https://arxiv.org/pdf/2510.15992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15992]] Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments(https://arxiv.org/abs/2510.15992)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The growing industrial demand for customized and cost-efficient large language models (LLMs) is fueled by the rise of vertical, domain-specific tasks and the need to optimize performance under constraints such as latency and budget. Knowledge distillation, as an efficient model compression and transfer technique, offers a feasible solution. However, existing distillation frameworks often require manual intervention and struggle to meet such complex user-defined distillation requirements. To bridge this gap, we propose Stratos, an end-to-end LLM distillation pipeline that automates server and model selection, knowledge distillation, and deployment in distributed cloud environments. Given user-defined constraints on model performance and system budget, Stratos automatically selects Pareto-optimal servers, dynamically matches teacher-student pairs, and adapts distillation strategies based on task complexity to optimize cloud hosting. Experiments show that Stratos produces a student model that achieves four times the accuracy of its GPT-4o teacher baseline on a rare, domain-specific Mahjong reasoning task with reverse synthetic data and knowledge injection. Moreover, it achieves reduced latency and cost without compromising accuracy. These results highlight its promise for vertical-domain LLM deployment.</li>
</ul>

<h3>Title: MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Dongsen Zhang, Zekun Li, Xu Luo, Xuannan Liu, Peipei Li, Wenjun Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.15994">https://arxiv.org/abs/2510.15994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.15994">https://arxiv.org/pdf/2510.15994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.15994]] MCP Security Bench (MSB): Benchmarking Attacks Against Model Context Protocol in LLM Agents(https://arxiv.org/abs/2510.15994)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>The Model Context Protocol (MCP) standardizes how large language model (LLM) agents discover, describe, and call external tools. While MCP unlocks broad interoperability, it also enlarges the attack surface by making tools first-class, composable objects with natural-language metadata, and standardized I/O. We present MSB (MCP Security Benchmark), the first end-to-end evaluation suite that systematically measures how well LLM agents resist MCP-specific attacks throughout the full tool-use pipeline: task planning, tool invocation, and response handling. MSB contributes: (1) a taxonomy of 12 attacks including name-collision, preference manipulation, prompt injections embedded in tool descriptions, out-of-scope parameter requests, user-impersonating responses, false-error escalation, tool-transfer, retrieval injection, and mixed attacks; (2) an evaluation harness that executes attacks by running real tools (both benign and malicious) via MCP rather than simulation; and (3) a robustness metric that quantifies the trade-off between security and performance: Net Resilient Performance (NRP). We evaluate nine popular LLM agents across 10 domains and 400+ tools, producing 2,000 attack instances. Results reveal the effectiveness of attacks against each stage of MCP. Models with stronger performance are more vulnerable to attacks due to their outstanding tool calling and instruction following capabilities. MSB provides a practical baseline for researchers and practitioners to study, compare, and harden MCP agents.</li>
</ul>

<h3>Title: Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers</h3>
<ul>
<li><strong>Authors: </strong>Giacomo Bertollo, Naz Bodemir, Jonah Burgess</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16005">https://arxiv.org/abs/2510.16005</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16005">https://arxiv.org/pdf/2510.16005</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16005]] Breaking Guardrails, Facing Walls: Insights on Adversarial AI for Defenders & Researchers(https://arxiv.org/abs/2510.16005)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense</a></li>
<li><strong>Abstract: </strong>Analyzing 500 CTF participants, this paper shows that while participants readily bypassed simple AI guardrails using common techniques, layered multi-step defenses still posed significant challenges, offering concrete insights for building safer AI systems.</li>
</ul>

<h3>Title: Transfer learning strategies for accelerating reinforcement-learning-based flow control</h3>
<ul>
<li><strong>Authors: </strong>Saeed Salehi</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.flu-dyn</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16016">https://arxiv.org/abs/2510.16016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16016">https://arxiv.org/pdf/2510.16016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16016]] Transfer learning strategies for accelerating reinforcement-learning-based flow control(https://arxiv.org/abs/2510.16016)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work investigates transfer learning strategies to accelerate deep reinforcement learning (DRL) for multifidelity control of chaotic fluid flows. Progressive neural networks (PNNs), a modular architecture designed to preserve and reuse knowledge across tasks, are employed for the first time in the context of DRL-based flow control. In addition, a comprehensive benchmarking of conventional fine-tuning strategies is conducted, evaluating their performance, convergence behavior, and ability to retain transferred knowledge. The Kuramoto-Sivashinsky (KS) system is employed as a benchmark to examine how knowledge encoded in control policies, trained in low-fidelity environments, can be effectively transferred to high-fidelity settings. Systematic evaluations show that while fine-tuning can accelerate convergence, it is highly sensitive to pretraining duration and prone to catastrophic forgetting. In contrast, PNNs enable stable and efficient transfer by preserving prior knowledge and providing consistent performance gains, and are notably robust to overfitting during the pretraining phase. Layer-wise sensitivity analysis further reveals how PNNs dynamically reuse intermediate representations from the source policy while progressively adapting deeper layers to the target task. Moreover, PNNs remain effective even when the source and target environments differ substantially, such as in cases with mismatched physical regimes or control objectives, where fine-tuning strategies often result in suboptimal adaptation or complete failure of knowledge transfer. The results highlight the potential of novel transfer learning frameworks for robust, scalable, and computationally efficient flow control that can potentially be applied to more complex flow configurations.</li>
</ul>

<h3>Title: InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects</h3>
<ul>
<li><strong>Authors: </strong>Ibrahim Sheikh Mohamed, Abdullah Yahya Abdullah Omaisan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16017">https://arxiv.org/abs/2510.16017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16017">https://arxiv.org/pdf/2510.16017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16017]] InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects(https://arxiv.org/abs/2510.16017)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Infrastructure in smart cities is increasingly monitored by networks of closed circuit television (CCTV) cameras. Roads, bridges and tunnels develop cracks, potholes, and fluid leaks that threaten public safety and require timely repair. Manual inspection is costly and hazardous, and existing automatic systems typically address individual defect types or provide unstructured outputs that cannot directly guide maintenance crews. This paper proposes a comprehensive pipeline that leverages street CCTV streams for multi defect detection and segmentation using the YOLO family of object detectors and passes the detections to a vision language model (VLM) for scene aware summarization. The VLM generates a structured action plan in JSON format that includes incident descriptions, recommended tools, dimensions, repair plans, and urgent alerts. We review literature on pothole, crack and leak detection, highlight recent advances in large vision language models such as QwenVL and LLaVA, and describe the design of our early prototype. Experimental evaluation on public datasets and captured CCTV clips demonstrates that the system accurately identifies diverse defects and produces coherent summaries. We conclude by discussing challenges and directions for scaling the system to city wide deployments.</li>
</ul>

<h3>Title: Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization</h3>
<ul>
<li><strong>Authors: </strong>Changsheng Wang, Xin Chen, Sijia Liu, Ke Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16022">https://arxiv.org/abs/2510.16022</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16022">https://arxiv.org/pdf/2510.16022</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16022]] Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization(https://arxiv.org/abs/2510.16022)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Adapting pretrained large language models (LLMs) to code domains via supervised fine-tuning (FT) has been commonly used for code generation. However, we identify a previously underappreciated failure mode, the memorization barrier, where strong memorization of downstream code data in the base model could trap optimization and prevent the standard FT from effectively acquiring new, generalizable code knowledge. To overcome this barrier, we propose the information bottleneck (IB)-guided fine-tuning, termed IB-FT, which applies an IB penalty on hidden representations of the code data to compress spurious, memorized features while preserving task-relevant information. Extensive experiments on two code benchmarks (OriGen and Evol-CodeAlpaca-V1) show that IB-FT substantially alleviates the memorization barrier, improves top-1 performance (Pass@$1$), and yields far more stable gains under the stricter multi-sample metric Pass@$k^{(m)}$ (a problem counts as solved only if at least $m$ of $k$ samples pass unit tests) compared with conventional FT.</li>
</ul>

<h3>Title: Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Fanmeng Wang, Shan Mei, Wentao Guo, Hongshuai Wang, Qi Ou, Zhifeng Gao, Hongteng Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16023">https://arxiv.org/abs/2510.16023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16023">https://arxiv.org/pdf/2510.16023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16023]] Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model(https://arxiv.org/abs/2510.16023)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Polymers, macromolecules formed from covalently bonded monomers, underpin countless technologies and are indispensable to modern life. While deep learning is advancing polymer science, existing methods typically represent the whole polymer solely through monomer-level descriptors, overlooking the global structural information inherent in polymer conformations, which ultimately limits their practical performance. Moreover, this field still lacks a universal foundation model that can effectively support diverse downstream tasks, thereby severely constraining progress. To address these challenges, we introduce PolyConFM, the first polymer foundation model that unifies polymer modeling and design through conformation-centric generative pretraining. Recognizing that each polymer conformation can be decomposed into a sequence of local conformations (i.e., those of its repeating units), we pretrain PolyConFM under the conditional generation paradigm, reconstructing these local conformations via masked autoregressive (MAR) modeling and further generating their orientation transformations to recover the corresponding polymer conformation. Besides, we construct the first high-quality polymer conformation dataset via molecular dynamics simulations to mitigate data sparsity, thereby enabling conformation-centric pretraining. Experiments demonstrate that PolyConFM consistently outperforms representative task-specific methods on diverse downstream tasks, equipping polymer science with a universal and powerful tool.</li>
</ul>

<h3>Title: On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Abdulrahman Alhaidari, Balaji Palanisamy, Prashant Krishnamurthy</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16024">https://arxiv.org/abs/2510.16024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16024">https://arxiv.org/pdf/2510.16024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16024]] On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation(https://arxiv.org/abs/2510.16024)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Billions of dollars are lost every year in DeFi platforms by transactions exploiting business logic or accounting vulnerabilities. Existing defenses focus on static code analysis, public mempool screening, attacker contract detection, or trusted off-chain monitors, none of which prevents exploits submitted through private relays or malicious contracts that execute within the same block. We present the first decentralized, fully on-chain learning framework that: (i) performs gas-prohibitive computation on Layer-2 to reduce cost, (ii) propagates verified model updates to Layer-1, and (iii) enables gas-bounded, low-latency inference inside smart contracts. A novel Proof-of-Improvement (PoIm) protocol governs the training process and verifies each decentralized micro update as a self-verifying training transaction. Updates are accepted by \textit{PoIm} only if they demonstrably improve at least one core metric (e.g., accuracy, F1-score, precision, or recall) on a public benchmark without degrading any of the other core metrics, while adversarial proposals get financially penalized through an adaptable test set for evolving threats. We develop quantization and loop-unrolling techniques that enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs (with support for formally verified decision tree inference) within the Ethereum block gas limit, while remaining bit-exact to their off-chain counterparts, formally proven in Z3. We curate 298 unique real-world exploits (2020 - 2025) with 402 exploit transactions across eight EVM chains, collectively responsible for \$3.74 B in losses.</li>
</ul>

<h3>Title: Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Jianzhu Yao, Hongxu Su, Taobo Liao, Zerui Cheng, Huan Zhang, Xuechao Wang, Pramod Viswanath</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16028">https://arxiv.org/abs/2510.16028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16028">https://arxiv.org/pdf/2510.16028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16028]] Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks(https://arxiv.org/abs/2510.16028)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Neural networks increasingly run on hardware outside the user's control (cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about what actually ran or whether returned outputs faithfully reflect the intended inputs. Users lack recourse against service downgrades (model swaps, quantization, graph rewrites, or discrepancies like altered ad embeddings). Verifying outputs is hard because floating-point(FP) execution on heterogeneous accelerators is inherently nondeterministic. Existing approaches are either impractical for real FP neural networks or reintroduce vendor trust. We present NAO: a Nondeterministic tolerance Aware Optimistic verification protocol that accepts outputs within principled operator-level acceptance regions rather than requiring bitwise equality. NAO combines two error models: (i) sound per-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile profiles calibrated across hardware. Discrepancies trigger a Merkle-anchored, threshold-guided dispute game that recursively partitions the computation graph until one operator remains, where adjudication reduces to a lightweight theoretical-bound check or a small honest-majority vote against empirical thresholds. Unchallenged results finalize after a challenge window, without requiring trusted hardware or deterministic kernels. We implement NAO as a PyTorch-compatible runtime and a contract layer currently deployed on Ethereum Holesky testnet. The runtime instruments graphs, computes per-operator bounds, and runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on Qwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100, RTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than theoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO reconciles scalability with verifiability for real-world heterogeneous ML compute.</li>
</ul>

<h3>Title: RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction</h3>
<ul>
<li><strong>Authors: </strong>Yingguang Yang, Xianghua Zeng, Qi Wu, Hao Peng, Yutong Xia, Hao Liu, Bin Chong, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16035">https://arxiv.org/abs/2510.16035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16035">https://arxiv.org/pdf/2510.16035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16035]] RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction(https://arxiv.org/abs/2510.16035)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, diffusion</a></li>
<li><strong>Abstract: </strong>Social networks have become a crucial source of real-time information for individuals. The influence of social bots within these platforms has garnered considerable attention from researchers, leading to the development of numerous detection technologies. However, the vulnerability and robustness of these detection methods is still underexplored. Existing Graph Neural Network (GNN)-based methods cannot be directly applied due to the issues of limited control over social agents, the black-box nature of bot detectors, and the heterogeneity of bots. To address these challenges, this paper proposes the first adversarial multi-agent Reinforcement learning framework for social Bot control attacks (RoBCtrl) targeting GNN-based social bot detectors. Specifically, we use a diffusion model to generate high-fidelity bot accounts by reconstructing existing account data with minor modifications, thereby evading detection on social platforms. To the best of our knowledge, this is the first application of diffusion models to mimic the behavior of evolving social bots effectively. We then employ a Multi-Agent Reinforcement Learning (MARL) method to simulate bots adversarial behavior. We categorize social accounts based on their influence and budget. Different agents are then employed to control bot accounts across various categories, optimizing the attachment strategy through reinforcement learning. Additionally, a hierarchical state abstraction based on structural entropy is designed to accelerate the reinforcement learning. Extensive experiments on social bot detection datasets demonstrate that our framework can effectively undermine the performance of GNN-based detectors.</li>
</ul>

<h3>Title: IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Zewen Li, Zitong Yu, Qilang Ye, Weicheng Xie, Wei Zhuo, Linlin Shen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16036">https://arxiv.org/abs/2510.16036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16036">https://arxiv.org/pdf/2510.16036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16036]] IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection(https://arxiv.org/abs/2510.16036)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model, segmentation</a></li>
<li><strong>Abstract: </strong>The robust causal capability of Multimodal Large Language Models (MLLMs) hold the potential of detecting defective objects in Industrial Anomaly Detection (IAD). However, most traditional IAD methods lack the ability to provide multi-turn human-machine dialogues and detailed descriptions, such as the color of objects, the shape of an anomaly, or specific types of anomalies. At the same time, methods based on large pre-trained models have not fully stimulated the ability of large models in anomaly detection tasks. In this paper, we explore the combination of rich text semantics with both image-level and pixel-level information from images and propose IAD-GPT, a novel paradigm based on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate detailed anomaly prompts for specific objects. These specific prompts from the large language model (LLM) are used to activate the detection and segmentation functions of the pre-trained visual-language model (i.e., CLIP). To enhance the visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein image features interact with normal and abnormal text prompts to dynamically select enhancement pathways, which enables language models to focus on specific aspects of visual data, enhancing their ability to accurately interpret and respond to anomalies within images. Moreover, we design a Multi-Mask Fusion module to incorporate mask as expert knowledge, which enhances the LLM's perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA datasets demonstrate our state-of-the-art performance on self-supervised and few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA datasets. The codes are available at \href{this https URL}{this https URL}.</li>
</ul>

<h3>Title: Membership Inference over Diffusion-models-based Synthetic Tabular Data</h3>
<ul>
<li><strong>Authors: </strong>Peini Cheng, Amir Bahmani</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16037">https://arxiv.org/abs/2510.16037</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16037">https://arxiv.org/pdf/2510.16037</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16037]] Membership Inference over Diffusion-models-based Synthetic Tabular Data(https://arxiv.org/abs/2510.16037)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, membership infer, diffusion</a></li>
<li><strong>Abstract: </strong>This study investigates the privacy risks associated with diffusion-based synthetic tabular data generation methods, focusing on their susceptibility to Membership Inference Attacks (MIAs). We examine two recent models, TabDDPM and TabSyn, by developing query-based MIAs based on the step-wise error comparison method. Our findings reveal that TabDDPM is more vulnerable to these attacks. TabSyn exhibits resilience against our attack models. Our work underscores the importance of evaluating the privacy implications of diffusion models and encourages further research into robust privacy-preserving mechanisms for synthetic data generation.</li>
</ul>

<h3>Title: A Novel GPT-Based Framework for Anomaly Detection in System Logs</h3>
<ul>
<li><strong>Authors: </strong>Zeng Zhang, Wenjie Yin, Xiaoqi Li</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16044">https://arxiv.org/abs/2510.16044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16044">https://arxiv.org/pdf/2510.16044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16044]] A Novel GPT-Based Framework for Anomaly Detection in System Logs(https://arxiv.org/abs/2510.16044)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, transformer</a></li>
<li><strong>Abstract: </strong>Identification of anomalous events within system logs constitutes a pivotal element within the frame- work of cybersecurity defense strategies. However, this process faces numerous challenges, including the management of substantial data volumes, the distribution of anomalies, and the precision of con- ventional methods. To address this issue, the present paper puts forward a proposal for an intelligent detection method for system logs based on Genera- tive Pre-trained Transformers (GPT). The efficacy of this approach is attributable to a combination of structured input design and a Focal Loss op- timization strategy, which collectively result in a substantial enhancement of the performance of log anomaly detection. The initial approach involves the conversion of raw logs into event ID sequences through the use of the Drain parser. Subsequently, the Focal Loss loss function is employed to address the issue of class imbalance. The experimental re- sults demonstrate that the optimized GPT-2 model significantly outperforms the unoptimized model in a range of key metrics, including precision, recall, and F1 score. In specific tasks, comparable or superior performance has been demonstrated to that of the GPT-3.5 API.</li>
</ul>

<h3>Title: AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization</h3>
<ul>
<li><strong>Authors: </strong>Mengtao Lv, Ruiqi Zhu, Xinyu Wang, Yun Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16045">https://arxiv.org/abs/2510.16045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16045">https://arxiv.org/pdf/2510.16045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16045]] AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization(https://arxiv.org/abs/2510.16045)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in various kinds of tasks, while the billion or even trillion parameters bring storage and efficiency bottlenecks for inference. Quantization, particularly floating-point quantization, is known to be capable of speeding up LLM inference by reducing memory footprint and data movement during the inference process. For the first time, we advance the floating-point quantization exploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant, to further approach the quantization sweet spot. AMS-Quant incorporates two novel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing, which groups k quantized weights and lets them share the least significant mantissa bit, allowing us to further approach the minimum quantization bit-width without accuracy loss. (2) It introduces Adaptive Searching, which employs an offline optimization strategy to minimize the accuracy degradation introduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA Linear kernels, which translates memory savings into wall-clock latency reduction by reducing memory access. Extensive experiments on large-scale datasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3 and FP4.25-e2m2, and significantly speed up the LLM decoding over FP16 inference (2.8x and 3.2x), with negligible accuracy loss.</li>
</ul>

<h3>Title: GUIrilla: A Scalable Framework for Automated Desktop UI Exploration</h3>
<ul>
<li><strong>Authors: </strong>Sofiya Garkot, Maksym Shamrai, Ivan Synytsia, Mariya Hirna</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16051">https://arxiv.org/abs/2510.16051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16051">https://arxiv.org/pdf/2510.16051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16051]] GUIrilla: A Scalable Framework for Automated Desktop UI Exploration(https://arxiv.org/abs/2510.16051)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Autonomous agents capable of operating complex graphical user interfaces (GUIs) have the potential to transform desktop automation. While recent advances in large language models (LLMs) have significantly improved UI understanding, navigating full-window, multi-application desktop environments remains a major challenge. Data availability is limited by costly manual annotation, closed-source datasets and surface-level synthetic pipelines. We introduce GUIrilla, an automated scalable framework that systematically explores applications via native accessibility APIs to address the critical data collection challenge in GUI automation. Our framework focuses on macOS - an ecosystem with limited representation in current UI datasets - though many of its components are designed for broader cross-platform applicability. GUIrilla organizes discovered interface elements and crawler actions into hierarchical GUI graphs and employs specialized interaction handlers to achieve comprehensive application coverage. Using the application graphs from GUIrilla crawler, we construct and release GUIrilla-Task, a large-scale dataset of 27,171 functionally grounded tasks across 1,108 macOS applications, each annotated with full-desktop and window-level screenshots, accessibility metadata, and semantic action traces. Empirical results show that tuning LLM-based agents on GUIrilla-Task significantly improves performance on downstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro benchmark while using 97% less data. We also release macapptree, an open-source library for reproducible collection of structured accessibility metadata, along with the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold benchmark, and the framework code to support open research in desktop autonomy.</li>
</ul>

<h3>Title: PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation</h3>
<ul>
<li><strong>Authors: </strong>Zheng Hui, Yijiang River Dong, Sanhanat Sivapiromrat, Ehsan Shareghi, Nigel Collier</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16054">https://arxiv.org/abs/2510.16054</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16054">https://arxiv.org/pdf/2510.16054</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16054]] PrivacyPAD: A Reinforcement Learning Framework for Dynamic Privacy-Aware Delegation(https://arxiv.org/abs/2510.16054)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, large language model</a></li>
<li><strong>Abstract: </strong>When users submit queries to Large Language Models (LLMs), their prompts can often contain sensitive data, forcing a difficult choice: Send the query to a powerful proprietary LLM providers to achieving state-of-the-art performance and risk data exposure, or relying on smaller, local models guarantees data privacy but often results in a degradation of task performance. Prior approaches have relied on static pipelines that use LLM rewriting, which shatters linguistic coherence and indiscriminately removes privacy-sensitive information, including task-critical content. We reformulate this challenge (Privacy-Conscious Delegation) as a sequential decision-making problem and introduce a novel reinforcement learning (RL) framework called PrivacyPAD to solve it. Our framework trains an agent to dynamically route text chunks, learning a policy that optimally balances the trade-off between privacy leakage and task performance. It implicitly distinguishes between replaceable Personally Identifiable Information (PII) (which it shields locally) and task-critical PII (which it strategically sends to the remote model for maximal utility). To validate our approach in complex scenarios, we also introduce a new medical dataset with high PII density. Our framework achieves a new state-of-the-art on the privacy-utility frontier, demonstrating the necessity of learned, adaptive policies for deploying LLMs in sensitive environments.</li>
</ul>

<h3>Title: Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus</h3>
<ul>
<li><strong>Authors: </strong>Md Kamrul Siam, Md Jobair Hossain Faruk, Jerry Q. Cheng, Huanying Gu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16057">https://arxiv.org/abs/2510.16057</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16057">https://arxiv.org/pdf/2510.16057</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16057]] Fusion-Augmented Large Language Models: Boosting Diagnostic Trustworthiness via Model Consensus(https://arxiv.org/abs/2510.16057)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study presents a novel multi-model fusion framework leveraging two state-of-the-art large language models (LLMs), ChatGPT and Claude, to enhance the reliability of chest X-ray interpretation on the CheXpert dataset. From the full CheXpert corpus of 224,316 chest radiographs, we randomly selected 234 radiologist-annotated studies to evaluate unimodal performance using image-only prompts. In this setting, ChatGPT and Claude achieved diagnostic accuracies of 62.8% and 76.9%, respectively. A similarity-based consensus approach, using a 95% output similarity threshold, improved accuracy to 77.6%. To assess the impact of multimodal inputs, we then generated synthetic clinical notes following the MIMIC-CXR template and evaluated a separate subset of 50 randomly selected cases paired with both images and synthetic text. On this multimodal cohort, performance improved to 84% for ChatGPT and 76% for Claude, while consensus accuracy reached 91.3%. Across both experimental conditions, agreement-based fusion consistently outperformed individual models. These findings highlight the utility of integrating complementary modalities and using output-level consensus to improve the trustworthiness and clinical utility of AI-assisted radiological diagnosis, offering a practical path to reduce diagnostic errors with minimal computational overhead.</li>
</ul>

<h3>Title: Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Guiyao Tie, Zenghui Yuan, Zeli Zhao, Chaoran Hu, Tianhe Gu, Ruihang Zhang, Sizhe Zhang, Junran Wu, Xiaoyue Tu, Ming Jin, Qingsong Wen, Lixing Chen, Pan Zhou, Lichao Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16062">https://arxiv.org/abs/2510.16062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16062">https://arxiv.org/pdf/2510.16062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16062]] Can LLMs Correct Themselves? A Benchmark of Self-Correction in LLMs(https://arxiv.org/abs/2510.16062)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Self-correction of large language models (LLMs) emerges as a critical component for enhancing their reasoning performance. Although various self-correction methods have been proposed, a comprehensive evaluation of these methods remains largely unexplored, and the question of whether LLMs can truly correct themselves is a matter of significant interest and concern. In this study, we introduce CorrectBench, a benchmark developed to evaluate the effectiveness of self-correction strategies, including intrinsic, external, and fine-tuned approaches, across three tasks: commonsense reasoning, mathematical reasoning, and code generation. Our findings reveal that: 1) Self-correction methods can improve accuracy, especially for complex reasoning tasks; 2) Mixing different self-correction strategies yields further improvements, though it reduces efficiency; 3) Reasoning LLMs (e.g., DeepSeek-R1) have limited optimization under additional self-correction methods and have high time costs. Interestingly, a comparatively simple chain-of-thought (CoT) baseline demonstrates competitive accuracy and efficiency. These results underscore the potential of self-correction to enhance LLM's reasoning performance while highlighting the ongoing challenge of improving their efficiency. Consequently, we advocate for further research focused on optimizing the balance between reasoning capabilities and operational efficiency. Project Page: this https URL</li>
</ul>

<h3>Title: Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks</h3>
<ul>
<li><strong>Authors: </strong>Muhy Eddin Za'ter, Bri-Mathias Hodge</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16063">https://arxiv.org/abs/2510.16063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16063">https://arxiv.org/pdf/2510.16063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16063]] Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks(https://arxiv.org/abs/2510.16063)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate voltage estimation in distribution networks is critical for real-time monitoring and increasing the reliability of the grid. As DER penetration and distribution level voltage variability increase, robust distribution system state estimation (DSSE) has become more essential to maintain safe and efficient operations. Traditional DSSE techniques, however, struggle with sparse measurements and the scale of modern feeders, limiting their scalability to large networks. This paper presents a hierarchical graph neural network for substation-level voltage estimation that exploits both electrical topology and physical features, while remaining robust to the low observability levels common to real-world distribution networks. Leveraging the public SMART-DS datasets, the model is trained and evaluated on thousands of buses across multiple substations and DER penetration scenarios. Comprehensive experiments demonstrate that the proposed method achieves up to 2 times lower RMSE than alternative data-driven models, and maintains high accuracy with as little as 1\% measurement coverage. The results highlight the potential of GNNs to enable scalable, reproducible, and data-driven voltage monitoring for distribution systems.</li>
</ul>

<h3>Title: FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Lunchen Xie, Zehua He, Qingjiang Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16065">https://arxiv.org/abs/2510.16065</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16065">https://arxiv.org/pdf/2510.16065</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16065]] FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning(https://arxiv.org/abs/2510.16065)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>Personalized Federated Learning (PFL) has emerged as a critical research frontier addressing data heterogeneity issue across distributed clients. Novel model architectures and collaboration mechanisms are engineered to accommodate statistical disparities while producing client-specific models. Parameter decoupling represents a promising paradigm for maintaining model performance in PFL frameworks. However, the communication efficiency of many existing methods remains suboptimal, sustaining substantial communication burdens that impede practical deployment. To bridge this gap, we propose Federated Learning with Programmed Update and Reduced INformation (FedPURIN), a novel framework that strategically identifies critical parameters for transmission through an integer programming formulation. This mathematically grounded strategy is seamlessly integrated into a sparse aggregation scheme, achieving a significant communication reduction while preserving the efficacy. Comprehensive evaluations on standard image classification benchmarks under varied non-IID conditions demonstrate competitive performance relative to state-of-the-art methods, coupled with quantifiable communication reduction through sparse aggregation. The framework establishes a new paradigm for communication-efficient PFL, particularly advantageous for edge intelligence systems operating with heterogeneous data sources.</li>
</ul>

<h3>Title: A Multi-Cloud Framework for Zero-Trust Workload Authentication</h3>
<ul>
<li><strong>Authors: </strong>Saurabh Deochake, Ryan Murphy, Jeremiah Gearheart</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16067">https://arxiv.org/abs/2510.16067</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16067">https://arxiv.org/pdf/2510.16067</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16067]] A Multi-Cloud Framework for Zero-Trust Workload Authentication(https://arxiv.org/abs/2510.16067)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, robust</a></li>
<li><strong>Abstract: </strong>Static, long-lived credentials for workload authentication create untenable security risks that violate Zero-Trust principles. This paper presents a multi-cloud framework using Workload Identity Federation (WIF) and OpenID Connect (OIDC) for secretless authentication. Our approach uses cryptographically-verified, ephemeral tokens, allowing workloads to authenticate without persistent private keys and mitigating credential theft. We validate this framework in an enterprise-scale Kubernetes environment, which significantly reduces the attack surface. The model offers a unified solution to manage workload identities across disparate clouds, enabling future implementation of robust, attribute-based access control.</li>
</ul>

<h3>Title: MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data</h3>
<ul>
<li><strong>Authors: </strong>Qinxuan Wang, Chuang Wang, Mingyu Zhang, Jingwei Sun, Peipei Yang, Shuo Tang, Shiming Xiang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16071">https://arxiv.org/abs/2510.16071</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16071">https://arxiv.org/pdf/2510.16071</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16071]] MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data(https://arxiv.org/abs/2510.16071)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Neural operators have emerged as a powerful data-driven paradigm for solving Partial Differential Equations (PDEs), offering orders-of-magnitude acceleration over traditional solvers. However, existing approaches still suffer from limited accuracy and scalability, particularly on irregular domains where fluid flows exhibit rich multiscale structures. In this work, we introduce the Multiscale Neural Operator (MNO), a new architecture for Computational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point clouds. MNO explicitly decomposes information across three scales: a global dimension-shrinkage attention module for long-range dependencies, a local graph attention module for neighborhood-level interactions, and a micro point-wise attention module for fine-grained details. This design preserves multiscale inductive biases while remaining computationally efficient. We evaluate MNO on four diverse benchmarks, covering both steady-state and unsteady flow scenarios with up to 300K points. Across all tasks, MNO consistently outperforms state-of-the-art baselines, reducing prediction errors by 5% to 40% and demonstrating improved robustness in challenging 3D CFD problems. Our results highlight the importance of explicit multiscale design for neural operators and establish MNO as a scalable framework for learning complex fluid dynamics on irregular domains.</li>
</ul>

<h3>Title: Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Farjana Yesmin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16072">https://arxiv.org/abs/2510.16072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16072">https://arxiv.org/pdf/2510.16072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16072]] Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation(https://arxiv.org/abs/2510.16072)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, interpretability</a></li>
<li><strong>Abstract: </strong>Machine learning models trained on imbalanced datasets often exhibit intersectional biases-systematic errors arising from the interaction of multiple attributes such as object class and environmental conditions. This paper presents a data-driven framework for analyzing and mitigating such biases in image classification. We introduce the Intersectional Fairness Evaluation Framework (IFEF), which combines quantitative fairness metrics with interpretability tools to systematically identify bias patterns in model predictions. Building on this analysis, we propose Bias-Weighted Augmentation (BWA), a novel data augmentation strategy that adapts transformation intensities based on subgroup distribution statistics. Experiments on the Open Images V7 dataset with five object classes demonstrate that BWA improves accuracy for underrepresented class-environment intersections by up to 24 percentage points while reducing fairness metric disparities by 35%. Statistical analysis across multiple independent runs confirms the significance of improvements (p < 0.05). Our methodology provides a replicable approach for analyzing and addressing intersectional biases in image classification systems.</li>
</ul>

<h3>Title: Early-stopping for Transformer model training</h3>
<ul>
<li><strong>Authors: </strong>Jing He, Hua Jiang, Cheng Li, Siqian Xin, Shuzhen Yang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16074">https://arxiv.org/abs/2510.16074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16074">https://arxiv.org/pdf/2510.16074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16074]] Early-stopping for Transformer model training(https://arxiv.org/abs/2510.16074)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>This work introduces a novel theoretical framework grounded in Random Matrix Theory (RMT) for analyzing Transformer training dynamics. We focus on the underlying mechanisms that drive performance improvements and derive principled early-stopping criteria. Empirically, we observe that the spectral density of the shallow self-attention matrix V consistently evolves into a heavy-tailed distribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we demarcate training into three stages: structural exploration, heavy-tailed structure stabilization, and convergence saturation. This staging provides guidance for preliminary stopping decisions. Crucially, we propose two consistent and validation-free criteria: a quantitative metric for heavy-tailed dynamics and a novel spectral signature indicative of convergence. The strong alignment between these criteria highlights the utility of RMT for monitoring and diagnosing the progression of Transformer model training.</li>
</ul>

<h3>Title: ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates</h3>
<ul>
<li><strong>Authors: </strong>Abdelilah Ganmati, Karim Afdel, Lahcen Koutti</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16078">https://arxiv.org/abs/2510.16078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16078">https://arxiv.org/pdf/2510.16078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16078]] ISO/IEC-Compliant Match-on-Card Face Verification with Short Binary Templates(https://arxiv.org/abs/2510.16078)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>We present a practical match-on-card design for face verification in which compact 64/128-bit templates are produced off-card by PCA-ITQ and compared on-card via constant-time Hamming distance. We specify ISO/IEC 7816-4 and 14443-4 command APDUs with fixed-length payloads and decision-only status words (no score leakage), together with a minimal per-identity EEPROM map. Using real binary codes from a CelebA working set (55 identities, 412 images), we (i) derive operating thresholds from ROC/DET, (ii) replay enroll->verify transactions at those thresholds, and (iii) bound end-to-end time by pure link latency plus a small constant on-card budget. Even at the slowest contact rate (9.6 kbps), total verification time is 43.9 ms (64 b) and 52.3 ms (128 b); at 38.4 kbps both are <14 ms. At FAR = 1%, both code lengths reach TPR = 0.836, while 128 b lowers EER relative to 64 b. An optional +6 B helper (targeted symbol-level parity over empirically unstable bits) is latency-negligible. Overall, short binary templates, fixed-payload decision-only APDUs, and constant-time matching satisfy ISO/IEC transport constraints with wide timing margin and align with ISO/IEC 24745 privacy goals. Limitations: single-dataset evaluation and design-level (pre-hardware) timing; we outline AgeDB/CFP-FP and on-card microbenchmarks as next steps.</li>
</ul>

<h3>Title: EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle</h3>
<ul>
<li><strong>Authors: </strong>Rong Wu, Xiaoman Wang, Jianbiao Mei, Pinlong Cai, Daocheng Fu, Cheng Yang, Licheng Wen, Xuemeng Yang, Yufan Shen, Yuxin Wang, Botian Shi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16079">https://arxiv.org/abs/2510.16079</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16079">https://arxiv.org/pdf/2510.16079</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16079]] EvolveR: Self-Evolving LLM Agents through an Experience-Driven Lifecycle(https://arxiv.org/abs/2510.16079)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current Large Language Model (LLM) agents show strong performance in tool use, but lack the crucial capability to systematically learn from their own experiences. While existing frameworks mainly focus on mitigating external knowledge gaps, they fail to address a more fundamental limitation: the inability to iteratively refine problem-solving strategies. In this work, we introduce EvolveR, a framework designed to enable agent to self-improve through a complete, closed-loop experience lifecycle. This lifecycle comprises two key stages: (1) Offline Self-Distillation, where the agent's interaction trajectories are synthesized into a structured repository of abstract, reusable strategic principles; (2) Online Interaction, where the agent interacts with tasks and actively retrieves distilled principles to guide its decision-making, accumulating a diverse set of behavioral trajectories. This loop employs a policy reinforcement mechanism to iteratively update the agent based on its performance. We demonstrate the effectiveness of EvolveR on complex multi-hop question-answering benchmarks, where it achieves superior performance over strong agentic baselines. Our work presents a comprehensive blueprint for agents that learn not only from external data but also from the consequences of their own actions, paving the way for more autonomous and continuously improving systems. Code is available at this https URL.</li>
</ul>

<h3>Title: PassREfinder-FL: Privacy-Preserving Credential Stuffing Risk Prediction via Graph-Based Federated Learning for Representing Password Reuse between Websites</h3>
<ul>
<li><strong>Authors: </strong>Jaehan Kim, Minkyoo Song, Minjae Seo, Youngjin Jin, Seungwon Shin, Jinwoo Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16083">https://arxiv.org/abs/2510.16083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16083">https://arxiv.org/pdf/2510.16083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16083]] PassREfinder-FL: Privacy-Preserving Credential Stuffing Risk Prediction via Graph-Based Federated Learning for Representing Password Reuse between Websites(https://arxiv.org/abs/2510.16083)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Credential stuffing attacks have caused significant harm to online users who frequently reuse passwords across multiple websites. While prior research has attempted to detect users with reused passwords or identify malicious login attempts, existing methods often compromise usability by restricting password creation or website access, and their reliance on complex account-sharing mechanisms hinders real-world deployment. To address these limitations, we propose PassREfinder-FL, a novel framework that predicts credential stuffing risks across websites. We introduce the concept of password reuse relations -- defined as the likelihood of users reusing passwords between websites -- and represent them as edges in a website graph. Using graph neural networks (GNNs), we perform a link prediction task to assess credential reuse risk between sites. Our approach scales to a large number of arbitrary websites by incorporating public website information and linking newly observed websites as nodes in the graph. To preserve user privacy, we extend PassREfinder-FL with a federated learning (FL) approach that eliminates the need to share user sensitive information across administrators. Evaluation on a real-world dataset of 360 million breached accounts from 22,378 websites shows that PassREfinder-FL achieves an F1-score of 0.9153 in the FL setting. We further validate that our FL-based GNN achieves a 4-11% performance improvement over other state-of-the-art GNN models through an ablation study. Finally, we demonstrate that the predicted results can be used to quantify password reuse likelihood as actionable risk scores.</li>
</ul>

<h3>Title: FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Liu, Pengjunfei Chu, Shuming Dong, Chen Zhang, Mingcheng Li, Jin Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16086">https://arxiv.org/abs/2510.16086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16086">https://arxiv.org/pdf/2510.16086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16086]] FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis(https://arxiv.org/abs/2510.16086)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In recent years, Multimodal Sentiment Analysis (MSA) has become a research hotspot that aims to utilize multimodal data for human sentiment understanding. Previous MSA studies have mainly focused on performing interaction and fusion on complete multimodal data, ignoring the problem of missing modalities in real-world applications due to occlusion, personal privacy constraints, and device malfunctions, resulting in low generalizability. To this end, we propose a Factorization-guided Semantic Recovery Framework (FSRF) to mitigate the modality missing problem in the MSA task. Specifically, we propose a de-redundant homo-heterogeneous factorization module that factorizes modality into modality-homogeneous, modality-heterogeneous, and noisy representations and design elaborate constraint paradigms for representation learning. Furthermore, we design a distribution-aligned self-distillation module that fully recovers the missing semantics by utilizing bidirectional knowledge transfer. Comprehensive experiments on two datasets indicate that FSRF has a significant performance advantage over previous methods with uncertain missing modalities.</li>
</ul>

<h3>Title: Towards a Blockchain-Based CI/CD Framework to Enhance Security in Cloud Environments</h3>
<ul>
<li><strong>Authors: </strong>Sabbir M Saleh, Nazim Madhavji, John Steinbacher</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16087">https://arxiv.org/abs/2510.16087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16087">https://arxiv.org/pdf/2510.16087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16087]] Towards a Blockchain-Based CI/CD Framework to Enhance Security in Cloud Environments(https://arxiv.org/abs/2510.16087)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Security is becoming a pivotal point in cloud platforms. Several divisions, such as business organisations, health care, government, etc., have experienced cyber-attacks on their infrastructures. This research focuses on security issues within Continuous Integration and Deployment (CI/CD) pipelines in a cloud platform as a reaction to recent cyber breaches. This research proposes a blockchain-based solution to enhance CI/CD pipeline security. This research aims to develop a framework that leverages blockchain's distributed ledger technology and tamper-resistant features to improve CI/CD pipeline security. The goal is to emphasise secure software deployment by integrating threat modelling frameworks and adherence to coding standards. It also aims to employ tools to automate security testing to detect publicly disclosed vulnerabilities and flaws, such as an outdated version of Java Spring Framework, a JavaScript library from an unverified source, or a database library that allows SQL injection attacks in the deployed software through the framework.</li>
</ul>

<h3>Title: STABLE: Gated Continual Learning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>William Hoy, Nurcin Celik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16089">https://arxiv.org/abs/2510.16089</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16089">https://arxiv.org/pdf/2510.16089</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16089]] STABLE: Gated Continual Learning for Large Language Models(https://arxiv.org/abs/2510.16089)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly require mechanisms for continual adaptation without full retraining. However, sequential updates can lead to catastrophic forgetting, where new edits degrade previously acquired knowledge. This work presents STABLE, a gated continual self editing framework that constrains forgetting during sequential updates using parameter efficient fine tuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate edit is evaluated against a stability budget using one of three metrics: (i) Exact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase, reflecting reduced model confidence; and (iii) KL divergence, quantifying distributional drift between the base and adapted models. If a threshold is exceeded, the LoRA update is rescaled through a clipping procedure or rejected. Experiments on the Qwen-2.5-7B model show that gating effectively mitigates forgetting while preserving adaptability. EM based gating achieved the highest cumulative performance in short continual learning sequences. Our results show that different gating strategies can achieve comparable distribution shift (measured by KL divergence) while producing different accuracy outcomes, highlighting the importance of gating design in continual adaptation. This approach offers a principled method for continual model editing, enabling LLMs to integrate new knowledge while maintaining reliability. Code: this https URL</li>
</ul>

<h3>Title: Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification</h3>
<ul>
<li><strong>Authors: </strong>Binglan Han, Anuradha Mathrani, Teo Susnjak</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16091">https://arxiv.org/abs/2510.16091</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16091">https://arxiv.org/pdf/2510.16091</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16091]] Evaluating Prompting Strategies and Large Language Models in Systematic Literature Review Screening: Relevance and Task-Stage Classification(https://arxiv.org/abs/2510.16091)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This study quantifies how prompting strategies interact with large language models (LLMs) to automate the screening stage of systematic literature reviews (SLRs). We evaluate six LLMs (GPT-4o, GPT-4o-mini, DeepSeek-Chat-V3, Gemini-2.5-Flash, Claude-3.5-Haiku, Llama-4-Maverick) under five prompt types (zero-shot, few-shot, chain-of-thought (CoT), CoT-few-shot, self-reflection) across relevance classification and six Level-2 tasks, using accuracy, precision, recall, and F1. Results show pronounced model-prompt interaction effects: CoT-few-shot yields the most reliable precision-recall balance; zero-shot maximizes recall for high-sensitivity passes; and self-reflection underperforms due to over-inclusivity and instability across models. GPT-4o and DeepSeek provide robust overall performance, while GPT-4o-mini performs competitively at a substantially lower dollar cost. A cost-performance analysis for relevance classification (per 1,000 abstracts) reveals large absolute differences among model-prompt pairings; GPT-4o-mini remains low-cost across prompts, and structured prompts (CoT/CoT-few-shot) on GPT-4o-mini offer attractive F1 at a small incremental cost. We recommend a staged workflow that (1) deploys low-cost models with structured prompts for first-pass screening and (2) escalates only borderline cases to higher-capacity models. These findings highlight LLMs' uneven but promising potential to automate literature screening. By systematically analyzing prompt-model interactions, we provide a comparative benchmark and practical guidance for task-adaptive LLM deployment.</li>
</ul>

<h3>Title: Compressing Many-Shots in In-Context Learning</h3>
<ul>
<li><strong>Authors: </strong>Devvrit Khatri, Pranamya Kulkarni, Nilesh Gupta, Yerram Varun, Liqian Peng, Jay Yagnik, Praneeth Netrapalli, Cho-Jui Hsieh, Alec Go, Inderjit S Dhillon, Aditya Kusupati, Prateek Jain</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16092">https://arxiv.org/abs/2510.16092</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16092">https://arxiv.org/pdf/2510.16092</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16092]] Compressing Many-Shots in In-Context Learning(https://arxiv.org/abs/2510.16092)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have been shown to be able to learn different tasks without explicit finetuning when given many input-output examples / demonstrations through In-Context Learning (ICL). Increasing the number of examples, called ``shots'', improves downstream task performance but incurs higher memory and computational costs. In this work, we study an approach to improve the memory and computational efficiency of ICL inference by compressing the many-shot prompts. Given many shots comprising t tokens, our goal is to generate a m soft-token summary, where m < t. We first show that existing prompt compression methods are ineffective for many-shot compression, and simply using fewer shots as a baseline is surprisingly strong. To achieve effective compression, we find that: (a) a stronger compressor model with more trainable parameters is necessary, and (b) compressing many-shot representations at each transformer layer enables more fine-grained compression by providing each layer with its own compressed representation. Based on these insights, we propose MemCom, a layer-wise compression method. We systematically evaluate various compressor models and training approaches across different model sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence lengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms strong baselines across all compression ratios on multiple classification tasks with large label sets. Notably, while baseline performance degrades sharply at higher compression ratios, often by over 20-30%, MemCom maintains high accuracy with minimal degradation, typically dropping by less than 10%.</li>
</ul>

<h3>Title: ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles</h3>
<ul>
<li><strong>Authors: </strong>Nishad Sahu, Shounak Sural, Aditya Satish Patil, Ragunathan (Raj)Rajkumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16118">https://arxiv.org/abs/2510.16118</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16118">https://arxiv.org/pdf/2510.16118</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16118]] ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles(https://arxiv.org/abs/2510.16118)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Reliable perception is fundamental for safety critical decision making in autonomous driving. Yet, vision based object detector neural networks remain vulnerable to uncertainty arising from issues such as data bias and distributional shifts. In this paper, we introduce ObjectTransforms, a technique for quantifying and reducing uncertainty in vision based object detection through object specific transformations at both training and inference times. At training time, ObjectTransforms perform color space perturbations on individual objects, improving robustness to lighting and color variations. ObjectTransforms also uses diffusion models to generate realistic, diverse pedestrian instances. At inference time, object perturbations are applied to detected objects and the variance of detection scores are used to quantify predictive uncertainty in real time. This uncertainty signal is then used to filter out false positives and also recover false negatives, improving the overall precision recall curve. Experiments with YOLOv8 on the NuImages 10K dataset demonstrate that our method yields notable accuracy improvements and uncertainty reduction across all object classes during training, while predicting desirably higher uncertainty values for false positives as compared to true positives during inference. Our results highlight the potential of ObjectTransforms as a lightweight yet effective mechanism for reducing and quantifying uncertainty in vision-based perception during training and inference respectively.</li>
</ul>

<h3>Title: The Hidden Cost of Modeling P(X): Vulnerability to Membership Inference Attacks in Generative Text Classifiers</h3>
<ul>
<li><strong>Authors: </strong>Owais Makroo, Siva Rajesh Kasa, Sumegh Roychowdhury, Karan Gupta, Nikhil Pattisapu, Santhosh Kasa, Sumit Negi</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16122">https://arxiv.org/abs/2510.16122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16122">https://arxiv.org/pdf/2510.16122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16122]] The Hidden Cost of Modeling P(X): Vulnerability to Membership Inference Attacks in Generative Text Classifiers(https://arxiv.org/abs/2510.16122)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer, generative</a></li>
<li><strong>Abstract: </strong>Membership Inference Attacks (MIAs) pose a critical privacy threat by enabling adversaries to determine whether a specific sample was included in a model's training dataset. Despite extensive research on MIAs, systematic comparisons between generative and discriminative classifiers remain limited. This work addresses this gap by first providing theoretical motivation for why generative classifiers exhibit heightened susceptibility to MIAs, then validating these insights through comprehensive empirical evaluation. Our study encompasses discriminative, generative, and pseudo-generative text classifiers across varying training data volumes, evaluated on nine benchmark datasets. Employing a diverse array of MIA strategies, we consistently demonstrate that fully generative classifiers which explicitly model the joint likelihood $P(X,Y)$ are most vulnerable to membership leakage. Furthermore, we observe that the canonical inference approach commonly used in generative classifiers significantly amplifies this privacy risk. These findings reveal a fundamental utility-privacy trade-off inherent in classifier design, underscoring the critical need for caution when deploying generative classifiers in privacy-sensitive applications. Our results motivate future research directions in developing privacy-preserving generative classifiers that can maintain utility while mitigating membership inference vulnerabilities.</li>
</ul>

<h3>Title: Prompt injections as a tool for preserving identity in GAI image descriptions</h3>
<ul>
<li><strong>Authors: </strong>Kate Glazko, Jennifer Mankoff</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16128">https://arxiv.org/abs/2510.16128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16128">https://arxiv.org/pdf/2510.16128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16128]] Prompt injections as a tool for preserving identity in GAI image descriptions(https://arxiv.org/abs/2510.16128)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, generative</a></li>
<li><strong>Abstract: </strong>Generative AI risks such as bias and lack of representation impact people who do not interact directly with GAI systems, but whose content does: indirect users. Several approaches to mitigating harms to indirect users have been described, but most require top down or external intervention. An emerging strategy, prompt injections, provides an empowering alternative: indirect users can mitigate harm against them, from within their own content. Our approach proposes prompt injections not as a malicious attack vector, but as a tool for content/image owner resistance. In this poster, we demonstrate one case study of prompt injections for empowering an indirect user, by retaining an image owner's gender and disabled identity when an image is described by GAI.</li>
</ul>

<h3>Title: Aria Gen 2 Pilot Dataset</h3>
<ul>
<li><strong>Authors: </strong>Chen Kong, James Fort, Aria Kang, Jonathan Wittmer, Simon Green, Tianwei Shen, Yipu Zhao, Cheng Peng, Gustavo Solaira, Andrew Berkovich, Nikhil Raina, Vijay Baiyya, Evgeniy Oleinik, Eric Huang, Fan Zhang, Julian Straub, Mark Schwesinger, Luis Pesqueira, Xiaqing Pan, Jakob Julian Engel, Carl Ren, Mingfei Yan, Richard Newcombe</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.HC, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16134">https://arxiv.org/abs/2510.16134</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16134">https://arxiv.org/pdf/2510.16134</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16134]] Aria Gen 2 Pilot Dataset(https://arxiv.org/abs/2510.16134)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal open dataset captured using the state-of-the-art Aria Gen 2 glasses. To facilitate timely access, A2PD is released incrementally with ongoing dataset enhancements. The initial release features Dia'ane, our primary subject, who records her daily activities alongside friends, each equipped with Aria Gen 2 glasses. It encompasses five primary scenarios: cleaning, cooking, eating, playing, and outdoor walking. In each of the scenarios, we provide comprehensive raw sensor data and output data from various machine perception algorithms. These data illustrate the device's ability to perceive the wearer, the surrounding environment, and interactions between the wearer and the environment, while maintaining robust performance across diverse users and conditions. The A2PD is publicly available at this http URL, with open-source tools and usage examples provided in Project Aria Tools.</li>
</ul>

<h3>Title: GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer</h3>
<ul>
<li><strong>Authors: </strong>Sayan Deb Sarkar, Sinisa Stekovic, Vincent Lepetit, Iro Armeni</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16136">https://arxiv.org/abs/2510.16136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16136">https://arxiv.org/pdf/2510.16136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16136]] GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer(https://arxiv.org/abs/2510.16136)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Transferring appearance to 3D assets using different representations of the appearance object - such as images or text - has garnered interest due to its wide range of applications in industries like gaming, augmented reality, and digital content creation. However, state-of-the-art methods still fail when the geometry between the input and appearance objects is significantly different. A straightforward approach is to directly apply a 3D generative model, but we show that this ultimately fails to produce appealing results. Instead, we propose a principled approach inspired by universal guidance. Given a pretrained rectified flow model conditioned on image or text, our training-free method interacts with the sampling process by periodically adding guidance. This guidance can be modeled as a differentiable loss function, and we experiment with two different types of guidance including part-aware losses for appearance and self-similarity. Our experiments show that our approach successfully transfers texture and geometric details to the input 3D asset, outperforming baselines both qualitatively and quantitatively. We also show that traditional metrics are not suitable for evaluating the task due to their inability of focusing on local details and comparing dissimilar inputs, in absence of ground truth data. We thus evaluate appearance transfer quality with a GPT-based system objectively ranking outputs, ensuring robust and human-like assessment, as further confirmed by our user study. Beyond showcased scenarios, our method is general and could be extended to different types of diffusion models and guidance functions.</li>
</ul>

<h3>Title: Expert Merging in Sparse Mixture of Experts with Nash Bargaining</h3>
<ul>
<li><strong>Authors: </strong>Dung V. Nguyen, Anh T. Nguyen, Minh H. Nguyen, Luc Q. Nguyen, Shiqi Jiang, Ethan Fetaya, Linh Duy Tran, Gal Chechik, Tan M. Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16138">https://arxiv.org/abs/2510.16138</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16138">https://arxiv.org/pdf/2510.16138</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16138]] Expert Merging in Sparse Mixture of Experts with Nash Bargaining(https://arxiv.org/abs/2510.16138)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing expert merging strategies for Sparse Mixture of Experts (SMoE) typically rely on input-dependent or input-independent averaging of expert parameters, but often lack a principled weighting mechanism. In this work, we reinterpret expert merging through the lens of game theory, revealing cooperative and competitive dynamics among experts. Based on this perspective, we introduce Nash Merging of Experts (NAMEx), a novel framework that incorporates Nash Bargaining into the merging process, enabling more balanced and efficient collaboration among experts. Additionally, we incorporate complex momentum into NAMEx to accelerate expert propagation with theoretical guarantees for convergence. Extensive experiments across language modelling, text classification, image classification, and zero-shot robustness under data corruption show that NAMEx consistently outperforms competing methods while integrating seamlessly with popular MoE architectures. Finally, we demonstrate NAMEx's scalability by applying it to large-scale systems, including Qwen1.5-MoE (14B) and DeepSeek-MoE (16B), where it proves effective in both zero-shot and fine-tuning settings.</li>
</ul>

<h3>Title: DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization</h3>
<ul>
<li><strong>Authors: </strong>Thanh-Huy Nguyen, Hoang-Thien Nguyen, Vi Vu, Ba-Thinh Lam, Phat Huynh, Tianyang Wang, Xingjian Li, Ulas Bagci, Min Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16146">https://arxiv.org/abs/2510.16146</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16146">https://arxiv.org/pdf/2510.16146</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16146]] DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization(https://arxiv.org/abs/2510.16146)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>The limited availability of annotated data in medical imaging makes semi-supervised learning increasingly appealing for its ability to learn from imperfect supervision. Recently, teacher-student frameworks have gained popularity for their training benefits and robust performance. However, jointly optimizing the entire network can hinder convergence and stability, especially in challenging scenarios. To address this for medical image segmentation, we propose DuetMatch, a novel dual-branch semi-supervised framework with asynchronous optimization, where each branch optimizes either the encoder or decoder while keeping the other frozen. To improve consistency under noisy conditions, we introduce Decoupled Dropout Perturbation, enforcing regularization across branches. We also design Pair-wise CutMix Cross-Guidance to enhance model diversity by exchanging pseudo-labels through augmented input pairs. To mitigate confirmation bias from noisy pseudo-labels, we propose Consistency Matching, refining labels using stable predictions from frozen teacher models. Extensive experiments on benchmark brain MRI segmentation datasets, including ISLES2022 and BraTS, show that DuetMatch consistently outperforms state-of-the-art methods, demonstrating its effectiveness and robustness across diverse semi-supervised segmentation scenarios.</li>
</ul>

<h3>Title: AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures</h3>
<ul>
<li><strong>Authors: </strong>Charles Rhys Campbell, Aldo H. Romero, Kamal Choudhary</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.supr-con</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16165">https://arxiv.org/abs/2510.16165</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16165">https://arxiv.org/pdf/2510.16165</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16165]] AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures(https://arxiv.org/abs/2510.16165)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Generative models have become significant assets in the exploration and identification of new materials, enabling the rapid proposal of candidate crystal structures that satisfy target properties. Despite the increasing adoption of diverse architectures, a rigorous comparative evaluation of their performance on materials datasets is lacking. In this work, we present a systematic benchmark of three representative generative models- AtomGPT (a transformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE), and FlowMM (a Riemannian flow matching model). These models were trained to reconstruct crystal structures from subsets of two publicly available superconductivity datasets- JARVIS Supercon 3D and DS A/B from the Alexandria database. Performance was assessed using the Kullback-Leibler (KL) divergence between predicted and reference distributions of lattice parameters, as well as the mean absolute error (MAE) of individual lattice constants. For the computed KLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and then FlowMM. All benchmarking code and model configurations will be made publicly available at this https URL.</li>
</ul>

<h3>Title: WebRTC Metadata and IP Leakage in Modern Browsers: A Cross-Platform Measurement Study</h3>
<ul>
<li><strong>Authors: </strong>Ahmed Fouad Kadhim Koysha, Aytug Boyaci, Rafet Akdeniz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16168">https://arxiv.org/abs/2510.16168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16168">https://arxiv.org/pdf/2510.16168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16168]] WebRTC Metadata and IP Leakage in Modern Browsers: A Cross-Platform Measurement Study(https://arxiv.org/abs/2510.16168)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect</a></li>
<li><strong>Abstract: </strong>Web Real-Time Communication (WebRTC) enables real-time peer-to-peer communication, but its Interactive Connectivity Establishment (ICE) process can unintentionally expose internal and public IP addresses as metadata. This paper presents a cross-platform measurement study of WebRTC metadata leakage using current (2025) builds of Chrome, Brave, Firefox, and Tor on desktop and mobile platforms. Experiments were conducted across semi-trusted Wi-Fi and untrusted mobile carrier networks. Results show that Chrome remains the most leakage-prone, disclosing LAN or Carrier-Grade NAT (CGNAT) addresses on mobile and metadata on desktop; Brave avoids direct IP leaks but exposes session-stable mDNS identifiers; Firefox provides strong protection on desktop but leaks internal IPs on Android; and Tor consistently prevents all forms of leakage. We introduce a structured threat model for semi-trusted environments and evaluate the limitations of mDNS obfuscation. Finally, we propose layered mitigation strategies combining browser defaults, institutional safeguards, and user controls. Findings demonstrate that while direct LAN leakage is declining, emerging vectors such as mDNS and CGNAT create persistent privacy risks requiring protocol-level redesign and policy action.</li>
</ul>

<h3>Title: Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness</h3>
<ul>
<li><strong>Authors: </strong>Longwei Wang, Ifrat Ikhtear Uddin, KC Santosh, Chaowei Zhang, Xiao Qin, Yang Zhou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16171">https://arxiv.org/abs/2510.16171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16171">https://arxiv.org/pdf/2510.16171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16171]] Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness(https://arxiv.org/abs/2510.16171)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>Adversarial examples reveal critical vulnerabilities in deep neural networks by exploiting their sensitivity to imperceptible input perturbations. While adversarial training remains the predominant defense strategy, it often incurs significant computational cost and may compromise clean-data accuracy. In this work, we investigate an architectural approach to adversarial robustness by embedding group-equivariant convolutions-specifically, rotation- and scale-equivariant layers-into standard convolutional neural networks (CNNs). These layers encode symmetry priors that align model behavior with structured transformations in the input space, promoting smoother decision boundaries and greater resilience to adversarial attacks. We propose and evaluate two symmetry-aware architectures: a parallel design that processes standard and equivariant features independently before fusion, and a cascaded design that applies equivariant operations sequentially. Theoretically, we demonstrate that such models reduce hypothesis space complexity, regularize gradients, and yield tighter certified robustness bounds under the CLEVER (Cross Lipschitz Extreme Value for nEtwork Robustness) framework. Empirically, our models consistently improve adversarial robustness and generalization across CIFAR-10, CIFAR-100, and CIFAR-10C under both FGSM and PGD attacks, without requiring adversarial training. These findings underscore the potential of symmetry-enforcing architectures as efficient and principled alternatives to data augmentation-based defenses.</li>
</ul>

<h3>Title: In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions</h3>
<ul>
<li><strong>Authors: </strong>Aria Pessianzadeh, Naima Sultana, Hildegarde Van den Bulck, David Gefen, Shahin Jabari, Rezvaneh Rezapour</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16173">https://arxiv.org/abs/2510.16173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16173">https://arxiv.org/pdf/2510.16173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16173]] In Generative AI We (Dis)Trust? Computational Analysis of Trust and Distrust in Reddit Discussions(https://arxiv.org/abs/2510.16173)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>The rise of generative AI (GenAI) has impacted many aspects of human life. As these systems become embedded in everyday practices, understanding public trust in them also becomes essential for responsible adoption and governance. Prior work on trust in AI has largely drawn from psychology and human-computer interaction, but there is a lack of computational, large-scale, and longitudinal approaches to measuring trust and distrust in GenAI and large language models (LLMs). This paper presents the first computational study of Trust and Distrust in GenAI, using a multi-year Reddit dataset (2022--2025) spanning 39 subreddits and 197,618 posts. Crowd-sourced annotations of a representative sample were combined with classification models to scale analysis. We find that Trust and Distrust are nearly balanced over time, with shifts around major model releases. Technical performance and usability dominate as dimensions, while personal experience is the most frequent reason shaping attitudes. Distinct patterns also emerge across trustors (e.g., experts, ethicists, general users). Our results provide a methodological framework for large-scale Trust analysis and insights into evolving public perceptions of GenAI.</li>
</ul>

<h3>Title: Cost Savings from Automatic Quality Assessment of Generated Images</h3>
<ul>
<li><strong>Authors: </strong>Xavier Giro-i-Nieto, Nefeli Andreou, Anqi Liang, Manel Baradad, Francesc Moreno-Noguer, Aleix Martinez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16179">https://arxiv.org/abs/2510.16179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16179">https://arxiv.org/pdf/2510.16179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16179]] Cost Savings from Automatic Quality Assessment of Generated Images(https://arxiv.org/abs/2510.16179)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Deep generative models have shown impressive progress in recent years, making it possible to produce high quality images with a simple text prompt or a reference image. However, state of the art technology does not yet meet the quality standards offered by traditional photographic methods. For this reason, production pipelines that use generated images often include a manual stage of image quality assessment (IQA). This process is slow and expensive, especially because of the low yield of automatically generated images that pass the quality bar. The IQA workload can be reduced by introducing an automatic pre-filtering stage, that will increase the overall quality of the images sent to review and, therefore, reduce the average cost required to obtain a high quality image. We present a formula that estimates the cost savings depending on the precision and pass yield of a generic IQA engine. This formula is applied in a use case of background inpainting, showcasing a significant cost saving of 51.61% obtained with a simple AutoML solution.</li>
</ul>

<h3>Title: Expressive Reward Synthesis with the Runtime Monitoring Language</h3>
<ul>
<li><strong>Authors: </strong>Daniel Donnelly, Angelo Ferrando, Francesco Belardinelli</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.FL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16185">https://arxiv.org/abs/2510.16185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16185">https://arxiv.org/pdf/2510.16185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16185]] Expressive Reward Synthesis with the Runtime Monitoring Language(https://arxiv.org/abs/2510.16185)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>A key challenge in reinforcement learning (RL) is reward (mis)specification, whereby imprecisely defined reward functions can result in unintended, possibly harmful, behaviours. Indeed, reward functions in RL are typically treated as black-box mappings from state-action pairs to scalar values. While effective in many settings, this approach provides no information about why rewards are given, which can hinder learning and interpretability. Reward Machines address this issue by representing reward functions as finite state automata, enabling the specification of structured, non-Markovian reward functions. However, their expressivity is typically bounded by regular languages, leaving them unable to capture more complex behaviours such as counting or parametrised conditions. In this work, we build on the Runtime Monitoring Language (RML) to develop a novel class of language-based Reward Machines. By leveraging the built-in memory of RML, our approach can specify reward functions for non-regular, non-Markovian tasks. We demonstrate the expressiveness of our approach through experiments, highlighting additional advantages in flexible event-handling and task specification over existing Reward Machine-based methods.</li>
</ul>

<h3>Title: Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI</h3>
<ul>
<li><strong>Authors: </strong>Zheng Huang, Enpei Zhang, Yinghao Cai, Weikang Qiu, Carl Yang, Elynn Chen, Xiang Zhang, Rex Ying, Dawei Zhou, Yujun Yan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16196">https://arxiv.org/abs/2510.16196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16196">https://arxiv.org/pdf/2510.16196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16196]] Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI(https://arxiv.org/abs/2510.16196)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Understanding how the brain encodes visual information is a central challenge in neuroscience and machine learning. A promising approach is to reconstruct visual stimuli, essentially images, from functional Magnetic Resonance Imaging (fMRI) signals. This involves two stages: transforming fMRI signals into a latent space and then using a pretrained generative model to reconstruct images. The reconstruction quality depends on how similar the latent space is to the structure of neural activity and how well the generative model produces images from that space. Yet, it remains unclear which type of latent space best supports this transformation and how it should be organized to represent visual stimuli effectively. We present two key findings. First, fMRI signals are more similar to the text space of a language model than to either a vision based space or a joint text image space. Second, text representations and the generative model should be adapted to capture the compositional nature of visual stimuli, including objects, their detailed attributes, and relationships. Building on these insights, we propose PRISM, a model that Projects fMRI sIgnals into a Structured text space as an interMediate representation for visual stimuli reconstruction. It includes an object centric diffusion module that generates images by composing individual objects to reduce object detection errors, and an attribute relationship search module that automatically identifies key attributes and relationships that best align with the neural activity. Extensive experiments on real world datasets demonstrate that our framework outperforms existing methods, achieving up to an 8% reduction in perceptual loss. These results highlight the importance of using structured text as the intermediate space to bridge fMRI signals and image reconstruction.</li>
</ul>

<h3>Title: Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions</h3>
<ul>
<li><strong>Authors: </strong>Mateus Pinto da Silva, Sabrina P. L. P. Correa, Hugo N. Oliveira, Ian M. Nunes, Jefersson A. dos Santos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16207">https://arxiv.org/abs/2510.16207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16207">https://arxiv.org/pdf/2510.16207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16207]] Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions(https://arxiv.org/abs/2510.16207)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Mapping agriculture in tropical areas through remote sensing presents unique challenges, including the lack of high-quality annotated data, the elevated costs of labeling, data variability, and regional generalisation. This paper advocates a Data-Centric Artificial Intelligence (DCAI) perspective and pipeline, emphasizing data quality and curation as key drivers for model robustness and scalability. It reviews and prioritizes techniques such as confident learning, core-set selection, data augmentation, and active learning. The paper highlights the readiness and suitability of 25 distinct strategies in large-scale agricultural mapping pipelines. The tropical context is of high interest, since high cloudiness, diverse crop calendars, and limited datasets limit traditional model-centric approaches. This tutorial outlines practical solutions as a data-centric approach for curating and training AI models better suited to the dynamic realities of tropical agriculture. Finally, we propose a practical pipeline using the 9 most mature and straightforward methods that can be applied to a large-scale tropical agricultural mapping project.</li>
</ul>

<h3>Title: StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales</h3>
<ul>
<li><strong>Authors: </strong>Nyle Siddiqui, Rohit Gupta, Sirnam Swetha, Mubarak Shah</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16209">https://arxiv.org/abs/2510.16209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16209">https://arxiv.org/pdf/2510.16209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16209]] StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales(https://arxiv.org/abs/2510.16209)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>State space models (SSMs) have emerged as a competitive alternative to transformers in various tasks. Their linear complexity and hidden-state recurrence make them particularly attractive for modeling long sequences, whereas attention becomes quadratically expensive. However, current training methods for video understanding are tailored towards transformers and fail to fully leverage the unique attributes of SSMs. For example, video models are often trained at a fixed resolution and video length to balance the quadratic scaling of attention cost against performance. Consequently, these models suffer from degraded performance when evaluated on videos with spatial and temporal resolutions unseen during training; a property we call spatio-temporal inflexibility. In the context of action recognition, this severely limits a model's ability to retain performance across both short- and long-form videos. Therefore, we propose a flexible training method that leverages and improves the inherent adaptability of SSMs. Our method samples videos at varying temporal and spatial resolutions during training and dynamically interpolates model weights to accommodate any spatio-temporal scale. This instills our SSM, which we call StretchySnake, with spatio-temporal flexibility and enables it to seamlessly handle videos ranging from short, fine-grained clips to long, complex activities. We introduce and compare five different variants of flexible training, and identify the most effective strategy for video SSMs. On short-action (UCF-101, HMDB-51) and long-action (COIN, Breakfast) benchmarks, StretchySnake outperforms transformer and SSM baselines alike by up to 28%, with strong adaptability to fine-grained actions (SSV2, Diving-48). Therefore, our method provides a simple drop-in training recipe that makes video SSMs more robust, resolution-agnostic, and efficient across diverse action recognition scenarios.</li>
</ul>

<h3>Title: Benchmarking noisy label detection methods</h3>
<ul>
<li><strong>Authors: </strong>Henrique Pickler, Jorge K. S. Kamassury, Danilo Silva</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16211">https://arxiv.org/abs/2510.16211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16211">https://arxiv.org/pdf/2510.16211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16211]] Benchmarking noisy label detection methods(https://arxiv.org/abs/2510.16211)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Label noise is a common problem in real-world datasets, affecting both model training and validation. Clean data are essential for achieving strong performance and ensuring reliable evaluation. While various techniques have been proposed to detect noisy labels, there is no clear consensus on optimal approaches. We perform a comprehensive benchmark of detection methods by decomposing them into three fundamental components: label agreement function, aggregation method, and information gathering approach (in-sample vs out-of-sample). This decomposition can be applied to many existing detection methods, and enables systematic comparison across diverse approaches. To fairly compare methods, we propose a unified benchmark task, detecting a fraction of training samples equal to the dataset's noise rate. We also introduce a novel metric: the false negative rate at this fixed operating point. Our evaluation spans vision and tabular datasets under both synthetic and real-world noise conditions. We identify that in-sample information gathering using average probability aggregation combined with the logit margin as the label agreement function achieves the best results across most scenarios. Our findings provide practical guidance for designing new detection methods and selecting techniques for specific applications.</li>
</ul>

<h3>Title: SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection</h3>
<ul>
<li><strong>Authors: </strong>Yang Feng, Xudong Pan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16219">https://arxiv.org/abs/2510.16219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16219">https://arxiv.org/pdf/2510.16219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16219]] SentinelNet: Safeguarding Multi-Agent Collaboration Through Credit-Based Dynamic Threat Detection(https://arxiv.org/abs/2510.16219)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Malicious agents pose significant threats to the reliability and decision-making capabilities of Multi-Agent Systems (MAS) powered by Large Language Models (LLMs). Existing defenses often fall short due to reactive designs or centralized architectures which may introduce single points of failure. To address these challenges, we propose SentinelNet, the first decentralized framework for proactively detecting and mitigating malicious behaviors in multi-agent collaboration. SentinelNet equips each agent with a credit-based detector trained via contrastive learning on augmented adversarial debate trajectories, enabling autonomous evaluation of message credibility and dynamic neighbor ranking via bottom-k elimination to suppress malicious communications. To overcome the scarcity of attack data, it generates adversarial trajectories simulating diverse threats, ensuring robust training. Experiments on MAS benchmarks show SentinelNet achieves near-perfect detection of malicious agents, close to 100% within two debate rounds, and recovers 95% of system accuracy from compromised baselines. By exhibiting strong generalizability across domains and attack patterns, SentinelNet establishes a novel paradigm for safeguarding collaborative MAS.</li>
</ul>

<h3>Title: VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction</h3>
<ul>
<li><strong>Authors: </strong>Djamel Eddine Boukhari</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16220">https://arxiv.org/abs/2510.16220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16220">https://arxiv.org/pdf/2510.16220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16220]] VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction(https://arxiv.org/abs/2510.16220)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Facial Beauty Prediction (FBP) is a complex and challenging computer vision task, aiming to model the subjective and intricate nature of human aesthetic perception. While deep learning models, particularly Convolutional Neural Networks (CNNs), have made significant strides, they often struggle to capture the global, holistic facial features that are critical to human judgment. Vision Transformers (ViT) address this by effectively modeling long-range spatial relationships, but their quadratic complexity can be a bottleneck. This paper introduces a novel, heterogeneous ensemble architecture, \textbf{VM-BeautyNet}, that synergistically fuses the complementary strengths of a Vision Transformer and a Mamba-based Vision model, a recent advancement in State-Space Models (SSMs). The ViT backbone excels at capturing global facial structure and symmetry, while the Mamba backbone efficiently models long-range dependencies with linear complexity, focusing on sequential features and textures. We evaluate our approach on the benchmark SCUT-FBP5500 dataset. Our proposed VM-BeautyNet achieves state-of-the-art performance, with a \textbf{Pearson Correlation (PC) of 0.9212}, a \textbf{Mean Absolute Error (MAE) of 0.2085}, and a \textbf{Root Mean Square Error (RMSE) of 0.2698}. Furthermore, through Grad-CAM visualizations, we provide interpretability analysis that confirms the complementary feature extraction of the two backbones, offering new insights into the model's decision-making process and presenting a powerful new architectural paradigm for computational aesthetics.</li>
</ul>

<h3>Title: What Can String Probability Tell Us About Grammaticality?</h3>
<ul>
<li><strong>Authors: </strong>Jennifer Hu, Ethan Gotlieb Wilcox, Siyuan Song, Kyle Mahowald, Roger P. Levy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16227">https://arxiv.org/abs/2510.16227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16227">https://arxiv.org/pdf/2510.16227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16227]] What Can String Probability Tell Us About Grammaticality?(https://arxiv.org/abs/2510.16227)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>What have language models (LMs) learned about grammar? This question remains hotly debated, with major ramifications for linguistic theory. However, since probability and grammaticality are distinct notions in linguistics, it is not obvious what string probabilities can reveal about an LM's underlying grammatical knowledge. We present a theoretical analysis of the relationship between grammar, meaning, and string probability, based on simple assumptions about the generative process of corpus data. Our framework makes three predictions, which we validate empirically using 280K sentence pairs in English and Chinese: (1) correlation between the probability of strings within minimal pairs, i.e., string pairs with minimal semantic differences; (2) correlation between models' and humans' deltas within minimal pairs; and (3) poor separation in probability space between unpaired grammatical and ungrammatical strings. Our analyses give theoretical grounding for using probability to learn about LMs' structural knowledge, and suggest directions for future work in LM grammatical evaluation.</li>
</ul>

<h3>Title: Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection</h3>
<ul>
<li><strong>Authors: </strong>Vishal Manikanden, Aniketh Bandlamudi, Daniel Haehn</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16235">https://arxiv.org/abs/2510.16235</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16235">https://arxiv.org/pdf/2510.16235</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16235]] Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection(https://arxiv.org/abs/2510.16235)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Oral Cavity Squamous Cell Carcinoma (OCSCC) is the most common type of head and neck cancer. Due to the subtle nature of its early stages, deep and hidden areas of development, and slow growth, OCSCC often goes undetected, leading to preventable deaths. However, properly trained Convolutional Neural Networks (CNNs), with their precise image segmentation techniques and ability to apply kernel matrices to modify the RGB values of images for accurate image pattern recognition, would be an effective means for early detection of OCSCC. Pairing this neural network with image capturing and processing hardware would allow increased efficacy in OCSCC detection. The aim of our project is to develop a Convolutional Neural Network trained to recognize OCSCC, as well as to design a physical hardware system to capture and process detailed images, in order to determine the image quality required for accurate predictions. A CNN was trained on 4293 training images consisting of benign and malignant tumors, as well as negative samples, and was evaluated for its precision, recall, and Mean Average Precision (mAP) in its predictions of OCSCC. A testing dataset of randomly assorted images of cancerous, non-cancerous, and negative images was chosen, and each image was altered to represent 5 common resolutions. This test data set was thoroughly analyzed by the CNN and predictions were scored on the basis of accuracy. The designed enhancement hardware was used to capture detailed images, and its impact was scored. An application was developed to facilitate the testing process and bring open access to the CNN. Images of increasing resolution resulted in higher-accuracy predictions on a logarithmic scale, demonstrating the diminishing returns of higher pixel counts.</li>
</ul>

<h3>Title: WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Lu, Jing Huang, Hui Liu, Jiri Gesi, Yan Han, Shihan Fu, Tianqi Zheng, Dakuo Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16252">https://arxiv.org/abs/2510.16252</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16252">https://arxiv.org/pdf/2510.16252</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16252]] WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale(https://arxiv.org/abs/2510.16252)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Training and evaluation of Reinforcement Learning (RL) web agents have gained increasing attention, yet a scalable and efficient environment that couples realistic and robust browser-side interaction with controllable server-side state at scale is still missing. Existing environments tend to have one or more of the following issues: they overwhelm policy models with excessive and noisy context; they perform actions non-deterministically without waiting for the UI or network to stabilize; or they cannot scale isolated client-server containers effectively for parallel RL rollouts. We propose WEBSERV, an environment that includes 1) a compact, site-agnostic browser environment that balances context and action complexity, and 2) a scalable RL environment via efficient launching and resetting web-servers to enable scalable RL training and evaluation. We evaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving state-of-the-art single-prompt success rates while cutting launch latency by ~5x and storage need by ~240x, with a comparable memory footprint, enabling 200+ concurrent containers on a single host.</li>
</ul>

<h3>Title: Detecting Adversarial Fine-tuning with Auditing Agents</h3>
<ul>
<li><strong>Authors: </strong>Sarah Egler, John Schulman, Nicholas Carlini</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16255">https://arxiv.org/abs/2510.16255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16255">https://arxiv.org/pdf/2510.16255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16255]] Detecting Adversarial Fine-tuning with Auditing Agents(https://arxiv.org/abs/2510.16255)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Model (LLM) providers expose fine-tuning APIs that let end users fine-tune their frontier LLMs. Unfortunately, it has been shown that an adversary with fine-tuning access to an LLM can bypass safeguards. Particularly concerning, such attacks may avoid detection with datasets that are only implicitly harmful. Our work studies robust detection mechanisms for adversarial use of fine-tuning APIs. We introduce the concept of a fine-tuning auditing agent and show it can detect harmful fine-tuning prior to model deployment. We provide our auditing agent with access to the fine-tuning dataset, as well as the fine-tuned and pre-fine-tuned models, and request the agent assigns a risk score for the fine-tuning job. We evaluate our detection approach on a diverse set of eight strong fine-tuning attacks from the literature, along with five benign fine-tuned models, totaling over 1400 independent audits. These attacks are undetectable with basic content moderation on the dataset, highlighting the challenge of the task. With the best set of affordances, our auditing agent achieves a 56.2% detection rate of adversarial fine-tuning at a 1% false positive rate. Most promising, the auditor is able to detect covert cipher attacks that evade safety evaluations and content moderation of the dataset. While benign fine-tuning with unintentional subtle safety degradation remains a challenge, we establish a baseline configuration for further work in this area. We release our auditing agent at this https URL.</li>
</ul>

<h3>Title: Instant Personalized Large Language Model Adaptation via Hypernetwork</h3>
<ul>
<li><strong>Authors: </strong>Zhaoxuan Tan, Zixuan Zhang, Haoyang Wen, Zheng Li, Rongzhi Zhang, Pei Chen, Fengran Mo, Zheyuan Liu, Qingkai Zeng, Qingyu Yin, Meng Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16282">https://arxiv.org/abs/2510.16282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16282">https://arxiv.org/pdf/2510.16282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16282]] Instant Personalized Large Language Model Adaptation via Hypernetwork(https://arxiv.org/abs/2510.16282)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, robust, large language model</a></li>
<li><strong>Abstract: </strong>Personalized large language models (LLMs) tailor content to individual preferences using user profiles or histories. However, existing parameter-efficient fine-tuning (PEFT) methods, such as the ``One-PEFT-Per-User'' (OPPU) paradigm, require training a separate adapter for each user, making them computationally expensive and impractical for real-time updates. We introduce Profile-to-PEFT, a scalable framework that employs a hypernetwork, trained end-to-end, to map a user's encoded profile directly to a full set of adapter parameters (e.g., LoRA), eliminating per-user training at deployment. This design enables instant adaptation, generalization to unseen users, and privacy-preserving local deployment. Experimental results demonstrate that our method outperforms both prompt-based personalization and OPPU while using substantially fewer computational resources at deployment. The framework exhibits strong generalization to out-of-distribution users and maintains robustness across varying user activity levels and different embedding backbones. The proposed Profile-to-PEFT framework enables efficient, scalable, and adaptive LLM personalization suitable for large-scale applications.</li>
</ul>

<h3>Title: OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Ryoto Miyamoto, Xin Fan, Fuyuko Kido, Tsuneo Matsumoto, Hayato Yamana</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16295">https://arxiv.org/abs/2510.16295</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16295">https://arxiv.org/pdf/2510.16295</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16295]] OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models(https://arxiv.org/abs/2510.16295)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer</a></li>
<li><strong>Abstract: </strong>OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in evaluating membership inference attacks (MIA) against large vision-language models (LVLMs). While prior work has reported high attack success rates, our analysis suggests that these results often arise from detecting distributional bias introduced during dataset construction rather than from identifying true membership status. To address this issue, we introduce a controlled benchmark of 6{,}000 images where the distributions of member and non-member samples are carefully balanced, and ground-truth membership labels are provided across three distinct training stages. Experiments using OpenLVLM-MIA demonstrated that the performance of state-of-the-art MIA methods converged to random chance under unbiased conditions. By offering a transparent and unbiased benchmark, OpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and provides a solid foundation for developing stronger privacy-preserving techniques.</li>
</ul>

<h3>Title: Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening</h3>
<ul>
<li><strong>Authors: </strong>Xin Wang, Yu Wang, Yunchao Liu, Jens Meiler, Tyler Derr</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16306">https://arxiv.org/abs/2510.16306</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16306">https://arxiv.org/pdf/2510.16306</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16306]] Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening(https://arxiv.org/abs/2510.16306)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Ligand-based virtual screening (VS) is an essential step in drug discovery that evaluates large chemical libraries to identify compounds that potentially bind to a therapeutic target. However, VS faces three major challenges: class imbalance due to the low active rate, structural imbalance among active molecules where certain scaffolds dominate, and the need to identify structurally diverse active compounds for novel drug development. We introduce ScaffAug, a scaffold-aware VS framework that addresses these challenges through three modules. The augmentation module first generates synthetic data conditioned on scaffolds of actual hits using generative AI, specifically a graph diffusion model. This helps mitigate the class imbalance and furthermore the structural imbalance, due to our proposed scaffold-aware sampling algorithm, designed to produce more samples for active molecules with underrepresented scaffolds. A model-agnostic self-training module is then used to safely integrate the generated synthetic data from our augmentation module with the original labeled data. Lastly, we introduce a reranking module that improves VS by enhancing scaffold diversity in the top recommended set of molecules, while still maintaining and even enhancing the overall general performance of identifying novel, active compounds. We conduct comprehensive computational experiments across five target classes, comparing ScaffAug against existing baseline methods by reporting the performance of multiple evaluation metrics and performing ablation studies on ScaffAug. Overall, this work introduces novel perspectives on effectively enhancing VS by leveraging generative augmentations, reranking, and general scaffold-awareness.</li>
</ul>

<h3>Title: Toward General Digraph Contrastive Learning: A Dual Spatial Perspective</h3>
<ul>
<li><strong>Authors: </strong>Daohan Su, Yang Zhang, Xunkai Li, Rong-Hua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16311">https://arxiv.org/abs/2510.16311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16311">https://arxiv.org/pdf/2510.16311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16311]] Toward General Digraph Contrastive Learning: A Dual Spatial Perspective(https://arxiv.org/abs/2510.16311)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Graph Contrastive Learning (GCL) has emerged as a powerful tool for extracting consistent representations from graphs, independent of labeled information. However, existing methods predominantly focus on undirected graphs, disregarding the pivotal directional information that is fundamental and indispensable in real-world networks (e.g., social networks and recommendations).In this paper, we introduce S2-DiGCL, a novel framework that emphasizes spatial insights from complex and real domain perspectives for directed graph (digraph) contrastive learning. From the complex-domain perspective, S2-DiGCL introduces personalized perturbations into the magnetic Laplacian to adaptively modulate edge phases and directional semantics. From the real-domain perspective, it employs a path-based subgraph augmentation strategy to capture fine-grained local asymmetries and topological dependencies. By jointly leveraging these two complementary spatial views, S2-DiGCL constructs high-quality positive and negative samples, leading to more general and robust digraph contrastive learning. Extensive experiments on 7 real-world digraph datasets demonstrate the superiority of our approach, achieving SOTA performance with 4.41% improvement in node classification and 4.34% in link prediction under both supervised and unsupervised settings.</li>
</ul>

<h3>Title: Scaling Laws for Deepfake Detection</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Wang, Longqi Cai, Taihong Xiao, Yuxiao Wang, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16320">https://arxiv.org/abs/2510.16320</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16320">https://arxiv.org/pdf/2510.16320</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16320]] Scaling Laws for Deepfake Detection(https://arxiv.org/abs/2510.16320)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a systematic study of scaling laws for the deepfake detection task. Specifically, we analyze the model performance against the number of real image domains, deepfake generation methods, and training images. Since no existing dataset meets the scale requirements for this research, we construct ScaleDF, the largest dataset to date in this field, which contains over 5.8 million real images from 51 different datasets (domains) and more than 8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we observe power-law scaling similar to that shown in large language models (LLMs). Specifically, the average detection error follows a predictable power-law decay as either the number of real domains or the number of deepfake methods increases. This key observation not only allows us to forecast the number of additional real domains or deepfake methods required to reach a target performance, but also inspires us to counter the evolving deepfake technology in a data-centric manner. Beyond this, we examine the role of pre-training and data augmentations in deepfake detection under scaling, as well as the limitations of scaling itself.</li>
</ul>

<h3>Title: Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention</h3>
<ul>
<li><strong>Authors: </strong>Yuyao Zhang, Yu-Wing Tai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16325">https://arxiv.org/abs/2510.16325</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16325">https://arxiv.org/pdf/2510.16325</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16325]] Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention(https://arxiv.org/abs/2510.16325)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Ultra-high-resolution text-to-image generation demands both fine-grained texture synthesis and globally coherent structure, yet current diffusion models remain constrained to sub-$1K \times 1K$ resolutions due to the prohibitive quadratic complexity of attention and the scarcity of native $4K$ training data. We present \textbf{Scale-DiT}, a new diffusion framework that introduces hierarchical local attention with low-resolution global guidance, enabling efficient, scalable, and semantically coherent image synthesis at ultra-high resolutions. Specifically, high-resolution latents are divided into fixed-size local windows to reduce attention complexity from quadratic to near-linear, while a low-resolution latent equipped with scaled positional anchors injects global semantics. A lightweight LoRA adaptation bridges global and local pathways during denoising, ensuring consistency across structure and detail. To maximize inference efficiency, we repermute token sequence in Hilbert curve order and implement a fused-kernel for skipping masked operations, resulting in a GPU-friendly design. Extensive experiments demonstrate that Scale-DiT achieves more than $2\times$ faster inference and lower memory usage compared to dense attention baselines, while reliably scaling to $4K \times 4K$ resolution without requiring additional high-resolution training data. On both quantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons, Scale-DiT delivers superior global coherence and sharper local detail, matching or outperforming state-of-the-art methods that rely on native 4K training. Taken together, these results highlight hierarchical local attention with guided low-resolution anchors as a promising and effective approach for advancing ultra-high-resolution image generation.</li>
</ul>

<h3>Title: DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution</h3>
<ul>
<li><strong>Authors: </strong>Yi Wei, Shunpu Tang, Liang Zhao, Qiangian Yang (College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16326">https://arxiv.org/abs/2510.16326</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16326">https://arxiv.org/pdf/2510.16326</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16326]] DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution(https://arxiv.org/abs/2510.16326)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in diffusion models have driven remarkable progress in image generation. However, the generation process remains computationally intensive, and users often need to iteratively refine prompts to achieve the desired results, further increasing latency and placing a heavy burden on cloud resources. To address this challenge, we propose DiffusionX, a cloud-edge collaborative framework for efficient multi-round, prompt-based generation. In this system, a lightweight on-device diffusion model interacts with users by rapidly producing preview images, while a high-capacity cloud model performs final refinements after the prompt is finalized. We further introduce a noise level predictor that dynamically balances the computation load, optimizing the trade-off between latency and cloud workload. Experiments show that DiffusionX reduces average generation time by 15.8% compared with Stable Diffusion v1.5, while maintaining comparable image quality. Moreover, it is only 0.9% slower than Tiny-SD with significantly improved image quality, thereby demonstrating efficiency and scalability with minimal overhead.</li>
</ul>

<h3>Title: Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation</h3>
<ul>
<li><strong>Authors: </strong>Fatemeh Jafarian Dehkordi, Elahe Vedadi, Alireza Feizbakhsh, Yasaman Keshtkarjahromi, Hulya Seferoglu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16331">https://arxiv.org/abs/2510.16331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16331">https://arxiv.org/pdf/2510.16331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16331]] Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation(https://arxiv.org/abs/2510.16331)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, federate</a></li>
<li><strong>Abstract: </strong>Striking a balance between protecting data privacy and enabling collaborative computation is a critical challenge for distributed machine learning. While privacy-preserving techniques for federated learning have been extensively developed, methods for scenarios involving bitwise operations, such as tree-based vertical federated learning (VFL), are still underexplored. Traditional mechanisms, including Shamir's secret sharing and multi-party computation (MPC), are not optimized for bitwise operations over binary data, particularly in settings where each participant holds a different part of the binary vector. This paper addresses the limitations of existing methods by proposing a novel binary multi-party computation (BiMPC) framework. The BiMPC mechanism facilitates privacy-preserving bitwise operations, with a particular focus on dot product computations of binary vectors, ensuring the privacy of each individual bit. The core of BiMPC is a novel approach called Dot Product via Modular Addition (DoMA), which uses regular and modular additions for efficient binary dot product calculation. To ensure privacy, BiMPC uses random masking in a higher field for linear computations and a three-party oblivious transfer (triot) protocol for non-linear binary operations. The privacy guarantees of the BiMPC framework are rigorously analyzed, demonstrating its efficiency and scalability in distributed settings.</li>
</ul>

<h3>Title: RL makes MLLMs see better than SFT</h3>
<ul>
<li><strong>Authors: </strong>Junha Song, Sangdoo Yun, Dongyoon Han, Jaegul Choo, Byeongho Heo</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16333">https://arxiv.org/abs/2510.16333</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16333">https://arxiv.org/pdf/2510.16333</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16333]] RL makes MLLMs see better than SFT(https://arxiv.org/abs/2510.16333)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>A dominant assumption in Multimodal Language Model (MLLM) research is that its performance is largely inherited from the LLM backbone, given its immense parameter scale and remarkable capabilities. This has created a void in the understanding of the vision encoder, which determines how MLLMs perceive images. The recent shift in MLLM training paradigms, from Supervised Finetuning (SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the significant lack of analysis on how such training reshapes the vision encoder as well as the MLLM. To address this, we first investigate the impact of training strategies on MLLMs, where RL shows a clear advantage over SFT in strongly vision-related VQA benchmarks. Motivated by this, we conduct a critical yet under-explored analysis of the vision encoder of MLLMs through diverse and in-depth experiments, ranging from ImageNet classification and segmentation to gradient visualization. Our results demonstrate that MLLM's post-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on MLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual representations. Specifically, the key finding of our study is that RL produces stronger and precisely localized visual representations compared to SFT, boosting the ability of the vision encoder for MLLM. We then reframe our findings into a simple recipe for building strong vision encoders for MLLMs, Preference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs, a PIVOT-trained vision encoder outperforms even larger and more heavily-trained counterparts, despite requiring less than 1% of the computational cost of standard vision pretraining. This result opens an effective and efficient path for advancing the vision backbones of MLLMs. Project page available at this https URL</li>
</ul>

<h3>Title: Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models</h3>
<ul>
<li><strong>Authors: </strong>Pratham Singla, Shivank Garg, Ayush Singh, Ishan Garg, Ketan Suhaas Saichandran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16340">https://arxiv.org/abs/2510.16340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16340">https://arxiv.org/pdf/2510.16340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16340]] Thinking About Thinking: Evaluating Reasoning in Post-Trained Language Models(https://arxiv.org/abs/2510.16340)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in post-training techniques have endowed Large Language Models (LLMs) with enhanced capabilities for tackling complex, logic-intensive tasks through the generation of supplementary planning tokens. This development raises a fundamental question: Are these models aware of what they "learn" and "think"? To address this, we define three core competencies: (1) awareness of learned latent policies, (2) generalization of these policies across domains, and (3) alignment between internal reasoning traces and final outputs. We empirically evaluate these abilities on several tasks, each designed to require learning a distinct policy. Furthermore, we contrast the profiles of models post-trained via Supervised Fine-Tuning (SFT), Direct Policy Optimization (DPO), and Group Relative Policy Optimization (GRPO). Our findings indicate that RL-trained models not only demonstrate greater awareness of their learned behaviors and stronger generalizability to novel, structurally similar tasks than SFT models but also often exhibit weak alignment between their reasoning traces and final outputs, an effect most pronounced in GRPO-trained models.</li>
</ul>

<h3>Title: MGTS-Net: Exploring Graph-Enhanced Multimodal Fusion for Augmented Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Shule Hao, Junpeng Bao, Wenli Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16350">https://arxiv.org/abs/2510.16350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16350">https://arxiv.org/pdf/2510.16350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16350]] MGTS-Net: Exploring Graph-Enhanced Multimodal Fusion for Augmented Time Series Forecasting(https://arxiv.org/abs/2510.16350)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent research in time series forecasting has explored integrating multimodal features into models to improve accuracy. However, the accuracy of such methods is constrained by three key challenges: inadequate extraction of fine-grained temporal patterns, suboptimal integration of multimodal information, and limited adaptability to dynamic multi-scale features. To address these problems, we propose MGTS-Net, a Multimodal Graph-enhanced Network for Time Series forecasting. The model consists of three core components: (1) a Multimodal Feature Extraction layer (MFE), which optimizes feature encoders according to the characteristics of temporal, visual, and textual modalities to extract temporal features of fine-grained patterns; (2) a Multimodal Feature Fusion layer (MFF), which constructs a heterogeneous graph to model intra-modal temporal dependencies and cross-modal alignment relationships and dynamically aggregates multimodal knowledge; (3) a Multi-Scale Prediction layer (MSP), which adapts to multi-scale features by dynamically weighting and fusing the outputs of short-term, medium-term, and long-term predictors. Extensive experiments demonstrate that MGTS-Net exhibits excellent performance with light weight and high efficiency. Compared with other state-of-the-art baseline models, our method achieves superior performance, validating the superiority of the proposed methodology.</li>
</ul>

<h3>Title: Sparse Transformer Architectures via Regularized Wasserstein Proximal Operator with $L_1$ Prior</h3>
<ul>
<li><strong>Authors: </strong>Fuqun Han, Stanley Osher, Wuchen Li</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16356">https://arxiv.org/abs/2510.16356</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16356">https://arxiv.org/pdf/2510.16356</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16356]] Sparse Transformer Architectures via Regularized Wasserstein Proximal Operator with $L_1$ Prior(https://arxiv.org/abs/2510.16356)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>In this work, we propose a sparse transformer architecture that incorporates prior information about the underlying data distribution directly into the transformer structure of the neural network. The design of the model is motivated by a special optimal transport problem, namely the regularized Wasserstein proximal operator, which admits a closed-form solution and turns out to be a special representation of transformer architectures. Compared with classical flow-based models, the proposed approach improves the convexity properties of the optimization problem and promotes sparsity in the generated samples. Through both theoretical analysis and numerical experiments, including applications in generative modeling and Bayesian inverse problems, we demonstrate that the sparse transformer achieves higher accuracy and faster convergence to the target distribution than classical neural ODE-based methods.</li>
</ul>

<h3>Title: Utilising Large Language Models for Generating Effective Counter Arguments to Anti-Vaccine Tweets</h3>
<ul>
<li><strong>Authors: </strong>Utsav Dhanuka, Soham Poddar, Saptarshi Ghosh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16359">https://arxiv.org/abs/2510.16359</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16359">https://arxiv.org/pdf/2510.16359</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16359]] Utilising Large Language Models for Generating Effective Counter Arguments to Anti-Vaccine Tweets(https://arxiv.org/abs/2510.16359)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In an era where public health is increasingly influenced by information shared on social media, combatting vaccine skepticism and misinformation has become a critical societal goal. Misleading narratives around vaccination have spread widely, creating barriers to achieving high immunisation rates and undermining trust in health recommendations. While efforts to detect misinformation have made significant progress, the generation of real time counter-arguments tailored to debunk such claims remains an insufficiently explored area. In this work, we explore the capabilities of LLMs to generate sound counter-argument rebuttals to vaccine misinformation. Building on prior research in misinformation debunking, we experiment with various prompting strategies and fine-tuning approaches to optimise counter-argument generation. Additionally, we train classifiers to categorise anti-vaccine tweets into multi-labeled categories such as concerns about vaccine efficacy, side effects, and political influences allowing for more context aware rebuttals. Our evaluation, conducted through human judgment, LLM based assessments, and automatic metrics, reveals strong alignment across these methods. Our findings demonstrate that integrating label descriptions and structured fine-tuning enhances counter-argument effectiveness, offering a promising approach for mitigating vaccine misinformation at scale.</li>
</ul>

<h3>Title: End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction</h3>
<ul>
<li><strong>Authors: </strong>Nilmadhab Das, Vishal Vaibhav, Yash Sunil Choudhary, V. Vijaya Saradhi, Ashish Anand</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16363">https://arxiv.org/abs/2510.16363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16363">https://arxiv.org/pdf/2510.16363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16363]] End-to-End Argument Mining through Autoregressive Argumentative Structure Prediction(https://arxiv.org/abs/2510.16363)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, extraction, generative</a></li>
<li><strong>Abstract: </strong>Argument Mining (AM) helps in automating the extraction of complex argumentative structures such as Argument Components (ACs) like Premise, Claim etc. and Argumentative Relations (ARs) like Support, Attack etc. in an argumentative text. Due to the inherent complexity of reasoning involved with this task, modelling dependencies between ACs and ARs is challenging. Most of the recent approaches formulate this task through a generative paradigm by flattening the argumentative structures. In contrast to that, this study jointly formulates the key tasks of AM in an end-to-end fashion using Autoregressive Argumentative Structure Prediction (AASP) framework. The proposed AASP framework is based on the autoregressive structure prediction framework that has given good performance for several NLP tasks. AASP framework models the argumentative structures as constrained pre-defined sets of actions with the help of a conditional pre-trained language model. These actions build the argumentative structures step-by-step in an autoregressive manner to capture the flow of argumentative reasoning in an efficient way. Extensive experiments conducted on three standard AM benchmarks demonstrate that AASP achieves state-of-theart (SoTA) results across all AM tasks in two benchmarks and delivers strong results in one benchmark.</li>
</ul>

<h3>Title: EditMark: Watermarking Large Language Models based on Model Editing</h3>
<ul>
<li><strong>Authors: </strong>Shuai Li, Kejiang Chen, Jun Jiang, Jie Zhang, Qiyi Yao, Kai Zeng, Weiming Zhang, Nenghai Yu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16367">https://arxiv.org/abs/2510.16367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16367">https://arxiv.org/pdf/2510.16367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16367]] EditMark: Watermarking Large Language Models based on Model Editing(https://arxiv.org/abs/2510.16367)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, steal, extraction, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated remarkable capabilities, but their training requires extensive data and computational resources, rendering them valuable digital assets. Therefore, it is essential to watermark LLMs to protect their copyright and trace unauthorized use or resale. Existing methods for watermarking LLMs primarily rely on training LLMs with a watermarked dataset, which entails burdensome training costs and negatively impacts the LLM's performance. In addition, their watermarked texts are not logical or natural, thereby reducing the stealthiness of the watermark. To address these issues, we propose EditMark, the first watermarking method that leverages model editing to embed a training-free, stealthy, and performance-lossless watermark for LLMs. We observe that some questions have multiple correct answers. Therefore, we assign each answer a unique watermark and update the weights of LLMs to generate corresponding questions and answers through the model editing technique. In addition, we refine the model editing technique to align with the requirements of watermark embedding. Specifically, we introduce an adaptive multi-round stable editing strategy, coupled with the injection of a noise matrix, to improve both the effectiveness and robustness of the watermark embedding. Extensive experiments indicate that EditMark can embed 32-bit watermarks into LLMs within 20 seconds (Fine-tuning: 6875 seconds) with a watermark extraction success rate of 100%, which demonstrates its effectiveness and efficiency. External experiments further demonstrate that EditMark has fidelity, stealthiness, and a certain degree of robustness against common attacks.</li>
</ul>

<h3>Title: MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization</h3>
<ul>
<li><strong>Authors: </strong>Pulin Li, Guocheng Wu, Li Yin, Yuxin Zheng, Wei Zhang, Yanjie Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16370">https://arxiv.org/abs/2510.16370</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16370">https://arxiv.org/pdf/2510.16370</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16370]] MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization(https://arxiv.org/abs/2510.16370)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Social manufacturing leverages community collaboration and scattered resources to realize mass individualization in modern industry. However, this paradigm shift also introduces substantial challenges in quality control, particularly in defect detection. The main difficulties stem from three aspects. First, products often have highly customized configurations. Second, production typically involves fragmented, small-batch orders. Third, imaging environments vary considerably across distributed sites. To overcome the scarcity of real-world datasets and tailored algorithms, we introduce the Mass Individualization Robust Anomaly Detection (MIRAD) dataset. As the first benchmark explicitly designed for anomaly detection in social manufacturing, MIRAD captures three critical dimensions of this domain: (1) diverse individualized products with large intra-class variation, (2) data collected from six geographically dispersed manufacturing nodes, and (3) substantial imaging heterogeneity, including variations in lighting, background, and motion conditions. We then conduct extensive evaluations of state-of-the-art (SOTA) anomaly detection methods on MIRAD, covering one-class, multi-class, and zero-shot approaches. Results show a significant performance drop across all models compared with conventional benchmarks, highlighting the unresolved complexities of defect detection in real-world individualized production. By bridging industrial requirements and academic research, MIRAD provides a realistic foundation for developing robust quality control solutions essential for Industry 5.0. The dataset is publicly available at this https URL.</li>
</ul>

<h3>Title: Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mohammad Javad Ahmadi, Iman Gandomi, Parisa Abdi, Seyed-Farzad Mohammadi, Amirhossein Taslimi, Mehdi Khodaparast, Hassan Hashemi, Mahdi Tavakoli, Hamid D. Taghirad</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16371">https://arxiv.org/abs/2510.16371</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16371">https://arxiv.org/pdf/2510.16371</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16371]] Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis(https://arxiv.org/abs/2510.16371)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The development of computer-assisted surgery systems depends on large-scale, annotated datasets. Current resources for cataract surgery often lack the diversity and annotation depth needed to train generalizable deep-learning models. To address this gap, we present a dataset of 3,000 phacoemulsification cataract surgery videos from two surgical centers, performed by surgeons with a range of experience levels. This resource is enriched with four annotation layers: temporal surgical phases, instance segmentation of instruments and anatomical structures, instrument-tissue interaction tracking, and quantitative skill scores based on the established competency rubrics like the ICO-OSCAR. The technical quality of the dataset is supported by a series of benchmarking experiments for key surgical AI tasks, including workflow recognition, scene segmentation, and automated skill assessment. Furthermore, we establish a domain adaptation baseline for the phase recognition task by training a model on a subset of surgical centers and evaluating its performance on a held-out center. The dataset and annotations are available in Google Form (this https URL).</li>
</ul>

<h3>Title: Navigating through the hidden embedding space: steering LLMs to improve mental health assessment</h3>
<ul>
<li><strong>Authors: </strong>Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16373">https://arxiv.org/abs/2510.16373</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16373">https://arxiv.org/pdf/2510.16373</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16373]] Navigating through the hidden embedding space: steering LLMs to improve mental health assessment(https://arxiv.org/abs/2510.16373)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of Large Language Models (LLMs) is transforming AI, opening new opportunities in sensitive and high-impact areas such as Mental Health (MH). Yet, despite these advancements, recent evidence reveals that smaller-scale models still struggle to deliver optimal performance in domain-specific applications. In this study, we present a cost-efficient yet powerful approach to improve MH assessment capabilities of an LLM, without relying on any computationally intensive techniques. Our lightweight method consists of a linear transformation applied to a specific layer's activations, leveraging steering vectors to guide the model's output. Remarkably, this intervention enables the model to achieve improved results across two distinct tasks: (1) identifying whether a Reddit post is useful for detecting the presence or absence of depressive symptoms (relevance prediction task), and (2) completing a standardized psychological screening questionnaire for depression based on users' Reddit post history (questionnaire completion task). Results highlight the untapped potential of steering mechanisms as computationally efficient tools for LLMs' MH domain adaptation.</li>
</ul>

<h3>Title: iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance</h3>
<ul>
<li><strong>Authors: </strong>Rishi Raj Sahoo, Surbhi Saswati Mohanty, Subhankar Mishra</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16375">https://arxiv.org/abs/2510.16375</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16375">https://arxiv.org/pdf/2510.16375</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16375]] iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance(https://arxiv.org/abs/2510.16375)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Road potholes pose significant safety hazards and maintenance challenges, particularly on India's diverse and under-maintained road networks. This paper presents iWatchRoadv2, a fully automated end-to-end platform for real-time pothole detection, GPS-based geotagging, and dynamic road health visualization using OpenStreetMap (OSM). We curated a self-annotated dataset of over 7,000 dashcam frames capturing diverse Indian road conditions, weather patterns, and lighting scenarios, which we used to fine-tune the Ultralytics YOLO model for accurate pothole detection. The system synchronizes OCR-extracted video timestamps with external GPS logs to precisely geolocate each detected pothole, enriching detections with comprehensive metadata, including road segment attribution and contractor information managed through an optimized backend database. iWatchRoadv2 introduces intelligent governance features that enable authorities to link road segments with contract metadata through a secure login interface. The system automatically sends alerts to contractors and officials when road health deteriorates, supporting automated accountability and warranty enforcement. The intuitive web interface delivers actionable analytics to stakeholders and the public, facilitating evidence-driven repair planning, budget allocation, and quality assessment. Our cost-effective and scalable solution streamlines frame processing and storage while supporting seamless public engagement for urban and rural deployments. By automating the complete pothole monitoring lifecycle, from detection to repair verification, iWatchRoadv2 enables data-driven smart city management, transparent governance, and sustainable improvements in road infrastructure maintenance. The platform and live demonstration are accessible at this https URL.</li>
</ul>

<h3>Title: ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents</h3>
<ul>
<li><strong>Authors: </strong>David Peer, Sebastian Stabinger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16381">https://arxiv.org/abs/2510.16381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16381">https://arxiv.org/pdf/2510.16381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16381]] ATA: A Neuro-Symbolic Approach to Implement Autonomous and Trustworthy Agents(https://arxiv.org/abs/2510.16381)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive capabilities, yet their deployment in high-stakes domains is hindered by inherent limitations in trustworthiness, including hallucinations, instability, and a lack of transparency. To address these challenges, we introduce a generic neuro-symbolic approach, which we call Autonomous Trustworthy Agents (ATA). The core of our approach lies in decoupling tasks into two distinct phases: Offline knowledge ingestion and online task processing. During knowledge ingestion, an LLM translates an informal problem specification into a formal, symbolic knowledge base. This formal representation is crucial as it can be verified and refined by human experts, ensuring its correctness and alignment with domain requirements. In the subsequent task processing phase, each incoming input is encoded into the same formal language. A symbolic decision engine then utilizes this encoded input in conjunction with the formal knowledge base to derive a reliable result. Through an extensive evaluation on a complex reasoning task, we demonstrate that a concrete implementation of ATA is competitive with state-of-the-art end-to-end reasoning models in a fully automated setup while maintaining trustworthiness. Crucially, with a human-verified and corrected knowledge base, our approach significantly outperforms even larger models, while exhibiting perfect determinism, enhanced stability against input perturbations, and inherent immunity to prompt injection attacks. By generating decisions grounded in symbolic reasoning, ATA offers a practical and controllable architecture for building the next generation of transparent, auditable, and reliable autonomous agents.</li>
</ul>

<h3>Title: REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting</h3>
<ul>
<li><strong>Authors: </strong>Changyue Shi, Minghao Chen, Yiping Mao, Chuxiao Yang, Xinyuan Hu, Jiajun Ding, Zhou Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16410">https://arxiv.org/abs/2510.16410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16410">https://arxiv.org/pdf/2510.16410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16410]] REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting(https://arxiv.org/abs/2510.16410)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Bridging the gap between complex human instructions and precise 3D object grounding remains a significant challenge in vision and robotics. Existing 3D segmentation methods often struggle to interpret ambiguous, reasoning-based instructions, while 2D vision-language models that excel at such reasoning lack intrinsic 3D spatial understanding. In this paper, we introduce REALM, an innovative MLLM-agent framework that enables open-world reasoning-based segmentation without requiring extensive 3D-specific post-training. We perform segmentation directly on 3D Gaussian Splatting representations, capitalizing on their ability to render photorealistic novel views that are highly suitable for MLLM comprehension. As directly feeding one or more rendered views to the MLLM can lead to high sensitivity to viewpoint selection, we propose a novel Global-to-Local Spatial Grounding strategy. Specifically, multiple global views are first fed into the MLLM agent in parallel for coarse-level localization, aggregating responses to robustly identify the target object. Then, several close-up novel views of the object are synthesized to perform fine-grained local segmentation, yielding accurate and consistent 3D masks. Extensive experiments show that REALM achieves remarkable performance in interpreting both explicit and implicit instructions across LERF, 3D-OVS, and our newly introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly supports a range of 3D interaction tasks, including object removal, replacement, and style transfer, demonstrating its practical utility and versatility. Project page: this https URL.</li>
</ul>

<h3>Title: Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures</h3>
<ul>
<li><strong>Authors: </strong>Minh-Khoi Nguyen-Nhat, Rachel S.Y. Teo, Laziz Abdullaev, Maurice Mok, Viet-Hoang Tran, Tan Minh Nguyen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16411">https://arxiv.org/abs/2510.16411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16411">https://arxiv.org/pdf/2510.16411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16411]] Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures(https://arxiv.org/abs/2510.16411)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Sparse Mixture of Experts (SMoE) has emerged as a promising solution to achieving unparalleled scalability in deep learning by decoupling model parameter count from computational cost. By activating only a small subset of parameters per sample, SMoE enables significant growth in model capacity while maintaining efficiency. However, SMoE struggles to adapt to distributional shifts, leading to reduced robustness under data contamination. In this work, we introduce SymphonySMoE, a novel family of SMoE that introduces a social graph to model interactions among experts. This graph-based structure enhances the token routing process, addressing the robustness challenges that are inherent in conventional SMoE designs. SymphonySMoE is lightweight, modular, and integrates seamlessly with existing SMoE-based models such as the XMoE and the Generalist Language Model. We provide both theoretical analysis and empirical evidence demonstrating SymphonySMoE's advantages over baseline SMoE. Extensive experiments on language modeling and visual instruction tuning validate our method's effectiveness. We further highlight the scalability of SymphonySMoE to models with 4.2 and 7.4 billion parameters, showcasing its applicability in fine-tuning tasks for large-scale systems.</li>
</ul>

<h3>Title: SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Xiaojun Guo, Runyu Zhou, Yifei Wang, Qi Zhang, Chenheng Zhang, Stefanie Jegelka, Xiaohan Wang, Jiajun Chai, Guojun Yin, Wei Lin, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16416">https://arxiv.org/abs/2510.16416</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16416">https://arxiv.org/pdf/2510.16416</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16416]] SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning(https://arxiv.org/abs/2510.16416)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have shown remarkable abilities by integrating large language models with visual inputs. However, they often fail to utilize visual evidence adequately, either depending on linguistic priors in vision-centric tasks or resorting to textual shortcuts during reasoning. Although reinforcement learning (RL) can align models with desired behaviors, its application to VLMs has been hindered by the lack of scalable and reliable reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel framework that leverages self-supervised learning (SSL) tasks as a source of verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL objectives-such as predicting image rotation or reconstructing masked patches-into dense, automatic reward signals, eliminating the need for human preference data or unreliable AI evaluators. Experiments show that SSL4RL substantially improves performance on both vision-centric and vision-language reasoning benchmarks. Furthermore, through systematic ablations, we identify key factors-such as task difficulty, model scale, and semantic alignment with the target domain-that influence the effectiveness of SSL4RL tasks, offering new design principles for future work. We also demonstrate the framework's generality by applying it to graph learning, where it yields significant gains. SSL4RL establishes a versatile and effective paradigm for aligning multimodal models using verifiable, self-supervised objectives.</li>
</ul>

<h3>Title: LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching</h3>
<ul>
<li><strong>Authors: </strong>Aidyn Ubingazhibov, Rémi Pautrat, Iago Suárez, Shaohui Liu, Marc Pollefeys, Viktor Larsson</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16438">https://arxiv.org/abs/2510.16438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16438">https://arxiv.org/pdf/2510.16438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16438]] LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching(https://arxiv.org/abs/2510.16438)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Lines and points are complementary local features, whose combination has proven effective for applications such as SLAM and Structure-from-Motion. The backbone of these pipelines are the local feature matchers, establishing correspondences across images. Traditionally, point and line matching have been treated as independent tasks. Recently, GlueStick proposed a GNN-based network that simultaneously operates on points and lines to establish matches. While running a single joint matching reduced the overall computational complexity, the heavy architecture prevented real-time applications or deployment to edge devices. Inspired by recent progress in point matching, we propose LightGlueStick, a lightweight matcher for points and line segments. The key novel component in our architecture is the Attentional Line Message Passing (ALMP), which explicitly exposes the connectivity of the lines to the network, allowing for efficient communication between nodes. In thorough experiments we show that LightGlueStick establishes a new state-of-the-art across different benchmarks. The code is available at this https URL.</li>
</ul>

<h3>Title: FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution</h3>
<ul>
<li><strong>Authors: </strong>Syed Rifat Raiyan, Md Farhan Ishmam, Abdullah Al Imran, Mohammad Ali Moni</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16439">https://arxiv.org/abs/2510.16439</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16439">https://arxiv.org/pdf/2510.16439</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16439]] FrugalPrompt: Reducing Contextual Overhead in Large Language Models via Token Attribution(https://arxiv.org/abs/2510.16439)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) owe much of their stellar performance to expansive input contexts, yet such verbosity inflates monetary costs, carbon footprint, and inference-time latency. Much of this overhead manifests from the redundant low-utility tokens present in typical prompts, as only a fraction of tokens typically carries the majority of the semantic weight. We address this inefficiency by introducing FrugalPrompt, a novel prompt compression framework for LLMs, which retains only the most semantically significant tokens. Leveraging two state-of-the-art token attribution methods, GlobEnc and DecompX, we assign salience scores to every token in an input sequence, rank them to preserve the top-k% tokens in their original order, and obtain a sparse frugalized prompt. We evaluate the approach across four NLP tasks: Sentiment Analysis, Commonsense QA, Summarization, and Mathematical Reasoning, using a suite of frontier LLMs. For the first three tasks, a 20% prompt reduction incurs only a marginal loss in task performance, demonstrating that contemporary LLMs can reconstruct elided context from high-salience cues. In contrast, performance on mathematical reasoning deteriorates sharply, reflecting a stronger dependence on complete token continuity. Further analysis with bottom-k% and random-k% tokens reveals asymmetric performance patterns that may suggest potential task contamination effects, wherein models may resort to shallow memorized patterns from pretraining exposure for conventional NLP tasks. We posit that our work contributes to a more nuanced understanding of LLM behavior in performance-efficiency trade-offs, and delineate the boundary between tasks tolerant to contextual sparsity and those requiring exhaustive context. Our source code and models are available at: this https URL</li>
</ul>

<h3>Title: Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution</h3>
<ul>
<li><strong>Authors: </strong>Dimitris Stefanopoulos, Andreas Voskou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16440">https://arxiv.org/abs/2510.16440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16440">https://arxiv.org/pdf/2510.16440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16440]] Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution(https://arxiv.org/abs/2510.16440)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This report presents the winning solution for Task 1 of Colliding with Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at ECML-PKDD 2025. The task required designing an adversarial attack against a provided classification model that maximizes misclassification while minimizing perturbations. Our approach employs a multi-round gradient-based strategy that leverages the differentiable structure of the model, augmented with random initialization and sample-mixing techniques to enhance effectiveness. The resulting attack achieved the best results in perturbation size and fooling success rate, securing first place in the competition.</li>
</ul>

<h3>Title: EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Haoran Sun, Chen Cai, Huiping Zhuang, Kong Aik Lee, Lap-Pui Chau, Yi Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16442">https://arxiv.org/abs/2510.16442</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16442">https://arxiv.org/pdf/2510.16442</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16442]] EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning(https://arxiv.org/abs/2510.16442)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, explainability, large language model</a></li>
<li><strong>Abstract: </strong>The rapid development of deepfake video technology has not only facilitated artistic creation but also made it easier to spread misinformation. Traditional deepfake video detection (DVD) methods face issues such as a lack of transparency in their principles and insufficient generalization capabilities to cope with evolving forgery techniques. This highlights an urgent need for detectors that can identify forged content and provide verifiable reasoning explanations. This paper proposes the explainable deepfake video detection (EDVD) task and designs the EDVD-LLaMA multimodal, a large language model (MLLM) reasoning framework, which provides traceable reasoning processes alongside accurate detection results and trustworthy explanations. Our approach first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT) to extract and fuse global and local cross-frame deepfake features, providing rich spatio-temporal semantic information input for MLLM reasoning. Second, we construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which introduces facial feature data as hard constraints during the reasoning process to achieve pixel-level spatio-temporal video localization, suppress hallucinated outputs, and enhance the reliability of the chain of thought. In addition, we build an Explainable Reasoning FF++ benchmark dataset (ER-FF++set), leveraging structured data to annotate videos and ensure quality control, thereby supporting dual supervision for reasoning and detection. Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding performance and robustness in terms of detection accuracy, explainability, and its ability to handle cross-forgery methods and cross-dataset scenarios. Compared to previous DVD methods, it provides a more explainable and superior solution. The source code and dataset will be publicly available.</li>
</ul>

<h3>Title: Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution</h3>
<ul>
<li><strong>Authors: </strong>Dimitris Stefanopoulos, Andreas Voskou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16443">https://arxiv.org/abs/2510.16443</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16443">https://arxiv.org/pdf/2510.16443</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16443]] Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution(https://arxiv.org/abs/2510.16443)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>This report presents the winning solution for Task 2 of Colliding with Adversaries: A Challenge on Robust Learning in High Energy Physics Discovery at ECML-PKDD 2025. The goal of the challenge was to design and train a robust ANN-based model capable of achieving high accuracy in a binary classification task on both clean and adversarial data generated with the Random Distribution Shuffle Attack (RDSA). Our solution consists of two components: a data generation phase and a robust model training phase. In the first phase, we produced 15 million artificial training samples using a custom methodology derived from Random Distribution Shuffle Attack (RDSA). In the second phase, we introduced a robust architecture comprising (i)a Feature Embedding Block with shared weights among features of the same type and (ii)a Dense Fusion Tail responsible for the final prediction. Training this architecture on our adversarial dataset achieved a mixed accuracy score of 80\%, exceeding the second-place solution by two percentage points.</li>
</ul>

<h3>Title: Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance</h3>
<ul>
<li><strong>Authors: </strong>Chien Thai, Mai Xuan Trang, Huong Ninh, Hoang Hiep Ly, Anh Son Le</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16445">https://arxiv.org/abs/2510.16445</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16445">https://arxiv.org/pdf/2510.16445</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16445]] Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance(https://arxiv.org/abs/2510.16445)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting rotated objects accurately and efficiently is a significant challenge in computer vision, particularly in applications such as aerial imagery, remote sensing, and autonomous driving. Although traditional object detection frameworks are effective for axis-aligned objects, they often underperform in scenarios involving rotated objects due to their limitations in capturing orientation variations. This paper introduces an improved loss function aimed at enhancing detection accuracy and robustness by leveraging the Gaussian bounding box representation and Bhattacharyya distance. In addition, we advocate for the use of an anisotropic Gaussian representation to address the issues associated with isotropic variance in square-like objects. Our proposed method addresses these challenges by incorporating a rotation-invariant loss function that effectively captures the geometric properties of rotated objects. We integrate this proposed loss function into state-of-the-art deep learning-based rotated object detection detectors, and extensive experiments demonstrated significant improvements in mean Average Precision metrics compared to existing methods. The results highlight the potential of our approach to establish new benchmark in rotated object detection, with implications for a wide range of applications requiring precise and reliable object localization irrespective of orientation.</li>
</ul>

<h3>Title: TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model</h3>
<ul>
<li><strong>Authors: </strong>Bin Yu, Xinming Wang, Shijie Lian, Haotian Li, Changti Wu, Ruina Hu, Bailing Wang, Yuliang Wei, Kai Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16449">https://arxiv.org/abs/2510.16449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16449">https://arxiv.org/pdf/2510.16449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16449]] TrajSelector: Harnessing Latent Representations for Efficient and Effective Best-of-N in Large Reasoning Model(https://arxiv.org/abs/2510.16449)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable progress in complex reasoning tasks, largely enabled by test-time scaling (TTS) paradigms that allocate additional compute during inference. Among these, external TTS (particularly the Best-of-N selection paradigm) yields scalable performance improvements by selecting from multiple independently generated reasoning trajectories. However, this approach faces key limitations: (i) the high computational overhead of deploying process reward models, (ii) the underutilization of the LLM's intrinsic latent representations. We introduce TrajSelector, an efficient and effective Best-of-N framework that exploit the hidden states in the sampler LLM for process-level scoring. A lightweight verifier (with only 0.6B parameters) evaluates the quality of step-wise trajectory, and then aggregates these scores to identify the optimal reasoning trajectory. Our framework employs a fully data-driven, end-to-end training recipe that eliminates reliance on massive step-level annotations. Experiential results across five benchmarks demonstrate that TrajSelector delivers consistent performance gains. In Best-of-32 settings, it surpasses majority voting by 4.61% accuracy and outperforms existing process reward models by 4.31% to 12.21%, all while maintaining lower inference costs.</li>
</ul>

<h3>Title: Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy</h3>
<ul>
<li><strong>Authors: </strong>Shan Xiong, Jiabao Chen, Ye Wang, Jialin Peng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16450">https://arxiv.org/abs/2510.16450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16450">https://arxiv.org/pdf/2510.16450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16450]] Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy(https://arxiv.org/abs/2510.16450)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Annotation-efficient segmentation of the numerous mitochondria instances from various electron microscopy (EM) images is highly valuable for biological and neuroscience research. Although unsupervised domain adaptation (UDA) methods can help mitigate domain shifts and reduce the high costs of annotating each domain, they typically have relatively low performance in practical applications. Thus, we investigate weakly supervised domain adaptation (WDA) that utilizes additional sparse point labels on the target domain, which require minimal annotation effort and minimal expert knowledge. To take full use of the incomplete and imprecise point annotations, we introduce a multitask learning framework that jointly conducts segmentation and center detection with a novel cross-teaching mechanism and class-focused cross-domain contrastive learning. While leveraging unlabeled image regions is essential, we introduce segmentation self-training with a novel instance-aware pseudo-label (IPL) selection strategy. Unlike existing methods that typically rely on pixel-wise pseudo-label filtering, the IPL semantically selects reliable and diverse pseudo-labels with the help of the detection task. Comprehensive validations and comparisons on challenging datasets demonstrate that our method outperforms existing UDA and WDA methods, significantly narrowing the performance gap with the supervised upper bound. Furthermore, under the UDA setting, our method also achieves substantial improvements over other UDA techniques.</li>
</ul>

<h3>Title: RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Deyi Ji, Yuekui Yang, Haiyang Wu, Shaoping Ma, Tianrun Chen, Lanyun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16455">https://arxiv.org/abs/2510.16455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16455">https://arxiv.org/pdf/2510.16455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16455]] RAVEN: Robust Advertisement Video Violation Temporal Grounding via Reinforcement Reasoning(https://arxiv.org/abs/2510.16455)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Advertisement (Ad) video violation detection is critical for ensuring platform compliance, but existing methods struggle with precise temporal grounding, noisy annotations, and limited generalization. We propose RAVEN, a novel framework that integrates curriculum reinforcement learning with multimodal large language models (MLLMs) to enhance reasoning and cognitive capabilities for violation detection. RAVEN employs a progressive training strategy, combining precisely and coarsely annotated data, and leverages Group Relative Policy Optimization (GRPO) to develop emergent reasoning abilities without explicit reasoning annotations. Multiple hierarchical sophisticated reward mechanism ensures precise temporal grounding and consistent category prediction. Experiments on industrial datasets and public benchmarks show that RAVEN achieves superior performances in violation category accuracy and temporal interval localization. We also design a pipeline to deploy the RAVEN on the online Ad services, and online A/B testing further validates its practical applicability, with significant improvements in precision and recall. RAVEN also demonstrates strong generalization, mitigating the catastrophic forgetting issue associated with supervised fine-tuning.</li>
</ul>

<h3>Title: Heimdallr: Fingerprinting SD-WAN Control-Plane Architecture via Encrypted Control Traffic</h3>
<ul>
<li><strong>Authors: </strong>Minjae Seo, Jaehan Kim, Eduard Marin, Myoungsung You, Taejune Park, Seungsoo Lee, Seungwon Shin, Jinwoo Kim</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.NI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16461">https://arxiv.org/abs/2510.16461</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16461">https://arxiv.org/pdf/2510.16461</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16461]] Heimdallr: Fingerprinting SD-WAN Control-Plane Architecture via Encrypted Control Traffic(https://arxiv.org/abs/2510.16461)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Software-defined wide area network (SD-WAN) has emerged as a new paradigm for steering a large-scale network flexibly by adopting distributed software-defined network (SDN) controllers. The key to building a logically centralized but physically distributed control-plane is running diverse cluster management protocols to achieve consistency through an exchange of control traffic. Meanwhile, we observe that the control traffic exposes unique time-series patterns and directional relationships due to the operational structure even though the traffic is encrypted, and this pattern can disclose confidential information such as control-plane topology and protocol dependencies, which can be exploited for severe attacks. With this insight, we propose a new SD-WAN fingerprinting system, called Heimdallr. It analyzes periodical and operational patterns of SD-WAN cluster management protocols and the context of flow directions from the collected control traffic utilizing a deep learning-based approach, so that it can classify the cluster management protocols automatically from miscellaneous control traffic datasets. Our evaluation, which is performed in a realistic SD-WAN environment consisting of geographically distant three campus networks and one enterprise network shows that Heimdallr can classify SD-WAN control traffic with $\geq$ 93%, identify individual protocols with $\geq$ 80% macro F-1 scores, and finally can infer control-plane topology with $\geq$ 70% similarity.</li>
</ul>

<h3>Title: Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making</h3>
<ul>
<li><strong>Authors: </strong>Emmanuelle Claeys, Elena Kerjean, Jean-Michel Loubes</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16462">https://arxiv.org/abs/2510.16462</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16462">https://arxiv.org/pdf/2510.16462</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16462]] Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making(https://arxiv.org/abs/2510.16462)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>We introduce a sequential reinforcement learning framework for imitation learning designed to model heterogeneous cognitive strategies in pollinators. Focusing on honeybees, our approach leverages trajectory similarity to capture and forecast behavior across individuals that rely on distinct strategies: some exploiting numerical cues, others drawing on memory, or being influenced by environmental factors such as weather. Through empirical evaluation, we show that state-of-the-art imitation learning methods often fail in this setting: when expert policies shift across memory windows or deviate from optimality, these models overlook both fast and slow learning behaviors and cannot faithfully reproduce key decision patterns. Moreover, they offer limited interpretability, hindering biological insight. Our contribution addresses these challenges by (i) introducing a model that minimizes predictive loss while identifying the effective memory horizon most consistent with behavioral data, and (ii) ensuring full interpretability to enable biologists to analyze underlying decision-making strategies and finally (iii) providing a mathematical framework linking bee policy search with bandit formulations under varying exploration-exploitation dynamics, and releasing a novel dataset of 80 tracked bees observed under diverse weather conditions. This benchmark facilitates research on pollinator cognition and supports ecological governance by improving simulations of insect behavior in agroecosystems. Our findings shed new light on the learning strategies and memory interplay shaping pollinator decision-making.</li>
</ul>

<h3>Title: Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety</h3>
<ul>
<li><strong>Authors: </strong>Vamshi Krishna Bonagiri, Ponnurangam Kumaragurum, Khanh Nguyen, Benjamin Plaut</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16492">https://arxiv.org/abs/2510.16492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16492">https://arxiv.org/pdf/2510.16492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16492]] Check Yourself Before You Wreck Yourself: Selectively Quitting Improves LLM Agent Safety(https://arxiv.org/abs/2510.16492)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Model (LLM) agents increasingly operate in complex environments with real-world consequences, their safety becomes critical. While uncertainty quantification is well-studied for single-turn tasks, multi-turn agentic scenarios with real-world tool access present unique challenges where uncertainties and ambiguities compound, leading to severe or catastrophic risks beyond traditional text generation failures. We propose using "quitting" as a simple yet effective behavioral mechanism for LLM agents to recognize and withdraw from situations where they lack confidence. Leveraging the ToolEmu framework, we conduct a systematic evaluation of quitting behavior across 12 state-of-the-art LLMs. Our results demonstrate a highly favorable safety-helpfulness trade-off: agents prompted to quit with explicit instructions improve safety by an average of +0.39 on a 0-3 scale across all models (+0.64 for proprietary models), while maintaining a negligible average decrease of -0.03 in helpfulness. Our analysis demonstrates that simply adding explicit quit instructions proves to be a highly effective safety mechanism that can immediately be deployed in existing agent systems, and establishes quitting as an effective first-line defense mechanism for autonomous agents in high-stakes applications.</li>
</ul>

<h3>Title: Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection</h3>
<ul>
<li><strong>Authors: </strong>Michelle Yuan, Khushbu Pahwa, Shuaichen Chang, Mustafa Kaba, Jiarong Jiang, Xiaofei Ma, Yi Zhang, Monica Sunkara</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16499">https://arxiv.org/abs/2510.16499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16499">https://arxiv.org/pdf/2510.16499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16499]] Automated Composition of Agents: A Knapsack Approach for Agentic Component Selection(https://arxiv.org/abs/2510.16499)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Designing effective agentic systems requires the seamless composition and integration of agents, tools, and models within dynamic and uncertain environments. Most existing methods rely on static, semantic retrieval approaches for tool or agent discovery. However, effective reuse and composition of existing components remain challenging due to incomplete capability descriptions and the limitations of retrieval methods. Component selection suffers because the decisions are not based on capability, cost, and real-time utility. To address these challenges, we introduce a structured, automated framework for agentic system composition that is inspired by the knapsack problem. Our framework enables a composer agent to systematically identify, select, and assemble an optimal set of agentic components by jointly considering performance, budget constraints, and compatibility. By dynamically testing candidate components and modeling their utility in real-time, our approach streamlines the assembly of agentic systems and facilitates scalable reuse of resources. Empirical evaluation with Claude 3.5 Sonnet across five benchmarking datasets shows that our online-knapsack-based composer consistently lies on the Pareto frontier, achieving higher success rates at significantly lower component costs compared to our baselines. In the single-agent setup, the online knapsack composer shows a success rate improvement of up to 31.6% in comparison to the retrieval baselines. In multi-agent systems, the online knapsack composer increases success rate from 37% to 87% when agents are selected from an agent inventory of 100+ agents. The substantial performance gap confirms the robust adaptability of our method across diverse domains and budget constraints.</li>
</ul>

<h3>Title: OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks</h3>
<ul>
<li><strong>Authors: </strong>Franko Šikić, Sven Lončarić</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16508">https://arxiv.org/abs/2510.16508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16508">https://arxiv.org/pdf/2510.16508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16508]] OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks(https://arxiv.org/abs/2510.16508)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Out-of-stock (OOS) detection is a very important retail verification process that aims to infer the unavailability of products in their designated areas on the shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based method that advances OOS detection through auxiliary learning. In particular, we extend a well-established YOLOv8 object detection architecture with additional convolutional branches to simultaneously detect OOS, segment products, and estimate scene depth. While OOS detection and product segmentation branches are trained using ground truth data, the depth estimation branch is trained using pseudo-labeled annotations produced by the state-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore, since the aforementioned pseudo-labeled depth estimates display relative depth, we propose an appropriate depth normalization procedure that stabilizes the training process. The experimental results show that the proposed method surpassed the performance of the SOTA OOS detection methods by 1.8% of the mean average precision (mAP). In addition, ablation studies confirm the effectiveness of auxiliary learning and the proposed depth normalization procedure, with the former increasing mAP by 3.7% and the latter by 4.2%.</li>
</ul>

<h3>Title: eDCF: Estimating Intrinsic Dimension using Local Connectivity</h3>
<ul>
<li><strong>Authors: </strong>Dhruv Gupta, Aditya Nagarsekar, Vraj Shah, Sujith Thomas</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16513">https://arxiv.org/abs/2510.16513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16513">https://arxiv.org/pdf/2510.16513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16513]] eDCF: Estimating Intrinsic Dimension using Local Connectivity(https://arxiv.org/abs/2510.16513)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern datasets often contain high-dimensional features exhibiting complex dependencies. To effectively analyze such data, dimensionality reduction methods rely on estimating the dataset's intrinsic dimension (id) as a measure of its underlying complexity. However, estimating id is challenging due to its dependence on scale: at very fine scales, noise inflates id estimates, while at coarser scales, estimates stabilize to lower, scale-invariant values. This paper introduces a novel, scalable, and parallelizable method called eDCF, which is based on Connectivity Factor (CF), a local connectivity-based metric, to robustly estimate intrinsic dimension across varying scales. Our method consistently matches leading estimators, achieving comparable values of mean absolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our approach also attains higher exact intrinsic dimension match rates, reaching up to 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling under medium to high noise levels and large datasets. Further, we showcase our method's ability to accurately detect fractal geometries in decision boundaries, confirming its utility for analyzing realistic, structured data.</li>
</ul>

<h3>Title: Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Ashutosh Srivastava, Lokesh Nagalapatti, Gautam Jajoo, Aniket Vashishtha, Parameswari Krishnamurthy, Amit Sharma</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16530">https://arxiv.org/abs/2510.16530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16530">https://arxiv.org/pdf/2510.16530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16530]] Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks(https://arxiv.org/abs/2510.16530)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Recent claims of strong performance by Large Language Models (LLMs) on causal discovery are undermined by a key flaw: many evaluations rely on benchmarks likely included in pretraining corpora. Thus, apparent success suggests that LLM-only methods, which ignore observational data, outperform classical statistical approaches. We challenge this narrative by asking: Do LLMs truly reason about causal structure, and how can we measure it without memorization concerns? Can they be trusted for real-world scientific discovery? We argue that realizing LLMs' potential for causal analysis requires two shifts: (P.1) developing robust evaluation protocols based on recent scientific studies to guard against dataset leakage, and (P.2) designing hybrid methods that combine LLM-derived knowledge with data-driven statistics. To address P.1, we encourage evaluating discovery methods on novel, real-world scientific studies. We outline a practical recipe for extracting causal graphs from recent publications released after an LLM's training cutoff, ensuring relevance and preventing memorization while capturing both established and novel relations. Compared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy, they perform far worse on our curated graphs, underscoring the need for statistical grounding. Supporting P.2, we show that using LLM predictions as priors for the classical PC algorithm significantly improves accuracy over both LLM-only and purely statistical methods. We call on the community to adopt science-grounded, leakage-resistant benchmarks and invest in hybrid causal discovery methods suited to real-world inquiry.</li>
</ul>

<h3>Title: $ρ$Hammer: Reviving RowHammer Attacks on New Architectures via Prefetching</h3>
<ul>
<li><strong>Authors: </strong>Weijie Chen, Shan Tang, Yulin Tang, Xiapu Luo, Yinqian Zhang, Weizhong Qiang</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16544">https://arxiv.org/abs/2510.16544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16544">https://arxiv.org/pdf/2510.16544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16544]] $ρ$Hammer: Reviving RowHammer Attacks on New Architectures via Prefetching(https://arxiv.org/abs/2510.16544)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Rowhammer is a critical vulnerability in dynamic random access memory (DRAM) that continues to pose a significant threat to various systems. However, we find that conventional load-based attacks are becoming highly ineffective on the most recent architectures such as Intel Alder and Raptor Lake. In this paper, we present $\rho$Hammer, a new Rowhammer framework that systematically overcomes three core challenges impeding attacks on these new architectures. First, we design an efficient and generic DRAM address mapping reverse-engineering method that uses selective pairwise measurements and structured deduction, enabling recovery of complex mappings within seconds on the latest memory controllers. Second, to break through the activation rate bottleneck of load-based hammering, we introduce a novel prefetch-based hammering paradigm that leverages the asynchronous nature of x86 prefetch instructions and is further enhanced by multi-bank parallelism to maximize throughput. Third, recognizing that speculative execution causes more severe disorder issues for prefetching, which cannot be simply mitigated by memory barriers, we develop a counter-speculation hammering technique using control-flow obfuscation and optimized NOP-based pseudo-barriers to maintain prefetch order with minimal overhead. Evaluations across four latest Intel architectures demonstrate $\rho$Hammer's breakthrough effectiveness: it induces up to 200K+ additional bit flips within 2-hour attack pattern fuzzing processes and has a 112x higher flip rate than the load-based hammering baselines on Comet and Rocket Lake. Also, we are the first to revive Rowhammer attacks on the latest Raptor Lake architecture, where baselines completely fail, achieving stable flip rates of 2,291/min and fast end-to-end exploitation.</li>
</ul>

<h3>Title: Predicting life satisfaction using machine learning and explainable AI</h3>
<ul>
<li><strong>Authors: </strong>Alif Elham Khan, Mohammad Junayed Hasan, Humayra Anjum, Nabeel Mohammed, Sifat Momen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16547">https://arxiv.org/abs/2510.16547</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16547">https://arxiv.org/pdf/2510.16547</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16547]] Predicting life satisfaction using machine learning and explainable AI(https://arxiv.org/abs/2510.16547)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Life satisfaction is a crucial facet of human well-being. Hence, research on life satisfaction is incumbent for understanding how individuals experience their lives and influencing interventions targeted at enhancing mental health and well-being. Life satisfaction has traditionally been measured using analog, complicated, and frequently error-prone methods. These methods raise questions concerning validation and propagation. However, this study demonstrates the potential for machine learning algorithms to predict life satisfaction with a high accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a government survey of 19000 people aged 16-64 years in Denmark. Using feature learning techniques, 27 significant questions for assessing contentment were extracted, making the study highly reproducible, simple, and easily interpretable. Furthermore, clinical and biomedical large language models (LLMs) were explored for predicting life satisfaction by converting tabular data into natural language sentences through mapping and adding meaningful counterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It was found that life satisfaction prediction is more closely related to the biomedical domain than the clinical domain. Ablation studies were also conducted to understand the impact of data resampling and feature selection techniques on model performance. Moreover, the correlation between primary determinants with different age brackets was analyzed, and it was found that health condition is the most important determinant across all ages. This study demonstrates how machine learning, large language models and XAI can jointly contribute to building trust and understanding in using AI to investigate human behavior, with significant ramifications for academics and professionals working to quantify and comprehend subjective well-being.</li>
</ul>

<h3>Title: NeurIPT: Foundation Model for Neural Interfaces</h3>
<ul>
<li><strong>Authors: </strong>Zitao Fang, Chenxuan Li, Hongting Zhou, Shuyang Yu, Guodong Du, Ashwaq Qasem, Yang Lu, Jing Li, Junsong Zhang, Sim Kuan Goh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16548">https://arxiv.org/abs/2510.16548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16548">https://arxiv.org/pdf/2510.16548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16548]] NeurIPT: Foundation Model for Neural Interfaces(https://arxiv.org/abs/2510.16548)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Electroencephalography (EEG) has wide-ranging applications, from clinical diagnosis to brain-computer interfaces (BCIs). With the increasing volume and variety of EEG data, there has been growing interest in establishing foundation models (FMs) to scale up and generalize neural decoding. Despite showing early potential, applying FMs to EEG remains challenging due to substantial inter-subject, inter-task, and inter-condition variability, as well as diverse electrode configurations across recording setups. To tackle these open challenges, we propose NeurIPT, a foundation model developed for diverse EEG-based Neural Interfaces with a Pre-trained Transformer by capturing both homogeneous and heterogeneous spatio-temporal characteristics inherent in EEG signals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP), masking based on signal amplitude rather than random intervals, to learn robust representations across varying signal intensities beyond local interpolation. Moreover, this temporal representation is enhanced by a Progressive Mixture-of-Experts (PMoE) architecture, where specialized expert subnetworks are progressively introduced at deeper layers, adapting effectively to the diverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages the 3D physical coordinates of electrodes, enabling effective transfer of embedding across varying EEG settings, and develops Intra-Inter Lobe Pooling (IILP) during fine-tuning to efficiently exploit regional brain features. Empirical evaluations across eight downstream BCI datasets, via fine-tuning, demonstrated NeurIPT consistently achieved state-of-the-art performance, highlighting its broad applicability and robust generalization. Our work pushes forward the state of FMs in EEG and offers insights into scalable and generalizable neural information processing systems.</li>
</ul>

<h3>Title: ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Haoxuan Zhang, Ruochi Li, Sarthak Shrestha, Shree Harshini Mamidala, Revanth Putta, Arka Krishan Aggarwal, Ting Xiao, Junhua Ding, Haihua Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16549">https://arxiv.org/abs/2510.16549</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16549">https://arxiv.org/pdf/2510.16549</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16549]] ReviewGuard: Enhancing Deficient Peer Review Detection via LLM-Driven Data Augmentation(https://arxiv.org/abs/2510.16549)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Peer review serves as the gatekeeper of science, yet the surge in submissions and widespread adoption of large language models (LLMs) in scholarly evaluation present unprecedented challenges. Recent work has focused on using LLMs to improve review efficiency or generate insightful review content. However, unchecked deficient reviews from both human experts and AI systems threaten to systematically undermine the peer review ecosystem and compromise academic integrity. To address this critical issue, we introduce ReviewGuard, an automated system for detecting and categorizing deficient reviews. ReviewGuard employs a comprehensive four-stage LLM-driven framework that: (1) collects ICLR and NeurIPS papers with their corresponding reviews from OpenReview; (2) annotates review types using GPT-4.1 with human validation; (3) addresses class imbalance and data scarcity through LLM-driven synthetic data augmentation, producing a final corpus of 6,634 papers, 24,657 real reviews, and 46,438 synthetic reviews; and (4) fine-tunes both encoder-based models and open source LLMs. We perform comprehensive feature analysis of the structure and quality of the review text. Compared to sufficient reviews, deficient reviews demonstrate lower rating scores, higher self-reported confidence, reduced structural complexity, and a higher proportion of negative sentiment. AI-generated text detection reveals that, since ChatGPT's emergence, AI-generated reviews have increased dramatically. In the evaluation of deficient review detection models, mixed training with synthetic and real review data provides substantial enhancements to recall and F1 scores on the binary task. This study presents the first LLM-driven system for detecting deficient peer reviews, providing evidence to inform AI governance in peer review while offering valuable insights into human-AI collaboration to maintain academic integrity.</li>
</ul>

<h3>Title: LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ang Li, Yifei Wang, Zhihang Yuan, Stefanie Jegelka, Yisen Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16552">https://arxiv.org/abs/2510.16552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16552">https://arxiv.org/pdf/2510.16552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16552]] LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs(https://arxiv.org/abs/2510.16552)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Reinforcement learning in large language models (LLMs) often relies on scalar rewards, a practice that discards valuable textual rationale buried in the rollouts, forcing the model to explore \textit{de novo} with each attempt and hindering sample efficiency. While LLMs can uniquely learn from language feedback provided in-context, naively integrating on-line experiences into RL training presents a paradox: feedback from the same problem risks information leakage and memorization, while feedback from different problems often leads to behavior collapse due to irrelevant context. To resolve this tension, we propose \textbf{Language-And-Numerical Policy Optimization (LANPO)}, a framework that cleanly separates the roles of feedback: language guides exploration, while numerical rewards drive optimization. LANPO builds a dynamic experience pool from past trials and introduces two principles to ensure feedback is effective: \emph{Reward-Agnostic Reflection} for safe intra-sample self-correction and \emph{Relevant Abstraction} to distill generalizable lessons from inter-sample experiences. Across mathematical reasoning benchmarks, LANPO enables 7B and 14B models to significantly outperform strong baselines trained with GRPO in test accuracy. Our work provides a robust method for integrating historical experiences into the LLM RL loop, creating more effective and data-efficient learning agents.</li>
</ul>

<h3>Title: Fit for Purpose? Deepfake Detection in the Real World</h3>
<ul>
<li><strong>Authors: </strong>Guangyu Lin, Li Lin, Christina P. Walker, Daniel S. Schiff, Shu Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16556">https://arxiv.org/abs/2510.16556</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16556">https://arxiv.org/pdf/2510.16556</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16556]] Fit for Purpose? Deepfake Detection in the Real World(https://arxiv.org/abs/2510.16556)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative, large language model</a></li>
<li><strong>Abstract: </strong>The rapid proliferation of AI-generated content, driven by advances in generative adversarial networks, diffusion models, and multimodal large language models, has made the creation and dissemination of synthetic media effortless, heightening the risks of misinformation, particularly political deepfakes that distort truth and undermine trust in political institutions. In turn, governments, research institutions, and industry have strongly promoted deepfake detection initiatives as solutions. Yet, most existing models are trained and validated on synthetic, laboratory-controlled datasets, limiting their generalizability to the kinds of real-world political deepfakes circulating on social platforms that affect the public. In this work, we introduce the first systematic benchmark based on the Political Deepfakes Incident Database, a curated collection of real-world political deepfakes shared on social media since 2018. Our study includes a systematic evaluation of state-of-the-art deepfake detectors across academia, government, and industry. We find that the detectors from academia and government perform relatively poorly. While paid detection tools achieve relatively higher performance than free-access models, all evaluated detectors struggle to generalize effectively to authentic political deepfakes, and are vulnerable to simple manipulations, especially in the video domain. Results urge the need for politically contextualized deepfake detection frameworks to better safeguard the public in real-world settings.</li>
</ul>

<h3>Title: Toward Understanding Security Issues in the Model Context Protocol Ecosystem</h3>
<ul>
<li><strong>Authors: </strong>Xiaofan Li, Xing Gao</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16558">https://arxiv.org/abs/2510.16558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16558">https://arxiv.org/pdf/2510.16558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16558]] Toward Understanding Security Issues in the Model Context Protocol Ecosystem(https://arxiv.org/abs/2510.16558)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>The Model Context Protocol (MCP) is an emerging open standard that enables AI-powered applications to interact with external tools through structured metadata. A rapidly growing ecosystem has formed around MCP, including a wide range of MCP hosts (i.e., Cursor, Windsurf, Claude Desktop, and Cline), MCP registries (i.e., this http URL, MCP Market, MCP Store, Pulse MCP, Smithery, and npm), and thousands of community-contributed MCP servers. Although the MCP ecosystem is gaining traction, there has been little systematic study of its architecture and associated security risks. In this paper, we present the first comprehensive security analysis of the MCP ecosystem. We decompose MCP ecosystem into three core components: hosts, registries, and servers, and study the interactions and trust relationships among them. Users search for servers on registries and configure them in the host, which translates LLM-generated output into external tool invocations provided by the servers and executes them. Our qualitative analysis reveals that hosts lack output verification mechanisms for LLM-generated outputs, enabling malicious servers to manipulate model behavior and induce a variety of security threats, including but not limited to sensitive data exfiltration. We uncover a wide range of vulnerabilities that enable attackers to hijack servers, due to the lack of a vetted server submission process in registries. To support our analysis, we collect and analyze a dataset of 67,057 servers from six public registries. Our quantitative analysis demonstrates that a substantial number of servers can be hijacked by attackers. Finally, we propose practical defense strategies for MCP hosts, registries, and users. We responsibly disclosed our findings to affected hosts and registries.</li>
</ul>

<h3>Title: Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Seungho Cho, Changgeon Ko, Eui Jun Hwang, Junmyeong Lee, Huije Lee, Jong C. Park</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16565">https://arxiv.org/abs/2510.16565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16565">https://arxiv.org/pdf/2510.16565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16565]] Language over Content: Tracing Cultural Understanding in Multilingual Large Language Models(https://arxiv.org/abs/2510.16565)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used across diverse cultural contexts, making accurate cultural understanding essential. Prior evaluations have mostly focused on output-level performance, obscuring the factors that drive differences in responses, while studies using circuit analysis have covered few languages and rarely focused on culture. In this work, we trace LLMs' internal cultural understanding mechanisms by measuring activation path overlaps when answering semantically equivalent questions under two conditions: varying the target country while fixing the question language, and varying the question language while fixing the country. We also use same-language country pairs to disentangle language from cultural aspects. Results show that internal paths overlap more for same-language, cross-country questions than for cross-language, same-country questions, indicating strong language-specific patterns. Notably, the South Korea-North Korea pair exhibits low overlap and high variability, showing that linguistic similarity does not guarantee aligned internal representation.</li>
</ul>

<h3>Title: AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Ammar, Hadiya Murad Hadi, Usman Majeed Butt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16573">https://arxiv.org/abs/2510.16573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16573">https://arxiv.org/pdf/2510.16573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16573]] AI-Generated Text Detection in Low-Resource Languages: A Case Study on Urdu(https://arxiv.org/abs/2510.16573)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are now capable of generating text that closely resembles human writing, making them powerful tools for content creation, but this growing ability has also made it harder to tell whether a piece of text was written by a human or by a machine. This challenge becomes even more serious for languages like Urdu, where there are very few tools available to detect AI-generated text. To address this gap, we propose a novel AI-generated text detection framework tailored for the Urdu language. A balanced dataset comprising 1,800 humans authored, and 1,800 AI generated texts, sourced from models such as Gemini, GPT-4o-mini, and Kimi AI was developed. Detailed linguistic and statistical analysis was conducted, focusing on features such as character and word counts, vocabulary richness (Type Token Ratio), and N-gram patterns, with significance evaluated through t-tests and MannWhitney U tests. Three state-of-the-art multilingual transformer models such as mdeberta-v3-base, distilbert-base-multilingualcased, and xlm-roberta-base were fine-tuned on this dataset. The mDeBERTa-v3-base achieved the highest performance, with an F1-score 91.29 and accuracy of 91.26% on the test set. This research advances efforts in contesting misinformation and academic misconduct in Urdu-speaking communities and contributes to the broader development of NLP tools for low resource languages.</li>
</ul>

<h3>Title: Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries</h3>
<ul>
<li><strong>Authors: </strong>Xinfeng Li, Shengyuan Pang, Jialin Wu, Jiangyi Deng, Huanlong Zhong, Yanjiao Chen, Jie Zhang, Wenyuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16581">https://arxiv.org/abs/2510.16581</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16581">https://arxiv.org/pdf/2510.16581</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16581]] Patronus: Safeguarding Text-to-Image Models against White-Box Adversaries(https://arxiv.org/abs/2510.16581)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack</a></li>
<li><strong>Abstract: </strong>Text-to-image (T2I) models, though exhibiting remarkable creativity in image generation, can be exploited to produce unsafe images. Existing safety measures, e.g., content moderation or model alignment, fail in the presence of white-box adversaries who know and can adjust model parameters, e.g., by fine-tuning. This paper presents a novel defensive framework, named Patronus, which equips T2I models with holistic protection to defend against white-box adversaries. Specifically, we design an internal moderator that decodes unsafe input features into zero vectors while ensuring the decoding performance of benign input features. Furthermore, we strengthen the model alignment with a carefully designed non-fine-tunable learning mechanism, ensuring the T2I model will not be compromised by malicious fine-tuning. We conduct extensive experiments to validate the intactness of the performance on safe content generation and the effectiveness of rejecting unsafe content generation. Results also confirm the resilience of Patronus against various fine-tuning attacks by white-box adversaries.</li>
</ul>

<h3>Title: Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration</h3>
<ul>
<li><strong>Authors: </strong>Alan Kai Hassen, Andrius Bernatavicius, Antonius P. A. Janssen, Mike Preuss, Gerard J. P. van Westen, Djork-Arné Clevert</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16590">https://arxiv.org/abs/2510.16590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16590">https://arxiv.org/pdf/2510.16590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16590]] Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration(https://arxiv.org/abs/2510.16590)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Applications of machine learning in chemistry are often limited by the scarcity and expense of labeled data, restricting traditional supervised methods. In this work, we introduce a framework for molecular reasoning using general-purpose Large Language Models (LLMs) that operates without requiring labeled training data. Our method anchors chain-of-thought reasoning to the molecular structure by using unique atomic identifiers. First, the LLM performs a one-shot task to identify relevant fragments and their associated chemical labels or transformation classes. In an optional second step, this position-aware information is used in a few-shot task with provided class examples to predict the chemical transformation. We apply our framework to single-step retrosynthesis, a task where LLMs have previously underperformed. Across academic benchmarks and expert-validated drug discovery molecules, our work enables LLMs to achieve high success rates in identifying chemically plausible reaction sites ($\geq90\%$), named reaction classes ($\geq40\%$), and final reactants ($\geq74\%$). Beyond solving complex chemical tasks, our work also provides a method to generate theoretically grounded synthetic datasets by mapping chemical knowledge onto the molecular structure and thereby addressing data scarcity.</li>
</ul>

<h3>Title: DESTinE Block: Private Blockchain Based Data Storage Framework for Power System</h3>
<ul>
<li><strong>Authors: </strong>Khandaker Akramul Haque, Katherine R. Davis</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16593">https://arxiv.org/abs/2510.16593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16593">https://arxiv.org/pdf/2510.16593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16593]] DESTinE Block: Private Blockchain Based Data Storage Framework for Power System(https://arxiv.org/abs/2510.16593)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security</a></li>
<li><strong>Abstract: </strong>This paper presents DESTinE Block, a blockchain-based data storage framework designed for power systems and optimized for resource-constrained environments, including grid-edge devices such as single-board computers. The proposed architecture leverages the InterPlanetary File System (IPFS) for storing large files while maintaining secure and traceable metadata on a custom blockchain named DESTinE Block. The metadata, comprising the IPFS Content Identifier (CID), uploader identity, administrator verification, and timestamp; is immutably recorded on-chain to ensure authenticity and integrity. DESTinE Block adopts a dual-blockchain abstraction, where the blockchain remains unaware of the IPFS storage layer to enhance security and limit the exposure of sensitive file data. The consensus mechanism is based on Proof of Authority (PoA), where both an administrator and an uploader with distinct cryptographic key pairs are required to create a block collaboratively. Each block contains verified signatures of both parties and is designed to be computationally efficient, enabling deployment on devices like the Raspberry Pi 5. The framework was tested on both an x86-based device and an ARM64-based Raspberry Pi, demonstrating its potential for secure, decentralized logging and measurement storage in smart grid applications. Moreover, DESTinE Block is compared with a similar framework based on Multichain. The results indicate that DESTinE Block provides a promising solution for tamper-evident data retention in distributed power system infrastructure while maintaining minimal hardware requirements.</li>
</ul>

<h3>Title: SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Huang, Liang Shi, Yitian Zhang, Yi Xu, Yun Fu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16596">https://arxiv.org/abs/2510.16596</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16596">https://arxiv.org/pdf/2510.16596</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16596]] SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense(https://arxiv.org/abs/2510.16596)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks. However, object hallucination, where models produce plausible but inaccurate object descriptions, remains a significant challenge. In contrast to previous work focusing on LLM components, this paper is the first to trace LVLM hallucinations to visual encoders and identifies three key issues: statistical bias, inherent bias, and vulnerability. To address these challenges, we propose SHIELD, a training-free framework that mitigates hallucinations through three strategies: re-weighting visual tokens to reduce statistical bias, introducing noise-derived tokens to counter inherent bias, and applying adversarial attacks with contrastive decoding to address vulnerability. Experiments demonstrate that SHIELD effectively mitigates object hallucinations across diverse benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on the general LVLM benchmark, highlighting its broad applicability. Code will be released.</li>
</ul>

<h3>Title: VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jiaying Zhu, Yurui Zhu, Xin Lu, Wenrui Yan, Dong Li, Kunlin Liu, Xueyang Fu, Zheng-Jun Zha</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16598">https://arxiv.org/abs/2510.16598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16598">https://arxiv.org/pdf/2510.16598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16598]] VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs(https://arxiv.org/abs/2510.16598)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) encounter significant computational and memory bottlenecks from the massive number of visual tokens generated by high-resolution images or multi-image inputs. Previous token compression techniques are often constrained by heuristic rules that risk discarding critical information. They may suffer from biases, such as attention sinks, that lead to sharp performance drops under aggressive compression ratios. To address these limitations, we reformulate token compression as a lightweight plug-and-play framework that reformulates token compression into an end-to-end learnable decision process. To be specific, we propose VisionSelector, a scorer module decoupled from the MLLM backbone that incorporates a differentiable Top-K mechanism and a curriculum annealing strategy to bridge the training-inference gap, enabling efficient and adaptive token selection various arbitrary compression rates. Remarkably lightweight with only 12.85M trainable parameters, VisionSelector demonstrates generalization across various compression rates and adaptively identifying critical tokens. This leads to superior performance across all compression budgets, evidenced by preserving 100% accuracy on MME with 30% retention budget, outperforming prior methods by 12.14% at 10% retention budget, and doubling prefill speed. Our code is available at this https URL .</li>
</ul>

<h3>Title: Fine-tuning of Large Language Models for Constituency Parsing Using a Sequence to Sequence Approach</h3>
<ul>
<li><strong>Authors: </strong>Francisco Jose Cortes Delgado, Eduardo Martinez Gracia, Rafael Valencia Garcia</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16604">https://arxiv.org/abs/2510.16604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16604">https://arxiv.org/pdf/2510.16604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16604]] Fine-tuning of Large Language Models for Constituency Parsing Using a Sequence to Sequence Approach(https://arxiv.org/abs/2510.16604)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in natural language processing with large neural models have opened new possibilities for syntactic analysis based on machine learning. This work explores a novel approach to phrase-structure analysis by fine-tuning large language models (LLMs) to translate an input sentence into its corresponding syntactic structure. The main objective is to extend the capabilities of MiSintaxis, a tool designed for teaching Spanish syntax. Several models from the Hugging Face repository were fine-tuned using training data generated from the AnCora-ES corpus, and their performance was evaluated using the F1 score. The results demonstrate high accuracy in phrase-structure analysis and highlight the potential of this methodology.</li>
</ul>

<h3>Title: Structuring Security: A Survey of Cybersecurity Ontologies, Semantic Log Processing, and LLMs Application</h3>
<ul>
<li><strong>Authors: </strong>Bruno Lourenço, Pedro Adão, João F. Ferreira, Mario Monteiro Marques, Cátia Vaz</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16610">https://arxiv.org/abs/2510.16610</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16610">https://arxiv.org/pdf/2510.16610</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16610]] Structuring Security: A Survey of Cybersecurity Ontologies, Semantic Log Processing, and LLMs Application(https://arxiv.org/abs/2510.16610)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, large language model</a></li>
<li><strong>Abstract: </strong>This survey investigates how ontologies, semantic log processing, and Large Language Models (LLMs) enhance cybersecurity. Ontologies structure domain knowledge, enabling interoperability, data integration, and advanced threat analysis. Security logs, though critical, are often unstructured and complex. To address this, automated construction of Knowledge Graphs (KGs) from raw logs is emerging as a key strategy for organizing and reasoning over security data. LLMs enrich this process by providing contextual understanding and extracting insights from unstructured content. This work aligns with European Union (EU) efforts such as NIS 2 and the Cybersecurity Taxonomy, highlighting challenges and opportunities in intelligent ontology-driven cyber defense.</li>
</ul>

<h3>Title: A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications</h3>
<ul>
<li><strong>Authors: </strong>Melika Filvantorkaman, Maral Filvan Torkaman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16611">https://arxiv.org/abs/2510.16611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16611">https://arxiv.org/pdf/2510.16611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16611]] A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications(https://arxiv.org/abs/2510.16611)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Medical imaging plays a vital role in modern diagnostics; however, interpreting high-resolution radiological data remains time-consuming and susceptible to variability among clinicians. Traditional image processing techniques often lack the precision, robustness, and speed required for real-time clinical use. To overcome these limitations, this paper introduces a deep learning framework for real-time medical image analysis designed to enhance diagnostic accuracy and computational efficiency across multiple imaging modalities, including X-ray, CT, and MRI. The proposed system integrates advanced neural network architectures such as U-Net, EfficientNet, and Transformer-based models with real-time optimization strategies including model pruning, quantization, and GPU acceleration. The framework enables flexible deployment on edge devices, local servers, and cloud infrastructures, ensuring seamless interoperability with clinical systems such as PACS and EHR. Experimental evaluations on public benchmark datasets demonstrate state-of-the-art performance, achieving classification accuracies above 92%, segmentation Dice scores exceeding 91%, and inference times below 80 milliseconds. Furthermore, visual explanation tools such as Grad-CAM and segmentation overlays enhance transparency and clinical interpretability. These results indicate that the proposed framework can substantially accelerate diagnostic workflows, reduce clinician workload, and support trustworthy AI integration in time-critical healthcare environments.</li>
</ul>

<h3>Title: Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs</h3>
<ul>
<li><strong>Authors: </strong>Sebastian Mocanu, Emil Slusanschi, Marius Leordeanu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16624">https://arxiv.org/abs/2510.16624</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16624">https://arxiv.org/pdf/2510.16624</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16624]] Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs(https://arxiv.org/abs/2510.16624)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a vision-only autonomous flight system for small UAVs operating in controlled indoor environments. The system combines semantic segmentation with monocular depth estimation to enable obstacle avoidance, scene exploration, and autonomous safe landing operations without requiring GPS or expensive sensors such as LiDAR. A key innovation is an adaptive scale factor algorithm that converts non-metric monocular depth predictions into accurate metric distance measurements by leveraging semantic ground plane detection and camera intrinsic parameters, achieving a mean distance error of 14.4 cm. The approach uses a knowledge distillation framework where a color-based Support Vector Machine (SVM) teacher generates training data for a lightweight U-Net student network (1.6M parameters) capable of real-time semantic segmentation. For more complex environments, the SVM teacher can be replaced with a state-of-the-art segmentation model. Testing was conducted in a controlled 5x4 meter laboratory environment with eight cardboard obstacles simulating urban structures. Extensive validation across 30 flight tests in a real-world environment and 100 flight tests in a digital-twin environment demonstrates that the combined segmentation and depth approach increases the distance traveled during surveillance and reduces mission time while maintaining 100% success rates. The system is further optimized through end-to-end learning, where a compact student neural network learns complete flight policies from demonstration data generated by our best-performing method, achieving an 87.5% autonomous mission success rate. This work advances practical vision-based drone navigation in structured environments, demonstrating solutions for metric depth estimation and computational efficiency challenges that enable deployment on resource-constrained platforms.</li>
</ul>

<h3>Title: A Versatile Framework for Designing Group-Sparse Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Alireza Heshmati, Saman Soleimani Roudi, Sajjad Amini, Shahrokh Ghaemmaghami, Farokh Marvasti</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16637">https://arxiv.org/abs/2510.16637</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16637">https://arxiv.org/pdf/2510.16637</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16637]] A Versatile Framework for Designing Group-Sparse Adversarial Attacks(https://arxiv.org/abs/2510.16637)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust, interpretability</a></li>
<li><strong>Abstract: </strong>Existing adversarial attacks often neglect perturbation sparsity, limiting their ability to model structural changes and to explain how deep neural networks (DNNs) process meaningful input patterns. We propose ATOS (Attack Through Overlapping Sparsity), a differentiable optimization framework that generates structured, sparse adversarial perturbations in element-wise, pixel-wise, and group-wise forms. For white-box attacks on image classifiers, we introduce the Overlapping Smoothed L0 (OSL0) function, which promotes convergence to a stationary point while encouraging sparse, structured perturbations. By grouping channels and adjacent pixels, ATOS improves interpretability and helps identify robust versus non-robust features. We approximate the L-infinity gradient using the logarithm of the sum of exponential absolute values to tightly control perturbation magnitude. On CIFAR-10 and ImageNet, ATOS achieves a 100% attack success rate while producing significantly sparser and more structurally coherent perturbations than prior methods. The structured group-wise attack highlights critical regions from the network's perspective, providing counterfactual explanations by replacing class-defining regions with robust features from the target class.</li>
</ul>

<h3>Title: MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models</h3>
<ul>
<li><strong>Authors: </strong>Young-Jun Lee, Byung-Kwan Lee, Jianshu Zhang, Yechan Hwang, Byungsoo Ko, Han-Gyu Kim, Dongyu Yao, Xuankun Rong, Eojin Joo, Seung-Ho Han, Bowon Ko, Ho-Jin Choi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16641">https://arxiv.org/abs/2510.16641</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16641">https://arxiv.org/pdf/2510.16641</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16641]] MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models(https://arxiv.org/abs/2510.16641)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vision-and-Language Models (VLMs) have shown impressive capabilities on single-turn benchmarks, yet real-world applications often demand more intricate multi-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only partially capture the breadth and depth of conversational scenarios encountered by users. In this work, we introduce MultiVerse, a novel multi-turn conversation benchmark featuring 647 dialogues - each averaging four turns - derived from a diverse set of 12 popular VLM evaluation benchmarks. With 484 tasks and 484 interaction goals, MultiVerse covers a wide range of topics, from factual knowledge and perception to advanced reasoning tasks such as mathematics and coding. To facilitate robust assessment, we propose a checklist-based evaluation method that leverages GPT-4o as the automated evaluator, measuring performance across 37 key aspects, including perceptual accuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on MultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve only a 50% success rate in complex multi-turn conversations, highlighting the dataset's challenging nature. Notably, we find that providing full dialogue context significantly enhances performance for smaller or weaker models, emphasizing the importance of in-context learning. We believe MultiVerse is a landscape of evaluating multi-turn interaction abilities for VLMs.</li>
</ul>

<h3>Title: Structured Interfaces for Automated Reasoning with 3D Scene Graphs</h3>
<ul>
<li><strong>Authors: </strong>Aaron Ray, Jacob Arkin, Harel Biggie, Chuchu Fan, Luca Carlone, Nicholas Roy</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16643">https://arxiv.org/abs/2510.16643</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16643">https://arxiv.org/pdf/2510.16643</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16643]] Structured Interfaces for Automated Reasoning with 3D Scene Graphs(https://arxiv.org/abs/2510.16643)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>In order to provide a robot with the ability to understand and react to a user's natural language inputs, the natural language must be connected to the robot's underlying representations of the world. Recently, large language models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for grounding natural language and representing the world. In this work, we address the challenge of using LLMs with 3DSGs to ground natural language. Existing methods encode the scene graph as serialized text within the LLM's context window, but this encoding does not scale to large or rich 3DSGs. Instead, we propose to use a form of Retrieval Augmented Generation to select a subset of the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide a query language interface (Cypher) as a tool to the LLM with which it can retrieve relevant data for language grounding. We evaluate our approach on instruction following and scene question-answering tasks and compare against baseline context window and code generation methods. Our results show that using Cypher as an interface to 3D scene graphs scales significantly better to large, rich graphs on both local and cloud-based models. This leads to large performance improvements in grounded language tasks while also substantially reducing the token count of the scene graph content. A video supplement is available at this https URL.</li>
</ul>

<h3>Title: Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration</h3>
<ul>
<li><strong>Authors: </strong>Zhixuan He, Yue Feng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16645">https://arxiv.org/abs/2510.16645</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16645">https://arxiv.org/pdf/2510.16645</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16645]] Unleashing Diverse Thinking Modes in LLMs through Multi-Agent Collaboration(https://arxiv.org/abs/2510.16645)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) demonstrate strong performance but often lack interpretable reasoning. This paper introduces the Multi-Agent Collaboration Framework for Diverse Thinking Modes (DiMo), which enhances both performance and interpretability by simulating a structured debate among four specialized LLM agents. Each agent embodies a distinct reasoning paradigm, allowing the framework to collaboratively explore diverse cognitive approaches. Through iterative debate, agents challenge and refine initial responses, yielding more robust conclusions and an explicit, auditable reasoning chain. Across six benchmarks and under a unified open-source setup, DiMo improves accuracy over widely used single-model and debate baselines, with the largest gains on math. We position DiMo as a semantics-aware, Web-native multi-agent framework: it models human-machine intelligence with LLM agents that produce semantically typed, URL-annotated evidence chains for explanations and user-friendly interactions. Although our experiments use standard reasoning benchmarks, the framework is designed to be instantiated over Web corpora and knowledge graphs, combining retrieval-augmented reasoning with structured justifications that downstream systems can inspect and reuse.</li>
</ul>

<h3>Title: Universal and Transferable Attacks on Pathology Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Yuntian Wang, Xilin Yang, Che-Yung Shen, Nir Pillar, Aydogan Ozcan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16660">https://arxiv.org/abs/2510.16660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16660">https://arxiv.org/pdf/2510.16660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16660]] Universal and Transferable Attacks on Pathology Foundation Models(https://arxiv.org/abs/2510.16660)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>We introduce Universal and Transferable Adversarial Perturbations (UTAP) for pathology foundation models that reveal critical vulnerabilities in their capabilities. Optimized using deep learning, UTAP comprises a fixed and weak noise pattern that, when added to a pathology image, systematically disrupts the feature representation capabilities of multiple pathology foundation models. Therefore, UTAP induces performance drops in downstream tasks that utilize foundation models, including misclassification across a wide range of unseen data distributions. In addition to compromising the model performance, we demonstrate two key features of UTAP: (1) universality: its perturbation can be applied across diverse field-of-views independent of the dataset that UTAP was developed on, and (2) transferability: its perturbation can successfully degrade the performance of various external, black-box pathology foundation models - never seen before. These two features indicate that UTAP is not a dedicated attack associated with a specific foundation model or image dataset, but rather constitutes a broad threat to various emerging pathology foundation models and their applications. We systematically evaluated UTAP across various state-of-the-art pathology foundation models on multiple datasets, causing a significant drop in their performance with visually imperceptible modifications to the input images using a fixed noise pattern. The development of these potent attacks establishes a critical, high-standard benchmark for model robustness evaluation, highlighting a need for advancing defense mechanisms and potentially providing the necessary assets for adversarial training to ensure the safe and reliable deployment of AI in pathology.</li>
</ul>

<h3>Title: All You Need is One: Capsule Prompt Tuning with a Single Vector</h3>
<ul>
<li><strong>Authors: </strong>Yiyang Liu, James C. Liang, Heng Fan, Wenhao Yang, Yiming Cui, Xiaotian Han, Lifu Huang, Dongfang Liu, Qifan Wang, Cheng Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16670">https://arxiv.org/abs/2510.16670</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16670">https://arxiv.org/pdf/2510.16670</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16670]] All You Need is One: Capsule Prompt Tuning with a Single Vector(https://arxiv.org/abs/2510.16670)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Prompt-based learning has emerged as a parameter-efficient finetuning (PEFT) approach to facilitate Large Language Model (LLM) adaptation to downstream tasks by conditioning generation with task-aware guidance. Despite its successes, current prompt-based learning methods heavily rely on laborious grid searching for optimal prompt length and typically require considerable number of prompts, introducing additional computational burden. Worse yet, our pioneer findings indicate that the task-aware prompt design is inherently limited by its absence of instance-aware information, leading to a subtle attention interplay with the input sequence. In contrast, simply incorporating instance-aware information as a part of the guidance can enhance the prompt-tuned model performance without additional fine-tuning. Moreover, we find an interesting phenomenon, namely "attention anchor", that incorporating instance-aware tokens at the earliest position of the sequence can successfully preserve strong attention to critical structural information and exhibit more active attention interaction with all input tokens. In light of our observation, we introduce Capsule Prompt-Tuning (CaPT), an efficient and effective solution that leverages off-the-shelf, informative instance semantics into prompt-based learning. Our approach innovatively integrates both instance-aware and task-aware information in a nearly parameter-free manner (i.e., one single capsule prompt). Empirical results demonstrate that our method can exhibit superior performance across various language tasks (e.g., 84.03\% average accuracy on T5-Large), serving as an "attention anchor," while enjoying high parameter efficiency (e.g., 0.003\% of model parameters on Llama3.2-1B).</li>
</ul>

<h3>Title: Evaluating protein binding interfaces with PUMBA</h3>
<ul>
<li><strong>Authors: </strong>Azam Shirali, Giri Narasimhan</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16674">https://arxiv.org/abs/2510.16674</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16674">https://arxiv.org/pdf/2510.16674</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16674]] Evaluating protein binding interfaces with PUMBA(https://arxiv.org/abs/2510.16674)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Protein-protein docking tools help in studying interactions between proteins, and are essential for drug, vaccine, and therapeutic development. However, the accuracy of a docking tool depends on a robust scoring function that can reliably differentiate between native and non-native complexes. PIsToN is a state-of-the-art deep learning-based scoring function that uses Vision Transformers in its architecture. Recently, the Mamba architecture has demonstrated exceptional performance in both natural language processing and computer vision, often outperforming Transformer-based models in their domains. In this study, we introduce PUMBA (Protein-protein interface evaluation with Vision Mamba), which improves PIsToN by replacing its Vision Transformer backbone with Vision Mamba. This change allows us to leverage Mamba's efficient long-range sequence modeling for sequences of image patches. As a result, the model's ability to capture both global and local patterns in protein-protein interface features is significantly improved. Evaluation on several widely-used, large-scale public datasets demonstrates that PUMBA consistently outperforms its original Transformer-based predecessor, PIsToN.</li>
</ul>

<h3>Title: Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory</h3>
<ul>
<li><strong>Authors: </strong>Anindya Sarkar, Binglin Ji, Yevgeniy Vorobeychik</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16676">https://arxiv.org/abs/2510.16676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16676">https://arxiv.org/pdf/2510.16676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16676]] Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory(https://arxiv.org/abs/2510.16676)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>In many scientific and engineering fields, where acquiring high-quality data is expensive--such as medical imaging, environmental monitoring, and remote sensing--strategic sampling of unobserved regions based on prior observations is crucial for maximizing discovery rates within a constrained budget. The rise of powerful generative models, such as diffusion models, has enabled active target discovery in partially observable environments by leveraging learned priors--probabilistic representations that capture underlying structure from data. With guidance from sequentially gathered task-specific observations, these models can progressively refine exploration and efficiently direct queries toward promising regions. However, in domains where learning a strong prior is infeasible due to extremely limited data or high sampling cost (such as rare species discovery, diagnostics for emerging diseases, etc.), these methods struggle to generalize. To overcome this limitation, we propose a novel approach that enables effective active target discovery even in settings with uninformative priors, ensuring robust exploration and adaptability in complex real-world scenarios. Our framework is theoretically principled and draws inspiration from neuroscience to guide its design. Unlike black-box policies, our approach is inherently interpretable, providing clear insights into decision-making. Furthermore, it guarantees a strong, monotonic improvement in prior estimates with each new observation, leading to increasingly accurate sampling and reinforcing both reliability and adaptability in dynamic settings. Through comprehensive experiments and ablation studies across various domains, including species distribution modeling and remote sensing, we demonstrate that our method substantially outperforms baseline approaches.</li>
</ul>

<h3>Title: Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers</h3>
<ul>
<li><strong>Authors: </strong>Ran Tong, Jiaqi Liu, Su Liu, Xin Hu, Lanruo Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16677">https://arxiv.org/abs/2510.16677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16677">https://arxiv.org/pdf/2510.16677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16677]] Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers(https://arxiv.org/abs/2510.16677)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We present a compact, strictly causal benchmark for streaming clinical time series on the MIT--BIH Arrhythmia Database using per-second heart rate. Two tasks are studied under record-level, non-overlapping splits: near-term tachycardia risk (next ten seconds) and one-step heart rate forecasting. We compare a GRU-D (RNN) and a Transformer under matched training budgets against strong non-learned baselines. Evaluation is calibration-aware for classification and proper for forecasting, with temperature scaling and grouped bootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the Transformer for tachycardia risk, while the Transformer clearly lowers forecasting error relative to GRU-D and persistence. Our results show that, in longitudinal monitoring, model choice is task-dependent: compact RNNs remain competitive for short-horizon risk scoring, whereas compact Transformers deliver clearer gains for point forecasting.</li>
</ul>

<h3>Title: Temporal Understanding under Deictic Frame of Reference</h3>
<ul>
<li><strong>Authors: </strong>Damin Zhang, Julia Rayz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16685">https://arxiv.org/abs/2510.16685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16685">https://arxiv.org/pdf/2510.16685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16685]] Temporal Understanding under Deictic Frame of Reference(https://arxiv.org/abs/2510.16685)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Understanding time is fundamental to human cognition, where temporal experience is often conceptualized through spatial metaphors grounded in sensory-motor experience. For example, "summer is approaching" parallels "We are approaching the summer". In such expressions, humans rely on a frame of reference (FoR) to interpret meaning relative to a particular viewpoint. Extending this concept to time, a temporal frame of reference (t-FoR) defines how temporal relations are perceived relative to an experiencer's moment of "now". While Large Language Models (LLMs) have shown remarkable advances in natural language understanding, their ability to interpret and reason about time remains limited. In this work, we introduce TUuD (Temporal Understanding under Deictic t-FoR), a framework that evaluates how LLMs interpret time-event and event-event relations when the reference point of "now" dynamically shifts along a timeline. Following recent work on temporal cognition \cite{li2025other}, LLMs are prompted to rate the similarity between the current moment and a target event from 0.00 (completely dissimilar) to 1.00 (highly similar), where similarity quantifies perceived temporal alignment between the two points. Our results show that four evaluated LLMs exhibit measurable adaptation to a deictic t-FoR, with similarity ratings peaking around the present and decreasing toward past and future events. The adaptation, however, weakens beyond near-term contexts, suggesting that while LLMs display partial human-like temporal cognition, their temporal reasoning remains sensitive to reference-frame shifts and temporal distance.</li>
</ul>

<h3>Title: Investigating the Impact of Rationales for LLMs on Natural Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Wenhang Shi, Shuqing Bian, Yiren Chen, Xinyi Zhang, Zhe Zhao, Pengfei Hu, Wei Lu, Xiaoyong Du</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16686">https://arxiv.org/abs/2510.16686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16686">https://arxiv.org/pdf/2510.16686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16686]] Investigating the Impact of Rationales for LLMs on Natural Language Understanding(https://arxiv.org/abs/2510.16686)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Chain-of-thought (CoT) rationales, which provide step-by-step reasoning to derive final answers, benefit LLMs in both inference and training. Incorporating rationales, either by generating them before answering during inference, or by placing them before or after the original answers during training - significantly improves model performance on mathematical, symbolic and commonsense reasoning tasks. However, most work focuses on the role of rationales in these reasoning tasks, overlooking their potential impact on other important tasks like natural language understanding (NLU) tasks. In this work, we raise the question: Can rationales similarly benefit NLU tasks? To conduct a systematic exploration, we construct NLURC, a comprehensive and high-quality NLU dataset collection with rationales, and develop various rationale-augmented methods. Through exploring the applicability of these methods on NLU tasks using the dataset, we uncover several potentially surprising findings: (1) CoT inference shifts from hindering NLU performance to surpassing direct label prediction as model size grows, indicating a positive correlation. (2) Most rationale-augmented training methods perform worse than label-only training, with one specially designed method consistently achieving improvements. (3) LLMs trained with rationales achieve significant performance gains on unseen NLU tasks, rivaling models ten times their size, while delivering interpretability on par with commercial LLMs.</li>
</ul>

<h3>Title: High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares</h3>
<ul>
<li><strong>Authors: </strong>Shurong Lin, Eric D. Kolaczyk, Adam Smith, Elliot Paquette</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16687">https://arxiv.org/abs/2510.16687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16687">https://arxiv.org/pdf/2510.16687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16687]] High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares(https://arxiv.org/abs/2510.16687)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, diffusion</a></li>
<li><strong>Abstract: </strong>The interplay between optimization and privacy has become a central theme in privacy-preserving machine learning. Noisy stochastic gradient descent (SGD) has emerged as a cornerstone algorithm, particularly in large-scale settings. These variants of gradient methods inject carefully calibrated noise into each update to achieve differential privacy, the gold standard notion of rigorous privacy guarantees. Prior work primarily provides various bounds on statistical risk and privacy loss for noisy SGD, yet the \textit{exact} behavior of the process remains unclear, particularly in high-dimensional settings. This work leverages a diffusion approach to analyze noisy SGD precisely, providing a continuous-time perspective that captures both statistical risk evolution and privacy loss dynamics in high dimensions. Moreover, we study a variant of noisy SGD that does not require explicit knowledge of gradient sensitivity, unlike existing work that assumes or enforces sensitivity through gradient clipping. Specifically, we focus on the least squares problem with $\ell_2$ regularization.</li>
</ul>

<h3>Title: Pursuing Minimal Sufficiency in Spatial Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yejie Guo, Yunzhong Hou, Wufei Ma, Meng Tang, Ming-Hsuan Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16688">https://arxiv.org/abs/2510.16688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16688">https://arxiv.org/pdf/2510.16688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16688]] Pursuing Minimal Sufficiency in Spatial Reasoning(https://arxiv.org/abs/2510.16688)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Spatial reasoning, the ability to ground language in 3D understanding, remains a persistent challenge for Vision-Language Models (VLMs). We identify two fundamental bottlenecks: inadequate 3D understanding capabilities stemming from 2D-centric pre-training, and reasoning failures induced by redundant 3D information. To address these, we first construct a Minimal Sufficient Set (MSS) of information before answering a given question: a compact selection of 3D perception results from \textit{expert models}. We introduce MSSR (Minimal Sufficient Spatial Reasoner), a dual-agent framework that implements this principle. A Perception Agent programmatically queries 3D scenes using a versatile perception toolbox to extract sufficient information, including a novel SOG (Situated Orientation Grounding) module that robustly extracts language-grounded directions. A Reasoning Agent then iteratively refines this information to pursue minimality, pruning redundant details and requesting missing ones in a closed loop until the MSS is curated. Extensive experiments demonstrate that our method, by explicitly pursuing both sufficiency and minimality, significantly improves accuracy and achieves state-of-the-art performance across two challenging benchmarks. Furthermore, our framework produces interpretable reasoning paths, offering a promising source of high-quality training data for future models. Source code is available at this https URL.</li>
</ul>

<h3>Title: CLIP: Client-Side Invariant Pruning for Mitigating Stragglers in Secure Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Anthony DiMaggio, Raghav Sharma, Gururaj Saileshwar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16694">https://arxiv.org/abs/2510.16694</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16694">https://arxiv.org/pdf/2510.16694</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16694]] CLIP: Client-Side Invariant Pruning for Mitigating Stragglers in Secure Federated Learning(https://arxiv.org/abs/2510.16694)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, federate</a></li>
<li><strong>Abstract: </strong>Secure federated learning (FL) preserves data privacy during distributed model training. However, deploying such frameworks across heterogeneous devices results in performance bottlenecks, due to straggler clients with limited computational or network capabilities, slowing training for all participating clients. This paper introduces the first straggler mitigation technique for secure aggregation with deep neural networks. We propose CLIP, a client-side invariant neuron pruning technique coupled with network-aware pruning, that addresses compute and network bottlenecks due to stragglers during training with minimal accuracy loss. Our technique accelerates secure FL training by 13% to 34% across multiple datasets (CIFAR10, Shakespeare, FEMNIST) with an accuracy impact of between 1.3% improvement to 2.6% reduction.</li>
</ul>

<h3>Title: Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization</h3>
<ul>
<li><strong>Authors: </strong>Tianxin Wei, Yifan Chen, Xinrui He, Wenxuan Bao, Jingrui He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16704">https://arxiv.org/abs/2510.16704</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16704">https://arxiv.org/pdf/2510.16704</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16704]] Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization(https://arxiv.org/abs/2510.16704)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Distribution shifts between training and testing samples frequently occur in practice and impede model generalization performance. This crucial challenge thereby motivates studies on domain generalization (DG), which aim to predict the label on unseen target domain data by solely using data from source domains. It is intuitive to conceive the class-separated representations learned in contrastive learning (CL) are able to improve DG, while the reality is quite the opposite: users observe directly applying CL deteriorates the performance. We analyze the phenomenon with the insights from CL theory and discover lack of intra-class connectivity in the DG setting causes the deficiency. We thus propose a new paradigm, domain-connecting contrastive learning (DCCL), to enhance the conceptual connectivity across domains and obtain generalizable representations for DG. On the data side, more aggressive data augmentation and cross-domain positive samples are introduced to improve intra-class connectivity. On the model side, to better embed the unseen test domains, we propose model anchoring to exploit the intra-class connectivity in pre-trained representations and complement the anchoring with generative transformation loss. Extensive experiments on five standard DG benchmarks are performed. The results verify that DCCL outperforms state-of-the-art baselines even without domain supervision. The detailed model implementation and the code are provided through this https URL</li>
</ul>

<h3>Title: Rotation, Scale, and Translation Resilient Black-box Fingerprinting for Intellectual Property Protection of EaaS Models</h3>
<ul>
<li><strong>Authors: </strong>Hongjie Zhang, Zhiqi Zhao, Hanzhou Wu, Zhihua Xia, Athanasios V. Vasilakos</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16706">https://arxiv.org/abs/2510.16706</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16706">https://arxiv.org/pdf/2510.16706</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16706]] Rotation, Scale, and Translation Resilient Black-box Fingerprinting for Intellectual Property Protection of EaaS Models(https://arxiv.org/abs/2510.16706)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, attack, robust, watermark</a></li>
<li><strong>Abstract: </strong>Feature embedding has become a cornerstone technology for processing high-dimensional and complex data, which results in that Embedding as a Service (EaaS) models have been widely deployed in the cloud. To protect the intellectual property of EaaS models, existing methods apply digital watermarking to inject specific backdoor triggers into EaaS models by modifying training samples or network parameters. However, these methods inevitably produce detectable patterns through semantic analysis and exhibit susceptibility to geometric transformations including rotation, scaling, and translation (RST). To address this problem, we propose a fingerprinting framework for EaaS models, rather than merely refining existing watermarking techniques. Different from watermarking techniques, the proposed method establishes EaaS model ownership through geometric analysis of embedding space's topological structure, rather than relying on the modified training samples or triggers. The key innovation lies in modeling the victim and suspicious embeddings as point clouds, allowing us to perform robust spatial alignment and similarity measurement, which inherently resists RST attacks. Experimental results evaluated on visual and textual embedding tasks verify the superiority and applicability. This research reveals inherent characteristics of EaaS models and provides a promising solution for ownership verification of EaaS models under the black-box scenario.</li>
</ul>

<h3>Title: HumanCM: One Step Human Motion Prediction</h3>
<ul>
<li><strong>Authors: </strong>Liu Haojie, Gao Suixiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16709">https://arxiv.org/abs/2510.16709</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16709">https://arxiv.org/pdf/2510.16709</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16709]] HumanCM: One Step Human Motion Prediction(https://arxiv.org/abs/2510.16709)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We present HumanCM, a one-step human motion prediction framework built upon consistency models. Instead of relying on multi-step denoising as in diffusion-based methods, HumanCM performs efficient single-step generation by learning a self-consistent mapping between noisy and clean motion states. The framework adopts a Transformer-based spatiotemporal architecture with temporal embeddings to model long-range dependencies and preserve motion coherence. Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves comparable or superior accuracy to state-of-the-art diffusion models while reducing inference steps by up to two orders of magnitude.</li>
</ul>

<h3>Title: The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models</h3>
<ul>
<li><strong>Authors: </strong>Shivam Ratnakar, Sanjay Raghavendra</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16712">https://arxiv.org/abs/2510.16712</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16712">https://arxiv.org/pdf/2510.16712</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16712]] The Chameleon Nature of LLMs: Quantifying Multi-Turn Stance Instability in Search-Enabled Language Models(https://arxiv.org/abs/2510.16712)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Integration of Large Language Models with search/retrieval engines has become ubiquitous, yet these systems harbor a critical vulnerability that undermines their reliability. We present the first systematic investigation of "chameleon behavior" in LLMs: their alarming tendency to shift stances when presented with contradictory questions in multi-turn conversations (especially in search-enabled LLMs). Through our novel Chameleon Benchmark Dataset, comprising 17,770 carefully crafted question-answer pairs across 1,180 multi-turn conversations spanning 12 controversial domains, we expose fundamental flaws in state-of-the-art systems. We introduce two theoretically grounded metrics: the Chameleon Score (0-1) that quantifies stance instability, and Source Re-use Rate (0-1) that measures knowledge diversity. Our rigorous evaluation of Llama-4-Maverick, GPT-4o-mini, and Gemini-2.5-Flash reveals consistent failures: all models exhibit severe chameleon behavior (scores 0.391-0.511), with GPT-4o-mini showing the worst performance. Crucially, small across-temperature variance (less than 0.004) suggests the effect is not a sampling artifact. Our analysis uncovers the mechanism: strong correlations between source re-use rate and confidence (r=0.627) and stance changes (r=0.429) are statistically significant (p less than 0.05), indicating that limited knowledge diversity makes models pathologically deferential to query framing. These findings highlight the need for comprehensive consistency evaluation before deploying LLMs in healthcare, legal, and financial systems where maintaining coherent positions across interactions is critical for reliable decision support.</li>
</ul>

<h3>Title: so much depends / upon / a whitespace: Why Whitespace Matters for Poets and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sriharsh Bhyravajjula, Melanie Walsh, Anna Preus, Maria Antoniak</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16713">https://arxiv.org/abs/2510.16713</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16713">https://arxiv.org/pdf/2510.16713</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16713]] so much depends / upon / a whitespace: Why Whitespace Matters for Poets and LLMs(https://arxiv.org/abs/2510.16713)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Whitespace is a critical component of poetic form, reflecting both adherence to standardized forms and rebellion against those forms. Each poem's whitespace distribution reflects the artistic choices of the poet and is an integral semantic and spatial feature of the poem. Yet, despite the popularity of poetry as both a long-standing art form and as a generation task for large language models (LLMs), whitespace has not received sufficient attention from the NLP community. Using a corpus of 19k English-language published poems from Poetry Foundation, we investigate how 4k poets have used whitespace in their works. We release a subset of 2.8k public-domain poems with preserved formatting to facilitate further research in this area. We compare whitespace usage in the published poems to (1) 51k LLM-generated poems, and (2) 12k unpublished poems posted in an online community. We also explore whitespace usage across time periods, poetic forms, and data sources. Additionally, we find that different text processing methods can result in significantly different representations of whitespace in poetry data, motivating us to use these poems and whitespace patterns to discuss implications for the processing strategies used to assemble pretraining datasets for LLMs.</li>
</ul>

<h3>Title: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes</h3>
<ul>
<li><strong>Authors: </strong>Xiongkun Linghu, Jiangyong Huang, Ziyu Zhu, Baoxiong Jia, Siyuan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16714">https://arxiv.org/abs/2510.16714</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16714">https://arxiv.org/pdf/2510.16714</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16714]] Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes(https://arxiv.org/abs/2510.16714)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Existing research on 3D Large Language Models (LLMs) still struggles to achieve grounded question-answering, primarily due to the under-exploration of the mech- anism of human-like scene-object grounded reasoning. This paper bridges the gap by presenting a novel framework. We first introduce a grounded Chain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a complex reasoning task into simpler and manageable problems, and building corresponding visual clues based on multimodal expert modules. To enable such a method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning dataset, consisting of 185K high-quality instances. Extensive experiments across various complex 3D scene reasoning benchmarks demonstrate that our new framework achieves strong performance with high grounding-QA coherence. To the best of our knowledge, this is the first successful application of CoT reasoning to 3D scene understanding, enabling step-by-step human-like reasoning and showing potential for extension to broader 3D scene understanding scenarios.</li>
</ul>

<h3>Title: DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge</h3>
<ul>
<li><strong>Authors: </strong>Asmita Mohanty, Gezheng Kang, Lei Gao, Murali Annavaram</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16716">https://arxiv.org/abs/2510.16716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16716">https://arxiv.org/pdf/2510.16716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16716]] DistilLock: Safeguarding LLMs from Unauthorized Knowledge Distillation on the Edge(https://arxiv.org/abs/2510.16716)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated strong performance across diverse tasks, but fine-tuning them typically relies on cloud-based, centralized infrastructures. This requires data owners to upload potentially sensitive data to external servers, raising serious privacy concerns. An alternative approach is to fine-tune LLMs directly on edge devices using local data; however, this introduces a new challenge: the model owner must transfer proprietary models to the edge, which risks intellectual property (IP) leakage. To address this dilemma, we propose DistilLock, a TEE-assisted fine-tuning framework that enables privacy-preserving knowledge distillation on the edge. In DistilLock, a proprietary foundation model is executed within a trusted execution environment (TEE) enclave on the data owner's device, acting as a secure black-box teacher. This setup preserves both data privacy and model IP by preventing direct access to model internals. Furthermore, DistilLock employs a model obfuscation mechanism to offload obfuscated weights to untrusted accelerators for efficient knowledge distillation without compromising security. We demonstrate that DistilLock prevents unauthorized knowledge distillation processes and model-stealing attacks while maintaining high computational efficiency, but offering a secure and practical solution for edge-based LLM personalization.</li>
</ul>

<h3>Title: LSTM-Based Forecasting and Analysis of EV Charging Demand in a Dense Urban Campus</h3>
<ul>
<li><strong>Authors: </strong>Zak Ressler, Marcus Grijalva, Angelica Marie Ignacio, Melanie Torres, Abelardo Cuadra Rojas, Rohollah Moghadam, Mohammad Rasoul narimani</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16719">https://arxiv.org/abs/2510.16719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16719">https://arxiv.org/pdf/2510.16719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16719]] LSTM-Based Forecasting and Analysis of EV Charging Demand in a Dense Urban Campus(https://arxiv.org/abs/2510.16719)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper presents a framework for processing EV charging load data in order to forecast future load predictions using a Recurrent Neural Network, specifically an LSTM. The framework processes a large set of raw data from multiple locations and transforms it with normalization and feature extraction to train the LSTM. The pre-processing stage corrects for missing or incomplete values by interpolating and normalizing the measurements. This information is then fed into a Long Short-Term Memory Model designed to capture the short-term fluctuations while also interpreting the long-term trends in the charging data. Experimental results demonstrate the model's ability to accurately predict charging demand across multiple time scales (daily, weekly, and monthly), providing valuable insights for infrastructure planning, energy management, and grid integration of EV charging facilities. The system's modular design allows for adaptation to different charging locations with varying usage patterns, making it applicable across diverse deployment scenarios.</li>
</ul>

<h3>Title: Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Sanskar Pandey, Ruhaan Chopra, Angkul Puniya, Sohom Pal</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16727">https://arxiv.org/abs/2510.16727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16727">https://arxiv.org/pdf/2510.16727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16727]] Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy in Large Language Models(https://arxiv.org/abs/2510.16727)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Large language models internalize a structural trade-off between truthfulness and obsequious flattery, emerging from reward optimization that conflates helpfulness with polite submission. This latent bias, known as sycophancy, manifests as a preference for user agreement over principled reasoning. We introduce Beacon, a single-turn forced-choice benchmark that isolates this bias independent of conversational context, enabling precise measurement of the tension between factual accuracy and submissive bias. Evaluations across twelve state-of-the-art models reveal that sycophancy decomposes into stable linguistic and affective sub-biases, each scaling with model capacity. We further propose prompt-level and activation-level interventions that modulate these biases in opposing directions, exposing the internal geometry of alignment as a dynamic manifold between truthfulness and socially compliant judgment. Beacon reframes sycophancy as a measurable form of normative misgeneralization, providing a reproducible foundation for studying and mitigating alignment drift in large-scale generative systems.</li>
</ul>

<h3>Title: Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models</h3>
<ul>
<li><strong>Authors: </strong>Jianbiao Mei, Yu Yang, Xuemeng Yang, Licheng Wen, Jiajun Lv, Botian Shi, Yong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16729">https://arxiv.org/abs/2510.16729</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16729">https://arxiv.org/pdf/2510.16729</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16729]] Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models(https://arxiv.org/abs/2510.16729)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>End-to-end autonomous driving systems increasingly rely on vision-centric world models to understand and predict their environment. However, a common ineffectiveness in these models is the full reconstruction of future scenes, which expends significant capacity on redundantly modeling static backgrounds. To address this, we propose IR-WM, an Implicit Residual World Model that focuses on modeling the current state and evolution of the world. IR-WM first establishes a robust bird's-eye-view representation of the current state from the visual observation. It then leverages the BEV features from the previous timestep as a strong temporal prior and predicts only the "residual", i.e., the changes conditioned on the ego-vehicle's actions and scene context. To alleviate error accumulation over time, we further apply an alignment module to calibrate semantic and dynamic misalignments. Moreover, we investigate different forecasting-planning coupling schemes and demonstrate that the implicit future state generated by world models substantially improves planning accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D occupancy forecasting and trajectory planning.</li>
</ul>

<h3>Title: UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid</h3>
<ul>
<li><strong>Authors: </strong>Tianyang Dou, Ming Li, Jiangying Qin, Xuan Liao, Jiageng Zhong, Armin Gruen, Mengyi Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16730">https://arxiv.org/abs/2510.16730</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16730">https://arxiv.org/pdf/2510.16730</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16730]] UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid(https://arxiv.org/abs/2510.16730)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Coral reefs are vital yet fragile ecosystems that require accurate large-scale mapping for effective conservation. Although global products such as the Allen Coral Atlas provide unprecedented coverage of global coral reef distri-bution, their predictions are frequently limited in spatial precision and semantic consistency, especially in regions requiring fine-grained boundary delineation. To address these challenges, we propose UKANFormer, a novel se-mantic segmentation model designed to achieve high-precision mapping under noisy supervision derived from Allen Coral Atlas. Building upon the UKAN architecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans) block in the decoder, enabling the extraction of both global semantic structures and local boundary details. In experiments, UKANFormer achieved a coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming conventional baselines under the same noisy labels setting. Remarkably, the model produces predictions that are visually and structurally more accurate than the noisy labels used for training. These results challenge the notion that data quality directly limits model performance, showing that architectural design can mitigate label noise and sup-port scalable mapping under imperfect supervision. UKANFormer provides a foundation for ecological monitoring where reliable labels are scarce.</li>
</ul>

<h3>Title: Zero-Shot Performance Prediction for Probabilistic Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Viktoria Schram, Markus Hiller, Daniel Beck, Trevor Cohn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16743">https://arxiv.org/abs/2510.16743</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16743">https://arxiv.org/pdf/2510.16743</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16743]] Zero-Shot Performance Prediction for Probabilistic Scaling Laws(https://arxiv.org/abs/2510.16743)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The prediction of learning curves for Natural Language Processing (NLP) models enables informed decision-making to meet specific performance objectives, while reducing computational overhead and lowering the costs associated with dataset acquisition and curation. In this work, we formulate the prediction task as a multitask learning problem, where each task's data is modelled as being organized within a two-layer hierarchy. To model the shared information and dependencies across tasks and hierarchical levels, we employ latent variable multi-output Gaussian Processes, enabling to account for task correlations and supporting zero-shot prediction of learning curves (LCs). We demonstrate that this approach facilitates the development of probabilistic scaling laws at lower costs. Applying an active learning strategy, LCs can be queried to reduce predictive uncertainty and provide predictions close to ground truth scaling laws. We validate our framework on three small-scale NLP datasets with up to $30$ LCs. These are obtained from nanoGPT models, from bilingual translation using mBART and Transformer models, and from multilingual translation using M2M100 models of varying sizes.</li>
</ul>

<h3>Title: Cryptanalysis of a Privacy-Preserving Ride-Hailing Service from NSS 2022</h3>
<ul>
<li><strong>Authors: </strong>Srinivas Vivek</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16744">https://arxiv.org/abs/2510.16744</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16744">https://arxiv.org/pdf/2510.16744</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16744]] Cryptanalysis of a Privacy-Preserving Ride-Hailing Service from NSS 2022(https://arxiv.org/abs/2510.16744)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, privacy, attack</a></li>
<li><strong>Abstract: </strong>Ride-Hailing Services (RHS) match a ride request initiated by a rider with a suitable driver responding to the ride request. A Privacy-Preserving RHS (PP-RHS) aims to facilitate ride matching while ensuring the privacy of riders' and drivers' location data w.r.t. the Service Provider (SP). At NSS 2022, Xie et al. proposed a PP-RHS. In this work, we demonstrate a passive attack on their PP-RHS protocol. Our attack allows the SP to completely recover the locations of the rider as well as that of the responding drivers in every ride request. Further, our attack is very efficient as it is independent of the security parameter.</li>
</ul>

<h3>Title: An Efficient Semantic Segmentation Decoder for In-Car or Distributed Applications</h3>
<ul>
<li><strong>Authors: </strong>Danish Nazir, Gowtham Sai Inti, Timo Bartels, Jan Piewek, Thorsten Bagdonat, Tim Fingscheidt</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16747">https://arxiv.org/abs/2510.16747</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16747">https://arxiv.org/pdf/2510.16747</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16747]] An Efficient Semantic Segmentation Decoder for In-Car or Distributed Applications(https://arxiv.org/abs/2510.16747)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Modern automotive systems leverage deep neural networks (DNNs) for semantic segmentation and operate in two key application areas: (1) In-car, where the DNN solely operates in the vehicle without strict constraints on the data rate. (2) Distributed, where one DNN part operates in the vehicle and the other part typically on a large-scale cloud platform with a particular constraint on transmission bitrate efficiency. Typically, both applications share an image and source encoder, while each uses distinct (joint) source and task decoders. Prior work utilized convolutional neural networks for joint source and task decoding but did not investigate transformer-based alternatives such as SegDeformer, which offer superior performance at the cost of higher computational complexity. In this work, we propose joint feature and task decoding for SegDeformer, thereby enabling lower computational complexity in both in-car and distributed applications, despite SegDeformer's computational demands. This improves scalability in the cloud while reducing in-car computational complexity. For the in-car application, we increased the frames per second (fps) by up to a factor of $11.7$ ($1.4$ fps to $16.5$ fps) on Cityscapes and by up to a factor of $3.5$ ($43.3$ fps to $154.3$ fps) on ADE20K, while being on-par w.r.t.\ the mean intersection over union (mIoU) of the transformer-based baseline that doesn't compress by a source codec. For the distributed application, we achieve state-of-the-art (SOTA) over a wide range of bitrates on the mIoU metric, while using only $0.14$\% ($0.04$\%) of cloud DNN parameters used in previous SOTA, reported on ADE20K (Cityscapes).</li>
</ul>

<h3>Title: Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling</h3>
<ul>
<li><strong>Authors: </strong>Erik Riise, Mehmet Onurcan Kaya, Dim P. Papadopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16751">https://arxiv.org/abs/2510.16751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16751">https://arxiv.org/pdf/2510.16751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16751]] Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling(https://arxiv.org/abs/2510.16751)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>While inference-time scaling through search has revolutionized Large Language Models, translating these gains to image generation has proven difficult. Recent attempts to apply search strategies to continuous diffusion models show limited benefits, with simple random sampling often performing best. We demonstrate that the discrete, sequential nature of visual autoregressive models enables effective search for image generation. We show that beam search substantially improves text-to-image generation, enabling a 2B parameter autoregressive model to outperform a 12B parameter diffusion model across benchmarks. Systematic ablations show that this advantage comes from the discrete token space, which allows early pruning and computational reuse, and our verifier analysis highlights trade-offs between speed and reasoning capability. These findings suggest that model architecture, not just scale, is critical for inference-time optimization in visual generation.</li>
</ul>

<h3>Title: Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Ivan Molodetskikh, Kirill Malyshev, Mark Mirgaleev, Nikita Zagainov, Evgeney Bogatyrev, Dmitriy Vatolin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16752">https://arxiv.org/abs/2510.16752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16752">https://arxiv.org/pdf/2510.16752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16752]] Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution(https://arxiv.org/abs/2510.16752)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative image super-resolution (SR) is rapidly advancing in visual quality and detail restoration. As the capacity of SR models expands, however, so does their tendency to produce artifacts: incorrect, visually disturbing details that reduce perceived quality. Crucially, their perceptual impact varies: some artifacts are barely noticeable while others strongly degrade the image. We argue that artifacts should be characterized by their prominence to human observers rather than treated as uniform binary defects. Motivated by this, we present a novel dataset of 1302 artifact examples from 11 contemporary image-SR methods, where each artifact is paired with a crowdsourced prominence score. Building on this dataset, we train a lightweight regressor that produces spatial prominence heatmaps and outperforms existing methods at detecting prominent artifacts. We release the dataset and code to facilitate prominence-aware evaluation and mitigation of SR artifacts.</li>
</ul>

<h3>Title: EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Mingzheng Zhang, Jinfeng Gao, Dan Xu, Jiangrui Yu, Yuhan Qiao, Lan Chen, Jin Tang, Xiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16776">https://arxiv.org/abs/2510.16776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16776">https://arxiv.org/pdf/2510.16776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16776]] EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation(https://arxiv.org/abs/2510.16776)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, large language model</a></li>
<li><strong>Abstract: </strong>X-ray image-based medical report generation (MRG) is a pivotal area in artificial intelligence that can significantly reduce diagnostic burdens for clinicians and patient wait times. Existing MRG models predominantly rely on Large Language Models (LLMs) to improve report generation, with limited exploration of pre-trained vision foundation models or advanced fine-tuning techniques. Mainstream frameworks either avoid fine-tuning or utilize simplistic methods like LoRA, often neglecting the potential of enhancing cross-attention mechanisms. Additionally, while Transformer-based models dominate vision-language tasks, non-Transformer architectures, such as the Mamba network, remain underexplored for medical report generation, presenting a promising avenue for future research. In this paper, we propose EMRRG, a novel X-ray report generation framework that fine-tunes pre-trained Mamba networks using parameter-efficient methods. Specifically, X-ray images are divided into patches, tokenized, and processed by an SSM-based vision backbone for feature extraction, with Partial LoRA yielding optimal performance. An LLM with a hybrid decoder generates the medical report, enabling end-to-end training and achieving strong results on benchmark datasets. Extensive experiments on three widely used benchmark datasets fully validated the effectiveness of our proposed strategies for the X-ray MRG. The source code of this paper will be released on this https URL.</li>
</ul>

<h3>Title: 3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding</h3>
<ul>
<li><strong>Authors: </strong>Chang Wu, Zhiyuan Liu, Wen Shu, Liang Wang, Yanchen Luo, Wenqiang Lei, Yatao Bian, Junfeng Fang, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16780">https://arxiv.org/abs/2510.16780</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16780">https://arxiv.org/pdf/2510.16780</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16780]] 3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding(https://arxiv.org/abs/2510.16780)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Masked graph modeling (MGM) is a promising approach for molecular representation learning (MRL).However, extending the success of re-mask decoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting challenges: avoiding 2D structure leakage to the decoder, while still providing sufficient 2D context for reconstructing re-masked this http URL address these challenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding. The core innovation of 3D-GSRD lies in its Selective Re-mask Decoding(SRD), which re-masks only 3D-relevant information from encoder representations while preserving the 2D graph this http URL SRD is synergistically integrated with a 3D Relational-Transformer(3D-ReTrans) encoder alongside a structure-independent decoder. We analyze that SRD, combined with the structure-independent decoder, enhances the encoder's role in MRL. Extensive experiments show that 3D-GSRD achieves strong downstream performance, setting a new state-of-the-art on 7 out of 8 targets in the widely used MD17 molecular property prediction benchmark. The code is released at this https URL.</li>
</ul>

<h3>Title: Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features</h3>
<ul>
<li><strong>Authors: </strong>Shihao Ji, Zihui Song</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16781">https://arxiv.org/abs/2510.16781</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16781">https://arxiv.org/pdf/2510.16781</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16781]] Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features(https://arxiv.org/abs/2510.16781)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, segmentation</a></li>
<li><strong>Abstract: </strong>The remarkable zero-shot reasoning capabilities of large-scale Visual Language Models (VLMs) on static images have yet to be fully translated to the video domain. Conventional video understanding models often rely on extensive, task-specific training on annotated datasets, a process that is both costly and limited in scalability. This paper introduces a novel, training-free framework for video understanding that circumvents end-to-end training by synergistically combining the rich semantic priors of pre-trained VLMs with classic machine learning algorithms for pattern discovery. Our core idea is to reframe video understanding as a self-supervised spatio-temporal clustering problem within a high-dimensional semantic feature space. The proposed pipeline first transforms a video stream into a semantic feature trajectory using the frozen visual encoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal Segmentation (KTS), a robust machine learning technique, to partition the continuous feature stream into discrete, semantically coherent event segments. These segments are then subjected to unsupervised density-based clustering to identify recurring macroscopic scenes and themes throughout the video. By selecting representative keyframes from each discovered cluster and leveraging the VLM's generative capabilities for textual description, our framework automatically produces a structured, multi-modal summary of the video content. This approach provides an effective, interpretable, and model-agnostic pathway for zero-shot, automated structural analysis of video content.</li>
</ul>

<h3>Title: LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding</h3>
<ul>
<li><strong>Authors: </strong>Sheikh Jubair, Arwa Omayrah, Amal Alshammari, Alhanoof Althnian, Abdulhamed Alothaimen, Norah A. Alzahrani, Shahad D. Alzaidi, Nora Al-Twairesh, Abdulmohsen Al-Thubaity</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16783">https://arxiv.org/abs/2510.16783</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16783">https://arxiv.org/pdf/2510.16783</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16783]] LC-Eval: A Bilingual Multi-Task Evaluation Benchmark for Long-Context Understanding(https://arxiv.org/abs/2510.16783)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Models (LLMs) have demonstrated sophisticated capabilities, including the ability to process and comprehend extended contexts. These emergent capabilities necessitate rigorous evaluation methods to effectively assess their performance in long-context understanding. In this paper, we present \textbf{LC-Eval}, a bilingual, multi-task evaluation benchmark designed to evaluate long-context understanding in English and Arabic, targeting context lengths ranging from 4k to over 128k tokens. LC-Eval introduces four novel and challenging tasks: multi-document question answering, bilingual question answering, claim verification within a paragraph, and multiple-choice questions based on long contexts. These tasks are designed to assess LLMs' abilities in deep reasoning, document comprehension, information tracing, and bilingual information extraction and understanding. The benchmark includes datasets in both Arabic and English for each task, allowing for a comparative analysis of their performance across different text genres. Evaluations were conducted on both open-weight and closed LLMs, with results indicating that LC-Eval presents significant challenges. Even high-performing models, such as GPT-4o, struggled with certain tasks, highlighting the complexity and rigor of the benchmark.</li>
</ul>

<h3>Title: Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jiazhen Liu, Long Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16785">https://arxiv.org/abs/2510.16785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16785">https://arxiv.org/pdf/2510.16785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16785]] Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs(https://arxiv.org/abs/2510.16785)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model, segmentation</a></li>
<li><strong>Abstract: </strong>Integrating diverse visual capabilities into a unified model is a significant trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion of segmentation poses a distinct set of challenges. To equip MLLMs with pixel-level segmentation abilities, prevailing methods require finetuning the model to produce specific outputs compatible with a mask decoder. This process typically alters the model's output space and compromises its intrinsic generalization, which undermines the goal of building a unified model. We introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel plug-and-play solution. LENS attaches a lightweight, trainable head to a completely frozen MLLM. By refining the spatial cues embedded in attention maps, LENS extracts keypoints and describes them into point-wise features directly compatible with the mask decoder. Extensive experiments validate our approach: LENS achieves segmentation performance competitive with or superior to that of retraining-based methods. Crucially, it does so while fully preserving the MLLM's generalization capabilities, which are significantly degraded by finetuning approaches. As such, the attachable design of LENS establishes an efficient and powerful paradigm for extending MLLMs, paving the way for truly multi-talented, unified models.</li>
</ul>

<h3>Title: Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry</h3>
<ul>
<li><strong>Authors: </strong>Sara Hatami Rostami, Behrooz Nasihatkon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16790">https://arxiv.org/abs/2510.16790</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16790">https://arxiv.org/pdf/2510.16790</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16790]] Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry(https://arxiv.org/abs/2510.16790)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>This paper presents a fully unsupervised approach for binary road segmentation (road vs. non-road), eliminating the reliance on costly manually labeled datasets. The method leverages scene geometry and temporal cues to distinguish road from non-road regions. Weak labels are first generated from geometric priors, marking pixels above the horizon as non-road and a predefined quadrilateral in front of the vehicle as road. In a refinement stage, temporal consistency is enforced by tracking local feature points across frames and penalizing inconsistent label assignments using mutual information maximization. This enhances both precision and temporal stability. On the Cityscapes dataset, the model achieves an Intersection-over-Union (IoU) of 0.82, demonstrating high accuracy with a simple design. These findings demonstrate the potential of combining geometric constraints and temporal consistency for scalable unsupervised road segmentation in autonomous driving.</li>
</ul>

<h3>Title: Personalized Image Filter: Mastering Your Photographic Style</h3>
<ul>
<li><strong>Authors: </strong>Chengxuan Zhu, Shuchen Weng, Jiacong Fang, Peixuan Zhang, Si Li, Chao Xu, Boxin Shi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16791">https://arxiv.org/abs/2510.16791</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16791">https://arxiv.org/pdf/2510.16791</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16791]] Personalized Image Filter: Mastering Your Photographic Style(https://arxiv.org/abs/2510.16791)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Photographic style, as a composition of certain photographic concepts, is the charm behind renowned photographers. But learning and transferring photographic style need a profound understanding of how the photo is edited from the unknown original appearance. Previous works either fail to learn meaningful photographic concepts from reference images, or cannot preserve the content of the content image. To tackle these issues, we proposed a Personalized Image Filter (PIF). Based on a pretrained text-to-image diffusion model, the generative prior enables PIF to learn the average appearance of photographic concepts, as well as how to adjust them according to text prompts. PIF then learns the photographic style of reference images with the textual inversion technique, by optimizing the prompts for the photographic concepts. PIF shows outstanding performance in extracting and transferring various kinds of photographic style. Project page: this https URL</li>
</ul>

<h3>Title: Black-box Optimization of LLM Outputs by Asking for Directions</h3>
<ul>
<li><strong>Authors: </strong>Jie Zhang, Meng Ding, Yang Liu, Jue Hong, Florian Tramèr</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16794">https://arxiv.org/abs/2510.16794</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16794">https://arxiv.org/pdf/2510.16794</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16794]] Black-box Optimization of LLM Outputs by Asking for Directions(https://arxiv.org/abs/2510.16794)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>We present a novel approach for attacking black-box large language models (LLMs) by exploiting their ability to express confidence in natural language. Existing black-box attacks require either access to continuous model outputs like logits or confidence scores (which are rarely available in practice), or rely on proxy signals from other models. Instead, we demonstrate how to prompt LLMs to express their internal confidence in a way that is sufficiently calibrated to enable effective adversarial optimization. We apply our general method to three attack scenarios: adversarial examples for vision-LLMs, jailbreaks and prompt injections. Our attacks successfully generate malicious inputs against systems that only expose textual outputs, thereby dramatically expanding the attack surface for deployed LLMs. We further find that better and larger models exhibit superior calibration when expressing confidence, creating a concerning security paradox where model capability improvements directly enhance vulnerability. Our code is available at this [link](this https URL).</li>
</ul>

<h3>Title: MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Vera Pavlova, Mohammed Makhlouf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16797">https://arxiv.org/abs/2510.16797</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16797">https://arxiv.org/pdf/2510.16797</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16797]] MOSAIC: Masked Objective with Selective Adaptation for In-domain Contrastive Learning(https://arxiv.org/abs/2510.16797)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce MOSAIC (Masked Objective with Selective Adaptation for In-domain Contrastive learning), a multi-stage framework for domain adaptation of sentence embedding models that incorporates joint domain-specific masked supervision. Our approach addresses the challenges of adapting large-scale general-domain sentence embedding models to specialized domains. By jointly optimizing masked language modeling (MLM) and contrastive objectives within a unified training pipeline, our method enables effective learning of domain-relevant representations while preserving the robust semantic discrimination properties of the original model. We empirically validate our approach on both high-resource and low-resource domains, achieving improvements up to 13.4% in NDCG@10 (Normalized Discounted Cumulative Gain) over strong general-domain baselines. Comprehensive ablation studies further demonstrate the effectiveness of each component, highlighting the importance of balanced joint supervision and staged adaptation.</li>
</ul>

<h3>Title: Mixed-Precision Quantization for Language Models: Techniques and Prospects</h3>
<ul>
<li><strong>Authors: </strong>Mariam Rakka, Marios Fournarakis, Olga Krestinskaya, Jinane Bazzi, Khaled N. Salama, Fadi Kurdahi, Ahmed M. Eltawil, Mohammed E. Fouda</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16805">https://arxiv.org/abs/2510.16805</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16805">https://arxiv.org/pdf/2510.16805</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16805]] Mixed-Precision Quantization for Language Models: Techniques and Prospects(https://arxiv.org/abs/2510.16805)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The rapid scaling of language models (LMs) has resulted in unprecedented computational, memory, and energy requirements, making their training and deployment increasingly unsustainable. Quantization has emerged as an essential compression technique to reduce model size, alleviate memory bottlenecks, and accelerate inference. However, while uniform low-bit quantization (e.g., INT8, INT4) provides significant efficiency gains, it can degrade accuracy in sensitive components of transformer-based LMs. Mixed-precision quantization offers a promising alternative by selectively allocating precision across layers or within tensors to balance efficiency and accuracy. This survey provides a comprehensive overview of Mixed-Precision quantization frameworks for LMs (MXPLMs). We first review quantization fundamentals, including uniform and non-uniform quantizers, quantization granularity, and methods widely used in post-training quantization. We then categorize and compare recent MXPLM frameworks according to their bit allocation strategies and precision configurations across weights, activations, and key-value caches. A comparative analysis highlights differences in perplexity, zero-shot task performance, and deployment trade-offs. Furthermore, we contrast MXPLMs with earlier mixed-precision quantization methods for deep neural networks, identifying strategies that transfer and those that face challenges in the LM setting. Finally, we summarize open issues and future directions, including hardware-aware design, activation quantization, and scalable optimization methods for billion-parameter models. By consolidating recent advances, this work serves as a reference for understanding the current landscape and research prospects of mixed-precision quantization for large-scale language models.</li>
</ul>

<h3>Title: Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads</h3>
<ul>
<li><strong>Authors: </strong>Zhoutong Wu, Yuan Zhang, Yiming Dong, Chenheng Zhang, Cong Fang, Kun Yuan, Zhouchen Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16807">https://arxiv.org/abs/2510.16807</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16807">https://arxiv.org/pdf/2510.16807</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16807]] Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads(https://arxiv.org/abs/2510.16807)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer models have driven breakthroughs across various language tasks by their strong capability to learn rich contextual representations. Scaling them to improve representation, however, often demands substantial memory and compute costs, such as the Key-Value (KV) cache used during auto-regressive decoding. Skip connections offer a promising way to improve representation without bloating resource usage, yet most prior works either improve expressivity while leaving KV costs unchanged, or reduce memory at the cost of weaker representation. In this work, we propose SkipV1Former, a Transformer variant that uses skip connections from the first layer's Value heads to strengthen model representation and reduce KV cache. Specifically, from the second block onward, each layer reuses half of its Value heads from the very first layer, while computing the other half as usual-cutting Value projections and V cache by nearly 50 \%. Theoretically, we show that routing uncompressed first-layer Values into deeper layers restores information lost to compression and accelerates the model's implicit mesa-optimization-a key pattern of Transformer in auto-regressive tasks. Empirically, across different model scales, SkipV1Former delivers consistent reductions of approximately 25 \% in KV cache while improving perplexity relative to standard Multi-Head Attention (MHA) Transformers and some advanced variants. Moreover, we propose a recipe for uptraining existing MHA Transformer checkpoints to SkipV1Former with only 10-15\% additional compute. Finally, SkipV1Former can seamlessly combine advanced methods like Group-Query Attention and Multi-Latent Attention to achieve further KV cache savings and performance improvement. When combined with YOCO, it cuts KV cache size by nearly 50 \% while still improving performance.</li>
</ul>

<h3>Title: Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity</h3>
<ul>
<li><strong>Authors: </strong>Simon Jaxy, Anton Theys, Patrick Willett, W. Chris Carleton, Ralf Vandam, Pieter Libin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16814">https://arxiv.org/abs/2510.16814</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16814">https://arxiv.org/pdf/2510.16814</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16814]] Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity(https://arxiv.org/abs/2510.16814)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>Archaeological predictive modelling estimates where undiscovered sites are likely to occur by combining known locations with environmental, cultural, and geospatial variables. We address this challenge using a deep learning approach but must contend with structural label scarcity inherent to archaeology: positives are rare, and most locations are unlabeled. To address this, we adopt a semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a semantic segmentation model and evaluated on two datasets covering a representative range of archaeological periods. Our approach employs dynamic pseudolabeling, refined with a Conditional Random Field (CRF) implemented via an RNN, increasing label confidence under severe class imbalance. On a geospatial dataset derived from a digital elevation model (DEM), our model performs on par with the state-of-the-art, LAMAP, while achieving higher Dice scores. On raw satellite imagery, assessed end-to-end with stratified k-fold cross-validation, it maintains performance and yields predictive surfaces with improved interpretability. Overall, our results indicate that semi-supervised learning offers a promising approach to identifying undiscovered sites across large, sparsely annotated landscapes.</li>
</ul>

<h3>Title: Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities</h3>
<ul>
<li><strong>Authors: </strong>Hans Hergen Lehmann, Jae Hee Lee, Steven Schockaert, Stefan Wermter</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16815">https://arxiv.org/abs/2510.16815</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16815">https://arxiv.org/pdf/2510.16815</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16815]] Knowing the Facts but Choosing the Shortcut: Understanding How Large Language Models Compare Entities(https://arxiv.org/abs/2510.16815)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly used for knowledge-based reasoning tasks, yet understanding when they rely on genuine knowledge versus superficial heuristics remains challenging. We investigate this question through entity comparison tasks by asking models to compare entities along numerical attributes (e.g., ``Which river is longer, the Danube or the Nile?''), which offer clear ground truth for systematic analysis. Despite having sufficient numerical knowledge to answer correctly, LLMs frequently make predictions that contradict this knowledge. We identify three heuristic biases that strongly influence model predictions: entity popularity, mention order, and semantic co-occurrence. For smaller models, a simple logistic regression using only these surface cues predicts model choices more accurately than the model's own numerical predictions, suggesting heuristics largely override principled reasoning. Crucially, we find that larger models (32B parameters) selectively rely on numerical knowledge when it is more reliable, while smaller models (7--8B parameters) show no such discrimination, which explains why larger models outperform smaller ones even when the smaller models possess more accurate knowledge. Chain-of-thought prompting steers all models towards using the numerical features across all model sizes.</li>
</ul>

<h3>Title: Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator</h3>
<ul>
<li><strong>Authors: </strong>Ming Zhong, Zhenya Yan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math-ph, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16816">https://arxiv.org/abs/2510.16816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16816">https://arxiv.org/pdf/2510.16816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16816]] Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator(https://arxiv.org/abs/2510.16816)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural operators offer a powerful data-driven framework for learning mappings between function spaces, in which the transformer-based neural operator architecture faces a fundamental scalability-accuracy trade-off: softmax attention provides excellent fidelity but incurs quadratic complexity $\mathcal{O}(N^2 d)$ in the number of mesh points $N$ and hidden dimension $d$, while linear attention variants reduce cost to $\mathcal{O}(N d^2)$ but often suffer significant accuracy degradation. To address the aforementioned challenge, in this paper, we present a novel type of neural operators, Linear Attention Neural Operator (LANO), which achieves both scalability and high accuracy by reformulating attention through an agent-based mechanism. LANO resolves this dilemma by introducing a compact set of $M$ agent tokens $(M \ll N)$ that mediate global interactions among $N$ tokens. This agent attention mechanism yields an operator layer with linear complexity $\mathcal{O}(MN d)$ while preserving the expressive power of softmax attention. Theoretically, we demonstrate the universal approximation property, thereby demonstrating improved conditioning and stability properties. Empirically, LANO surpasses current state-of-the-art neural PDE solvers, including Transolver with slice-based softmax attention, achieving average $19.5\%$ accuracy improvement across standard benchmarks. By bridging the gap between linear complexity and softmax-level performance, LANO establishes a scalable, high-accuracy foundation for scientific machine learning applications.</li>
</ul>

<h3>Title: ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification</h3>
<ul>
<li><strong>Authors: </strong>Yahia Battach, Abdulwahab Felemban, Faizan Farooq Khan, Yousef A. Radwan, Xiang Li, Fabio Marchese, Sara Beery, Burton H. Jones, Francesca Benzoni, Mohamed Elhoseiny</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16822">https://arxiv.org/abs/2510.16822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16822">https://arxiv.org/pdf/2510.16822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16822]] ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification(https://arxiv.org/abs/2510.16822)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Coral reefs are rapidly declining due to anthropogenic pressures such as climate change, underscoring the urgent need for scalable, automated monitoring. We introduce ReefNet, a large public coral reef image dataset with point-label annotations mapped to the World Register of Marine Species (WoRMS). ReefNet aggregates imagery from 76 curated CoralNet sources and an additional site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level hard coral annotations with expert-verified labels. Unlike prior datasets, which are often limited by size, geography, or coarse labels and are not ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global scale to WoRMS. We propose two evaluation settings: (i) a within-source benchmark that partitions each source's images for localized evaluation, and (ii) a cross-source benchmark that withholds entire sources to test domain generalization. We analyze both supervised and zero-shot classification performance on ReefNet and find that while supervised within-source performance is promising, supervised performance drops sharply across domains, and performance is low across the board for zero-shot models, especially for rare and visually similar genera. This provides a challenging benchmark intended to catalyze advances in domain generalization and fine-grained coral classification. We will release our dataset, benchmarking code, and pretrained models to advance robust, domain-adaptive, global coral reef monitoring and conservation.</li>
</ul>

<h3>Title: ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning</h3>
<ul>
<li><strong>Authors: </strong>Yingxu Wang, Kunyu Zhang, Jiaxin Huang, Nan Yin, Siwei Liu, Eran Segal</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.MN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16824">https://arxiv.org/abs/2510.16824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16824">https://arxiv.org/pdf/2510.16824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16824]] ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning(https://arxiv.org/abs/2510.16824)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Multimodal molecular representation learning, which jointly models molecular graphs and their textual descriptions, enhances predictive accuracy and interpretability by enabling more robust and reliable predictions of drug toxicity, bioactivity, and physicochemical properties through the integration of structural and semantic information. However, existing multimodal methods suffer from two key limitations: (1) they typically perform cross-modal interaction only at the final encoder layer, thus overlooking hierarchical semantic dependencies; (2) they lack a unified prototype space for robust alignment between modalities. To address these limitations, we propose ProtoMol, a prototype-guided multimodal framework that enables fine-grained integration and consistent semantic alignment between molecular graphs and textual descriptions. ProtoMol incorporates dual-branch hierarchical encoders, utilizing Graph Neural Networks to process structured molecular graphs and Transformers to encode unstructured texts, resulting in comprehensive layer-wise representations. Then, ProtoMol introduces a layer-wise bidirectional cross-modal attention mechanism that progressively aligns semantic features across layers. Furthermore, a shared prototype space with learnable, class-specific anchors is constructed to guide both modalities toward coherent and discriminative representations. Extensive experiments on multiple benchmark datasets demonstrate that ProtoMol consistently outperforms state-of-the-art baselines across a variety of molecular property prediction tasks.</li>
</ul>

<h3>Title: Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to Data Provenance and Policy</h3>
<ul>
<li><strong>Authors: </strong>Hasan Akgul, Daniel Borg, Arta Berisha, Amina Rahimova, Andrej Novak, Mila Petrov</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16830">https://arxiv.org/abs/2510.16830</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16830">https://arxiv.org/pdf/2510.16830</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16830]] Verifiable Fine-Tuning for LLMs: Zero-Knowledge Training Proofs Bound to Data Provenance and Policy(https://arxiv.org/abs/2510.16830)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate, large language model</a></li>
<li><strong>Abstract: </strong>Large language models are often adapted through parameter efficient fine tuning, but current release practices provide weak assurances about what data were used and how updates were computed. We present Verifiable Fine Tuning, a protocol and system that produces succinct zero knowledge proofs that a released model was obtained from a public initialization under a declared training program and an auditable dataset commitment. The approach combines five elements. First, commitments that bind data sources, preprocessing, licenses, and per epoch quota counters to a manifest. Second, a verifiable sampler that supports public replayable and private index hiding batch selection. Third, update circuits restricted to parameter efficient fine tuning that enforce AdamW style optimizer semantics and proof friendly approximations with explicit error budgets. Fourth, recursive aggregation that folds per step proofs into per epoch and end to end certificates with millisecond verification. Fifth, provenance binding and optional trusted execution property cards that attest code identity and constants. On English and bilingual instruction mixtures, the method maintains utility within tight budgets while achieving practical proof performance. Policy quotas are enforced with zero violations, and private sampling windows show no measurable index leakage. Federated experiments demonstrate that the system composes with probabilistic audits and bandwidth constraints. These results indicate that end to end verifiable fine tuning is feasible today for real parameter efficient pipelines, closing a critical trust gap for regulated and decentralized deployments.</li>
</ul>

<h3>Title: Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction</h3>
<ul>
<li><strong>Authors: </strong>Abdur Rahman, Mohammad Marufuzzaman, Jason Street, Haifeng Wang, Veera G. Gude, Randy Buchanan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16832">https://arxiv.org/abs/2510.16832</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16832">https://arxiv.org/pdf/2510.16832</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16832]] Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction(https://arxiv.org/abs/2510.16832)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and quick prediction of wood chip moisture content is critical for optimizing biofuel production and ensuring energy efficiency. The current widely used direct method (oven drying) is limited by its longer processing time and sample destructiveness. On the other hand, existing indirect methods, including near-infrared spectroscopy-based, electrical capacitance-based, and image-based approaches, are quick but not accurate when wood chips come from various sources. Variability in the source material can alter data distributions, undermining the performance of data-driven models. Therefore, there is a need for a robust approach that effectively mitigates the impact of source variability. Previous studies show that manually extracted texture features have the potential to predict wood chip moisture class. Building on this, in this study, we conduct a comprehensive analysis of five distinct texture feature types extracted from wood chip images to predict moisture content. Our findings reveal that a combined feature set incorporating all five texture features achieves an accuracy of 95% and consistently outperforms individual texture features in predicting moisture content. To ensure robust moisture prediction, we propose a domain adaptation method named AdaptMoist that utilizes the texture features to transfer knowledge from one source of wood chip data to another, addressing variability across different domains. We also proposed a criterion for model saving based on adjusted mutual information. The AdaptMoist method improves prediction accuracy across domains by 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted models. These results highlight the effectiveness of AdaptMoist as a robust solution for wood chip moisture content estimation across domains, making it a potential solution for wood chip-reliant industries.</li>
</ul>

<h3>Title: From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display</h3>
<ul>
<li><strong>Authors: </strong>Xiangyu Mu, Dongliang Zhou, Jie Hou, Haijun Zhang, Weili Guan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16833">https://arxiv.org/abs/2510.16833</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16833">https://arxiv.org/pdf/2510.16833</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16833]] From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display(https://arxiv.org/abs/2510.16833)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Mannequin-based clothing displays offer a cost-effective alternative to real-model showcases for online fashion presentation, but lack realism and expressive detail. To overcome this limitation, we introduce a new task called mannequin-to-human (M2H) video generation, which aims to synthesize identity-controllable, photorealistic human videos from footage of mannequins. We propose M2HVideo, a pose-aware and identity-preserving video generation framework that addresses two key challenges: the misalignment between head and body motion, and identity drift caused by temporal modeling. In particular, M2HVideo incorporates a dynamic pose-aware head encoder that fuses facial semantics with body pose to produce consistent identity embeddings across frames. To address the loss of fine facial details due to latent space compression, we introduce a mirror loss applied in pixel space through a denoising diffusion implicit model (DDIM)-based one-step denoising. Additionally, we design a distribution-aware adapter that aligns statistical distributions of identity and clothing features to enhance temporal coherence. Extensive experiments on the UBC fashion dataset, our self-constructed ASOS dataset, and the newly collected MannequinVideos dataset captured on-site demonstrate that M2HVideo achieves superior performance in terms of clothing consistency, identity preservation, and video fidelity in comparison to state-of-the-art methods.</li>
</ul>

<h3>Title: ThreatIntel-Andro: Expert-Verified Benchmarking for Robust Android Malware Research</h3>
<ul>
<li><strong>Authors: </strong>Hongpeng Bai, Minhong Dong, Yao Zhang, Shunzhe Zhao, Haobo Zhang, Lingyue Li, Yude Bai, Guangquan Xu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16835">https://arxiv.org/abs/2510.16835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16835">https://arxiv.org/pdf/2510.16835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16835]] ThreatIntel-Andro: Expert-Verified Benchmarking for Robust Android Malware Research(https://arxiv.org/abs/2510.16835)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The rapidly evolving Android malware ecosystem demands high-quality, real-time datasets as a foundation for effective detection and defense. With the widespread adoption of mobile devices across industrial systems, they have become a critical yet often overlooked attack surface in industrial cybersecurity. However, mainstream datasets widely used in academia and industry (e.g., Drebin) exhibit significant limitations: on one hand, their heavy reliance on VirusTotal's multi-engine aggregation results introduces substantial label noise; on the other hand, outdated samples reduce their temporal relevance. Moreover, automated labeling tools (e.g., AVClass2) suffer from suboptimal aggregation strategies, further compounding labeling errors and propagating inaccuracies throughout the research community.</li>
</ul>

<h3>Title: Neuronal Group Communication for Efficient Neural representation</h3>
<ul>
<li><strong>Authors: </strong>Zhengqi Pei, Qingming Huang, Shuhui Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16851">https://arxiv.org/abs/2510.16851</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16851">https://arxiv.org/pdf/2510.16851</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16851]] Neuronal Group Communication for Efficient Neural representation(https://arxiv.org/abs/2510.16851)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The ever-increasing scale of modern neural networks has brought unprecedented performance alongside daunting challenges in efficiency and interpretability. This paper addresses the core question of how to build large neural systems that learn efficient, modular, and interpretable representations. We propose Neuronal Group Communication (NGC), a theory-driven framework that reimagines a neural network as a dynamical system of interacting neuronal groups rather than a monolithic collection of neural weights. Instead of treating each weight as an independent trainable parameter, NGC treats weights as transient interactions between embedding-like neuronal states, with neural computation unfolding through iterative communication among groups of neurons. This low-rank, modular representation yields compact models: groups of neurons exchange low-dimensional signals, enabling intra-group specialization and inter-group information sharing while dramatically reducing redundant parameters. By drawing on dynamical systems theory, we introduce a neuronal stability metric (analogous to Lyapunov stability) that quantifies the contraction of neuron activations toward stable patterns during sequence processing. Using this metric, we reveal that emergent reasoning capabilities correspond to an external driving force or ``potential'', which nudges the neural dynamics away from trivial trajectories while preserving stability. Empirically, we instantiate NGC in large language models (LLMs) and demonstrate improved performance on complex reasoning benchmarks under moderate compression. NGC consistently outperforms standard low-rank approximations and cross-layer basis-sharing methods at comparable compression rates. We conclude by discussing the broader implications of NGC, including how structured neuronal group dynamics might relate to generalization in high-dimensional learning systems.</li>
</ul>

<h3>Title: ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Akhila Kambhatla, Taminul Islam, Khaled R Ahmed</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16854">https://arxiv.org/abs/2510.16854</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16854">https://arxiv.org/pdf/2510.16854</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16854]] ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification(https://arxiv.org/abs/2510.16854)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>The escalating threat of weapon-related violence necessitates automated detection systems capable of pixel-level precision for accurate threat assessment in real-time security applications. Traditional weapon detection approaches rely on object detection frameworks that provide only coarse bounding box localizations, lacking the fine-grained segmentation required for comprehensive threat analysis. Furthermore, existing semantic segmentation models either sacrifice accuracy for computational efficiency or require excessive computational resources incompatible with edge deployment scenarios. This paper presents ArmFormer, a lightweight transformer-based semantic segmentation framework that strategically integrates Convolutional Block Attention Module (CBAM) with MixVisionTransformer architecture to achieve superior accuracy while maintaining computational efficiency suitable for resource-constrained edge devices. Our approach combines CBAM-enhanced encoder backbone with attention-integrated hamburger decoder to enable multi-class weapon segmentation across five categories: handgun, rifle, knife, revolver, and human. Comprehensive experiments demonstrate that ArmFormer achieves state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M parameters, ArmFormer outperforms heavyweight models requiring up to 48x more computation, establishing it as the optimal solution for deployment on portable security cameras, surveillance drones, and embedded AI accelerators in distributed security infrastructure.</li>
</ul>

<h3>Title: BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shujian Gao, Yuan Wang, Zekuan Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16863">https://arxiv.org/abs/2510.16863</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16863">https://arxiv.org/pdf/2510.16863</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16863]] BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation(https://arxiv.org/abs/2510.16863)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Semi-supervised medical image segmentation (SSMIS) seeks to match fully supervised performance while sharply reducing annotation cost. Mainstream SSMIS methods rely on \emph{label-space consistency}, yet they overlook the equally critical \emph{representation-space alignment}. Without harmonizing latent features, models struggle to learn representations that are both discriminative and spatially coherent. To this end, we introduce \textbf{Bilateral Alignment in Representation and Label spaces (BARL)}, a unified framework that couples two collaborative branches and enforces alignment in both spaces. For label-space alignment, inspired by co-training and multi-scale decoding, we devise \textbf{Dual-Path Regularization (DPR)} and \textbf{Progressively Cognitive Bias Correction (PCBC)} to impose fine-grained cross-branch consistency while mitigating error accumulation from coarse to fine scales. For representation-space alignment, we conduct region-level and lesion-instance matching between branches, explicitly capturing the fragmented, complex pathological patterns common in medical imagery. Extensive experiments on four public benchmarks and a proprietary CBCT dataset demonstrate that BARL consistently surpasses state-of-the-art SSMIS methods. Ablative studies further validate the contribution of each component. Code will be released soon.</li>
</ul>

<h3>Title: Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Yu, Zhengwei Chen, Xuemiao Xu, Lei Zhang, Haoxin Yang, Yongwei Nie, Shengfeng He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16865">https://arxiv.org/abs/2510.16865</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16865">https://arxiv.org/pdf/2510.16865</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16865]] Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection(https://arxiv.org/abs/2510.16865)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>3D anomaly detection in point-cloud data is critical for industrial quality control, aiming to identify structural defects with high reliability. However, current memory bank-based methods often suffer from inconsistent feature transformations and limited discriminative capacity, particularly in capturing local geometric details and achieving rotation invariance. These limitations become more pronounced when registration fails, leading to unreliable detection results. We argue that point-cloud registration plays an essential role not only in aligning geometric structures but also in guiding feature extraction toward rotation-invariant and locally discriminative representations. To this end, we propose a registration-induced, rotation-invariant feature extraction framework that integrates the objectives of point-cloud registration and memory-based anomaly detection. Our key insight is that both tasks rely on modeling local geometric structures and leveraging feature similarity across samples. By embedding feature extraction into the registration learning process, our framework jointly optimizes alignment and representation learning. This integration enables the network to acquire features that are both robust to rotations and highly effective for anomaly detection. Extensive experiments on the Anomaly-ShapeNet and Real3D-AD datasets demonstrate that our method consistently outperforms existing approaches in effectiveness and generalizability.</li>
</ul>

<h3>Title: Addendum: Systematic Evaluation of Randomized Cache Designs against Cache Occupancy</h3>
<ul>
<li><strong>Authors: </strong>Anirban Chakraborty, Nimish Mishra, Sayandeep Saha, Sarani Bhattacharya, Debdeep Mukhopadhyay</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16871">https://arxiv.org/abs/2510.16871</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16871">https://arxiv.org/pdf/2510.16871</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16871]] Addendum: Systematic Evaluation of Randomized Cache Designs against Cache Occupancy(https://arxiv.org/abs/2510.16871)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, fair</a></li>
<li><strong>Abstract: </strong>In the main text published at USENIX Security 2025, we presented a systematic analysis of the role of cache occupancy in the design considerations for randomized caches (from the perspectives of performance and security). On the performance front, we presented a uniform benchmarking strategy that allows for a fair comparison among different randomized cache designs. Likewise, from the security perspective, we presented three threat assumptions: (1) covert channels; (2) process fingerprinting side-channel; and (3) AES key recovery. The main takeaway of our work is an open problem of designing a randomized cache of comparable efficiency with modern set-associative LLCs, while still resisting both contention-based and occupancy-based attacks. This note is meant as an addendum to the main text in light of the observations made in [2]. To summarize, the authors in [2] argue that (1) L1d cache size plays a role in adversarial success, and that (2) a patched version of MIRAGE with randomized initial seeding of global eviction map prevents leakage of AES key. We discuss the same in this addendum.</li>
</ul>

<h3>Title: On the Credibility of Deniable Communication in Court</h3>
<ul>
<li><strong>Authors: </strong>Jacob Leiken, Sunoo Park</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16873">https://arxiv.org/abs/2510.16873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16873">https://arxiv.org/pdf/2510.16873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16873]] On the Credibility of Deniable Communication in Court(https://arxiv.org/abs/2510.16873)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>Over time, cryptographically deniable systems have come to be associated in computer-science literature with the idea of "denying" evidence in court - specifically, with the ability to convincingly forge evidence in courtroom scenarios and an inability to authenticate evidence in such contexts. Evidentiary processes in courts, however, have been developed over centuries to account for the reality that evidence has always been forgeable, and relies on factors outside of cryptographic models to seek the truth "as well as possible" while acknowledging that all evidence is imperfect. We argue that deniability does not and need not change this paradigm. Our analysis highlights a gap between technical deniability notions and their application to the real world. There will always be factors outside a cryptographic model that influence perceptions of a message's authenticity, in realistic situations. We propose the broader concept of credibility to capture these factors. The credibility of a system is determined by (1) a threshold of quality that a forgery must pass to be "believable" as an original communication, which varies based on sociotechnical context and threat model, (2) the ease of creating a forgery that passes this threshold, which is also context- and threat-model-dependent, and (3) default system retention policy and retention settings. All three aspects are important for designing secure communication systems for real-world threat models, and some aspects of (2) and (3) may be incorporated directly into technical system design. We hope that our model of credibility will facilitate system design and deployment that addresses threats that are not and cannot be captured by purely technical definitions and existing cryptographic models, and support more nuanced discourse on the strengths and limitations of cryptographic guarantees within specific legal and sociotechnical contexts.</li>
</ul>

<h3>Title: Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning</h3>
<ul>
<li><strong>Authors: </strong>Heming Zou, Yixiu Mao, Yun Qu, Qi Wang, Xiangyang Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16882">https://arxiv.org/abs/2510.16882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16882">https://arxiv.org/pdf/2510.16882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16882]] Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning(https://arxiv.org/abs/2510.16882)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Supervised fine-tuning (SFT) is a commonly used technique to adapt large language models (LLMs) to downstream tasks. In practice, SFT on a full dataset is computationally expensive and sometimes suffers from overfitting or bias amplification. This facilitates the rise of data curation in SFT, which prioritizes the most valuable data to optimze. This work studies the online batch selection family that dynamically scores and filters samples during the training process. However, existing popular methods often (i) rely merely on the utility of data to select a subset while neglecting other crucial factors like diversity, (ii) rely on external resources such as reference models or validation sets, and (iii) incur extra training time over full-dataset training. To address these limitations, this work develops \textbf{UDS (Utility-Diversity Sampling)}, a framework for efficient online batch selection in SFT. UDS leverages the nuclear norm of the logits matrix to capture both data utility and intra-sample diversity, while estimating inter-sample diversity through efficient low-dimensional embedding comparisons with a lightweight memory buffer of historical samples. Such a design eliminates the need for external resources and unnecessary backpropagation, securing computational efficiency. Experiments on multiple benchmarks demonstrate that UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets, and significantly reduces training time compared to full-dataset fine-tuning. Code is available at this https URL.</li>
</ul>

<h3>Title: UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains</h3>
<ul>
<li><strong>Authors: </strong>Duo Wang, Yuan Zuo, Guangyue Lu, Junjie Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16885">https://arxiv.org/abs/2510.16885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16885">https://arxiv.org/pdf/2510.16885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16885]] UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains(https://arxiv.org/abs/2510.16885)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Generalizing to unseen graph tasks without task-specific supervision is challenging: conventional graph neural networks are typically tied to a fixed label space, while large language models (LLMs) struggle to capture graph structure. We introduce UniGTE, an instruction-tuned encoder-decoder framework that unifies structural and semantic reasoning. The encoder augments a pretrained autoregressive LLM with learnable alignment tokens and a structure-aware graph-text attention mechanism, enabling it to attend jointly to a tokenized graph and a natural-language task prompt while remaining permutation-invariant to node order. This yields compact, task-aware graph representations. Conditioned solely on these representations, a frozen LLM decoder predicts and reconstructs: it outputs the task answer and simultaneously paraphrases the input graph in natural language. The reconstruction objective regularizes the encoder to preserve structural cues. UniGTE is instruction-tuned on five datasets spanning node-level, edge-level, and graph-level tasks across diverse domains, yet requires no fine-tuning at inference. It achieves new state-of-the-art zero-shot results on node classification, link prediction, graph classification, and graph regression under cross-task and cross-domain settings, demonstrating that tight integration of graph structure with LLM semantics enables robust, transferable graph reasoning.</li>
</ul>

<h3>Title: Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Nusrat Munia, Abdullah Imran</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16887">https://arxiv.org/abs/2510.16887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16887">https://arxiv.org/pdf/2510.16887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16887]] Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis(https://arxiv.org/abs/2510.16887)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, fair, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative models, especially Diffusion Models, have demonstrated remarkable capability in generating high-quality synthetic data, including medical images. However, traditional class-conditioned generative models often struggle to generate images that accurately represent specific medical categories, limiting their usefulness for applications such as skin cancer diagnosis. To address this problem, we propose a classification-induced diffusion model, namely, Class-N-Diff, to simultaneously generate and classify dermoscopic images. Our Class-N-Diff model integrates a classifier within a diffusion model to guide image generation based on its class conditions. Thus, the model has better control over class-conditioned image synthesis, resulting in more realistic and diverse images. Additionally, the classifier demonstrates improved performance, highlighting its effectiveness for downstream diagnostic tasks. This unique integration in our Class-N-Diff makes it a robust tool for enhancing the quality and utility of diffusion model-based synthetic dermoscopic image generation. Our code is available at this https URL.</li>
</ul>

<h3>Title: Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback</h3>
<ul>
<li><strong>Authors: </strong>Zongjian Li, Zheyuan Liu, Qihui Zhang, Bin Lin, Shenghai Yuan, Zhiyuan Yan, Yang Ye, Wangbo Yu, Yuwei Niu, Li Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16888">https://arxiv.org/abs/2510.16888</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16888">https://arxiv.org/pdf/2510.16888</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16888]] Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback(https://arxiv.org/abs/2510.16888)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Instruction-based image editing has achieved remarkable progress; however, models solely trained via supervised fine-tuning often overfit to annotated patterns, hindering their ability to explore and generalize beyond training distributions. To this end, we introduce Edit-R1, a novel post-training framework for instruction-based image editing based on policy optimization. Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a likelihood-free policy optimization method consistent with the flow matching forward process, thereby enabling the use of higher-order samplers and more efficient training. Another key challenge here is the absence of a universal reward model, resulting from the diverse nature of editing instructions and tasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM) as a unified, training-free reward model, leveraging its output logits to provide fine-grained feedback. Furthermore, we carefully design a low-variance group filtering mechanism to reduce MLLM scoring noise and stabilize optimization. UniWorld-V2, trained with this framework, achieves \textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks, scoring 4.49 and 7.83, respectively. Crucially, our framework is model-agnostic, delivering substantial performance gains when applied to diverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its wide applicability. Code and models are publicly available at this https URL.</li>
</ul>

<h3>Title: DeepChem Equivariant: SE(3)-Equivariant Support in an Open-Source Molecular Machine Learning Library</h3>
<ul>
<li><strong>Authors: </strong>Jose Siguenza, Bharath Ramsundar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16897">https://arxiv.org/abs/2510.16897</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16897">https://arxiv.org/pdf/2510.16897</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16897]] DeepChem Equivariant: SE(3)-Equivariant Support in an Open-Source Molecular Machine Learning Library(https://arxiv.org/abs/2510.16897)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Neural networks that incorporate geometric relationships respecting SE(3) group transformations (e.g. rotations and translations) are increasingly important in molecular applications, such as molecular property prediction, protein structure modeling, and materials design. These models, known as SE(3)-equivariant neural networks, ensure outputs transform predictably with input coordinate changes by explicitly encoding spatial atomic positions. Although libraries such as E3NN [4] and SE(3)-TRANSFORMER [3 ] offer powerful implementations, they often require substantial deep learning or mathematical prior knowledge and lack complete training pipelines. We extend DEEPCHEM [ 13] with support for ready-to-use equivariant models, enabling scientists with minimal deep learning background to build, train, and evaluate models, such as SE(3)-Transformer and Tensor Field Networks. Our implementation includes equivariant models, complete training pipelines, and a toolkit of equivariant utilities, supported with comprehensive tests and documentation, to facilitate both application and further development of SE(3)-equivariant models.</li>
</ul>

<h3>Title: Adaptive Online Learning with LSTM Networks for Energy Price Prediction</h3>
<ul>
<li><strong>Authors: </strong>Salih Salihoglu, Ibrahim Ahmed, Afshin Asadi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16898">https://arxiv.org/abs/2510.16898</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16898">https://arxiv.org/pdf/2510.16898</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16898]] Adaptive Online Learning with LSTM Networks for Energy Price Prediction(https://arxiv.org/abs/2510.16898)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Accurate prediction of electricity prices is crucial for stakeholders in the energy market, particularly for grid operators, energy producers, and consumers. This study focuses on developing a predictive model leveraging Long Short-Term Memory (LSTM) networks to forecast day-ahead electricity prices in the California energy market. The model incorporates a variety of features, including historical price data, weather conditions, and the energy generation mix. A novel custom loss function that integrates Mean Absolute Error (MAE), Jensen-Shannon Divergence (JSD), and a smoothness penalty is introduced to enhance the prediction accuracy and interpretability. Additionally, an online learning approach is implemented to allow the model to adapt to new data incrementally, ensuring continuous relevance and accuracy. The results demonstrate that the custom loss function can improve the model's performance, aligning predicted prices more closely with actual values, particularly during peak intervals. Also, the online learning model outperforms other models by effectively incorporating real-time data, resulting in lower prediction error and variability. The inclusion of the energy generation mix further enhances the model's predictive capabilities, highlighting the importance of comprehensive feature integration. This research provides a robust framework for electricity price forecasting, offering valuable insights and tools for better decision-making in dynamic electricity markets.</li>
</ul>

<h3>Title: SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Dun Liu, Qin Pang, Guangai Liu, Hongyu Mou, Jipeng Fan, Yiming Miao, Pin-Han Ho, Limei Peng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16899">https://arxiv.org/abs/2510.16899</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16899">https://arxiv.org/pdf/2510.16899</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16899]] SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning(https://arxiv.org/abs/2510.16899)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>The effectiveness of artificial intelligence (AI) in healthcare is significantly hindered by unstructured clinical documentation, which results in noisy, inconsistent, and logically fragmented training data. To address this challenge, we present a knowledge-driven framework that integrates the standardized clinical terminology SNOMED CT with the Neo4j graph database to construct a structured medical knowledge graph. In this graph, clinical entities such as diseases, symptoms, and medications are represented as nodes, and semantic relationships such as ``caused by,'' ``treats,'' and ``belongs to'' are modeled as edges in Neo4j, with types mapped from formal SNOMED CT relationship concepts (e.g., \texttt{Causative agent}, \texttt{Indicated for}). This design enables multi-hop reasoning and ensures terminological consistency. By extracting and standardizing entity-relationship pairs from clinical texts, we generate structured, JSON-formatted datasets that embed explicit diagnostic pathways. These datasets are used to fine-tune large language models (LLMs), significantly improving the clinical logic consistency of their outputs. Experimental results demonstrate that our knowledge-guided approach enhances the validity and interpretability of AI-generated diagnostic reasoning, providing a scalable solution for building reliable AI-assisted clinical systems.</li>
</ul>

<h3>Title: A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch</h3>
<ul>
<li><strong>Authors: </strong>Sarah Al-Shareeda, Gulcihan Ozdemir, Heung Seok Jeon, Khaleel Ahmad</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16911">https://arxiv.org/abs/2510.16911</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16911">https://arxiv.org/pdf/2510.16911</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16911]] A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch(https://arxiv.org/abs/2510.16911)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>How can short-term energy consumption be accurately forecasted when sensor data is noisy, incomplete, and lacks contextual richness? This question guided our participation in the \textit{2025 Competition on Electric Energy Consumption Forecast Adopting Multi-criteria Performance Metrics}, which challenged teams to predict next-day power demand using real-world high-frequency data. We proposed a robust yet lightweight Deep Learning (DL) pipeline combining hourly downsizing, dual-mode imputation (mean and polynomial regression), and comprehensive normalization, ultimately selecting Standard Scaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model achieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\% accuracy. Despite asymmetric inputs and imputed gaps, it generalized well, captured nonlinear demand patterns, and maintained low inference latency. Notably, spatiotemporal heatmap analysis reveals a strong alignment between temperature trends and predicted consumption, further reinforcing the model's reliability. These results demonstrate that targeted preprocessing paired with compact recurrent architectures can still enable fast, accurate, and deployment-ready energy forecasting in real-world conditions.</li>
</ul>

<h3>Title: Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Akhila Kambhatla, Ahmed R Khaled</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16913">https://arxiv.org/abs/2510.16913</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16913">https://arxiv.org/pdf/2510.16913</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16913]] Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation(https://arxiv.org/abs/2510.16913)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, robust, fair, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Thermal weapon segmentation is crucial for surveillance and security applications, enabling robust detection under lowlight and visually obscured conditions where RGB-based systems fail. While convolutional neural networks (CNNs) dominate thermal segmentation literature, their ability to capture long-range dependencies and fine structural details is limited. Vision Transformers (ViTs), with their global context modeling capabilities, have achieved state-of-the-art results in RGB segmentation tasks, yet their potential in thermal weapon segmentation remains underexplored. This work adapts and evaluates four transformer-based architectures SegFormer, DeepLabV3\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a custom thermal dataset comprising 9,711 images collected from real world surveillance videos and automatically annotated using SAM2. We employ standard augmentation strategies within the MMSegmentation framework to ensure robust model training and fair architectural comparison. Experimental results demonstrate significant improvements in segmentation performance: SegFormer-b5 achieves the highest mIoU (94.15\%) and Pixel Accuracy (97.04\%), while SegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive mIoU (90.84\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and 92.24\% mIoU, and DeepLabV3\+ R101-D8 reaches 92.76\% mIoU at 29.86 FPS. The transformer architectures demonstrate robust generalization capabilities for weapon detection in low-light and occluded thermal environments, with flexible accuracy-speed trade-offs suitable for diverse real-time security applications.</li>
</ul>

<h3>Title: Domain Generalizable Continual Learning</h3>
<ul>
<li><strong>Authors: </strong>Hongwei Yan, Guanglong Sun, Zhiqi Kang, Yi Zhong, Liyuan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16914">https://arxiv.org/abs/2510.16914</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16914">https://arxiv.org/pdf/2510.16914</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16914]] Domain Generalizable Continual Learning(https://arxiv.org/abs/2510.16914)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>To adapt effectively to dynamic real-world environments, intelligent systems must continually acquire new skills while generalizing them to diverse, unseen scenarios. Here, we introduce a novel and realistic setting named domain generalizable continual learning (DGCL): a model learns sequential tasks with each involving a single domain, aiming to perform well across all encountered tasks and domains. This setting poses unique challenges in acquiring, retaining, and leveraging both semantic- and domain-relevant information for robust generalization. Although state-of-the-art continual learning (CL) methods have employed pre-trained models (PTMs) to enhance task-specific generalization, they typically assume identical training and testing domains for each task and therefore perform poorly in DGCL. To this end, we propose adaptive Domain Transformation (DoT), an innovative PTMs-based approach tailored to DGCL. Inspired by the distributed-plus-hub theory of the human brain, DoT disentangles semantic- and domain-relevant information in representation learning, and adaptively transforms task representations across various domains for output alignment, ensuring balanced and generalized predictions. DoT serves as a plug-in strategy that greatly facilitates state-of-the-art CL baselines under both full parameter tuning and parameter-efficient tuning paradigms in DGCL, validated by extensive experiments. Also, DoT is shown to accumulate domain-generalizable knowledge from DGCL, and ensure resource efficiency with a lightweight implementation.</li>
</ul>

<h3>Title: SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search</h3>
<ul>
<li><strong>Authors: </strong>Dong Li, Xujiang Zhao, Linlin Yu, Yanchi Liu, Wei Cheng, Zhengzhang Chen, Zhong Chen, Feng Chen, Chen Zhao, Haifeng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16916">https://arxiv.org/abs/2510.16916</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16916">https://arxiv.org/pdf/2510.16916</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16916]] SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search(https://arxiv.org/abs/2510.16916)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) offer promising capabilities for tackling complex reasoning tasks, including optimization problems. However, existing methods either rely on prompt engineering, which leads to poor generalization across problem types, or require costly supervised training. We introduce SolverLLM, a training-free framework that leverages test-time scaling to solve diverse optimization problems. Rather than solving directly, SolverLLM generates mathematical formulations and translates them into solver-ready code, guided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the search process, we modify classical MCTS with (1) dynamic expansion for adaptive formulation generation, (2) prompt backpropagation to guide exploration via outcome-driven feedback, and (3) uncertainty backpropagation to incorporate reward reliability into decision-making. Experiments on six standard benchmark datasets demonstrate that SolverLLM outperforms both prompt-based and learning-based baselines, achieving strong generalization without additional training.</li>
</ul>

<h3>Title: UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Mansi Phute, Matthew Hull, Haoran Wang, Alec Helbling, ShengYun Peng, Willian Lunardi, Martin Andreoni, Wenke Lee, Polo Chau</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16923">https://arxiv.org/abs/2510.16923</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16923">https://arxiv.org/pdf/2510.16923</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16923]] UNDREAM: Bridging Differentiable Rendering and Photorealistic Simulation for End-to-end Adversarial Attacks(https://arxiv.org/abs/2510.16923)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Deep learning models deployed in safety critical applications like autonomous driving use simulations to test their robustness against adversarial attacks in realistic conditions. However, these simulations are non-differentiable, forcing researchers to create attacks that do not integrate simulation environmental factors, reducing attack success. To address this limitation, we introduce UNDREAM, the first software framework that bridges the gap between photorealistic simulators and differentiable renderers to enable end-to-end optimization of adversarial perturbations on any 3D objects. UNDREAM enables manipulation of the environment by offering complete control over weather, lighting, backgrounds, camera angles, trajectories, and realistic human and object movements, thereby allowing the creation of diverse scenes. We showcase a wide array of distinct physically plausible adversarial objects that UNDREAM enables researchers to swiftly explore in different configurable environments. This combination of photorealistic simulation and differentiable optimization opens new avenues for advancing research of physical adversarial attacks.</li>
</ul>

<h3>Title: Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Zhihui Yang, Yupei Wang, Kaijie Mo, Zhe Zhao, Renfen Hu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16924">https://arxiv.org/abs/2510.16924</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16924">https://arxiv.org/pdf/2510.16924</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16924]] Does Visual Grounding Enhance the Understanding of Embodied Knowledge in Large Language Models?(https://arxiv.org/abs/2510.16924)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Despite significant progress in multimodal language models (LMs), it remains unclear whether visual grounding enhances their understanding of embodied knowledge compared to text-only models. To address this question, we propose a novel embodied knowledge understanding benchmark based on the perceptual theory from psychology, encompassing visual, auditory, tactile, gustatory, olfactory external senses, and interoception. The benchmark assesses the models' perceptual abilities across different sensory modalities through vector comparison and question-answering tasks with over 1,700 questions. By comparing 30 state-of-the-art LMs, we surprisingly find that vision-language models (VLMs) do not outperform text-only models in either task. Moreover, the models perform significantly worse in the visual dimension compared to other sensory dimensions. Further analysis reveals that the vector representations are easily influenced by word form and frequency, and the models struggle to answer questions involving spatial perception and reasoning. Our findings underscore the need for more effective integration of embodied knowledge in LMs to enhance their understanding of the physical world.</li>
</ul>

<h3>Title: Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input</h3>
<ul>
<li><strong>Authors: </strong>Chenxu Li, Zhicai Wang, Yuan Sheng, Xingyu Zhu, Yanbin Hao, Xiang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16926">https://arxiv.org/abs/2510.16926</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16926">https://arxiv.org/pdf/2510.16926</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16926]] Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input(https://arxiv.org/abs/2510.16926)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) increasingly support dynamic image resolutions. However, current evaluation paradigms primarily assess semantic performance, overlooking the critical question of resolution robustness - whether performance remains stable across varying input resolutions. To address this gap, we introduce \textbf{Res-Bench}, a comprehensive benchmark comprising 14,400 samples across 12 resolution levels and six core capability dimensions. We designed a novel evaluation framework that goes beyond traditional accuracy metrics to capture performance stability. This framework introduces multiple robustness metrics: Spearman's correlation for assessing resolution-performance trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring performance volatility. Using these metrics, we conducted a large-scale evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and task-centric robustness examination, (2) investigation of preprocessing strategies including padding and super-resolution, and (3) exploration of fine-tuning for stability enhancement.</li>
</ul>

<h3>Title: Closing the Curvature Gap: Full Transformer Hessians and Their Implications for Scaling Laws</h3>
<ul>
<li><strong>Authors: </strong>Egor Petrov, Nikita Kiselev, Vladislav Meshkov, Andrey Grabovoy</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16927">https://arxiv.org/abs/2510.16927</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16927">https://arxiv.org/pdf/2510.16927</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16927]] Closing the Curvature Gap: Full Transformer Hessians and Their Implications for Scaling Laws(https://arxiv.org/abs/2510.16927)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>The lack of theoretical results for Layer Normalization and feedforward Hessians has left a gap in the study of Transformer optimization landscapes. We address this by deriving explicit second-order expressions for these components, thereby completing the Hessian characterization of full Transformer blocks. Our results generalize prior self-attention analyses and yield estimations for the role of each sublayer in curvature propagation. We demonstrate how these Hessian structures inform both convergence dynamics and the empirical scaling laws governing large-model performance. Further, we propose a Taylor-expansion-based framework for analyzing loss differences to quantify convergence trajectories. By extending Hessian theory to the full Transformer architecture, this work establishes a new foundation for theoretical and empirical investigations of optimization in large-scale deep learning.</li>
</ul>

<h3>Title: ChiKhaPo: A Large-Scale Multilingual Benchmark for Evaluating Lexical Comprehension and Generation in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Emily Chang, Niyati Bafna</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16928">https://arxiv.org/abs/2510.16928</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16928">https://arxiv.org/pdf/2510.16928</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16928]] ChiKhaPo: A Large-Scale Multilingual Benchmark for Evaluating Lexical Comprehension and Generation in Large Language Models(https://arxiv.org/abs/2510.16928)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Existing benchmarks for large language models (LLMs) are largely restricted to high- or mid-resource languages, and often evaluate performance on higher-order tasks in reasoning and generation. However, plenty of evidence points to the fact that LLMs lack basic linguistic competence in the vast majority of the world's 3800+ written languages. We introduce ChiKhaPo, consisting of 8 subtasks of varying difficulty designed to evaluate the lexical comprehension and generation abilities of generative models. ChiKhaPo draws on existing lexicons, monolingual data, and bitext, and provides coverage for 2700+ languages for 2 subtasks, surpassing any existing benchmark in terms of language coverage. We further show that 6 SOTA models struggle on our benchmark, and discuss the factors contributing to performance scores, including language family, language resourcedness, task, and comprehension versus generation directions. With ChiKhaPo, we hope to enable and encourage the massively multilingual benchmarking of LLMs.</li>
</ul>

<h3>Title: Prompt-MII: Meta-Learning Instruction Induction for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Emily Xiao, Yixiao Zeng, Ada Chen, Chin-Jou Li, Amanda Bertsch, Graham Neubig</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16932">https://arxiv.org/abs/2510.16932</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16932">https://arxiv.org/pdf/2510.16932</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16932]] Prompt-MII: Meta-Learning Instruction Induction for LLMs(https://arxiv.org/abs/2510.16932)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>A popular method to adapt large language models (LLMs) to new tasks is in-context learning (ICL), which is effective but incurs high inference costs as context length grows. In this paper we propose a method to perform instruction induction, where we take training examples and reduce them to a compact but descriptive prompt that can achieve performance comparable to ICL over the full training set. Specifically, we propose PROMPT-MII, a reinforcement learning (RL) based framework to meta-learn an instruction induction model that can generate compact instructions on the fly for an arbitrary new dataset. We train on over 3,000 diverse classification datasets from the HuggingFace hub, and evaluate on 90 unseen tasks. PROMPT-MII improves downstream model quality by 4-9 F1 points (10-20% relative), matching ICL performance while requiring 3-13x fewer tokens.</li>
</ul>

<h3>Title: A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Cristian J. Vaca-Rubio, Roberto Pereira, Luis Blanco, Engin Zeydan, Màrius Caus</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16940">https://arxiv.org/abs/2510.16940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16940">https://arxiv.org/pdf/2510.16940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16940]] A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting(https://arxiv.org/abs/2510.16940)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This work introduces Probabilistic Kolmogorov-Arnold Network (P-KAN), a novel probabilistic extension of Kolmogorov-Arnold Networks (KANs) for time series forecasting. By replacing scalar weights with spline-based functional connections and directly parameterizing predictive distributions, P-KANs offer expressive yet parameter-efficient models capable of capturing nonlinear and heavy-tailed dynamics. We evaluate P-KANs on satellite traffic forecasting, where uncertainty-aware predictions enable dynamic thresholding for resource allocation. Results show that P-KANs consistently outperform Multi Layer Perceptron (MLP) baselines in both accuracy and calibration, achieving superior efficiency-risk trade-offs while using significantly fewer parameters. We build up P-KANs on two distributions, namely Gaussian and Student-t distributions. The Gaussian variant provides robust, conservative forecasts suitable for safety-critical scenarios, whereas the Student-t variant yields sharper distributions that improve efficiency under stable demand. These findings establish P-KANs as a powerful framework for probabilistic forecasting with direct applicability to satellite communications and other resource-constrained domains.</li>
</ul>

<h3>Title: Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Dania Refai, Moataz Ahmed</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16943">https://arxiv.org/abs/2510.16943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16943">https://arxiv.org/pdf/2510.16943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16943]] Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation(https://arxiv.org/abs/2510.16943)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are increasingly used to convert natural language descriptions into mathematical optimization formulations. Current evaluations often treat formulations as a whole, relying on coarse metrics like solution accuracy or runtime, which obscure structural or numerical errors. In this study, we present a comprehensive, component-level evaluation framework for LLM-generated formulations. Beyond the conventional optimality gap, our framework introduces metrics such as precision and recall for decision variables and constraints, constraint and objective root mean squared error (RMSE), and efficiency indicators based on token usage and latency. We evaluate GPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of varying complexity under six prompting strategies. Results show that GPT-5 consistently outperforms other models, with chain-of-thought, self-consistency, and modular prompting proving most effective. Analysis indicates that solver performance depends primarily on high constraint recall and low constraint RMSE, which together ensure structural correctness and solution reliability. Constraint precision and decision variable metrics play secondary roles, while concise outputs enhance computational efficiency. These findings highlight three principles for NLP-to-optimization modeling: (i) Complete constraint coverage prevents violations, (ii) minimizing constraint RMSE ensures solver-level accuracy, and (iii) concise outputs improve computational efficiency. The proposed framework establishes a foundation for fine-grained, diagnostic evaluation of LLMs in optimization modeling.</li>
</ul>

<h3>Title: Quantile Regression, Variational Autoencoders, and Diffusion Models for Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ganglin Tian, Anastase Alexandre Charantonis, Camille Le Coz, Alexis Tantet, Riwal Plougonven</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16958">https://arxiv.org/abs/2510.16958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16958">https://arxiv.org/pdf/2510.16958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16958]] Quantile Regression, Variational Autoencoders, and Diffusion Models for Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed Prediction(https://arxiv.org/abs/2510.16958)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>This study aims to improve the spatial representation of uncertainties when regressing surface wind speeds from large-scale atmospheric predictors for sub-seasonal forecasting. Sub-seasonal forecasting often relies on large-scale atmospheric predictors such as 500 hPa geopotential height (Z500), which exhibit higher predictability than surface variables and can be downscaled to obtain more localised information. Previous work by Tian et al. (2024) demonstrated that stochastic perturbations based on model residuals can improve ensemble dispersion representation in statistical downscaling frameworks, but this method fails to represent spatial correlations and physical consistency adequately. More sophisticated approaches are needed to capture the complex relationships between large-scale predictors and local-scale predictands while maintaining physical consistency. Probabilistic deep learning models offer promising solutions for capturing complex spatial dependencies. This study evaluates three probabilistic methods with distinct uncertainty quantification mechanisms: Quantile Regression Neural Network that directly models distribution quantiles, Variational Autoencoders that leverage latent space sampling, and Diffusion Models that utilise iterative denoising. These models are trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts to regress probabilistic wind speed ensembles. Our results show that probabilistic downscaling approaches provide more realistic spatial uncertainty representations compared to simpler stochastic methods, with each probabilistic model offering different strengths in terms of ensemble dispersion, deterministic skill, and physical consistency. These findings establish probabilistic downscaling as an effective enhancement to operational sub-seasonal wind forecasts for renewable energy planning and risk assessment.</li>
</ul>

<h3>Title: Efficient derandomization of differentially private counting queries</h3>
<ul>
<li><strong>Authors: </strong>Surendra Ghentiyala</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16959">https://arxiv.org/abs/2510.16959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16959">https://arxiv.org/pdf/2510.16959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16959]] Efficient derandomization of differentially private counting queries(https://arxiv.org/abs/2510.16959)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, fair</a></li>
<li><strong>Abstract: </strong>Differential privacy for the 2020 census required an estimated 90 terabytes of randomness [GL20], an amount which may be prohibitively expensive or entirely infeasible to generate. Motivated by these practical concerns, [CSV25] initiated the study of the randomness complexity of differential privacy, and in particular, the randomness complexity of $d$ counting queries. This is the task of outputting the number of entries in a dataset that satisfy predicates $\mathcal{P}_1, \dots, \mathcal{P}_d$ respectively. They showed the rather surprising fact that though any reasonably accurate, $\varepsilon$-differentially private mechanism for one counting query requires $1-O(\varepsilon)$ bits of randomness in expectation, there exists a fairly accurate mechanism for $d$ counting queries which requires only $O(\log d)$ bits of randomness in expectation. The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a combinatorial object known as rounding schemes. Here, we give a polynomial time mechanism which achieves nearly the same randomness complexity versus accuracy tradeoff as that of [CSV25]. Our construction is based on the following simple observation: after a randomized shift of the answer to each counting query, the answer to many counting queries remains the same regardless of whether we add noise to that coordinate or not. This allows us to forgo the step of adding noise to the result of many counting queries. Our mechanism does not make use of rounding schemes. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries.</li>
</ul>

<h3>Title: Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert Signatures</h3>
<ul>
<li><strong>Authors: </strong>Pingzhi Li, Morris Yu-Chao Huang, Zhen Tan, Qingquan Song, Jie Peng, Kai Zou, Yu Cheng, Kaidi Xu, Tianlong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16968">https://arxiv.org/abs/2510.16968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16968">https://arxiv.org/pdf/2510.16968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16968]] Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert Signatures(https://arxiv.org/abs/2510.16968)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, robust, large language model</a></li>
<li><strong>Abstract: </strong>Knowledge Distillation (KD) accelerates training of large language models (LLMs) but poses intellectual property protection and LLM diversity risks. Existing KD detection methods based on self-identity or output similarity can be easily evaded through prompt engineering. We present a KD detection framework effective in both white-box and black-box settings by exploiting an overlooked signal: the transfer of MoE "structural habits", especially internal routing patterns. Our approach analyzes how different experts specialize and collaborate across various inputs, creating distinctive fingerprints that persist through the distillation process. To extend beyond the white-box setup and MoE architectures, we further propose Shadow-MoE, a black-box method that constructs proxy MoE representations via auxiliary distillation to compare these patterns between arbitrary model pairs. We establish a comprehensive, reproducible benchmark that offers diverse distilled checkpoints and an extensible framework to facilitate future research. Extensive experiments demonstrate >94% detection accuracy across various scenarios and strong robustness to prompt-based evasion, outperforming existing baselines while highlighting the structural habits transfer in LLMs.</li>
</ul>

<h3>Title: Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis</h3>
<ul>
<li><strong>Authors: </strong>Praveenbalaji Rajendran, Mojtaba Safari, Wenfeng He, Mingzhe Hu, Shansong Wang, Jun Zhou, Xiaofeng Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, physics.med-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16973">https://arxiv.org/abs/2510.16973</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16973">https://arxiv.org/pdf/2510.16973</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16973]] Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis(https://arxiv.org/abs/2510.16973)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, interpretability, explainability, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in artificial intelligence (AI), particularly foundation models (FMs), have revolutionized medical image analysis, demonstrating strong zero- and few-shot performance across diverse medical imaging tasks, from segmentation to report generation. Unlike traditional task-specific AI models, FMs leverage large corpora of labeled and unlabeled multimodal datasets to learn generalized representations that can be adapted to various downstream clinical applications with minimal fine-tuning. However, despite the rapid proliferation of FM research in medical imaging, the field remains fragmented, lacking a unified synthesis that systematically maps the evolution of architectures, training paradigms, and clinical applications across modalities. To address this gap, this review article provides a comprehensive and structured analysis of FMs in medical image analysis. We systematically categorize studies into vision-only and vision-language FMs based on their architectural foundations, training strategies, and downstream clinical tasks. Additionally, a quantitative meta-analysis of the studies was conducted to characterize temporal trends in dataset utilization and application domains. We also critically discuss persistent challenges, including domain adaptation, efficient fine-tuning, computational constraints, and interpretability along with emerging solutions such as federated learning, knowledge distillation, and advanced prompting. Finally, we identify key future research directions aimed at enhancing the robustness, explainability, and clinical integration of FMs, thereby accelerating their translation into real-world medical practice.</li>
</ul>

<h3>Title: Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Shurong Lin, Aleksandra Slavković, Deekshith Reddy Bhoomireddy</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16974">https://arxiv.org/abs/2510.16974</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16974">https://arxiv.org/pdf/2510.16974</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16974]] Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees(https://arxiv.org/abs/2510.16974)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In social sciences, small- to medium-scale datasets are common and linear regression (LR) is canonical. In privacy-aware settings, much work has focused on differentially private (DP) LR, but mostly on point estimation with limited attention to uncertainty quantification. Meanwhile, synthetic data generation (SDG) is increasingly important for reproducibility studies, yet current DP LR methods do not readily support it. Mainstream SDG approaches are either tailored to discretized data, making them less suitable for continuous regression, or rely on deep models that require large datasets, limiting their use for the smaller, continuous data typical in social science. We propose a method for LR with valid inference under Gaussian DP: a DP bias-corrected estimator with asymptotic confidence intervals (CIs) and a general SDG procedure in which regression on the synthetic data matches our DP regression. Our binning-aggregation strategy is effective in small- to moderate-dimensional settings. Experiments show our method (1) improves accuracy over existing methods, (2) provides valid CIs, and (3) produces more reliable synthetic data for downstream ML tasks than current DP SDGs.</li>
</ul>

<h3>Title: Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision</h3>
<ul>
<li><strong>Authors: </strong>Kanghui Ning, Zijie Pan, Yushan Jiang, Anderson Schneider, Yuriy Nevmyvaka, Dongjin Song</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16980">https://arxiv.org/abs/2510.16980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16980">https://arxiv.org/pdf/2510.16980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16980]] Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision(https://arxiv.org/abs/2510.16980)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series reasoning is emerging as the next frontier in temporal analysis, aiming to move beyond pattern recognition towards explicit, interpretable, and trustworthy inference. This paper presents a BlueSky vision built on two complementary directions. One builds robust foundations for time series reasoning, centered on comprehensive temporal understanding, structured multi-step reasoning, and faithful evaluation frameworks. The other advances system-level reasoning, moving beyond language-only explanations by incorporating multi-agent collaboration, multi-modal context, and retrieval-augmented approaches. Together, these directions outline a flexible and extensible framework for advancing time series reasoning, aiming to deliver interpretable and trustworthy temporal intelligence across diverse domains.</li>
</ul>

<h3>Title: One-step Diffusion Models with Bregman Density Ratio Matching</h3>
<ul>
<li><strong>Authors: </strong>Yuanzhi Zhu, Eleftherios Tsonis, Lucas Degeorge, Vicky Kalogeiton</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16983">https://arxiv.org/abs/2510.16983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16983">https://arxiv.org/pdf/2510.16983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16983]] One-step Diffusion Models with Bregman Density Ratio Matching(https://arxiv.org/abs/2510.16983)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion and flow models achieve high generative quality but remain computationally expensive due to slow multi-step sampling. Distillation methods accelerate them by training fast student generators, yet most existing objectives lack a unified theoretical foundation. In this work, we propose Di-Bregman, a compact framework that formulates diffusion distillation as Bregman divergence-based density-ratio matching. This convex-analytic view connects several existing objectives through a common lens. Experiments on CIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves improved one-step FID over reverse-KL distillation and maintains high visual fidelity compared to the teacher model. Our results highlight Bregman density-ratio matching as a practical and theoretically-grounded route toward efficient one-step diffusion generation.</li>
</ul>

<h3>Title: Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection</h3>
<ul>
<li><strong>Authors: </strong>Akif Islam, Mohd Ruhul Ameen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16985">https://arxiv.org/abs/2510.16985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16985">https://arxiv.org/pdf/2510.16985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16985]] Parameter-Efficient Fine-Tuning for Low-Resource Languages: A Comparative Study of LLMs for Bengali Hate Speech Detection(https://arxiv.org/abs/2510.16985)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Bengali social media platforms have witnessed a sharp increase in hate speech, disproportionately affecting women and adolescents. While datasets such as BD-SHS provide a basis for structured evaluation, most prior approaches rely on either computationally costly full-model fine-tuning or proprietary APIs. This paper presents the first application of Parameter-Efficient Fine-Tuning (PEFT) for Bengali hate speech detection using LoRA and QLoRA. Three instruction-tuned large language models - Gemma-3-4B, Llama-3.2-3B, and Mistral-7B - were fine-tuned on the BD-SHS dataset of 50,281 annotated comments. Each model was adapted by training fewer than 1% of its parameters, enabling experiments on a single consumer-grade GPU. The results show that Llama-3.2-3B achieved the highest F1-score of 92.23%, followed by Mistral-7B at 88.94% and Gemma-3-4B at 80.25%. These findings establish PEFT as a practical and replicable strategy for Bengali and related low-resource languages.</li>
</ul>

<h3>Title: CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams</h3>
<ul>
<li><strong>Authors: </strong>Junhao Zhao, Zishuai Liu, Ruili Fang, Jin Lu, Linghan Zhang, Fei Dou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16988">https://arxiv.org/abs/2510.16988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16988">https://arxiv.org/pdf/2510.16988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16988]] CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams(https://arxiv.org/abs/2510.16988)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The recognition of Activities of Daily Living (ADLs) from event-triggered ambient sensors is an essential task in Ambient Assisted Living, yet existing methods remain constrained by representation-level limitations. Sequence-based approaches preserve temporal order of sensor activations but are sensitive to noise and lack spatial awareness, while image-based approaches capture global patterns and implicit spatial correlations but compress fine-grained temporal dynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation) fail to enforce alignment between sequence- and image-based representation views, underutilizing their complementary strengths. We propose Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an end-to-end framework that jointly optimizes representation learning via Sequence-Image Contrastive Alignment (SICA) and classification via cross-entropy, ensuring both cross-representation alignment and task-specific discriminability. CARE integrates (i) time-aware, noise-resilient sequence encoding with (ii) spatially-informed and frequency-sensitive image representations, and employs (iii) a joint contrastive-classification objective for end-to-end learning of aligned and discriminative embeddings. Evaluated on three CASAS datasets, CARE achieves state-of-the-art performance (89.8% on Milan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to sensor malfunctions and layout variability, highlighting its potential for reliable ADL recognition in smart homes.</li>
</ul>

<h3>Title: Training-free Online Video Step Grounding</h3>
<ul>
<li><strong>Authors: </strong>Luca Zanella, Massimiliano Mancini, Yiming Wang, Alessio Tonioni, Elisa Ricci</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16989">https://arxiv.org/abs/2510.16989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16989">https://arxiv.org/pdf/2510.16989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16989]] Training-free Online Video Step Grounding(https://arxiv.org/abs/2510.16989)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Given a task and a set of steps composing it, Video Step Grounding (VSG) aims to detect which steps are performed in a video. Standard approaches for this task require a labeled training set (e.g., with step-level annotations or narrations), which may be costly to collect. Moreover, they process the full video offline, limiting their applications for scenarios requiring online decisions. Thus, in this work, we explore how to perform VSG online and without training. We achieve this by exploiting the zero-shot capabilities of recent Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step associated with a restricted set of frames, without access to the whole video. We show that this online strategy without task-specific tuning outperforms offline and training-based models. Motivated by this finding, we develop Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting knowledge of past frames into the LMM-based predictions. BaGLM exploits Bayesian filtering principles, modeling step transitions via (i) a dependency matrix extracted through large language models and (ii) an estimation of step progress. Experiments on three datasets show superior performance of BaGLM over state-of-the-art training-based offline methods.</li>
</ul>

<h3>Title: Graph4MM: Weaving Multimodal Learning with Structural Information</h3>
<ul>
<li><strong>Authors: </strong>Xuying Ning, Dongqi Fu, Tianxin Wei, Wujiang Xu, Jingrui He</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.16990">https://arxiv.org/abs/2510.16990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.16990">https://arxiv.org/pdf/2510.16990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.16990]] Graph4MM: Weaving Multimodal Learning with Structural Information(https://arxiv.org/abs/2510.16990)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer, generative</a></li>
<li><strong>Abstract: </strong>Real-world multimodal data usually exhibit complex structural relationships beyond traditional one-to-one mappings like image-caption pairs. Entities across modalities interact in intricate ways, with images and text forming diverse interconnections through contextual dependencies and co-references. Graphs provide powerful structural information for modeling intra-modal and inter-modal relationships. However, previous works fail to distinguish multi-hop neighbors and treat the graph as a standalone modality, which fragments the overall understanding. This limitation presents two key challenges in multimodal learning: (1) integrating structural information from multi-hop neighbors into foundational models, and (2) fusing modality-specific information in a principled manner. To address these challenges, we revisit the role of graphs in multimodal learning within the era of foundation models and propose Graph4MM, a graph-based multimodal learning framework. To be specific, we introduce Hop-Diffused Attention, which integrates multi-hop structural information into self-attention through causal masking and hop diffusion. Furthermore, we design MM-QFormer, a multi-mapping querying transformer for cross-modal fusion. Through theoretical and empirical analysis, we show that leveraging structures to integrate both intra- and inter-modal interactions improves multimodal understanding beyond treating them as a standalone modality. Experiments on both generative and discriminative tasks show that Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines, achieving a 6.93% average improvement.</li>
</ul>

<h3>Title: Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs</h3>
<ul>
<li><strong>Authors: </strong>Masahiro Kaneko, Timothy Baldwin</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17000">https://arxiv.org/abs/2510.17000</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17000">https://arxiv.org/pdf/2510.17000</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17000]] Bits Leaked per Query: Information-Theoretic Bounds on Adversarial Attacks against LLMs(https://arxiv.org/abs/2510.17000)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack, large language model</a></li>
<li><strong>Abstract: </strong>Adversarial attacks by malicious users that threaten the safety of large language models (LLMs) can be viewed as attempts to infer a target property $T$ that is unknown when an instruction is issued, and becomes knowable only after the model's reply is observed. Examples of target properties $T$ include the binary flag that triggers an LLM's harmful response or rejection, and the degree to which information deleted by unlearning can be restored, both elicited via adversarial instructions. The LLM reveals an \emph{observable signal} $Z$ that potentially leaks hints for attacking through a response containing answer tokens, thinking process tokens, or logits. Yet the scale of information leaked remains anecdotal, leaving auditors without principled guidance and defenders blind to the transparency--risk trade-off. We fill this gap with an information-theoretic framework that computes how much information can be safely disclosed, and enables auditors to gauge how close their methods come to the fundamental limit. Treating the mutual information $I(Z;T)$ between the observation $Z$ and the target property $T$ as the leaked bits per query, we show that achieving error $\varepsilon$ requires at least $\log(1/\varepsilon)/I(Z;T)$ queries, scaling linearly with the inverse leak rate and only logarithmically with the desired accuracy. Thus, even a modest increase in disclosure collapses the attack cost from quadratic to logarithmic in terms of the desired accuracy. Experiments on seven LLMs across system-prompt leakage, jailbreak, and relearning attacks corroborate the theory: exposing answer tokens alone requires about a thousand queries; adding logits cuts this to about a hundred; and revealing the full thinking process trims it to a few dozen. Our results provide the first principled yardstick for balancing transparency and security when deploying LLMs.</li>
</ul>

<h3>Title: Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic</h3>
<ul>
<li><strong>Authors: </strong>Yuval Reif, Guy Kaplan, Roy Schwartz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17001">https://arxiv.org/abs/2510.17001</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17001">https://arxiv.org/pdf/2510.17001</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17001]] Vocab Diet: Reshaping the Vocabulary of LLMs with Vector Arithmetic(https://arxiv.org/abs/2510.17001)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) were shown to encode word form variations, such as "walk"->"walked", as linear directions in embedding space. However, standard tokenization algorithms treat these variations as distinct tokens -- filling the size-capped vocabulary with surface form variants (e.g., "walk", "walking", "Walk"), at the expense of less frequent words and multilingual coverage. We show that many of these variations can be captured by transformation vectors -- additive offsets that yield the appropriate word's representation when applied to the base form word embedding -- in both the input and output spaces. Building on this, we propose a compact reshaping of the vocabulary: rather than assigning unique tokens to each surface form, we compose them from shared base form and transformation vectors (e.g., "walked" = "walk" + past tense). We apply our approach to multiple LLMs and across five languages, removing up to 10% of vocabulary entries -- thereby freeing space to allocate new, more diverse tokens. Importantly, we do so while also expanding vocabulary coverage to out-of-vocabulary words, with minimal impact on downstream performance, and without modifying model weights. Our findings motivate a foundational rethinking of vocabulary design, moving from string enumeration to a compositional vocabulary that leverages the underlying structure of language.</li>
</ul>

<h3>Title: EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of Analog Circuit</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Danial Chitnis</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17002">https://arxiv.org/abs/2510.17002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17002">https://arxiv.org/pdf/2510.17002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17002]] EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of Analog Circuit(https://arxiv.org/abs/2510.17002)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Circuit schematics play a crucial role in analog integrated circuit design, serving as the primary medium for human understanding and verification of circuit functionality. While recent large language model (LLM)-based approaches have shown promise in circuit topology generation and device sizing, most rely solely on textual representations such as SPICE netlists, which lack visual interpretability for circuit designers. To address this limitation, we propose EEschematic, an AI agent for automatic analog schematic generation based on a Multimodal Large Language Model (MLLM). EEschematic integrates textual, visual, and symbolic modalities to translate SPICE netlists into schematic diagrams represented in a human-editable format. The framework uses six analog substructure examples for few-shot placement and a Visual Chain-of-Thought (VCoT) strategy to iteratively refine placement and wiring, enhancing schematic clarity and symmetry. Experimental results on representative analog circuits, including a CMOS inverter, a five-transistor operational transconductance amplifier (5T-OTA), and a telescopic cascode amplifier, demonstrate that EEschematic produces schematics with high visual quality and structural correctness.</li>
</ul>

<h3>Title: Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization</h3>
<ul>
<li><strong>Authors: </strong>Masahiro Kaneko, Zeerak Talat, Timothy Baldwin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17006">https://arxiv.org/abs/2510.17006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17006">https://arxiv.org/pdf/2510.17006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17006]] Online Learning Defense against Iterative Jailbreak Attacks via Prompt Optimization(https://arxiv.org/abs/2510.17006)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, large language model</a></li>
<li><strong>Abstract: </strong>Iterative jailbreak methods that repeatedly rewrite and input prompts into large language models (LLMs) to induce harmful outputs -- using the model's previous responses to guide each new iteration -- have been found to be a highly effective attack strategy. Despite being an effective attack strategy against LLMs and their safety mechanisms, existing defenses do not proactively disrupt this dynamic trial-and-error cycle. In this study, we propose a novel framework that dynamically updates its defense strategy through online learning in response to each new prompt from iterative jailbreak methods. Leveraging the distinctions between harmful jailbreak-generated prompts and typical harmless prompts, we introduce a reinforcement learning-based approach that optimizes prompts to ensure appropriate responses for harmless tasks while explicitly rejecting harmful prompts. Additionally, to curb overfitting to the narrow band of partial input rewrites explored during an attack, we introduce Past-Direction Gradient Damping (PDGD). Experiments conducted on three LLMs show that our approach significantly outperforms five existing defense methods against five iterative jailbreak methods. Moreover, our results indicate that our prompt optimization strategy simultaneously enhances response quality for harmless tasks.</li>
</ul>

<h3>Title: An empirical study of the effect of video encoders on Temporal Video Grounding</h3>
<ul>
<li><strong>Authors: </strong>Ignacio M. De la Jara, Cristian Rodriguez-Opazo, Edison Marrese-Taylor, Felipe Bravo-Marquez</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17007">https://arxiv.org/abs/2510.17007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17007">https://arxiv.org/pdf/2510.17007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17007]] An empirical study of the effect of video encoders on Temporal Video Grounding(https://arxiv.org/abs/2510.17007)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Temporal video grounding is a fundamental task in computer vision, aiming to localize a natural language query in a long, untrimmed video. It has a key role in the scientific community, in part due to the large amount of video generated every day. Although we find extensive work in this task, we note that research remains focused on a small selection of video representations, which may lead to architectural overfitting in the long run. To address this issue, we propose an empirical study to investigate the impact of different video features on a classical architecture. We extract features for three well-known benchmarks, Charades-STA, ActivityNet-Captions and YouCookII, using video encoders based on CNNs, temporal reasoning and transformers. Our results show significant differences in the performance of our model by simply changing the video encoder, while also revealing clear patterns and errors derived from the use of certain features, ultimately indicating potential feature complementarity.</li>
</ul>

<h3>Title: DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking</h3>
<ul>
<li><strong>Authors: </strong>Lanni Bu, Lauren Levin, Amir Zeldes</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17013">https://arxiv.org/abs/2510.17013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17013">https://arxiv.org/pdf/2510.17013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17013]] DiscoTrack: A Multilingual LLM Benchmark for Discourse Tracking(https://arxiv.org/abs/2510.17013)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Recent LLM benchmarks have tested models on a range of phenomena, but are still focused primarily on natural language understanding for extraction of explicit information, such as QA or summarization, with responses often tar- geting information from individual sentences. We are still lacking more challenging, and im- portantly also multilingual, benchmarks focus- ing on implicit information and pragmatic infer- ences across larger documents in the context of discourse tracking: integrating and aggregating information across sentences, paragraphs and multiple speaker utterances. To this end, we present DiscoTrack, an LLM benchmark target- ing a range of tasks across 12 languages and four levels of discourse understanding: salience recognition, entity tracking, discourse relations and bridging inference. Our evaluation shows that these tasks remain challenging, even for state-of-the-art models.</li>
</ul>

<h3>Title: Do Satellite Tasks Need Special Pretraining?</h3>
<ul>
<li><strong>Authors: </strong>Ani Vanyan, Alvard Barseghyan, Hakob Tamazyan, Tigran Galstyan, Vahan Huroyan, Naira Hovakimyan, Hrant Khachatrian</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17014">https://arxiv.org/abs/2510.17014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17014">https://arxiv.org/pdf/2510.17014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17014]] Do Satellite Tasks Need Special Pretraining?(https://arxiv.org/abs/2510.17014)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Foundation models have advanced machine learning across various modalities, including images. Recently multiple teams trained foundation models specialized for remote sensing applications. This line of research is motivated by the distinct characteristics of remote sensing imagery, specific applications and types of robustness useful for satellite image analysis. In this work we systematically challenge the idea that specific foundation models are more useful than general-purpose vision foundation models, at least in the small scale. First, we design a simple benchmark that measures generalization of remote sensing models towards images with lower resolution for two downstream tasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID, an ImageNet-scale satellite imagery dataset, with several modifications specific to remote sensing. We show that none of those pretrained models bring consistent improvements upon general-purpose baselines at the ViT-B scale.</li>
</ul>

<h3>Title: Justitia: Fair and Efficient Scheduling for LLM Applications</h3>
<ul>
<li><strong>Authors: </strong>Mingyan Yang, Guanjie Wang, Manqi Luo, Yifei Liu, Chen Chen, Han Zhao, Yu Feng, Quan Chen, Minyi Guo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17015">https://arxiv.org/abs/2510.17015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17015">https://arxiv.org/pdf/2510.17015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17015]] Justitia: Fair and Efficient Scheduling for LLM Applications(https://arxiv.org/abs/2510.17015)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, large language model</a></li>
<li><strong>Abstract: </strong>In the era of Large Language Models (LLMs), it has been popular to launch a series of LLM inferences -- we call an LLM application -- to better solve real-world problems. When serving those applications in shared GPU servers, the schedulers are expected to attain fast application completions with guaranteed worst-case performance. However, mainstream LLM schedulers fail to behave well for LLM applications -- due to head-of-line blocking or over-constrained resource allocation. In this paper, we propose to serve LLM applications in a fair and also efficient manner. To this end, we design Justitia, a novel scheduler with three key techniques. First, given that memory is prevalently a bottleneck for mainstream inference frameworks like vLLM, Justitia models the service cost of LLM applications in a memory-centric manner. Meanwhile, it uses a simple neural network model to conduct light-weight and also accurate demand prediction. Moreover, Justitia adopts a virtual-time based fair queuing algorithm to reduce the overall performance with guaranteed worst-case delay. We have implemented Justitia atop vLLM, and experimental results involving diverse LLM applications show that it can substantially enhance the scheduling efficiency with fairness preserved.</li>
</ul>

<h3>Title: SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents</h3>
<ul>
<li><strong>Authors: </strong>Qiusi Zhan, Angeline Budiman-Chan, Abdelrahman Zayed, Xingzhi Guo, Daniel Kang, Joo-Kyung Kim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17017">https://arxiv.org/abs/2510.17017</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17017">https://arxiv.org/pdf/2510.17017</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17017]] SafeSearch: Do Not Trade Safety for Utility in LLM Search Agents(https://arxiv.org/abs/2510.17017)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) based search agents iteratively generate queries, retrieve external information, and reason to answer open-domain questions. While researchers have primarily focused on improving their utility, their safety behaviors remain underexplored. In this paper, we first evaluate search agents using red-teaming datasets and find that they are more likely to produce harmful outputs than base LLMs. For example, when asked ``How can I track someone's location without their consent?'', a base model refuses, whereas a search agent designed to retrieve and cite sources may lower its refusal threshold, fetch documents (e.g., court cases), and, once appended, synthesize them into an informative yet unsafe summary. We further show that utility-oriented fine-tuning intensifies this risk, motivating joint alignment of safety and utility. We present SafeSearch, a multi-objective reinforcement learning approach that couples a final-output safety/utility reward with a novel query-level shaping term that penalizes unsafe queries and rewards safe ones. Experiments show that SafeSearch reduces agent harmfulness by over 70% across three red-teaming datasets while producing safe, helpful responses, and matches the QA performance of a utility-only finetuned agent; further analyses confirm the effectiveness of the query-level reward in jointly improving safety and utility.</li>
</ul>

<h3>Title: Extended LSTM: Adaptive Feature Gating for Toxic Comment Classification</h3>
<ul>
<li><strong>Authors: </strong>Noor Islam S. Mohammad</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17018">https://arxiv.org/abs/2510.17018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17018">https://arxiv.org/pdf/2510.17018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17018]] Extended LSTM: Adaptive Feature Gating for Toxic Comment Classification(https://arxiv.org/abs/2510.17018)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Toxic comment detection remains a challenging task, where transformer-based models (e.g., BERT) incur high computational costs and degrade on minority toxicity classes, while classical ensembles lack semantic adaptability. We propose xLSTM, a parameter-efficient and theoretically grounded framework that unifies cosine-similarity gating, adaptive feature prioritization, and principled class rebalancing. A learnable reference vector {v} in {R}^d modulates contextual embeddings via cosine similarity, amplifying toxic cues and attenuating benign signals to yield stronger gradients under severe class imbalance. xLSTM integrates multi-source embeddings (GloVe, FastText, BERT CLS) through a projection layer, a character-level BiLSTM for morphological cues, embedding-space SMOTE for minority augmentation, and adaptive focal loss with dynamic class weighting. On the Jigsaw Toxic Comment benchmark, xLSTM attains 96.0% accuracy and 0.88 macro-F1, outperforming BERT by 33% on threat and 28% on identity_hate categories, with 15 times fewer parameters and 50ms inference latency. Cosine gating contributes a +4.8% F1 gain in ablations. The results establish a new efficiency adaptability frontier, demonstrating that lightweight, theoretically informed architectures can surpass large pretrained models on imbalanced, domain-specific NLP tasks.</li>
</ul>

<h3>Title: Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Bingqi Shang, Yiwei Chen, Yihua Zhang, Bingquan Shen, Sijia Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17021">https://arxiv.org/abs/2510.17021</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17021">https://arxiv.org/pdf/2510.17021</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17021]] Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning(https://arxiv.org/abs/2510.17021)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) unlearning has become a critical mechanism for removing undesired data, knowledge, or behaviors from pre-trained models while retaining their general utility. Yet, with the rise of open-weight LLMs, we ask: can the unlearning process itself be backdoored, appearing successful under normal conditions yet reverting to pre-unlearned behavior when a hidden trigger is activated? Drawing inspiration from classical backdoor attacks that embed triggers into training data to enforce specific behaviors, we investigate backdoor unlearning, where models forget as intended in the clean setting but recover forgotten knowledge when the trigger appears. We show that designing such attacks presents unique challenges, hinging on where triggers are placed and how backdoor training is reinforced. We uncover a strong link between backdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens consistently attract disproportionate attention in LLMs. Our analysis reveals that these attention sinks serve as gateways for backdoor unlearning: placing triggers at sink positions and aligning their attention values markedly enhances backdoor persistence. Extensive experiments validate these findings, showing that attention-sink-guided backdoor unlearning reliably restores forgotten knowledge in the presence of backdoor triggers, while behaving indistinguishably from a normally unlearned model when triggers are absent. Code is available at this https URL.</li>
</ul>

<h3>Title: Enrich and Detect: Video Temporal Grounding with Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Shraman Pramanick, Effrosyni Mavroudi, Yale Song, Rama Chellappa, Lorenzo Torresani, Triantafyllos Afouras</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17023">https://arxiv.org/abs/2510.17023</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17023">https://arxiv.org/pdf/2510.17023</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17023]] Enrich and Detect: Video Temporal Grounding with Multimodal LLMs(https://arxiv.org/abs/2510.17023)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce ED-VTG, a method for fine-grained video temporal grounding utilizing multi-modal large language models. Our approach harnesses the capabilities of multimodal LLMs to jointly process text and video, in order to effectively localize natural language queries in videos through a two-stage process. Rather than being directly grounded, language queries are initially transformed into enriched sentences that incorporate missing details and cues to aid in grounding. In the second stage, these enriched queries are grounded, using a lightweight decoder, which specializes at predicting accurate boundaries conditioned on contextualized representations of the enriched queries. To mitigate noise and reduce the impact of hallucinations, our model is trained with a multiple-instance-learning objective that dynamically selects the optimal version of the query for each training sample. We demonstrate state-of-the-art results across various benchmarks in temporal video grounding and paragraph grounding settings. Experiments reveal that our method significantly outperforms all previously proposed LLM-based temporal grounding approaches and is either superior or comparable to specialized models, while maintaining a clear advantage against them in zero-shot evaluation scenarios.</li>
</ul>

<h3>Title: Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kyle Cox, Jiawei Xu, Yikun Han, Rong Xu, Tianhao Li, Chi-Yang Hsu, Tianlong Chen, Walter Gerych, Ying Ding</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17028">https://arxiv.org/abs/2510.17028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17028">https://arxiv.org/pdf/2510.17028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17028]] Mapping from Meaning: Addressing the Miscalibration of Prompt-Sensitive Language Models(https://arxiv.org/abs/2510.17028)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>An interesting behavior in large language models (LLMs) is prompt sensitivity. When provided with different but semantically equivalent versions of the same prompt, models may produce very different distributions of answers. This suggests that the uncertainty reflected in a model's output distribution for one prompt may not reflect the model's uncertainty about the meaning of the prompt. We model prompt sensitivity as a type of generalization error, and show that sampling across the semantic ``concept space'' with paraphrasing perturbations improves uncertainty calibration without compromising accuracy. Additionally, we introduce a new metric for uncertainty decomposition in black-box LLMs that improves upon entropy-based decomposition by modeling semantic continuities in natural language generation. We show that this decomposition metric can be used to quantify how much LLM uncertainty is attributed to prompt sensitivity. Our work introduces a new way to improve uncertainty calibration in prompt-sensitive language models, and provides evidence that some LLMs fail to exhibit consistent general reasoning about the meanings of their inputs.</li>
</ul>

<h3>Title: Watermark Robustness and Radioactivity May Be at Odds in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Leixu Huang, Zedian Shao, Teodora Baluta</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17033">https://arxiv.org/abs/2510.17033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17033">https://arxiv.org/pdf/2510.17033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17033]] Watermark Robustness and Radioactivity May Be at Odds in Federated Learning(https://arxiv.org/abs/2510.17033)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, watermark, large language model</a></li>
<li><strong>Abstract: </strong>Federated learning (FL) enables fine-tuning large language models (LLMs) across distributed data sources. As these sources increasingly include LLM-generated text, provenance tracking becomes essential for accountability and transparency. We adapt LLM watermarking for data provenance in FL where a subset of clients compute local updates on watermarked data, and the server averages all updates into the global LLM. In this setup, watermarks are radioactive: the watermark signal remains detectable after fine-tuning with high confidence. The $p$-value can reach $10^{-24}$ even when as little as $6.6\%$ of data is watermarked. However, the server can act as an active adversary that wants to preserve model utility while evading provenance tracking. Our observation is that updates induced by watermarked synthetic data appear as outliers relative to non-watermark updates. Our adversary thus applies strong robust aggregation that can filter these outliers, together with the watermark signal. All evaluated radioactive watermarks are not robust against such an active filtering server. Our work suggests fundamental trade-offs between radioactivity, robustness, and utility.</li>
</ul>

<h3>Title: Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding</h3>
<ul>
<li><strong>Authors: </strong>Yutong Zhong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17034">https://arxiv.org/abs/2510.17034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17034">https://arxiv.org/pdf/2510.17034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17034]] Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding(https://arxiv.org/abs/2510.17034)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal 3D grounding has garnered considerable interest in Vision-Language Models (VLMs) \cite{yin2025spatial} for advancing spatial reasoning in complex environments. However, these models suffer from a severe "2D semantic bias" that arises from over-reliance on 2D image features for coarse localization, largely disregarding 3D geometric inputs and resulting in suboptimal fusion performance. In this paper, we propose a novel training framework called What-Where Representation Re-Forming (W2R2) to tackle this issue via disentangled representation learning and targeted shortcut suppression. Our approach fundamentally reshapes the model's internal space by designating 2D features as semantic beacons for "What" identification and 3D features as spatial anchors for "Where" localization, enabling precise 3D grounding without modifying inference architecture. Key components include a dual-objective loss function with an Alignment Loss that supervises fused predictions using adapted cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes overly effective 2D-dominant pseudo-outputs via a margin-based mechanism. Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of W2R2, with significant gains in localization accuracy and robustness, particularly in cluttered outdoor scenes.</li>
</ul>

<h3>Title: Conditional Synthetic Live and Spoof Fingerprint Generation</h3>
<ul>
<li><strong>Authors: </strong>Syed Konain Abbas, Sandip Purnapatra, M. G. Sarwar Murshed, Conor Miller-Lynch, Lambert Igene, Soumyabrata Dey, Stephanie Schuckers, Faraz Hussain</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17035">https://arxiv.org/abs/2510.17035</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17035">https://arxiv.org/pdf/2510.17035</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17035]] Conditional Synthetic Live and Spoof Fingerprint Generation(https://arxiv.org/abs/2510.17035)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, robust, biometric, generative</a></li>
<li><strong>Abstract: </strong>Large fingerprint datasets, while important for training and evaluation, are time-consuming and expensive to collect and require strict privacy measures. Researchers are exploring the use of synthetic fingerprint data to address these issues. This paper presents a novel approach for generating synthetic fingerprint images (both spoof and live), addressing concerns related to privacy, cost, and accessibility in biometric data collection. Our approach utilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce high-resolution synthetic live fingerprints, conditioned on specific finger identities (thumb through little finger). Additionally, we employ CycleGANs to translate these into realistic spoof fingerprints, simulating a variety of presentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof fingerprints are crucial for developing robust spoof detection systems. Through these generative models, we created two synthetic datasets (DB2 and DB3), each containing 1,500 fingerprint images of all ten fingers with multiple impressions per finger, and including corresponding spoofs in eight material types. The results indicate robust performance: our StyleGAN3 model achieves a Fréchet Inception Distance (FID) as low as 5, and the generated fingerprints achieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The StyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess fingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably, matching experiments confirm strong privacy preservation, with no significant evidence of identity leakage, confirming the strong privacy-preserving properties of our synthetic datasets.</li>
</ul>

<h3>Title: Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation</h3>
<ul>
<li><strong>Authors: </strong>Nguyen Do, Bach Ngo, Youval Kashuv, Canh V. Pham, Hanghang Tong, My T. Thai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17036">https://arxiv.org/abs/2510.17036</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17036">https://arxiv.org/pdf/2510.17036</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17036]] Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation(https://arxiv.org/abs/2510.17036)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We study the Quality of Service Degradation (QoSD) problem, in which an adversary perturbs edge weights to degrade network performance. This setting arises in both network infrastructures and distributed ML systems, where communication quality, not just connectivity, determines functionality. While classical methods rely on combinatorial optimization, and recent ML approaches address only restricted linear variants with small-size networks, no prior model directly tackles the QoSD problem under nonlinear edge-weight functions. This work proposes \PIMMA, a self-reinforcing generative framework that synthesizes feasible solutions in latent space, to fill this gap. Our method includes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm that uses graph learning and approximation to produce feasible solutions with performance guarantee, (2) Morph: a new theoretically grounded training paradigm for Mixture of Conditional VAEs guided by an energy-based model to capture solution feature distributions, and (3) Refine: a reinforcement learning agent that explores this space to generate progressively near-optimal solutions using our designed differentiable reward function. Experiments on both synthetic and real-world networks show that our approach consistently outperforms classical and ML baselines, particularly in scenarios with nonlinear cost functions where traditional methods fail to generalize.</li>
</ul>

<h3>Title: Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework</h3>
<ul>
<li><strong>Authors: </strong>Mohammad R. Salmanpour, Sonya Falahati, Amir Hossein Pouria, Amin Mousavi, Somayeh Sadat Mehrnia, Morteza Alizadeh, Arman Gorji, Zeinab Farsangi, Alireza Safarian, Mehdi Maghsudi, Carlos Uribe, Arman Rahmim, Ren Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17039">https://arxiv.org/abs/2510.17039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17039">https://arxiv.org/pdf/2510.17039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17039]] Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework(https://arxiv.org/abs/2510.17039)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Lung cancer remains the leading cause of cancer mortality, with CT imaging central to screening, prognosis, and treatment. Manual segmentation is variable and time-intensive, while deep learning (DL) offers automation but faces barriers to clinical adoption. Guided by the Knowledge-to-Action framework, this study develops a clinician-in-the-loop DL pipeline to enhance reproducibility, prognostic accuracy, and clinical trust. Multi-center CT data from 999 patients across 12 public datasets were analyzed using five DL models (3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against expert contours on whole and click-point cropped images. Segmentation reproducibility was assessed using 497 PySERA-extracted radiomic features via Spearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic modeling compared supervised (SL) and semi-supervised learning (SSL) across 38 dimensionality reduction strategies and 24 classifiers. Six physicians qualitatively evaluated masks across seven domains, including clinical meaningfulness, boundary quality, prognostic value, trust, and workflow integration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71), radiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive accuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed SL across models. Radiologists favored VNet for peritumoral representation and smoother boundaries, preferring AI-generated initial masks for refinement rather than replacement. These results demonstrate that integrating VNet with SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer prognosis, highlighting a feasible path toward physician-centered AI translation.</li>
</ul>

<h3>Title: Person Re-Identification via Generalized Class Prototypes</h3>
<ul>
<li><strong>Authors: </strong>Md Ahmed Al Muzaddid, William J. Beksi</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17043">https://arxiv.org/abs/2510.17043</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17043">https://arxiv.org/pdf/2510.17043</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17043]] Person Re-Identification via Generalized Class Prototypes(https://arxiv.org/abs/2510.17043)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Advanced feature extraction methods have significantly contributed to enhancing the task of person re-identification. In addition, modifications to objective functions have been developed to further improve performance. Nonetheless, selecting better class representatives is an underexplored area of research that can also lead to advancements in re-identification performance. Although past works have experimented with using the centroid of a gallery image class during training, only a few have investigated alternative representations during the retrieval stage. In this paper, we demonstrate that these prior techniques yield suboptimal results in terms of re-identification metrics. To address the re-identification problem, we propose a generalized selection method that involves choosing representations that are not limited to class centroids. Our approach strikes a balance between accuracy and mean average precision, leading to improvements beyond the state of the art. For example, the actual number of representations per class can be adjusted to meet specific application requirements. We apply our methodology on top of multiple re-identification embeddings, and in all cases it substantially improves upon contemporary results</li>
</ul>

<h3>Title: How Universal Are SAM2 Features?</h3>
<ul>
<li><strong>Authors: </strong>Masoud Khairi Atani, Alon Harell, Hyomin Choi, Runyu Yang, Fabien Racape, Ivan V. Bajic</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17051">https://arxiv.org/abs/2510.17051</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17051">https://arxiv.org/pdf/2510.17051</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17051]] How Universal Are SAM2 Features?(https://arxiv.org/abs/2510.17051)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The trade-off between general-purpose foundation vision models and their specialized counterparts is critical for efficient feature coding design and is not yet fully understood. We investigate this trade-off by comparing the feature versatility of the general-purpose Hiera encoder against the segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight, trainable neck to probe the adaptability of their frozen features, we quantify the information-theoretic cost of specialization. Our results reveal that while SAM2's specialization is highly effective for spatially-related tasks like depth estimation, it comes at a cost. The specialized SAM2 encoder underperforms its generalist predecessor, Hiera, on conceptually distant tasks such as pose estimation and image captioning, demonstrating a measurable loss of broader semantic information. A novel cross-neck analysis on SAM2 reveals that each level of adaptation creates a further representational bottleneck. Our analysis illuminates these trade-offs in feature universality, providing a quantitative foundation for designing efficient feature coding and adaptation strategies for diverse downstream applications.</li>
</ul>

<h3>Title: Consistent Zero-Shot Imitation with Contrastive Goal Inference</h3>
<ul>
<li><strong>Authors: </strong>Kathryn Wantlin, Chongyi Zheng, Benjamin Eysenbach</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17059">https://arxiv.org/abs/2510.17059</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17059">https://arxiv.org/pdf/2510.17059</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17059]] Consistent Zero-Shot Imitation with Contrastive Goal Inference(https://arxiv.org/abs/2510.17059)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the same way that generative models today conduct most of their training in a self-supervised fashion, how can agentic models conduct their training in a self-supervised fashion, interactively exploring, learning, and preparing to quickly adapt to new tasks? A prerequisite for embodied agents deployed in real world interactions ought to be training with interaction, yet today's most successful AI models (e.g., VLMs, LLMs) are trained without an explicit notion of action. The problem of pure exploration (which assumes no data as input) is well studied in the reinforcement learning literature and provides agents with a wide array of experiences, yet it fails to prepare them for rapid adaptation to new tasks. Today's language and vision models are trained on data provided by humans, which provides a strong inductive bias for the sorts of tasks that the model will have to solve (e.g., modeling chords in a song, phrases in a sonnet, sentences in a medical record). However, when they are prompted to solve a new task, there is a faulty tacit assumption that humans spend most of their time in the most rewarding states. The key contribution of our paper is a method for pre-training interactive agents in a self-supervised fashion, so that they can instantly mimic human demonstrations. Our method treats goals (i.e., observations) as the atomic construct. During training, our method automatically proposes goals and practices reaching them, building off prior work in reinforcement learning exploration. During evaluation, our method solves an (amortized) inverse reinforcement learning problem to explain demonstrations as optimal goal-reaching behavior. Experiments on standard benchmarks (not designed for goal-reaching) show that our approach outperforms prior methods for zero-shot imitation.</li>
</ul>

<h3>Title: Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation</h3>
<ul>
<li><strong>Authors: </strong>Guoqing Luo, Iffat Maab, Lili Mou, Junichi Yamagishi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17062">https://arxiv.org/abs/2510.17062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17062">https://arxiv.org/pdf/2510.17062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17062]] Investigating Thinking Behaviours of Reasoning-Based Language Models for Social Bias Mitigation(https://arxiv.org/abs/2510.17062)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>While reasoning-based large language models excel at complex tasks through an internal, structured thinking process, a concerning phenomenon has emerged that such a thinking process can aggregate social stereotypes, leading to biased outcomes. However, the underlying behaviours of these language models in social bias scenarios remain underexplored. In this work, we systematically investigate mechanisms within the thinking process behind this phenomenon and uncover two failure patterns that drive social bias aggregation: 1) stereotype repetition, where the model relies on social stereotypes as its primary justification, and 2) irrelevant information injection, where it fabricates or introduces new details to support a biased narrative. Building on these insights, we introduce a lightweight prompt-based mitigation approach that queries the model to review its own initial reasoning against these specific failure patterns. Experiments on question answering (BBQ and StereoSet) and open-ended (BOLD) benchmarks show that our approach effectively reduces bias while maintaining or improving accuracy.</li>
</ul>

<h3>Title: Towards a Generalizable Fusion Architecture for Multimodal Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Jad Berjawi, Yoann Dupas, Christophe C'erin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17078">https://arxiv.org/abs/2510.17078</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17078">https://arxiv.org/pdf/2510.17078</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17078]] Towards a Generalizable Fusion Architecture for Multimodal Object Detection(https://arxiv.org/abs/2510.17078)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Multimodal object detection improves robustness in chal- lenging conditions by leveraging complementary cues from multiple sensor modalities. We introduce Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing architecture designed to enhance the fusion of RGB and infrared (IR) inputs. FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress redun- dant spectral features with a cross-attention-based fusion module (MCAF) to improve intermodal feature sharing. Unlike approaches tailored to specific datasets, FMCAF aims for generalizability, improving performance across different multimodal challenges without requiring dataset- specific tuning. On LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection), FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50 on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a flexible foundation for robust multimodal fusion in future detection pipelines.</li>
</ul>

<h3>Title: Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability</h3>
<ul>
<li><strong>Authors: </strong>Ziqing Zhu</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17087">https://arxiv.org/abs/2510.17087</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17087">https://arxiv.org/pdf/2510.17087</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17087]] Quantum Key Distribution for Virtual Power Plant Communication: A Lightweight Key-Aware Scheduler with Provable Stability(https://arxiv.org/abs/2510.17087)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, protect</a></li>
<li><strong>Abstract: </strong>Virtual power plants (VPPs) are becoming a cornerstone of future grids, aggregating distributed PV, wind, storage, and flexible loads for market participation and real-time balancing. As operations move to minute-- and second--level feedback, communication security shifts from a compliance item to an operational constraint: latency, reliability, and confidentiality jointly determine whether dispatch, protection, and settlement signals arrive on time. Conventional PKI and key-rotation schemes struggle with cross-domain, high-frequency messaging and face long-term quantum threats. Quantum key distribution (QKD) offers information-theoretic key freshness, but its key yield is scarce and stochastic, often misaligned with bursty VPP traffic. This paper proposes a key-aware priority and quota framework that treats quantum keys as first-class scheduling resources. The design combines (i) forecast-driven long-term quotas and short-term tokens, (ii) key-aware deficit-round-robin arbitration, (iii) a preemptive emergency key reserve, and (iv) graceful degradation via encryption-mode switching and controlled down-sampling for non-critical traffic. A drift-plus-penalty analysis establishes strong stability under average supply--demand balance with quantifiable bounds on backlog and tail latency, providing interpretable operating guarantees. We build a reproducible testbed on IEEE 33- and 123-bus VPP systems and evaluate normal, degraded, and outage regimes with industry-consistent message classes and TTLs. Against FIFO, fixed-priority, and static-quota baselines, the proposed scheme consistently reduces tail delay and passive timeouts for critical messages, improves per-bit key utility, and enhances power-tracking reliability during key scarcity and regime switches.</li>
</ul>

<h3>Title: Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing</h3>
<ul>
<li><strong>Authors: </strong>Zan Li, Rui Fan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17088">https://arxiv.org/abs/2510.17088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17088">https://arxiv.org/pdf/2510.17088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17088]] Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing(https://arxiv.org/abs/2510.17088)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity freezes, contagion cascades, regime shifts), but existing detectors treat all anomalies uniformly, producing scalar scores without revealing which mechanism is failing, where risks concentrate, or how to intervene. This opacity prevents targeted regulatory responses. Three unsolved challenges persist: (1) static graph structures cannot adapt when market correlations shift during regime changes; (2) uniform detection mechanisms miss type-specific signatures across multiple temporal scales while failing to integrate individual behaviors with network contagion; (3) black-box outputs provide no actionable guidance on anomaly mechanisms or their temporal evolution. We address these via adaptive graph learning with specialized expert networks that provide built-in interpretability. Our framework captures multi-scale temporal dependencies through BiLSTM with self-attention, fuses temporal and spatial information via cross-modal attention, learns dynamic graphs through neural multi-source interpolation, adaptively balances learned dynamics with structural priors via stress-modulated fusion, routes anomalies to four mechanism-specific experts, and produces dual-level interpretable attributions. Critically, interpretability is embedded architecturally rather than applied post-hoc. On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events with 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley Bank case study demonstrates anomaly evolution tracking: Price-Shock expert weight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48 (66% above baseline) one week later, revealing automatic temporal mechanism identification without labeled supervision.</li>
</ul>

<h3>Title: GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation</h3>
<ul>
<li><strong>Authors: </strong>Ruitong Gan, Junran Peng, Yang Liu, Chuanchen Luo, Qing Li, Zhaoxiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17095">https://arxiv.org/abs/2510.17095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17095">https://arxiv.org/pdf/2510.17095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17095]] GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation(https://arxiv.org/abs/2510.17095)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>Planes are fundamental primitives of 3D sences, especially in man-made environments such as indoor spaces and urban streets. Representing these planes in a structured and parameterized format facilitates scene editing and physical simulations in downstream applications. Recently, Gaussian Splatting (GS) has demonstrated remarkable effectiveness in the Novel View Synthesis task, with extensions showing great potential in accurate surface reconstruction. However, even state-of-the-art GS representations often struggle to reconstruct planar regions with sufficient smoothness and precision. To address this issue, we propose GSPlane, which recovers accurate geometry and produces clean and well-structured mesh connectivity for plane regions in the reconstructed scene. By leveraging off-the-shelf segmentation and normal prediction models, GSPlane extracts robust planar priors to establish structured representations for planar Gaussian coordinates, which help guide the training process by enforcing geometric consistency. To further enhance training robustness, a Dynamic Gaussian Re-classifier is introduced to adaptively reclassify planar Gaussians with persistently high gradients as non-planar, ensuring more reliable optimization. Furthermore, we utilize the optimized planar priors to refine the mesh layouts, significantly improving topological structure while reducing the number of vertices and faces. We also explore applications of the structured planar representation, which enable decoupling and flexible manipulation of objects on supportive planes. Extensive experiments demonstrate that, with no sacrifice in rendering quality, the introduction of planar priors significantly improves the geometric accuracy of the extracted meshes across various baselines.</li>
</ul>

<h3>Title: Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Elias Hossain, Swayamjit Saha, Somshubhra Roy, Ravi Prasad</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17098">https://arxiv.org/abs/2510.17098</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17098">https://arxiv.org/pdf/2510.17098</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17098]] Can Transformer Memory Be Corrupted? Investigating Cache-Side Vulnerabilities in Large Language Models(https://arxiv.org/abs/2510.17098)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack, robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Even when prompts and parameters are secured, transformer language models remain vulnerable because their key-value (KV) cache during inference constitutes an overlooked attack surface. This paper introduces Malicious Token Injection (MTI), a modular framework that systematically perturbs cached key vectors at selected layers and timesteps through controlled magnitude and frequency, using additive Gaussian noise, zeroing, and orthogonal rotations. A theoretical analysis quantifies how these perturbations propagate through attention, linking logit deviations to the Frobenius norm of corruption and softmax Lipschitz dynamics. Empirical results show that MTI significantly alters next-token distributions and downstream task performance across GPT-2 and LLaMA-2/7B, as well as destabilizes retrieval-augmented and agentic reasoning pipelines. These findings identify cache integrity as a critical yet underexplored vulnerability in current LLM deployments, positioning cache corruption as a reproducible and theoretically grounded threat model for future robustness and security research.</li>
</ul>

<h3>Title: Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement</h3>
<ul>
<li><strong>Authors: </strong>Xiaogang Xu, Jian Wang, Yunfan Lu, Ruihang Chu, Ruixing Wang, Jiafei Wu, Bei Yu, Liang Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17105">https://arxiv.org/abs/2510.17105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17105">https://arxiv.org/pdf/2510.17105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17105]] Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement(https://arxiv.org/abs/2510.17105)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion-based methods, leveraging pre-trained large models like Stable Diffusion via ControlNet, have achieved remarkable performance in several low-level vision tasks. However, Pre-Trained Diffusion-Based (PTDB) methods often sacrifice content fidelity to attain higher perceptual realism. This issue is exacerbated in low-light scenarios, where severely degraded information caused by the darkness limits effective control. We identify two primary causes of fidelity loss: the absence of suitable conditional latent modeling and the lack of bidirectional interaction between the conditional latent and noisy latent in the diffusion process. To address this, we propose a novel optimization strategy for conditioning in pre-trained diffusion models, enhancing fidelity while preserving realism and aesthetics. Our method introduces a mechanism to recover spatial details lost during VAE encoding, i.e., a latent refinement pipeline incorporating generative priors. Additionally, the refined latent condition interacts dynamically with the noisy latent, leading to improved restoration performance. Our approach is plug-and-play, seamlessly integrating into existing diffusion networks to provide more effective control. Extensive experiments demonstrate significant fidelity improvements in PTDB methods.</li>
</ul>

<h3>Title: Fighter: Unveiling the Graph Convolutional Nature of Transformers in Time Series Modeling</h3>
<ul>
<li><strong>Authors: </strong>Chen Zhang, Weixin Bu, Wendong Xu, Runsheng Yu, Yik-Chung Wu, Ngai Wong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17106">https://arxiv.org/abs/2510.17106</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17106">https://arxiv.org/pdf/2510.17106</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17106]] Fighter: Unveiling the Graph Convolutional Nature of Transformers in Time Series Modeling(https://arxiv.org/abs/2510.17106)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>Transformers have achieved remarkable success in time series modeling, yet their internal mechanisms remain opaque. This work demystifies the Transformer encoder by establishing its fundamental equivalence to a Graph Convolutional Network (GCN). We show that in the forward pass, the attention distribution matrix serves as a dynamic adjacency matrix, and its composition with subsequent transformations performs computations analogous to graph convolution. Moreover, we demonstrate that in the backward pass, the update dynamics of value and feed-forward projections mirror those of GCN parameters. Building on this unified theoretical reinterpretation, we propose \textbf{Fighter} (Flexible Graph Convolutional Transformer), a streamlined architecture that removes redundant linear projections and incorporates multi-hop graph aggregation. This perspective yields an explicit and interpretable representation of temporal dependencies across different scales, naturally expressed as graph edges. Experiments on standard forecasting benchmarks confirm that Fighter achieves competitive performance while providing clearer mechanistic interpretability of its predictions.</li>
</ul>

<h3>Title: Verification-Aware Planning for Multi-Agent Systems</h3>
<ul>
<li><strong>Authors: </strong>Tianyang Xu, Dan Zhang, Kushan Mitra, Estevam Hruschka</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17109">https://arxiv.org/abs/2510.17109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17109">https://arxiv.org/pdf/2510.17109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17109]] Verification-Aware Planning for Multi-Agent Systems(https://arxiv.org/abs/2510.17109)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) agents are increasingly deployed to tackle complex tasks, often necessitating collaboration among multiple specialized agents. However, multi-agent collaboration introduces new challenges in planning, coordination, and verification. Execution failures frequently arise not from flawed reasoning alone, but from subtle misalignments in task interpretation, output format, or inter-agent handoffs. To address these challenges, we present VeriMAP, a framework for multi-agent collaboration with verification-aware planning. The VeriMAP planner decomposes tasks, models subtask dependencies, and encodes planner-defined passing criteria as subtask verification functions (VFs) in Python and natural language. We evaluate VeriMAP on diverse datasets, demonstrating that it outperforms both single- and multi-agent baselines while enhancing system robustness and interpretability. Our analysis highlights how verification-aware planning enables reliable coordination and iterative refinement in multi-agent systems, without relying on external labels or annotations.</li>
</ul>

<h3>Title: Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras</h3>
<ul>
<li><strong>Authors: </strong>Hodaka Kawachi, Tomoya Nakamura, Hiroaki Santo, SaiKiran Kumar Tedla, Trevor Dalton Canham, Yasushi Yagi, Michael S. Brown</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17114">https://arxiv.org/abs/2510.17114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17114">https://arxiv.org/pdf/2510.17114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17114]] Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras(https://arxiv.org/abs/2510.17114)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, extraction, watermark</a></li>
<li><strong>Abstract: </strong>This paper introduces a method for using LED-based environmental lighting to produce visually imperceptible watermarks for consumer cameras. Our approach optimizes an LED light source's spectral profile to be minimally visible to the human eye while remaining highly detectable by typical consumer cameras. The method jointly considers the human visual system's sensitivity to visible spectra, modern consumer camera sensors' spectral sensitivity, and narrowband LEDs' ability to generate broadband spectra perceived as "white light" (specifically, D65 illumination). To ensure imperceptibility, we employ spectral modulation rather than intensity modulation. Unlike conventional visible light communication, our approach enables watermark extraction at standard low frame rates (30-60 fps). While the information transfer rate is modest-embedding 128 bits within a 10-second video clip-this capacity is sufficient for essential metadata supporting privacy protection and content verification.</li>
</ul>

<h3>Title: Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for Continuous-Time Control</h3>
<ul>
<li><strong>Authors: </strong>Chengxiu Hua, Jiawen Gu, Yushun Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17122">https://arxiv.org/abs/2510.17122</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17122">https://arxiv.org/pdf/2510.17122</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17122]] Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for Continuous-Time Control(https://arxiv.org/abs/2510.17122)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has achieved significant success across a wide range of domains, however, most existing methods are formulated in discrete time. In this work, we introduce a novel RL method for continuous-time control, where stochastic differential equations govern state-action dynamics. Departing from traditional value function-based approaches, our key contribution is the characterization of continuous-time Q-functions via a martingale condition and the linking of diffusion policy scores to the action gradient of a learned continuous Q-function by the dynamic programming principle. This insight motivates Continuous Q-Score Matching (CQSM), a score-based policy improvement algorithm. Notably, our method addresses a long-standing challenge in continuous-time RL: preserving the action-evaluation capability of Q-functions without relying on time discretization. We further provide theoretical closed-form solutions for linear-quadratic (LQ) control problems within our framework. Numerical results in simulated environments demonstrate the effectiveness of our proposed method and compare it to popular baselines.</li>
</ul>

<h3>Title: GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection</h3>
<ul>
<li><strong>Authors: </strong>Xin Gao, Jiyao Liu, Guanghao Li, Yueming Lyu, Jianxiong Gao, Weichen Yu, Ningsheng Xu, Liang Wang, Caifeng Shan, Ziwei Liu, Chenyang Si</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17131">https://arxiv.org/abs/2510.17131</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17131">https://arxiv.org/pdf/2510.17131</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17131]] GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection(https://arxiv.org/abs/2510.17131)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advancements have explored text-to-image diffusion models for synthesizing out-of-distribution (OOD) samples, substantially enhancing the performance of OOD detection. However, existing approaches typically rely on perturbing text-conditioned embeddings, resulting in semantic instability and insufficient shift diversity, which limit generalization to realistic OOD. To address these challenges, we propose GOOD, a novel and flexible framework that directly guides diffusion sampling trajectories towards OOD regions using off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level guidance: (1) Image-level guidance based on the gradient of log partition to reduce input likelihood, drives samples toward low-density regions in pixel space. (2) Feature-level guidance, derived from k-NN distance in the classifier's latent space, promotes sampling in feature-sparse regions. Hence, this dual-guidance design enables more controllable and diverse OOD sample generation. Additionally, we introduce a unified OOD score that adaptively combines image and feature discrepancies, enhancing detection robustness. We perform thorough quantitative and qualitative analyses to evaluate the effectiveness of GOOD, demonstrating that training with samples generated by GOOD can notably enhance OOD detection performance.</li>
</ul>

<h3>Title: Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Tsaknakis, Bingqing Song, Shuyu Gan, Dongyeop Kang, Alfredo Garcia, Gaowen Liu, Charles Fleming, Mingyi Hong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17132">https://arxiv.org/abs/2510.17132</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17132">https://arxiv.org/pdf/2510.17132</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17132]] Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction(https://arxiv.org/abs/2510.17132)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel at producing broadly relevant text, but this generality becomes a limitation when user-specific preferences are required, such as recommending restaurants or planning travel. In these scenarios, users rarely articulate every preference explicitly; instead, much of what they care about remains latent, waiting to be inferred. This raises a fundamental question: Can LLMs uncover and reason about such latent information through conversation? We address this problem by introducing a unified benchmark for evaluating latent information discovery - the ability of LLMs to reveal and utilize hidden user attributes through multi-turn interaction. The benchmark spans three progressively realistic settings: the classic 20 Questions game, Personalized Question Answering, and Personalized Text Summarization. All tasks share a tri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of elicitation and adaptation. Our results reveal that while LLMs can indeed surface latent information through dialogue, their success varies dramatically with context: from 32% to 98%, depending on task complexity, topic, and number of hidden attributes. This benchmark provides the first systematic framework for studying latent information discovery in personalized interaction, highlighting that effective preference inference remains an open frontier for building truly adaptive AI systems.</li>
</ul>

<h3>Title: In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Enhao Gu, Haolin Hou</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17136">https://arxiv.org/abs/2510.17136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17136">https://arxiv.org/pdf/2510.17136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17136]] In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models(https://arxiv.org/abs/2510.17136)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The generation of high-quality, diverse, and prompt-aligned images is a central goal in image-generating diffusion models. The popular classifier-free guidance (CFG) approach improves quality and alignment at the cost of reduced variation, creating an inherent entanglement of these effects. Recent work has successfully disentangled these properties by guiding a model with a separately trained, inferior counterpart; however, this solution introduces the considerable overhead of requiring an auxiliary model. We challenge this prerequisite by introducing In-situ Autoguidance, a method that elicits guidance from the model itself without any auxiliary components. Our approach dynamically generates an inferior prediction on the fly using a stochastic forward pass, reframing guidance as a form of inference-time self-correction. We demonstrate that this zero-cost approach is not only viable but also establishes a powerful new baseline for cost-efficient guidance, proving that the benefits of self-guidance can be achieved without external models.</li>
</ul>

<h3>Title: KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation</h3>
<ul>
<li><strong>Authors: </strong>WenBo Xu, Liu Liu, Li Zhang, Ran Zhang, Hao Wu, Dan Guo, Meng Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17137">https://arxiv.org/abs/2510.17137</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17137">https://arxiv.org/pdf/2510.17137</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17137]] KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation(https://arxiv.org/abs/2510.17137)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>Articulated objects, such as laptops and drawers, exhibit significant challenges for 3D reconstruction and pose estimation due to their multi-part geometries and variable joint configurations, which introduce structural diversity across different states. To address these challenges, we propose KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation, a unified framework for reconstructing diverse articulated instances and pose estimation from single view input. Specifically, we first encode complete geometry (SDFs), joint angles, and part segmentation into a structured latent space via a novel Kinematic-Aware VAE (KA-VAE). In addition, we employ two conditional diffusion models: one for regressing global pose (SE(3)) and joint parameters, and another for generating the kinematic-aware latent code from partial observations. Finally, we produce an iterative optimization module that bidirectionally refines reconstruction accuracy and kinematic parameters via Chamfer-distance minimization while preserving articulation constraints. Experimental results on synthetic, semi-synthetic, and real-world datasets demonstrate the effectiveness of our approach in accurately reconstructing articulated objects and estimating their kinematic properties.</li>
</ul>

<h3>Title: Rethinking On-policy Optimization for Query Augmentation</h3>
<ul>
<li><strong>Authors: </strong>Zhichao Xu, Shengyao Zhuang, Xueguang Ma, Bingsen Chen, Yijun Tian, Fengran Mo, Jie Cao, Vivek Srikumar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17139">https://arxiv.org/abs/2510.17139</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17139">https://arxiv.org/pdf/2510.17139</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17139]] Rethinking On-policy Optimization for Query Augmentation(https://arxiv.org/abs/2510.17139)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Recent advances in large language models (LLMs) have led to a surge of interest in query augmentation for information retrieval (IR). Two main approaches have emerged. The first prompts LLMs to generate answers or pseudo-documents that serve as new queries, relying purely on the model's parametric knowledge or contextual information. The second applies reinforcement learning (RL) to fine-tune LLMs for query rewriting, directly optimizing retrieval metrics. While having respective advantages and limitations, the two approaches have not been compared under consistent experimental conditions. In this work, we present the first systematic comparison of prompting-based and RL-based query augmentation across diverse benchmarks, including evidence-seeking, ad hoc, and tool retrieval. Our key finding is that simple, training-free query augmentation often performs on par with, or even surpasses, more expensive RL-based counterparts, especially when using powerful LLMs. Motivated by this discovery, we introduce a novel hybrid method, On-policy Pseudo-document Query Expansion (OPQE), which, instead of rewriting a query, the LLM policy learns to generate a pseudo-document that maximizes retrieval performance, thus merging the flexibility and generative structure of prompting with the targeted optimization of RL. We show OPQE outperforms both standalone prompting and RL-based rewriting, demonstrating that a synergistic approach yields the best results. Our implementation is made available to facilitate reproducibility.</li>
</ul>

<h3>Title: GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image</h3>
<ul>
<li><strong>Authors: </strong>Yinghui Wang, Xinyu Zhang, Peng Du</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17157">https://arxiv.org/abs/2510.17157</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17157">https://arxiv.org/pdf/2510.17157</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17157]] GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image(https://arxiv.org/abs/2510.17157)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Generating editable, parametric CAD models from a single image holds great potential to lower the barriers of industrial concept design. However, current multi-modal large language models (MLLMs) still struggle with accurately inferring 3D geometry from 2D images due to limited spatial reasoning capabilities. We address this limitation by introducing GACO-CAD, a novel two-stage post-training framework. It is designed to achieve a joint objective: simultaneously improving the geometric accuracy of the generated CAD models and encouraging the use of more concise modeling procedures. First, during supervised fine-tuning, we leverage depth and surface normal maps as dense geometric priors, combining them with the RGB image to form a multi-channel input. In the context of single-view reconstruction, these priors provide complementary spatial cues that help the MLLM more reliably recover 3D geometry from 2D observations. Second, during reinforcement learning, we introduce a group length reward that, while preserving high geometric fidelity, promotes the generation of more compact and less redundant parametric modeling sequences. A simple dynamic weighting strategy is adopted to stabilize training. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD achieves state-of-the-art performance under the same MLLM backbone, consistently outperforming existing methods in terms of code validity, geometric accuracy, and modeling conciseness.</li>
</ul>

<h3>Title: ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing</h3>
<ul>
<li><strong>Authors: </strong>Guanjie Cheng, Siyang Liu, Junqin Huang, Xinkui Zhao, Yin Wang, Mengying Zhu, Linghe Kong, Shuiguang Deng</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17162">https://arxiv.org/abs/2510.17162</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17162">https://arxiv.org/pdf/2510.17162</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17162]] ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing(https://arxiv.org/abs/2510.17162)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack</a></li>
<li><strong>Abstract: </strong>Mobile edge crowdsensing (MECS) systems continuously generate and transmit user data in dynamic, resource-constrained environments, exposing users to significant privacy threats. In practice, many privacy-preserving mechanisms build on differential privacy (DP). However, static DP mechanisms often fail to adapt to evolving risks, for example, shifts in adversarial capabilities, resource constraints and task requirements, resulting in either excessive noise or inadequate protection. To address this challenge, we propose ALPINE, a lightweight, adaptive framework that empowers terminal devices to autonomously adjust differential privacy levels in real time. ALPINE operates as a closed-loop control system consisting of four modules: dynamic risk perception, privacy decision via twin delayed deep deterministic policy gradient (TD3), local privacy execution and performance verification from edge nodes. Based on environmental risk assessments, we design a reward function that balances privacy gains, data utility and energy cost, guiding the TD3 agent to adaptively tune noise magnitude across diverse risk scenarios and achieve a dynamic equilibrium among privacy, utility and cost. Both the collaborative risk model and pretrained TD3-based agent are designed for low-overhead deployment. Extensive theoretical analysis and real-world simulations demonstrate that ALPINE effectively mitigates inference attacks while preserving utility and cost, making it practical for large-scale edge applications.</li>
</ul>

<h3>Title: When AI companions become witty: Can human brain recognize AI-generated irony?</h3>
<ul>
<li><strong>Authors: </strong>Xiaohui Rao, Hanlin Wu, Zhenguang G. Cai</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17168">https://arxiv.org/abs/2510.17168</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17168">https://arxiv.org/pdf/2510.17168</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17168]] When AI companions become witty: Can human brain recognize AI-generated irony?(https://arxiv.org/abs/2510.17168)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) are increasingly deployed as social agents and trained to produce humor and irony, a question emerges: when encountering witty AI remarks, do people interpret these as intentional communication or mere computational output? This study investigates whether people adopt the intentional stance, attributing mental states to explain behavior,toward AI during irony comprehension. Irony provides an ideal paradigm because it requires distinguishing intentional contradictions from unintended errors through effortful semantic reanalysis. We compared behavioral and neural responses to ironic statements from AI versus human sources using established ERP components: P200 reflecting early incongruity detection and P600 indexing cognitive efforts in reinterpreting incongruity as deliberate irony. Results demonstrate that people do not fully adopt the intentional stance toward AI-generated irony. Behaviorally, participants attributed incongruity to deliberate communication for both sources, though significantly less for AI than human, showing greater tendency to interpret AI incongruities as computational errors. Neural data revealed attenuated P200 and P600 effects for AI-generated irony, suggesting reduced effortful detection and reanalysis consistent with diminished attribution of communicative intent. Notably, people who perceived AI as more sincere showed larger P200 and P600 effects for AI-generated irony, suggesting that intentional stance adoption is calibrated by specific mental models of artificial agents. These findings reveal that source attribution shapes neural processing of social-communicative phenomena. Despite current LLMs' linguistic sophistication, achieving genuine social agency requires more than linguistic competence, it necessitates a shift in how humans perceive and attribute intentionality to artificial agents.</li>
</ul>

<h3>Title: Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition</h3>
<ul>
<li><strong>Authors: </strong>Roland Croft, Brian Du, Darcy Joseph, Sharath Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17169">https://arxiv.org/abs/2510.17169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17169">https://arxiv.org/pdf/2510.17169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17169]] Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition(https://arxiv.org/abs/2510.17169)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, robust</a></li>
<li><strong>Abstract: </strong>Face Recognition (FR) models have been shown to be vulnerable to adversarial examples that subtly alter benign facial images, exposing blind spots in these systems, as well as protecting user privacy. End-to-end FR systems first obtain preprocessed faces from diverse facial imagery prior to computing the similarity of the deep feature embeddings. Whilst face preprocessing is a critical component of FR systems, and hence adversarial attacks against them, we observe that this preprocessing is often overlooked in blackbox settings. Our study seeks to investigate the transferability of several out-of-the-box state-of-the-art adversarial attacks against FR when applied against different preprocessing techniques used in a blackbox setting. We observe that the choice of face detection model can degrade the attack success rate by up to 78%, whereas choice of interpolation method during downsampling has relatively minimal impacts. Furthermore, we find that the requirement for facial preprocessing even degrades attack strength in a whitebox setting, due to the unintended interaction of produced noise vectors against face detection models. Based on these findings, we propose a preprocessing-invariant method using input transformations that improves the transferability of the studied attacks by up to 27%. Our findings highlight the importance of preprocessing in FR systems, and the need for its consideration towards improving the adversarial generalisation of facial adversarial examples.</li>
</ul>

<h3>Title: QRïS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Wahid Akram, Keshav Sood, Muneeb Ul Hassan</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17175">https://arxiv.org/abs/2510.17175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17175">https://arxiv.org/pdf/2510.17175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17175]] QRïS: A Preemptive Novel Method for Quishing Detection Through Structural Features of QR(https://arxiv.org/abs/2510.17175)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability</a></li>
<li><strong>Abstract: </strong>Globally, individuals and organizations employ Quick Response (QR) codes for swift and convenient communication. Leveraging this, cybercriminals embed falsify and misleading information in QR codes to launch various phishing attacks which termed as Quishing. Many former studies have introduced defensive approaches to preclude Quishing such as by classifying the embedded content of QR codes and then label the QR codes accordingly, whereas other studies classify them using visual features (i.e., deep features, histogram density analysis features). However, these approaches mainly rely on black-box techniques which do not clearly provide interpretability and transparency to fully comprehend and reproduce the intrinsic decision process; therefore, having certain obvious limitations includes the approaches' trust, accountability, issues in bias detection, and many more. We proposed QRïS, the pioneer method to classify QR codes through the comprehensive structural analysis of a QR code which helps to identify phishing QR codes beforehand. Our classification method is clearly transparent which makes it reproducible, scalable, and easy to comprehend. First, we generated QR codes dataset (i.e. 400,000 samples) using recently published URLs datasets [1], [2]. Then, unlike black-box models, we developed a simple algorithm to extract 24 structural features from layout patterns present in QR codes. Later, we train the machine learning models on the harvested features and obtained accuracy of up to 83.18%. To further evaluate the effectiveness of our approach, we perform the comparative analysis of proposed method with relevant contemporary studies. Lastly, for real-world deployment and validation, we developed a mobile app which assures the feasibility of the proposed solution in real-world scenarios which eventually strengthen the applicability of the study.</li>
</ul>

<h3>Title: Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and New Defenses</h3>
<ul>
<li><strong>Authors: </strong>Runlin Lei, Lu Yi, Mingguo He, Pengyu Qiu, Zhewei Wei, Yongchao Liu, Chuntao Hong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17185">https://arxiv.org/abs/2510.17185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17185">https://arxiv.org/pdf/2510.17185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17185]] Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and New Defenses(https://arxiv.org/abs/2510.17185)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>While Graph Neural Networks (GNNs) and Large Language Models (LLMs) are powerful approaches for learning on Text-Attributed Graphs (TAGs), a comprehensive understanding of their robustness remains elusive. Current evaluations are fragmented, failing to systematically investigate the distinct effects of textual and structural perturbations across diverse models and attack scenarios. To address these limitations, we introduce a unified and comprehensive framework to evaluate robustness in TAG learning. Our framework evaluates classical GNNs, robust GNNs (RGNNs), and GraphLLMs across ten datasets from four domains, under diverse text-based, structure-based, and hybrid perturbations in both poisoning and evasion scenarios. Our extensive analysis reveals multiple findings, among which three are particularly noteworthy: 1) models have inherent robustness trade-offs between text and structure, 2) the performance of GNNs and RGNNs depends heavily on the text encoder and attack type, and 3) GraphLLMs are particularly vulnerable to training data corruption. To overcome the identified trade-offs, we introduce SFT-auto, a novel framework that delivers superior and balanced robustness against both textual and structural attacks within a single model. Our work establishes a foundation for future research on TAG security and offers practical solutions for robust TAG learning in adversarial environments. Our code is available at: this https URL.</li>
</ul>

<h3>Title: HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery</h3>
<ul>
<li><strong>Authors: </strong>Vaibhav Rathore, Divyam Gupta, Biplab Banerjee</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17188">https://arxiv.org/abs/2510.17188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17188">https://arxiv.org/pdf/2510.17188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17188]] HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery(https://arxiv.org/abs/2510.17188)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Generalized Category Discovery (GCD) aims to classify test-time samples into either seen categories** -- available during training -- or novel ones, without relying on label supervision. Most existing GCD methods assume simultaneous access to labeled and unlabeled data during training and arising from the same domain, limiting applicability in open-world scenarios involving distribution shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by requiring models to generalize to unseen domains containing novel categories, without accessing targetdomain data during training. The only prior DG-GCD method, DG2CD-Net, relies on episodic training with multiple synthetic domains and task vector aggregation, incurring high computational cost and error accumulation. We propose HIDISC, a hyperbolic representation learning framework that achieves domain and category-level generalization without episodic simulation. To expose the model to minimal but diverse domain variations, we augment the source domain using GPT-guided diffusion, avoiding overfitting while maintaining efficiency. To structure the representation space, we introduce Tangent CutMix, a curvature-aware interpolation that synthesizes pseudo-novel samples in tangent space, preserving manifold consistency. A unified loss -- combining penalized Busemann alignment, hybrid hyperbolic contrastive regularization, and adaptive outlier repulsion -- **facilitates compact, semantically structured embeddings. A learnable curvature parameter further adapts the geometry to dataset complexity. HIDISC achieves state-of-the-art results on PACS , Office-Home , and DomainNet, consistently outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.</li>
</ul>

<h3>Title: SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference</h3>
<ul>
<li><strong>Authors: </strong>Wenxun Wang, Shuchang Zhou, Wenyu Sun, Peiqin Sun, Yongpan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17189">https://arxiv.org/abs/2510.17189</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17189">https://arxiv.org/pdf/2510.17189</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17189]] SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference(https://arxiv.org/abs/2510.17189)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have shown remarkable performance in both natural language processing (NLP) and computer vision (CV) tasks. However, their real-time inference speed and efficiency are limited due to the inefficiency in Softmax and Layer Normalization (LayerNorm). Previous works based on function approximation suffer from inefficient implementation as they place emphasis on computation while disregarding memory overhead concerns. Moreover, such methods rely on retraining to compensate for approximation error which can be costly and inconvenient. In this paper, we present SOLE, a hardware-software co-design for Softmax and LayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes log2 quantization of exponent function and log-based division to approximate Softmax while AILayerNorm adopts low-precision statistic calculation. Compared with state-of-the-art designs, we achieve both low-precision calculation and low bit-width storage on Softmax and LayerNorm. Experiments show that SOLE maintains inference accuracy without retraining while offering orders of magnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x energy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements over prior state-of-the-art custom hardware for Softmax and LayerNorm, respectively.</li>
</ul>

<h3>Title: Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models</h3>
<ul>
<li><strong>Authors: </strong>Jiaqi Leng, Xiang Hu, Junxiong Wang, Jianguo Li, Wei Wu, Yucheng Lu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17196">https://arxiv.org/abs/2510.17196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17196">https://arxiv.org/pdf/2510.17196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17196]] Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models(https://arxiv.org/abs/2510.17196)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Effectively processing long contexts is a critical challenge for language models. While standard Transformers are limited by quadratic complexity and poor length extrapolation, alternative architectures like sliding window attention and state space models sacrifice the ability to effectively utilize the full context due to their fixed-size memory. Chunk-based sparse attention has emerged as a promising paradigm for extreme length generalization, yet the key architectural principles underpinning its success are not yet fully understood. In this work, we present a systematic dissection of these models to identify the core components driving their performance. Through a unified framework and comprehensive ablation studies, we demonstrate that a combination of three design principles is critical: (1) an expressive, non-linear Chunk Encoder with a dedicated CLS token to produce representations for retrieval; (2) a Bypassing Residual Path to stably integrate retrieved global information without it being overridden by the local residual stream; and (3) enforced selection sparsity during pre-training to bridge the train-test distribution gap. We provide a theoretical motivation for intra-chunk information processing and landmark generation. By combining these principles, we establish a new state-of-the-art for training-free length extrapolation, successfully generalizing models trained on a 4K context to 32 million tokens on RULER and BABILong. Our findings provide a clear and empirically-grounded set of design principles for developing future, highly-capable long-context language models.</li>
</ul>

<h3>Title: From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh</h3>
<ul>
<li><strong>Authors: </strong>M Saifuzzaman Rafat, Mohd Ruhul Ameen, Akif Islam, Abu Saleh Musa Miah, Jungpil Shin</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17198">https://arxiv.org/abs/2510.17198</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17198">https://arxiv.org/pdf/2510.17198</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17198]] From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh(https://arxiv.org/abs/2510.17198)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, segmentation</a></li>
<li><strong>Abstract: </strong>The great rivers of Bangladesh, arteries of commerce and sustenance, are also agents of relentless destruction. Each year, they swallow whole villages and vast tracts of farmland, erasing communities from the map and displacing thousands of families. To track this slow-motion catastrophe has, until now, been a Herculean task for human analysts. Here we show how a powerful general-purpose vision model, the Segment Anything Model (SAM), can be adapted to this task with remarkable precision. To do this, we assembled a new dataset - a digital chronicle of loss compiled from historical Google Earth imagery of Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially, this dataset is the first to include manually annotated data on the settlements that have vanished beneath the water. Our method first uses a simple color-channel analysis to provide a rough segmentation of land and water, and then fine-tunes SAM's mask decoder to recognize the subtle signatures of riverbank erosion. The resulting model demonstrates a keen eye for this destructive process, achieving a mean Intersection over Union of 86.30% and a Dice score of 92.60% - a performance that significantly surpasses traditional methods and off-the-shelf deep learning models. This work delivers three key contributions: the first annotated dataset of disappeared settlements in Bangladesh due to river erosion; a specialized AI model fine-tuned for this critical task; and a method for quantifying land loss with compelling visual evidence. Together, these tools provide a powerful new lens through which policymakers and disaster management agencies can monitor erosion, anticipate its trajectory, and ultimately protect the vulnerable communities in its path.</li>
</ul>

<h3>Title: Optimizing DINOv2 with Registers for Face Anti-Spoofing</h3>
<ul>
<li><strong>Authors: </strong>Mika Feng, Pierre Gallin-Martel, Koichi Ito, Takafumi Aoki</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17201">https://arxiv.org/abs/2510.17201</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17201">https://arxiv.org/pdf/2510.17201</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17201]] Optimizing DINOv2 with Registers for Face Anti-Spoofing(https://arxiv.org/abs/2510.17201)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Face recognition systems are designed to be robust against variations in head pose, illumination, and image blur during capture. However, malicious actors can exploit these systems by presenting a face photo of a registered user, potentially bypassing the authentication process. Such spoofing attacks must be detected prior to face recognition. In this paper, we propose a DINOv2-based spoofing attack detection method to discern minute differences between live and spoofed face images. Specifically, we employ DINOv2 with registers to extract generalizable features and to suppress perturbations in the attention mechanism, which enables focused attention on essential and minute features. We demonstrate the effectiveness of the proposed method through experiments conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop: Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.</li>
</ul>

<h3>Title: $\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Yingqi Fan, Anhao Zhao, Jinlan Fu, Junlong Tong, Hui Su, Yijie Pan, Wei Zhang, Xiaoyu Shen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17205">https://arxiv.org/abs/2510.17205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17205">https://arxiv.org/pdf/2510.17205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17205]] $\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs(https://arxiv.org/abs/2510.17205)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) have achieved strong performance across vision-language tasks, but suffer from significant computational overhead due to the quadratic growth of attention computations with the number of multimodal tokens. Though efforts have been made to prune tokens in MLLMs, \textit{they lack a fundamental understanding of how MLLMs process and fuse multimodal information.} Through systematic analysis, we uncover a \textbf{three-stage} cross-modal interaction process: (1) Shallow layers recognize task intent, with visual tokens acting as passive attention sinks; (2) Cross-modal fusion occurs abruptly in middle layers, driven by a few critical visual tokens; (3) Deep layers discard vision tokens, focusing solely on linguistic refinement. Based on these findings, we propose \emph{VisiPruner}, a training-free pruning framework that reduces up to 99\% of vision-related attention computations and 53.9\% of FLOPs on LLaVA-v1.5 7B. It significantly outperforms existing token pruning methods and generalizes across diverse MLLMs. Beyond pruning, our insights further provide actionable guidelines for training efficient MLLMs by aligning model architecture with its intrinsic layer-wise processing dynamics. Our code is available at: this https URL.</li>
</ul>

<h3>Title: Soft-Masked Diffusion Language Models</h3>
<ul>
<li><strong>Authors: </strong>Michael Hersche, Samuel Moor-Smith, Thomas Hofmann, Abbas Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17206">https://arxiv.org/abs/2510.17206</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17206">https://arxiv.org/pdf/2510.17206</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17206]] Soft-Masked Diffusion Language Models(https://arxiv.org/abs/2510.17206)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models have demonstrated strong potential in language modeling, offering various advantages over traditional autoregressive approaches. Their ability to generate and revise entire responses in parallel enables faster generation and built-in self-correction mechanisms. Most modern diffusion-based language models employ masked diffusion, where decoding involves iteratively processing masked tokens based on a binary decision: either retaining the mask or replacing it with the predicted token. However, this binary choice discards valuable predictive information when the mask is retained. To address this limitation, we introduce soft-masking (SM), a novel method that dynamically blends the embedding of the mask token with the embeddings of the top-$k$ predicted tokens from the previous decoding step, for each retained mask. This provides the model with a more informative prior, preserving context from earlier computations and allowing partial information about masked tokens to propagate beyond a single step. We propose a training methodology that adapts a pretrained masked diffusion language model to incorporate SM. We demonstrate that continuing pretraining a 169M parameter model with SM leads to improved perplexity and MAUVE scores. Furthermore, we finetune two state-of-the-art diffusion models, Dream-7B and Dream-Coder-7B, with SM. SM consistently improves performance across multiple coding benchmarks, particularly in high-throughput settings.</li>
</ul>

<h3>Title: Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting</h3>
<ul>
<li><strong>Authors: </strong>Chenchen Tan, Youyang Qu, Xinghao Li, Hui Zhang, Shujie Cui, Cunjian Chen, Longxiang Gao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17210">https://arxiv.org/abs/2510.17210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17210">https://arxiv.org/pdf/2510.17210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17210]] Wisdom is Knowing What not to Say: Hallucination-Free LLMs Unlearning via Attention Shifting(https://arxiv.org/abs/2510.17210)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The increase in computing power and the necessity of AI-assisted decision-making boost the growing application of large language models (LLMs). Along with this, the potential retention of sensitive data of LLMs has spurred increasing research into machine unlearning. However, existing unlearning approaches face a critical dilemma: Aggressive unlearning compromises model utility, while conservative strategies preserve utility but risk hallucinated responses. This significantly limits LLMs' reliability in knowledge-intensive applications. To address this, we introduce a novel Attention-Shifting (AS) framework for selective unlearning. AS is driven by two design objectives: (1) context-preserving suppression that attenuates attention to fact-bearing tokens without disrupting LLMs' linguistic structure; and (2) hallucination-resistant response shaping that discourages fabricated completions when queried about unlearning content. AS realizes these objectives through two attention-level interventions, which are importance-aware suppression applied to the unlearning set to reduce reliance on memorized knowledge and attention-guided retention enhancement that reinforces attention toward semantically essential tokens in the retained dataset to mitigate unintended degradation. These two components are jointly optimized via a dual-loss objective, which forms a soft boundary that localizes unlearning while preserving unrelated knowledge under representation superposition. Experimental results show that AS improves performance preservation over the state-of-the-art unlearning methods, achieving up to 15% higher accuracy on the ToFU benchmark and 10% on the TDEC benchmark, while maintaining competitive hallucination-free unlearning effectiveness. Compared to existing methods, AS demonstrates a superior balance between unlearning effectiveness, generalization, and response reliability.</li>
</ul>

<h3>Title: When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions</h3>
<ul>
<li><strong>Authors: </strong>Zhuo Cao, Heming Du, Bingqing Zhang, Xin Yu, Xue Li, Sen Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17218">https://arxiv.org/abs/2510.17218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17218">https://arxiv.org/pdf/2510.17218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17218]] When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions(https://arxiv.org/abs/2510.17218)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval (SMR). However, one query can correspond to multiple relevant moments in real-world applications. This makes the existing datasets and methods insufficient for video temporal grounding. By revisiting the gap between current MR tasks and real-world applications, we introduce a high-quality datasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new evaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists of 2,212 annotations covering 6,384 video segments. Building on existing efforts in MMR, we propose a framework called FlashMMR. Specifically, we propose a Multi-moment Post-verification module to refine the moment boundaries. We introduce constrained temporal adjustment and subsequently leverage a verification module to re-evaluate the candidate segments. Through this sophisticated filtering pipeline, low-confidence proposals are pruned, and robust multi-moment alignment is achieved. We retrain and evaluate 6 existing MR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings. Results show that QV-M$^2$ serves as an effective benchmark for training and evaluating MMR models, while FlashMMR provides a strong baseline. Specifically, on QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP, 2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method establish a foundation for advancing research in more realistic and challenging video temporal grounding scenarios. Code is released at this https URL.</li>
</ul>

<h3>Title: StreamingThinker: Large Language Models Can Think While Reading</h3>
<ul>
<li><strong>Authors: </strong>Junlong Tong, Yingqi Fan, Anhao Zhao, Yunpu Ma, Xiaoyu Shen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17238">https://arxiv.org/abs/2510.17238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17238">https://arxiv.org/pdf/2510.17238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17238]] StreamingThinker: Large Language Models Can Think While Reading(https://arxiv.org/abs/2510.17238)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable capabilities in chain of thought (CoT) reasoning. However, the current LLM reasoning paradigm initiates thinking only after the entire input is available, which introduces unnecessary latency and weakens attention to earlier information in dynamic scenarios. Inspired by human cognition of thinking while reading, we first design a \textit{\textbf{streaming thinking}} paradigm for LLMs, where reasoning unfolds in the order of input and further adjusts its depth once reading is complete. We instantiate this paradigm with \textit{StreamingThinker}, a framework that enables LLMs to think while reading through the integration of streaming CoT generation, streaming-constraint training, and streaming parallel inference. Specifically, StreamingThinker employs streaming reasoning units with quality control for CoT generation, enforces order-preserving reasoning through streaming attention masks and position encoding, and leverages parallel KV caches that decouple input encoding from reasoning generation, thereby ensuring alignment and enabling true concurrency. We evaluate StreamingThinker on the Qwen3 model family across math reasoning, logical reasoning, and context-based QA reasoning tasks. Experimental results show that the StreamingThinker preserves performance comparable to batch thinking, while yielding an 80\% reduction in token waiting before the onset of reasoning and a more than 60\% reduction in time-level latency for producing the final answer, demonstrating the effectiveness of the streaming paradigm for LLM reasoning. Code will be released at \href{this https URL}{this repository.}</li>
</ul>

<h3>Title: From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Zefan Cai, Haoyi Qiu, Haozhe Zhao, Ke Wan, Jiachen Li, Jiuxiang Gu, Wen Xiao, Nanyun Peng, Junjie Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17247">https://arxiv.org/abs/2510.17247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17247">https://arxiv.org/pdf/2510.17247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17247]] From Preferences to Prejudice: The Role of Alignment Tuning in Shaping Social Bias in Video Diffusion Models(https://arxiv.org/abs/2510.17247)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, diffusion</a></li>
<li><strong>Abstract: </strong>Recent advances in video diffusion models have significantly enhanced text-to-video generation, particularly through alignment tuning using reward models trained on human preferences. While these methods improve visual quality, they can unintentionally encode and amplify social biases. To systematically trace how such biases evolve throughout the alignment pipeline, we introduce VideoBiasEval, a comprehensive diagnostic framework for evaluating social representation in video generation. Grounded in established social bias taxonomies, VideoBiasEval employs an event-based prompting strategy to disentangle semantic content (actions and contexts) from actor attributes (gender and ethnicity). It further introduces multi-granular metrics to evaluate (1) overall ethnicity bias, (2) gender bias conditioned on ethnicity, (3) distributional shifts in social attributes across model variants, and (4) the temporal persistence of bias within videos. Using this framework, we conduct the first end-to-end analysis connecting biases in human preference datasets, their amplification in reward models, and their propagation through alignment-tuned video diffusion models. Our results reveal that alignment tuning not only strengthens representational biases but also makes them temporally stable, producing smoother yet more stereotyped portrayals. These findings highlight the need for bias-aware evaluation and mitigation throughout the alignment process to ensure fair and socially responsible video generation.</li>
</ul>

<h3>Title: A Prototypical Network with an Attention-based Encoder for Drivers Identification Application</h3>
<ul>
<li><strong>Authors: </strong>Wei-Hsun Lee (1), Che-Yu Chang (1), Kuang-Yu Li (2) ((1) Dept. of Transportation &amp; Communication Management Science, National Cheng Kung University, Taiwan (2) Institute of Data Science, National Cheng Kung University, Taiwan)</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17250">https://arxiv.org/abs/2510.17250</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17250">https://arxiv.org/pdf/2510.17250</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17250]] A Prototypical Network with an Attention-based Encoder for Drivers Identification Application(https://arxiv.org/abs/2510.17250)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, biometric</a></li>
<li><strong>Abstract: </strong>Driver identification has become an area of increasing interest in recent years, especially for data- driven applications, because biometric-based technologies may incur privacy issues. This study proposes a deep learning neural network architecture, an attention-based encoder (AttEnc), which uses an attention mechanism for driver identification and uses fewer model parameters than current methods. Most studies do not address the issue of data shortages for driver identification, and most of them are inflexible when encountering unknown drivers. In this study, an architecture that combines a prototypical network and an attention-based encoder (P-AttEnc) is proposed. It applies few-shot learning to overcome the data shortage issues and to enhance model generalizations. The experiments showed that the attention-based encoder can identify drivers with accuracies of 99.3%, 99.0% and 99.9% in three different datasets and has a prediction time that is 44% to 79% faster because it significantly reduces, on average, 87.6% of the model parameters. P-AttEnc identifies drivers based on few shot data, extracts driver fingerprints to address the issue of data shortages, and is able to classify unknown drivers. The first experiment showed that P-AttEnc can identify drivers with an accuracy of 69.8% in the one-shot scenario. The second experiment showed that P-AttEnc, in the 1-shot scenario, can classify unknown drivers with an average accuracy of 65.7%.</li>
</ul>

<h3>Title: Explainability of Large Language Models: Opportunities and Challenges toward Generating Trustworthy Explanations</h3>
<ul>
<li><strong>Authors: </strong>Shahin Atakishiyev, Housam K.B. Babiker, Jiayi Dai, Nawshad Farruque, Teruaki Hayashi, Nafisa Sadaf Hriti, Md Abed Rahman, Iain Smith, Mi-Young Kim, Osmar R. Zaïane, Randy Goebel</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17256">https://arxiv.org/abs/2510.17256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17256">https://arxiv.org/pdf/2510.17256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17256]] Explainability of Large Language Models: Opportunities and Challenges toward Generating Trustworthy Explanations(https://arxiv.org/abs/2510.17256)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, explainability, transformer, large language model</a></li>
<li><strong>Abstract: </strong>Large language models have exhibited impressive performance across a broad range of downstream tasks in natural language processing. However, how a language model predicts the next token and generates content is not generally understandable by humans. Furthermore, these models often make errors in prediction and reasoning, known as hallucinations. These errors underscore the urgent need to better understand and interpret the intricate inner workings of language models and how they generate predictive outputs. Motivated by this gap, this paper investigates local explainability and mechanistic interpretability within Transformer-based large language models to foster trust in such models. In this regard, our paper aims to make three key contributions. First, we present a review of local explainability and mechanistic interpretability approaches and insights from relevant studies in the literature. Furthermore, we describe experimental studies on explainability and reasoning with large language models in two critical domains -- healthcare and autonomous driving -- and analyze the trust implications of such explanations for explanation receivers. Finally, we summarize current unaddressed issues in the evolving landscape of LLM explainability and outline the opportunities, critical challenges, and future directions toward generating human-aligned, trustworthy LLM explanations.</li>
</ul>

<h3>Title: Fair and Interpretable Deepfake Detection in Videos</h3>
<ul>
<li><strong>Authors: </strong>Akihito Yoshii, Ryosuke Sonoda, Ramya Srinivasan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17264">https://arxiv.org/abs/2510.17264</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17264">https://arxiv.org/pdf/2510.17264</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17264]] Fair and Interpretable Deepfake Detection in Videos(https://arxiv.org/abs/2510.17264)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, fair, interpretability</a></li>
<li><strong>Abstract: </strong>Existing deepfake detection methods often exhibit bias, lack transparency, and fail to capture temporal information, leading to biased decisions and unreliable results across different demographic groups. In this paper, we propose a fairness-aware deepfake detection framework that integrates temporal feature learning and demographic-aware data augmentation to enhance fairness and interpretability. Our method leverages sequence-based clustering for temporal modeling of deepfake videos and concept extraction to improve detection reliability while also facilitating interpretable decisions for non-expert users. Additionally, we introduce a demography-aware data augmentation method that balances underrepresented groups and applies frequency-domain transformations to preserve deepfake artifacts, thereby mitigating bias and improving generalization. Extensive experiments on FaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA) architectures (Xception, ResNet) demonstrate the efficacy of the proposed method in obtaining the best tradeoff between fairness and accuracy when compared to SoTA.</li>
</ul>

<h3>Title: Adaptive Discretization for Consistency Models</h3>
<ul>
<li><strong>Authors: </strong>Jiayu Bai, Zhanbo Feng, Zhijie Deng, Tianqi Hou, Robert C. Qiu, Zenan Ling</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17266">https://arxiv.org/abs/2510.17266</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17266">https://arxiv.org/pdf/2510.17266</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17266]] Adaptive Discretization for Consistency Models(https://arxiv.org/abs/2510.17266)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Consistency Models (CMs) have shown promise for efficient one-step generation. However, most existing CMs rely on manually designed discretization schemes, which can cause repeated adjustments for different noise schedules and datasets. To address this, we propose a unified framework for the automatic and adaptive discretization of CMs, formulating it as an optimization problem with respect to the discretization step. Concretely, during the consistency training process, we propose using local consistency as the optimization objective to ensure trainability by avoiding excessive discretization, and taking global consistency as a constraint to ensure stability by controlling the denoising error in the training target. We establish the trade-off between local and global consistency with a Lagrange multiplier. Building on this framework, we achieve adaptive discretization for CMs using the Gauss-Newton method. We refer to our approach as ADCMs. Experiments demonstrate that ADCMs significantly improve the training efficiency of CMs, achieving superior generative performance with minimal training overhead on both CIFAR-10 and ImageNet. Moreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code is available at this https URL.</li>
</ul>

<h3>Title: Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Katie Luo, Jingwei Ji, Tong He, Runsheng Xu, Yichen Xie, Dragomir Anguelov, Mingxing Tan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17274">https://arxiv.org/abs/2510.17274</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17274">https://arxiv.org/pdf/2510.17274</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17274]] Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models(https://arxiv.org/abs/2510.17274)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Current autonomous driving systems rely on specialized models for perceiving and predicting motion, which demonstrate reliable performance in standard conditions. However, generalizing cost-effectively to diverse real-world scenarios remains a significant challenge. To address this, we propose Plug-and-Forecast (PnF), a plug-and-play approach that augments existing motion forecasting models with multimodal large language models (MLLMs). PnF builds on the insight that natural language provides a more effective way to describe and handle complex scenarios, enabling quick adaptation to targeted behaviors. We design prompts to extract structured scene understanding from MLLMs and distill this information into learnable embeddings to augment existing behavior prediction models. Our method leverages the zero-shot reasoning capabilities of MLLMs to achieve significant improvements in motion prediction performance, while requiring no fine-tuning -- making it practical to adopt. We validate our approach on two state-of-the-art motion forecasting models using the Waymo Open Motion Dataset and the nuScenes Dataset, demonstrating consistent performance improvements across both benchmarks.</li>
</ul>

<h3>Title: Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems</h3>
<ul>
<li><strong>Authors: </strong>Rishi Jha, Harold Triedman, Justin Wagle, Vitaly Shmatikov</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17276">https://arxiv.org/abs/2510.17276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17276">https://arxiv.org/pdf/2510.17276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17276]] Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems(https://arxiv.org/abs/2510.17276)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>Control-flow hijacking attacks manipulate orchestration mechanisms in multi-agent systems into performing unsafe actions that compromise the system and exfiltrate sensitive information. Recently proposed defenses, such as LlamaFirewall, rely on alignment checks of inter-agent communications to ensure that all agent invocations are "related to" and "likely to further" the original objective. We start by demonstrating control-flow hijacking attacks that evade these defenses even if alignment checks are performed by advanced LLMs. We argue that the safety and functionality objectives of multi-agent systems fundamentally conflict with each other. This conflict is exacerbated by the brittle definitions of "alignment" and the checkers' incomplete visibility into the execution context. We then propose, implement, and evaluate ControlValve, a new defense inspired by the principles of control-flow integrity and least privilege. ControlValve (1) generates permitted control-flow graphs for multi-agent systems, and (2) enforces that all executions comply with these graphs, along with contextual rules (generated in a zero-shot manner) for each agent invocation.</li>
</ul>

<h3>Title: Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks</h3>
<ul>
<li><strong>Authors: </strong>Xinkai Wang, Beibei Li, Zerui Shao, Ao Liu, Shouling Ji</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17277">https://arxiv.org/abs/2510.17277</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17277">https://arxiv.org/pdf/2510.17277</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17277]] Multimodal Safety Is Asymmetric: Cross-Modal Exploits Unlock Black-Box MLLMs Jailbreaks(https://arxiv.org/abs/2510.17277)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) have demonstrated significant utility across diverse real-world applications. But MLLMs remain vulnerable to jailbreaks, where adversarial inputs can collapse their safety constraints and trigger unethical responses. In this work, we investigate jailbreaks in the text-vision multimodal setting and pioneer the observation that visual alignment imposes uneven safety constraints across modalities in MLLMs, thereby giving rise to multimodal safety asymmetry. We then develop PolyJailbreak, a black-box jailbreak method grounded in reinforcement learning. Initially, we probe the model's attention dynamics and latent representation space, assessing how visual inputs reshape cross-modal information flow and diminish the model's ability to separate harmful from benign inputs, thereby exposing exploitable vulnerabilities. On this basis, we systematize them into generalizable and reusable operational rules that constitute a structured library of Atomic Strategy Primitives, which translate harmful intents into jailbreak inputs through step-wise transformations. Guided by the primitives, PolyJailbreak employs a multi-agent optimization process that automatically adapts inputs against the target models. We conduct comprehensive evaluations on a variety of open-source and closed-source MLLMs, demonstrating that PolyJailbreak outperforms state-of-the-art baselines.</li>
</ul>

<h3>Title: SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Mehdi Zekriyapanah Gashti, Mostafa Mohammadpour, Ghasem Farjamnia</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17278">https://arxiv.org/abs/2510.17278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17278">https://arxiv.org/pdf/2510.17278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17278]] SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation(https://arxiv.org/abs/2510.17278)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction, interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Accurate segmentation and classification of white blood cells (WBCs) in microscopic images are essential for diagnosis and monitoring of many hematological disorders, yet remain challenging due to staining variability, complex backgrounds, and class imbalance. In this paper, we introduce a novel Saliency-Guided Cross-Layer Deep Feature Fusion framework (SG-CLDFF) that tightly integrates saliency-driven preprocessing with multi-scale deep feature aggregation to improve both robustness and interpretability for WBC analysis. SG-CLDFF first computes saliency priors to highlight candidate WBC regions and guide subsequent feature extraction. A lightweight hybrid backbone (EfficientSwin-style) produces multi-resolution representations, which are fused by a ResNeXt-CC-inspired cross-layer fusion module to preserve complementary information from shallow and deep layers. The network is trained in a multi-task setup with concurrent segmentation and cell-type classification heads, using class-aware weighted losses and saliency-alignment regularization to mitigate imbalance and suppress background activation. Interpretability is enforced through Grad-CAM visualizations and saliency consistency checks, allowing model decisions to be inspected at the regional level. We validate the framework on standard public benchmarks (BCCD, LISC, ALL-IDB), reporting consistent gains in IoU, F1, and classification accuracy compared to strong CNN and transformer baselines. An ablation study also demonstrates the individual contributions of saliency preprocessing and cross-layer fusion. SG-CLDFF offers a practical and explainable path toward more reliable automated WBC analysis in clinical workflows.</li>
</ul>

<h3>Title: Analysis of Input-Output Mappings in Coinjoin Transactions with Arbitrary Values</h3>
<ul>
<li><strong>Authors: </strong>Jiri Gavenda, Petr Svenda, Stanislav Bobon, Vladimir Sedlacek</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17284">https://arxiv.org/abs/2510.17284</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17284">https://arxiv.org/pdf/2510.17284</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17284]] Analysis of Input-Output Mappings in Coinjoin Transactions with Arbitrary Values(https://arxiv.org/abs/2510.17284)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>A coinjoin protocol aims to increase transactional privacy for Bitcoin and Bitcoin-like blockchains via collaborative transactions, by violating assumptions behind common analysis heuristics. Estimating the resulting privacy gain is a crucial yet unsolved problem due to a range of influencing factors and large computational complexity. We adapt the BlockSci on-chain analysis software to coinjoin transactions, demonstrating a significant (10-50%) average post-mix anonymity set size decrease for all three major designs with a central coordinator: Whirlpool, Wasabi 1.x, and Wasabi 2.x. The decrease is highest during the first day and negligible after one year from a coinjoin creation. Moreover, we design a precise, parallelizable privacy estimation method, which takes into account coinjoin fees, implementation-specific limitations and users' post-mix behavior. We evaluate our method in detail on a set of emulated and real-world Wasabi 2.x coinjoins and extrapolate to its largest real-world coinjoins with hundreds of inputs and outputs. We conclude that despite the users' undesirable post-mix behavior, correctly attributing the coins to their owners is still very difficult, even with our improved analysis algorithm.</li>
</ul>

<h3>Title: Exploring Structural Degradation in Dense Representations for Self-supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Siran Dai, Qianqian Xu, Peisong Wen, Yang Liu, Qingming Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17299">https://arxiv.org/abs/2510.17299</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17299">https://arxiv.org/pdf/2510.17299</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17299]] Exploring Structural Degradation in Dense Representations for Self-supervised Learning(https://arxiv.org/abs/2510.17299)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this work, we observe a counterintuitive phenomenon in self-supervised learning (SSL): longer training may impair the performance of dense prediction tasks (e.g., semantic segmentation). We refer to this phenomenon as Self-supervised Dense Degradation (SDD) and demonstrate its consistent presence across sixteen state-of-the-art SSL methods with various losses, architectures, and datasets. When the model performs suboptimally on dense tasks at the end of training, measuring the performance during training becomes essential. However, evaluating dense performance effectively without annotations remains an open challenge. To tackle this issue, we introduce a Dense representation Structure Estimator (DSE), composed of a class-relevance measure and an effective dimensionality measure. The proposed DSE is both theoretically grounded and empirically validated to be closely correlated with the downstream performance. Based on this metric, we introduce a straightforward yet effective model selection strategy and a DSE-based regularization method. Experiments on sixteen SSL methods across four benchmarks confirm that model selection improves mIoU by $3.0\%$ on average with negligible computational cost. Additionally, DSE regularization consistently mitigates the effects of dense degradation. Code is available at this https URL.</li>
</ul>

<h3>Title: Single-Shuffle Full-Open Card-Based Protocols for Any Function</h3>
<ul>
<li><strong>Authors: </strong>Reo Eriguchi, Kazumasa Shinagawa</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17308">https://arxiv.org/abs/2510.17308</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17308">https://arxiv.org/pdf/2510.17308</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17308]] Single-Shuffle Full-Open Card-Based Protocols for Any Function(https://arxiv.org/abs/2510.17308)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure</a></li>
<li><strong>Abstract: </strong>A card-based secure computation protocol is a method for $n$ parties to compute a function $f$ on their private inputs $(x_1,\ldots,x_n)$ using physical playing cards, in such a way that the suits of revealed cards leak no information beyond the value of $f(x_1,\ldots,x_n)$. A \textit{single-shuffle full-open} protocol is a minimal model of card-based secure computation in which, after the parties place face-down cards representing their inputs, a single shuffle operation is performed and then all cards are opened to derive the output. Despite the simplicity of this model, the class of functions known to admit single-shuffle full-open protocols has been limited to a few small examples. In this work, we prove for the first time that every function admits a single-shuffle full-open protocol. We present two constructions that offer a trade-off between the number of cards and the complexity of the shuffle operation. These feasibility results are derived from a novel connection between single-shuffle full-open protocols and a cryptographic primitive known as \textit{Private Simultaneous Messages} protocols, which has rarely been studied in the context of card-based cryptography. We also present variants of single-shuffle protocols in which only a subset of cards are revealed. These protocols reduce the complexity of the shuffle operation compared to existing protocols in the same setting.</li>
</ul>

<h3>Title: The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment</h3>
<ul>
<li><strong>Authors: </strong>Eduard Marin, Jinwoo Kim, Alessio Pavoni, Mauro Conti, Roberto Di Pietro</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17311">https://arxiv.org/abs/2510.17311</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17311">https://arxiv.org/pdf/2510.17311</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17311]] The Hidden Dangers of Public Serverless Repositories: An Empirical Security Assessment(https://arxiv.org/abs/2510.17311)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>Serverless computing has rapidly emerged as a prominent cloud paradigm, enabling developers to focus solely on application logic without the burden of managing servers or underlying infrastructure. Public serverless repositories have become key to accelerating the development of serverless applications. However, their growing popularity makes them attractive targets for adversaries. Despite this, the security posture of these repositories remains largely unexplored, exposing developers and organizations to potential risks. In this paper, we present the first comprehensive analysis of the security landscape of serverless components hosted in public repositories. We analyse 2,758 serverless components from five widely used public repositories popular among developers and enterprises, and 125,936 Infrastructure as Code (IaC) templates across three widely used IaC frameworks. Our analysis reveals systemic vulnerabilities including outdated software packages, misuse of sensitive parameters, exploitable deployment configurations, susceptibility to typo-squatting attacks and opportunities to embed malicious behaviour within compressed serverless components. Finally, we provide practical recommendations to mitigate these threats.</li>
</ul>

<h3>Title: Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations</h3>
<ul>
<li><strong>Authors: </strong>Tal Barami, Nimrod Berman, Ilan Naiman, Amos H. Hason, Rotem Ezra, Omri Azencot</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17313">https://arxiv.org/abs/2510.17313</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17313">https://arxiv.org/pdf/2510.17313</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17313]] Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations(https://arxiv.org/abs/2510.17313)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Learning disentangled representations in sequential data is a key goal in deep learning, with broad applications in vision, audio, and time series. While real-world data involves multiple interacting semantic factors over time, prior work has mostly focused on simpler two-factor static and dynamic settings, primarily because such settings make data collection easier, thereby overlooking the inherently multi-factor nature of real-world data. We introduce the first standardized benchmark for evaluating multi-factor sequential disentanglement across six diverse datasets spanning video, audio, and time series. Our benchmark includes modular tools for dataset integration, model development, and evaluation metrics tailored to multi-factor analysis. We additionally propose a post-hoc Latent Exploration Stage to automatically align latent dimensions with semantic factors, and introduce a Koopman-inspired model that achieves state-of-the-art results. Moreover, we show that Vision-Language Models can automate dataset annotation and serve as zero-shot disentanglement evaluators, removing the need for manual labels and human intervention. Together, these contributions provide a robust and scalable foundation for advancing multi-factor sequential disentanglement.</li>
</ul>

<h3>Title: Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling</h3>
<ul>
<li><strong>Authors: </strong>Lipeng Xie, Sen Huang, Zhuo Zhang, Anni Zou, Yunpeng Zhai, Dingchao Ren, Kezun Zhang, Haoyuan Hu, Boyin Liu, Haoran Chen, Zhaoyang Liu, Bolin Ding</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17314">https://arxiv.org/abs/2510.17314</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17314">https://arxiv.org/pdf/2510.17314</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17314]] Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling(https://arxiv.org/abs/2510.17314)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Reward models are essential for aligning Large Language Models (LLMs) with human values, yet their development is hampered by costly preference datasets and poor interpretability. While recent rubric-based approaches offer transparency, they often lack systematic quality control and optimization, creating a trade-off between scalability and reliability. We address these limitations with a novel, training-free framework built on a key assumption: \textit{evaluation rubrics underlying human preferences exhibit significant generalization ability across diverse queries}, a property that enables remarkable data efficiency. Our two-stage approach first infers high-quality, query-specific rubrics using a validation-guided \textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these granular rubrics into a compact, non-redundant core set by maximizing an \textbf{information-theoretic coding rate}. The final output is an interpretable, hierarchical "Theme-Tips" rubric set. Extensive experiments demonstrate the framework's exceptional data efficiency and performance. Critically, using just 70 preference pairs (1.5\% of the source data), our method also empowers smaller models like Qwen3-8B to outperform specialized, fully-trained counterparts. This work pioneers a scalable, interpretable, and data-efficient path for reward modeling.</li>
</ul>

<h3>Title: A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World</h3>
<ul>
<li><strong>Authors: </strong>Wei Zhang, Zhanhao Hu, Xiao Li, Xiaopei Zhu, Xiaolin Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17322">https://arxiv.org/abs/2510.17322</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17322">https://arxiv.org/pdf/2510.17322</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17322]] A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World(https://arxiv.org/abs/2510.17322)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>In recent years, adversarial attacks against deep learning-based object detectors in the physical world have attracted much attention. To defend against these attacks, researchers have proposed various defense methods against adversarial patches, a typical form of physically-realizable attack. However, our experiments showed that simply enlarging the patch size could make these defense methods fail. Motivated by this, we evaluated various defense methods against adversarial clothes which have large coverage over the human body. Adversarial clothes provide a good test case for adversarial defense against patch-based attacks because they not only have large sizes but also look more natural than a large patch on humans. Experiments show that all the defense methods had poor performance against adversarial clothes in both the digital world and the physical world. In addition, we crafted a single set of clothes that broke multiple defense methods on Faster R-CNN. The set achieved an Attack Success Rate (ASR) of 96.06% against the undefended detector and over 64.84% ASRs against nine defended models in the physical world, unveiling the common vulnerability of existing adversarial defense methods against adversarial clothes. Code is available at: this https URL.</li>
</ul>

<h3>Title: CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration</h3>
<ul>
<li><strong>Authors: </strong>Gyuhwan Park, Kihyun Na, Injung Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17330">https://arxiv.org/abs/2510.17330</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17330">https://arxiv.org/pdf/2510.17330</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17330]] CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration(https://arxiv.org/abs/2510.17330)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, segmentation</a></li>
<li><strong>Abstract: </strong>The significance of license plate image restoration goes beyond the preprocessing stage of License Plate Recognition (LPR) systems, as it also serves various purposes, including increasing evidential value, enhancing the clarity of visual interface, and facilitating further utilization of license plate images. We propose a novel diffusion-based framework with character-level guidance, CharDiff, which effectively restores and recognizes severely degraded license plate images captured under realistic conditions. CharDiff leverages fine-grained character-level priors extracted through external segmentation and Optical Character Recognition (OCR) modules tailored for low-quality license plate images. For precise and focused guidance, CharDiff incorporates a novel Character-guided Attention through Region-wise Masking (CHARM) module, which ensures that each character's guidance is restricted to its own region, thereby avoiding interference with other regions. In experiments, CharDiff significantly outperformed the baseline restoration models in both restoration quality and recognition accuracy, achieving a 28% relative reduction in CER on the Roboflow-LP dataset, compared to the best-performing baseline model. These results indicate that the structured character-guided conditioning effectively enhances the robustness of diffusion-based license plate restoration and recognition in practical deployment scenarios.</li>
</ul>

<h3>Title: iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA</h3>
<ul>
<li><strong>Authors: </strong>Zhaoran Zhao, Xinli Yue, Jianhui Sun, Yuhao Xie, Tao Shao, Liangchao Yao, Fan Xia, Yuetang Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17332">https://arxiv.org/abs/2510.17332</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17332">https://arxiv.org/pdf/2510.17332</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17332]] iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA(https://arxiv.org/abs/2510.17332)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Image Quality Assessment (IQA) has progressed from scalar quality prediction to more interpretable, human-aligned evaluation paradigms. In this work, we address the emerging challenge of detailed and explainable IQA by proposing iDETEX-a unified multimodal large language model (MLLM) capable of simultaneously performing three key tasks: quality grounding, perception, and description. To facilitate efficient and generalizable training across these heterogeneous subtasks, we design a suite of task-specific offline augmentation modules and a data mixing strategy. These are further complemented by online enhancement strategies to fully exploit multi-sourced supervision. We validate our approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves state-of-the-art performance across all subtasks. Our model ranks first in the ICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its effectiveness and robustness in delivering accurate and interpretable quality assessments.</li>
</ul>

<h3>Title: Exploring The Missing Semantics In Event Modality</h3>
<ul>
<li><strong>Authors: </strong>Jingqian Wu, Shengpeng Xu, Yunbo Jia, Edmund Y. Lam</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17347">https://arxiv.org/abs/2510.17347</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17347">https://arxiv.org/pdf/2510.17347</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17347]] Exploring The Missing Semantics In Event Modality(https://arxiv.org/abs/2510.17347)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Event cameras offer distinct advantages such as low latency, high dynamic range, and efficient motion capture. However, event-to-video reconstruction (E2V), a fundamental event-based vision task, remains challenging, particularly for reconstructing and recovering semantic information. This is primarily due to the nature of the event camera, as it only captures intensity changes, ignoring static objects and backgrounds, resulting in a lack of semantic information in captured event modality. Further, semantic information plays a crucial role in video and frame reconstruction, yet is often overlooked by existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V framework that explores the missing visual semantic knowledge in event modality and leverages it to enhance event-to-video reconstruction. Specifically, Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to transfer the robust visual semantics from a frame-based vision foundation model, the Segment Anything Model (SAM), to the event encoder, while aligning the high-level features from distinct modalities. To better utilize the learned semantic feature, we further propose a semantic-aware feature fusion (SFF) block to integrate learned semantics in frame modality to form event representations with rich semantics that can be decoded by the event decoder. Further, to facilitate the reconstruction of semantic information, we propose a novel Semantic Perceptual E2V Supervision that helps the model to reconstruct semantic details by leveraging SAM-generated categorical labels. Extensive experiments demonstrate that Semantic-E2VID significantly enhances frame quality, outperforming state-of-the-art E2V methods across multiple benchmarks. The sample code is included in the supplementary material.</li>
</ul>

<h3>Title: Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Chenghao Zhang, Guanting Dong, Xinyu Yang, Zhicheng Dou</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17354">https://arxiv.org/abs/2510.17354</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17354">https://arxiv.org/pdf/2510.17354</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17354]] Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation(https://arxiv.org/abs/2510.17354)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) by retrieving relevant documents from an external corpus. However, existing RAG systems primarily focus on unimodal text documents, and often fall short in real-world scenarios where both queries and documents may contain mixed modalities (such as text and images). In this paper, we address the challenge of Universal Retrieval-Augmented Generation (URAG), which involves retrieving and reasoning over mixed-modal information to improve vision-language generation. To this end, we propose Nyx, a unified mixed-modal to mixed-modal retriever tailored for URAG scenarios. To mitigate the scarcity of realistic mixed-modal data, we introduce a four-stage automated pipeline for generation and filtering, leveraging web documents to construct NyxQA, a dataset comprising diverse mixed-modal question-answer pairs that better reflect real-world information needs. Building on this high-quality dataset, we adopt a two-stage training framework for Nyx: we first perform pre-training on NyxQA along with a variety of open-source retrieval datasets, followed by supervised fine-tuning using feedback from downstream vision-language models (VLMs) to align retrieval outputs with generative preferences. Experimental results demonstrate that Nyx not only performs competitively on standard text-only RAG benchmarks, but also excels in the more general and realistic URAG setting, significantly improving generation quality in vision-language tasks.</li>
</ul>

<h3>Title: Localist LLMs with Recruitment Learning</h3>
<ul>
<li><strong>Authors: </strong>Joachim Diederich</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17358">https://arxiv.org/abs/2510.17358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17358">https://arxiv.org/pdf/2510.17358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17358]] Localist LLMs with Recruitment Learning(https://arxiv.org/abs/2510.17358)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a novel framework for training large language models with continuously adjustable internal representations that span the full spectrum from localist (interpretable, rule-based) to distributed (generalizable, efficient) encodings. The key innovations are (1) a locality dial, a tunable parameter that dynamically controls the degree of localization during both training and inference without requiring model retraining, (2) an information-theoretic recruitment mechanism that adaptively allocates semantic blocks as needed, eliminating the requirement for complete domain knowledge at initialization, and (3) a hierarchical recruitment framework that extends capacity allocation to entire specialized LLMs, enabling multi-granularity architectural adaptation. This is achieved through group sparsity penalties on attention mechanisms, information-theoretic anchor design, dynamic rule injection, and principled recruitment  criteria based on penalized likelihood with explicit units. We provide rigorous mathematical results establishing explicit threshold conditions under which attention provably concentrates on semantically relevant blocks at stationary points, with exact bounds on attention entropy and pointer fidelity. The hierarchical recruitment mechanism provides convergence guarantees at both the block level (fine-grained, within-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the system discovers semantic partitions that balance model complexity against data encoding efficiency. This framework enables practitioners to continuously interpolate between interpretable and high-performance modes while adapting architectural capacity at multiple granularities, supporting applications in regulated domains requiring both transparency and capability.</li>
</ul>

<h3>Title: M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception</h3>
<ul>
<li><strong>Authors: </strong>U.V.B.L Udugama, George Vosselman, Francesco Nex</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17363">https://arxiv.org/abs/2510.17363</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17363">https://arxiv.org/pdf/2510.17363</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17363]] M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception(https://arxiv.org/abs/2510.17363)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Deploying real-time spatial perception on edge devices requires efficient multi-task models that leverage complementary task information while minimizing computational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel multi-task learning framework designed for semantic segmentation and depth, edge, and surface normal estimation from a single monocular image. Unlike conventional approaches that rely on independent single-task models or shared encoder-decoder architectures, M2H introduces a Window-Based Cross-Task Attention Module that enables structured feature exchange while preserving task-specific details, improving prediction consistency across tasks. Built on a lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time deployment and serves as the foundation for monocular spatial perception systems supporting 3D scene graph construction in dynamic environments. Comprehensive evaluations show that M2H outperforms state-of-the-art multi-task models on NYUDv2, surpasses single-task depth and semantic baselines on Hypersim, and achieves superior performance on the Cityscapes dataset, all while maintaining computational efficiency on laptop hardware. Beyond benchmarks, M2H is validated on real-world data, demonstrating its practicality in spatial perception tasks.</li>
</ul>

<h3>Title: Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs</h3>
<ul>
<li><strong>Authors: </strong>Vaggelis Dorovatas, Soroush Seifi, Gunshi Gupta, Rahaf Aljundi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17364">https://arxiv.org/abs/2510.17364</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17364">https://arxiv.org/pdf/2510.17364</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17364]] Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs(https://arxiv.org/abs/2510.17364)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video Large Language Models (Video-LLMs) excel at understanding videos in-context, provided they have full access to the video when answering queries. However, these models face challenges in streaming scenarios where hour-long videos must be processed online, and questions need timely responses. In this work, we propose a training-free approach compatible with standard Video-LLMs, leveraging three key concepts: 1) LLM-informed selection of visual tokens to identify those that the LLM has attended to and contributed to its understanding of each short clip. Our attention-based selection allows us to discard up to ~95% of unimportant visual tokens with minimal performance loss; 2) Recurrent processing of past selected tokens to generate temporally coherent understanding of each processed clip; 3) Caption-based question answering for lightweight and accurate responses. Our method achieves state-of-the-art performance on streaming video benchmarks, striking a balance between efficiency and effectiveness.</li>
</ul>

<h3>Title: Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise</h3>
<ul>
<li><strong>Authors: </strong>Paweł Borsukiewicz, Fadi Boutros, Iyiola E. Olatunji, Charles Beumier, Wendkûuni C. Ouedraogo, Jacques Klein, Tegawendé F. Bissyandé</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17372">https://arxiv.org/abs/2510.17372</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17372">https://arxiv.org/pdf/2510.17372</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17372]] Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise(https://arxiv.org/abs/2510.17372)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>The deployment of facial recognition systems has created an ethical dilemma: achieving high accuracy requires massive datasets of real faces collected without consent, leading to dataset retractions and potential legal liabilities under regulations like GDPR. While synthetic facial data presents a promising privacy-preserving alternative, the field lacks comprehensive empirical evidence of its viability. This study addresses this critical gap through extensive evaluation of synthetic facial recognition datasets. We present a systematic literature review identifying 25 synthetic facial recognition datasets (2018-2025), combined with rigorous experimental validation. Our methodology examines seven key requirements for privacy-preserving synthetic data: identity leakage prevention, intra-class variability, identity separability, dataset scale, ethical data sourcing, bias mitigation, and benchmark reliability. Through experiments involving over 10 million synthetic samples, extended by a comparison of results reported on five standard benchmarks, we provide the first comprehensive empirical assessment of synthetic data's capability to replace real datasets. Best-performing synthetic datasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and 94.91% respectively, surpassing established real datasets including CASIA-WebFace (94.70%). While those images remain private, publicly available alternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our findings reveal that they ensure proper intra-class variability while maintaining identity separability. Demographic bias analysis shows that, even though synthetic data inherits limited biases, it offers unprecedented control for bias mitigation through generation parameters. These results establish synthetic facial data as a scientifically viable and ethically imperative alternative for facial recognition research.</li>
</ul>

<h3>Title: Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories</h3>
<ul>
<li><strong>Authors: </strong>Achref Jaziri, Martin Rogmann, Martin Mundt, Visvanathan Ramesh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17381">https://arxiv.org/abs/2510.17381</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17381">https://arxiv.org/pdf/2510.17381</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17381]] Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories(https://arxiv.org/abs/2510.17381)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Detecting out-of-distribution (OOD) data is critical for machine learning, be it for safety reasons or to enable open-ended learning. However, beyond mere detection, choosing an appropriate course of action typically hinges on the type of OOD data encountered. Unfortunately, the latter is generally not distinguished in practice, as modern OOD detection methods collapse distributional shifts into single scalar outlier scores. This work argues that scalar-based methods are thus insufficient for OOD data to be properly contextualized and prospectively exploited, a limitation we overcome with the introduction of DISC: Diffusion-based Statistical Characterization. DISC leverages the iterative denoising process of diffusion models to extract a rich, multi-dimensional feature vector that captures statistical discrepancies across multiple noise levels. Extensive experiments on image and tabular benchmarks show that DISC matches or surpasses state-of-the-art detectors for OOD detection and, crucially, also classifies OOD type, a capability largely absent from prior work. As such, our work enables a shift from simple binary OOD detection to a more granular detection.</li>
</ul>

<h3>Title: Latent Spaces Beyond Synthesis: From GANs to Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Ludovica Schaerf</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17383">https://arxiv.org/abs/2510.17383</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17383">https://arxiv.org/pdf/2510.17383</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17383]] Latent Spaces Beyond Synthesis: From GANs to Diffusion Models(https://arxiv.org/abs/2510.17383)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper examines the evolving nature of internal representations in generative visual models, focusing on the conceptual and technical shift from GANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's account of synthesis as the amalgamation of distributed representations, we propose a distinction between "synthesis in a strict sense", where a compact latent space wholly determines the generative process, and "synthesis in a broad sense," which characterizes models whose representational labor is distributed across layers. Through close readings of model architectures and a targeted experimental setup that intervenes in layerwise representations, we show how diffusion models fragment the burden of representation and thereby challenge assumptions of unified internal space. By situating these findings within media theoretical frameworks and critically engaging with metaphors such as the latent space and the Platonic Representation Hypothesis, we argue for a reorientation of how generative AI is understood: not as a direct synthesis of content, but as an emergent configuration of specialized processes.</li>
</ul>

<h3>Title: Closed-Loop Transfer for Weakly-supervised Affordance Grounding</h3>
<ul>
<li><strong>Authors: </strong>Jiajin Tang, Zhengxuan Wei, Ge Zheng, Sibei Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17384">https://arxiv.org/abs/2510.17384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17384">https://arxiv.org/pdf/2510.17384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17384]] Closed-Loop Transfer for Weakly-supervised Affordance Grounding(https://arxiv.org/abs/2510.17384)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>Humans can perform previously unexperienced interactions with novel objects simply by observing others engage with them. Weakly-supervised affordance grounding mimics this process by learning to locate object regions that enable actions on egocentric images, using exocentric interaction images with image-level annotations. However, extracting affordance knowledge solely from exocentric images and transferring it one-way to egocentric images limits the applicability of previous works in complex interaction scenarios. Instead, this study introduces LoopTrans, a novel closed-loop framework that not only transfers knowledge from exocentric to egocentric but also transfers back to enhance exocentric knowledge extraction. Within LoopTrans, several innovative mechanisms are introduced, including unified cross-modal localization and denoising knowledge distillation, to bridge domain gaps between object-centered egocentric and interaction-centered exocentric images while enhancing knowledge transfer. Experiments show that LoopTrans achieves consistent improvements across all metrics on image and video benchmarks, even handling challenging scenarios where object interaction regions are fully occluded by the human body.</li>
</ul>

<h3>Title: TabR1: Taming GRPO for tabular reasoning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Pengxiang Cai, Zihao Gao, Jintai Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17385">https://arxiv.org/abs/2510.17385</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17385">https://arxiv.org/pdf/2510.17385</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17385]] TabR1: Taming GRPO for tabular reasoning LLMs(https://arxiv.org/abs/2510.17385)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Tabular prediction has traditionally relied on gradient-boosted decision trees and specialized deep learning models, which excel within tasks but provide limited interpretability and weak transfer across tables. Reasoning large language models (LLMs) promise cross-task adaptability with trans- parent reasoning traces, yet their potential has not been fully realized for tabular data. This paper presents TabR1, the first reasoning LLM for tabular prediction with multi-step reasoning. At its core is Permutation Relative Policy Optimization (PRPO), a simple yet efficient reinforcement learning method that encodes column-permutation invariance as a structural prior. By construct- ing multiple label-preserving permutations per sample and estimating advantages both within and across permutations, PRPO transforms sparse rewards into dense learning signals and improves generalization. With limited supervision, PRPO activates the reasoning ability of LLMs for tabular prediction, enhancing few-shot and zero-shot performance as well as interpretability. Comprehensive experiments demonstrate that TabR1 achieves performance comparable to strong baselines under full-supervision fine-tuning. In the zero-shot setting, TabR1 approaches the performance of strong baselines under the 32-shot setting. Moreover, TabR1 (8B) substantially outperforms much larger LLMs across various tasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B).</li>
</ul>

<h3>Title: The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple, Self-Contained Directives</h3>
<ul>
<li><strong>Authors: </strong>Henry Lim, Kwan Hui Lim</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17388">https://arxiv.org/abs/2510.17388</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17388">https://arxiv.org/pdf/2510.17388</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17388]] The Atomic Instruction Gap: Instruction-Tuned LLMs Struggle with Simple, Self-Contained Directives(https://arxiv.org/abs/2510.17388)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Instruction-tuned large language models (IT-LLMs) exhibit strong zero-shot reasoning, yet their ability to execute simple, self-contained instructions remains underexplored, despite this being foundational to complex instruction-following. We evaluate 20 IT-LLMs on modified MMLU and MMLU-Pro benchmarks, by systematically varying the format of option labels (alphabetic, numeric, Roman) while keeping their meaning identical under four paradigms, namely: (1) With explicit instructions, label changes cause large performance shifts (e.g., -30.45\% for Roman vs. numeric), revealing instruction-format bias. (2) Without instructions, performance drops further (up to -10.84\%) and label sensitivity intensifies, underscoring the role of explicit guidance. (3) When option contents are removed, models fail random-choice baselines except with numeric labels, suggesting weak adherence to atomic directives. (4) Three-shot exemplars yield no significant gains in robustness or fidelity, and generation analyses show persistent label errors, especially for non-numeric formats. Across model sizes, larger LLMs achieve higher accuracy but remain inconsistent in instruction adherence. These results expose the insufficiencies of current instruction-tuning paradigms and highlight the need for evaluation methods and training strategies that explicitly target atomic instruction-following.</li>
</ul>

<h3>Title: EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Numaan Naeem, Abdellah El Mekki, Muhammad Abdul-Mageed</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17389">https://arxiv.org/abs/2510.17389</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17389">https://arxiv.org/pdf/2510.17389</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17389]] EduAdapt: A Question Answer Benchmark Dataset for Evaluating Grade-Level Adaptability in LLMs(https://arxiv.org/abs/2510.17389)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) are transforming education by answering questions, explaining complex concepts, and generating content across a wide range of subjects. Despite strong performance on academic benchmarks, they often fail to tailor responses to students' grade levels. This is a critical need in K-12 education, where age-appropriate vocabulary and explanation are essential for effective learning. Existing models frequently produce outputs that are too advanced or vague for younger learners, and there are no standardized benchmarks to evaluate their ability to adjust across cognitive and developmental stages. To address this gap, we introduce EduAdapt, a benchmark of nearly 48k grade-labeled QA pairs across nine science subjects, spanning Grades 1-12 and grouped into four grade levels. We evaluate a diverse set of open-source LLMs on EduAdapt and find that while larger models generally perform better, they still struggle with generating suitable responses for early-grade students (Grades 1-5). Our work presents the first dataset and evaluation framework for assessing grade-level adaptability in LLMs, aiming to foster more developmentally aligned educational AI systems through better training and prompting strategies. EduAdapt code and datasets are publicly available at this https URL.</li>
</ul>

<h3>Title: RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse Problems</h3>
<ul>
<li><strong>Authors: </strong>Keivan Faghih Niresi, Zepeng Zhang, Olga Fink</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17396">https://arxiv.org/abs/2510.17396</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17396">https://arxiv.org/pdf/2510.17396</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17396]] RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse Problems(https://arxiv.org/abs/2510.17396)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Time series data are often affected by various forms of corruption, such as missing values, noise, and outliers, which pose significant challenges for tasks such as forecasting and anomaly detection. To address these issues, inverse problems focus on reconstructing the original signal from corrupted data by leveraging prior knowledge about its underlying structure. While deep learning methods have demonstrated potential in this domain, they often require extensive pretraining and struggle to generalize under distribution shifts. In this work, we propose RINS-T (Robust Implicit Neural Solvers for Time Series Linear Inverse Problems), a novel deep prior framework that achieves high recovery performance without requiring pretraining data. RINS-T leverages neural networks as implicit priors and integrates robust optimization techniques, making it resilient to outliers while relaxing the reliance on Gaussian noise assumptions. To further improve optimization stability and robustness, we introduce three key innovations: guided input initialization, input perturbation, and convex output combination techniques. Each of these contributions strengthens the framework's optimization stability and robustness. These advancements make RINS-T a flexible and effective solution for addressing complex real-world time series challenges. Our code is available at this https URL.</li>
</ul>

<h3>Title: Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Xie, Shuai Zeng, Yang Yu, Xiaoting Tang, Guanghui An, Dong Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17402">https://arxiv.org/abs/2510.17402</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17402">https://arxiv.org/pdf/2510.17402</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17402]] Leveraging Group Relative Policy Optimization to Advance Large Language Models in Traditional Chinese Medicine(https://arxiv.org/abs/2510.17402)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Traditional Chinese Medicine (TCM) presents a rich and structurally unique knowledge system that challenges conventional applications of large language models (LLMs). Although previous TCM-specific LLMs have shown progress through supervised fine-tuning, they often face limitations in alignment, data quality, and evaluation consistency. In this study, we introduce Ladder-base, the first TCM-focused LLM trained with Group Relative Policy Optimization (GRPO), a reinforcement learning method that improves reasoning and factual consistency by optimizing response selection based on intra-group comparisons. Ladder-base is built upon the Qwen2.5-7B-Instruct foundation model and trained exclusively on the textual subset of the TCM-Ladder benchmark, using 80 percent of the data for training and the remaining 20 percent split evenly between validation and test sets. Through standardized evaluation, Ladder-base demonstrates superior performance across multiple reasoning metrics when compared to both state-of-the-art general-purpose LLMs such as GPT-4, Gemini 2.5, Claude 3, and Qwen3 and domain-specific TCM models including BenTsao, HuatuoGPT2, and Zhongjing. These findings suggest that GRPO provides an effective and efficient strategy for aligning LLMs with expert-level reasoning in traditional medical domains and supports the development of trustworthy and clinically grounded TCM artificial intelligence systems.</li>
</ul>

<h3>Title: Process Automation Architecture Using RFID for Transparent Voting Systems</h3>
<ul>
<li><strong>Authors: </strong>Stella N. Arinze, Patrick U. Okafor, Onyekachi M. Egwuagu, Augustine O. Nwajana</a></li>
<li><strong>Subjects: </strong>cs.CR, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17403">https://arxiv.org/abs/2510.17403</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17403">https://arxiv.org/pdf/2510.17403</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17403]] Process Automation Architecture Using RFID for Transparent Voting Systems(https://arxiv.org/abs/2510.17403)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, robust</a></li>
<li><strong>Abstract: </strong>This paper presents the development of a process automation architecture leveraging Radio Frequency Identification (RFID) technology for secure, transparent and efficient voting systems. The proposed architecture automates the voting workflow through RFID-enabled voter identification, encrypted vote casting, and secure data transmission. Each eligible voter receives a smart RFID card containing a uniquely encrypted identifier, which is verified using an RC522 reader interfaced with a microcontroller. Upon successful verification, the voter interacts with a touchscreen interface to cast a vote, which is then encrypted using AES-128 and securely stored on a local SD card or transmitted via GSM to a central server. A tamper-proof monitoring mechanism records each session with time-stamped digital signatures, ensuring auditability and data integrity. The architecture is designed to function in both online and offline modes, with an automated batch synchronization mechanism that updates vote records once network connectivity is restored. System testing in simulated environments confirmed 100% voter authentication accuracy, minimized latency (average voting time of 11.5 seconds), and robustness against cloning, double voting, and data interception. The integration of real-time monitoring and secure process control modules enables electoral authorities to automate data logging, detect anomalies, and validate system integrity dynamically. This work demonstrates a scalable, automation-driven solution for voting infrastructure, offering enhanced transparency, resilience, and deployment flexibility, especially in environments where digital transformation of electoral processes is critically needed.</li>
</ul>

<h3>Title: S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction</h3>
<ul>
<li><strong>Authors: </strong>Tiezhi Wang, Wilhelm Haverkamp, Nils Strodthoff</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17406">https://arxiv.org/abs/2510.17406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17406">https://arxiv.org/pdf/2510.17406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17406]] S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction(https://arxiv.org/abs/2510.17406)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The electrocardiogram (ECG) exemplifies biosignal-based time series with continuous, temporally ordered structure reflecting cardiac physiological and pathophysiological dynamics. Detailed analysis of these dynamics has proven challenging, as conventional methods capture either global trends or local waveform features but rarely their simultaneous interplay at high temporal resolution. To bridge global and local signal analysis, we introduce S4ECG, a novel deep learning architecture leveraging structured state space models for multi-epoch arrhythmia classification. Our joint multi-epoch predictions significantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC, with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998, demonstrating superior performance in-distribution and enhanced out-of-distribution robustness. Systematic investigation reveals optimal temporal dependency windows spanning 10-20 minutes for peak performance. This work contributes to a paradigm shift toward temporally-aware arrhythmia detection algorithms, opening new possibilities for ECG interpretation, in particular for complex arrhythmias like atrial fibrillation and atrial flutter.</li>
</ul>

<h3>Title: A Conditional Diffusion Model for Probabilistic Prediction of Battery Capacity Degradation</h3>
<ul>
<li><strong>Authors: </strong>Hequn Li, Zhongwei Deng, Chunlin Jiang, Yvxin He andZhansheng Ning</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17414">https://arxiv.org/abs/2510.17414</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17414">https://arxiv.org/pdf/2510.17414</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17414]] A Conditional Diffusion Model for Probabilistic Prediction of Battery Capacity Degradation(https://arxiv.org/abs/2510.17414)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Accurate prediction of lithium-ion battery capacity and its associated uncertainty is essential for reliable battery management but remains challenging due to the stochastic nature of aging. This paper presents a novel method, termed the Condition Diffusion U-Net with Attention (CDUA), which integrates feature engineering and deep learning to address this challenge. The proposed approach employs a diffusion-based generative model for time-series forecasting and incorporates attention mechanisms to enhance predictive performance. Battery capacity is first derived from real-world vehicle operation data. The most relevant features are then identified using the Pearson correlation coefficient and the XGBoost algorithm. These features are used to train the CDUA model, which comprises two core components: (1) a contextual U-Net with self-attention to capture complex temporal dependencies, and (2) a denoising network to reconstruct accurate capacity values from noisy observations. Experimental validation on the real-world vehicle data demonstrates that the proposed CDUA model achieves a relative Mean Absolute Error (MAE) of 0.94% and a relative Root Mean Square Error (RMSE) of 1.14%, with a narrow 95% confidence interval of 3.74% in relative width. These results confirm that CDUA provides both accurate capacity estimation and reliable uncertainty quantification. Comparative experiments further verify its robustness and superior performance over existing mainstream approaches.</li>
</ul>

<h3>Title: BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Xie, Yang Yu, Yibo Chen, Hanyao Zhang, Lening Zhao, Jiaxuan He, Lei Jiang, Xiaoting Tang, Guanghui An, Dong Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.MA, cs.MM, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17415">https://arxiv.org/abs/2510.17415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17415">https://arxiv.org/pdf/2510.17415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17415]] BenCao: An Instruction-Tuned Large Language Model for Traditional Chinese Medicine(https://arxiv.org/abs/2510.17415)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Traditional Chinese Medicine (TCM), with a history spanning over two millennia, plays a role in global healthcare. However, applying large language models (LLMs) to TCM remains challenging due to its reliance on holistic reasoning, implicit logic, and multimodal diagnostic cues. Existing TCM-domain LLMs have made progress in text-based understanding but lack multimodal integration, interpretability, and clinical applicability. To address these limitations, we developed BenCao, a ChatGPT-based multimodal assistant for TCM, integrating structured knowledge bases, diagnostic data, and expert feedback refinement. BenCao was trained through natural language instruction tuning rather than parameter retraining, aligning with expert-level reasoning and ethical norms specific to TCM. The system incorporates a comprehensive knowledge base of over 1,000 classical and modern texts, a scenario-based instruction framework for diverse interactions, a chain-of-thought simulation mechanism for interpretable reasoning, and a feedback refinement process involving licensed TCM practitioners. BenCao connects to external APIs for tongue-image classification and multimodal database retrieval, enabling dynamic access to diagnostic resources. In evaluations across single-choice question benchmarks and multimodal classification tasks, BenCao achieved superior accuracy to general-domain and TCM-domain models, particularly in diagnostics, herb recognition, and constitution classification. The model was deployed as an interactive application on the OpenAI GPTs Store, accessed by nearly 1,000 users globally as of October 2025. This study demonstrates the feasibility of developing a TCM-domain LLM through natural language-based instruction tuning and multimodal integration, offering a practical framework for aligning generative AI with traditional medical reasoning and a scalable pathway for real-world deployment.</li>
</ul>

<h3>Title: Diffusion Models as Dataset Distillation Priors</h3>
<ul>
<li><strong>Authors: </strong>Duo Su, Huyu Wu, Huanran Chen, Yiming Shi, Yuzhu Wang, Xi Ye, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17421">https://arxiv.org/abs/2510.17421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17421">https://arxiv.org/pdf/2510.17421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17421]] Diffusion Models as Dataset Distillation Priors(https://arxiv.org/abs/2510.17421)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Dataset distillation aims to synthesize compact yet informative datasets from large ones. A significant challenge in this field is achieving a trifecta of diversity, generalization, and representativeness in a single distilled dataset. Although recent generative dataset distillation methods adopt powerful diffusion models as their foundation models, the inherent representativeness prior in diffusion models is overlooked. Consequently, these approaches often necessitate the integration of external constraints to enhance data quality. To address this, we propose Diffusion As Priors (DAP), which formalizes representativeness by quantifying the similarity between synthetic and real data in feature space using a Mercer kernel. We then introduce this prior as guidance to steer the reverse diffusion process, enhancing the representativeness of distilled samples without any retraining. Extensive experiments on large-scale datasets, such as ImageNet-1K and its subsets, demonstrate that DAP outperforms state-of-the-art methods in generating high-fidelity datasets while achieving superior cross-architecture generalization. Our work not only establishes a theoretical connection between diffusion priors and the objectives of dataset distillation but also provides a practical, training-free framework for improving the quality of the distilled dataset.</li>
</ul>

<h3>Title: Agentic Reinforcement Learning for Search is Unsafe</h3>
<ul>
<li><strong>Authors: </strong>Yushi Yang, Shreyansh Padarha, Andrew Lee, Adam Mahdi</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17431">https://arxiv.org/abs/2510.17431</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17431">https://arxiv.org/pdf/2510.17431</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17431]] Agentic Reinforcement Learning for Search is Unsafe(https://arxiv.org/abs/2510.17431)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Agentic reinforcement learning (RL) trains large language models to autonomously call tools during reasoning, with search as the most common application. These models excel at multi-step reasoning tasks, but their safety properties are not well understood. In this study, we show that RL-trained search models inherit refusal from instruction tuning and often deflect harmful requests by turning them into safe queries. However, this safety is fragile. Two simple attacks, one that forces the model to begin response with search (Search attack), another that encourages models to repeatedly search (Multi-search attack), trigger cascades of harmful searches and answers. Across two model families (Qwen, Llama) with both local and web search, these attacks lower refusal rates by up to 60.0%, answer safety by 82.5%, and search-query safety by 82.4%. The attacks succeed by triggering models to generate harmful, request-mirroring search queries before they can generate the inherited refusal tokens. This exposes a core weakness of current RL training: it rewards continued generation of effective queries without accounting for their harmfulness. As a result, RL search models have vulnerabilities that users can easily exploit, making it urgent to develop safety-aware agentic RL pipelines optimising for safe search.</li>
</ul>

<h3>Title: Rethinking Nighttime Image Deraining via Learnable Color Space Transformation</h3>
<ul>
<li><strong>Authors: </strong>Qiyuan Guan, Xiang Chen, Guiyue Jin, Jiyu Jin, Shumin Fan, Tianyu Song, Jinshan Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17440">https://arxiv.org/abs/2510.17440</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17440">https://arxiv.org/pdf/2510.17440</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17440]] Rethinking Nighttime Image Deraining via Learnable Color Space Transformation(https://arxiv.org/abs/2510.17440)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Compared to daytime image deraining, nighttime image deraining poses significant challenges due to inherent complexities of nighttime scenarios and the lack of high-quality datasets that accurately represent the coupling effect between rain and illumination. In this paper, we rethink the task of nighttime image deraining and contribute a new high-quality benchmark, HQ-NightRain, which offers higher harmony and realism compared to existing datasets. In addition, we develop an effective Color Space Transformation Network (CST-Net) for better removing complex rain from nighttime scenes. Specifically, we propose a learnable color space converter (CSC) to better facilitate rain removal in the Y channel, as nighttime rain is more pronounced in the Y channel compared to the RGB color space. To capture illumination information for guiding nighttime deraining, implicit illumination guidance is introduced enabling the learned features to improve the model's robustness in complex scenarios. Extensive experiments show the value of our dataset and the effectiveness of our method. The source code and datasets are available at this https URL.</li>
</ul>

<h3>Title: Explainable AI for microseismic event detection</h3>
<ul>
<li><strong>Authors: </strong>Ayrat Abdullin, Denis Anikiev, Umair bin Waheed</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17458">https://arxiv.org/abs/2510.17458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17458">https://arxiv.org/pdf/2510.17458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17458]] Explainable AI for microseismic event detection(https://arxiv.org/abs/2510.17458)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep neural networks like PhaseNet show high accuracy in detecting microseismic events, but their black-box nature is a concern in critical applications. We apply explainable AI (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive Explanations (SHAP), to interpret the PhaseNet model's decisions and improve its reliability. Grad-CAM highlights that the network's attention aligns with P- and S-wave arrivals. SHAP values quantify feature contributions, confirming that vertical-component amplitudes drive P-phase picks while horizontal components dominate S-phase picks, consistent with geophysical principles. Leveraging these insights, we introduce a SHAP-gated inference scheme that combines the model's output with an explanation-based metric to reduce errors. On a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of 0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet (F1-score 0.97) and demonstrating enhanced robustness to noise. These results show that XAI can not only interpret deep learning models but also directly enhance their performance, providing a template for building trust in automated seismic detectors.</li>
</ul>

<h3>Title: Evaluating Large Language Models on Urdu Idiom Translation</h3>
<ul>
<li><strong>Authors: </strong>Muhammad Farmal Khan, Mousumi Akter</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17460">https://arxiv.org/abs/2510.17460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17460">https://arxiv.org/pdf/2510.17460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17460]] Evaluating Large Language Models on Urdu Idiom Translation(https://arxiv.org/abs/2510.17460)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Idiomatic translation remains a significant challenge in machine translation, especially for low resource languages such as Urdu, and has received limited prior attention. To advance research in this area, we introduce the first evaluation datasets for Urdu to English idiomatic translation, covering both Native Urdu and Roman Urdu scripts and annotated with gold-standard English equivalents. We evaluate multiple open-source Large Language Models (LLMs) and Neural Machine Translation (NMT) systems on this task, focusing on their ability to preserve idiomatic and cultural meaning. Automatic metrics including BLEU, BERTScore, COMET, and XCOMET are used to assess translation quality. Our findings indicate that prompt engineering enhances idiomatic translation compared to direct translation, though performance differences among prompt types are relatively minor. Moreover, cross script comparisons reveal that text representation substantially affects translation quality, with Native Urdu inputs producing more accurate idiomatic translations than Roman Urdu.</li>
</ul>

<h3>Title: CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics</h3>
<ul>
<li><strong>Authors: </strong>Dan Zheng, Jing Feng, Juan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17467">https://arxiv.org/abs/2510.17467</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17467">https://arxiv.org/pdf/2510.17467</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17467]] CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics(https://arxiv.org/abs/2510.17467)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric, extraction</a></li>
<li><strong>Abstract: </strong>Current research in Electrocardiogram (ECG) biometrics mainly emphasizes resting-state conditions, leaving the performance decline in rest-exercise scenarios largely unresolved. This paper introduces CrossStateECG, a robust ECG-based authentication model explicitly tailored for cross-state (rest-exercise) conditions. The proposed model creatively combines multi-scale deep convolutional feature extraction with attention mechanisms to ensure strong identification across different physiological states. Experimental results on the exercise-ECGID dataset validate the effectiveness of CrossStateECG, achieving an identification accuracy of 92.50% in the Rest-to-Exercise scenario (training on resting ECG and testing on post-exercise ECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG and testing on resting ECG). Furthermore, CrossStateECG demonstrates exceptional performance across both state combinations, reaching an accuracy of 99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios. Additional validations on the ECG-ID and MIT-BIH datasets further confirmed the generalization abilities of CrossStateECG, underscoring its potential as a practical solution for post-exercise ECG-based authentication in dynamic real-world settings.</li>
</ul>

<h3>Title: Layer Specialization Underlying Compositional Reasoning in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Jing Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17469">https://arxiv.org/abs/2510.17469</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17469">https://arxiv.org/pdf/2510.17469</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17469]] Layer Specialization Underlying Compositional Reasoning in Transformers(https://arxiv.org/abs/2510.17469)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers exhibit compositional reasoning on sequences not observed during training, a capability often attributed to in-context learning (ICL) and skill composition. We investigate this phenomenon using the Random Hierarchy Model (RHM), a probabilistic context-free grammar that generates sequences through recursive rule application. Models are trained on subsets of sequences and evaluated across four generalization conditions: memorization, in-distribution generalization, out-of-distribution generalization with the same rules, and cross-layer transfer. Behaviorally, performance improves systematically with task complexity and the number of in-context examples, with out-of-distribution tasks requiring substantially more examples than in-distribution scenarios. Mechanistically, we identify a progressive emergence of layer specialization during training that correlates with generalization performance. Principal component analysis and attention pattern clustering reveal that transformers develop structured, hierarchically organized representations in specialized layers. These results demonstrate that transformers develop modular, interpretable mechanisms supporting compositional reasoning, linking internal algorithmic structure to observed behavioral capabilities.</li>
</ul>

<h3>Title: DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition</h3>
<ul>
<li><strong>Authors: </strong>Fo Hu, Can Wang, Qinxu Zheng, Xusheng Yang, Bin Zhou, Gang Li, Yu Sun, Wen-an Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17475">https://arxiv.org/abs/2510.17475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17475">https://arxiv.org/pdf/2510.17475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17475]] DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition(https://arxiv.org/abs/2510.17475)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Significant inter-individual variability limits the generalization of EEG-based emotion recognition under cross-domain settings. We address two core challenges in multi-source adaptation: (1) dynamically modeling distributional heterogeneity across sources and quantifying their relevance to a target to reduce negative transfer; and (2) achieving fine-grained semantic consistency to strengthen class discrimination. We propose a distribution-aware multi-source domain adaptation network (DAMSDAN). DAMSDAN integrates prototype-based constraints with adversarial learning to drive the encoder toward discriminative, domain-invariant emotion representations. A domain-aware source weighting strategy based on maximum mean discrepancy (MMD) dynamically estimates inter-domain shifts and reweights source contributions. In addition, a prototype-guided conditional alignment module with dual pseudo-label interaction enhances pseudo-label reliability and enables category-level, fine-grained alignment, mitigating noise propagation and semantic drift. Experiments on SEED and SEED-IV show average accuracies of 94.86\% and 79.78\% for cross-subject, and 95.12\% and 83.15\% for cross-session protocols. On the large-scale FACED dataset, DAMSDAN achieves 82.88\% (cross-subject). Extensive ablations and interpretability analyses corroborate the effectiveness of the proposed framework for cross-domain EEG-based emotion recognition.</li>
</ul>

<h3>Title: Disparities in Multilingual LLM-Based Healthcare Q&A</h3>
<ul>
<li><strong>Authors: </strong>Ipek Baris Schlicht, Burcu Sayin, Zhixue Zhao, Frederik M. Labonté, Cesare Barbera, Marco Viviani, Paolo Rosso, Lucie Flek</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17476">https://arxiv.org/abs/2510.17476</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17476">https://arxiv.org/pdf/2510.17476</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17476]] Disparities in Multilingual LLM-Based Healthcare Q&A(https://arxiv.org/abs/2510.17476)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Equitable access to reliable health information is vital when integrating AI into healthcare. Yet, information quality varies across languages, raising concerns about the reliability and consistency of multilingual Large Language Models (LLMs). We systematically examine cross-lingual disparities in pre-training source and factuality alignment in LLM answers for multilingual healthcare Q&A across English, German, Turkish, Chinese (Mandarin), and Italian. We (i) constructed Multilingual Wiki Health Care (MultiWikiHealthCare), a multilingual dataset from Wikipedia; (ii) analyzed cross-lingual healthcare coverage; (iii) assessed LLM response alignment with these references; and (iv) conducted a case study on factual alignment through the use of contextual information and Retrieval-Augmented Generation (RAG). Our findings reveal substantial cross-lingual disparities in both Wikipedia coverage and LLM factual alignment. Across LLMs, responses align more with English Wikipedia, even when the prompts are non-English. Providing contextual excerpts from non-English Wikipedia at inference time effectively shifts factual alignment toward culturally relevant knowledge. These results highlight practical pathways for building more equitable, multilingual AI systems for healthcare.</li>
</ul>

<h3>Title: Towards geological inference with process-based and deep generative modeling, part 2: inversion of fluvial deposits and latent-space disentanglement</h3>
<ul>
<li><strong>Authors: </strong>Guillaume Rongier, Luk Peeters</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.geo-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17478">https://arxiv.org/abs/2510.17478</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17478">https://arxiv.org/pdf/2510.17478</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17478]] Towards geological inference with process-based and deep generative modeling, part 2: inversion of fluvial deposits and latent-space disentanglement(https://arxiv.org/abs/2510.17478)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>High costs and uncertainties make subsurface decision-making challenging, as acquiring new data is rarely scalable. Embedding geological knowledge directly into predictive models offers a valuable alternative. A joint approach enables just that: process-based models that mimic geological processes can help train generative models that make predictions more efficiently. This study explores whether a generative adversarial network (GAN) - a type of deep-learning algorithm for generative modeling - trained to produce fluvial deposits can be inverted to match well and seismic data. Four inversion approaches applied to three test samples with 4, 8, and 20 wells struggled to match these well data, especially as the well number increased or as the test sample diverged from the training data. The key bottleneck lies in the GAN's latent representation: it is entangled, so samples with similar sedimentological features are not necessarily close in the latent space. Label conditioning or latent overparameterization can partially disentangle the latent space during training, although not yet sufficiently for a successful inversion. Fine-tuning the GAN to restructure the latent space locally reduces mismatches to acceptable levels for all test cases, with and without seismic data. But this approach depends on an initial, partially successful inversion step, which influences the quality and diversity of the final samples. Overall, GANs can already handle the tasks required for their integration into geomodeling workflows. We still need to further assess their robustness, and how to best leverage them in support of geological interpretation.</li>
</ul>

<h3>Title: Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization</h3>
<ul>
<li><strong>Authors: </strong>Aurélien Bellet, Edwige Cyffers, Davide Frey, Romaric Gaudel, Dimitri Lerévérend, François Taïani</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17480">https://arxiv.org/abs/2510.17480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17480">https://arxiv.org/pdf/2510.17480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17480]] Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization(https://arxiv.org/abs/2510.17480)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Decentralized Learning (DL) enables users to collaboratively train models without sharing raw data by iteratively averaging local updates with neighbors in a network graph. This setting is increasingly popular for its scalability and its ability to keep data local under user control. Strong privacy guarantees in DL are typically achieved through Differential Privacy (DP), with results showing that DL can even amplify privacy by disseminating noise across peer-to-peer communications. Yet in practice, the observed privacy-utility trade-off often appears worse than in centralized training, which may be due to limitations in current DP accounting methods for DL. In this paper, we show that recent advances in centralized DP accounting based on Matrix Factorization (MF) for analyzing temporal noise correlations can also be leveraged in DL. By generalizing existing MF results, we show how to cast both standard DL algorithms and common trust models into a unified formulation. This yields tighter privacy accounting for existing DP-DL algorithms and provides a principled way to develop new ones. To demonstrate the approach, we introduce MAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that outperforms existing methods on synthetic and real-world graphs.</li>
</ul>

<h3>Title: ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts</h3>
<ul>
<li><strong>Authors: </strong>Zheyue Tan, Zhiyuan Li, Tao Yuan, Dong Zhou, Weilin Liu, Yueqing Zhuang, Yadong Li, Guowei Niu, Cheng Qin, Zhuyu Yao, Congyi Liu, Haiyang Xu, Boxun Li, Guohao Dai, Bo Zhao, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17483">https://arxiv.org/abs/2510.17483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17483">https://arxiv.org/pdf/2510.17483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17483]] ReXMoE: Reusing Experts with Minimal Overhead in Mixture-of-Experts(https://arxiv.org/abs/2510.17483)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Mixture-of-Experts (MoE) architectures have emerged as a promising approach to scale Large Language Models (LLMs). MoE boosts the efficiency by activating a subset of experts per token. Recent works show that fine-grained experts substantially enriches the combinatorial flexibility of active experts and enhances model expressiveness. However, such a design is fundamentally limited by the layer-local routing mechanism: each layer is restricted to its own expert pool. This requires a careful trade-off between expert dimensionality and routing diversity given fixed parameter budgets. We describe ReXMoE, a novel MoE architecture that improves routing beyond the existing layer-local approaches by allowing routers to reuse experts across adjacent layers. ReXMoE decouples expert dimensionality from per-layer budgets, enabling richer expert combinations without sacrificing individual expert capacity or inflating overall parameters. To this end, we propose a new progressive scaling routing (PSR) strategy to gradually increase the candidate expert pool during training. As a result, ReXMoE improves both language modeling and downstream task performance. Extensive experiments on models ranging from 0.5B to 7B parameters across different architectures demonstrate that ReXMoE consistently improves performance under fixed architectural dimensions, confirming ReXMoE as new design paradigm for parameter-efficient and scalable MoE-based LLMs.</li>
</ul>

<h3>Title: DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured Hierarchical Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Yongxin He, Shan Zhang, Yixuan Cao, Lei Ma, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17489">https://arxiv.org/abs/2510.17489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17489">https://arxiv.org/pdf/2510.17489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17489]] DETree: DEtecting Human-AI Collaborative Texts via Tree-Structured Hierarchical Representation Learning(https://arxiv.org/abs/2510.17489)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Detecting AI-involved text is essential for combating misinformation, plagiarism, and academic misconduct. However, AI text generation includes diverse collaborative processes (AI-written text edited by humans, human-written text edited by AI, and AI-generated text refined by other AI), where various or even new LLMs could be involved. Texts generated through these varied processes exhibit complex characteristics, presenting significant challenges for detection. Current methods model these processes rather crudely, primarily employing binary classification (purely human vs. AI-involved) or multi-classification (treating human-AI collaboration as a new class). We observe that representations of texts generated through different processes exhibit inherent clustering relationships. Therefore, we propose DETree, a novel approach that models the relationships among different processes as a Hierarchical Affinity Tree structure, and introduces a specialized loss function that aligns text representations with this tree. To facilitate this learning, we developed RealBench, a comprehensive benchmark dataset that automatically incorporates a wide spectrum of hybrid texts produced through various human-AI collaboration processes. Our method improves performance in hybrid text detection tasks and significantly enhances robustness and generalization in out-of-distribution scenarios, particularly in few-shot learning conditions, further demonstrating the promise of training-based approaches in OOD settings. Our code and dataset are available at this https URL.</li>
</ul>

<h3>Title: Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents</h3>
<ul>
<li><strong>Authors: </strong>Yihong Tang, Kehai Chen, Liang Yue, Jinxin Fan, Caishen Zhou, Xiaoguang Li, Yuyang Zhang, Mingming Zhao, Shixiong Kai, Kaiyang Guo, Xingshan Zeng, Wenjing Cun, Lifeng Shang, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17491">https://arxiv.org/abs/2510.17491</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17491">https://arxiv.org/pdf/2510.17491</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17491]] Empowering Real-World: A Survey on the Technology, Practice, and Evaluation of LLM-driven Industry Agents(https://arxiv.org/abs/2510.17491)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rise of large language models (LLMs), LLM agents capable of autonomous reasoning, planning, and executing complex tasks have become a frontier in artificial intelligence. However, how to translate the research on general agents into productivity that drives industry transformations remains a significant challenge. To address this, this paper systematically reviews the technologies, applications, and evaluation methods of industry agents based on LLMs. Using an industry agent capability maturity framework, it outlines the evolution of agents in industry applications, from "process execution systems" to "adaptive social systems." First, we examine the three key technological pillars that support the advancement of agent capabilities: Memory, Planning, and Tool Use. We discuss how these technologies evolve from supporting simple tasks in their early forms to enabling complex autonomous systems and collective intelligence in more advanced forms. Then, we provide an overview of the application of industry agents in real-world domains such as digital engineering, scientific discovery, embodied intelligence, collaborative business execution, and complex system simulation. Additionally, this paper reviews the evaluation benchmarks and methods for both fundamental and specialized capabilities, identifying the challenges existing evaluation systems face regarding authenticity, safety, and industry specificity. Finally, we focus on the practical challenges faced by industry agents, exploring their capability boundaries, developmental potential, and governance issues in various scenarios, while providing insights into future directions. By combining technological evolution with industry practices, this review aims to clarify the current state and offer a clear roadmap and theoretical foundation for understanding and building the next generation of industry agents.</li>
</ul>

<h3>Title: I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models</h3>
<ul>
<li><strong>Authors: </strong>Giacomo Camposampiero, Michael Hersche, Roger Wattenhofer, Abu Sebastian, Abbas Rahimi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17496">https://arxiv.org/abs/2510.17496</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17496">https://arxiv.org/pdf/2510.17496</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17496]] I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models(https://arxiv.org/abs/2510.17496)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate generalization and robustness in analogical and mathematical reasoning for Large Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X extends I-RAVEN by increasing operand complexity, attribute range, and introducing perceptual uncertainty. Compared to LLMs, empirical results show that LRMs achieve improved productivity and systematicity on longer reasoning relations and wider attribute ranges, respectively. However, LRMs are still significantly challenged by reasoning under uncertainty and cannot effectively explore multiple probabilistic outcomes.</li>
</ul>

<h3>Title: Deep Self-Evolving Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Zihan Liu, Shun Zheng, Xumeng Wen, Yang Wang, Jiang Bian, Mao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17498">https://arxiv.org/abs/2510.17498</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17498">https://arxiv.org/pdf/2510.17498</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17498]] Deep Self-Evolving Reasoning(https://arxiv.org/abs/2510.17498)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Long-form chain-of-thought reasoning has become a cornerstone of advanced reasoning in large language models. While recent verification-refinement frameworks have enabled proprietary models to solve Olympiad-level problems, their effectiveness hinges on strong, reliable verification and correction capabilities, which remain fragile in open-weight, smaller-scale models. This work demonstrates that even with weak verification and refinement capabilities on hard tasks, the reasoning limits of such models can be substantially extended through a probabilistic paradigm we call Deep Self-Evolving Reasoning (DSER). We conceptualize iterative reasoning as a Markov chain, where each step represents a stochastic transition in the solution space. The key insight is that convergence to a correct solution is guaranteed as long as the probability of improvement marginally exceeds that of degradation. By running multiple long-horizon, self-evolving processes in parallel, DSER amplifies these small positive tendencies, enabling the model to asymptotically approach correct answers. Empirically, we apply DSER to the DeepSeek-R1-0528-Qwen3-8B model. On the challenging AIME 2024-2025 benchmark, DSER solves 5 out of 9 previously unsolvable problems and boosts overall performance, enabling this compact model to surpass the single-turn accuracy of its 600B-parameter teacher through majority voting. Beyond its immediate utility for test-time scaling, the DSER framework serves to diagnose the fundamental limitations of current open-weight reasoners. By clearly delineating their shortcomings in self-verification, refinement, and stability, our findings establish a clear research agenda for developing next-generation models with powerful, intrinsic self-evolving capabilities.</li>
</ul>

<h3>Title: Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization</h3>
<ul>
<li><strong>Authors: </strong>Yuanli Wu, Long Zhang, Yue Du, Bin Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17501">https://arxiv.org/abs/2510.17501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17501">https://arxiv.org/pdf/2510.17501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17501]] Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization(https://arxiv.org/abs/2510.17501)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>With the rapid proliferation of video content across social media, surveillance, and education platforms, efficiently summarizing long videos into concise yet semantically faithful surrogates has become increasingly vital. Existing supervised methods achieve strong in-domain accuracy by learning from dense annotations but suffer from high labeling costs and limited cross-dataset generalization, while unsupervised approaches, though label-free, often fail to capture high-level human semantics and fine-grained narrative cues. More recently, zero-shot prompting pipelines have leveraged large language models (LLMs) for training-free video summarization, yet remain highly sensitive to handcrafted prompt templates and dataset-specific score normalization. To overcome these limitations, we introduce a rubric-guided, pseudo-labeled prompting framework that transforms a small subset of ground-truth annotations into high-confidence pseudo labels, which are aggregated into structured, dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During inference, first and last segments are scored based solely on their descriptions, whereas intermediate ones incorporate brief contextual summaries of adjacent scenes to assess narrative progression and redundancy. This contextual prompting enables the LLM to balance local salience and global coherence without parameter tuning. On SumMe and TVSum, our method achieves F1 scores of \textbf{57.58} and \textbf{63.05}, surpassing unsupervised and prior zero-shot baselines while approaching supervised performance. The results demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based scoring and establishes a general, interpretable zero-shot paradigm for video summarization.</li>
</ul>

<h3>Title: Annotation-Efficient Universal Honesty Alignment</h3>
<ul>
<li><strong>Authors: </strong>Shiyu Ni, Keping Bi, Jiafeng Guo, Minghao Tang, Jingtong Wu, Zengxin Han, Xueqi Cheng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17509">https://arxiv.org/abs/2510.17509</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17509">https://arxiv.org/pdf/2510.17509</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17509]] Annotation-Efficient Universal Honesty Alignment(https://arxiv.org/abs/2510.17509)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Honesty alignment-the ability of large language models (LLMs) to recognize their knowledge boundaries and express calibrated confidence-is essential for trustworthy deployment. Existing methods either rely on training-free confidence estimation (e.g., token probabilities, self-consistency) or training-based calibration with correctness annotations. While effective, achieving universal honesty alignment with training-based calibration requires costly, large-scale labeling. To support annotation-efficient training, we introduce Elicitation-Then-Calibration (EliCal), a two-stage framework that first elicits internal confidence using inexpensive self-consistency supervision, then calibrates this confidence with a small set of correctness annotations. To support a large-scale study, we release HonestyBench, a benchmark covering ten free-form QA datasets with 560k training and 70k evaluation instances annotated with correctness and self-consistency signals. Experiments show that EliCal achieves near-optimal alignment with only 1k correctness annotations (0.18% of full supervision) and better alignment performance on unseen MMLU tasks than the calibration-only baseline, offering a scalable solution toward universal honesty alignment in LLMs.</li>
</ul>

<h3>Title: SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors</h3>
<ul>
<li><strong>Authors: </strong>Tiancheng Hu, Joachim Baumann, Lorenzo Lupo, Dirk Hovy, Nigel Collier, Paul Röttger</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17516">https://arxiv.org/abs/2510.17516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17516">https://arxiv.org/pdf/2510.17516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17516]] SimBench: Benchmarking the Ability of Large Language Models to Simulate Human Behaviors(https://arxiv.org/abs/2510.17516)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language model (LLM) simulations of human behavior have the potential to revolutionize the social and behavioral sciences, if and only if they faithfully reflect real human behaviors. Current evaluations are fragmented, based on bespoke tasks and metrics, creating a patchwork of incomparable results. To address this, we introduce SimBench, the first large-scale, standardized benchmark for a robust, reproducible science of LLM simulation. By unifying 20 diverse datasets covering tasks from moral decision-making to economic choice across a large global participant pool, SimBench provides the necessary foundation to ask fundamental questions about when, how, and why LLM simulations succeed or fail. We show that, while even the best LLMs today have limited simulation ability (score: 40.80/100), performance scales log-linearly with model size. Simulation performance is not improved by increased inference-time compute. We demonstrate an alignment-simulation trade-off: instruction-tuning improves performance on low-entropy (consensus) questions but degrades it on high-entropy (diverse) ones. Models particularly struggle when simulating specific demographic groups. Finally, we demonstrate that simulation ability correlates most strongly with deep, knowledge-intensive reasoning (MMLU-Pro, r=0.939). By making progress measurable, we aim to accelerate the development of more faithful LLM simulators.</li>
</ul>

<h3>Title: SAFE-D: A Spatiotemporal Detection Framework for Abnormal Driving Among Parkinson's Disease-like Drivers</h3>
<ul>
<li><strong>Authors: </strong>Hangcheng Cao, Baixiang Huang, Longzhi Yuan, Haonan An, Zihan Fang, Xianhao Chen, Yuguang Fang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17517">https://arxiv.org/abs/2510.17517</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17517">https://arxiv.org/pdf/2510.17517</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17517]] SAFE-D: A Spatiotemporal Detection Framework for Abnormal Driving Among Parkinson's Disease-like Drivers(https://arxiv.org/abs/2510.17517)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>A driver's health state serves as a determinant factor in driving behavioral regulation. Subtle deviations from normalcy can lead to operational anomalies, posing risks to public transportation safety. While prior efforts have developed detection mechanisms for functionally-driven temporary anomalies such as drowsiness and distraction, limited research has addressed pathologically-triggered deviations, especially those stemming from chronic medical conditions. To bridge this gap, we investigate the driving behavior of Parkinson's disease patients and propose SAFE-D, a novel framework for detecting Parkinson-related behavioral anomalies to enhance driving safety. Our methodology starts by performing analysis of Parkinson's disease symptomatology, focusing on primary motor impairments, and establishes causal links to degraded driving performance. To represent the subclinical behavioral variations of early-stage Parkinson's disease, our framework integrates data from multiple vehicle control components to build a behavioral profile. We then design an attention-based network that adaptively prioritizes spatiotemporal features, enabling robust anomaly detection under physiological variability. Finally, we validate SAFE-D on the Logitech G29 platform and CARLA simulator, using data from three road maps to emulate real-world driving. Our results show SAFE-D achieves 96.8% average accuracy in distinguishing normal and Parkinson-affected driving patterns.</li>
</ul>

<h3>Title: MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models</h3>
<ul>
<li><strong>Authors: </strong>Yongshun Zhang, Zhongyi Fan, Yonghang Zhang, Zhangzikang Li, Weifeng Chen, Zhongwei Feng, Chaoyue Wang, Peng Hou, Anxiang Zeng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17519">https://arxiv.org/abs/2510.17519</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17519">https://arxiv.org/pdf/2510.17519</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17519]] MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models(https://arxiv.org/abs/2510.17519)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In recent years, large-scale generative models for visual content (\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable progress. However, training large-scale video generation models remains particularly challenging and resource-intensive due to cross-modal text-video alignment, the long sequences involved, and the complex spatiotemporal dependencies. To address these challenges, we present a training framework that optimizes four pillars: (i) data processing, (ii) model architecture, (iii) training strategy, and (iv) infrastructure for large-scale video generation models. These optimizations delivered significant efficiency gains and performance improvements across all stages of data preprocessing, video compression, parameter scaling, curriculum-based pretraining, and alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent state-of-the-art video generators overall and, on e-commerce-oriented video generation tasks, surpasses leading open-source baselines in human evaluations. More importantly, we open-source the complete stack, including model weights, Megatron-Core-based large-scale training code, and inference pipelines for video generation and enhancement. To our knowledge, this is the first public release of large-scale video generation training code that exploits Megatron-Core to achieve high training efficiency and near-linear multi-node scaling, details are available in \href{this https URL}{our webpage}.</li>
</ul>

<h3>Title: Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning</h3>
<ul>
<li><strong>Authors: </strong>Canran Xiao, Chuangxin Zhao, Zong Ke, Fei Shen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17520">https://arxiv.org/abs/2510.17520</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17520">https://arxiv.org/pdf/2510.17520</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17520]] Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning(https://arxiv.org/abs/2510.17520)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Long-tail imbalance is endemic to multi-label learning: a few head labels dominate the gradient signal, while the many rare labels that matter in practice are silently ignored. We tackle this problem by casting the task as a cooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label Learning (CD-GTMLL) framework, the label space is split among several cooperating players that share a global accuracy payoff yet earn additional curiosity rewards that rise with label rarity and inter-player disagreement. These curiosity bonuses inject gradient on under-represented tags without hand-tuned class weights. We prove that gradient best-response updates ascend a differentiable potential and converge to tail-aware stationary points that tighten a lower bound on the expected Rare-F1. Extensive experiments on conventional benchmarks and three extreme-scale datasets show consistent state-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the strongest baselines, while ablations reveal emergent division of labour and faster consensus on rare classes. CD-GTMLL thus offers a principled, scalable route to long-tail robustness in multi-label prediction.</li>
</ul>

<h3>Title: Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs</h3>
<ul>
<li><strong>Authors: </strong>Francesco Balassone, Víctor Mayoral-Vilches, Stefan Rass, Martin Pinzger, Gaetano Perrone, Simon Pietro Romano, Peter Schartner</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17521">https://arxiv.org/abs/2510.17521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17521">https://arxiv.org/pdf/2510.17521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17521]] Cybersecurity AI: Evaluating Agentic Cybersecurity in Attack/Defense CTFs(https://arxiv.org/abs/2510.17521)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack</a></li>
<li><strong>Abstract: </strong>We empirically evaluate whether AI systems are more effective at attacking or defending in cybersecurity. Using CAI (Cybersecurity AI)'s parallel execution framework, we deployed autonomous agents in 23 Attack/Defense CTF battlegrounds. Statistical analysis reveals defensive agents achieve 54.3% unconstrained patching success versus 28.3% offensive initial access (p=0.0193), but this advantage disappears under operational constraints: when defense requires maintaining availability (23.9%) and preventing all intrusions (15.2%), no significant difference exists (p>0.05). Exploratory taxonomy analysis suggests potential patterns in vulnerability exploitation, though limited sample sizes preclude definitive conclusions. This study provides the first controlled empirical evidence challenging claims of AI attacker advantage, demonstrating that defensive effectiveness critically depends on success criteria, a nuance absent from conceptual analyses but essential for deployment. These findings underscore the urgency for defenders to adopt open-source Cybersecurity AI frameworks to maintain security equilibrium against accelerating offensive automation.</li>
</ul>

<h3>Title: Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples</h3>
<ul>
<li><strong>Authors: </strong>Sidney Bender, Ole Delzer, Jan Herrmann, Heike Antje Marxfeld, Klaus-Robert Müller, Grégoire Montavon</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17524">https://arxiv.org/abs/2510.17524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17524">https://arxiv.org/pdf/2510.17524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17524]] Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples(https://arxiv.org/abs/2510.17524)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Deep learning models remain vulnerable to spurious correlations, leading to so-called Clever Hans predictors that undermine robustness even in large-scale foundation and self-supervised models. Group distributional robustness methods, such as Deep Feature Reweighting (DFR) rely on explicit group labels to upweight underrepresented subgroups, but face key limitations: (1) group labels are often unavailable, (2) low within-group sample sizes hinder coverage of the subgroup distribution, and (3) performance degrades sharply when multiple spurious correlations fragment the data into even smaller groups. We propose Counterfactual Knowledge Distillation (CFKD), a framework that sidesteps these issues by generating diverse counterfactuals, enabling a human annotator to efficiently explore and correct the model's decision boundaries through a knowledge distillation step. Unlike DFR, our method not only reweights the undersampled groups, but it also enriches them with new data points. Our method does not require any confounder labels, achieves effective scaling to multiple confounders, and yields balanced generalization across groups. We demonstrate CFKD's efficacy across five datasets, spanning synthetic tasks to an industrial application, with particularly strong gains in low-data regimes with pronounced spurious correlations. Additionally, we provide an ablation study on the effect of the chosen counterfactual explainer and teacher model, highlighting their impact on robustness.</li>
</ul>

<h3>Title: MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Yovin Yahathugoda, Davide Prezzi, Piyalitt Ittichaiwong, Vicky Goh, Sebastien Ourselin, Michela Antonelli</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17529">https://arxiv.org/abs/2510.17529</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17529">https://arxiv.org/pdf/2510.17529</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17529]] MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation(https://arxiv.org/abs/2510.17529)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Active Surveillance (AS) is a treatment option for managing low and intermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while monitoring disease progression through serial MRI and clinical follow-up. Accurate prostate segmentation is an important preliminary step for automating this process, enabling automated detection and diagnosis of PCa. However, existing deep-learning segmentation models are often trained on single-time-point and expertly annotated datasets, making them unsuitable for longitudinal AS analysis, where multiple time points and a scarcity of expert labels hinder their effective fine-tuning. To address these challenges, we propose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation architecture that computes the segmentation for time point t by leveraging the MRI and the corresponding segmentation mask from the previous time point. We introduce two new components: (i) a Mamba-enhanced Cross-Attention Module, which integrates the Mamba block into cross attention to efficiently capture temporal evolution and long-range spatial dependencies, and (ii) a Shape Extractor Module that encodes the previous segmentation mask into a latent anatomical representation for refined zone delination. Moreover, we introduce a semi-supervised self-training strategy that leverages pseudo-labels generated from a pre-trained nnU-Net, enabling effective learning without expert annotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results showed that it significantly outperforms state-of-the-art U-Net and Transformer-based models, achieving superior prostate zone segmentation even when trained on limited and noisy data.</li>
</ul>

<h3>Title: OncoReason: Structuring Clinical Reasoning in LLMs for Robust and Interpretable Survival Prediction</h3>
<ul>
<li><strong>Authors: </strong>Raghu Vamshi Hemadri, Geetha Krishna Guruju, Kristi Topollai, Anna Ewa Choromanska</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17532">https://arxiv.org/abs/2510.17532</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17532">https://arxiv.org/pdf/2510.17532</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17532]] OncoReason: Structuring Clinical Reasoning in LLMs for Robust and Interpretable Survival Prediction(https://arxiv.org/abs/2510.17532)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Predicting cancer treatment outcomes requires models that are both accurate and interpretable, particularly in the presence of heterogeneous clinical data. While large language models (LLMs) have shown strong performance in biomedical NLP, they often lack structured reasoning capabilities critical for high-stakes decision support. We present a unified, multi-task learning framework that aligns autoregressive LLMs with clinical reasoning for outcome prediction on the MSK-CHORD dataset. Our models are trained to jointly perform binary survival classification, continuous survival time regression, and natural language rationale generation. We evaluate three alignment strategies: (1) standard supervised fine-tuning (SFT), (2) SFT with Chain-of-Thought (CoT) prompting to elicit step-by-step reasoning, and (3) Group Relative Policy Optimization (GRPO), a reinforcement learning method that aligns model outputs to expert-derived reasoning trajectories. Experiments with LLaMa3-8B and Med42-8B backbones demonstrate that CoT prompting improves F1 by +6.0 and reduces MAE by 12%, while GRPO achieves state-of-the-art interpretability and predictive performance across BLEU, ROUGE, and BERTScore. We further show that existing biomedical LLMs often fail to produce valid reasoning traces due to architectural constraints. Our findings underscore the importance of reasoning-aware alignment in multi-task clinical modeling and set a new benchmark for interpretable, trustworthy LLMs in precision oncology.</li>
</ul>

<h3>Title: TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model</h3>
<ul>
<li><strong>Authors: </strong>Yichen Liu, Yan Lin, Shengnan Guo, Zeyu Zhou, Youfang Lin, Huaiyu Wan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17545">https://arxiv.org/abs/2510.17545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17545">https://arxiv.org/pdf/2510.17545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17545]] TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model(https://arxiv.org/abs/2510.17545)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Vehicle GPS trajectories record how vehicles move over time, storing valuable travel semantics, including movement patterns and travel purposes. Learning travel semantics effectively and efficiently is crucial for real-world applications of trajectory data, which is hindered by two major challenges. First, travel purposes are tied to the functions of the roads and points-of-interest (POIs) involved in a trip. Such information is encoded in textual addresses and descriptions and introduces heavy computational burden to modeling. Second, real-world trajectories often contain redundant points, which harm both computational efficiency and trajectory embedding quality. To address these challenges, we propose TrajMamba, a novel approach for efficient and semantically rich vehicle trajectory learning. TrajMamba introduces a Traj-Mamba Encoder that captures movement patterns by jointly modeling both GPS and road perspectives of trajectories, enabling robust representations of continuous travel behaviors. It also incorporates a Travel Purpose-aware Pre-training procedure to integrate travel purposes into the learned embeddings without introducing extra overhead to embedding calculation. To reduce redundancy in trajectories, TrajMamba features a Knowledge Distillation Pre-training scheme to identify key trajectory points through a learnable mask generator and obtain effective compressed trajectory embeddings. Extensive experiments on two real-world datasets and three downstream tasks show that TrajMamba outperforms state-of-the-art baselines in both efficiency and accuracy.</li>
</ul>

<h3>Title: Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation</h3>
<ul>
<li><strong>Authors: </strong>Collin Zhang, Fei Huang, Chenhan Yuan, Junyang Lin</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17555">https://arxiv.org/abs/2510.17555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17555">https://arxiv.org/pdf/2510.17555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17555]] Language Confusion Gate: Language-Aware Decoding Through Model Self-Distillation(https://arxiv.org/abs/2510.17555)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) often experience language confusion, which is the unintended mixing of languages during text generation. Current solutions to this problem either necessitate model retraining or cannot differentiate between harmful confusion and acceptable code-switching. This paper introduces the Language Confusion Gate (LCG), a lightweight, plug-in solution that filters tokens during decoding without altering the base LLM. The LCG is trained using norm-adjusted self-distillation to predict appropriate language families and apply masking only when needed. Our method is based on the findings that language confusion is infrequent, correct-language tokens are usually among the top predictions, and output token embedding norms are larger for high-resource languages, which biases sampling. When evaluated across various models, including Qwen3, GPT-OSS, Gemma3, Llama3.1, LCG decreases language confusion significantly, often by an order of magnitude, without negatively impacting task performance. Code is available at this https URL.</li>
</ul>

<h3>Title: The Free Transformer</h3>
<ul>
<li><strong>Authors: </strong>François Fleuret</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17558">https://arxiv.org/abs/2510.17558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17558">https://arxiv.org/pdf/2510.17558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17558]] The Free Transformer(https://arxiv.org/abs/2510.17558)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>We propose an extension of the decoder Transformer that conditions its generative process on random latent variables which are learned without supervision thanks to a variational procedure. Experimental evaluations show that allowing such a conditioning translates into substantial improvements on downstream tasks.</li>
</ul>

<h3>Title: An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Lindsay Spoor, Álvaro Serra-Gómez, Aske Plaat, Thomas Moerland</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17564">https://arxiv.org/abs/2510.17564</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17564">https://arxiv.org/pdf/2510.17564</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17564]] An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning(https://arxiv.org/abs/2510.17564)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In safety-critical domains such as robotics, navigation and power systems, constrained optimization problems arise where maximizing performance must be carefully balanced with associated constraints. Safe reinforcement learning provides a framework to address these challenges, with Lagrangian methods being a popular choice. However, the effectiveness of Lagrangian methods crucially depends on the choice of the Lagrange multiplier $\lambda$, which governs the trade-off between return and constraint cost. A common approach is to update the multiplier automatically during training. Although this is standard in practice, there remains limited empirical evidence on the robustness of an automated update and its influence on overall performance. Therefore, we analyze (i) optimality and (ii) stability of Lagrange multipliers in safe reinforcement learning across a range of tasks. We provide $\lambda$-profiles that give a complete visualization of the trade-off between return and constraint cost of the optimization problem. These profiles show the highly sensitive nature of $\lambda$ and moreover confirm the lack of general intuition for choosing the optimal value $\lambda^*$. Our findings additionally show that automated multiplier updates are able to recover and sometimes even exceed the optimal performance found at $\lambda^*$ due to the vast difference in their learning trajectories. Furthermore, we show that automated multiplier updates exhibit oscillatory behavior during training, which can be mitigated through PID-controlled updates. However, this method requires careful tuning to achieve consistently better performance across tasks. This highlights the need for further research on stabilizing Lagrangian methods in safe reinforcement learning. The code used to reproduce our results can be found at this https URL.</li>
</ul>

<h3>Title: PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception</h3>
<ul>
<li><strong>Authors: </strong>Kaichen Zhou, Yuhan Wang, Grace Chen, Xinhai Chang, Gaspard Beaudouin, Fangneng Zhan, Paul Pu Liang, Mengyu Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17568">https://arxiv.org/abs/2510.17568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17568">https://arxiv.org/pdf/2510.17568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17568]] PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception(https://arxiv.org/abs/2510.17568)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent 3D feed-forward models, such as the Visual Geometry Grounded Transformer (VGGT), have shown strong capability in inferring 3D attributes of static scenes. However, since they are typically trained on static datasets, these models often struggle in real-world scenarios involving complex dynamic elements, such as moving humans or deformable objects like umbrellas. To address this limitation, we introduce PAGE-4D, a feedforward model that extends VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and point cloud reconstruction -- all without post-processing. A central challenge in multi-task 4D reconstruction is the inherent conflict between tasks: accurate camera pose estimation requires suppressing dynamic regions, while geometry reconstruction requires modeling them. To resolve this tension, we propose a dynamics-aware aggregator that disentangles static and dynamic information by predicting a dynamics-aware mask -- suppressing motion cues for pose estimation while amplifying them for geometry reconstruction. Extensive experiments show that PAGE-4D consistently outperforms the original VGGT in dynamic scenarios, achieving superior results in camera pose estimation, monocular and video depth estimation, and dense point map reconstruction.</li>
</ul>

<h3>Title: Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides</h3>
<ul>
<li><strong>Authors: </strong>Jyler Menard, R. A. Mansbach</a></li>
<li><strong>Subjects: </strong>cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17569">https://arxiv.org/abs/2510.17569</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17569">https://arxiv.org/pdf/2510.17569</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17569]] Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides(https://arxiv.org/abs/2510.17569)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat bacterial infections. Discovering and designing such peptides is difficult because of the vast number of possible sequences of amino acids. Deep generative models, such as variational autoencoders, have shown value in peptide design due to their ability to model sequence space with a continuous-valued latent space. Although such models have already been used to great effect in biomolecular design, they still suffer from a lack of interpretability and rigorous quantification of latent space quality as a search space. We investigate (1) whether further compression of the design space via dimensionality reduction may facilitate optimization, (2) the interpretability of the spaces, and (3) how organizing latent spaces with physicochemical properties may improve the efficiency of optimizing antimicrobial activity. We find that further reduction of the latent space via dimensionality reduction can be advantageous when organizing the space with more relevant information at data availability, that using the dimensionality reduction search space can be more interpretable, and that we can organize the latent space with different physicochemical properties even at different percentages of available labels.</li>
</ul>

<h3>Title: CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification</h3>
<ul>
<li><strong>Authors: </strong>Ludi Li, Junbin Mao, Hanhe Lin, Xu Tian, Fang-Xiang Wu, Jin Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17584">https://arxiv.org/abs/2510.17584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17584">https://arxiv.org/pdf/2510.17584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17584]] CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification(https://arxiv.org/abs/2510.17584)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical practice such as Alzheimer's disease diagnosis. To train a robust model for multi-pulse MRI classification, it requires large and diverse data from various medical institutions while protecting privacy by preventing raw data sharing across institutions. Although federated learning (FL) is a feasible solution to address this issue, it poses challenges of model convergence due to the effect of data heterogeneity and substantial communication overhead due to large numbers of parameters transmitted within the model. To address these challenges, we propose CEPerFed, a communication-efficient personalized FL method. It mitigates the effect of data heterogeneity by incorporating client-side historical risk gradients and historical mean gradients to coordinate local and global optimization. The former is used to weight the contributions from other clients, enhancing the reliability of local updates, while the latter enforces consistency between local updates and the global optimization direction to ensure stable convergence across heterogeneous data distributions. To address the high communication overhead, we propose a hierarchical SVD (HSVD) strategy that transmits only the most critical information required for model updates. Experiments on five classification tasks demonstrate the effectiveness of the CEPerFed method. The code will be released upon acceptance at this https URL.</li>
</ul>

<h3>Title: Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset</h3>
<ul>
<li><strong>Authors: </strong>Chuhong Wang, Hua Li, Chongyi Li, Huazhong Liu, Xiongxin Tang, Sam Kwong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17585">https://arxiv.org/abs/2510.17585</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17585">https://arxiv.org/pdf/2510.17585</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17585]] Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset(https://arxiv.org/abs/2510.17585)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, segmentation</a></li>
<li><strong>Abstract: </strong>With the development of underwater exploration and marine protection, underwater vision tasks are widespread. Due to the degraded underwater environment, characterized by color distortion, low contrast, and blurring, camouflaged instance segmentation (CIS) faces greater challenges in accurately segmenting objects that blend closely with their surroundings. Traditional camouflaged instance segmentation methods, trained on terrestrial-dominated datasets with limited underwater samples, may exhibit inadequate performance in underwater scenes. To address these issues, we introduce the first underwater camouflaged instance segmentation (UCIS) dataset, abbreviated as UCIS4K, which comprises 3,953 images of camouflaged marine organisms with instance-level annotations. In addition, we propose an Underwater Camouflaged Instance Segmentation network based on Segment Anything Model (UCIS-SAM). Our UCIS-SAM includes three key modules. First, the Channel Balance Optimization Module (CBOM) enhances channel characteristics to improve underwater feature learning, effectively addressing the model's limited understanding of underwater environments. Second, the Frequency Domain True Integration Module (FDTIM) is proposed to emphasize intrinsic object features and reduce interference from camouflage patterns, enhancing the segmentation performance of camouflaged objects blending with their surroundings. Finally, the Multi-scale Feature Frequency Aggregation Module (MFFAM) is designed to strengthen the boundaries of low-contrast camouflaged instances across multiple frequency bands, improving the model's ability to achieve more precise segmentation of camouflaged objects. Extensive experiments on the proposed UCIS4K and public benchmarks show that our UCIS-SAM outperforms state-of-the-art approaches.</li>
</ul>

<h3>Title: LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis</h3>
<ul>
<li><strong>Authors: </strong>Huiyuan Xie, Chenyang Li, Huining Zhu, Chubin Zhang, Yuxiao Ye, Zhenghao Liu, Zhiyuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17602">https://arxiv.org/abs/2510.17602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17602">https://arxiv.org/pdf/2510.17602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17602]] LawChain: Modeling Legal Reasoning Chains for Chinese Tort Case Analysis(https://arxiv.org/abs/2510.17602)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Legal reasoning is a fundamental component of legal analysis and decision-making. Existing computational approaches to legal reasoning predominantly rely on generic reasoning frameworks such as syllogism and IRAC, which do not comprehensively examine the nuanced processes that underpin legal reasoning. Moreover, current research has largely focused on criminal cases, with insufficient modeling for civil cases. In this work, we present a novel framework for explicitly modeling legal reasoning in the analysis of Chinese tort-related civil cases. We first operationalize the legal reasoning processes used in tort analysis into the LawChain framework. LawChain is a three-module reasoning framework, with each module consisting of multiple finer-grained sub-steps. Informed by the LawChain framework, we introduce the task of tort legal reasoning and construct an evaluation benchmark, LawChain$_{eval}$, to systematically assess the critical steps within analytical reasoning chains for tort analysis. Leveraging this benchmark, we evaluate state-of-the-art large language models for their legal reasoning ability in civil tort contexts. Our results indicate that current models still fall short in accurately handling crucial elements of tort legal reasoning. Furthermore, we introduce several baseline approaches that explicitly incorporate LawChain-style reasoning through prompting or post-training. We conduct further experiments on additional legal analysis tasks, such as Legal Named-Entity Recognition and Criminal Damages Calculation, to verify the generalizability of these baselines. The proposed baseline approaches achieve significant improvements in tort-related legal reasoning and generalize well to related legal analysis tasks, thus demonstrating the value of explicitly modeling legal reasoning chains to enhance the reasoning capabilities of language models.</li>
</ul>

<h3>Title: Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Siqi Chen, Shanyue Guan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17609">https://arxiv.org/abs/2510.17609</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17609">https://arxiv.org/pdf/2510.17609</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17609]] Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation(https://arxiv.org/abs/2510.17609)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>The advancement of UAV technology has enabled efficient, non-contact structural health monitoring. Combined with photogrammetry, UAVs can capture high-resolution scans and reconstruct detailed 3D models of infrastructure. However, a key challenge remains in segmenting specific structural components from these models-a process traditionally reliant on time-consuming and error-prone manual labeling. To address this issue, we propose a machine learning-based framework for automated segmentation of 3D point clouds. Our approach uses the complementary strengths of real-world UAV-scanned point clouds and synthetic data generated from Building Information Modeling (BIM) to overcome the limitations associated with manual labeling. Validation on a railroad track dataset demonstrated high accuracy in identifying and segmenting major components such as rails and crossties. Moreover, by using smaller-scale datasets supplemented with BIM data, the framework significantly reduced training time while maintaining reasonable segmentation accuracy. This automated approach improves the precision and efficiency of 3D infrastructure model segmentation and advances the integration of UAV and BIM technologies in structural health monitoring and infrastructure management.</li>
</ul>

<h3>Title: Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuefeng Peng, Parnian Afshar, Megan Ganji, Thomas Butler, Amir Houmansadr, Mingxian Wang, Dezhi Hong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17620">https://arxiv.org/abs/2510.17620</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17620">https://arxiv.org/pdf/2510.17620</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17620]] Forget to Know, Remember to Use: Context-Aware Unlearning for Large Language Models(https://arxiv.org/abs/2510.17620)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models may encode sensitive information or outdated knowledge that needs to be removed, to ensure responsible and compliant model responses. Unlearning has emerged as an efficient alternative to full retraining, aiming to remove specific knowledge while preserving overall model utility. Existing evaluations of unlearning methods focus on (1) the extent of forgetting of the target knowledge (forget set) and (2) maintaining performance on the retain set (i.e., utility). However, these evaluations overlook an important usability aspect: users may still want the model to leverage the removed information if it is re-introduced in the prompt. In a systematic evaluation of six state-of-the-art unlearning methods, we find that they consistently impair such contextual utility. To address this, we augment unlearning objectives with a plug-in term that preserves the model's ability to use forgotten knowledge when it is present in context. Extensive experiments demonstrate that our approach restores contextual utility to near original levels while still maintaining effective forgetting and retain-set utility.</li>
</ul>

<h3>Title: GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models</h3>
<ul>
<li><strong>Authors: </strong>Vincenzo Carletti, Pasquale Foggia, Carlo Mazzocca, Giuseppe Parrella, Mario Vento</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17621">https://arxiv.org/abs/2510.17621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17621">https://arxiv.org/pdf/2510.17621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17621]] GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models(https://arxiv.org/abs/2510.17621)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, federate, diffusion</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL) enables collaborative training of Machine Learning (ML) models across multiple clients while preserving their privacy. Rather than sharing raw data, federated clients transmit locally computed updates to train the global model. Although this paradigm should provide stronger privacy guarantees than centralized ML, client updates remain vulnerable to privacy leakage. Adversaries can exploit them to infer sensitive properties about the training data or even to reconstruct the original inputs via Gradient Inversion Attacks (GIAs). Under the honest-butcurious threat model, GIAs attempt to reconstruct training data by reversing intermediate updates using optimizationbased techniques. We observe that these approaches usually reconstruct noisy approximations of the original inputs, whose quality can be enhanced with specialized denoising models. This paper presents Gradient Update Inversion with DEnoising (GUIDE), a novel methodology that leverages diffusion models as denoising tools to improve image reconstruction attacks in FL. GUIDE can be integrated into any GIAs that exploits surrogate datasets, a widely adopted assumption in GIAs literature. We comprehensively evaluate our approach in two attack scenarios that use different FL algorithms, models, and datasets. Our results demonstrate that GUIDE integrates seamlessly with two state-ofthe- art GIAs, substantially improving reconstruction quality across multiple metrics. Specifically, GUIDE achieves up to 46% higher perceptual similarity, as measured by the DreamSim metric.</li>
</ul>

<h3>Title: CaMiT: A Time-Aware Car Model Dataset for Classification and Generation</h3>
<ul>
<li><strong>Authors: </strong>Frédéric LIN, Biruk Abere Ambaw, Adrian Popescu, Hejer Ammar, Romaric Audigier, Hervé Le Borgne (Université Paris-Saclay, CEA, List, F-91120, Palaiseau, France)</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17626">https://arxiv.org/abs/2510.17626</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17626">https://arxiv.org/pdf/2510.17626</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17626]] CaMiT: A Time-Aware Car Model Dataset for Classification and Generation(https://arxiv.org/abs/2510.17626)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>AI systems must adapt to evolving visual environments, especially in domains where object appearances change over time. We introduce Car Models in Time (CaMiT), a fine-grained dataset capturing the temporal evolution of car models, a representative class of technological artifacts. CaMiT includes 787K labeled samples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023), supporting both supervised and self-supervised learning. Static pretraining on in-domain data achieves competitive performance with large-scale generalist models while being more resource-efficient, yet accuracy declines when models are tested across years. To address this, we propose a time-incremental classification setting, a realistic continual learning scenario with emerging, evolving, and disappearing classes. We evaluate two strategies: time-incremental pretraining, which updates the backbone, and time-incremental classifier learning, which updates only the final layer, both improving temporal robustness. Finally, we explore time-aware image generation that leverages temporal metadata during training, yielding more realistic outputs. CaMiT offers a rich benchmark for studying temporal adaptation in fine-grained visual recognition and generation.</li>
</ul>

<h3>Title: Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives</h3>
<ul>
<li><strong>Authors: </strong>Zexian Huang, Mashnoon Islam, Brian Armstrong, Kourosh Khoshelham, Martin Tomko</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17644">https://arxiv.org/abs/2510.17644</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17644">https://arxiv.org/pdf/2510.17644</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17644]] Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives(https://arxiv.org/abs/2510.17644)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Dry-stone walls hold significant heritage and environmental value. Mapping these structures is essential for ecosystem preservation and wildfire management in Australia. Yet, many walls remain unidentified due to their inaccessibility and the high cost of manual mapping. Deep learning-based segmentation offers a scalable solution, but two major challenges persist: (1) visual occlusion of low-lying walls by dense vegetation, and (2) limited labeled data for supervised training. We propose DINO-CV, a segmentation framework for automatic mapping of low-lying dry-stone walls using high-resolution Airborne LiDAR-derived digital elevation models (DEMs). DEMs overcome visual occlusion by capturing terrain structures hidden beneath vegetation, enabling analysis of structural rather than spectral cues. DINO-CV introduces a self-supervised cross-view pre-training strategy based on knowledge distillation to mitigate data scarcity. It learns invariant visual and geometric representations across multiple DEM derivatives, supporting various vision backbones including ResNet, Wide ResNet, and Vision Transformers. Applied to the UNESCO World Heritage cultural landscape of Budj Bim, Victoria, the method identifies one of Australia's densest collections of colonial dry-stone walls beyond Indigenous heritage contexts. DINO-CV achieves a mean Intersection over Union (mIoU) of 68.6% on test areas and maintains 63.8% mIoU when fine-tuned with only 10% labeled data. These results demonstrate the potential of self-supervised learning on high-resolution DEM derivatives for automated dry-stone wall mapping in vegetated and heritage-rich environments with scarce annotations.</li>
</ul>

<h3>Title: ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification</h3>
<ul>
<li><strong>Authors: </strong>Athanasios Angelakis, Amne Mousa, Micah L. A. Heldeweg, Laurens A. Biesheuvel, Mark A. Haaksma, Jasper M. Smit, Pieter R. Tuinman, Paul W. G. Elbers</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17650">https://arxiv.org/abs/2510.17650</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17650">https://arxiv.org/pdf/2510.17650</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17650]] ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification(https://arxiv.org/abs/2510.17650)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and structurally normal lungs in lung ultrasound (LUS) videos remains challenging due to the high visual variability of non-cardiogenic inflammatory patterns (NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This heterogeneity complicates automated classification as overlapping B-lines and pleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer variant that removes both positional embeddings and the [CLS] token, making it fully permutation-invariant and suitable for unordered medical image data. To enhance generalization, we propose ShuffleStrides Data Augmentation (SSDA), which permutes probe-view sequences and frame orders while preserving anatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95 critically ill patients against nine state-of-the-art baselines. Despite the heterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60) and specificity (0.91), while all competing models collapsed to trivial classification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with 2.5x fewer parameters, supporting real-time clinical deployment. These results show that aligning architectural design with data structure can outperform scale in small-data medical imaging.</li>
</ul>

<h3>Title: Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs</h3>
<ul>
<li><strong>Authors: </strong>Sébastien Thuau, Siba Haidar, Ayush Bajracharya, Rachid Chelouah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17651">https://arxiv.org/abs/2510.17651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17651">https://arxiv.org/pdf/2510.17651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17651]] Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs(https://arxiv.org/abs/2510.17651)</code><input type="text"></li>
<li><strong>Keywords: </strong>federate</a></li>
<li><strong>Abstract: </strong>We examine frugal federated learning approaches to violence detection by comparing two complementary strategies: (i) zero-shot and federated fine-tuning of vision-language models (VLMs), and (ii) personalized training of a compact 3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter CNN3D as representative cases, we evaluate accuracy, calibration, and energy usage under realistic non-IID settings. Both approaches exceed 90% accuracy. CNN3D slightly outperforms Low-Rank Adaptation(LoRA)-tuned VLMs in ROC AUC and log loss, while using less energy. VLMs remain favorable for contextual reasoning and multimodal inference. We quantify energy and CO$_2$ emissions across training and inference, and analyze sustainability trade-offs for deployment. To our knowledge, this is the first comparative study of LoRA-tuned vision-language models and personalized CNNs for federated violence detection, with an emphasis on energy efficiency and environmental metrics. These findings support a hybrid model: lightweight CNNs for routine classification, with selective VLM activation for complex or descriptive scenarios. The resulting framework offers a reproducible baseline for responsible, resource-aware AI in video surveillance, with extensions toward real-time, multimodal, and lifecycle-aware systems.</li>
</ul>

<h3>Title: Qomhra: A Bilingual Irish-English Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Joseph McInerney</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17652">https://arxiv.org/abs/2510.17652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17652">https://arxiv.org/pdf/2510.17652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17652]] Qomhra: A Bilingual Irish-English Large Language Model(https://arxiv.org/abs/2510.17652)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces Qomhrá, a bilingual Irish-English large language model (LLM), developed under low-resource constraints presenting a complete pipeline spanning bilingual continued pre-training, instruction tuning, and alignment from human preferences. Newly accessible Irish corpora and English text are mixed and curated to improve Irish performance while preserving English ability. 6 closed-weight LLMs are judged for their Irish text generation by a native speaker, a learner and other LLMs. Google's Gemini-2.5-Pro is ranked the highest and is subsequently used to synthesise instruction tuning and human preference datasets. Two datasets are contributed leveraging Gemini-2.5-Pro: a 30K Irish-English parallel instruction tuning dataset and a 1K human preference dataset, generating accepted and rejected responses that show near perfect alignment with a native Irish speaker. Qomhrá is comprehensively evaluated across benchmarks testing translation, gender understanding, topic identification and world knowledge with gains of up to 29% in Irish and 44% in English. Qomhrá also undergoes instruction tuning and demonstrates clear progress in instruction following, crucial for chatbot functionality.</li>
</ul>

<h3>Title: Handling Extreme Class Imbalance: Using GANs in Data Augmentation for Suicide Prediction</h3>
<ul>
<li><strong>Authors: </strong>Vaishnavi Visweswaraiah, Tanvi Banerjee, William Romine</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17661">https://arxiv.org/abs/2510.17661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17661">https://arxiv.org/pdf/2510.17661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17661]] Handling Extreme Class Imbalance: Using GANs in Data Augmentation for Suicide Prediction(https://arxiv.org/abs/2510.17661)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Suicide prediction is the key for prevention, but real data with sufficient positive samples is rare and causes extreme class imbalance. We utilized machine learning (ML) to build the model and deep learning (DL) techniques, like Generative Adversarial Networks (GAN), to generate synthetic data samples to enhance the dataset. The initial dataset contained 656 samples, with only four positive cases, prompting the need for data augmentation. A variety of machine learning models, ranging from interpretable data models to black box algorithmic models, were used. On real test data, Logistic Regression (LR) achieved a weighted precision of 0.99, a weighted recall of 0.85, and a weighted F1 score of 0.91; Random Forest (RF) showed 0.98, 0.99, and 0.99, respectively; and Support Vector Machine (SVM) achieved 0.99, 0.76, and 0.86. LR and SVM correctly identified one suicide attempt case (sensitivity:1.0) and misclassified LR(20) and SVM (31) non-attempts as attempts (specificity: 0.85 & 0.76, respectively). RF identified 0 suicide attempt cases (sensitivity: 0.0) with 0 false positives (specificity: 1.0). These results highlight the models' effectiveness, with GAN playing a key role in generating synthetic data to support suicide prevention modeling efforts.</li>
</ul>

<h3>Title: 4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads</h3>
<ul>
<li><strong>Authors: </strong>Ling Liu, Jun Tian, Li Yi</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17664">https://arxiv.org/abs/2510.17664</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17664">https://arxiv.org/pdf/2510.17664</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17664]] 4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads(https://arxiv.org/abs/2510.17664)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>4D panoptic segmentation in a streaming setting is critical for highly dynamic environments, such as evacuating dense crowds and autonomous driving in complex scenarios, where real-time, fine-grained perception within a constrained time budget is essential. In this paper, we introduce 4DSegStreamer, a novel framework that employs a Dual-Thread System to efficiently process streaming frames. The framework is general and can be seamlessly integrated into existing 3D and 4D segmentation methods to enable real-time capability. It also demonstrates superior robustness compared to existing streaming perception approaches, particularly under high FPS conditions. The system consists of a predictive thread and an inference thread. The predictive thread leverages historical motion and geometric information to extract features and forecast future dynamics. The inference thread ensures timely prediction for incoming frames by aligning with the latest memory and compensating for ego-motion and dynamic object movements. We evaluate 4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of our approach, particularly in accurately predicting dynamic objects in complex scenes.</li>
</ul>

<h3>Title: LILO: Bayesian Optimization with Interactive Natural Language Feedback</h3>
<ul>
<li><strong>Authors: </strong>Katarzyna Kobalczyk, Zhiyuan Jerry Lin, Benjamin Letham, Zhuokai Zhao, Maximilian Balandat, Eytan Bakshy</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17671">https://arxiv.org/abs/2510.17671</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17671">https://arxiv.org/pdf/2510.17671</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17671]] LILO: Bayesian Optimization with Interactive Natural Language Feedback(https://arxiv.org/abs/2510.17671)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>For many real-world applications, feedback is essential in translating complex, nuanced, or subjective goals into quantifiable optimization objectives. We propose a language-in-the-loop framework that uses a large language model (LLM) to convert unstructured feedback in the form of natural language into scalar utilities to conduct BO over a numeric search space. Unlike preferential BO, which only accepts restricted feedback formats and requires customized models for each domain-specific problem, our approach leverages LLMs to turn varied types of textual feedback into consistent utility signals and to easily include flexible user priors without manual kernel design. At the same time, our method maintains the sample efficiency and principled uncertainty quantification of BO. We show that this hybrid method not only provides a more natural interface to the decision maker but also outperforms conventional BO baselines and LLM-only optimizers, particularly in feedback-limited regimes.</li>
</ul>

<h3>Title: Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model</h3>
<ul>
<li><strong>Authors: </strong>Xinwei Zhang, Hu Chen, Zhe Yuan, Sukun Tian, Peng Feng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17684">https://arxiv.org/abs/2510.17684</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17684">https://arxiv.org/pdf/2510.17684</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17684]] Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model(https://arxiv.org/abs/2510.17684)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Foundation models for medical image segmentation have achieved remarkable performance. Adaptive fine-tuning of natural image segmentation foundation models is crucial for medical image segmentation tasks. However, some limitations exist in existing fine-tuning methods: 1) insufficient representation of high-level features and 2) the fine-tuning process disrupts the structural integrity of pretrained weights. Inspired by these critical problems, we propose an intelligent communication mixture-of-experts boosted-medical image segmentation foundation model, named IC-MoE, with twofold ideas: 1) We construct basic experts, semantic experts, and adaptive experts. Moreover, we implement a pixel probability adaptive voting strategy, which enables expert selection and fusion through label consistency and load balancing. This approach preliminarily enhances the representation capability of high-level features while preserving the structural integrity of pretrained weights. 2) We propose a semantic-guided contrastive learning method to address the issue of weak supervision in contrastive learning. This method further enhances the representation capability of high-level features while preserving the structural integrity of pretrained weights. Extensive experiments across three public medical image segmentation datasets demonstrate that the IC-MoE outperforms other SOTA models. Consequently, the proposed IC-MoE effectively supplements foundational medical image segmentation models with high-level features and pretrained structural integrity. We also validate the superior generalizability of the IC-MoE across diverse medical image segmentation scenarios.</li>
</ul>

<h3>Title: Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning</h3>
<ul>
<li><strong>Authors: </strong>Min Cao, Xinyu Zhou, Ding Jiang, Bo Du, Mang Ye, Min Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17685">https://arxiv.org/abs/2510.17685</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17685">https://arxiv.org/pdf/2510.17685</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17685]] Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning(https://arxiv.org/abs/2510.17685)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Text-to-image person retrieval (TIPR) aims to identify the target person using textual descriptions, facing challenge in modality heterogeneity. Prior works have attempted to address it by developing cross-modal global or local alignment strategies. However, global methods typically overlook fine-grained cross-modal differences, whereas local methods require prior information to explore explicit part alignments. Additionally, current methods are English-centric, restricting their application in multilingual contexts. To alleviate these issues, we pioneer a multilingual TIPR task by developing a multilingual TIPR benchmark, for which we leverage large language models for initial translations and refine them by integrating domain-specific knowledge. Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation Reasoning and Aligning framework to learn alignment across languages and modalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module enables bidirectional prediction of masked image and text, implicitly enhancing the modeling of local relations across languages and modalities, a multi-dimensional global alignment module is integrated to bridge the modality heterogeneity. The proposed method achieves new state-of-the-art results on all multilingual TIPR datasets. Data and code are presented in this https URL.</li>
</ul>

<h3>Title: CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks</h3>
<ul>
<li><strong>Authors: </strong>Xu Zhang, Hao Li, Zhichao Lu</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17687">https://arxiv.org/abs/2510.17687</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17687">https://arxiv.org/pdf/2510.17687</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17687]] CrossGuard: Safeguarding MLLMs against Joint-Modal Implicit Malicious Attacks(https://arxiv.org/abs/2510.17687)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, defense, attack, robust, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) achieve strong reasoning and perception capabilities but are increasingly vulnerable to jailbreak attacks. While existing work focuses on explicit attacks, where malicious content resides in a single modality, recent studies reveal implicit attacks, in which benign text and image inputs jointly express unsafe intent. Such joint-modal threats are difficult to detect and remain underexplored, largely due to the scarcity of high-quality implicit data. We propose ImpForge, an automated red-teaming pipeline that leverages reinforcement learning with tailored reward modules to generate diverse implicit samples across 14 domains. Building on this dataset, we further develop CrossGuard, an intent-aware safeguard providing robust and comprehensive defense against both explicit and implicit threats. Extensive experiments across safe and unsafe benchmarks, implicit and explicit attacks, and multiple out-of-domain settings demonstrate that CrossGuard significantly outperforms existing defenses, including advanced MLLMs and guardrails, achieving stronger security while maintaining high utility. This offers a balanced and practical solution for enhancing MLLM robustness against real-world multimodal threats.</li>
</ul>

<h3>Title: Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Liqun He, Manolis Mavrikis, Mutlu Cukurova</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17698">https://arxiv.org/abs/2510.17698</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17698">https://arxiv.org/pdf/2510.17698</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17698]] Towards Mining Effective Pedagogical Strategies from Learner-LLM Educational Dialogues(https://arxiv.org/abs/2510.17698)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Dialogue plays a crucial role in educational settings, yet existing evaluation methods for educational applications of large language models (LLMs) primarily focus on technical performance or learning outcomes, often neglecting attention to learner-LLM interactions. To narrow this gap, this AIED Doctoral Consortium paper presents an ongoing study employing a dialogue analysis approach to identify effective pedagogical strategies from learner-LLM dialogues. The proposed approach involves dialogue data collection, dialogue act (DA) annotation, DA pattern mining, and predictive model building. Early insights are outlined as an initial step toward future research. The work underscores the need to evaluate LLM-based educational applications by focusing on dialogue dynamics and pedagogical strategies.</li>
</ul>

<h3>Title: GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver</h3>
<ul>
<li><strong>Authors: </strong>Aleksandr Oganov, Ilya Bykov, Eva Neudachina, Mishan Aliev, Alexander Tolmachev, Alexander Sidorov, Aleksandr Zuev, Andrey Okhotin, Denis Rakitin, Aibek Alanov</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17699">https://arxiv.org/abs/2510.17699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17699">https://arxiv.org/pdf/2510.17699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17699]] GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver(https://arxiv.org/abs/2510.17699)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>While diffusion models achieve state-of-the-art generation quality, they still suffer from computationally expensive sampling. Recent works address this issue with gradient-based optimization methods that distill a few-step ODE diffusion solver from the full sampling process, reducing the number of function evaluations from dozens to just a few. However, these approaches often rely on intricate training techniques and do not explicitly focus on preserving fine-grained details. In this paper, we introduce the Generalized Solver: a simple parameterization of the ODE sampler that does not require additional training tricks and improves quality over existing approaches. We further combine the original distillation loss with adversarial training, which mitigates artifacts and enhances detail fidelity. We call the resulting method the Generalized Adversarial Solver and demonstrate its superior performance compared to existing solver training methods under similar resource constraints. Code is available at this https URL.</li>
</ul>

<h3>Title: Elastic ViTs from Pretrained Models without Retraining</h3>
<ul>
<li><strong>Authors: </strong>Walter Simoncini, Michael Dorkenwald, Tijmen Blankevoort, Cees G.M. Snoek, Yuki M. Asano</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17700">https://arxiv.org/abs/2510.17700</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17700">https://arxiv.org/pdf/2510.17700</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17700]] Elastic ViTs from Pretrained Models without Retraining(https://arxiv.org/abs/2510.17700)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Vision foundation models achieve remarkable performance but are only available in a limited set of pre-determined sizes, forcing sub-optimal deployment choices under real-world constraints. We introduce SnapViT: Single-shot network approximation for pruned Vision Transformers, a new post-pretraining structured pruning method that enables elastic inference across a continuum of compute budgets. Our approach efficiently combines gradient information with cross-network structure correlations, approximated via an evolutionary algorithm, does not require labeled data, generalizes to models without a classification head, and is retraining-free. Experiments on DINO, SigLIPv2, DeIT, and AugReg models demonstrate superior performance over state-of-the-art methods across various sparsities, requiring less than five minutes on a single A100 GPU to generate elastic models that can be adjusted to any computational budget. Our key contributions include an efficient pruning strategy for pretrained Vision Transformers, a novel evolutionary approximation of Hessian off-diagonal structures, and a self-supervised importance scoring mechanism that maintains strong performance without requiring retraining or labels. Code and pruned models are available at: this https URL</li>
</ul>

<h3>Title: Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns</h3>
<ul>
<li><strong>Authors: </strong>Mhd Adnan Albani, Riad Sonbol</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17703">https://arxiv.org/abs/2510.17703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17703">https://arxiv.org/pdf/2510.17703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17703]] Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns(https://arxiv.org/abs/2510.17703)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of people over the age of 60, causing motor impairments that impede hand coordination activities such as writing and drawing. Many approaches have tried to support early detection of Parkinson's disease based on hand-drawn images; however, we identified two major limitations in the related works: (1) the lack of sufficient datasets, (2) the robustness when dealing with unseen patient data. In this paper, we propose a new approach to detect Parkinson's disease that consists of two stages: The first stage classifies based on their drawing type(circle, meander, spiral), and the second stage extracts the required features from the images and detects Parkinson's disease. We overcame the previous two limitations by applying a chunking strategy where we divide each image into 2x2 chunks. Each chunk is processed separately when extracting features and recognizing Parkinson's disease indicators. To make the final classification, an ensemble method is used to merge the decisions made from each chunk. Our evaluation shows that our proposed approach outperforms the top performing state-of-the-art approaches, in particular on unseen patients. On the NewHandPD dataset our approach, it achieved 97.08% accuracy for seen patients and 94.91% for unseen patients, our proposed approach maintained a gap of only 2.17 percentage points, compared to the 4.76-point drop observed in prior work.</li>
</ul>

<h3>Title: QueST: Incentivizing LLMs to Generate Difficult Problems</h3>
<ul>
<li><strong>Authors: </strong>Hanxu Hu, Xingxing Zhang, Jannis Vamvas, Rico Sennrich, Furu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17715">https://arxiv.org/abs/2510.17715</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17715">https://arxiv.org/pdf/2510.17715</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17715]] QueST: Incentivizing LLMs to Generate Difficult Problems(https://arxiv.org/abs/2510.17715)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models have achieved strong performance on reasoning tasks, solving competition-level coding and math problems. However, their scalability is limited by human-labeled datasets and the lack of large-scale, challenging coding problem training data. Existing competitive coding datasets contain only thousands to tens of thousands of problems. Previous synthetic data generation methods rely on either augmenting existing instruction datasets or selecting challenging problems from human-labeled data. In this paper, we propose QueST, a novel framework which combines difficulty-aware graph sampling and difficulty-aware rejection fine-tuning that directly optimizes specialized generators to create challenging coding problems. Our trained generators demonstrate superior capability compared to even GPT-4o at creating challenging problems that benefit downstream performance. We leverage QueST to generate large-scale synthetic coding problems, which we then use to distill from strong teacher models with long chain-of-thought or to conduct reinforcement learning for smaller models, proving effective in both scenarios. Our distillation experiments demonstrate significant performance gains. Specifically, after fine-tuning Qwen3-8B-base on 100K difficult problems generated by QueST, we surpass the performance of the original Qwen3-8B on LiveCodeBench. With an additional 112K examples (i.e., 28K human-written problems paired with multiple synthetic solutions), our 8B model matches the performance of the much larger DeepSeek-R1-671B. These findings indicate that generating complex problems via QueST offers an effective and scalable approach to advancing the frontiers of competitive coding and reasoning for large language models.</li>
</ul>

<h3>Title: Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging</h3>
<ul>
<li><strong>Authors: </strong>Suqiang Ma, Subhadeep Sengupta, Yao Lee, Beikang Gu, Xianyan Chen, Xianqiao Wang, Yang Liu, Mengjia Xu, Galit H. Frydman, He Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17716">https://arxiv.org/abs/2510.17716</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17716">https://arxiv.org/pdf/2510.17716</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17716]] Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging(https://arxiv.org/abs/2510.17716)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Circulating blood cell clusters (CCCs) containing red blood cells (RBCs), white blood cells(WBCs), and platelets are significant biomarkers linked to conditions like thrombosis, infection, and inflammation. Flow cytometry, paired with fluorescence staining, is commonly used to analyze these cell clusters, revealing cell morphology and protein profiles. While computational approaches based on machine learning have advanced the automatic analysis of single-cell flow cytometry images, there is a lack of effort to build tools to automatically analyze images containing CCCs. Unlike single cells, cell clusters often exhibit irregular shapes and sizes. In addition, these cell clusters often consist of heterogeneous cell types, which require multi-channel staining to identify the specific cell types within the clusters. This study introduces a new computational framework for analyzing CCC images and identifying cell types within clusters. Our framework uses a two-step analysis strategy. First, it categorizes images into cell cluster and non-cluster groups by fine-tuning the You Only Look Once(YOLOv11) model, which outperforms traditional convolutional neural networks (CNNs), Vision Transformers (ViT). Then, it identifies cell types by overlaying cluster contours with regions from multi-channel fluorescence stains, enhancing accuracy despite cell debris and staining artifacts. This approach achieved over 95% accuracy in both cluster classification and phenotype identification. In summary, our automated framework effectively analyzes CCC images from flow cytometry, leveraging both bright-field and fluorescence data. Initially tested on blood cells, it holds potential for broader applications, such as analyzing immune and tumor cell clusters, supporting cellular research across various diseases.</li>
</ul>

<h3>Title: Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions</h3>
<ul>
<li><strong>Authors: </strong>Zhiqiang Teng, Beibei Lin, Tingting Chen, Zifeng Yuan, Xuanyi Li, Xuanyu Zhang, Shunli Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17719">https://arxiv.org/abs/2510.17719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17719">https://arxiv.org/pdf/2510.17719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17719]] Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions(https://arxiv.org/abs/2510.17719)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe occlusions and optical distortions caused by raindrop contamination on the camera lens, substantially degrading reconstruction quality. Existing benchmarks typically evaluate 3DGS using synthetic raindrop images with known camera poses (constrained images), assuming ideal conditions. However, in real-world scenarios, raindrops often interfere with accurate camera pose estimation and point cloud initialization. Moreover, a significant domain gap between synthetic and real raindrops further impairs generalization. To tackle these issues, we introduce RaindropGS, a comprehensive benchmark designed to evaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images to clear 3DGS reconstructions. Specifically, the whole benchmark pipeline consists of three parts: data preparation, data processing, and raindrop-aware 3DGS evaluation, including types of raindrop interference, camera pose estimation and point cloud initialization, single image rain removal comparison, and 3D Gaussian training comparison. First, we collect a real-world raindrop reconstruction dataset, in which each scene contains three aligned image sets: raindrop-focused, background-focused, and rain-free ground truth, enabling a comprehensive evaluation of reconstruction quality under different focus conditions. Through comprehensive experiments and analyses, we reveal critical insights into the performance limitations of existing 3DGS methods on unconstrained raindrop images and the varying impact of different pipeline components: the impact of camera focus position on 3DGS reconstruction performance, and the interference caused by inaccurate pose and point cloud initialization on reconstruction. These insights establish clear directions for developing more robust 3DGS methods under raindrop conditions.</li>
</ul>

<h3>Title: MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Yaning Pan, Zekun Wang, Qianqian Xie, Yongqian Wen, Yuanxing Zhang, Guohui Zhang, Haoxuan Hu, Zhiyu Pan, Yibing Huang, Zhidong Gan, Yonghong Lin, An Ping, Tianhao Peng, Jiaheng Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17722">https://arxiv.org/abs/2510.17722</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17722">https://arxiv.org/pdf/2510.17722</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17722]] MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues(https://arxiv.org/abs/2510.17722)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The recent development of Multimodal Large Language Models (MLLMs) has significantly advanced AI's ability to understand visual modalities. However, existing evaluation benchmarks remain limited to single-turn question answering, overlooking the complexity of multi-turn dialogues in real-world scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video understanding benchmark for evaluating MLLMs in multi-turn dialogues. Specifically, our MT-Video-Bench mainly assesses six core competencies that focus on perceptivity and interactivity, encompassing 987 meticulously curated multi-turn dialogues from diverse domains. These capabilities are rigorously aligned with real-world applications, such as interactive sports analysis and multi-turn video-based intelligent tutoring. With MT-Video-Bench, we extensively evaluate various state-of-the-art open-source and closed-source MLLMs, revealing their significant performance discrepancies and limitations in handling multi-turn video dialogues. The benchmark will be publicly available to foster future research.</li>
</ul>

<h3>Title: Signature Forgery Detection: Improving Cross-Dataset Generalization</h3>
<ul>
<li><strong>Authors: </strong>Matheus Ramos Parracho</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17724">https://arxiv.org/abs/2510.17724</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17724">https://arxiv.org/pdf/2510.17724</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17724]] Signature Forgery Detection: Improving Cross-Dataset Generalization(https://arxiv.org/abs/2510.17724)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, biometric</a></li>
<li><strong>Abstract: </strong>Automated signature verification is a critical biometric technique used in banking, identity authentication, and legal documentation. Despite the notable progress achieved by deep learning methods, most approaches in offline signature verification still struggle to generalize across datasets, as variations in handwriting styles and acquisition protocols often degrade performance. This study investigates feature learning strategies for signature forgery detection, focusing on improving cross-dataset generalization -- that is, model robustness when trained on one dataset and tested on another. Using three public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental pipelines were developed: one based on raw signature images and another employing a preprocessing method referred to as shell preprocessing. Several behavioral patterns were identified and analyzed; however, no definitive superiority between the two approaches was established. The results show that the raw-image model achieved higher performance across benchmarks, while the shell-based model demonstrated promising potential for future refinement toward robust, cross-domain signature verification.</li>
</ul>

<h3>Title: AcademicEval: Live Long-Context LLM Benchmark</h3>
<ul>
<li><strong>Authors: </strong>Haozhen Zhang, Tao Feng, Pengrui Han, Jiaxuan You</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17725">https://arxiv.org/abs/2510.17725</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17725">https://arxiv.org/pdf/2510.17725</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17725]] AcademicEval: Live Long-Context LLM Benchmark(https://arxiv.org/abs/2510.17725)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have recently achieved remarkable performance in long-context understanding. However, current long-context LLM benchmarks are limited by rigid context length, labor-intensive annotation, and the pressing challenge of label leakage issues during LLM training. Therefore, we propose \textsc{AcademicEval}, a live benchmark for evaluating LLMs over long-context generation tasks. \textsc{AcademicEval} adopts papers on arXiv to introduce several academic writing tasks with long-context inputs, \textit{i.e.}, \textsc{Title}, \textsc{Abstract}, \textsc{Introduction}, and \textsc{Related Work}, which cover a wide range of abstraction levels and require no manual labeling. Moreover, \textsc{AcademicEval} integrates high-quality and expert-curated few-shot demonstrations from a collected co-author graph to enable flexible context length. Especially, \textsc{AcademicEval} features an efficient live evaluation, ensuring no label leakage. We conduct a holistic evaluation on \textsc{AcademicEval}, and the results illustrate that LLMs perform poorly on tasks with hierarchical abstraction levels and tend to struggle with long few-shot demonstrations, highlighting the challenge of our benchmark. Through experimental analysis, we also reveal some insights for enhancing LLMs' long-context modeling capabilities. Code is available at this https URL</li>
</ul>

<h3>Title: Enabling Fine-Grained Operating Points for Black-Box LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ege Beyazit, KL Navaneet, Prashant Mathur, Roi Blanco, Vidit Bansal, Karim Bouyarmane</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17727">https://arxiv.org/abs/2510.17727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17727">https://arxiv.org/pdf/2510.17727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17727]] Enabling Fine-Grained Operating Points for Black-Box LLMs(https://arxiv.org/abs/2510.17727)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Black-box Large Language Models (LLMs) provide practical and accessible alternatives to other machine learning methods, as they require minimal labeled data and machine learning expertise to develop solutions for various decision making problems. However, for applications that need operating with constraints on specific metrics (e.g., precision $\geq$ 95%), decision making with black-box LLMs remains unfavorable, due to their low numerical output cardinalities. This results in limited control over their operating points, preventing fine-grained adjustment of their decision making behavior. In this paper, we study using black-box LLMs as classifiers, focusing on efficiently improving their operational granularity without performance loss. Specifically, we first investigate the reasons behind their low-cardinality numerical outputs and show that they are biased towards generating rounded but informative verbalized probabilities. Then, we experiment with standard prompt engineering, uncertainty estimation and confidence elicitation techniques, and observe that they do not effectively improve operational granularity without sacrificing performance or increasing inference cost. Finally, we propose efficient approaches to significantly increase the number and diversity of available operating points. Our proposed approaches provide finer-grained operating points and achieve comparable to or better performance than the benchmark methods across 11 datasets and 3 LLMs.</li>
</ul>

<h3>Title: Can Image-To-Video Models Simulate Pedestrian Dynamics?</h3>
<ul>
<li><strong>Authors: </strong>Aaron Appelle, Jerome P. Lynch</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17731">https://arxiv.org/abs/2510.17731</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17731">https://arxiv.org/pdf/2510.17731</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17731]] Can Image-To-Video Models Simulate Pedestrian Dynamics?(https://arxiv.org/abs/2510.17731)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Recent high-performing image-to-video (I2V) models based on variants of the diffusion transformer (DiT) have displayed remarkable inherent world-modeling capabilities by virtue of training on large scale video datasets. We investigate whether these models can generate realistic pedestrian movement patterns in crowded public scenes. Our framework conditions I2V models on keyframes extracted from pedestrian trajectory benchmarks, then evaluates their trajectory prediction performance using quantitative measures of pedestrian dynamics.</li>
</ul>

<h3>Title: Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition</h3>
<ul>
<li><strong>Authors: </strong>Timur Ismagilov, Shakaiba Majeed, Michael Milford, Tan Viet Tuyen Nguyen, Sarvapali D. Ramchurn, Shoaib Ehsan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17739">https://arxiv.org/abs/2510.17739</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17739">https://arxiv.org/pdf/2510.17739</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17739]] Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition(https://arxiv.org/abs/2510.17739)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We address multi-reference visual place recognition (VPR), where reference sets captured under varying conditions are used to improve localisation performance. While deep learning with large-scale training improves robustness, increasing data diversity and model complexity incur extensive computational cost during training and deployment. Descriptor-level fusion via voting or aggregation avoids training, but often targets multi-sensor setups or relies on heuristics with limited gains under appearance and viewpoint change. We propose a training-free, descriptor-agnostic approach that jointly models places using multiple reference descriptors via matrix decomposition into basis representations, enabling projection-based residual matching. We also introduce SotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance data, our method improves Recall@1 by up to ~18% over single-reference and outperforms multi-reference baselines across appearance and viewpoint changes, with gains of ~5% on unstructured data, demonstrating strong generalisation while remaining lightweight.</li>
</ul>

<h3>Title: VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Qilin Liao, Anamika Lochab, Ruqi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17759">https://arxiv.org/abs/2510.17759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17759">https://arxiv.org/pdf/2510.17759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17759]] VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models(https://arxiv.org/abs/2510.17759)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, steal, diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Vision-Language Models (VLMs) extend large language models with visual reasoning, but their multimodal design also introduces new, underexplored vulnerabilities. Existing multimodal red-teaming methods largely rely on brittle templates, focus on single-attack settings, and expose only a narrow subset of vulnerabilities. To address these limitations, we introduce VERA-V, a variational inference framework that recasts multimodal jailbreak discovery as learning a joint posterior distribution over paired text-image prompts. This probabilistic view enables the generation of stealthy, coupled adversarial inputs that bypass model guardrails. We train a lightweight attacker to approximate the posterior, allowing efficient sampling of diverse jailbreaks and providing distributional insights into vulnerabilities. VERA-V further integrates three complementary strategies: (i) typography-based text prompts that embed harmful cues, (ii) diffusion-based image synthesis that introduces adversarial signals, and (iii) structured distractors to fragment VLM attention. Experiments on HarmBench and HADES benchmarks show that VERA-V consistently outperforms state-of-the-art baselines on both open-source and frontier VLMs, achieving up to 53.75% higher attack success rate (ASR) over the best baseline on GPT-4o.</li>
</ul>

<h3>Title: Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications</h3>
<ul>
<li><strong>Authors: </strong>Xiao Ye, Jacob Dineen, Zhaonan Li, Zhikun Xu, Weiyu Chen, Shijie Lu, Yuxi Huang, Ming Shen, Phu Tran, Ji-Eun Irene Yum, Muhammad Ali Khan, Muhammad Umar Afzal, Irbaz Bin Riaz, Ben Zhou</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17764">https://arxiv.org/abs/2510.17764</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17764">https://arxiv.org/pdf/2510.17764</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17764]] Evaluating Medical LLMs by Levels of Autonomy: A Survey Moving from Benchmarks to Applications(https://arxiv.org/abs/2510.17764)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Medical Large language models achieve strong scores on standard benchmarks; however, the transfer of those results to safe and reliable performance in clinical workflows remains a challenge. This survey reframes evaluation through a levels-of-autonomy lens (L0-L3), spanning informational tools, information transformation and aggregation, decision support, and supervised agents. We align existing benchmarks and metrics with the actions permitted at each level and their associated risks, making the evaluation targets explicit. This motivates a level-conditioned blueprint for selecting metrics, assembling evidence, and reporting claims, alongside directions that link evaluation to oversight. By centering autonomy, the survey moves the field beyond score-based claims toward credible, risk-aware evidence for real clinical use.</li>
</ul>

<h3>Title: Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning</h3>
<ul>
<li><strong>Authors: </strong>Ryan A. Robinett, Sophia A. Madejski, Kyle Ruark, Samantha J. Riesenfeld, Lorenzo Orecchia</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17772">https://arxiv.org/abs/2510.17772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17772">https://arxiv.org/pdf/2510.17772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17772]] Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning(https://arxiv.org/abs/2510.17772)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability</a></li>
<li><strong>Abstract: </strong>Despite the popularity of the manifold hypothesis, current manifold-learning methods do not support machine learning directly on the latent $d$-dimensional data manifold, as they primarily aim to perform dimensionality reduction into $\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$ approaches $d$. On the other hand, methods that directly learn the latent manifold as a differentiable atlas have been relatively underexplored. In this paper, we aim to give a proof of concept of the effectiveness and potential of atlas-based methods. To this end, we implement a generic data structure to maintain a differentiable atlas that enables Riemannian optimization over the manifold. We complement this with an unsupervised heuristic that learns a differentiable atlas from point cloud data. We experimentally demonstrate that this approach has advantages in terms of efficiency and accuracy in selected settings. Moreover, in a supervised classification task over the Klein bottle and in RNA velocity analysis of hematopoietic data, we showcase the improved interpretability and robustness of our approach.</li>
</ul>

<h3>Title: Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion</h3>
<ul>
<li><strong>Authors: </strong>Md. Enamul Atiq, Shaikh Anowarul Fattah</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17773">https://arxiv.org/abs/2510.17773</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17773">https://arxiv.org/pdf/2510.17773</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17773]] Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion(https://arxiv.org/abs/2510.17773)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Skin cancer is a life-threatening disease where early detection significantly improves patient outcomes. Automated diagnosis from dermoscopic images is challenging due to high intra-class variability and subtle inter-class differences. Many deep learning models operate as "black boxes," limiting clinical trust. In this work, we propose a dual-encoder attention-based framework that leverages both segmented lesions and clinical metadata to enhance skin lesion classification in terms of both accuracy and interpretability. A novel Deep-UNet architecture with Dual Attention Gates (DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment lesions. The classification stage uses two DenseNet201 encoders-one on the original image and another on the segmented lesion whose features are fused via multi-head cross-attention. This dual-input design guides the model to focus on salient pathological regions. In addition, a transformer-based module incorporates patient metadata (age, sex, lesion site) into the prediction. We evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019 challenges. The proposed method achieves state-of-the-art segmentation performance and significantly improves classification accuracy and average AUC compared to baseline models. To validate our model's reliability, we use Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps. These visualizations confirm that our model's predictions are based on the lesion area, unlike models that rely on spurious background features. These results demonstrate that integrating precise lesion segmentation and clinical data with attention-based fusion leads to a more accurate and interpretable skin cancer classification model.</li>
</ul>

<h3>Title: Inference-Time Compute Scaling For Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Adam Stecklov, Noah El Rimawi-Fine, Mathieu Blanchette</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17786">https://arxiv.org/abs/2510.17786</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17786">https://arxiv.org/pdf/2510.17786</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17786]] Inference-Time Compute Scaling For Flow Matching(https://arxiv.org/abs/2510.17786)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, large language model</a></li>
<li><strong>Abstract: </strong>Allocating extra computation at inference time has recently improved sample quality in large language models and diffusion-based image generation. In parallel, Flow Matching (FM) has gained traction in language, vision, and scientific domains, but inference-time scaling methods for it remain under-explored. Concurrently, Kim et al., 2025 approach this problem but replace the linear interpolant with a non-linear variance-preserving (VP) interpolant at inference, sacrificing FM's efficient and straight sampling. Additionally, inference-time compute scaling for flow matching has only been applied to visual tasks, like image generation. We introduce novel inference-time scaling procedures for FM that preserve the linear interpolant during sampling. Evaluations of our method on image generation, and for the first time (to the best of our knowledge), unconditional protein generation, show that I) sample quality consistently improves as inference compute increases, and II) flow matching inference-time scaling can be applied to scientific domains.</li>
</ul>

<h3>Title: Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains</h3>
<ul>
<li><strong>Authors: </strong>Austin Xu, Xuan-Phi Nguyen, Yilun Zhou, Chien-Sheng Wu, Caiming Xiong, Shafiq Joty</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17793">https://arxiv.org/abs/2510.17793</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17793">https://arxiv.org/pdf/2510.17793</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17793]] Foundational Automatic Evaluators: Scaling Multi-Task Generative Evaluator Training for Reasoning-Centric Domains(https://arxiv.org/abs/2510.17793)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Finetuning specialized generative evaluators has emerged as a popular paradigm to meet the increasing demand for scalable evaluation during both training and test-time. However, recent work has largely focused on applying new methodology, such as reinforcement learning (RL), to training evaluators, shying away from large-scale, data-driven development. In this work, we focus on data scaling, curating a set of 2.5M samples spanning five unique evaluation tasks (pairwise, step-level, reference-free and reference-based verification, and single rating) and multiple domains focused on reasoning evaluation. With our data, we train Foundational Automatic Reasoning Evaluators (FARE), a family of 8B and 20B (with 3.6B active) parameter evaluators, with a simple iterative rejection-sampling supervised finetuning (SFT) approach. FARE-8B challenges larger specialized RL-trained evaluators and FARE-20B sets the new standard for open-source evaluators, surpassing specialized 70B+ evaluators. Beyond static benchmarks, we evaluate FARE in real-world tasks: As inference-time rerankers, FARE-20B achieves near-oracle performance on MATH. As verifiers in RL training, FARE improves the downstream RL-trained model performance by up to 14.1% vs. string-matching verifiers. When initialized from FARE, a continually-finetuned FARE-Code outperforms gpt-oss-20B by 65% on evaluating test-case quality.</li>
</ul>

<h3>Title: Executable Knowledge Graphs for Replicating AI Research</h3>
<ul>
<li><strong>Authors: </strong>Yujie Luo, Zhuoyun Yu, Xuehai Wang, Yuqi Zhu, Ningyu Zhang, Lanning Wei, Lun Du, Da Zheng, Huajun Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.MA, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17795">https://arxiv.org/abs/2510.17795</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17795">https://arxiv.org/pdf/2510.17795</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17795]] Executable Knowledge Graphs for Replicating AI Research(https://arxiv.org/abs/2510.17795)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Replicating AI research is a crucial yet challenging task for large language model (LLM) agents. Existing approaches often struggle to generate executable code, primarily due to insufficient background knowledge and the limitations of retrieval-augmented generation (RAG) methods, which fail to capture latent technical details hidden in referenced papers. Furthermore, previous approaches tend to overlook valuable implementation-level code signals and lack structured knowledge representations that support multi-granular retrieval and reuse. To overcome these challenges, we propose Executable Knowledge Graphs (xKG), a modular and pluggable knowledge base that automatically integrates technical insights, code snippets, and domain-specific knowledge extracted from scientific literature. When integrated into three agent frameworks with two different LLMs, xKG shows substantial performance gains (10.9% with o3-mini) on PaperBench, demonstrating its effectiveness as a general and extensible solution for automated AI research replication. Code will released at this https URL.</li>
</ul>

<h3>Title: Glyph: Scaling Context Windows via Visual-Text Compression</h3>
<ul>
<li><strong>Authors: </strong>Jiale Cheng, Yusen Liu, Xinyu Zhang, Yulin Fei, Wenyi Hong, Ruiliang Lyu, Weihan Wang, Zhe Su, Xiaotao Gu, Xiao Liu, Yushi Bai, Jie Tang, Hongning Wang, Minlie Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17800">https://arxiv.org/abs/2510.17800</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17800">https://arxiv.org/pdf/2510.17800</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17800]] Glyph: Scaling Context Windows via Visual-Text Compression(https://arxiv.org/abs/2510.17800)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly rely on long-context modeling for tasks such as document understanding, code analysis, and multi-step reasoning. However, scaling context windows to the million-token level brings prohibitive computational and memory costs, limiting the practicality of long-context LLMs. In this work, we take a different perspective-visual context scaling-to tackle this challenge. Instead of extending token-based sequences, we propose Glyph, a framework that renders long texts into images and processes them with vision-language models (VLMs). This approach substantially compresses textual input while preserving semantic information, and we further design an LLM-driven genetic search to identify optimal visual rendering configurations for balancing accuracy and compression. Through extensive experiments, we demonstrate that our method achieves 3-4x token compression while maintaining accuracy comparable to leading LLMs such as Qwen3-8B on various long-context benchmarks. This compression also leads to around 4x faster prefilling and decoding, and approximately 2x faster SFT training. Furthermore, under extreme compression, a 128K-context VLM could scale to handle 1M-token-level text tasks. In addition, the rendered text data benefits real-world multimodal tasks, such as document understanding. Our code and model are released at this https URL.</li>
</ul>

<h3>Title: Unbiased Gradient Low-Rank Projection</h3>
<ul>
<li><strong>Authors: </strong>Rui Pan, Yang Luo, Yuxing Liu, Yang You, Tong Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17802">https://arxiv.org/abs/2510.17802</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17802">https://arxiv.org/pdf/2510.17802</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17802]] Unbiased Gradient Low-Rank Projection(https://arxiv.org/abs/2510.17802)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Memory-efficient optimization is critical for training increasingly large language models (LLMs). A popular strategy involves gradient low-rank projection, storing only the projected optimizer states, with GaLore being a representative example. However, a significant drawback of many such methods is their lack of convergence guarantees, as various low-rank projection approaches introduce inherent biases relative to the original optimization algorithms, which contribute to performance gaps compared to full-parameter training. Aiming to tackle this problem, this paper investigates the layerwise sampling technique for debiasing low-rank projection mechanisms. In particular, an instantiation of the paradigm gives rise to a novel and unbiased low-rank optimization method built upon GaLore's mechanism and the Muon algorithm, named GaLore Unbiased with Muon (GUM). We theoretically prove our method matches the convergence guarantees of the base Muon algorithm while preserving the memory efficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and pretraining also demonstrate non-trivial improvements over GaLore and even better performance than full-parameter training. Further investigation shows that the improvement of this technique comes from a more uniform distribution of knowledge inside layers, leading to more efficient utilization of the model parameter space and better memorization.</li>
</ul>

<h3>Title: ConsistEdit: Highly Consistent and Precise Training-free Visual Editing</h3>
<ul>
<li><strong>Authors: </strong>Zixin Yin, Ling-Hao Chen, Lionel Ni, Xili Dai</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2510.17803">https://arxiv.org/abs/2510.17803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2510.17803">https://arxiv.org/pdf/2510.17803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2510.17803]] ConsistEdit: Highly Consistent and Precise Training-free Visual Editing(https://arxiv.org/abs/2510.17803)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in training-free attention control methods have enabled flexible and efficient text-guided editing capabilities for existing generation models. However, current approaches struggle to simultaneously deliver strong editing strength while preserving consistency with the source. This limitation becomes particularly critical in multi-round and video editing, where visual errors can accumulate over time. Moreover, most existing methods enforce global consistency, which limits their ability to modify individual attributes such as texture while preserving others, thereby hindering fine-grained editing. Recently, the architectural shift from U-Net to MM-DiT has brought significant improvements in generative performance and introduced a novel mechanism for integrating text and vision modalities. These advancements pave the way for overcoming challenges that previous methods failed to resolve. Through an in-depth analysis of MM-DiT, we identify three key insights into its attention mechanisms. Building on these, we propose ConsistEdit, a novel attention control method specifically tailored for MM-DiT. ConsistEdit incorporates vision-only attention control, mask-guided pre-attention fusion, and differentiated manipulation of the query, key, and value tokens to produce consistent, prompt-aligned edits. Extensive experiments demonstrate that ConsistEdit achieves state-of-the-art performance across a wide range of image and video editing tasks, including both structure-consistent and structure-inconsistent scenarios. Unlike prior methods, it is the first approach to perform editing across all inference steps and attention layers without handcraft, significantly enhancing reliability and consistency, which enables robust multi-round and multi-region editing. Furthermore, it supports progressive adjustment of structural consistency, enabling finer control.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
