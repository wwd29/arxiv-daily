<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: EBAKE-SE: A Novel ECC Based Authenticated Key Exchange between Industrial IoT Devices using Secure Element. (arXiv:2207.13419v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13419">http://arxiv.org/abs/2207.13419</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13419] EBAKE-SE: A Novel ECC Based Authenticated Key Exchange between Industrial IoT Devices using Secure Element](http://arxiv.org/abs/2207.13419)</code></li>
<li>Summary: <p>Industrial IoT (IIoT) aims to enhance services provided by various industries
such as manufacturing and product processing. IIoT suffers from various
challenges and security is one of the key challenge among those challenges.
Authentication and access control are two notable challenges for any Industrial
IoT (IIoT) based industrial deployment. Any IoT based Industry 4.0 enterprise
designs networks between hundreds of tiny devices such as sensors, actuators,
fog devices and gateways. Thus, articulating a secure authentication protocol
between sensing devices or a sensing device and user devices is an essential
step in IoT security. In this paper, first, we present cryptanalysis for the
certificate-based scheme proposed for similar environment by Das et al. and
prove that their scheme is vulnerable to various traditional attacks such as
device anonymity, MITM, and DoS. We then put forward an inter-device
authentication scheme using an ECC (Elliptic Curve Cryptography) that is highly
secure and lightweight compared to other schemes for a similar environment.
Furthermore, we set forth a formal security analysis using the random oracle
based ROR model and informal security analysis over the Doleve-Yao channel. In
this paper, we present the comparison of the proposed scheme with existing
schemes based on communication cost, computation cost and security index to
prove that the proposed EBAKE-SE is highly efficient, reliable, and trustworthy
compared to other existing schemes for inter-device authentication. At long
last, we present an implementation for the proposed EBAKE-SE using MQTT
protocol
</p></li>
</ul>

<h3>Title: Balanced Encoding of Near-Zero Correlation for an AES Implementation. (arXiv:2207.13559v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13559">http://arxiv.org/abs/2207.13559</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13559] Balanced Encoding of Near-Zero Correlation for an AES Implementation](http://arxiv.org/abs/2207.13559)</code></li>
<li>Summary: <p>Power consumption of a circuit can be exploited to recover the secret key of
a cryptographic algorithm. This technique is known as power analysis, one of
the well-known techniques of side-channel analysis. Many software
countermeasures against power analysis present a time-space trade-off. Masking
and shuffling come at cost of the execution time and the extreme use of
run-time random number generators. Internally encoded implementations of block
ciphers, on the other hand, require large memory space to store a set of lookup
tables. While the internal encoding is widely used in white-box cryptography,
it has a serious drawback. It cannot protect the secret key against power
analysis. In this paper, we propose a secure internal encoding method of an AES
implementation. Provided that the five inner rounds are left unprotected
because these are not subject to power analysis, the lookup tables are
approximately 232KB in size and the number of operation including XORs and
table lookups are about 1,000 in total. This is about half the table size
required by the white-box AES implementation, which is vulnerable to power
analysis, and is about three times the amount of operations required by the
straightforward AES implementation.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Mistakes of A Popular Protocol Calculating Private Set Intersection and Union Cardinality and Its Corrections. (arXiv:2207.13277v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13277">http://arxiv.org/abs/2207.13277</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13277] Mistakes of A Popular Protocol Calculating Private Set Intersection and Union Cardinality and Its Corrections](http://arxiv.org/abs/2207.13277)</code></li>
<li>Summary: <p>In 2012, De Cristofaro et al. proposed a protocol to calculate the Private
Set Intersection and Union cardinality(PSI-CA and PSU-CA). This protocol's
security is based on the famous DDH assumption. Since its publication, it has
gained lots of popularity because of its efficiency(linear complexity in
computation and communication) and concision. So far, it's still considered one
of the most efficient PSI-CA protocols and the most cited(more than 170
citations) PSI-CA paper based on the Google Scholar search.
</p></li>
</ul>

<p>However, when we tried to implement this protocol, we couldn't get the
correct result of the test data. Since the original paper lacks of experimental
results to verify the protocol's correctness, we looked deeper into the
protocol and found out it made a fundamental mistake. Needless to say, its
correctness analysis and security proof are also wrong.
</p>
<p>In this paper, we will point out this PSI-CA protocol's mistakes, and provide
the correct version of this protocol as well as the PSI protocol developed from
this protocol. We also present a new security proof and some experimental
results of the corrected protocol.
</p>

<h3>Title: Railway cyber-security in the era of interconnected systems: a survey. (arXiv:2207.13412v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13412">http://arxiv.org/abs/2207.13412</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13412] Railway cyber-security in the era of interconnected systems: a survey](http://arxiv.org/abs/2207.13412)</code></li>
<li>Summary: <p>Technological advances in the telecommunications industry have brought
significant advantages in the management and performance of communication
networks. The railway industry, where signaling systems are now fully
computerized, is among the ones that have benefited the most. These
interconnected systems, however, have a wide area exposed to cyberattacks. This
survey examines the cybersecurity aspects of railway signaling systems by
considering the standards, guidelines, and frameworks most widely used in the
industry. We dedicate specific attention to communication networks since data
communication systems are essential to signaling architectures. To this end, we
explore using dedicated cyber ranges as an enabling technology to model attacks
to computer networks, emulate attack-defense scenarios, study vulnerabilities
impact in general, and finally devise countermeasures to them.
</p></li>
</ul>

<h3>Title: Information We Can Extract About a User From 'One Minute Mobile Application Usage'. (arXiv:2207.13222v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13222">http://arxiv.org/abs/2207.13222</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13222] Information We Can Extract About a User From 'One Minute Mobile Application Usage'](http://arxiv.org/abs/2207.13222)</code></li>
<li>Summary: <p>Understanding human behavior is an important task and has applications in
many domains such as targeted advertisement, health analytics, security, and
entertainment, etc. For this purpose, designing a system for activity
recognition (AR) is important. However, since every human can have different
behaviors, understanding and analyzing common patterns become a challenging
task. Since smartphones are easily available to every human being in the modern
world, using them to track the human activities becomes possible. In this
paper, we extracted different human activities using accelerometer,
magnetometer, and gyroscope sensors of android smartphones by building an
android mobile applications. Using different social media applications, such as
Facebook, Instagram, Whatsapp, and Twitter, we extracted the raw sensor values
along with the attributes of $29$ subjects along with their attributes (class
labels) such as age, gender, and left/right/both hands application usage. We
extract features from the raw signals and use them to perform classification
using different machine learning (ML) algorithms. Using statistical analysis,
we show the importance of different features towards the prediction of class
labels. In the end, we use the trained ML model on our data to extract unknown
features from a well known activity recognition data from UCI repository, which
highlights the potential of privacy breach using ML models. This security
analysis could help researchers in future to take appropriate steps to preserve
the privacy of human subjects.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Concurrent Subsidiary Supervision for Unsupervised Source-Free Domain Adaptation. (arXiv:2207.13247v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13247">http://arxiv.org/abs/2207.13247</a></li>
<li>Code URL: <a href="https://github.com/val-iisc/stickerda">https://github.com/val-iisc/stickerda</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13247] Concurrent Subsidiary Supervision for Unsupervised Source-Free Domain Adaptation](http://arxiv.org/abs/2207.13247)</code></li>
<li>Summary: <p>The prime challenge in unsupervised domain adaptation (DA) is to mitigate the
domain shift between the source and target domains. Prior DA works show that
pretext tasks could be used to mitigate this domain shift by learning domain
invariant representations. However, in practice, we find that most existing
pretext tasks are ineffective against other established techniques. Thus, we
theoretically analyze how and when a subsidiary pretext task could be leveraged
to assist the goal task of a given DA problem and develop objective subsidiary
task suitability criteria. Based on this criteria, we devise a novel process of
sticker intervention and cast sticker classification as a supervised subsidiary
DA problem concurrent to the goal task unsupervised DA. Our approach not only
improves goal task adaptation performance, but also facilitates
privacy-oriented source-free DA i.e. without concurrent source-target access.
Experiments on the standard Office-31, Office-Home, DomainNet, and VisDA
benchmarks demonstrate our superiority for both single-source and multi-source
source-free DA. Our approach also complements existing non-source-free works,
achieving leading performance.
</p></li>
</ul>

<h3>Title: Post-Train Adaptive MobileNet for Fast Anti-Spoofing. (arXiv:2207.13410v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13410">http://arxiv.org/abs/2207.13410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13410] Post-Train Adaptive MobileNet for Fast Anti-Spoofing](http://arxiv.org/abs/2207.13410)</code></li>
<li>Summary: <p>Many applications require high accuracy of neural networks as well as low
latency and user data privacy guaranty. Face anti-spoofing is one of such
tasks. However, a single model might not give the best results for different
device performance categories, while training multiple models is time
consuming. In this work we present Post-Train Adaptive (PTA) block. Such a
block is simple in structure and offers a drop-in replacement for the
MobileNetV2 Inverted Residual block. The PTA block has multiple branches with
different computation costs. The branch to execute can be selected on-demand
and at runtime; thus, offering different inference times and configuration
capability for multiple device tiers. Crucially, the model is trained once and
can be easily reconfigured after training, even directly on a mobile device. In
addition, the proposed approach shows substantially better overall performance
in comparison to the original MobileNetV2 as tested on CelebA-Spoof dataset.
Different PTA block configurations are sampled at training time, which also
decreases overall wall-clock time needed to train the model. While we present
computational results for the anti-spoofing problem, the MobileNetV2 with PTA
blocks is applicable to any problem solvable with convolutional neural
networks, which makes the results presented practically significant.
</p></li>
</ul>

<h3>Title: Exploring the Unprecedented Privacy Risks of the Metaverse. (arXiv:2207.13176v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13176">http://arxiv.org/abs/2207.13176</a></li>
<li>Code URL: <a href="https://github.com/metaguard/metadata">https://github.com/metaguard/metadata</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13176] Exploring the Unprecedented Privacy Risks of the Metaverse](http://arxiv.org/abs/2207.13176)</code></li>
<li>Summary: <p>Thirty study participants playtested an innocent-looking "escape room" game
in virtual reality (VR). Behind the scenes, an adversarial program had
accurately inferred over 25 personal data attributes, from anthropometrics like
height and wingspan to demographics like age and gender, within just a few
minutes of gameplay. As notoriously data-hungry companies become increasingly
involved in VR development, this experimental scenario may soon represent a
typical VR user experience. While virtual telepresence applications (and the
so-called "metaverse") have recently received increased attention and
investment from major tech firms, these environments remain relatively
under-studied from a security and privacy standpoint. In this work, we
illustrate how VR attackers can covertly ascertain dozens of personal data
attributes from seemingly-anonymous users of popular metaverse applications
like VRChat. These attackers can be as simple as other VR users without special
privilege, and the potential scale and scope of this data collection far exceed
what is feasible within traditional mobile and web applications. We aim to shed
light on the unique privacy risks of the metaverse, and provide the first
holistic framework for understanding intrusive data harvesting attacks in these
emerging VR ecosystems.
</p></li>
</ul>

<h3>Title: Fine-grained Private Knowledge Distillation. (arXiv:2207.13253v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13253">http://arxiv.org/abs/2207.13253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13253] Fine-grained Private Knowledge Distillation](http://arxiv.org/abs/2207.13253)</code></li>
<li>Summary: <p>Knowledge distillation has emerged as a scalable and effective way for
privacy-preserving machine learning. One remaining drawback is that it consumes
privacy in a model-level (i.e., client-level) manner, every distillation query
incurs privacy loss of one client's all records. In order to attain
fine-grained privacy accountant and improve utility, this work proposes a
model-free reverse $k$-NN labeling method towards record-level private
knowledge distillation, where each record is employed for labeling at most $k$
queries. Theoretically, we provide bounds of labeling error rate under the
centralized/local/shuffle model of differential privacy (w.r.t. the number of
records per query, privacy budgets). Experimentally, we demonstrate that it
achieves new state-of-the-art accuracy with one order of magnitude lower of
privacy loss. Specifically, on the CIFAR-$10$ dataset, it reaches $82.1\%$ test
accuracy with centralized privacy budget $1.0$; on the MNIST/SVHN dataset, it
reaches $99.1\%$/$95.6\%$ accuracy respectively with budget $0.1$. It is the
first time deep learning with differential privacy achieve comparable accuracy
with reasonable data privacy protection (i.e., $\exp(\epsilon)\leq 1.5$). Our
code is available at https://github.com/liyuntong9/rknn.
</p></li>
</ul>

<h3>Title: Analyzing the Differentially Private Theil-Sen Estimator for Simple Linear Regression. (arXiv:2207.13289v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13289">http://arxiv.org/abs/2207.13289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13289] Analyzing the Differentially Private Theil-Sen Estimator for Simple Linear Regression](http://arxiv.org/abs/2207.13289)</code></li>
<li>Summary: <p>In this paper, we focus on differentially private point and interval
estimators for simple linear regression. Motivated by recent work that
highlights the strong empirical performance of a robust algorithm called
$\texttt{DPTheilSen}$, we provide a theoretical analysis of its privacy and
accuracy guarantees, offer guidance on setting hyperparameters, and show how to
produce differentially private confidence intervals for the slope.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: SAC-AP: Soft Actor Critic based Deep Reinforcement Learning for Alert Prioritization. (arXiv:2207.13666v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13666">http://arxiv.org/abs/2207.13666</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13666] SAC-AP: Soft Actor Critic based Deep Reinforcement Learning for Alert Prioritization](http://arxiv.org/abs/2207.13666)</code></li>
<li>Summary: <p>Intrusion detection systems (IDS) generate a large number of false alerts
which makes it difficult to inspect true positives. Hence, alert prioritization
plays a crucial role in deciding which alerts to investigate from an enormous
number of alerts that are generated by IDS. Recently, deep reinforcement
learning (DRL) based deep deterministic policy gradient (DDPG) off-policy
method has shown to achieve better results for alert prioritization as compared
to other state-of-the-art methods. However, DDPG is prone to the problem of
overfitting. Additionally, it also has a poor exploration capability and hence
it is not suitable for problems with a stochastic environment. To address these
limitations, we present a soft actor-critic based DRL algorithm for alert
prioritization (SAC-AP), an off-policy method, based on the maximum entropy
reinforcement learning framework that aims to maximize the expected reward
while also maximizing the entropy. Further, the interaction between an
adversary and a defender is modeled as a zero-sum game and a double oracle
framework is utilized to obtain the approximate mixed strategy Nash equilibrium
(MSNE). SAC-AP finds robust alert investigation policies and computes pure
strategy best response against opponent's mixed strategy. We present the
overall design of SAC-AP and evaluate its performance as compared to other
state-of-the art alert prioritization methods. We consider defender's loss,
i.e., the defender's inability to investigate the alerts that are triggered due
to attacks, as the performance metric. Our results show that SAC-AP achieves up
to 30% decrease in defender's loss as compared to the DDPG based alert
prioritization method and hence provides better protection against intrusions.
Moreover, the benefits are even higher when SAC-AP is compared to other
traditional alert prioritization methods including Uniform, GAIN, RIO and
Suricata.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity. (arXiv:2207.13129v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13129">http://arxiv.org/abs/2207.13129</a></li>
<li>Code URL: <a href="https://github.com/framartin/lgv-geometric-transferability">https://github.com/framartin/lgv-geometric-transferability</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13129] LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity](http://arxiv.org/abs/2207.13129)</code></li>
<li>Summary: <p>We propose transferability from Large Geometric Vicinity (LGV), a new
technique to increase the transferability of black-box adversarial attacks. LGV
starts from a pretrained surrogate model and collects multiple weight sets from
a few additional training epochs with a constant and high learning rate. LGV
exploits two geometric properties that we relate to transferability. First,
models that belong to a wider weight optimum are better surrogates. Second, we
identify a subspace able to generate an effective surrogate ensemble among this
wider optimum. Through extensive experiments, we show that LGV alone
outperforms all (combinations of) four established test-time transformations by
1.8 to 59.9 percentage points. Our findings shed new light on the importance of
the geometry of the weight space to explain the transferability of adversarial
examples.
</p></li>
</ul>

<h3>Title: Point Cloud Attacks in Graph Spectral Domain: When 3D Geometry Meets Graph Signal Processing. (arXiv:2207.13326v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13326">http://arxiv.org/abs/2207.13326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13326] Point Cloud Attacks in Graph Spectral Domain: When 3D Geometry Meets Graph Signal Processing](http://arxiv.org/abs/2207.13326)</code></li>
<li>Summary: <p>With the increasing attention in various 3D safety-critical applications,
point cloud learning models have been shown to be vulnerable to adversarial
attacks. Although existing 3D attack methods achieve high success rates, they
delve into the data space with point-wise perturbation, which may neglect the
geometric characteristics. Instead, we propose point cloud attacks from a new
perspective -- the graph spectral domain attack, aiming to perturb graph
transform coefficients in the spectral domain that corresponds to varying
certain geometric structure. Specifically, leveraging on graph signal
processing, we first adaptively transform the coordinates of points onto the
spectral domain via graph Fourier transform (GFT) for compact representation.
Then, we analyze the influence of different spectral bands on the geometric
structure, based on which we propose to perturb the GFT coefficients via a
learnable graph spectral filter. Considering the low-frequency components
mainly contribute to the rough shape of the 3D object, we further introduce a
low-frequency constraint to limit perturbations within imperceptible
high-frequency components. Finally, the adversarial point cloud is generated by
transforming the perturbed spectral representation back to the data domain via
the inverse GFT. Experimental results demonstrate the effectiveness of the
proposed attack in terms of both the imperceptibility and attack success rates.
</p></li>
</ul>

<h3>Title: Look Closer to Your Enemy: Learning to Attack via Teacher-student Mimicking. (arXiv:2207.13381v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13381">http://arxiv.org/abs/2207.13381</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13381] Look Closer to Your Enemy: Learning to Attack via Teacher-student Mimicking](http://arxiv.org/abs/2207.13381)</code></li>
<li>Summary: <p>This paper aims to generate realistic attack samples of person
re-identification, ReID, by reading the enemy's mind (VM). In this paper, we
propose a novel inconspicuous and controllable ReID attack baseline, LCYE, to
generate adversarial query images. Concretely, LCYE first distills VM's
knowledge via teacher-student memory mimicking in the proxy task. Then this
knowledge prior acts as an explicit cipher conveying what is essential and
realistic, believed by VM, for accurate adversarial misleading. Besides,
benefiting from the multiple opposing task framework of LCYE, we further
investigate the interpretability and generalization of ReID models from the
view of the adversarial attack, including cross-domain adaption, cross-model
consensus, and online learning process. Extensive experiments on four ReID
benchmarks show that our method outperforms other state-of-the-art attackers
with a large margin in white-box, black-box, and target attacks. Our code is
now available at https://gitfront.io/r/user-3704489/mKXusqDT4ffr/LCYE/.
</p></li>
</ul>

<h3>Title: Hardly Perceptible Trojan Attack against Neural Networks with Bit Flips. (arXiv:2207.13417v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13417">http://arxiv.org/abs/2207.13417</a></li>
<li>Code URL: <a href="https://github.com/jiawangbai/hpt">https://github.com/jiawangbai/hpt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13417] Hardly Perceptible Trojan Attack against Neural Networks with Bit Flips](http://arxiv.org/abs/2207.13417)</code></li>
<li>Summary: <p>The security of deep neural networks (DNNs) has attracted increasing
attention due to their widespread use in various applications. Recently, the
deployed DNNs have been demonstrated to be vulnerable to Trojan attacks, which
manipulate model parameters with bit flips to inject a hidden behavior and
activate it by a specific trigger pattern. However, all existing Trojan attacks
adopt noticeable patch-based triggers (e.g., a square pattern), making them
perceptible to humans and easy to be spotted by machines. In this paper, we
present a novel attack, namely hardly perceptible Trojan attack (HPT). HPT
crafts hardly perceptible Trojan images by utilizing the additive noise and per
pixel flow field to tweak the pixel values and positions of the original
images, respectively. To achieve superior attack performance, we propose to
jointly optimize bit flips, additive noise, and flow field. Since the weight
bits of the DNNs are binary, this problem is very hard to be solved. We handle
the binary constraint with equivalent replacement and provide an effective
optimization algorithm. Extensive experiments on CIFAR-10, SVHN, and ImageNet
datasets show that the proposed HPT can generate hardly perceptible Trojan
images, while achieving comparable or better attack performance compared to the
state-of-the-art methods. The code is available at:
https://github.com/jiawangbai/HPT.
</p></li>
</ul>

<h3>Title: Partial Selfish Mining for More Profits. (arXiv:2207.13478v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13478">http://arxiv.org/abs/2207.13478</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13478] Partial Selfish Mining for More Profits](http://arxiv.org/abs/2207.13478)</code></li>
<li>Summary: <p>Mining attacks aim to gain an unfair share of extra rewards in the blockchain
mining. Selfish mining can preserve discovered blocks and strategically release
them, wasting honest miners' computing resources and getting higher profits.
Previous mining attacks either conceal the mined whole blocks (hiding or
discarding), or release them completely in a particular time slot (e.g.,
causing a fork). In this paper, we extend the mining attack's strategy space to
partial block sharing, and propose a new and feasible Partial Selfish Mining
(PSM) attack. We show that by releasing partial block data publicly and
attracting rational miners to work on attacker's private branch, attackers and
these attracted miners can gain an unfair share of mining rewards. We then
propose Advanced PSM (A-PSM) attack that can further improve attackers' profits
to be no less than the selfish mining. Both theoretical and experimental
results show that PSM attackers can be more profitable than selfish miners
under a certain range of mining power and network conditions. A-PSM attackers
can gain even higher profits than both selfish mining and honest mining with
attracted rational miners.
</p></li>
</ul>

<h3>Title: Membership Inference Attacks via Adversarial Examples. (arXiv:2207.13572v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13572">http://arxiv.org/abs/2207.13572</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13572] Membership Inference Attacks via Adversarial Examples](http://arxiv.org/abs/2207.13572)</code></li>
<li>Summary: <p>The raise of machine learning and deep learning led to significant
improvement in several domains. This change is supported by both the dramatic
rise in computation power and the collection of large datasets. Such massive
datasets often include personal data which can represent a threat to privacy.
Membership inference attacks are a novel direction of research which aims at
recovering training data used by a learning algorithm. In this paper, we
develop a mean to measure the leakage of training data leveraging a quantity
appearing as a proxy of the total variation of a trained model near its
training samples. We extend our work by providing a novel defense mechanism.
Our contributions are supported by empirical evidence through convincing
numerical experiments.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Mid-level Representation Enhancement and Graph Embedded Uncertainty Suppressing for Facial Expression Recognition. (arXiv:2207.13235v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13235">http://arxiv.org/abs/2207.13235</a></li>
<li>Code URL: <a href="https://github.com/cruiseyugh/gus">https://github.com/cruiseyugh/gus</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13235] Mid-level Representation Enhancement and Graph Embedded Uncertainty Suppressing for Facial Expression Recognition](http://arxiv.org/abs/2207.13235)</code></li>
<li>Summary: <p>Facial expression is an essential factor in conveying human emotional states
and intentions. Although remarkable advancement has been made in facial
expression recognition (FER) task, challenges due to large variations of
expression patterns and unavoidable data uncertainties still remain. In this
paper, we propose mid-level representation enhancement (MRE) and graph embedded
uncertainty suppressing (GUS) addressing these issues. On one hand, MRE is
introduced to avoid expression representation learning being dominated by a
limited number of highly discriminative patterns. On the other hand, GUS is
introduced to suppress the feature ambiguity in the representation space. The
proposed method not only has stronger generalization capability to handle
different variations of expression patterns but also more robustness to capture
expression representations. Experimental evaluation on Aff-Wild2 have verified
the effectiveness of the proposed method.
</p></li>
</ul>

<h3>Title: Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13243">http://arxiv.org/abs/2207.13243</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13243] Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks](http://arxiv.org/abs/2207.13243)</code></li>
<li>Summary: <p>The last decade of machine learning has seen drastic increases in scale and
capabilities, and deep neural networks (DNNs) are increasingly being deployed
across a wide range of domains. However, the inner workings of DNNs are
generally difficult to understand, raising concerns about the safety of using
these systems without a rigorous understanding of how they function. In this
survey, we review literature on techniques for interpreting the inner
components of DNNs, which we call "inner" interpretability methods.
Specifically, we review methods for interpreting weights, neurons, subnetworks,
and latent representations with a focus on how these techniques relate to the
goal of designing safer, more trustworthy AI systems. We also highlight
connections between interpretability and work in modularity, adversarial
robustness, continual learning, network compression, and studying the human
visual system. Finally, we discuss key challenges and argue for future work in
interpretability for AI safety that focuses on diagnostics, benchmarking, and
robustness.
</p></li>
</ul>

<h3>Title: GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video and GPS data. (arXiv:2207.13297v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13297">http://arxiv.org/abs/2207.13297</a></li>
<li>Code URL: <a href="https://github.com/jimmy9704/gps-glass">https://github.com/jimmy9704/gps-glass</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13297] GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video and GPS data](http://arxiv.org/abs/2207.13297)</code></li>
<li>Summary: <p>Semantic segmentation for autonomous driving should be robust against various
in-the-wild environments. Nighttime semantic segmentation is especially
challenging due to a lack of annotated nighttime images and a large domain gap
from daytime images with sufficient annotation. In this paper, we propose a
novel GPS-based training framework for nighttime semantic segmentation. Given
GPS-aligned pairs of daytime and nighttime images, we perform cross-domain
correspondence matching to obtain pixel-level pseudo supervision. Moreover, we
conduct flow estimation between daytime video frames and apply GPS-based
scaling to acquire another pixel-level pseudo supervision. Using these pseudo
supervisions with a confidence map, we train a nighttime semantic segmentation
network without any annotation from nighttime images. Experimental results
demonstrate the effectiveness of the proposed method on several nighttime
semantic segmentation datasets. Our source code is available at
https://github.com/jimmy9704/GPS-GLASS.
</p></li>
</ul>

<h3>Title: NICEST: Noisy Label Correction and Training for Robust Scene Graph Generation. (arXiv:2207.13316v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13316">http://arxiv.org/abs/2207.13316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13316] NICEST: Noisy Label Correction and Training for Robust Scene Graph Generation](http://arxiv.org/abs/2207.13316)</code></li>
<li>Summary: <p>Nearly all existing scene graph generation (SGG) models have overlooked the
ground-truth annotation qualities of mainstream SGG datasets, i.e., they
assume: 1) all the manually annotated positive samples are equally correct; 2)
all the un-annotated negative samples are absolutely background. In this paper,
we argue that neither of the assumptions applies to SGG: there are numerous
noisy ground-truth predicate labels that break these two assumptions and harm
the training of unbiased SGG models. To this end, we propose a novel NoIsy
label CorrEction and Sample Training strategy for SGG: NICEST. Specifically, it
consists of two parts: NICE and NIST, which rule out these noisy label issues
by generating high-quality samples and the effective training strategy,
respectively. NICE first detects noisy samples and then reassigns them more
high-quality soft predicate labels. NIST is a multi-teacher knowledge
distillation based training strategy, which enables the model to learn unbiased
fusion knowledge. And a dynamic trade-off weighting strategy in NIST is
designed to penalize the bias of different teachers. Due to the model-agnostic
nature of both NICE and NIST, our NICEST can be seamlessly incorporated into
any SGG architecture to boost its performance on different predicate
categories. In addition, to better evaluate the generalization of SGG models,
we further propose a new benchmark VG-OOD, by re-organizing the prevalent VG
dataset and deliberately making the predicate distributions of the training and
test sets as different as possible for each subject-object category pair. This
new benchmark helps disentangle the influence of subject-object category based
frequency biases. Extensive ablations and results on different backbones and
tasks have attested to the effectiveness and generalization ability of each
component of NICEST.
</p></li>
</ul>

<h3>Title: PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation. (arXiv:2207.13340v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13340">http://arxiv.org/abs/2207.13340</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13340] PointFix: Learning to Fix Domain Bias for Robust Online Stereo Adaptation](http://arxiv.org/abs/2207.13340)</code></li>
<li>Summary: <p>Online stereo adaptation tackles the domain shift problem, caused by
different environments between synthetic (training) and real (test) datasets,
to promptly adapt stereo models in dynamic real-world applications such as
autonomous driving. However, previous methods often fail to counteract
particular regions related to dynamic objects with more severe environmental
changes. To mitigate this issue, we propose to incorporate an auxiliary
point-selective network into a meta-learning framework, called PointFix, to
provide a robust initialization of stereo models for online stereo adaptation.
In a nutshell, our auxiliary network learns to fix local variants intensively
by effectively back-propagating local information through the meta-gradient for
the robust initialization of the baseline model. This network is
model-agnostic, so can be used in any kind of architectures in a plug-and-play
manner. We conduct extensive experiments to verify the effectiveness of our
method under three adaptation settings such as short-, mid-, and long-term
sequences. Experimental results show that the proper initialization of the base
stereo model by the auxiliary network enables our learning paradigm to achieve
state-of-the-art performance at inference.
</p></li>
</ul>

<h3>Title: One-Trimap Video Matting. (arXiv:2207.13353v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13353">http://arxiv.org/abs/2207.13353</a></li>
<li>Code URL: <a href="https://github.com/hongje/otvm">https://github.com/hongje/otvm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13353] One-Trimap Video Matting](http://arxiv.org/abs/2207.13353)</code></li>
<li>Summary: <p>Recent studies made great progress in video matting by extending the success
of trimap-based image matting to the video domain. In this paper, we push this
task toward a more practical setting and propose One-Trimap Video Matting
network (OTVM) that performs video matting robustly using only one
user-annotated trimap. A key of OTVM is the joint modeling of trimap
propagation and alpha prediction. Starting from baseline trimap propagation and
alpha prediction networks, our OTVM combines the two networks with an
alpha-trimap refinement module to facilitate information flow. We also present
an end-to-end training strategy to take full advantage of the joint model. Our
joint modeling greatly improves the temporal stability of trimap propagation
compared to the previous decoupled methods. We evaluate our model on two latest
video matting benchmarks, Deep Video Matting and VideoMatting108, and
outperform state-of-the-art by significant margins (MSE improvements of 56.4%
and 56.7%, respectively). The source code and model are available online:
https://github.com/Hongje/OTVM.
</p></li>
</ul>

<h3>Title: TransNorm: Transformer Provides a Strong Spatial Normalization Mechanism for a Deep Segmentation Model. (arXiv:2207.13415v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13415">http://arxiv.org/abs/2207.13415</a></li>
<li>Code URL: <a href="https://github.com/rezazad68/transnorm">https://github.com/rezazad68/transnorm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13415] TransNorm: Transformer Provides a Strong Spatial Normalization Mechanism for a Deep Segmentation Model](http://arxiv.org/abs/2207.13415)</code></li>
<li>Summary: <p>In the past few years, convolutional neural networks (CNNs), particularly
U-Net, have been the prevailing technique in the medical image processing era.
Specifically, the seminal U-Net, as well as its alternatives, have successfully
managed to address a wide variety of medical image segmentation tasks. However,
these architectures are intrinsically imperfect as they fail to exhibit
long-range interactions and spatial dependencies leading to a severe
performance drop in the segmentation of medical images with variable shapes and
structures. Transformers, preliminary proposed for sequence-to-sequence
prediction, have arisen as surrogate architectures to precisely model global
information assisted by the self-attention mechanism. Despite being feasibly
designed, utilizing a pure Transformer for image segmentation purposes can
result in limited localization capacity stemming from inadequate low-level
features. Thus, a line of research strives to design robust variants of
Transformer-based U-Net. In this paper, we propose Trans-Norm, a novel deep
segmentation framework which concomitantly consolidates a Transformer module
into both encoder and skip-connections of the standard U-Net. We argue that the
expedient design of skip-connections can be crucial for accurate segmentation
as it can assist in feature fusion between the expanding and contracting paths.
In this respect, we derive a Spatial Normalization mechanism from the
Transformer module to adaptively recalibrate the skip connection path.
Extensive experiments across three typical tasks for medical image segmentation
demonstrate the effectiveness of TransNorm. The codes and trained models are
publicly available at https://github.com/rezazad68/transnorm.
</p></li>
</ul>

<h3>Title: Rethinking Efficacy of Softmax for Lightweight Non-Local Neural Networks. (arXiv:2207.13423v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13423">http://arxiv.org/abs/2207.13423</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13423] Rethinking Efficacy of Softmax for Lightweight Non-Local Neural Networks](http://arxiv.org/abs/2207.13423)</code></li>
<li>Summary: <p>Non-local (NL) block is a popular module that demonstrates the capability to
model global contexts. However, NL block generally has heavy computation and
memory costs, so it is impractical to apply the block to high-resolution
feature maps. In this paper, to investigate the efficacy of NL block, we
empirically analyze if the magnitude and direction of input feature vectors
properly affect the attention between vectors. The results show the inefficacy
of softmax operation which is generally used to normalize the attention map of
the NL block. Attention maps normalized with softmax operation highly rely upon
magnitude of key vectors, and performance is degenerated if the magnitude
information is removed. By replacing softmax operation with the scaling factor,
we demonstrate improved performance on CIFAR-10, CIFAR-100, and Tiny-ImageNet.
In Addition, our method shows robustness to embedding channel reduction and
embedding weight initialization. Notably, our method makes multi-head attention
employable without additional computational cost.
</p></li>
</ul>

<h3>Title: Reducing the Vision and Language Bias for Temporal Sentence Grounding. (arXiv:2207.13457v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13457">http://arxiv.org/abs/2207.13457</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13457] Reducing the Vision and Language Bias for Temporal Sentence Grounding](http://arxiv.org/abs/2207.13457)</code></li>
<li>Summary: <p>Temporal sentence grounding (TSG) is an important yet challenging task in
multimedia information retrieval. Although previous TSG methods have achieved
decent performance, they tend to capture the selection biases of frequently
appeared video-query pairs in the dataset rather than present robust multimodal
reasoning abilities, especially for the rarely appeared pairs. In this paper,
we study the above issue of selection biases and accordingly propose a
Debiasing-TSG (D-TSG) model to filter and remove the negative biases in both
vision and language modalities for enhancing the model generalization ability.
Specifically, we propose to alleviate the issue from two perspectives: 1)
Feature distillation. We built a multi-modal debiasing branch to firstly
capture the vision and language biases, and then apply a bias identification
module to explicitly recognize the true negative biases and remove them from
the benign multi-modal representations. 2) Contrastive sample generation. We
construct two types of negative samples to enforce the model to accurately
learn the aligned multi-modal semantics and make complete semantic reasoning.
We apply the proposed model to both commonly and rarely appeared TSG cases, and
demonstrate its effectiveness by achieving the state-of-the-art performance on
three benchmark datasets (ActivityNet Caption, TACoS, and Charades-STA).
</p></li>
</ul>

<h3>Title: A Proper Orthogonal Decomposition approach for parameters reduction of Single Shot Detector networks. (arXiv:2207.13551v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13551">http://arxiv.org/abs/2207.13551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13551] A Proper Orthogonal Decomposition approach for parameters reduction of Single Shot Detector networks](http://arxiv.org/abs/2207.13551)</code></li>
<li>Summary: <p>As a major breakthrough in artificial intelligence and deep learning,
Convolutional Neural Networks have achieved an impressive success in solving
many problems in several fields including computer vision and image processing.
Real-time performance, robustness of algorithms and fast training processes
remain open problems in these contexts. In addition object recognition and
detection are challenging tasks for resource-constrained embedded systems,
commonly used in the industrial sector. To overcome these issues, we propose a
dimensionality reduction framework based on Proper Orthogonal Decomposition, a
classical model order reduction technique, in order to gain a reduction in the
number of hyperparameters of the net. We have applied such framework to SSD300
architecture using PASCAL VOC dataset, demonstrating a reduction of the network
dimension and a remarkable speedup in the fine-tuning of the network in a
transfer learning context.
</p></li>
</ul>

<h3>Title: Multi-layer Representation Learning for Robust OOD Image Classification. (arXiv:2207.13678v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13678">http://arxiv.org/abs/2207.13678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13678] Multi-layer Representation Learning for Robust OOD Image Classification](http://arxiv.org/abs/2207.13678)</code></li>
<li>Summary: <p>Convolutional Neural Networks have become the norm in image classification.
Nevertheless, their difficulty to maintain high accuracy across datasets has
become apparent in the past few years. In order to utilize such models in
real-world scenarios and applications, they must be able to provide trustworthy
predictions on unseen data. In this paper, we argue that extracting features
from a CNN's intermediate layers can assist in the model's final prediction.
Specifically, we adapt the Hypercolumns method to a ResNet-18 and find a
significant increase in the model's accuracy, when evaluating on the NICO
dataset.
</p></li>
</ul>

<h3>Title: Shift-tolerant Perceptual Similarity Metric. (arXiv:2207.13686v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13686">http://arxiv.org/abs/2207.13686</a></li>
<li>Code URL: <a href="https://github.com/abhijay9/shifttolerant-lpips">https://github.com/abhijay9/shifttolerant-lpips</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13686] Shift-tolerant Perceptual Similarity Metric](http://arxiv.org/abs/2207.13686)</code></li>
<li>Summary: <p>Existing perceptual similarity metrics assume an image and its reference are
well aligned. As a result, these metrics are often sensitive to a small
alignment error that is imperceptible to the human eyes. This paper studies the
effect of small misalignment, specifically a small shift between the input and
reference image, on existing metrics, and accordingly develops a shift-tolerant
similarity metric. This paper builds upon LPIPS, a widely used learned
perceptual similarity metric, and explores architectural design considerations
to make it robust against imperceptible misalignment. Specifically, we study a
wide spectrum of neural network elements, such as anti-aliasing filtering,
pooling, striding, padding, and skip connection, and discuss their roles in
making a robust metric. Based on our studies, we develop a new deep neural
network-based perceptual similarity metric. Our experiments show that our
metric is tolerant to imperceptible shifts while being consistent with the
human similarity judgment.
</p></li>
</ul>

<h3>Title: A Survey of Intent Classification and Slot-Filling Datasets for Task-Oriented Dialog. (arXiv:2207.13211v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13211">http://arxiv.org/abs/2207.13211</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13211] A Survey of Intent Classification and Slot-Filling Datasets for Task-Oriented Dialog](http://arxiv.org/abs/2207.13211)</code></li>
<li>Summary: <p>Interest in dialog systems has grown substantially in the past decade. By
extension, so too has interest in developing and improving intent
classification and slot-filling models, which are two components that are
commonly used in task-oriented dialog systems. Moreover, good evaluation
benchmarks are important in helping to compare and analyze systems that
incorporate such models. Unfortunately, much of the literature in the field is
limited to analysis of relatively few benchmark datasets. In an effort to
promote more robust analyses of task-oriented dialog systems, we have conducted
a survey of publicly available datasets for the tasks of intent classification
and slot-filling. We catalog the important characteristics of each dataset, and
offer discussion on the applicability, strengths, and weaknesses of each. Our
goal is that this survey aids in increasing the accessibility of these
datasets, which we hope will enable their use in future evaluations of intent
classification and slot-filling models for task-oriented dialog systems.
</p></li>
</ul>

<h3>Title: Time Series Forecasting Models Copy the Past: How to Mitigate. (arXiv:2207.13441v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13441">http://arxiv.org/abs/2207.13441</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13441] Time Series Forecasting Models Copy the Past: How to Mitigate](http://arxiv.org/abs/2207.13441)</code></li>
<li>Summary: <p>Time series forecasting is at the core of important application domains
posing significant challenges to machine learning algorithms. Recently neural
network architectures have been widely applied to the problem of time series
forecasting. Most of these models are trained by minimizing a loss function
that measures predictions' deviation from the real values. Typical loss
functions include mean squared error (MSE) and mean absolute error (MAE). In
the presence of noise and uncertainty, neural network models tend to replicate
the last observed value of the time series, thus limiting their applicability
to real-world data. In this paper, we provide a formal definition of the above
problem and we also give some examples of forecasts where the problem is
observed. We also propose a regularization term penalizing the replication of
previously seen values. We evaluate the proposed regularization term both on
synthetic and real-world datasets. Our results indicate that the regularization
term mitigates to some extent the aforementioned problem and gives rise to more
robust models.
</p></li>
</ul>

<h3>Title: Safe and Robust Experience Sharing for Deterministic Policy Gradient Algorithms. (arXiv:2207.13453v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13453">http://arxiv.org/abs/2207.13453</a></li>
<li>Code URL: <a href="https://github.com/baturaysaglam/dase">https://github.com/baturaysaglam/dase</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13453] Safe and Robust Experience Sharing for Deterministic Policy Gradient Algorithms](http://arxiv.org/abs/2207.13453)</code></li>
<li>Summary: <p>Learning in high dimensional continuous tasks is challenging, mainly when the
experience replay memory is very limited. We introduce a simple yet effective
experience sharing mechanism for deterministic policies in continuous action
domains for the future off-policy deep reinforcement learning applications in
which the allocated memory for the experience replay buffer is limited. To
overcome the extrapolation error induced by learning from other agents'
experiences, we facilitate our algorithm with a novel off-policy correction
technique without any action probability estimates. We test the effectiveness
of our method in challenging OpenAI Gym continuous control tasks and conclude
that it can achieve a safe experience sharing across multiple agents and
exhibits a robust performance when the replay memory is strictly limited.
</p></li>
</ul>

<h3>Title: Learned Label Aggregation for Weak Supervision. (arXiv:2207.13545v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13545">http://arxiv.org/abs/2207.13545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13545] Learned Label Aggregation for Weak Supervision](http://arxiv.org/abs/2207.13545)</code></li>
<li>Summary: <p>The lack of labeled training data is the bottleneck of machine learning in
many applications. To resolve the bottleneck, one promising direction is the
data programming approach that aggregates different sources of weak supervision
signals to generate labeled data easily. Data programming encodes each weak
supervision source with a labeling function (LF), a user-provided program that
predicts noisy labels. The quality of the generated labels depends on a label
aggregation model that aggregates all noisy labels from all LFs to infer the
ground-truth labels.
</p></li>
</ul>

<p>Existing label aggregation methods typically rely on various assumptions and
are not robust across datasets, as we will show empirically. We for the first
time provide an analytical label aggregation method that makes minimum
assumption and is optimal in minimizing a certain form of the averaged
prediction error. Since the complexity of the analytical form is exponential,
we train a model that learns to be the analytical method. Once trained, the
model can be used for any unseen datasets and the model predicts the
ground-truth labels for each dataset in a single forward pass in linear time.
We show the model can be trained using synthetically generated data and design
an effective architecture for the model. On 14 real-world datasets, our model
significantly outperforms the best existing methods in both accuracy (by 3.5
points on average) and efficiency (by six times on average).
</p>

<h2>biometric</h2>
<h3>Title: Statistical Keystroke Synthesis for Improved Bot Detection. (arXiv:2207.13394v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13394">http://arxiv.org/abs/2207.13394</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13394] Statistical Keystroke Synthesis for Improved Bot Detection](http://arxiv.org/abs/2207.13394)</code></li>
<li>Summary: <p>This work proposes two statistical approaches for the synthesis of keystroke
biometric data based on Universal and User-dependent Models. Both approaches
are validated on the bot detection task, using the keystroke synthetic data to
better train the systems. Our experiments include a dataset with 136 million
keystroke events from 168,000 subjects. We have analyzed the performance of the
two synthesis approaches through qualitative and quantitative experiments.
Different bot detectors are considered based on two supervised classifiers
(Support Vector Machine and Long Short-Term Memory network) and a learning
framework including human and generated samples. Our results prove that the
proposed statistical approaches are able to generate realistic human-like
synthetic keystroke samples. Also, the classification results suggest that in
scenarios with large labeled data, these synthetic samples can be detected with
high accuracy. However, in few-shot learning scenarios it represents an
important challenge.
</p></li>
</ul>

<h3>Title: Multi-Forgery Detection Challenge 2022: Push the Frontier of Unconstrained and Diverse Forgery Detection. (arXiv:2207.13505v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13505">http://arxiv.org/abs/2207.13505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13505] Multi-Forgery Detection Challenge 2022: Push the Frontier of Unconstrained and Diverse Forgery Detection](http://arxiv.org/abs/2207.13505)</code></li>
<li>Summary: <p>In this paper, we present the Multi-Forgery Detection Challenge held
concurrently with the IEEE Computer Society Workshop on Biometrics at CVPR</li>
<li>Our Multi-Forgery Detection Challenge aims to detect automatic image
manipulations including but not limited to image editing, image synthesis,
image generation, image photoshop, etc. Our challenge has attracted 674 teams
from all over the world, with about 2000 valid result submission counts. We
invited the Top 10 teams to present their solutions to the challenge, from
which three teams are awarded prizes in the grand finale. In this paper, we
present the solutions from the Top 3 teams, in order to boost the research work
in the field of image forgery detection.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Retrieval-Augmented Transformer for Image Captioning. (arXiv:2207.13162v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13162">http://arxiv.org/abs/2207.13162</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13162] Retrieval-Augmented Transformer for Image Captioning](http://arxiv.org/abs/2207.13162)</code></li>
<li>Summary: <p>Image captioning models aim at connecting Vision and Language by providing
natural language descriptions of input images. In the past few years, the task
has been tackled by learning parametric models and proposing visual feature
extraction advancements or by modeling better multi-modal connections. In this
paper, we investigate the development of an image captioning approach with a
kNN memory, with which knowledge can be retrieved from an external corpus to
aid the generation process. Our architecture combines a knowledge retriever
based on visual similarities, a differentiable encoder, and a kNN-augmented
attention layer to predict tokens based on the past context and on text
retrieved from the external memory. Experimental results, conducted on the COCO
dataset, demonstrate that employing an explicit external memory can aid the
generation process and increase caption quality. Our work opens up new avenues
for improving image captioning models at larger scale.
</p></li>
</ul>

<h3>Title: DynaMarks: Defending Against Deep Learning Model Extraction Using Dynamic Watermarking. (arXiv:2207.13321v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13321">http://arxiv.org/abs/2207.13321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13321] DynaMarks: Defending Against Deep Learning Model Extraction Using Dynamic Watermarking](http://arxiv.org/abs/2207.13321)</code></li>
<li>Summary: <p>The functionality of a deep learning (DL) model can be stolen via model
extraction where an attacker obtains a surrogate model by utilizing the
responses from a prediction API of the original model. In this work, we propose
a novel watermarking technique called DynaMarks to protect the intellectual
property (IP) of DL models against such model extraction attacks in a black-box
setting. Unlike existing approaches, DynaMarks does not alter the training
process of the original model but rather embeds watermark into a surrogate
model by dynamically changing the output responses from the original model
prediction API based on certain secret parameters at inference runtime. The
experimental outcomes on Fashion MNIST, CIFAR-10, and ImageNet datasets
demonstrate the efficacy of DynaMarks scheme to watermark surrogate models
while preserving the accuracies of the original models deployed in edge
devices. In addition, we also perform experiments to evaluate the robustness of
DynaMarks against various watermark removal strategies, thus allowing a DL
model owner to reliably prove model ownership.
</p></li>
</ul>

<h3>Title: Deep Clustering with Features from Self-Supervised Pretraining. (arXiv:2207.13364v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13364">http://arxiv.org/abs/2207.13364</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13364] Deep Clustering with Features from Self-Supervised Pretraining](http://arxiv.org/abs/2207.13364)</code></li>
<li>Summary: <p>A deep clustering model conceptually consists of a feature extractor that
maps data points to a latent space, and a clustering head that groups data
points into clusters in the latent space. Although the two components used to
be trained jointly in an end-to-end fashion, recent works have proved it
beneficial to train them separately in two stages. In the first stage, the
feature extractor is trained via self-supervised learning, which enables the
preservation of the cluster structures among the data points. To preserve the
cluster structures even better, we propose to replace the first stage with
another model that is pretrained on a much larger dataset via self-supervised
learning. The method is simple and might suffer from domain shift. Nonetheless,
we have empirically shown that it can achieve superior clustering performance.
When a vision transformer (ViT) architecture is used for feature extraction,
our method has achieved clustering accuracy 94.0%, 55.6% and 97.9% on CIFAR-10,
CIFAR-100 and STL-10 respectively. The corresponding previous state-of-the-art
results are 84.3%, 47.7% and 80.8%. Our code will be available online with the
publication of the paper.
</p></li>
</ul>

<h3>Title: VICTOR: Visual Incompatibility Detection with Transformers and Fashion-specific contrastive pre-training. (arXiv:2207.13458v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13458">http://arxiv.org/abs/2207.13458</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13458] VICTOR: Visual Incompatibility Detection with Transformers and Fashion-specific contrastive pre-training](http://arxiv.org/abs/2207.13458)</code></li>
<li>Summary: <p>In order to consider fashion outfits as aesthetically pleasing, the garments
that constitute them need to be compatible in terms of visual aspects, such as
style, category and color. With the advent and omnipresence of computer vision
deep learning models, increased interest has also emerged for the task of
visual compatibility detection with the aim to develop quality fashion outfit
recommendation systems. Previous works have defined visual compatibility as a
binary classification task with items in a garment being considered as fully
compatible or fully incompatible. However, this is not applicable to Outfit
Maker applications where users create their own outfits and need to know which
specific items may be incompatible with the rest of the outfit. To address
this, we propose the Visual InCompatibility TransfORmer (VICTOR) that is
optimized for two tasks: 1) overall compatibility as regression and 2) the
detection of mismatching items. Unlike previous works that either rely on
feature extraction from ImageNet-pretrained models or by end-to-end fine
tuning, we utilize fashion-specific contrastive language-image pre-training for
fine tuning computer vision neural networks on fashion imagery. Moreover, we
build upon the Polyvore outfit benchmark to generate partially mismatching
outfits, creating a new dataset termed Polyvore-MISFITs, that is used to train
VICTOR. A series of ablation and comparative analyses show that the proposed
architecture can compete and even surpass the current state-of-the-art on
Polyvore datasets while reducing the instance-wise floating operations by 88%,
striking a balance between high performance and efficiency.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Federated Selective Aggregation for Knowledge Amalgamation. (arXiv:2207.13309v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13309">http://arxiv.org/abs/2207.13309</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13309] Federated Selective Aggregation for Knowledge Amalgamation](http://arxiv.org/abs/2207.13309)</code></li>
<li>Summary: <p>In this paper, we explore a new knowledge-amalgamation problem, termed
Federated Selective Aggregation (FedSA). The goal of FedSA is to train a
student model for a new task with the help of several decentralized teachers,
whose pre-training tasks and data are different and agnostic. Our motivation
for investigating such a problem setup stems from a recent dilemma of model
sharing. Many researchers or institutes have spent enormous resources on
training large and competent networks. Due to the privacy, security, or
intellectual property issues, they are, however, not able to share their own
pre-trained models, even if they wish to contribute to the community. The
proposed FedSA offers a solution to this dilemma and makes it one step further
since, again, the learned student may specialize in a new task different from
all of the teachers. To this end, we proposed a dedicated strategy for handling
FedSA. Specifically, our student-training process is driven by a novel
saliency-based approach that adaptively selects teachers as the participants
and integrates their representative capabilities into the student. To evaluate
the effectiveness of FedSA, we conduct experiments on both single-task and
multi-task settings. Experimental results demonstrate that FedSA effectively
amalgamates knowledge from decentralized models and achieves competitive
performance to centralized baselines.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: ALBench: A Framework for Evaluating Active Learning in Object Detection. (arXiv:2207.13339v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13339">http://arxiv.org/abs/2207.13339</a></li>
<li>Code URL: <a href="https://github.com/industryessentials/ymir">https://github.com/industryessentials/ymir</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13339] ALBench: A Framework for Evaluating Active Learning in Object Detection](http://arxiv.org/abs/2207.13339)</code></li>
<li>Summary: <p>Active learning is an important technology for automated machine learning
systems. In contrast to Neural Architecture Search (NAS) which aims at
automating neural network architecture design, active learning aims at
automating training data selection. It is especially critical for training a
long-tailed task, in which positive samples are sparsely distributed. Active
learning alleviates the expensive data annotation issue through incrementally
training models powered with efficient data selection. Instead of annotating
all unlabeled samples, it iteratively selects and annotates the most valuable
samples. Active learning has been popular in image classification, but has not
been fully explored in object detection. Most of current approaches on object
detection are evaluated with different settings, making it difficult to fairly
compare their performance. To facilitate the research in this field, this paper
contributes an active learning benchmark framework named as ALBench for
evaluating active learning in object detection. Developed on an automatic deep
model training system, this ALBench framework is easy-to-use, compatible with
different active learning algorithms, and ensures the same training and testing
protocols. We hope this automated benchmark system help researchers to easily
reproduce literature's performance and have objective comparisons with prior
arts. The code will be release through Github.
</p></li>
</ul>

<h3>Title: Towards Soft Fairness in Restless Multi-Armed Bandits. (arXiv:2207.13343v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13343">http://arxiv.org/abs/2207.13343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13343] Towards Soft Fairness in Restless Multi-Armed Bandits](http://arxiv.org/abs/2207.13343)</code></li>
<li>Summary: <p>Restless multi-armed bandits (RMAB) is a framework for allocating limited
resources under uncertainty. It is an extremely useful model for monitoring
beneficiaries and executing timely interventions to ensure maximum benefit in
public health settings (e.g., ensuring patients take medicines in tuberculosis
settings, ensuring pregnant mothers listen to automated calls about good
pregnancy practices). Due to the limited resources, typically certain
communities or regions are starved of interventions that can have follow-on
effects. To avoid starvation in the executed interventions across
individuals/regions/communities, we first provide a soft fairness constraint
and then provide an approach to enforce the soft fairness constraint in RMABs.
The soft fairness constraint requires that an algorithm never probabilistically
favor one arm over another if the long-term cumulative reward of choosing the
latter arm is higher. Our approach incorporates softmax based value iteration
method in the RMAB setting to design selection algorithms that manage to
satisfy the proposed fairness constraint. Our method, referred to as SoftFair,
also provides theoretical performance guarantees and is asymptotically optimal.
Finally, we demonstrate the utility of our approaches on simulated benchmarks
and show that the soft fairness constraint can be handled without a significant
sacrifice on value.
</p></li>
</ul>

<h3>Title: Fairness and Randomness in Machine Learning: Statistical Independence and Relativization. (arXiv:2207.13596v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13596">http://arxiv.org/abs/2207.13596</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13596] Fairness and Randomness in Machine Learning: Statistical Independence and Relativization](http://arxiv.org/abs/2207.13596)</code></li>
<li>Summary: <p>Fair Machine Learning endeavors to prevent unfairness arising in the context
of machine learning applications embedded in society. Despite the variety of
definitions of fairness and proposed "fair algorithms", there remain unresolved
conceptual problems regarding fairness. In this paper, we argue that randomness
and fairness can be considered equivalent concepts in machine learning. We
obtain a relativized notion of randomness expressed as statistical independence
by appealing to Von Mises' century-old foundations for probability. Via
fairness notions in machine learning, which are expressed as statistical
independence as well, we then link the ante randomness assumptions about the
data to the ex post requirements for fair predictions. This connection proves
fruitful: we use it to argue that randomness and fairness are essentially
relative and that randomness should reflect its nature as a modeling assumption
in machine learning.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Semi-analytical Industrial Cooling System Model for Reinforcement Learning. (arXiv:2207.13131v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2207.13131">http://arxiv.org/abs/2207.13131</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2207.13131] Semi-analytical Industrial Cooling System Model for Reinforcement Learning](http://arxiv.org/abs/2207.13131)</code></li>
<li>Summary: <p>We present a hybrid industrial cooling system model that embeds analytical
solutions within a multi-physics simulation. This model is designed for
reinforcement learning (RL) applications and balances simplicity with
simulation fidelity and interpretability. The model's fidelity is evaluated
against real world data from a large scale cooling system. This is followed by
a case study illustrating how the model can be used for RL research. For this,
we develop an industrial task suite that allows specifying different problem
settings and levels of complexity, and use it to evaluate the performance of
different RL algorithms.
</p></li>
</ul>

<h2>exlainability</h2>
<h2>watermark</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
