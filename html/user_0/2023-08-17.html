<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: A Floating-Point Secure Implementation of the Report Noisy Max with Gap Mechanism. (arXiv:2308.08057v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08057">http://arxiv.org/abs/2308.08057</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08057]] A Floating-Point Secure Implementation of the Report Noisy Max with Gap Mechanism(http://arxiv.org/abs/2308.08057)</code></li>
<li>Summary: <p>The Noisy Max mechanism and its variations are fundamental private selection
algorithms that are used to select items from a set of candidates (such as the
most common diseases in a population), while controlling the privacy leakage in
the underlying data. A recently proposed extension, Noisy Top-k with Gap,
provides numerical information about how much better the selected items are
compared to the non-selected items (e.g., how much more common are the selected
diseases). This extra information comes at no privacy cost but crucially relies
on infinite precision for the privacy guarantees. In this paper, we provide a
finite-precision secure implementation of this algorithm that takes advantage
of integer arithmetic.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising Diffusion Model. (arXiv:2308.08367v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08367">http://arxiv.org/abs/2308.08367</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08367]] Diff-CAPTCHA: An Image-based CAPTCHA with Security Enhanced by Denoising Diffusion Model(http://arxiv.org/abs/2308.08367)</code></li>
<li>Summary: <p>To enhance the security of text CAPTCHAs, various methods have been employed,
such as adding the interference lines on the text, randomly distorting the
characters, and overlapping multiple characters. These methods partly increase
the difficulty of automated segmentation and recognition attacks. However,
facing the rapid development of the end-to-end breaking algorithms, their
security has been greatly weakened. The diffusion model is a novel image
generation model that can generate the text images with deep fusion of
characters and background images. In this paper, an image-click CAPTCHA scheme
called Diff-CAPTCHA is proposed based on denoising diffusion models. The
background image and characters of the CAPTCHA are treated as a whole to guide
the generation process of a diffusion model, thus weakening the character
features available for machine learning, enhancing the diversity of character
features in the CAPTCHA, and increasing the difficulty of breaking algorithms.
To evaluate the security of Diff-CAPTCHA, this paper develops several attack
methods, including end-to-end attacks based on Faster R-CNN and two-stage
attacks, and Diff-CAPTCHA is compared with three baseline schemes, including
commercial CAPTCHA scheme and security-enhanced CAPTCHA scheme based on style
transfer. The experimental results show that diffusion models can effectively
enhance CAPTCHA security while maintaining good usability in human testing.
</p></li>
</ul>

<h3>Title: Introducing a New Evaluation Criteria for EMD-Base Steganography Method. (arXiv:2308.07970v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07970">http://arxiv.org/abs/2308.07970</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07970]] Introducing a New Evaluation Criteria for EMD-Base Steganography Method(http://arxiv.org/abs/2308.07970)</code></li>
<li>Summary: <p>Steganography is a technique to hide the presence of secret communication.
When one of the communication elements is under the influence of the enemy, it
can be used. The main measure to evaluate steganography methods in a certain
capacity is security. Therefore, in a certain capacity, reducing the amount of
changes in the cover media, creates a higher embedding efficiency and thus more
security of an steganography method. Mostly, security and capacity are in
conflict with each other, the increase of one lead to the decrease of the
other. The presence of a single criterion that represents security and capacity
at the same time be useful in comparing steganography methods. EMD and the
relevant methods are a group of steganography techniques, which optimize the
amount of changes resulting from embedding (security). The present paper is
aimed to provide an evaluation criterion for this group of steganography
methods. In this study, after a general review and comparison of EMD-based
steganography techniques, we present a method to compare them exactly, from the
perspective of embedding efficiency. First, a formula is presented to determine
the value of embedding efficiency, which indicates the effect of one or more
changes on one or more pixels. The results demonstrate that the proposed
embedding efficiency formula shows the performance of the methods better when
several changes are made on a pixel compared to the existing criteria. In the
second step, we have obtained an upper bound, which determines the best
efficiency for each certain capacity. Finally, based on the introduced bound,
another evaluation criterion for a better comparison of the methods is
presented.
</p></li>
</ul>

<h3>Title: Challenges with Passwordless FIDO2 in an Enterprise Setting: A Usability Study. (arXiv:2308.08096v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08096">http://arxiv.org/abs/2308.08096</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08096]] Challenges with Passwordless FIDO2 in an Enterprise Setting: A Usability Study(http://arxiv.org/abs/2308.08096)</code></li>
<li>Summary: <p>Fast Identity Online 2 (FIDO2), a modern authentication protocol, is gaining
popularity as a default strong authentication mechanism. It has been recognized
as a leading candidate to overcome limitations (e.g., phishing resistance) of
existing authentication solutions. However, the task of deprecating weak
methods such as password-based authentication is not trivial and requires a
comprehensive approach. While security, privacy, and end-user usability of
FIDO2 have been addressed in both academic and industry literature, the
difficulties associated with its integration with production environments, such
as solution completeness or edge-case support, have received little attention.
In particular, complex environments such as enterprise identity management pose
unique challenges for any authentication system. In this paper, we identify
challenging enterprise identity lifecycle use cases (e.g., remote workforce and
legacy systems) by conducting a usability study, in which over 100
cybersecurity professionals shared their perception of challenges to FIDO2
integration from their hands-on field experience. Our analysis of the user
study results revealed serious gaps such as account recovery (selected by over
60% of our respondents), and identify priority development areas for the FIDO2
community.
</p></li>
</ul>

<h3>Title: Evaluating IP Blacklists Effectiveness. (arXiv:2308.08356v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08356">http://arxiv.org/abs/2308.08356</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08356]] Evaluating IP Blacklists Effectiveness(http://arxiv.org/abs/2308.08356)</code></li>
<li>Summary: <p>IP blacklists are widely used to increase network security by preventing
communications with peers that have been marked as malicious. There are several
commercial offerings as well as several free-of-charge blacklists maintained by
volunteers on the web. Despite their wide adoption, the effectiveness of the
different IP blacklists in real-world scenarios is still not clear. In this
paper, we conduct a large-scale network monitoring study which provides
insightful findings regarding the effectiveness of blacklists. The results
collected over several hundred thousand IP hosts belonging to three distinct
large production networks highlight that blacklists are often tuned for
precision, with the result that many malicious activities, such as scanning,
are completely undetected. The proposed instrumentation approach to detect IP
scanning and suspicious activities is implemented with home-grown and
open-source software. Our tools enable the creation of blacklists without the
security risks posed by the deployment of honeypots.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Privacy at Risk: Exploiting Similarities in Health Data for Identity Inference. (arXiv:2308.08310v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08310">http://arxiv.org/abs/2308.08310</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08310]] Privacy at Risk: Exploiting Similarities in Health Data for Identity Inference(http://arxiv.org/abs/2308.08310)</code></li>
<li>Summary: <p>Smartwatches enable the efficient collection of health data that can be used
for research and comprehensive analysis to improve the health of individuals.
In addition to the analysis capabilities, ensuring privacy when handling health
data is a critical concern as the collection and analysis of such data become
pervasive. Since health data contains sensitive information, it should be
handled with responsibility and is therefore often treated anonymously.
However, also the data itself can be exploited to reveal information and break
anonymity. We propose a novel similarity-based re-identification attack on
time-series health data and thereby unveil a significant vulnerability. Despite
privacy measures that remove identifying information, our attack demonstrates
that a brief amount of various sensor data from a target individual is adequate
to possibly identify them within a database of other samples, solely based on
sensor-level similarities. In our example scenario, where data owners leverage
health data from smartwatches, findings show that we are able to correctly link
the target data in two out of three cases. User privacy is thus already
inherently threatened by the data itself and even when removing personal
information.
</p></li>
</ul>

<h3>Title: Optimizing Noise for $f$-Differential Privacy via Anti-Concentration and Stochastic Dominance. (arXiv:2308.08343v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08343">http://arxiv.org/abs/2308.08343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08343]] Optimizing Noise for $f$-Differential Privacy via Anti-Concentration and Stochastic Dominance(http://arxiv.org/abs/2308.08343)</code></li>
<li>Summary: <p>In this paper, we establish anti-concentration inequalities for additive
noise mechanisms which achieve $f$-differential privacy ($f$-DP), a notion of
privacy phrased in terms of a tradeoff function (a.k.a. ROC curve) $f$ which
limits the ability of an adversary to determine which individuals were in the
database. We show that canonical noise distributions (CNDs), proposed by Awan
and Vadhan (2023), match the anti-concentration bounds at half-integer values,
indicating that their tail behavior is near-optimal. We also show that all CNDs
are sub-exponential, regardless of the $f$-DP guarantee. In the case of
log-concave CNDs, we show that they are the stochastically smallest noise
compared to any other noise distributions with the same privacy guarantee. In
terms of integer-valued noise, we propose a new notion of discrete CND and
prove that a discrete CND always exists, can be constructed by rounding a
continuous CND, and that the discrete CND is unique when designed for a
statistic with sensitivity 1. We further show that the discrete CND at
sensitivity 1 is stochastically smallest compared to other integer-valued
noises. Our theoretical results shed light on the different types of privacy
guarantees possible in the $f$-DP framework and can be incorporated in more
complex mechanisms to optimize performance.
</p></li>
</ul>

<h3>Title: Independent Distribution Regularization for Private Graph Embedding. (arXiv:2308.08360v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08360">http://arxiv.org/abs/2308.08360</a></li>
<li>Code URL: https://github.com/hkust-knowcomp/privategraphencoder</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08360]] Independent Distribution Regularization for Private Graph Embedding(http://arxiv.org/abs/2308.08360)</code></li>
<li>Summary: <p>Learning graph embeddings is a crucial task in graph mining tasks. An
effective graph embedding model can learn low-dimensional representations from
graph-structured data for data publishing benefiting various downstream
applications such as node classification, link prediction, etc. However, recent
studies have revealed that graph embeddings are susceptible to attribute
inference attacks, which allow attackers to infer private node attributes from
the learned graph embeddings. To address these concerns, privacy-preserving
graph embedding methods have emerged, aiming to simultaneously consider primary
learning and privacy protection through adversarial learning. However, most
existing methods assume that representation models have access to all sensitive
attributes in advance during the training stage, which is not always the case
due to diverse privacy preferences. Furthermore, the commonly used adversarial
learning technique in privacy-preserving representation learning suffers from
unstable training issues. In this paper, we propose a novel approach called
Private Variational Graph AutoEncoders (PVGAE) with the aid of independent
distribution penalty as a regularization term. Specifically, we split the
original variational graph autoencoder (VGAE) to learn sensitive and
non-sensitive latent representations using two sets of encoders. Additionally,
we introduce a novel regularization to enforce the independence of the
encoders. We prove the theoretical effectiveness of regularization from the
perspective of mutual information. Experimental results on three real-world
datasets demonstrate that PVGAE outperforms other baselines in private
embedding learning regarding utility performance and privacy protection.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Exploring Winograd Convolution for Cost-effective Neural Network Fault Tolerance. (arXiv:2308.08230v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08230">http://arxiv.org/abs/2308.08230</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08230]] Exploring Winograd Convolution for Cost-effective Neural Network Fault Tolerance(http://arxiv.org/abs/2308.08230)</code></li>
<li>Summary: <p>Winograd is generally utilized to optimize convolution performance and
computational efficiency because of the reduced multiplication operations, but
the reliability issues brought by winograd are usually overlooked. In this
work, we observe the great potential of winograd convolution in improving
neural network (NN) fault tolerance. Based on the observation, we evaluate
winograd convolution fault tolerance comprehensively from different
granularities ranging from models, layers, and operation types for the first
time. Then, we explore the use of inherent fault tolerance of winograd
convolution for cost-effective NN protection against soft errors. Specifically,
we mainly investigate how winograd convolution can be effectively incorporated
with classical fault-tolerant design approaches including triple modular
redundancy (TMR), fault-aware retraining, and constrained activation functions.
According to our experiments, winograd convolution can reduce the
fault-tolerant design overhead by 55.77\% on average without any accuracy loss
compared to standard convolution, and further reduce the computing overhead by
17.24\% when the inherent fault tolerance of winograd convolution is
considered. When it is applied on fault-tolerant neural networks enhanced with
fault-aware retraining and constrained activation functions, the resulting
model accuracy generally shows significant improvement in presence of various
faults.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training. (arXiv:2308.07934v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07934">http://arxiv.org/abs/2308.07934</a></li>
<li>Code URL: https://github.com/jianshuod/tba</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07934]] One-bit Flip is All You Need: When Bit-flip Attack Meets Model Training(http://arxiv.org/abs/2308.07934)</code></li>
<li>Summary: <p>Deep neural networks (DNNs) are widely deployed on real-world devices.
Concerns regarding their security have gained great attention from researchers.
Recently, a new weight modification attack called bit flip attack (BFA) was
proposed, which exploits memory fault inject techniques such as row hammer to
attack quantized models in the deployment stage. With only a few bit flips, the
target model can be rendered useless as a random guesser or even be implanted
with malicious functionalities. In this work, we seek to further reduce the
number of bit flips. We propose a training-assisted bit flip attack, in which
the adversary is involved in the training stage to build a high-risk model to
release. This high-risk model, obtained coupled with a corresponding malicious
model, behaves normally and can escape various detection methods. The results
on benchmark datasets show that an adversary can easily convert this high-risk
but normal model to a malicious one on victim's side by \textbf{flipping only
one critical bit} on average in the deployment stage. Moreover, our attack
still poses a significant threat even when defenses are employed. The codes for
reproducing main experiments are available at
\url{https://github.com/jianshuod/TBA}.
</p></li>
</ul>

<h3>Title: Test-Time Poisoning Attacks Against Test-Time Adaptation Models. (arXiv:2308.08505v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08505">http://arxiv.org/abs/2308.08505</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08505]] Test-Time Poisoning Attacks Against Test-Time Adaptation Models(http://arxiv.org/abs/2308.08505)</code></li>
<li>Summary: <p>Deploying machine learning (ML) models in the wild is challenging as it
suffers from distribution shifts, where the model trained on an original domain
cannot generalize well to unforeseen diverse transfer domains. To address this
challenge, several test-time adaptation (TTA) methods have been proposed to
improve the generalization ability of the target pre-trained models under test
data to cope with the shifted distribution. The success of TTA can be credited
to the continuous fine-tuning of the target model according to the
distributional hint from the test samples during test time. Despite being
powerful, it also opens a new attack surface, i.e., test-time poisoning
attacks, which are substantially different from previous poisoning attacks that
occur during the training time of ML models (i.e., adversaries cannot intervene
in the training process). In this paper, we perform the first test-time
poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT,
and RPL. Concretely, we generate poisoned samples based on the surrogate models
and feed them to the target TTA models. Experimental results show that the TTA
methods are generally vulnerable to test-time poisoning attacks. For instance,
the adversary can feed as few as 10 poisoned samples to degrade the performance
of the target model from 76.20% to 41.83%. Our results demonstrate that TTA
algorithms lacking a rigorous security assessment are unsuitable for deployment
in real-life scenarios. As such, we advocate for the integration of defenses
against test-time poisoning attacks into the design of TTA methods.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling. (arXiv:2308.08012v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08012">http://arxiv.org/abs/2308.08012</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08012]] Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling(http://arxiv.org/abs/2308.08012)</code></li>
<li>Summary: <p>Connectivity robustness, a crucial aspect for understanding, optimizing, and
repairing complex networks, has traditionally been evaluated through
time-consuming and often impractical simulations. Fortunately, machine learning
provides a new avenue for addressing this challenge. However, several key
issues remain unresolved, including the performance in more general edge
removal scenarios, capturing robustness through attack curves instead of
directly training for robustness, scalability of predictive tasks, and
transferability of predictive capabilities. In this paper, we address these
challenges by designing a convolutional neural networks (CNN) model with
spatial pyramid pooling networks (SPP-net), adapting existing evaluation
metrics, redesigning the attack modes, introducing appropriate filtering rules,
and incorporating the value of robustness as training data. The results
demonstrate the thoroughness of the proposed CNN framework in addressing the
challenges of high computational time across various network types, failure
component types and failure scenarios. However, the performance of the proposed
CNN model varies: for evaluation tasks that are consistent with the trained
network type, the proposed CNN model consistently achieves accurate evaluations
of both attack curves and robustness values across all removal scenarios. When
the predicted network type differs from the trained network, the CNN model
still demonstrates favorable performance in the scenario of random node
failure, showcasing its scalability and performance transferability.
Nevertheless, the performance falls short of expectations in other removal
scenarios. This observed scenario-sensitivity in the evaluation of network
features has been overlooked in previous studies and necessitates further
attention and optimization. Lastly, we discuss important unresolved questions
and further investigation.
</p></li>
</ul>

<h3>Title: View Consistent Purification for Accurate Cross-View Localization. (arXiv:2308.08110v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08110">http://arxiv.org/abs/2308.08110</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08110]] View Consistent Purification for Accurate Cross-View Localization(http://arxiv.org/abs/2308.08110)</code></li>
<li>Summary: <p>This paper proposes a fine-grained self-localization method for outdoor
robotics that utilizes a flexible number of onboard cameras and readily
accessible satellite images. The proposed method addresses limitations in
existing cross-view localization methods that struggle to handle noise sources
such as moving objects and seasonal variations. It is the first sparse
visual-only method that enhances perception in dynamic environments by
detecting view-consistent key points and their corresponding deep features from
ground and satellite views, while removing off-the-ground objects and
establishing homography transformation between the two views. Moreover, the
proposed method incorporates a spatial embedding approach that leverages camera
intrinsic and extrinsic information to reduce the ambiguity of purely visual
matching, leading to improved feature matching and overall pose estimation
accuracy. The method exhibits strong generalization and is robust to
environmental changes, requiring only geo-poses as ground truth. Extensive
experiments on the KITTI and Ford Multi-AV Seasonal datasets demonstrate that
our proposed method outperforms existing state-of-the-art methods, achieving
median spatial accuracy errors below $0.5$ meters along the lateral and
longitudinal directions, and a median orientation accuracy error below 2
degrees.
</p></li>
</ul>

<h3>Title: Unsupervised Domain Adaptive Detection with Network Stability Analysis. (arXiv:2308.08182v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08182">http://arxiv.org/abs/2308.08182</a></li>
<li>Code URL: https://github.com/tiankongzhang/nsa</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08182]] Unsupervised Domain Adaptive Detection with Network Stability Analysis(http://arxiv.org/abs/2308.08182)</code></li>
<li>Summary: <p>Domain adaptive detection aims to improve the generality of a detector,
learned from the labeled source domain, on the unlabeled target domain. In this
work, drawing inspiration from the concept of stability from the control theory
that a robust system requires to remain consistent both externally and
internally regardless of disturbances, we propose a novel framework that
achieves unsupervised domain adaptive detection through stability analysis. In
specific, we treat discrepancies between images and regions from different
domains as disturbances, and introduce a novel simple but effective Network
Stability Analysis (NSA) framework that considers various disturbances for
domain adaptation. Particularly, we explore three types of perturbations
including heavy and light image-level disturbances and instancelevel
disturbance. For each type, NSA performs external consistency analysis on the
outputs from raw and perturbed images and/or internal consistency analysis on
their features, using teacher-student models. By integrating NSA into Faster
R-CNN, we immediately achieve state-of-the-art results. In particular, we set a
new record of 52.7% mAP on Cityscapes-to-FoggyCityscapes, showing the potential
of NSA for domain adaptive detection. It is worth noticing, our NSA is designed
for general purpose, and thus applicable to one-stage detection model (e.g.,
FCOS) besides the adopted one, as shown by experiments.
https://github.com/tiankongzhang/NSA.
</p></li>
</ul>

<h3>Title: Automatic Vision-Based Parking Slot Detection and Occupancy Classification. (arXiv:2308.08192v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08192">http://arxiv.org/abs/2308.08192</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08192]] Automatic Vision-Based Parking Slot Detection and Occupancy Classification(http://arxiv.org/abs/2308.08192)</code></li>
<li>Summary: <p>Parking guidance information (PGI) systems are used to provide information to
drivers about the nearest parking lots and the number of vacant parking slots.
Recently, vision-based solutions started to appear as a cost-effective
alternative to standard PGI systems based on hardware sensors mounted on each
parking slot. Vision-based systems provide information about parking occupancy
based on images taken by a camera that is recording a parking lot. However,
such systems are challenging to develop due to various possible viewpoints,
weather conditions, and object occlusions. Most notably, they require manual
labeling of parking slot locations in the input image which is sensitive to
camera angle change, replacement, or maintenance. In this paper, the algorithm
that performs Automatic Parking Slot Detection and Occupancy Classification
(APSD-OC) solely on input images is proposed. Automatic parking slot detection
is based on vehicle detections in a series of parking lot images upon which
clustering is applied in bird's eye view to detect parking slots. Once the
parking slots positions are determined in the input image, each detected
parking slot is classified as occupied or vacant using a specifically trained
ResNet34 deep classifier. The proposed approach is extensively evaluated on
well-known publicly available datasets (PKLot and CNRPark+EXT), showing high
efficiency in parking slot detection and robustness to the presence of illegal
parking or passing vehicles. Trained classifier achieves high accuracy in
parking slot occupancy classification.
</p></li>
</ul>

<h3>Title: How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning. (arXiv:2308.08224v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08224">http://arxiv.org/abs/2308.08224</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08224]] How To Overcome Confirmation Bias in Semi-Supervised Image Classification By Active Learning(http://arxiv.org/abs/2308.08224)</code></li>
<li>Summary: <p>Do we need active learning? The rise of strong deep semi-supervised methods
raises doubt about the usability of active learning in limited labeled data
settings. This is caused by results showing that combining semi-supervised
learning (SSL) methods with a random selection for labeling can outperform
existing active learning (AL) techniques. However, these results are obtained
from experiments on well-established benchmark datasets that can overestimate
the external validity. However, the literature lacks sufficient research on the
performance of active semi-supervised learning methods in realistic data
scenarios, leaving a notable gap in our understanding. Therefore we present
three data challenges common in real-world applications: between-class
imbalance, within-class imbalance, and between-class similarity. These
challenges can hurt SSL performance due to confirmation bias. We conduct
experiments with SSL and AL on simulated data challenges and find that random
sampling does not mitigate confirmation bias and, in some cases, leads to worse
performance than supervised learning. In contrast, we demonstrate that AL can
overcome confirmation bias in SSL in these realistic settings. Our results
provide insights into the potential of combining active and semi-supervised
learning in the presence of common real-world challenges, which is a promising
direction for robust methods when learning with limited labeled data in
real-world applications.
</p></li>
</ul>

<h3>Title: Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations. (arXiv:2308.08321v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08321">http://arxiv.org/abs/2308.08321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08321]] Stable and Causal Inference for Discriminative Self-supervised Deep Visual Representations(http://arxiv.org/abs/2308.08321)</code></li>
<li>Summary: <p>In recent years, discriminative self-supervised methods have made significant
strides in advancing various visual tasks. The central idea of learning a data
encoder that is robust to data distortions/augmentations is straightforward yet
highly effective. Although many studies have demonstrated the empirical success
of various learning methods, the resulting learned representations can exhibit
instability and hinder downstream performance. In this study, we analyze
discriminative self-supervised methods from a causal perspective to explain
these unstable behaviors and propose solutions to overcome them. Our approach
draws inspiration from prior works that empirically demonstrate the ability of
discriminative self-supervised methods to demix ground truth causal sources to
some extent. Unlike previous work on causality-empowered representation
learning, we do not apply our solutions during the training process but rather
during the inference process to improve time efficiency. Through experiments on
both controlled image datasets and realistic image datasets, we show that our
proposed solutions, which involve tempering a linear transformation with
controlled synthetic data, are effective in addressing these issues.
</p></li>
</ul>

<h3>Title: Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval. (arXiv:2308.08431v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08431">http://arxiv.org/abs/2308.08431</a></li>
<li>Code URL: https://github.com/vaishwarya96/hierarchy-image-retrieval</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08431]] Integrating Visual and Semantic Similarity Using Hierarchies for Image Retrieval(http://arxiv.org/abs/2308.08431)</code></li>
<li>Summary: <p>Most of the research in content-based image retrieval (CBIR) focus on
developing robust feature representations that can effectively retrieve
instances from a database of images that are visually similar to a query.
However, the retrieved images sometimes contain results that are not
semantically related to the query. To address this, we propose a method for
CBIR that captures both visual and semantic similarity using a visual
hierarchy. The hierarchy is constructed by merging classes with overlapping
features in the latent space of a deep neural network trained for
classification, assuming that overlapping classes share high visual and
semantic similarities. Finally, the constructed hierarchy is integrated into
the distance calculation metric for similarity search. Experiments on standard
datasets: CUB-200-2011 and CIFAR100, and a real-life use case using diatom
microscopy images show that our method achieves superior performance compared
to the existing methods on image retrieval.
</p></li>
</ul>

<h3>Title: Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction. (arXiv:2308.08518v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08518">http://arxiv.org/abs/2308.08518</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08518]] Exploiting Point-Wise Attention in 6D Object Pose Estimation Based on Bidirectional Prediction(http://arxiv.org/abs/2308.08518)</code></li>
<li>Summary: <p>Traditional geometric registration based estimation methods only exploit the
CAD model implicitly, which leads to their dependence on observation quality
and deficiency to occlusion.To address the problem,the paper proposes a
bidirectional correspondence prediction network with a point-wise
attention-aware mechanism. This network not only requires the model points to
predict the correspondence but also explicitly models the geometric
similarities between observations and the model prior.} Our key insight is that
the correlations between each model point and scene point provide essential
information for learning point-pair matches. To further tackle the correlation
noises brought by feature distribution divergence, we design a simple but
effective pseudo-siamese network to improve feature homogeneity.Experimental
results on the public datasets of LineMOD, YCB-Video, and Occ-LineMOD show that
the proposed method achieves better performance than other state-of-the-art
methods under the same evaluation criteria. Its robustness in estimating poses
is greatly improved, especially in an environment with severe occlusions.
</p></li>
</ul>

<h3>Title: MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models. (arXiv:2308.08204v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08204">http://arxiv.org/abs/2308.08204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08204]] MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models(http://arxiv.org/abs/2308.08204)</code></li>
<li>Summary: <p>Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts
within knowledge graphs and automatically infer missing links. Existing methods
can mainly be categorized into structure-based or description-based. On the one
hand, structure-based methods effectively represent relational facts in
knowledge graphs using entity embeddings. However, they struggle with
semantically rich real-world entities due to limited structural information and
fail to generalize to unseen entities. On the other hand, description-based
methods leverage pre-trained language models (PLMs) to understand textual
information. They exhibit strong robustness towards unseen entities. However,
they have difficulty with larger negative sampling and often lag behind
structure-based methods. To address these issues, in this paper, we propose
Momentum Contrast for knowledge graph completion with Structure-Augmented
pre-trained language models (MoCoSA), which allows the PLM to perceive the
structural information by the adaptable structure encoder. To improve learning
efficiency, we proposed momentum hard negative and intra-relation negative
sampling. Experimental results demonstrate that our approach achieves
state-of-the-art performance in terms of mean reciprocal rank (MRR), with
improvements of 2.5% on WN18RR and 21% on OpenBG500.
</p></li>
</ul>

<h3>Title: S-Mixup: Structural Mixup for Graph Neural Networks. (arXiv:2308.08097v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08097">http://arxiv.org/abs/2308.08097</a></li>
<li>Code URL: https://github.com/sukwonyun/s-mixup</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08097]] S-Mixup: Structural Mixup for Graph Neural Networks(http://arxiv.org/abs/2308.08097)</code></li>
<li>Summary: <p>Existing studies for applying the mixup technique on graphs mainly focus on
graph classification tasks, while the research in node classification is still
under-explored. In this paper, we propose a novel mixup augmentation for node
classification called Structural Mixup (S-Mixup). The core idea is to take into
account the structural information while mixing nodes. Specifically, S-Mixup
obtains pseudo-labels for unlabeled nodes in a graph along with their
prediction confidence via a Graph Neural Network (GNN) classifier. These serve
as the criteria for the composition of the mixup pool for both inter and
intra-class mixups. Furthermore, we utilize the edge gradient obtained from the
GNN training and propose a gradient-based edge selection strategy for selecting
edges to be attached to the nodes generated by the mixup. Through extensive
experiments on real-world benchmark datasets, we demonstrate the effectiveness
of S-Mixup evaluated on the node classification task. We observe that S-Mixup
enhances the robustness and generalization performance of GNNs, especially in
heterophilous situations. The source code of S-Mixup can be found at
\url{https://github.com/SukwonYun/S-Mixup}
</p></li>
</ul>

<h3>Title: Benchmarking Adversarial Robustness of Compressed Deep Learning Models. (arXiv:2308.08160v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08160">http://arxiv.org/abs/2308.08160</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08160]] Benchmarking Adversarial Robustness of Compressed Deep Learning Models(http://arxiv.org/abs/2308.08160)</code></li>
<li>Summary: <p>The increasing size of Deep Neural Networks (DNNs) poses a pressing need for
model compression, particularly when employed on resource constrained devices.
Concurrently, the susceptibility of DNNs to adversarial attacks presents
another significant hurdle. Despite substantial research on both model
compression and adversarial robustness, their joint examination remains
underexplored. Our study bridges this gap, seeking to understand the effect of
adversarial inputs crafted for base models on their pruned versions. To examine
this relationship, we have developed a comprehensive benchmark across diverse
adversarial attacks and popular DNN models. We uniquely focus on models not
previously exposed to adversarial training and apply pruning schemes optimized
for accuracy and performance. Our findings reveal that while the benefits of
pruning enhanced generalizability, compression, and faster inference times are
preserved, adversarial robustness remains comparable to the base model. This
suggests that model compression while offering its unique advantages, does not
undermine adversarial robustness.
</p></li>
</ul>

<h3>Title: Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness. (arXiv:2308.08173v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08173">http://arxiv.org/abs/2308.08173</a></li>
<li>Code URL: https://github.com/francesco-campi/rob-subgraphs</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08173]] Expressivity of Graph Neural Networks Through the Lens of Adversarial Robustness(http://arxiv.org/abs/2308.08173)</code></li>
<li>Summary: <p>We perform the first adversarial robustness study into Graph Neural Networks
(GNNs) that are provably more powerful than traditional Message Passing Neural
Networks (MPNNs). In particular, we use adversarial robustness as a tool to
uncover a significant gap between their theoretically possible and empirically
achieved expressive power. To do so, we focus on the ability of GNNs to count
specific subgraph patterns, which is an established measure of expressivity,
and extend the concept of adversarial robustness to this task. Based on this,
we develop efficient adversarial attacks for subgraph counting and show that
more powerful GNNs fail to generalize even to small perturbations to the
graph's structure. Expanding on this, we show that such architectures also fail
to count substructures on out-of-distribution graphs.
</p></li>
</ul>

<h3>Title: Robust Bayesian Satisficing. (arXiv:2308.08291v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08291">http://arxiv.org/abs/2308.08291</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08291]] Robust Bayesian Satisficing(http://arxiv.org/abs/2308.08291)</code></li>
<li>Summary: <p>Distributional shifts pose a significant challenge to achieving robustness in
contemporary machine learning. To overcome this challenge, robust satisficing
(RS) seeks a robust solution to an unspecified distributional shift while
achieving a utility above a desired threshold. This paper focuses on the
problem of RS in contextual Bayesian optimization when there is a discrepancy
between the true and reference distributions of the context. We propose a novel
robust Bayesian satisficing algorithm called RoBOS for noisy black-box
optimization. Our algorithm guarantees sublinear lenient regret under certain
assumptions on the amount of distribution shift. In addition, we define a
weaker notion of regret called robust satisficing regret, in which our
algorithm achieves a sublinear upper bound independent of the amount of
distribution shift. To demonstrate the effectiveness of our method, we apply it
to various learning problems and compare it to other approaches, such as
distributionally robust optimization.
</p></li>
</ul>

<h3>Title: A distributed neural network architecture for dynamic sensor selection with application to bandwidth-constrained body-sensor networks. (arXiv:2308.08379v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08379">http://arxiv.org/abs/2308.08379</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08379]] A distributed neural network architecture for dynamic sensor selection with application to bandwidth-constrained body-sensor networks(http://arxiv.org/abs/2308.08379)</code></li>
<li>Summary: <p>We propose a dynamic sensor selection approach for deep neural networks
(DNNs), which is able to derive an optimal sensor subset selection for each
specific input sample instead of a fixed selection for the entire dataset. This
dynamic selection is jointly learned with the task model in an end-to-end way,
using the Gumbel-Softmax trick to allow the discrete decisions to be learned
through standard backpropagation. We then show how we can use this dynamic
selection to increase the lifetime of a wireless sensor network (WSN) by
imposing constraints on how often each node is allowed to transmit. We further
improve performance by including a dynamic spatial filter that makes the
task-DNN more robust against the fact that it now needs to be able to handle a
multitude of possible node subsets. Finally, we explain how the selection of
the optimal channels can be distributed across the different nodes in a WSN. We
validate this method on a use case in the context of body-sensor networks,
where we use real electroencephalography (EEG) sensor data to emulate an EEG
sensor network. We analyze the resulting trade-offs between transmission load
and task accuracy.
</p></li>
</ul>

<h3>Title: Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities. (arXiv:2308.08407v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08407">http://arxiv.org/abs/2308.08407</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08407]] Explainable AI for clinical risk prediction: a survey of concepts, methods, and modalities(http://arxiv.org/abs/2308.08407)</code></li>
<li>Summary: <p>Recent advancements in AI applications to healthcare have shown incredible
promise in surpassing human performance in diagnosis and disease prognosis.
With the increasing complexity of AI models, however, concerns regarding their
opacity, potential biases, and the need for interpretability. To ensure trust
and reliability in AI systems, especially in clinical risk prediction models,
explainability becomes crucial. Explainability is usually referred to as an AI
system's ability to provide a robust interpretation of its decision-making
logic or the decisions themselves to human stakeholders. In clinical risk
prediction, other aspects of explainability like fairness, bias, trust, and
transparency also represent important concepts beyond just interpretability. In
this review, we address the relationship between these concepts as they are
often used together or interchangeably. This review also discusses recent
progress in developing explainable models for clinical risk prediction,
highlighting the importance of quantitative and clinical evaluation and
validation across multiple common modalities in clinical practice. It
emphasizes the need for external validation and the combination of diverse
interpretability methods to enhance trust and fairness. Adopting rigorous
testing, such as using synthetic datasets with known generative factors, can
further improve the reliability of explainability methods. Open access and
code-sharing resources are essential for transparency and reproducibility,
enabling the growth and trustworthiness of explainable research. While
challenges exist, an end-to-end approach to explainability in clinical risk
prediction, incorporating stakeholders from clinicians to developers, is
essential for success.
</p></li>
</ul>

<h3>Title: LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs. (arXiv:2308.08469v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08469">http://arxiv.org/abs/2308.08469</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08469]] LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs(http://arxiv.org/abs/2308.08469)</code></li>
<li>Summary: <p>In this work, we leverage pre-trained Large Language Models (LLMs) to enhance
time-series forecasting. Mirroring the growing interest in unifying models for
Natural Language Processing and Computer Vision, we envision creating an
analogous model for long-term time-series forecasting. Due to limited
large-scale time-series data for building robust foundation models, our
approach LLM4TS focuses on leveraging the strengths of pre-trained LLMs. By
combining time-series patching with temporal encoding, we have enhanced the
capability of LLMs to handle time-series data effectively. Inspired by the
supervised fine-tuning in chatbot domains, we prioritize a two-stage
fine-tuning process: first conducting supervised fine-tuning to orient the LLM
towards time-series data, followed by task-specific downstream fine-tuning.
Furthermore, to unlock the flexibility of pre-trained LLMs without extensive
parameter adjustments, we adopt several Parameter-Efficient Fine-Tuning (PEFT)
techniques. Drawing on these innovations, LLM4TS has yielded state-of-the-art
results in long-term forecasting. Our model has also shown exceptional
capabilities as both a robust representation learner and an effective few-shot
learner, thanks to the knowledge transferred from the pre-trained LLM.
</p></li>
</ul>

<h2>biometric</h2>
<h3>Title: Boosting Cross-Quality Face Verification using Blind Face Restoration. (arXiv:2308.07967v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07967">http://arxiv.org/abs/2308.07967</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07967]] Boosting Cross-Quality Face Verification using Blind Face Restoration(http://arxiv.org/abs/2308.07967)</code></li>
<li>Summary: <p>In recent years, various Blind Face Restoration (BFR) techniques were
developed. These techniques transform low quality faces suffering from multiple
degradations to more realistic and natural face images with high perceptual
quality. However, it is crucial for the task of face verification to not only
enhance the perceptual quality of the low quality images but also to improve
the biometric-utility face quality metrics. Furthermore, preserving the
valuable identity information is of great importance. In this paper, we
investigate the impact of applying three state-of-the-art blind face
restoration techniques namely, GFP-GAN, GPEN and SGPN on the performance of
face verification system under very challenging environment characterized by
very low quality images. Extensive experimental results on the recently
proposed cross-quality LFW database using three state-of-the-art deep face
recognition models demonstrate the effectiveness of GFP-GAN in boosting
significantly the face verification accuracy.
</p></li>
</ul>

<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark. (arXiv:2308.08443v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08443">http://arxiv.org/abs/2308.08443</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08443]] High-Fidelity Lake Extraction via Two-Stage Prompt Enhancement: Establishing a Novel Baseline and Benchmark(http://arxiv.org/abs/2308.08443)</code></li>
<li>Summary: <p>The extraction of lakes from remote sensing images is a complex challenge due
to the varied lake shapes and data noise. Current methods rely on multispectral
image datasets, making it challenging to learn lake features accurately from
pixel arrangements. This, in turn, affects model learning and the creation of
accurate segmentation masks. This paper introduces a unified prompt-based
dataset construction approach that provides approximate lake locations using
point, box, and mask prompts. We also propose a two-stage prompt enhancement
framework, LEPrompter, which involves prompt-based and prompt-free stages
during training. The prompt-based stage employs a prompt encoder to extract
prior information, integrating prompt tokens and image embeddings through self-
and cross-attention in the prompt decoder. Prompts are deactivated once the
model is trained to ensure independence during inference, enabling automated
lake extraction. Evaluations on Surface Water and Qinghai-Tibet Plateau Lake
datasets show consistent performance improvements compared to the previous
state-of-the-art method. LEPrompter achieves mIoU scores of 91.48% and 97.43%
on the respective datasets without introducing additional parameters or GFLOPs.
Supplementary materials provide the source code, pre-trained models, and
detailed user studies.
</p></li>
</ul>

<h3>Title: Automated Testing and Improvement of Named Entity Recognition Systems. (arXiv:2308.07937v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07937">http://arxiv.org/abs/2308.07937</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07937]] Automated Testing and Improvement of Named Entity Recognition Systems(http://arxiv.org/abs/2308.07937)</code></li>
<li>Summary: <p>Named entity recognition (NER) systems have seen rapid progress in recent
years due to the development of deep neural networks. These systems are widely
used in various natural language processing applications, such as information
extraction, question answering, and sentiment analysis. However, the complexity
and intractability of deep neural networks can make NER systems unreliable in
certain circumstances, resulting in incorrect predictions. For example, NER
systems may misidentify female names as chemicals or fail to recognize the
names of minority groups, leading to user dissatisfaction. To tackle this
problem, we introduce TIN, a novel, widely applicable approach for
automatically testing and repairing various NER systems. The key idea for
automated testing is that the NER predictions of the same named entities under
similar contexts should be identical. The core idea for automated repairing is
that similar named entities should have the same NER prediction under the same
context. We use TIN to test two SOTA NER models and two commercial NER APIs,
i.e., Azure NER and AWS NER. We manually verify 784 of the suspicious issues
reported by TIN and find that 702 are erroneous issues, leading to high
precision (85.0%-93.4%) across four categories of NER errors: omission,
over-labeling, incorrect category, and range error. For automated repairing,
TIN achieves a high error reduction rate (26.8%-50.6%) over the four systems
under test, which successfully repairs 1,056 out of the 1,877 reported NER
errors.
</p></li>
</ul>

<h3>Title: Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation. (arXiv:2308.08090v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08090">http://arxiv.org/abs/2308.08090</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08090]] Separate the Wheat from the Chaff: Model Deficiency Unlearning via Parameter-Efficient Module Operation(http://arxiv.org/abs/2308.08090)</code></li>
<li>Summary: <p>Large language models (LLMs) have been widely used in various applications
but are known to suffer from issues related to untruthfulness and toxicity.
While parameter-efficient modules (PEMs) have demonstrated their effectiveness
in equipping models with new skills, leveraging PEMs for deficiency unlearning
remains underexplored. In this work, we propose a PEMs operation approach,
namely Extraction-before-Subtraction (Ext-Sub), to enhance the truthfulness and
detoxification of LLMs through the integration of ``expert'' PEM and
``anti-expert'' PEM. Remarkably, even anti-expert PEM possess valuable
capabilities due to their proficiency in generating fabricated content, which
necessitates language modeling and logical narrative competence. Rather than
merely negating the parameters, our approach involves extracting and
eliminating solely the deficiency capability within anti-expert PEM while
preserving the general capabilities. To evaluate the effectiveness of our
approach in terms of truthfulness and detoxification, we conduct extensive
experiments on LLMs, encompassing additional abilities such as language
modeling and mathematical reasoning. Our empirical results demonstrate that our
approach effectively improves truthfulness and detoxification, while largely
preserving the fundamental abilities of LLMs.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: DFedADMM: Dual Constraints Controlled Model Inconsistency for Decentralized Federated Learning. (arXiv:2308.08290v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08290">http://arxiv.org/abs/2308.08290</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08290]] DFedADMM: Dual Constraints Controlled Model Inconsistency for Decentralized Federated Learning(http://arxiv.org/abs/2308.08290)</code></li>
<li>Summary: <p>To address the communication burden issues associated with federated learning
(FL), decentralized federated learning (DFL) discards the central server and
establishes a decentralized communication network, where each client
communicates only with neighboring clients. However, existing DFL methods still
suffer from two major challenges: local inconsistency and local heterogeneous
overfitting, which have not been fundamentally addressed by existing DFL
methods. To tackle these issues, we propose novel DFL algorithms, DFedADMM and
its enhanced version DFedADMM-SAM, to enhance the performance of DFL. The
DFedADMM algorithm employs primal-dual optimization (ADMM) by utilizing dual
variables to control the model inconsistency raised from the decentralized
heterogeneous data distributions. The DFedADMM-SAM algorithm further improves
on DFedADMM by employing a Sharpness-Aware Minimization (SAM) optimizer, which
uses gradient perturbations to generate locally flat models and searches for
models with uniformly low loss values to mitigate local heterogeneous
overfitting. Theoretically, we derive convergence rates of $\small
\mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}\Big)$ and $\small
\mathcal{O}\Big(\frac{1}{\sqrt{KT}}+\frac{1}{KT(1-\psi)^2}+
\frac{1}{T^{3/2}K^{1/2}}\Big)$ in the non-convex setting for DFedADMM and
DFedADMM-SAM, respectively, where $1 - \psi$ represents the spectral gap of the
gossip matrix. Empirically, extensive experiments on MNIST, CIFAR10 and
CIFAR100 datesets demonstrate that our algorithms exhibit superior performance
in terms of both generalization and convergence speed compared to existing
state-of-the-art (SOTA) optimizers in DFL.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem. (arXiv:2308.08051v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08051">http://arxiv.org/abs/2308.08051</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08051]] Unbiased Decisions Reduce Regret: Adversarial Domain Adaptation for the Bank Loan Problem(http://arxiv.org/abs/2308.08051)</code></li>
<li>Summary: <p>In many real world settings binary classification decisions are made based on
limited data in near real-time, e.g. when assessing a loan application. We
focus on a class of these problems that share a common feature: the true label
is only observed when a data point is assigned a positive label by the
principal, e.g. we only find out whether an applicant defaults if we accepted
their loan application. As a consequence, the false rejections become
self-reinforcing and cause the labelled training set, that is being
continuously updated by the model decisions, to accumulate bias. Prior work
mitigates this effect by injecting optimism into the model, however this comes
at the cost of increased false acceptance rate. We introduce adversarial
optimism (AdOpt) to directly address bias in the training set using adversarial
domain adaptation. The goal of AdOpt is to learn an unbiased but informative
representation of past data, by reducing the distributional shift between the
set of accepted data points and all data points seen thus far. AdOpt
significantly exceeds state-of-the-art performance on a set of challenging
benchmark problems. Our experiments also provide initial evidence that the
introduction of adversarial domain adaptation improves fairness in this
setting.
</p></li>
</ul>

<h3>Title: Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features. (arXiv:2308.08482v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08482">http://arxiv.org/abs/2308.08482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08482]] Benign Shortcut for Debiasing: Fair Visual Recognition via Intervention with Shortcut Features(http://arxiv.org/abs/2308.08482)</code></li>
<li>Summary: <p>Machine learning models often learn to make predictions that rely on
sensitive social attributes like gender and race, which poses significant
fairness risks, especially in societal applications, such as hiring, banking,
and criminal justice. Existing work tackles this issue by minimizing the
employed information about social attributes in models for debiasing. However,
the high correlation between target task and these social attributes makes
learning on the target task incompatible with debiasing. Given that model bias
arises due to the learning of bias features (\emph{i.e}., gender) that help
target task optimization, we explore the following research question: \emph{Can
we leverage shortcut features to replace the role of bias feature in target
task optimization for debiasing?} To this end, we propose \emph{Shortcut
Debiasing}, to first transfer the target task's learning of bias attributes
from bias features to shortcut features, and then employ causal intervention to
eliminate shortcut features during inference. The key idea of \emph{Shortcut
Debiasing} is to design controllable shortcut features to on one hand replace
bias features in contributing to the target task during the training stage, and
on the other hand be easily removed by intervention during the inference stage.
This guarantees the learning of the target task does not hinder the elimination
of bias features. We apply \emph{Shortcut Debiasing} to several benchmark
datasets, and achieve significant improvements over the state-of-the-art
debiasing methods in both accuracy and fairness.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations. (arXiv:2308.08162v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08162">http://arxiv.org/abs/2308.08162</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08162]] Interpretability Benchmark for Evaluating Spatial Misalignment of Prototypical Parts Explanations(http://arxiv.org/abs/2308.08162)</code></li>
<li>Summary: <p>Prototypical parts-based networks are becoming increasingly popular due to
their faithful self-explanations. However, their similarity maps are calculated
in the penultimate network layer. Therefore, the receptive field of the
prototype activation region often depends on parts of the image outside this
region, which can lead to misleading interpretations. We name this undesired
behavior a spatial explanation misalignment and introduce an interpretability
benchmark with a set of dedicated metrics for quantifying this phenomenon. In
addition, we propose a method for misalignment compensation and apply it to
existing state-of-the-art models. We show the expressiveness of our benchmark
and the effectiveness of the proposed compensation methodology through
extensive empirical studies.
</p></li>
</ul>

<h3>Title: Explainable Multi-View Deep Networks Methodology for Experimental Physics. (arXiv:2308.08206v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08206">http://arxiv.org/abs/2308.08206</a></li>
<li>Code URL: https://github.com/scientific-computing-lab-nrcn/multi-view-explainability</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08206]] Explainable Multi-View Deep Networks Methodology for Experimental Physics(http://arxiv.org/abs/2308.08206)</code></li>
<li>Summary: <p>Physical experiments often involve multiple imaging representations, such as
X-ray scans and microscopic images. Deep learning models have been widely used
for supervised analysis in these experiments. Combining different image
representations is frequently required to analyze and make a decision properly.
Consequently, multi-view data has emerged - datasets where each sample is
described by views from different angles, sources, or modalities. These
problems are addressed with the concept of multi-view learning. Understanding
the decision-making process of deep learning models is essential for reliable
and credible analysis. Hence, many explainability methods have been devised
recently. Nonetheless, there is a lack of proper explainability in multi-view
models, which are challenging to explain due to their architectures. In this
paper, we suggest different multi-view architectures for the vision domain,
each suited to another problem, and we also present a methodology for
explaining these models. To demonstrate the effectiveness of our methodology,
we focus on the domain of High Energy Density Physics (HEDP) experiments, where
multiple imaging representations are used to assess the quality of foam
samples. We apply our methodology to classify the foam samples quality using
the suggested multi-view architectures. Through experimental results, we
showcase the improvement of accurate architecture choice on both accuracy - 78%
to 84% and AUC - 83% to 93% and present a trade-off between performance and
explainability. Specifically, we demonstrate that our approach enables the
explanation of individual one-view models, providing insights into the
decision-making process of each view. This understanding enhances the
interpretability of the overall multi-view model. The sources of this work are
available at:
https://github.com/Scientific-Computing-Lab-NRCN/Multi-View-Explainability.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation. (arXiv:2308.07929v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07929">http://arxiv.org/abs/2308.07929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07929]] Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation(http://arxiv.org/abs/2308.07929)</code></li>
<li>Summary: <p>Recently, large multimodal models, such as CLIP and Stable Diffusion have
experimented tremendous successes in both foundations and applications.
However, as these models increase in parameter size and computational
requirements, it becomes more challenging for users to personalize them for
specific tasks or preferences. In this work, we address the problem of adapting
the previous models towards sets of particular human preferences, aligning the
retrieved or generated images with the preferences of the user. We leverage the
Bradley-Terry preference model to develop a fast adaptation method that
efficiently fine-tunes the original model, with few examples and with minimal
computing resources. Extensive evidence of the capabilities of this framework
is provided through experiments in different domains related to multimodal text
and image understanding, including preference prediction as a reward model, and
generation tasks.
</p></li>
</ul>

<h3>Title: YODA: You Only Diffuse Areas. An Area-Masked Diffusion Approach For Image Super-Resolution. (arXiv:2308.07977v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07977">http://arxiv.org/abs/2308.07977</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07977]] YODA: You Only Diffuse Areas(http://arxiv.org/abs/2308.07977)</code></li>
<li>Summary: <p>This work introduces "You Only Diffuse Areas" (YODA), a novel method for
partial diffusion in Single-Image Super-Resolution (SISR). The core idea is to
utilize diffusion selectively on spatial regions based on attention maps
derived from the low-resolution image and the current time step in the
diffusion process. This time-dependent targeting enables a more effective
conversion to high-resolution outputs by focusing on areas that benefit the
most from the iterative refinement process, i.e., detail-rich objects. We
empirically validate YODA by extending leading diffusion-based SISR methods SR3
and SRDiff. Our experiments demonstrate new state-of-the-art performance gains
in face and general SR across PSNR, SSIM, and LPIPS metrics. A notable finding
is YODA's stabilization effect on training by reducing color shifts, especially
when induced by small batch sizes, potentially contributing to
resource-constrained scenarios. The proposed spatial and temporal adaptive
diffusion mechanism opens promising research directions, including developing
enhanced attention map extraction techniques and optimizing inference latency
based on sparser diffusion.
</p></li>
</ul>

<h3>Title: DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory. (arXiv:2308.08089v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08089">http://arxiv.org/abs/2308.08089</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08089]] DragNUWA: Fine-grained Control in Video Generation by Integrating Text, Image, and Trajectory(http://arxiv.org/abs/2308.08089)</code></li>
<li>Summary: <p>Controllable video generation has gained significant attention in recent
years. However, two main limitations persist: Firstly, most existing works
focus on either text, image, or trajectory-based control, leading to an
inability to achieve fine-grained control in videos. Secondly, trajectory
control research is still in its early stages, with most experiments being
conducted on simple datasets like Human3.6M. This constraint limits the models'
capability to process open-domain images and effectively handle complex curved
trajectories. In this paper, we propose DragNUWA, an open-domain
diffusion-based video generation model. To tackle the issue of insufficient
control granularity in existing works, we simultaneously introduce text, image,
and trajectory information to provide fine-grained control over video content
from semantic, spatial, and temporal perspectives. To resolve the problem of
limited open-domain trajectory control in current research, We propose
trajectory modeling with three aspects: a Trajectory Sampler (TS) to enable
open-domain control of arbitrary trajectories, a Multiscale Fusion (MF) to
control trajectories in different granularities, and an Adaptive Training (AT)
strategy to generate consistent videos following trajectories. Our experiments
validate the effectiveness of DragNUWA, demonstrating its superior performance
in fine-grained control in video generation. The homepage link is
\url{https://www.microsoft.com/en-us/research/project/dragnuwa/}
</p></li>
</ul>

<h3>Title: Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis. (arXiv:2308.08157v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08157">http://arxiv.org/abs/2308.08157</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08157]] Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis(http://arxiv.org/abs/2308.08157)</code></li>
<li>Summary: <p>Existing text-to-image generation approaches have set high standards for
photorealism and text-image correspondence, largely benefiting from web-scale
text-image datasets, which can include up to 5~billion pairs. However,
text-to-image generation models trained on domain-specific datasets, such as
urban scenes, medical images, and faces, still suffer from low text-image
correspondence due to the lack of text-image pairs. Additionally, collecting
billions of text-image pairs for a specific domain can be time-consuming and
costly. Thus, ensuring high text-image correspondence without relying on
web-scale text-image datasets remains a challenging task. In this paper, we
present a novel approach for enhancing text-image correspondence by leveraging
available semantic layouts. Specifically, we propose a Gaussian-categorical
diffusion process that simultaneously generates both images and corresponding
layout pairs. Our experiments reveal that we can guide text-to-image generation
models to be aware of the semantics of different image regions, by training the
model to generate semantic labels for each pixel. We demonstrate that our
approach achieves higher text-image correspondence compared to existing
text-to-image generation approaches in the Multi-Modal CelebA-HQ and the
Cityscapes dataset, where text-image pairs are scarce. Codes are available in
this https://pmh9960.github.io/research/GCDP
</p></li>
</ul>

<h3>Title: Dual-Stream Diffusion Net for Text-to-Video Generation. (arXiv:2308.08316v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08316">http://arxiv.org/abs/2308.08316</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08316]] Dual-Stream Diffusion Net for Text-to-Video Generation(http://arxiv.org/abs/2308.08316)</code></li>
<li>Summary: <p>With the emerging diffusion models, recently, text-to-video generation has
aroused increasing attention. But an important bottleneck therein is that
generative videos often tend to carry some flickers and artifacts. In this
work, we propose a dual-stream diffusion net (DSDN) to improve the consistency
of content variations in generating videos. In particular, the designed two
diffusion streams, video content and motion branches, could not only run
separately in their private spaces for producing personalized video variations
as well as content, but also be well-aligned between the content and motion
domains through leveraging our designed cross-transformer interaction module,
which would benefit the smoothness of generated videos. Besides, we also
introduce motion decomposer and combiner to faciliate the operation on video
motion. Qualitative and quantitative experiments demonstrate that our method
could produce amazing continuous videos with fewer flickers.
</p></li>
</ul>

<h3>Title: TeCH: Text-guided Reconstruction of Lifelike Clothed Humans. (arXiv:2308.08545v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08545">http://arxiv.org/abs/2308.08545</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08545]] TeCH: Text-guided Reconstruction of Lifelike Clothed Humans(http://arxiv.org/abs/2308.08545)</code></li>
<li>Summary: <p>Despite recent research advancements in reconstructing clothed humans from a
single image, accurately restoring the "unseen regions" with high-level details
remains an unsolved challenge that lacks attention. Existing methods often
generate overly smooth back-side surfaces with a blurry texture. But how to
effectively capture all visual attributes of an individual from a single image,
which are sufficient to reconstruct unseen areas (e.g., the back view)?
Motivated by the power of foundation models, TeCH reconstructs the 3D human by
leveraging 1) descriptive text prompts (e.g., garments, colors, hairstyles)
which are automatically generated via a garment parsing model and Visual
Question Answering (VQA), 2) a personalized fine-tuned Text-to-Image diffusion
model (T2I) which learns the "indescribable" appearance. To represent
high-resolution 3D clothed humans at an affordable cost, we propose a hybrid 3D
representation based on DMTet, which consists of an explicit body shape grid
and an implicit distance field. Guided by the descriptive prompts +
personalized T2I diffusion model, the geometry and texture of the 3D humans are
optimized through multi-view Score Distillation Sampling (SDS) and
reconstruction losses based on the original observation. TeCH produces
high-fidelity 3D clothed humans with consistent &amp; delicate texture, and
detailed full-body geometry. Quantitative and qualitative experiments
demonstrate that TeCH outperforms the state-of-the-art methods in terms of
reconstruction accuracy and rendering quality. The code will be publicly
available for research purposes at https://huangyangyi.github.io/tech
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and Blind Super-Resolution. (arXiv:2308.08142v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08142">http://arxiv.org/abs/2308.08142</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08142]] S2R: Exploring a Double-Win Transformer-Based Framework for Ideal and Blind Super-Resolution(http://arxiv.org/abs/2308.08142)</code></li>
<li>Summary: <p>Nowadays, deep learning based methods have demonstrated impressive
performance on ideal super-resolution (SR) datasets, but most of these methods
incur dramatically performance drops when directly applied in real-world SR
reconstruction tasks with unpredictable blur kernels. To tackle this issue,
blind SR methods are proposed to improve the visual results on random blur
kernels, which causes unsatisfactory reconstruction effects on ideal
low-resolution images similarly. In this paper, we propose a double-win
framework for ideal and blind SR task, named S2R, including a light-weight
transformer-based SR model (S2R transformer) and a novel coarse-to-fine
training strategy, which can achieve excellent visual results on both ideal and
random fuzzy conditions. On algorithm level, S2R transformer smartly combines
some efficient and light-weight blocks to enhance the representation ability of
extracted features with relatively low number of parameters. For training
strategy, a coarse-level learning process is firstly performed to improve the
generalization of the network with the help of a large-scale external dataset,
and then, a fast fine-tune process is developed to transfer the pre-trained
model to real-world SR tasks by mining the internal features of the image.
Experimental results show that the proposed S2R outperforms other single-image
SR models in ideal SR condition with only 578K parameters. Meanwhile, it can
achieve better visual results than regular blind SR models in blind fuzzy
conditions with only 10 gradient updates, which improve convergence speed by
300 times, significantly accelerating the transfer-learning process in
real-world situations.
</p></li>
</ul>

<h3>Title: Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network. (arXiv:2308.08220v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08220">http://arxiv.org/abs/2308.08220</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08220]] Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network(http://arxiv.org/abs/2308.08220)</code></li>
<li>Summary: <p>This paper presents a novel network structure with illumination-aware gamma
correction and complete image modelling to solve the low-light image
enhancement problem. Low-light environments usually lead to less informative
large-scale dark areas, directly learning deep representations from low-light
images is insensitive to recovering normal illumination. We propose to
integrate the effectiveness of gamma correction with the strong modelling
capacities of deep networks, which enables the correction factor gamma to be
learned in a coarse to elaborate manner via adaptively perceiving the deviated
illumination. Because exponential operation introduces high computational
complexity, we propose to use Taylor Series to approximate gamma correction,
accelerating the training and inference speed. Dark areas usually occupy large
scales in low-light images, common local modelling structures, e.g., CNN,
SwinIR, are thus insufficient to recover accurate illumination across whole
low-light images. We propose a novel Transformer block to completely simulate
the dependencies of all pixels across images via a local-to-global hierarchical
attention mechanism, so that dark areas could be inferred by borrowing the
information from far informative regions in a highly effective manner.
Extensive experiments on several benchmark datasets demonstrate that our
approach outperforms state-of-the-art methods.
</p></li>
</ul>

<h3>Title: Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos. (arXiv:2308.08303v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08303">http://arxiv.org/abs/2308.08303</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08303]] Leveraging Next-Active Objects for Context-Aware Anticipation in Egocentric Videos(http://arxiv.org/abs/2308.08303)</code></li>
<li>Summary: <p>Objects are crucial for understanding human-object interactions. By
identifying the relevant objects, one can also predict potential future
interactions or actions that may occur with these objects. In this paper, we
study the problem of Short-Term Object interaction anticipation (STA) and
propose NAOGAT (Next-Active-Object Guided Anticipation Transformer), a
multi-modal end-to-end transformer network, that attends to objects in observed
frames in order to anticipate the next-active-object (NAO) and, eventually, to
guide the model to predict context-aware future actions. The task is
challenging since it requires anticipating future action along with the object
with which the action occurs and the time after which the interaction will
begin, a.k.a. the time to contact (TTC). Compared to existing video modeling
architectures for action anticipation, NAOGAT captures the relationship between
objects and the global scene context in order to predict detections for the
next active object and anticipate relevant future actions given these
detections, leveraging the objects' dynamics to improve accuracy. One of the
key strengths of our approach, in fact, is its ability to exploit the motion
dynamics of objects within a given clip, which is often ignored by other
models, and separately decoding the object-centric and motion-centric
information. Through our experiments, we show that our model outperforms
existing methods on two separate datasets, Ego4D and EpicKitchens-100 ("Unseen
Set"), as measured by several additional metrics, such as time to contact, and
next-active-object localization. The code will be available upon acceptance.
</p></li>
</ul>

<h3>Title: Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN. (arXiv:2308.08333v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08333">http://arxiv.org/abs/2308.08333</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08333]] Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN(http://arxiv.org/abs/2308.08333)</code></li>
<li>Summary: <p>Monocular depth estimation is an ongoing challenge in computer vision. Recent
progress with Transformer models has demonstrated notable advantages over
conventional CNNs in this area. However, there's still a gap in understanding
how these models prioritize different regions in 2D images and how these
regions affect depth estimation performance. To explore the differences between
Transformers and CNNs, we employ a sparse pixel approach to contrastively
analyze the distinctions between the two. Our findings suggest that while
Transformers excel in handling global context and intricate textures, they lag
behind CNNs in preserving depth gradient continuity. To further enhance the
performance of Transformer models in monocular depth estimation, we propose the
Depth Gradient Refinement (DGR) module that refines depth estimation through
high-order differentiation, feature fusion, and recalibration. Additionally, we
leverage optimal transport theory, treating depth maps as spatial probability
distributions, and employ the optimal transport distance as a loss function to
optimize our model. Experimental results demonstrate that models integrated
with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed
loss function enhance performance without increasing complexity and
computational costs. This research not only offers fresh insights into the
distinctions between Transformers and CNNs in depth estimation but also paves
the way for novel depth estimation methodologies.
</p></li>
</ul>

<h3>Title: Agglomerative Transformer for Human-Object Interaction Detection. (arXiv:2308.08370v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08370">http://arxiv.org/abs/2308.08370</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08370]] Agglomerative Transformer for Human-Object Interaction Detection(http://arxiv.org/abs/2308.08370)</code></li>
<li>Summary: <p>We propose an agglomerative Transformer (AGER) that enables Transformer-based
human-object interaction (HOI) detectors to flexibly exploit extra
instance-level cues in a single-stage and end-to-end manner for the first time.
AGER acquires instance tokens by dynamically clustering patch tokens and
aligning cluster centers to instances with textual guidance, thus enjoying two
benefits: 1) Integrality: each instance token is encouraged to contain all
discriminative feature regions of an instance, which demonstrates a significant
improvement in the extraction of different instance-level cues and subsequently
leads to a new state-of-the-art performance of HOI detection with 36.75 mAP on
HICO-Det. 2) Efficiency: the dynamical clustering mechanism allows AGER to
generate instance tokens jointly with the feature learning of the Transformer
encoder, eliminating the need of an additional object detector or instance
decoder in prior methods, thus allowing the extraction of desirable extra cues
for HOI detection in a single-stage and end-to-end pipeline. Concretely, AGER
reduces GFLOPs by 8.5% and improves FPS by 36%, even compared to a vanilla
DETR-like pipeline without extra cue extraction.
</p></li>
</ul>

<h3>Title: Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer. (arXiv:2308.08414v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08414">http://arxiv.org/abs/2308.08414</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08414]] Tem-adapter: Adapting Image-Text Pretraining for Video Question Answer(http://arxiv.org/abs/2308.08414)</code></li>
<li>Summary: <p>Video-language pre-trained models have shown remarkable success in guiding
video question-answering (VideoQA) tasks. However, due to the length of video
sequences, training large-scale video-based models incurs considerably higher
costs than training image-based ones. This motivates us to leverage the
knowledge from image-based pretraining, despite the obvious gaps between image
and video domains. To bridge these gaps, in this paper, we propose Tem-Adapter,
which enables the learning of temporal dynamics and complex semantics by a
visual Temporal Aligner and a textual Semantic Aligner. Unlike conventional
pretrained knowledge adaptation methods that only concentrate on the downstream
task objective, the Temporal Aligner introduces an extra language-guided
autoregressive task aimed at facilitating the learning of temporal
dependencies, with the objective of predicting future states based on
historical clues and language guidance that describes event progression.
Besides, to reduce the semantic gap and adapt the textual representation for
better event description, we introduce a Semantic Aligner that first designs a
template to fuse question and answer pairs as event descriptions and then
learns a Transformer decoder with the whole video sequence as guidance for
refinement. We evaluate Tem-Adapter and different pre-train transferring
methods on two VideoQA benchmarks, and the significant performance improvement
demonstrates the effectiveness of our method.
</p></li>
</ul>

<h3>Title: Using Artificial Populations to Study Psychological Phenomena in Neural Models. (arXiv:2308.08032v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08032">http://arxiv.org/abs/2308.08032</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08032]] Using Artificial Populations to Study Psychological Phenomena in Neural Models(http://arxiv.org/abs/2308.08032)</code></li>
<li>Summary: <p>The recent proliferation of research into transformer based natural language
processing has led to a number of studies which attempt to detect the presence
of human-like cognitive behavior in the models. We contend that, as is true of
human psychology, the investigation of cognitive behavior in language models
must be conducted in an appropriate population of an appropriate size for the
results to be meaningful. We leverage work in uncertainty estimation in a novel
approach to efficiently construct experimental populations. The resultant tool,
PopulationLM, has been made open source. We provide theoretical grounding in
the uncertainty estimation literature and motivation from current cognitive
work regarding language models. We discuss the methodological lessons from
other scientific communities and attempt to demonstrate their application to
two artificial population studies. Through population based experimentation we
find that language models exhibit behavior consistent with typicality effects
among categories highly represented in training. However, we find that language
models don't tend to exhibit structural priming effects. Generally, our results
show that single models tend to over estimate the presence of cognitive
behaviors in neural models.
</p></li>
</ul>

<h3>Title: Fast Training of NMT Model with Data Sorting. (arXiv:2308.08153v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08153">http://arxiv.org/abs/2308.08153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08153]] Fast Training of NMT Model with Data Sorting(http://arxiv.org/abs/2308.08153)</code></li>
<li>Summary: <p>The Transformer model has revolutionized Natural Language Processing tasks
such as Neural Machine Translation, and many efforts have been made to study
the Transformer architecture, which increased its efficiency and accuracy. One
potential area for improvement is to address the computation of empty tokens
that the Transformer computes only to discard them later, leading to an
unnecessary computational burden. To tackle this, we propose an algorithm that
sorts translation sentence pairs based on their length before batching,
minimizing the waste of computing power. Since the amount of sorting could
violate the independent and identically distributed (i.i.d) data assumption, we
sort the data partially. In experiments, we apply the proposed method to
English-Korean and English-Luganda language pairs for machine translation and
show that there are gains in computational time while maintaining the
performance. Our method is independent of architectures, so that it can be
easily integrated into any training process with flexible data lengths.
</p></li>
</ul>

<h3>Title: Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey. (arXiv:2308.08234v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08234">http://arxiv.org/abs/2308.08234</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08234]] Challenges and Opportunities of Using Transformer-Based Multi-Task Learning in NLP Through ML Lifecycle: A Survey(http://arxiv.org/abs/2308.08234)</code></li>
<li>Summary: <p>The increasing adoption of natural language processing (NLP) models across
industries has led to practitioners' need for machine learning systems to
handle these models efficiently, from training to serving them in production.
However, training, deploying, and updating multiple models can be complex,
costly, and time-consuming, mainly when using transformer-based pre-trained
language models. Multi-Task Learning (MTL) has emerged as a promising approach
to improve efficiency and performance through joint training, rather than
training separate models. Motivated by this, we first provide an overview of
transformer-based MTL approaches in NLP. Then, we discuss the challenges and
opportunities of using MTL approaches throughout typical ML lifecycle phases,
specifically focusing on the challenges related to data engineering, model
development, deployment, and monitoring phases. This survey focuses on
transformer-based MTL architectures and, to the best of our knowledge, is novel
in that it systematically analyses how transformer-based MTL in NLP fits into
ML lifecycle phases. Furthermore, we motivate research on the connection
between MTL and continual learning (CL), as this area remains unexplored. We
believe it would be practical to have a model that can handle both MTL and CL,
as this would make it easier to periodically re-train the model, update it due
to distribution shifts, and add new capabilities to meet real-world
requirements.
</p></li>
</ul>

<h3>Title: Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction. (arXiv:2308.08442v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08442">http://arxiv.org/abs/2308.08442</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08442]] Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction(http://arxiv.org/abs/2308.08442)</code></li>
<li>Summary: <p>Text-to-Text Transfer Transformer (T5) has recently been considered for the
Grapheme-to-Phoneme (G2P) transduction. As a follow-up, a tokenizer-free
byte-level model based on T5 referred to as ByT5, recently gave promising
results on word-level G2P conversion by representing each input character with
its corresponding UTF-8 encoding. Although it is generally understood that
sentence-level or paragraph-level G2P can improve usability in real-world
applications as it is better suited to perform on heteronyms and linking sounds
between words, we find that using ByT5 for these scenarios is nontrivial. Since
ByT5 operates on the character level, it requires longer decoding steps, which
deteriorates the performance due to the exposure bias commonly observed in
auto-regressive generation models. This paper shows that the performance of
sentence-level and paragraph-level G2P can be improved by mitigating such
exposure bias using our proposed loss-based sampling method.
</p></li>
</ul>

<h3>Title: How to Mask in Error Correction Code Transformer: Systematic and Double Masking. (arXiv:2308.08128v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08128">http://arxiv.org/abs/2308.08128</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08128]] How to Mask in Error Correction Code Transformer: Systematic and Double Masking(http://arxiv.org/abs/2308.08128)</code></li>
<li>Summary: <p>In communication and storage systems, error correction codes (ECCs) are
pivotal in ensuring data reliability. As deep learning's applicability has
broadened across diverse domains, there is a growing research focus on neural
network-based decoders that outperform traditional decoding algorithms. Among
these neural decoders, Error Correction Code Transformer (ECCT) has achieved
the state-of-the-art performance, outperforming other methods by large margins.
To further enhance the performance of ECCT, we propose two novel methods.
First, leveraging the systematic encoding technique of ECCs, we introduce a new
masking matrix for ECCT, aiming to improve the performance and reduce the
computational complexity. Second, we propose a novel transformer architecture
of ECCT called a double-masked ECCT. This architecture employs two different
mask matrices in a parallel manner to learn more diverse features of the
relationship between codeword bits in the masked self-attention blocks.
Extensive simulation results show that the proposed double-masked ECCT
outperforms the conventional ECCT, achieving the state-of-the-art decoding
performance with significant margins.
</p></li>
</ul>

<h3>Title: It Ain't That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models. (arXiv:2308.08268v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08268">http://arxiv.org/abs/2308.08268</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08268]] It Ain't That Bad: Understanding the Mysterious Performance Drop in OOD Generalization for Generative Transformer Models(http://arxiv.org/abs/2308.08268)</code></li>
<li>Summary: <p>Generative Transformer-based models have achieved remarkable proficiency on
solving diverse problems. However, their generalization ability is not fully
understood and not always satisfying. Researchers take basic mathematical tasks
like n-digit addition or multiplication as important perspectives for
investigating their generalization behaviors. Curiously, it is observed that
when training on n-digit operations (e.g., additions) in which both input
operands are n-digit in length, models generalize successfully on unseen
n-digit inputs (in-distribution (ID) generalization), but fail miserably and
mysteriously on longer, unseen cases (out-of-distribution (OOD)
generalization). Studies try to bridge this gap with workarounds such as
modifying position embedding, fine-tuning, and priming with more extensive or
instructive data. However, without addressing the essential mechanism, there is
hardly any guarantee regarding the robustness of these solutions. We bring this
unexplained performance drop into attention and ask whether it is purely from
random errors. Here we turn to the mechanistic line of research which has
notable successes in model interpretability. We discover that the strong ID
generalization stems from structured representations, while behind the
unsatisfying OOD performance, the models still exhibit clear learned algebraic
structures. Specifically, these models map unseen OOD inputs to outputs with
equivalence relations in the ID domain. These highlight the potential of the
models to carry useful information for improved generalization.
</p></li>
</ul>

<h3>Title: Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals. (arXiv:2308.08480v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08480">http://arxiv.org/abs/2308.08480</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08480]] Label Propagation Techniques for Artifact Detection in Imbalanced Classes using Photoplethysmogram Signals(http://arxiv.org/abs/2308.08480)</code></li>
<li>Summary: <p>Photoplethysmogram (PPG) signals are widely used in healthcare for monitoring
vital signs, but they are susceptible to motion artifacts that can lead to
inaccurate interpretations. In this study, the use of label propagation
techniques to propagate labels among PPG samples is explored, particularly in
imbalanced class scenarios where clean PPG samples are significantly
outnumbered by artifact-contaminated samples. With a precision of 91%, a recall
of 90% and an F1 score of 90% for the class without artifacts, the results
demonstrate its effectiveness in labeling a medical dataset, even when clean
samples are rare. For the classification of artifacts our study compares
supervised classifiers such as conventional classifiers and neural networks
(MLP, Transformers, FCN) with the semi-supervised label propagation algorithm.
With a precision of 89%, a recall of 95% and an F1 score of 92%, the KNN
supervised model gives good results, but the semi-supervised algorithm performs
better in detecting artifacts. The findings suggest that the semi-supervised
algorithm label propagation hold promise for artifact detection in PPG signals,
which can enhance the reliability of PPG-based health monitoring systems in
real-world applications.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment. (arXiv:2308.08525v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08525">http://arxiv.org/abs/2308.08525</a></li>
<li>Code URL: https://github.com/chenqi008/leica</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08525]] Likelihood-Based Text-to-Image Evaluation with Patch-Level Perceptual and Semantic Credit Assignment(http://arxiv.org/abs/2308.08525)</code></li>
<li>Summary: <p>Text-to-image synthesis has made encouraging progress and attracted lots of
public attention recently. However, popular evaluation metrics in this area,
like the Inception Score and Fr'echet Inception Distance, incur several issues.
First of all, they cannot explicitly assess the perceptual quality of generated
images and poorly reflect the semantic alignment of each text-image pair. Also,
they are inefficient and need to sample thousands of images to stabilise their
evaluation results. In this paper, we propose to evaluate text-to-image
generation performance by directly estimating the likelihood of the generated
images using a pre-trained likelihood-based text-to-image generative model,
i.e., a higher likelihood indicates better perceptual quality and better
text-image alignment. To prevent the likelihood of being dominated by the
non-crucial part of the generated image, we propose several new designs to
develop a credit assignment strategy based on the semantic and perceptual
significance of the image patches. In the experiments, we evaluate the proposed
metric on multiple popular text-to-image generation models and datasets in
accessing both the perceptual quality and the text-image alignment. Moreover,
it can successfully assess the generation ability of these models with as few
as a hundred samples, making it very efficient in practice.
</p></li>
</ul>

<h3>Title: Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System. (arXiv:2308.08169v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08169">http://arxiv.org/abs/2308.08169</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08169]] Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System(http://arxiv.org/abs/2308.08169)</code></li>
<li>Summary: <p>End-to-end task-oriented dialogue (TOD) systems have achieved promising
performance by leveraging sophisticated natural language understanding and
natural language generation capabilities of pre-trained models. This work
enables the TOD systems with more flexibility through a simple cache. The cache
provides the flexibility to dynamically update the TOD systems and handle both
existing and unseen dialogue scenarios. Towards this end, we first fine-tune a
retrieval module to effectively retrieve the most relevant information entries
from the cache. We then train end-to-end TOD models that can refer to and
ground on both dialogue history and retrieved information during TOD
generation. The cache is straightforward to construct, and the backbone models
of TOD systems are compatible with existing pre-trained generative models.
Extensive experiments demonstrate the superior performance of our framework,
with a notable improvement in non-empty joint goal accuracy by 6.7% compared to
strong baselines.
</p></li>
</ul>

<h3>Title: Deep Generative Imputation Model for Missing Not At Random Data. (arXiv:2308.08158v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08158">http://arxiv.org/abs/2308.08158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08158]] Deep Generative Imputation Model for Missing Not At Random Data(http://arxiv.org/abs/2308.08158)</code></li>
<li>Summary: <p>Data analysis usually suffers from the Missing Not At Random (MNAR) problem,
where the cause of the value missing is not fully observed. Compared to the
naive Missing Completely At Random (MCAR) problem, it is more in line with the
realistic scenario whereas more complex and challenging. Existing statistical
methods model the MNAR mechanism by different decomposition of the joint
distribution of the complete data and the missing mask. But we empirically find
that directly incorporating these statistical methods into deep generative
models is sub-optimal. Specifically, it would neglect the confidence of the
reconstructed mask during the MNAR imputation process, which leads to
insufficient information extraction and less-guaranteed imputation quality. In
this paper, we revisit the MNAR problem from a novel perspective that the
complete data and missing mask are two modalities of incomplete data on an
equal footing. Along with this line, we put forward a generative-model-specific
joint probability decomposition method, conjunction model, to represent the
distributions of two modalities in parallel and extract sufficient information
from both complete data and missing mask. Taking a step further, we exploit a
deep generative imputation model, namely GNR, to process the real-world missing
mechanism in the latent space and concurrently impute the incomplete data and
reconstruct the missing mask. The experimental results show that our GNR
surpasses state-of-the-art MNAR baselines with significant margins (averagely
improved from 9.9% to 18.8% in RMSE) and always gives a better mask
reconstruction accuracy which makes the imputation more principle.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: $A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models. (arXiv:2308.07997v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.07997">http://arxiv.org/abs/2308.07997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.07997]] $A^2$Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models(http://arxiv.org/abs/2308.07997)</code></li>
<li>Summary: <p>We study the task of zero-shot vision-and-language navigation (ZS-VLN), a
practical yet challenging problem in which an agent learns to navigate
following a path described by language instructions without requiring any
path-instruction annotation data. Normally, the instructions have complex
grammatical structures and often contain various action descriptions (e.g.,
"proceed beyond", "depart from"). How to correctly understand and execute these
action demands is a critical problem, and the absence of annotated data makes
it even more challenging. Note that a well-educated human being can easily
understand path instructions without the need for any special training. In this
paper, we propose an action-aware zero-shot VLN method ($A^2$Nav) by exploiting
the vision-and-language ability of foundation models. Specifically, the
proposed method consists of an instruction parser and an action-aware
navigation policy. The instruction parser utilizes the advanced reasoning
ability of large language models (e.g., GPT-3) to decompose complex navigation
instructions into a sequence of action-specific object navigation sub-tasks.
Each sub-task requires the agent to localize the object and navigate to a
specific goal position according to the associated action demand. To accomplish
these sub-tasks, an action-aware navigation policy is learned from freely
collected action-specific datasets that reveal distinct characteristics of each
action demand. We use the learned navigation policy for executing sub-tasks
sequentially to follow the navigation instruction. Extensive experiments show
$A^2$Nav achieves promising ZS-VLN performance and even surpasses the
supervised learning methods on R2R-Habitat and RxR-Habitat datasets.
</p></li>
</ul>

<h3>Title: Painter: Teaching Auto-regressive Language Models to Draw Sketches. (arXiv:2308.08520v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08520">http://arxiv.org/abs/2308.08520</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08520]] Painter: Teaching Auto-regressive Language Models to Draw Sketches(http://arxiv.org/abs/2308.08520)</code></li>
<li>Summary: <p>Large language models (LLMs) have made tremendous progress in natural
language understanding and they have also been successfully adopted in other
domains such as computer vision, robotics, reinforcement learning, etc. In this
work, we apply LLMs to image generation tasks by directly generating the
virtual brush strokes to paint an image. We present Painter, an LLM that can
convert user prompts in text description format to sketches by generating the
corresponding brush strokes in an auto-regressive way. We construct Painter
based on off-the-shelf LLM that is pre-trained on a large text corpus, by
fine-tuning it on the new task while preserving language understanding
capabilities. We create a dataset of diverse multi-object sketches paired with
textual prompts that covers several object types and tasks. Painter can
generate sketches from text descriptions, remove objects from canvas, and
detect and classify objects in sketches. Although this is an unprecedented
pioneering work in using LLMs for auto-regressive image generation, the results
are very encouraging.
</p></li>
</ul>

<h3>Title: DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue. (arXiv:2308.08043v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08043">http://arxiv.org/abs/2308.08043</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08043]] DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue(http://arxiv.org/abs/2308.08043)</code></li>
<li>Summary: <p>Large Language Models (LLMs), such as ChatGPT, are becoming increasingly
sophisticated, demonstrating capabilities that closely resemble those of
humans. These AI models are playing an essential role in assisting humans with
a wide array of tasks in daily life. A significant application of AI is its use
as a chat agent, responding to human inquiries across various domains. Current
LLMs have shown proficiency in answering general questions. However, basic
question-answering dialogue often falls short in complex diagnostic scenarios,
such as legal or medical consultations. These scenarios typically necessitate
Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively
pose questions and guide users towards specific task completion. Previous
fine-tuning models have underperformed in TOD, and current LLMs do not
inherently possess this capability. In this paper, we introduce DiagGPT
(Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD
scenarios. Our experiments reveal that DiagGPT exhibits outstanding performance
in conducting TOD with users, demonstrating its potential for practical
applications.
</p></li>
</ul>

<h3>Title: The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models. (arXiv:2308.08061v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08061">http://arxiv.org/abs/2308.08061</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08061]] The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models(http://arxiv.org/abs/2308.08061)</code></li>
<li>Summary: <p>When deploying machine learning models in production for any
product/application, there are three properties that are commonly desired.
First, the models should be generalizable, in that we can extend it to further
use cases as our knowledge of the domain area develops. Second they should be
evaluable, so that there are clear metrics for performance and the calculation
of those metrics in production settings are feasible. Finally, the deployment
should be cost-optimal as far as possible. In this paper we propose that these
three objectives (i.e. generalization, evaluation and cost-optimality) can
often be relatively orthogonal and that for large language models, despite
their performance over conventional NLP models, enterprises need to carefully
assess all the three factors before making substantial investments in this
technology. We propose a framework for generalization, evaluation and
cost-modeling specifically tailored to large language models, offering insights
into the intricacies of development, deployment and management for these large
language models.
</p></li>
</ul>

<h3>Title: Time Travel in LLMs: Tracing Data Contamination in Large Language Models. (arXiv:2308.08493v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08493">http://arxiv.org/abs/2308.08493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08493]] Time Travel in LLMs: Tracing Data Contamination in Large Language Models(http://arxiv.org/abs/2308.08493)</code></li>
<li>Summary: <p>Data contamination, i.e., the presence of test data from downstream tasks in
the training data of large language models (LLMs), is a potential major issue
in understanding LLMs' effectiveness on other tasks. We propose a
straightforward yet effective method for identifying data contamination within
LLMs. At its core, our approach starts by identifying potential contamination
in individual instances that are drawn from a small random sample; using this
information, our approach then assesses if an entire dataset partition is
contaminated. To estimate contamination of individual instances, we employ
"guided instruction:" a prompt consisting of the dataset name, partition type,
and the initial segment of a reference instance, asking the LLM to complete it.
An instance is flagged as contaminated if the LLM's output either exactly or
closely matches the latter segment of the reference. To understand if an entire
partition is contaminated, we propose two ideas. The first idea marks a dataset
partition as contaminated if the average overlap score with the reference
instances (as measured by ROUGE or BLEURT) is statistically significantly
better with the guided instruction vs. a general instruction that does not
include the dataset and partition name. The second idea marks a dataset as
contaminated if a classifier based on GPT-4 with in-context learning prompting
marks multiple instances as contaminated. Our best method achieves an accuracy
between 92% and 100% in detecting if an LLM is contaminated with seven
datasets, containing train and test/validation partitions, when contrasted with
manual evaluation by human expert. Further, our findings indicate that GPT-4 is
contaminated with AG News, WNLI, and XSum datasets.
</p></li>
</ul>

<h3>Title: Convergence of Two-Layer Regression with Nonlinear Units. (arXiv:2308.08358v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08358">http://arxiv.org/abs/2308.08358</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08358]] Convergence of Two-Layer Regression with Nonlinear Units(http://arxiv.org/abs/2308.08358)</code></li>
<li>Summary: <p>Large language models (LLMs), such as ChatGPT and GPT4, have shown
outstanding performance in many human life task. Attention computation plays an
important role in training LLMs. Softmax unit and ReLU unit are the key
structure in attention computation. Inspired by them, we put forward a softmax
ReLU regression problem. Generally speaking, our goal is to find an optimal
solution to the regression problem involving the ReLU unit. In this work, we
calculate a close form representation for the Hessian of the loss function.
Under certain assumptions, we prove the Lipschitz continuous and the PSDness of
the Hessian. Then, we introduce an greedy algorithm based on approximate Newton
method, which converges in the sense of the distance to optimal solution. Last,
We relax the Lipschitz condition and prove the convergence in the sense of loss
value.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for Long-tailed Semantic Segmentation. (arXiv:2308.08213v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08213">http://arxiv.org/abs/2308.08213</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08213]] MEDOE: A Multi-Expert Decoder and Output Ensemble Framework for Long-tailed Semantic Segmentation(http://arxiv.org/abs/2308.08213)</code></li>
<li>Summary: <p>Long-tailed distribution of semantic categories, which has been often ignored
in conventional methods, causes unsatisfactory performance in semantic
segmentation on tail categories. In this paper, we focus on the problem of
long-tailed semantic segmentation. Although some long-tailed recognition
methods (e.g., re-sampling/re-weighting) have been proposed in other problems,
they can probably compromise crucial contextual information and are thus hardly
adaptable to the problem of long-tailed semantic segmentation. To address this
issue, we propose MEDOE, a novel framework for long-tailed semantic
segmentation via contextual information ensemble-and-grouping. The proposed
two-sage framework comprises a multi-expert decoder (MED) and a multi-expert
output ensemble (MOE). Specifically, the MED includes several "experts". Based
on the pixel frequency distribution, each expert takes the dataset masked
according to the specific categories as input and generates contextual
information self-adaptively for classification; The MOE adopts learnable
decision weights for the ensemble of the experts' outputs. As a model-agnostic
framework, our MEDOE can be flexibly and efficiently coupled with various
popular deep neural networks (e.g., DeepLabv3+, OCRNet, and PSPNet) to improve
their performance in long-tailed semantic segmentation. Experimental results
show that the proposed framework outperforms the current methods on both
Cityscapes and ADE20K datasets by up to 1.78% in mIoU and 5.89% in mAcc.
</p></li>
</ul>

<h3>Title: Improving Audio-Visual Segmentation with Bidirectional Generation. (arXiv:2308.08288v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08288">http://arxiv.org/abs/2308.08288</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08288]] Improving Audio-Visual Segmentation with Bidirectional Generation(http://arxiv.org/abs/2308.08288)</code></li>
<li>Summary: <p>The aim of audio-visual segmentation (AVS) is to precisely differentiate
audible objects within videos down to the pixel level. Traditional approaches
often tackle this challenge by combining information from various modalities,
where the contribution of each modality is implicitly or explicitly modeled.
Nevertheless, the interconnections between different modalities tend to be
overlooked in audio-visual modeling. In this paper, inspired by the human
ability to mentally simulate the sound of an object and its visual appearance,
we introduce a bidirectional generation framework. This framework establishes
robust correlations between an object's visual characteristics and its
associated sound, thereby enhancing the performance of AVS. To achieve this, we
employ a visual-to-audio projection component that reconstructs audio features
from object segmentation masks and minimizes reconstruction errors. Moreover,
recognizing that many sounds are linked to object movements, we introduce an
implicit volumetric motion estimation module to handle temporal dynamics that
may be challenging to capture using conventional optical flow methods. To
showcase the effectiveness of our approach, we conduct comprehensive
experiments and analyses on the widely recognized AVSBench benchmark. As a
result, we establish a new state-of-the-art performance level in the AVS
benchmark, particularly excelling in the challenging MS3 subset which involves
segmenting multiple sound sources. To facilitate reproducibility, we plan to
release both the source code and the pre-trained model.
</p></li>
</ul>

<h3>Title: MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions. (arXiv:2308.08544v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2308.08544">http://arxiv.org/abs/2308.08544</a></li>
<li>Code URL: https://github.com/henghuiding/MeViS</li>
<li>Copy Paste: <code><input type="checkbox">[[2308.08544]] MeViS: A Large-scale Benchmark for Video Segmentation with Motion Expressions(http://arxiv.org/abs/2308.08544)</code></li>
<li>Summary: <p>This paper strives for motion expressions guided video segmentation, which
focuses on segmenting objects in video content based on a sentence describing
the motion of the objects. Existing referring video object datasets typically
focus on salient objects and use language expressions that contain excessive
static attributes that could potentially enable the target object to be
identified in a single frame. These datasets downplay the importance of motion
in video content for language-guided video object segmentation. To investigate
the feasibility of using motion expressions to ground and segment objects in
videos, we propose a large-scale dataset called MeViS, which contains numerous
motion expressions to indicate target objects in complex environments. We
benchmarked 5 existing referring video object segmentation (RVOS) methods and
conducted a comprehensive comparison on the MeViS dataset. The results show
that current RVOS methods cannot effectively address motion expression-guided
video segmentation. We further analyze the challenges and propose a baseline
approach for the proposed MeViS dataset. The goal of our benchmark is to
provide a platform that enables the development of effective language-guided
video segmentation algorithms that leverage motion expressions as a primary cue
for object segmentation in complex video scenes. The proposed MeViS dataset has
been released at https://henghuiding.github.io/MeViS.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
