<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-09</h1>
<h2>secure</h2>
<h3>Title: Forensic Video Analytic Software. (arXiv:2401.02960v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02960">http://arxiv.org/abs/2401.02960</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02960]] Forensic Video Analytic Software(http://arxiv.org/abs/2401.02960)</code></li>
<li>Summary: <p>Law enforcement officials heavily depend on Forensic Video Analytic (FVA)
Software in their evidence extraction process. However present-day FVA software
are complex, time consuming, equipment dependent and expensive. Developing
countries struggle to gain access to this gateway to a secure haven. The term
forensic pertains the application of scientific methods to the investigation of
crime through post-processing, whereas surveillance is the close monitoring of
real-time feeds.
</p>
<p>The principle objective of this Final Year Project was to develop an
efficient and effective FVA Software, addressing the shortcomings through a
stringent and systematic review of scholarly research papers, online databases
and legal documentation. The scope spans multiple object detection, multiple
object tracking, anomaly detection, activity recognition, tampering detection,
general and specific image enhancement and video synopsis.
</p>
<p>Methods employed include many machine learning techniques, GPU acceleration
and efficient, integrated architecture development both for real-time and
postprocessing. For this CNN, GMM, multithreading and OpenCV C++ coding were
used. The implications of the proposed methodology would rapidly speed up the
FVA process especially through the novel video synopsis research arena. This
project has resulted in three research outcomes Moving Object Based Collision
Free Video Synopsis, Forensic and Surveillance Analytic Tool Architecture and
Tampering Detection Inter-Frame Forgery.
</p>
<p>The results include forensic and surveillance panel outcomes with emphasis on
video synopsis and Sri Lankan context. Principal conclusions include the
optimization and efficient algorithm integration to overcome limitations in
processing power, memory and compromise between real-time performance and
accuracy.
</p></li>
</ul>

<h3>Title: Zero-Knowledge Proof in NuLink. (arXiv:2401.03118v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03118">http://arxiv.org/abs/2401.03118</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03118]] Zero-Knowledge Proof in NuLink(http://arxiv.org/abs/2401.03118)</code></li>
<li>Summary: <p>NuLink provides privacy-preserving technology for decentralized applications
via APIs. Users can securely store its valuable data, trade with others and so
on. To ensure the privacy and security of service provided by NuLink,
(zero-knowledge) proof systems are necessary. Zero-knowledge proof systems
allow the prover to make the verifier believe that a certain conclusion is
correct without providing any useful information to the verifier. In NuLink, we
are going to use (zero-knowledge) proof system in the following three methods:
1. Users store their data through NuLink in a decentralized manner. To ensure
that the storage clients are indeed storing the data, we employ proof of
storage systems. In this system, users prepare certain challenges that can only
be correctly answered by those who are actually storing the data. 2. Users have
the option to outsource computations to NuLink. To verify the correctness of
the computation results provided by the compute node, we require the node to
provide a proof of correctness via SNARK systems. When sensitive parameters are
used as inputs for computation, we utilize zk-SNARKs to prevent any potential
leakage of these parameters. 3. Users may choose to trade their data through
NuLink. To confirm that the buyer has sufficient digital funds and the seller
possesses the desired data, both parties can provide a proof via zk-SNARKs.
This builds confidence and prevents cheating during transactions. Using
zero-knowledge proof systems, we can ensure that all nodes in NuLink behaves
honestly and avoid cheating in the whole system.
</p></li>
</ul>

<h3>Title: SecureReg: A Combined Framework for Proactively Exposing Malicious Domain Name Registrations. (arXiv:2401.03196v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03196">http://arxiv.org/abs/2401.03196</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03196]] SecureReg: A Combined Framework for Proactively Exposing Malicious Domain Name Registrations(http://arxiv.org/abs/2401.03196)</code></li>
<li>Summary: <p>Rising cyber threats, with miscreants registering thousands of new domains
daily for Internet-scale attacks like spam, phishing, and drive-by downloads,
emphasize the need for innovative detection methods. This paper introduces a
cutting-edge approach for identifying suspicious domains at the onset of the
registration process. The accompanying data pipeline generates crucial features
by comparing new domains to registered domains,emphasizing the crucial
similarity score. Leveraging a novel combination of Natural Language Processing
(NLP) techniques, including a pretrained Canine model, and Multilayer
Perceptron (MLP) models, our system analyzes semantic and numerical attributes,
providing a robust solution for early threat detection. This integrated
approach significantly reduces the window of vulnerability, fortifying defenses
against potential threats. The findings demonstrate the effectiveness of the
integrated approach and contribute to the ongoing efforts in developing
proactive strategies to mitigate the risks associated with illicit online
activities through the early identification of suspicious domain registrations.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Transferable Learned Image Compression-Resistant Adversarial Perturbations. (arXiv:2401.03115v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03115">http://arxiv.org/abs/2401.03115</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03115]] Transferable Learned Image Compression-Resistant Adversarial Perturbations(http://arxiv.org/abs/2401.03115)</code></li>
<li>Summary: <p>Adversarial attacks can readily disrupt the image classification system,
revealing the vulnerability of DNN-based recognition tasks. While existing
adversarial perturbations are primarily applied to uncompressed images or
compressed images by the traditional image compression method, i.e., JPEG,
limited studies have investigated the robustness of models for image
classification in the context of DNN-based image compression. With the rapid
evolution of advanced image compression, DNN-based learned image compression
has emerged as the promising approach for transmitting images in many
security-critical applications, such as cloud-based face recognition and
autonomous driving, due to its superior performance over traditional
compression. Therefore, there is a pressing need to fully investigate the
robustness of a classification system post-processed by learned image
compression. To bridge this research gap, we explore the adversarial attack on
a new pipeline that targets image classification models that utilize learned
image compressors as pre-processing modules. Furthermore, to enhance the
transferability of perturbations across various quality levels and
architectures of learned image compression models, we introduce a saliency
score-based sampling method to enable the fast generation of transferable
perturbation. Extensive experiments with popular attack methods demonstrate the
enhanced transferability of our proposed method when attacking images that have
been post-processed with different learned image compression models.
</p></li>
</ul>

<h3>Title: Real Time Human Detection by Unmanned Aerial Vehicles. (arXiv:2401.03275v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03275">http://arxiv.org/abs/2401.03275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03275]] Real Time Human Detection by Unmanned Aerial Vehicles(http://arxiv.org/abs/2401.03275)</code></li>
<li>Summary: <p>One of the most important problems in computer vision and remote sensing is
object detection, which identifies particular categories of diverse things in
pictures. Two crucial data sources for public security are the thermal infrared
(TIR) remote sensing multi-scenario photos and videos produced by unmanned
aerial vehicles (UAVs). Due to the small scale of the target, complex scene
information, low resolution relative to the viewable videos, and dearth of
publicly available labeled datasets and training models, their object detection
procedure is still difficult. A UAV TIR object detection framework for pictures
and videos is suggested in this study. The Forward-looking Infrared (FLIR)
cameras used to gather ground-based TIR photos and videos are used to create
the ``You Only Look Once'' (YOLO) model, which is based on CNN architecture.
Results indicated that in the validating task, detecting human object had an
average precision at IOU (Intersection over Union) = 0.5, which was 72.5\%,
using YOLOv7 (YOLO version 7) state of the art model \cite{1}, while the
detection speed around 161 frames per second (FPS/second). The usefulness of
the YOLO architecture is demonstrated in the application, which evaluates the
cross-detection performance of people in UAV TIR videos under a YOLOv7 model in
terms of the various UAVs' observation angles. The qualitative and quantitative
evaluation of object detection from TIR pictures and videos using deep-learning
models is supported favorably by this work.
</p></li>
</ul>

<h3>Title: Fine-tuning and Utilization Methods of Domain-specific LLMs. (arXiv:2401.02981v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02981">http://arxiv.org/abs/2401.02981</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02981]] Fine-tuning and Utilization Methods of Domain-specific LLMs(http://arxiv.org/abs/2401.02981)</code></li>
<li>Summary: <p>Recent releases of pre-trained Large Language Models (LLMs) have gained
considerable traction, yet research on fine-tuning and employing
domain-specific LLMs remains scarce. This study investigates approaches for
fine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs,
foundational models, and methods for domain-specific pre-training. Focusing on
the financial sector, it details dataset selection, preprocessing, model
choice, and considerations crucial for LLM fine-tuning in finance. Addressing
the unique characteristics of financial data, the study explores the
construction of domain-specific vocabularies and considerations for security
and regulatory compliance. In the practical application of LLM fine-tuning, the
study outlines the procedure and implementation for generating domain-specific
LLMs in finance. Various financial cases, including stock price prediction,
sentiment analysis of financial news, automated document processing, research,
information extraction, and customer service enhancement, are exemplified. The
study explores the potential of LLMs in the financial domain, identifies
limitations, and proposes directions for improvement, contributing valuable
insights for future research. Ultimately, it advances natural language
processing technology in business, suggesting proactive LLM utilization in
financial services across industries.
</p></li>
</ul>

<h3>Title: End-to-End Anti-Backdoor Learning on Images and Time Series. (arXiv:2401.03215v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03215">http://arxiv.org/abs/2401.03215</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03215]] End-to-End Anti-Backdoor Learning on Images and Time Series(http://arxiv.org/abs/2401.03215)</code></li>
<li>Summary: <p>Backdoor attacks present a substantial security concern for deep learning
models, especially those utilized in applications critical to safety and
security. These attacks manipulate model behavior by embedding a hidden trigger
during the training phase, allowing unauthorized control over the model's
output during inference time. Although numerous defenses exist for image
classification models, there is a conspicuous absence of defenses tailored for
time series data, as well as an end-to-end solution capable of training clean
models on poisoned data. To address this gap, this paper builds upon
Anti-Backdoor Learning (ABL) and introduces an innovative method, End-to-End
Anti-Backdoor Learning (E2ABL), for robust training against backdoor attacks.
Unlike the original ABL, which employs a two-stage training procedure, E2ABL
accomplishes end-to-end training through an additional classification head
linked to the shallow layers of a Deep Neural Network (DNN). This secondary
head actively identifies potential backdoor triggers, allowing the model to
dynamically cleanse these samples and their corresponding labels during
training. Our experiments reveal that E2ABL significantly improves on existing
defenses and is effective against a broad range of backdoor attacks in both
image and time series domains.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: AccidentGPT: Large Multi-Modal Foundation Model for Traffic Accident Analysis. (arXiv:2401.03040v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03040">http://arxiv.org/abs/2401.03040</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03040]] AccidentGPT: Large Multi-Modal Foundation Model for Traffic Accident Analysis(http://arxiv.org/abs/2401.03040)</code></li>
<li>Summary: <p>Traffic accident analysis is pivotal for enhancing public safety and
developing road regulations. Traditional approaches, although widely used, are
often constrained by manual analysis processes, subjective decisions, uni-modal
outputs, as well as privacy issues related to sensitive data. This paper
introduces the idea of AccidentGPT, a foundation model of traffic accident
analysis, which incorporates multi-modal input data to automatically
reconstruct the accident process video with dynamics details, and furthermore
provide multi-task analysis with multi-modal outputs. The design of the
AccidentGPT is empowered with a multi-modality prompt with feedback for
task-oriented adaptability, a hybrid training schema to leverage labelled and
unlabelled data, and a edge-cloud split configuration for data privacy. To
fully realize the functionalities of this model, we proposes several research
opportunities. This paper serves as the stepping stone to fill the gaps in
traditional approaches of traffic accident analysis and attract the research
community attention for automatic, objective, and privacy-preserving traffic
accident analysis.
</p></li>
</ul>

<h3>Title: MiniScope: Automated UI Exploration and Privacy Inconsistency Detection of MiniApps via Two-phase Iterative Hybrid Analysis. (arXiv:2401.03218v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03218">http://arxiv.org/abs/2401.03218</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03218]] MiniScope: Automated UI Exploration and Privacy Inconsistency Detection of MiniApps via Two-phase Iterative Hybrid Analysis(http://arxiv.org/abs/2401.03218)</code></li>
<li>Summary: <p>The advent of MiniApps, operating within larger SuperApps, has revolutionized
user experiences by offering a wide range of services without the need for
individual app downloads. However, this convenience has raised significant
privacy concerns, as these MiniApps often require access to sensitive data,
potentially leading to privacy violations. Our research addresses the critical
gaps in the analysis of MiniApps' privacy practices, especially focusing on
WeChat MiniApps in the Android ecosystem. Despite existing privacy regulations
and platform guidelines, there is a lack of effective mechanisms to safeguard
user privacy fully. We introduce MiniScope, a novel two-phase hybrid analysis
approach, specifically designed for the MiniApp environment. This approach
overcomes the limitations of existing static analysis techniques by
incorporating dynamic UI exploration for complete code coverage and accurate
privacy practice identification. Our methodology includes modeling UI
transition states, resolving cross-package callback control flows, and
automated iterative UI exploration. This allows for a comprehensive
understanding of MiniApps' privacy practices, addressing the unique challenges
of sub-package loading and event-driven callbacks. Our empirical evaluation of
over 120K MiniApps using MiniScope demonstrates its effectiveness in
identifying privacy inconsistencies. The results reveal significant issues,
with 5.7% of MiniApps over-collecting private data and 33.4% overclaiming data
collection. These findings emphasize the urgent need for more precise privacy
monitoring systems and highlight the responsibility of SuperApp operators to
enforce stricter privacy measures.
</p></li>
</ul>

<h2>protect</h2>
<h2>defense</h2>
<h3>Title: Data-Dependent Stability Analysis of Adversarial Training. (arXiv:2401.03156v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03156">http://arxiv.org/abs/2401.03156</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03156]] Data-Dependent Stability Analysis of Adversarial Training(http://arxiv.org/abs/2401.03156)</code></li>
<li>Summary: <p>Stability analysis is an essential aspect of studying the generalization
ability of deep learning, as it involves deriving generalization bounds for
stochastic gradient descent-based training algorithms. Adversarial training is
the most widely used defense against adversarial example attacks. However,
previous generalization bounds for adversarial training have not included
information regarding the data distribution. In this paper, we fill this gap by
providing generalization bounds for stochastic gradient descent-based
adversarial training that incorporate data distribution information. We utilize
the concepts of on-average stability and high-order approximate Lipschitz
conditions to examine how changes in data distribution and adversarial budget
can affect robust generalization gaps. Our derived generalization bounds for
both convex and non-convex losses are at least as good as the uniform
stability-based counterparts which do not include data distribution
information. Furthermore, our findings demonstrate how distribution shifts from
data poisoning attacks can impact robust generalization.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Advancing DDoS Attack Detection: A Synergistic Approach Using Deep Residual Neural Networks and Synthetic Oversampling. (arXiv:2401.03116v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03116">http://arxiv.org/abs/2401.03116</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03116]] Advancing DDoS Attack Detection: A Synergistic Approach Using Deep Residual Neural Networks and Synthetic Oversampling(http://arxiv.org/abs/2401.03116)</code></li>
<li>Summary: <p>Distributed Denial of Service (DDoS) attacks pose a significant threat to the
stability and reliability of online systems. Effective and early detection of
such attacks is pivotal for safeguarding the integrity of networks. In this
work, we introduce an enhanced approach for DDoS attack detection by leveraging
the capabilities of Deep Residual Neural Networks (ResNets) coupled with
synthetic oversampling techniques. Because of the inherent class imbalance in
many cyber-security datasets, conventional methods often struggle with false
negatives, misclassifying subtle DDoS patterns as benign. By applying the
Synthetic Minority Over-sampling Technique (SMOTE) to the CICIDS dataset, we
balance the representation of benign and malicious data points, enabling the
model to better discern intricate patterns indicative of an attack. Our deep
residual network, tailored for this specific task, further refines the
detection process. Experimental results on a real-world dataset demonstrate
that our approach achieves an accuracy of 99.98%, significantly outperforming
traditional methods. This work underscores the potential of combining advanced
data augmentation techniques with deep learning models to bolster
cyber-security defenses.
</p></li>
</ul>

<h3>Title: The 4-adic complexity of quaternary sequences with low autocorrelation and high linear complexity. (arXiv:2401.03204v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03204">http://arxiv.org/abs/2401.03204</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03204]] The 4-adic complexity of quaternary sequences with low autocorrelation and high linear complexity(http://arxiv.org/abs/2401.03204)</code></li>
<li>Summary: <p>Recently, Jiang et al. proposed several new classes of quaternary sequences
with low autocorrelation and high linear complexity by using the inverse Gray
mapping (JAMC, \textbf{69} (2023): 689--706). In this paper, we estimate the
4-adic complexity of these quaternary sequences. Our results show that these
sequences have large 4-adic complexity to resist the attack of the rational
approximation algorithm.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Preserving Silent Features for Domain Generalization. (arXiv:2401.03170v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03170">http://arxiv.org/abs/2401.03170</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03170]] Preserving Silent Features for Domain Generalization(http://arxiv.org/abs/2401.03170)</code></li>
<li>Summary: <p>Domain generalization (DG) aims to improve the generalization ability of the
model trained on several known training domains over unseen test domains.
Previous work has shown that self-supervised contrastive pre-training improves
the robustness of the model on downstream tasks. However, in this paper, we
find that self-supervised models do not exhibit better generalization
performance than supervised models pre-trained on the same dataset in the DG
setting. We argue that this is owing to the fact that the richer intra-class
discriminative features extracted by self-supervised contrastive learning,
which we term silent features, are suppressed during supervised fine-tuning.
These silent features are likely to contain features that are more
generalizable on the test domain. In this work, we model and analyze this
feature suppression phenomenon and theoretically prove that preserving silent
features can achieve lower expected test domain risk under certain conditions.
In light of this, we propose a simple yet effective method termed STEP (Silent
Feature Preservation) to improve the generalization performance of the
self-supervised contrastive learning pre-trained model by alleviating the
suppression of silent features during the supervised fine-tuning process.
Experimental results show that STEP exhibits state-of-the-art performance on
standard DG benchmarks with significant distribution shifts.
</p></li>
</ul>

<h3>Title: Distribution-aware Interactive Attention Network and Large-scale Cloud Recognition Benchmark on FY-4A Satellite Image. (arXiv:2401.03182v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03182">http://arxiv.org/abs/2401.03182</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03182]] Distribution-aware Interactive Attention Network and Large-scale Cloud Recognition Benchmark on FY-4A Satellite Image(http://arxiv.org/abs/2401.03182)</code></li>
<li>Summary: <p>Accurate cloud recognition and warning are crucial for various applications,
including in-flight support, weather forecasting, and climate research.
However, recent deep learning algorithms have predominantly focused on
detecting cloud regions in satellite imagery, with insufficient attention to
the specificity required for accurate cloud recognition. This limitation
inspired us to develop the novel FY-4A-Himawari-8 (FYH) dataset, which includes
nine distinct cloud categories and uses precise domain adaptation methods to
align 70,419 image-label pairs in terms of projection, temporal resolution, and
spatial resolution, thereby facilitating the training of supervised deep
learning networks. Given the complexity and diversity of cloud formations, we
have thoroughly analyzed the challenges inherent to cloud recognition tasks,
examining the intricate characteristics and distribution of the data. To
effectively address these challenges, we designed a Distribution-aware
Interactive-Attention Network (DIAnet), which preserves pixel-level details
through a high-resolution branch and a parallel multi-resolution cross-branch.
We also integrated a distribution-aware loss (DAL) to mitigate the imbalance
across cloud categories. An Interactive Attention Module (IAM) further enhances
the robustness of feature extraction combined with spatial and channel
information. Empirical evaluations on the FYH dataset demonstrate that our
method outperforms other cloud recognition networks, achieving superior
performance in terms of mean Intersection over Union (mIoU). The code for
implementing DIAnet is available at https://github.com/icey-zhang/DIAnet.
</p></li>
</ul>

<h3>Title: DistFormer: Enhancing Local and Global Features for Monocular Per-Object Distance Estimation. (arXiv:2401.03191v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03191">http://arxiv.org/abs/2401.03191</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03191]] DistFormer: Enhancing Local and Global Features for Monocular Per-Object Distance Estimation(http://arxiv.org/abs/2401.03191)</code></li>
<li>Summary: <p>Accurate per-object distance estimation is crucial in safety-critical
applications such as autonomous driving, surveillance, and robotics. Existing
approaches rely on two scales: local information (i.e., the bounding box
proportions) or global information, which encodes the semantics of the scene as
well as the spatial relations with neighboring objects. However, these
approaches may struggle with long-range objects and in the presence of strong
occlusions or unusual visual patterns. In this respect, our work aims to
strengthen both local and global cues. Our architecture -- named DistFormer --
builds upon three major components acting jointly: i) a robust context encoder
extracting fine-grained per-object representations; ii) a masked
encoder-decoder module exploiting self-supervision to promote the learning of
useful per-object features; iii) a global refinement module that aggregates
object representations and computes a joint, spatially-consistent estimation.
To evaluate the effectiveness of DistFormer, we conduct experiments on the
standard KITTI dataset and the large-scale NuScenes and MOTSynth datasets. Such
datasets cover various indoor/outdoor environments, changing weather
conditions, appearances, and camera viewpoints. Our comprehensive analysis
shows that DistFormer outperforms existing methods. Moreover, we further delve
into its generalization capabilities, showing its regularization benefits in
zero-shot synth-to-real transfer.
</p></li>
</ul>

<h3>Title: RustNeRF: Robust Neural Radiance Field with Low-Quality Images. (arXiv:2401.03257v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03257">http://arxiv.org/abs/2401.03257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03257]] RustNeRF: Robust Neural Radiance Field with Low-Quality Images(http://arxiv.org/abs/2401.03257)</code></li>
<li>Summary: <p>Recent work on Neural Radiance Fields (NeRF) exploits multi-view 3D
consistency, achieving impressive results in 3D scene modeling and
high-fidelity novel-view synthesis. However, there are limitations. First,
existing methods assume enough high-quality images are available for training
the NeRF model, ignoring real-world image degradation. Second, previous methods
struggle with ambiguity in the training set due to unmodeled inconsistencies
among different views. In this work, we present RustNeRF for real-world
high-quality NeRF. To improve NeRF's robustness under real-world inputs, we
train a 3D-aware preprocessing network that incorporates real-world degradation
modeling. We propose a novel implicit multi-view guidance to address
information loss during image degradation and restoration. Extensive
experiments demonstrate RustNeRF's advantages over existing approaches under
real-world degradation. The code will be released.
</p></li>
</ul>

<h3>Title: Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion. (arXiv:2401.02993v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02993">http://arxiv.org/abs/2401.02993</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02993]] Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion(http://arxiv.org/abs/2401.02993)</code></li>
<li>Summary: <p>Retrieval-based augmentations that aim to incorporate knowledge from an
external database into language models have achieved great success in various
knowledge-intensive (KI) tasks, such as question-answering and text generation.
However, integrating retrievals in non-knowledge-intensive (NKI) tasks, such as
text classification, is still challenging. Existing works focus on
concatenating retrievals to inputs as context to form the prompt-based inputs.
Unfortunately, such methods require language models to have the capability to
handle long texts. Besides, inferring such concatenated data would also consume
a significant amount of computational resources.
</p>
<p>To solve these challenges, we propose \textbf{ReFusion} in this paper, a
computation-efficient \textbf{Re}trieval representation \textbf{Fusion} with
neural architecture search. The main idea is to directly fuse the retrieval
representations into the language models. Specifically, we first propose an
online retrieval module that retrieves representations of similar sentences.
Then, we present a retrieval fusion module including two effective ranking
schemes, i.e., reranker-based scheme and ordered-mask-based scheme, to fuse the
retrieval representations with hidden states. Furthermore, we use Neural
Architecture Search (NAS) to seek the optimal fusion structure across different
layers. Finally, we conduct comprehensive experiments, and the results
demonstrate our ReFusion can achieve superior and robust performance on various
NKI tasks.
</p></li>
</ul>

<h3>Title: TimeGraphs: Graph-based Temporal Reasoning. (arXiv:2401.03134v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03134">http://arxiv.org/abs/2401.03134</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03134]] TimeGraphs: Graph-based Temporal Reasoning(http://arxiv.org/abs/2401.03134)</code></li>
<li>Summary: <p>Many real-world systems exhibit temporal, dynamic behaviors, which are
captured as time series of complex agent interactions. To perform temporal
reasoning, current methods primarily encode temporal dynamics through simple
sequence-based models. However, in general these models fail to efficiently
capture the full spectrum of rich dynamics in the input, since the dynamics is
not uniformly distributed. In particular, relevant information might be harder
to extract and computing power is wasted for processing all individual
timesteps, even if they contain no significant changes or no new information.
Here we propose TimeGraphs, a novel approach that characterizes dynamic
interactions as a hierarchical temporal graph, diverging from traditional
sequential representations. Our approach models the interactions using a
compact graph-based representation, enabling adaptive reasoning across diverse
time scales. Adopting a self-supervised method, TimeGraphs constructs a
multi-level event hierarchy from a temporal input, which is then used to
efficiently reason about the unevenly distributed dynamics. This construction
process is scalable and incremental to accommodate streaming data. We evaluate
TimeGraphs on multiple datasets with complex, dynamic agent interactions,
including a football simulator, the Resistance game, and the MOMA human
activity dataset. The results demonstrate both robustness and efficiency of
TimeGraphs on a range of temporal reasoning tasks. Our approach obtains
state-of-the-art performance and leads to a performance increase of up to 12.2%
on event prediction and recognition tasks over current approaches. Our
experiments further demonstrate a wide array of capabilities including
zero-shot generalization, robustness in case of data sparsity, and adaptability
to streaming data flow.
</p></li>
</ul>

<h3>Title: Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection. (arXiv:2401.03341v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03341">http://arxiv.org/abs/2401.03341</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03341]] Weakly Augmented Variational Autoencoder in Time Series Anomaly Detection(http://arxiv.org/abs/2401.03341)</code></li>
<li>Summary: <p>Due to their unsupervised training and uncertainty estimation, deep
Variational Autoencoders (VAEs) have become powerful tools for
reconstruction-based Time Series Anomaly Detection (TSAD). Existing VAE-based
TSAD methods, either statistical or deep, tune meta-priors to estimate the
likelihood probability for effectively capturing spatiotemporal dependencies in
the data. However, these methods confront the challenge of inherent data
scarcity, which is often the case in anomaly detection tasks. Such scarcity
easily leads to latent holes, discontinuous regions in latent space, resulting
in non-robust reconstructions on these discontinuous spaces. We propose a novel
generative framework that combines VAEs with self-supervised learning (SSL) to
address this issue.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: REE-HDSC: Recognizing Extracted Entities for the Historical Database Suriname Curacao. (arXiv:2401.02972v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02972">http://arxiv.org/abs/2401.02972</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02972]] REE-HDSC: Recognizing Extracted Entities for the Historical Database Suriname Curacao(http://arxiv.org/abs/2401.02972)</code></li>
<li>Summary: <p>We describe the project REE-HDSC and outline our efforts to improve the
quality of named entities extracted automatically from texts generated by
hand-written text recognition (HTR) software. We describe a six-step processing
pipeline and test it by processing 19th and 20th century death certificates
from the civil registry of Curacao. We find that the pipeline extracts dates
with high precision but that the precision of person name extraction is low.
Next we show how name precision extraction can be improved by retraining HTR
models with names, post-processing and by identifying and removing incorrect
names.
</p></li>
</ul>

<h3>Title: Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis. (arXiv:2401.02992v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02992">http://arxiv.org/abs/2401.02992</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02992]] Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis(http://arxiv.org/abs/2401.02992)</code></li>
<li>Summary: <p>In the evolving field of corporate sustainability, analyzing unstructured
Environmental, Social, and Governance (ESG) reports is a complex challenge due
to their varied formats and intricate content. This study introduces an
innovative methodology utilizing the "Unstructured Core Library", specifically
tailored to address these challenges by transforming ESG reports into
structured, analyzable formats. Our approach significantly advances the
existing research by offering high-precision text cleaning, adept
identification and extraction of text from images, and standardization of
tables within these reports. Emphasizing its capability to handle diverse data
types, including text, images, and tables, the method adeptly manages the
nuances of differing page layouts and report styles across industries. This
research marks a substantial contribution to the fields of industrial ecology
and corporate sustainability assessment, paving the way for the application of
advanced NLP technologies and large language models in the analysis of
corporate governance and sustainability. Our code is available at
https://github.com/linancn/TianGong-AI-Unstructure.git.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: FedTGP: Trainable Global Prototypes with Adaptive-Margin-Enhanced Contrastive Learning for Data and Model Heterogeneity in Federated Learning. (arXiv:2401.03230v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03230">http://arxiv.org/abs/2401.03230</a></li>
<li>Code URL: <a href="https://github.com/tsingz0/fedtgp">https://github.com/tsingz0/fedtgp</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03230]] FedTGP: Trainable Global Prototypes with Adaptive-Margin-Enhanced Contrastive Learning for Data and Model Heterogeneity in Federated Learning(http://arxiv.org/abs/2401.03230)</code></li>
<li>Summary: <p>Recently, Heterogeneous Federated Learning (HtFL) has attracted attention due
to its ability to support heterogeneous models and data. To reduce the high
communication cost of transmitting model parameters, a major challenge in HtFL,
prototype-based HtFL methods are proposed to solely share class
representatives, a.k.a, prototypes, among heterogeneous clients while
maintaining the privacy of clients' models. However, these prototypes are
naively aggregated into global prototypes on the server using weighted
averaging, resulting in suboptimal global knowledge which negatively impacts
the performance of clients. To overcome this challenge, we introduce a novel
HtFL approach called FedTGP, which leverages our Adaptive-margin-enhanced
Contrastive Learning (ACL) to learn Trainable Global Prototypes (TGP) on the
server. By incorporating ACL, our approach enhances prototype separability
while preserving semantic meaning. Extensive experiments with twelve
heterogeneous models demonstrate that our FedTGP surpasses state-of-the-art
methods by up to 9.08% in accuracy while maintaining the communication and
privacy advantages of prototype-based HtFL. Our code is available at
https://github.com/TsingZ0/FedTGP.
</p></li>
</ul>

<h3>Title: Distributed client selection with multi-objective in federated learning assisted Internet of Vehicles. (arXiv:2401.03159v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03159">http://arxiv.org/abs/2401.03159</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03159]] Distributed client selection with multi-objective in federated learning assisted Internet of Vehicles(http://arxiv.org/abs/2401.03159)</code></li>
<li>Summary: <p>Federated learning is an emerging distributed machine learning framework in
the Internet of Vehicles (IoV). In IoV, millions of vehicles are willing to
train the model to share their knowledge. Maintaining an active state means the
participants must update their state to the FL server in a fixed interval and
participate to next round. However, the cost by maintaining an active state is
very large when there are a huge number of participating vehicles. In this
paper, we proposed a distributed client selection scheme to reduce the cost of
maintaining the active state for all participants. The clients with the highest
evaluation are elected among the neighbours. In the evaluator, four variables
are considered including sample quantity, throughput available, computational
capability and the quality of the local dataset. We adopted fuzzy logic as the
evaluator since the closed-form solution over four variables does not exist.
Extensive simulation results show our proposal approximates the centralized
client selection in terms of accuracy and can significantly reduce the
communication overhead.
</p></li>
</ul>

<h3>Title: Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices. (arXiv:2401.03233v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03233">http://arxiv.org/abs/2401.03233</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03233]] Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices(http://arxiv.org/abs/2401.03233)</code></li>
<li>Summary: <p>Split Learning (SL) is a promising Distributed Learning approach in
electromyography (EMG) based prosthetic control, due to its applicability
within resource-constrained environments. Other learning approaches, such as
Deep Learning and Federated Learning (FL), provide suboptimal solutions, since
prosthetic devices are extremely limited in terms of processing power and
battery life. The viability of implementing SL in such scenarios is caused by
its inherent model partitioning, with clients executing the smaller model
segment. However, selecting an inadequate cut layer hinders the training
process in SL systems. This paper presents an algorithm for optimal cut layer
selection in terms of maximizing the convergence rate of the model. The
performance evaluation demonstrates that the proposed algorithm substantially
accelerates the convergence in an EMG pattern recognition task for improving
prosthetic device control.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Adaptive Boosting with Fairness-aware Reweighting Technique for Fair Classification. (arXiv:2401.03097v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03097">http://arxiv.org/abs/2401.03097</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03097]] Adaptive Boosting with Fairness-aware Reweighting Technique for Fair Classification(http://arxiv.org/abs/2401.03097)</code></li>
<li>Summary: <p>Machine learning methods based on AdaBoost have been widely applied to
various classification problems across many mission-critical applications
including healthcare, law and finance. However, there is a growing concern
about the unfairness and discrimination of data-driven classification models,
which is inevitable for classical algorithms including AdaBoost. In order to
achieve fair classification, a novel fair AdaBoost (FAB) approach is proposed
that is an interpretable fairness-improving variant of AdaBoost. We mainly
investigate binary classification problems and focus on the fairness of three
different indicators (i.e., accuracy, false positive rate and false negative
rate). By utilizing a fairness-aware reweighting technique for base
classifiers, the proposed FAB approach can achieve fair classification while
maintaining the advantage of AdaBoost with negligible sacrifice of predictive
performance. In addition, a hyperparameter is introduced in FAB to show
preferences for the fairness-accuracy trade-off. An upper bound for the target
loss function that quantifies error rate and unfairness is theoretically
derived for FAB, which provides a strict theoretical support for the
fairness-improving methods designed for AdaBoost. The effectiveness of the
proposed method is demonstrated on three real-world datasets (i.e., Adult,
COMPAS and HSLS) with respect to the three fairness indicators. The results are
accordant with theoretic analyses, and show that (i) FAB significantly improves
classification fairness at a small cost of accuracy compared with AdaBoost; and
(ii) FAB outperforms state-of-the-art fair classification methods including
equalized odds method, exponentiated gradient method, and disparate
mistreatment method in terms of the fairness-accuracy trade-off.
</p></li>
</ul>

<h3>Title: Fair Sampling in Diffusion Models through Switching Mechanism. (arXiv:2401.03140v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03140">http://arxiv.org/abs/2401.03140</a></li>
<li>Code URL: <a href="https://github.com/uzn36/attributeswitching">https://github.com/uzn36/attributeswitching</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03140]] Fair Sampling in Diffusion Models through Switching Mechanism(http://arxiv.org/abs/2401.03140)</code></li>
<li>Summary: <p>Diffusion models have shown their effectiveness in generation tasks by
well-approximating the underlying probability distribution. However, diffusion
models are known to suffer from an amplified inherent bias from the training
data in terms of fairness. While the sampling process of diffusion models can
be controlled by conditional guidance, previous works have attempted to find
empirical guidance to achieve quantitative fairness. To address this
limitation, we propose a fairness-aware sampling method called
\textit{attribute switching} mechanism for diffusion models. Without additional
training, the proposed sampling can obfuscate sensitive attributes in generated
data without relying on classifiers. We mathematically prove and experimentally
demonstrate the effectiveness of the proposed method on two key aspects: (i)
the generation of fair data and (ii) the preservation of the utility of the
generated data.
</p></li>
</ul>

<h2>interpretability</h2>
<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: Latte: Latent Diffusion Transformer for Video Generation. (arXiv:2401.03048v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03048">http://arxiv.org/abs/2401.03048</a></li>
<li>Code URL: <a href="https://github.com/maxin-cn/Latte">https://github.com/maxin-cn/Latte</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03048]] Latte: Latent Diffusion Transformer for Video Generation(http://arxiv.org/abs/2401.03048)</code></li>
<li>Summary: <p>We propose a novel Latent Diffusion Transformer, namely Latte, for video
generation. Latte first extracts spatio-temporal tokens from input videos and
then adopts a series of Transformer blocks to model video distribution in the
latent space. In order to model a substantial number of tokens extracted from
videos, four efficient variants are introduced from the perspective of
decomposing the spatial and temporal dimensions of input videos. To improve the
quality of generated videos, we determine the best practices of Latte through
rigorous experimental analysis, including video clip patch embedding, model
variants, timestep-class information injection, temporal positional embedding,
and learning strategies. Our comprehensive evaluation demonstrates that Latte
achieves state-of-the-art performance across four standard video generation
datasets, i.e., FaceForensics, SkyTimelapse, UCF101, and Taichi-HD. In
addition, we extend Latte to text-to-video generation (T2V) task, where Latte
achieves comparable results compared to recent T2V models. We strongly believe
that Latte provides valuable insights for future research on incorporating
Transformers into diffusion models for video generation.
</p></li>
</ul>

<h3>Title: SAR Despeckling via Regional Denoising Diffusion Probabilistic Model. (arXiv:2401.03122v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03122">http://arxiv.org/abs/2401.03122</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03122]] SAR Despeckling via Regional Denoising Diffusion Probabilistic Model(http://arxiv.org/abs/2401.03122)</code></li>
<li>Summary: <p>Speckle noise poses a significant challenge in maintaining the quality of
synthetic aperture radar (SAR) images, so SAR despeckling techniques have drawn
increasing attention. Despite the tremendous advancements of deep learning in
fixed-scale SAR image despeckling, these methods still struggle to deal with
large-scale SAR images. To address this problem, this paper introduces a novel
despeckling approach termed Region Denoising Diffusion Probabilistic Model
(R-DDPM) based on generative models. R-DDPM enables versatile despeckling of
SAR images across various scales, accomplished within a single training
session. Moreover, The artifacts in the fused SAR images can be avoided
effectively with the utilization of region-guided inverse sampling. Experiments
of our proposed R-DDPM on Sentinel-1 data demonstrates superior performance to
existing methods.
</p></li>
</ul>

<h3>Title: Controllable Image Synthesis of Industrial Data Using Stable Diffusion. (arXiv:2401.03152v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03152">http://arxiv.org/abs/2401.03152</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03152]] Controllable Image Synthesis of Industrial Data Using Stable Diffusion(http://arxiv.org/abs/2401.03152)</code></li>
<li>Summary: <p>Training supervised deep neural networks that perform defect detection and
segmentation requires large-scale fully-annotated datasets, which can be hard
or even impossible to obtain in industrial environments. Generative AI offers
opportunities to enlarge small industrial datasets artificially, thus enabling
the usage of state-of-the-art supervised approaches in the industry.
Unfortunately, also good generative models need a lot of data to train, while
industrial datasets are often tiny. Here, we propose a new approach for reusing
general-purpose pre-trained generative models on industrial data, ultimately
allowing the generation of self-labelled defective images. First, we let the
model learn the new concept, entailing the novel data distribution. Then, we
force it to learn to condition the generative process, producing industrial
images that satisfy well-defined topological characteristics and show defects
with a given geometry and location. To highlight the advantage of our approach,
we use the synthetic dataset to optimise a crack segmentor for a real
industrial use case. When the available data is small, we observe considerable
performance increase under several metrics, showing the method's potential in
production environments.
</p></li>
</ul>

<h3>Title: An Event-Oriented Diffusion-Refinement Method for Sparse Events Completion. (arXiv:2401.03153v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03153">http://arxiv.org/abs/2401.03153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03153]] An Event-Oriented Diffusion-Refinement Method for Sparse Events Completion(http://arxiv.org/abs/2401.03153)</code></li>
<li>Summary: <p>Event cameras or dynamic vision sensors (DVS) record asynchronous response to
brightness changes instead of conventional intensity frames, and feature
ultra-high sensitivity at low bandwidth. The new mechanism demonstrates great
advantages in challenging scenarios with fast motion and large dynamic range.
However, the recorded events might be highly sparse due to either limited
hardware bandwidth or extreme photon starvation in harsh environments. To
unlock the full potential of event cameras, we propose an inventive event
sequence completion approach conforming to the unique characteristics of event
data in both the processing stage and the output form. Specifically, we treat
event streams as 3D event clouds in the spatiotemporal domain, develop a
diffusion-based generative model to generate dense clouds in a coarse-to-fine
manner, and recover exact timestamps to maintain the temporal resolution of raw
data successfully. To validate the effectiveness of our method comprehensively,
we perform extensive experiments on three widely used public datasets with
different spatial resolutions, and additionally collect a novel event dataset
covering diverse scenarios with highly dynamic motions and under harsh
illumination. Besides generating high-quality dense events, our method can
benefit downstream applications such as object classification and intensity
frame reconstruction.
</p></li>
</ul>

<h3>Title: PosDiffNet: Positional Neural Diffusion for Point Cloud Registration in a Large Field of View with Perturbations. (arXiv:2401.03167v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03167">http://arxiv.org/abs/2401.03167</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03167]] PosDiffNet: Positional Neural Diffusion for Point Cloud Registration in a Large Field of View with Perturbations(http://arxiv.org/abs/2401.03167)</code></li>
<li>Summary: <p>Point cloud registration is a crucial technique in 3D computer vision with a
wide range of applications. However, this task can be challenging, particularly
in large fields of view with dynamic objects, environmental noise, or other
perturbations. To address this challenge, we propose a model called PosDiffNet.
Our approach performs hierarchical registration based on window-level,
patch-level, and point-level correspondence. We leverage a graph neural partial
differential equation (PDE) based on Beltrami flow to obtain high-dimensional
features and position embeddings for point clouds. We incorporate position
embeddings into a Transformer module based on a neural ordinary differential
equation (ODE) to efficiently represent patches within points. We employ the
multi-level correspondence derived from the high feature similarity scores to
facilitate alignment between point clouds. Subsequently, we use registration
methods such as SVD-based algorithms to predict the transformation using
corresponding point pairs. We evaluate PosDiffNet on several 3D point cloud
datasets, verifying that it achieves state-of-the-art (SOTA) performance for
point cloud registration in large fields of view with perturbations. The
implementation code of experiments is available at
https://github.com/AI-IT-AVs/PosDiffNet.
</p></li>
</ul>

<h3>Title: MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond. (arXiv:2401.03221v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03221">http://arxiv.org/abs/2401.03221</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03221]] MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond(http://arxiv.org/abs/2401.03221)</code></li>
<li>Summary: <p>Recently, text-to-image diffusion models become a new paradigm in image
processing fields, including content generation, image restoration and
image-to-image translation. Given a target prompt, Denoising Diffusion
Probabilistic Models (DDPM) are able to generate realistic yet eligible images.
With this appealing property, the image translation task has the potential to
be free from target image samples for supervision. By using a target text
prompt for domain adaption, the diffusion model is able to implement zero-shot
image-to-image translation advantageously. However, the sampling and inversion
processes of DDPM are stochastic, and thus the inversion process often fail to
reconstruct the input content. Specifically, the displacement effect will
gradually accumulated during the diffusion and inversion processes, which led
to the reconstructed results deviating from the source domain. To make
reconstruction explicit, we propose a prompt redescription strategy to realize
a mirror effect between the source and reconstructed image in the diffusion
model (MirrorDiffusion). More specifically, a prompt redescription mechanism is
investigated to align the text prompts with latent code at each time step of
the Denoising Diffusion Implicit Models (DDIM) inversion to pursue a
structure-preserving reconstruction. With the revised DDIM inversion,
MirrorDiffusion is able to realize accurate zero-shot image translation by
editing optimized text prompts and latent code. Extensive experiments
demonstrate that MirrorDiffusion achieves superior performance over the
state-of-the-art methods on zero-shot image translation benchmarks by clear
margins and practical model stability.
</p></li>
</ul>

<h3>Title: Image Inpainting via Tractable Steering of Diffusion Models. (arXiv:2401.03349v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03349">http://arxiv.org/abs/2401.03349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03349]] Image Inpainting via Tractable Steering of Diffusion Models(http://arxiv.org/abs/2401.03349)</code></li>
<li>Summary: <p>Diffusion models are the current state of the art for generating
photorealistic images. Controlling the sampling process for constrained image
generation tasks such as inpainting, however, remains challenging since exact
conditioning on such constraints is intractable. While existing methods use
various techniques to approximate the constrained posterior, this paper
proposes to exploit the ability of Tractable Probabilistic Models (TPMs) to
exactly and efficiently compute the constrained posterior, and to leverage this
signal to steer the denoising process of diffusion models. Specifically, this
paper adopts a class of expressive TPMs termed Probabilistic Circuits (PCs).
Building upon prior advances, we further scale up PCs and make them capable of
guiding the image generation process of diffusion models. Empirical results
suggest that our approach can consistently improve the overall quality and
semantic coherence of inpainted images across three natural image datasets
(i.e., CelebA-HQ, ImageNet, and LSUN) with only ~10% additional computational
overhead brought by the TPM. Further, with the help of an image encoder and
decoder, our method can readily accept semantic constraints on specific regions
of the image, which opens up the potential for more controlled image generation
tasks. In addition to proposing a new framework for constrained image
generation, this paper highlights the benefit of more tractable models and
motivates the development of expressive TPMs.
</p></li>
</ul>

<h3>Title: The Rise of Diffusion Models in Time-Series Forecasting. (arXiv:2401.03006v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03006">http://arxiv.org/abs/2401.03006</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03006]] The Rise of Diffusion Models in Time-Series Forecasting(http://arxiv.org/abs/2401.03006)</code></li>
<li>Summary: <p>This survey delves into the application of diffusion models in time-series
forecasting. Diffusion models are demonstrating state-of-the-art results in
various fields of generative AI. The paper includes comprehensive background
information on diffusion models, detailing their conditioning methods and
reviewing their use in time-series forecasting. The analysis covers 11 specific
time-series implementations, the intuition and theory behind them, the
effectiveness on different datasets, and a comparison among each other. Key
contributions of this work are the thorough exploration of diffusion models'
applications in time-series forecasting and a chronologically ordered overview
of these models. Additionally, the paper offers an insightful discussion on the
current state-of-the-art in this domain and outlines potential future research
directions. This serves as a valuable resource for researchers in AI and
time-series analysis, offering a clear view of the latest advancements and
future potential of diffusion models.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: CATFace: Cross-Attribute-Guided Transformer with Self-Attention Distillation for Low-Quality Face Recognition. (arXiv:2401.03037v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03037">http://arxiv.org/abs/2401.03037</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03037]] CATFace: Cross-Attribute-Guided Transformer with Self-Attention Distillation for Low-Quality Face Recognition(http://arxiv.org/abs/2401.03037)</code></li>
<li>Summary: <p>Although face recognition (FR) has achieved great success in recent years, it
is still challenging to accurately recognize faces in low-quality images due to
the obscured facial details. Nevertheless, it is often feasible to make
predictions about specific soft biometric (SB) attributes, such as gender, and
baldness even in dealing with low-quality images. In this paper, we propose a
novel multi-branch neural network that leverages SB attribute information to
boost the performance of FR. To this end, we propose a cross-attribute-guided
transformer fusion (CATF) module that effectively captures the long-range
dependencies and relationships between FR and SB feature representations. The
synergy created by the reciprocal flow of information in the dual
cross-attention operations of the proposed CATF module enhances the performance
of FR. Furthermore, we introduce a novel self-attention distillation framework
that effectively highlights crucial facial regions, such as landmarks by
aligning low-quality images with those of their high-quality counterparts in
the feature space. The proposed self-attention distillation regularizes our
network to learn a unified quality-invariant feature representation in
unconstrained environments. We conduct extensive experiments on various FR
benchmarks varying in quality. Experimental results demonstrate the superiority
of our FR method compared to state-of-the-art FR studies.
</p></li>
</ul>

<h3>Title: Explicit Visual Prompts for Visual Object Tracking. (arXiv:2401.03142v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03142">http://arxiv.org/abs/2401.03142</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03142]] Explicit Visual Prompts for Visual Object Tracking(http://arxiv.org/abs/2401.03142)</code></li>
<li>Summary: <p>How to effectively exploit spatio-temporal information is crucial to capture
target appearance changes in visual tracking. However, most deep learning-based
trackers mainly focus on designing a complicated appearance model or template
updating strategy, while lacking the exploitation of context between
consecutive frames and thus entailing the \textit{when-and-how-to-update}
dilemma. To address these issues, we propose a novel explicit visual prompts
framework for visual tracking, dubbed \textbf{EVPTrack}. Specifically, we
utilize spatio-temporal tokens to propagate information between consecutive
frames without focusing on updating templates. As a result, we cannot only
alleviate the challenge of \textit{when-to-update}, but also avoid the
hyper-parameters associated with updating strategies. Then, we utilize the
spatio-temporal tokens to generate explicit visual prompts that facilitate
inference in the current frame. The prompts are fed into a transformer encoder
together with the image tokens without additional processing. Consequently, the
efficiency of our model is improved by avoiding \textit{how-to-update}. In
addition, we consider multi-scale information as explicit visual prompts,
providing multiscale template features to enhance the EVPTrack's ability to
handle target scale changes. Extensive experimental results on six benchmarks
(i.e., LaSOT, LaSOT\rm $_{ext}$, GOT-10k, UAV123, TrackingNet, and TNL2K.)
validate that our EVPTrack can achieve competitive performance at a real-time
speed by effectively exploiting both spatio-temporal and multi-scale
information. Code and models are available at
https://github.com/GXNU-ZhongLab/EVPTrack.
</p></li>
</ul>

<h3>Title: Multimodal Informative ViT: Information Aggregation and Distribution for Hyperspectral and LiDAR Classification. (arXiv:2401.03179v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03179">http://arxiv.org/abs/2401.03179</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03179]] Multimodal Informative ViT: Information Aggregation and Distribution for Hyperspectral and LiDAR Classification(http://arxiv.org/abs/2401.03179)</code></li>
<li>Summary: <p>In multimodal land cover classification (MLCC), a common challenge is the
redundancy in data distribution, where irrelevant information from multiple
modalities can hinder the effective integration of their unique features. To
tackle this, we introduce the Multimodal Informative Vit (MIVit), a system with
an innovative information aggregate-distributing mechanism. This approach
redefines redundancy levels and integrates performance-aware elements into the
fused representation, facilitating the learning of semantics in both forward
and backward directions. MIVit stands out by significantly reducing redundancy
in the empirical distribution of each modality's separate and fused features.
It employs oriented attention fusion (OAF) for extracting shallow local
features across modalities in horizontal and vertical dimensions, and a
Transformer feature extractor for extracting deep global features through
long-range attention. We also propose an information aggregation constraint
(IAC) based on mutual information, designed to remove redundant information and
preserve complementary information within embedded features. Additionally, the
information distribution flow (IDF) in MIVit enhances performance-awareness by
distributing global classification information across different modalities'
feature maps. This architecture also addresses missing modality challenges with
lightweight independent modality classifiers, reducing the computational load
typically associated with Transformers. Our results show that MIVit's
bidirectional aggregate-distributing mechanism between modalities is highly
effective, achieving an average overall accuracy of 95.56% across three
multimodal datasets. This performance surpasses current state-of-the-art
methods in MLCC. The code for MIVit is accessible at
https://github.com/icey-zhang/MIViT.
</p></li>
</ul>

<h3>Title: UnetTSF: A Better Performance Linear Complexity Time Series Prediction Model. (arXiv:2401.03001v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03001">http://arxiv.org/abs/2401.03001</a></li>
<li>Code URL: <a href="https://github.com/lichuustc/unettsf">https://github.com/lichuustc/unettsf</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03001]] UnetTSF: A Better Performance Linear Complexity Time Series Prediction Model(http://arxiv.org/abs/2401.03001)</code></li>
<li>Summary: <p>Recently, Transformer-base models have made significant progress in the field
of time series prediction which have achieved good results and become baseline
models beyond Dlinear. The paper proposes an U-Net time series prediction model
(UnetTSF) with linear complexity, which adopts the U-Net architecture. We are
the first to use FPN technology to extract features from time series data,
replacing the method of decomposing time series data into trend and seasonal
terms, while designing a fusion structure suitable for time series data. After
testing on 8 open-source datasets, compared to the best linear model DLiner.
Out of 32 testing projects, 31 achieved the best results. The average decrease
in mse is 10.1%, while the average decrease in mae is 9.1%. Compared with the
complex transformer-base PatchTST, UnetTSF obtained 9 optimal results for mse
and 15 optimal results for mae in 32 testing projects.
</p></li>
</ul>

<h3>Title: Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection. (arXiv:2401.03322v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03322">http://arxiv.org/abs/2401.03322</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03322]] Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection(http://arxiv.org/abs/2401.03322)</code></li>
<li>Summary: <p>This paper introduces a hybrid attention and autoencoder (AE) model for
unsupervised online anomaly detection in time series. The autoencoder captures
local structural patterns in short embeddings, while the attention model learns
long-term features, facilitating parallel computing with positional encoding.
Unique in its approach, our proposed hybrid model combines attention and
autoencoder for the first time in time series anomaly detection. It employs an
attention-based mechanism, akin to the deep transformer model, with key
architectural modifications for predicting the next time step window in the
autoencoder's latent space. The model utilizes a threshold from the validation
dataset for anomaly detection and introduces an alternative method based on
analyzing the first statistical moment of error, improving accuracy without
dependence on a validation dataset. Evaluation on diverse real-world benchmark
datasets and comparing with other well-established models, confirms the
effectiveness of our proposed model in anomaly detection.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: A Surrogate-Assisted Extended Generative Adversarial Network for Parameter Optimization in Free-Form Metasurface Design. (arXiv:2401.02961v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02961">http://arxiv.org/abs/2401.02961</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02961]] A Surrogate-Assisted Extended Generative Adversarial Network for Parameter Optimization in Free-Form Metasurface Design(http://arxiv.org/abs/2401.02961)</code></li>
<li>Summary: <p>Metasurfaces have widespread applications in fifth-generation (5G) microwave
communication. Among the metasurface family, free-form metasurfaces excel in
achieving intricate spectral responses compared to regular-shape counterparts.
However, conventional numerical methods for free-form metasurfaces are
time-consuming and demand specialized expertise. Alternatively, recent studies
demonstrate that deep learning has great potential to accelerate and refine
metasurface designs. Here, we present XGAN, an extended generative adversarial
network (GAN) with a surrogate for high-quality free-form metasurface designs.
The proposed surrogate provides a physical constraint to XGAN so that XGAN can
accurately generate metasurfaces monolithically from input spectral responses.
In comparative experiments involving 20000 free-form metasurface designs, XGAN
achieves 0.9734 average accuracy and is 500 times faster than the conventional
methodology. This method facilitates the metasurface library building for
specific spectral responses and can be extended to various inverse design
problems, including optical metamaterials, nanophotonic devices, and drug
discovery.
</p></li>
</ul>

<h3>Title: A Physics-guided Generative AI Toolkit for Geophysical Monitoring. (arXiv:2401.03131v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03131">http://arxiv.org/abs/2401.03131</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03131]] A Physics-guided Generative AI Toolkit for Geophysical Monitoring(http://arxiv.org/abs/2401.03131)</code></li>
<li>Summary: <p>Full-waveform inversion (FWI) plays a vital role in geoscience to explore the
subsurface. It utilizes the seismic wave to image the subsurface velocity map.
As the machine learning (ML) technique evolves, the data-driven approaches
using ML for FWI tasks have emerged, offering enhanced accuracy and reduced
computational cost compared to traditional physics-based methods. However, a
common challenge in geoscience, the unprivileged data, severely limits ML
effectiveness. The issue becomes even worse during model pruning, a step
essential in geoscience due to environmental complexities. To tackle this, we
introduce the EdGeo toolkit, which employs a diffusion-based model guided by
physics principles to generate high-fidelity velocity maps. The toolkit uses
the acoustic wave equation to generate corresponding seismic waveform data,
facilitating the fine-tuning of pruned ML models. Our results demonstrate
significant improvements in SSIM scores and reduction in both MAE and MSE
across various pruning ratios. Notably, the ML model fine-tuned using data
generated by EdGeo yields superior quality of velocity maps, especially in
representing unprivileged features, outperforming other existing methods.
</p></li>
</ul>

<h3>Title: Deep Anomaly Detection in Text. (arXiv:2401.02971v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02971">http://arxiv.org/abs/2401.02971</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02971]] Deep Anomaly Detection in Text(http://arxiv.org/abs/2401.02971)</code></li>
<li>Summary: <p>Deep anomaly detection methods have become increasingly popular in recent
years, with methods like Stacked Autoencoders, Variational Autoencoders, and
Generative Adversarial Networks greatly improving the state-of-the-art. Other
methods rely on augmenting classical models (such as the One-Class Support
Vector Machine), by learning an appropriate kernel function using Neural
Networks. Recent developments in representation learning by self-supervision
are proving to be very beneficial in the context of anomaly detection. Inspired
by the advancements in anomaly detection using self-supervised learning in the
field of computer vision, this thesis aims to develop a method for detecting
anomalies by exploiting pretext tasks tailored for text corpora. This approach
greatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG
News, for both semi-supervised and unsupervised anomaly detection, thus proving
the potential for self-supervised anomaly detectors in the field of natural
language processing.
</p></li>
</ul>

<h3>Title: Learning from a Generative AI Predecessor -- The Many Motivations for Interacting with Conversational Agents. (arXiv:2401.02978v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02978">http://arxiv.org/abs/2401.02978</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02978]] Learning from a Generative AI Predecessor -- The Many Motivations for Interacting with Conversational Agents(http://arxiv.org/abs/2401.02978)</code></li>
<li>Summary: <p>For generative AI to succeed, how engaging a conversationalist must it be?
For almost sixty years, some conversational agents have responded to any
question or comment to keep a conversation going. In recent years, several
utilized machine learning or sophisticated language processing, such as Tay,
Xiaoice, Zo, Hugging Face, Kuki, and Replika. Unlike generative AI, they
focused on engagement, not expertise. Millions of people were motivated to
engage with them. What were the attractions? Will generative AI do better if it
is equally engaging, or should it be less engaging? Prior to the emergence of
generative AI, we conducted a large-scale quantitative and qualitative analysis
to learn what motivated millions of people to engage with one such 'virtual
companion,' Microsoft's Zo. We examined the complete chat logs of 2000
anonymized people. We identified over a dozen motivations that people had for
interacting with this software. Designers learned different ways to increase
engagement. Generative conversational AI does not yet have a clear revenue
model to address its high cost. It might benefit from being more engaging, even
as it supports productivity and creativity. Our study and analysis point to
opportunities and challenges.
</p></li>
</ul>

<h3>Title: Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods. (arXiv:2401.02986v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02986">http://arxiv.org/abs/2401.02986</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02986]] Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods(http://arxiv.org/abs/2401.02986)</code></li>
<li>Summary: <p>Organizations face the challenge of ensuring compliance with an increasing
amount of requirements from various regulatory documents. Which requirements
are relevant depends on aspects such as the geographic location of the
organization, its domain, size, and business processes. Considering these
contextual factors, as a first step, relevant documents (e.g., laws,
regulations, directives, policies) are identified, followed by a more detailed
analysis of which parts of the identified documents are relevant for which step
of a given business process. Nowadays the identification of regulatory
requirements relevant to business processes is mostly done manually by domain
and legal experts, posing a tremendous effort on them, especially for a large
number of regulatory documents which might frequently change. Hence, this work
examines how legal and domain experts can be assisted in the assessment of
relevant requirements. For this, we compare an embedding-based NLP ranking
method, a generative AI method using GPT-4, and a crowdsourced method with the
purely manual method of creating relevancy labels by experts. The proposed
methods are evaluated based on two case studies: an Australian insurance case
created with domain experts and a global banking use case, adapted from SAP
Signavio's workflow example of an international guideline. A gold standard is
created for both BPMN2.0 processes and matched to real-world textual
requirements from multiple regulatory documents. The evaluation and discussion
provide insights into strengths and weaknesses of each method regarding
applicability, automation, transparency, and reproducibility and provide
guidelines on which method combinations will maximize benefits for given
characteristics such as process usage, impact, and dynamics of an application
scenario.
</p></li>
</ul>

<h3>Title: PIXAR: Auto-Regressive Language Modeling in Pixel Space. (arXiv:2401.03321v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03321">http://arxiv.org/abs/2401.03321</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03321]] PIXAR: Auto-Regressive Language Modeling in Pixel Space(http://arxiv.org/abs/2401.03321)</code></li>
<li>Summary: <p>Recent works showed the possibility of building open-vocabulary large
language models (LLMs) that directly operate on pixel representations and are
implemented as encoder-decoder models that reconstruct masked image patches of
rendered text. However, these pixel-based LLMs are limited to autoencoding
tasks and cannot generate new text as images. As such, they cannot be used for
open-answer or generative language tasks. In this work, we overcome this
limitation and introduce PIXAR, the first pixel-based autoregressive LLM that
does not rely on a pre-defined vocabulary for both input and output text.
Consisting of only a decoder, PIXAR can answer free-form generative tasks while
keeping the text representation learning performance on par with previous
encoder-decoder models. Furthermore, we highlight the challenges to
autoregressively generate non-blurred text as images and link this to the usual
maximum likelihood objective. We propose a simple adversarial pretraining that
significantly improves the readability and performance of PIXAR making it
comparable to GPT2 on short text generation tasks. This paves the way to
building open-vocabulary LLMs that are usable for free-form generative tasks
and questions the necessity of the usual symbolic input representation -- text
as tokens -- for these challenging tasks.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: Incorporating Visual Experts to Resolve the Information Loss in Multimodal Large Language Models. (arXiv:2401.03105v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03105">http://arxiv.org/abs/2401.03105</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03105]] Incorporating Visual Experts to Resolve the Information Loss in Multimodal Large Language Models(http://arxiv.org/abs/2401.03105)</code></li>
<li>Summary: <p>Multimodal Large Language Models (MLLMs) are experiencing rapid growth,
yielding a plethora of noteworthy contributions in recent months. The
prevailing trend involves adopting data-driven methodologies, wherein diverse
instruction-following datasets are collected. However, a prevailing challenge
persists in these approaches, specifically in relation to the limited visual
perception ability, as CLIP-like encoders employed for extracting visual
information from inputs. Though these encoders are pre-trained on billions of
image-text pairs, they still grapple with the information loss dilemma, given
that textual captions only partially capture the contents depicted in images.
To address this limitation, this paper proposes to improve the visual
perception ability of MLLMs through a mixture-of-experts knowledge enhancement
mechanism. Specifically, we introduce a novel method that incorporates
multi-task encoders and visual tools into the existing MLLMs training and
inference pipeline, aiming to provide a more comprehensive and accurate
summarization of visual inputs. Extensive experiments have evaluated its
effectiveness of advancing MLLMs, showcasing improved visual perception
achieved through the integration of visual experts.
</p></li>
</ul>

<h3>Title: MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing. (arXiv:2401.03190v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03190">http://arxiv.org/abs/2401.03190</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03190]] MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing(http://arxiv.org/abs/2401.03190)</code></li>
<li>Summary: <p>Large language models are known for encoding a vast amount of factual
knowledge, but they often becomes outdated due to the ever-changing nature of
external information. A promising solution to this challenge is the utilization
of model editing methods to update the knowledge in an efficient manner.
However, the majority of existing model editing techniques are limited to
monolingual frameworks, thus failing to address the crucial issue of
cross-lingual knowledge synchronization for multilingual models. To tackle this
problem, we propose a simple yet effective method that trains multilingual
patch neuron to store cross-lingual knowledge. It can be easily adapted to
existing approaches to enhance their cross-lingual editing capabilities. To
evaluate our method, we conduct experiments using both the XNLI dataset and a
self-constructed XFEVER dataset. Experimental results demonstrate that our
proposed method achieves improved performance in cross-lingual editing tasks
without requiring excessive modifications to the original methodology, thereby
showcasing its user-friendly characteristics. Codes will be released soon.
</p></li>
</ul>

<h3>Title: 3DMIT: 3D Multi-modal Instruction Tuning for Scene Understanding. (arXiv:2401.03201v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03201">http://arxiv.org/abs/2401.03201</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03201]] 3DMIT: 3D Multi-modal Instruction Tuning for Scene Understanding(http://arxiv.org/abs/2401.03201)</code></li>
<li>Summary: <p>The remarkable potential of multi-modal large language models (MLLMs) in
comprehending both vision and language information has been widely
acknowledged. However, the scarcity of 3D scenes-language pairs in comparison
to their 2D counterparts, coupled with the inadequacy of existing approaches in
understanding of 3D scenes by LLMs, poses a significant challenge. In response,
we collect and construct an extensive dataset comprising 75K
instruction-response pairs tailored for 3D scenes. This dataset addresses tasks
related to 3D VQA, 3D grounding, and 3D conversation. To further enhance the
integration of 3D spatial information into LLMs, we introduce a novel and
efficient prompt tuning paradigm, 3DMIT. This paradigm eliminates the alignment
stage between 3D scenes and language and extends the instruction prompt with
the 3D modality information including the entire scene and segmented objects.
We evaluate the effectiveness of our method across diverse tasks in the 3D
scene domain and find that our approach serves as a strategic means to enrich
LLMs' comprehension of the 3D world. Our code is available at
https://github.com/staymylove/3DMIT.
</p></li>
</ul>

<h3>Title: Large Language Models as Visual Cross-Domain Learners. (arXiv:2401.03253v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03253">http://arxiv.org/abs/2401.03253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03253]] Large Language Models as Visual Cross-Domain Learners(http://arxiv.org/abs/2401.03253)</code></li>
<li>Summary: <p>Recent advances achieved by deep learning models rely on the independent and
identically distributed assumption, hindering their applications in real-world
scenarios with domain shifts. To address the above issues, cross-domain
learning aims at extracting domain-invariant knowledge to reduce the domain
shift between training and testing data. However, in visual cross-domain
learning, traditional methods concentrate solely on the image modality,
neglecting the use of the text modality to alleviate the domain shift. In this
work, we propose Large Language models as Visual cross-dOmain learners (LLaVO).
LLaVO uses vision-language models to convert images into detailed textual
descriptions. A large language model is then finetuned on textual descriptions
of the source/target domain generated by a designed instruction template.
Extensive experimental results on various cross-domain tasks under the domain
generalization and unsupervised domain adaptation settings have demonstrated
the effectiveness of the proposed method.
</p></li>
</ul>

<h3>Title: Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02974">http://arxiv.org/abs/2401.02974</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02974]] Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online(http://arxiv.org/abs/2401.02974)</code></li>
<li>Summary: <p>This paper examines the efficacy of utilizing large language models (LLMs) to
detect public threats posted online. Amid rising concerns over the spread of
threatening rhetoric and advance notices of violence, automated content
analysis techniques may aid in early identification and moderation. Custom data
collection tools were developed to amass post titles from a popular Korean
online community, comprising 500 non-threat examples and 20 threats. Various
LLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as
either "threat" or "safe." Statistical analysis found all models demonstrated
strong accuracy, passing chi-square goodness of fit tests for both threat and
non-threat identification. GPT-4 performed best overall with 97.9% non-threat
and 100% threat accuracy. Affordability analysis also showed PaLM API pricing
as highly cost-efficient. The findings indicate LLMs can effectively augment
human content moderation at scale to help mitigate emerging online risks.
However, biases, transparency, and ethical oversight remain vital
considerations before real-world implementation.
</p></li>
</ul>

<h3>Title: BIBench: Benchmarking Data Analysis Knowledge of Large Language Models. (arXiv:2401.02982v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02982">http://arxiv.org/abs/2401.02982</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02982]] BIBench: Benchmarking Data Analysis Knowledge of Large Language Models(http://arxiv.org/abs/2401.02982)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of tasks. However, their proficiency and reliability in the
specialized domain of Data Analysis, particularly with a focus on data-driven
thinking, remain uncertain. To bridge this gap, we introduce BIBench, a
comprehensive benchmark designed to evaluate the data analysis capabilities of
LLMs within the context of Business Intelligence (BI). BIBench assesses LLMs
across three dimensions: 1) BI foundational knowledge, evaluating the models'
numerical reasoning and familiarity with financial concepts; 2) BI knowledge
application, determining the models' ability to quickly comprehend textual
information and generate analysis questions from multiple views; and 3) BI
technical skills, examining the models' use of technical knowledge to address
real-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning
three categories of task types: classification, extraction, and generation.
Additionally, we've developed BIChat, a domain-specific dataset with over a
million data points, to fine-tune LLMs. We will release BIBenchmark, BIChat,
and the evaluation scripts at \url{https://github.com/cubenlp/BIBench}. This
benchmark aims to provide a measure for in-depth analysis of LLM abilities and
foster the advancement of LLMs in the field of data analysis.
</p></li>
</ul>

<h3>Title: Large Language Models in Mental Health Care: a Scoping Review. (arXiv:2401.02984v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02984">http://arxiv.org/abs/2401.02984</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02984]] Large Language Models in Mental Health Care: a Scoping Review(http://arxiv.org/abs/2401.02984)</code></li>
<li>Summary: <p>Objective: The growing use of large language models (LLMs) stimulates a need
for a comprehensive review of their applications and outcomes in mental health
care contexts. This scoping review aims to critically analyze the existing
development and applications of LLMs in mental health care, highlighting their
successes and identifying their challenges and limitations in these specialized
fields. Materials and Methods: A broad literature search was conducted in
November 2023 using six databases (PubMed, Web of Science, Google Scholar,
arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred
Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A
total of 313 publications were initially identified, and after applying the
study inclusion criteria, 34 publications were selected for the final review.
Results: We identified diverse applications of LLMs in mental health care,
including diagnosis, therapy, patient engagement enhancement, etc. Key
challenges include data availability and reliability, nuanced handling of
mental states, and effective evaluation methods. Despite successes in accuracy
and accessibility improvement, gaps in clinical applicability and ethical
considerations were evident, pointing to the need for robust data, standardized
evaluations, and interdisciplinary collaboration. Conclusion: LLMs show
promising potential in advancing mental health care, with applications in
diagnostics, and patient support. Continued advancements depend on
collaborative, multidisciplinary efforts focused on framework enhancement,
rigorous dataset development, technological refinement, and ethical integration
to ensure the effective and safe application of LLMs in mental health care.
</p></li>
</ul>

<h3>Title: Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education. (arXiv:2401.02985v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02985">http://arxiv.org/abs/2401.02985</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02985]] Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education(http://arxiv.org/abs/2401.02985)</code></li>
<li>Summary: <p>The rapid evolution of artificial intelligence (AI), especially in the domain
of Large Language Models (LLMs) and generative AI, has opened new avenues for
application across various fields, yet its role in business education remains
underexplored. This study introduces the first benchmark to assess the
performance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and
GPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models
(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission
process for graduate business programs. Our analysis shows that most LLMs
outperform human candidates, with GPT-4 Turbo not only outperforming the other
models but also surpassing the average scores of graduate students at top
business schools. Through a case study, this research examines GPT-4 Turbo's
ability to explain answers, evaluate responses, identify errors, tailor
instructions, and generate alternative scenarios. The latest LLM versions,
GPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in
reasoning tasks compared to their predecessors, underscoring their potential
for complex problem-solving. While AI's promise in education, assessment, and
tutoring is clear, challenges remain. Our study not only sheds light on LLMs'
academic potential but also emphasizes the need for careful development and
application of AI in education. As AI technology advances, it is imperative to
establish frameworks and protocols for AI interaction, verify the accuracy of
AI-generated content, ensure worldwide access for diverse learners, and create
an educational environment where AI supports human expertise. This research
sets the stage for further exploration into the responsible use of AI to enrich
educational experiences and improve exam preparation and assessment methods.
</p></li>
</ul>

<h3>Title: Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02987">http://arxiv.org/abs/2401.02987</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02987]] Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach(http://arxiv.org/abs/2401.02987)</code></li>
<li>Summary: <p>The emergence of pretrained models has significantly impacted from Natural
Language Processing (NLP) and Computer Vision to relational datasets.
Traditionally, these models are assessed through fine-tuned downstream tasks.
However, this raises the question of how to evaluate these models more
efficiently and more effectively. In this study, we explore a novel approach
where we leverage the meta features associated with each entity as a source of
worldly knowledge and employ entity representations from the models. We propose
using the consistency between these representations and the meta features as a
metric for evaluating pretrained models. Our method's effectiveness is
demonstrated across various domains, including models with relational datasets,
large language models and images models.
</p></li>
</ul>

<h3>Title: Blar-SQL: Faster, Stronger, Smaller NL2SQL. (arXiv:2401.02997v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.02997">http://arxiv.org/abs/2401.02997</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.02997]] Blar-SQL: Faster, Stronger, Smaller NL2SQL(http://arxiv.org/abs/2401.02997)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have gained considerable notoriety in the field
of natural language to SQL tasks (NL2SQL). In this study, we show how task
decomposition can greatly benefit LLMs in database understanding and query
generation in order to answer human questions with an SQL query.
</p>
<p>We fined-tuned open source models, specifically Llama-2 and Code Llama, by
combining 2 different models each designated to focus on one of two tasks in
order to leverage each model's core competency to further increase the accuracy
of the final SQL query.
</p>
<p>We propose a new framework to divide the schema into chunks in order to fit
more information into a limited context. Our results are comparable with those
obtained by GPT-4 at the same time being 135 times smaller, 90 times faster and
more than 100 times cheaper than GPT-4.
</p></li>
</ul>

<h3>Title: Examining Forgetting in Continual Pre-training of Aligned Large Language Models. (arXiv:2401.03129v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03129">http://arxiv.org/abs/2401.03129</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03129]] Examining Forgetting in Continual Pre-training of Aligned Large Language Models(http://arxiv.org/abs/2401.03129)</code></li>
<li>Summary: <p>Recent advances in Large Language Models (LLMs) have exhibited remarkable
proficiency across various tasks. Given the potent applications of LLMs in
numerous fields, there has been a surge in LLM development. In developing LLMs,
a common practice involves continual pre-training on previously fine-tuned
models. However, this can lead to catastrophic forgetting. In our work, we
investigate the phenomenon of forgetting that occurs during continual
pre-training on an existing fine-tuned LLM. We evaluate the impact of
continuous pre-training on the fine-tuned LLM across various dimensions,
including output format, knowledge, and reliability. Experiment results
highlight the non-trivial challenge of addressing catastrophic forgetting
during continual pre-training, especially the repetition issue.
</p></li>
</ul>

<h3>Title: Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification. (arXiv:2401.03158v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03158">http://arxiv.org/abs/2401.03158</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03158]] Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification(http://arxiv.org/abs/2401.03158)</code></li>
<li>Summary: <p>Short Text Classification (STC) is crucial for processing and comprehending
the brief but substantial content prevalent on contemporary digital platforms.
The STC encounters difficulties in grasping semantic and syntactic intricacies,
an issue that is apparent in traditional pre-trained language models. Although
Graph Convolutional Networks enhance performance by integrating external
knowledge bases, these methods are limited by the quality and extent of the
knowledge applied. Recently, the emergence of Large Language Models (LLMs) and
Chain-of-Thought (CoT) has significantly improved the performance of complex
reasoning tasks. However, some studies have highlighted the limitations of
their application in fundamental NLP tasks. Consequently, this study sought to
employ CoT to investigate the capabilities of LLMs in STC tasks. This study
introduces Quartet Logic: A Four-Step Reasoning (QLFR) framework. This
framework primarily incorporates Syntactic and Semantic Enrichment CoT,
effectively decomposing the STC task into four distinct steps: (i) essential
concept identification, (ii) common-sense knowledge retrieval, (iii) text
rewriting, and (iv) classification. This elicits the inherent knowledge and
abilities of LLMs to address the challenges in STC. Surprisingly, we found that
QLFR can also improve the performance of smaller models. Therefore, we
developed a CoT-Driven Multi-task learning (QLFR-CML) method to facilitate the
knowledge transfer from LLMs to smaller models. Extensive experimentation
across six short-text benchmarks validated the efficacy of the proposed
methods. Notably, QLFR achieved state-of-the-art performance on all datasets,
with significant improvements, particularly on the Ohsumed and TagMyNews
datasets.
</p></li>
</ul>

<h3>Title: {\delta}-CAUSAL: Exploring Defeasibility in Causal Reasoning. (arXiv:2401.03183v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03183">http://arxiv.org/abs/2401.03183</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03183]] {\delta}-CAUSAL: Exploring Defeasibility in Causal Reasoning(http://arxiv.org/abs/2401.03183)</code></li>
<li>Summary: <p>Defeasibility in causal reasoning implies that the causal relationship
between cause and effect can be strengthened or weakened. Namely, the causal
strength between cause and effect should increase or decrease with the
incorporation of strengthening arguments (supporters) or weakening arguments
(defeaters), respectively. However, existing works ignore defeasibility in
causal reasoning and fail to evaluate existing causal strength metrics in
defeasible settings. In this work, we present {\delta}-CAUSAL, the first
benchmark dataset for studying defeasibility in causal reasoning.
{\delta}-CAUSAL includes around 11K events spanning ten domains, featuring
defeasible causality pairs, i.e., cause-effect pairs accompanied by supporters
and defeaters. We further show current causal strength metrics fail to reflect
the change of causal strength with the incorporation of supporters or defeaters
in {\delta}-CAUSAL. To this end, we propose CESAR (Causal Embedding aSsociation
with Attention Rating), a metric that measures causal strength based on
token-level causal relationships. CESAR achieves a significant 69.7% relative
improvement over existing metrics, increasing from 47.2% to 80.1% in capturing
the causal strength change brought by supporters and defeaters. We further
demonstrate even Large Language Models (LLMs) like GPT-3.5 still lag 4.5 and
10.7 points behind humans in generating supporters and defeaters, emphasizing
the challenge posed by {\delta}-CAUSAL.
</p></li>
</ul>

<h3>Title: The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models. (arXiv:2401.03205v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03205">http://arxiv.org/abs/2401.03205</a></li>
<li>Code URL: <a href="https://github.com/rucaibox/halueval-2.0">https://github.com/rucaibox/halueval-2.0</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03205]] The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models(http://arxiv.org/abs/2401.03205)</code></li>
<li>Summary: <p>In the era of large language models (LLMs), hallucination (i.e., the tendency
to generate factually incorrect content) poses great challenge to trustworthy
and reliable deployment of LLMs in real-world applications. To tackle the LLM
hallucination, three key questions should be well studied: how to detect
hallucinations (detection), why do LLMs hallucinate (source), and what can be
done to mitigate them (mitigation). To address these challenges, this work
presents a systematic empirical study on LLM hallucination, focused on the the
three aspects of hallucination detection, source and mitigation. Specially, we
construct a new hallucination benchmark HaluEval 2.0, and designs a simple yet
effective detection method for LLM hallucination. Furthermore, we zoom into the
different training or utilization stages of LLMs and extensively analyze the
potential factors that lead to the LLM hallucination. Finally, we implement and
examine a series of widely used techniques to mitigate the hallucinations in
LLMs. Our work has led to several important findings to understand the
hallucination origin and mitigate the hallucinations in LLMs. Our code and data
can be accessed at https://github.com/RUCAIBox/HaluEval-2.0.
</p></li>
</ul>

<h3>Title: Malla: Demystifying Real-world Large Language Model Integrated Malicious Services. (arXiv:2401.03315v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03315">http://arxiv.org/abs/2401.03315</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03315]] Malla: Demystifying Real-world Large Language Model Integrated Malicious Services(http://arxiv.org/abs/2401.03315)</code></li>
<li>Summary: <p>The underground exploitation of large language models (LLMs) for malicious
services (i.e., Malla) is witnessing an uptick, amplifying the cyber threat
landscape and posing questions about the trustworthiness of LLM technologies.
However, there has been little effort to understand this new cybercrime, in
terms of its magnitude, impact, and techniques. In this paper, we conduct the
first systematic study on 212 real-world Mallas, uncovering their proliferation
in underground marketplaces and exposing their operational modalities. Our
study discloses the Malla ecosystem, revealing its significant growth and
impact on today's public LLM services. Through examining 212 Mallas, we
uncovered eight backend LLMs used by Mallas, along with 182 prompts that
circumvent the protective measures of public LLM APIs. We further demystify the
tactics employed by Mallas, including the abuse of uncensored LLMs and the
exploitation of public LLM APIs through jailbreak prompts. Our findings enable
a better understanding of the real-world exploitation of LLMs by
cybercriminals, offering insights into strategies to counteract this
cybercrime.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Learning Multimodal Volumetric Features for Large-Scale Neuron Tracing. (arXiv:2401.03043v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03043">http://arxiv.org/abs/2401.03043</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03043]] Learning Multimodal Volumetric Features for Large-Scale Neuron Tracing(http://arxiv.org/abs/2401.03043)</code></li>
<li>Summary: <p>The current neuron reconstruction pipeline for electron microscopy (EM) data
usually includes automatic image segmentation followed by extensive human
expert proofreading. In this work, we aim to reduce human workload by
predicting connectivity between over-segmented neuron pieces, taking both
microscopy image and 3D morphology features into account, similar to human
proofreading workflow. To this end, we first construct a dataset, named
FlyTracing, that contains millions of pairwise connections of segments
expanding the whole fly brain, which is three orders of magnitude larger than
existing datasets for neuron segment connection. To learn sophisticated
biological imaging features from the connectivity annotations, we propose a
novel connectivity-aware contrastive learning method to generate dense
volumetric EM image embedding. The learned embeddings can be easily
incorporated with any point or voxel-based morphological representations for
automatic neuron tracing. Extensive comparisons of different combination
schemes of image and morphological representation in identifying split errors
across the whole fly brain demonstrate the superiority of the proposed
approach, especially for the locations that contain severe imaging artifacts,
such as section missing and misalignment. The dataset and code are available at
https://github.com/Levishery/Flywire-Neuron-Tracing.
</p></li>
</ul>

<h3>Title: Multi-View 3D Instance Segmentation of Structural Anomalies for Enhanced Structural Inspection of Concrete Bridges. (arXiv:2401.03298v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03298">http://arxiv.org/abs/2401.03298</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03298]] Multi-View 3D Instance Segmentation of Structural Anomalies for Enhanced Structural Inspection of Concrete Bridges(http://arxiv.org/abs/2401.03298)</code></li>
<li>Summary: <p>For effective structural damage assessment, the instances of damages need to
be localized in the world of a 3D model. Due to a lack of data, the detection
of structural anomalies can currently not be directly learned and performed in
3D space. In this work, a three-stage approach is presented, which uses the
good performance of detection models on image level to segment instances of
anomalies in the 3D space. In the detection stage, semantic segmentation
predictions are produced on image level. The mapping stage transfers the
image-level prediction onto the respective point cloud. In the extraction
stage, 3D anomaly instances are extracted from the segmented point cloud. Cloud
contraction is used to transform cracks into their medial axis representation.
For areal anomalies the bounding polygon is extracted by means of alpha shapes.
The approach covers the classes crack, spalling, and corrosion and the three
image-level segmentation models TopoCrack, nnU-Net, and DetectionHMA are
compared. Granted a localization tolerance of 4cm, IoUs of over 90% can be
achieved for crack and corrosion and 41% for spalling, which appears to be a
specifically challenging class. Detection on instance-level measured in AP is
about 45% for crack and spalling and 73% for corrosion.
</p></li>
</ul>

<h3>Title: SeqNAS: Neural Architecture Search for Event Sequence Classification. (arXiv:2401.03246v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.03246">http://arxiv.org/abs/2401.03246</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.03246]] SeqNAS: Neural Architecture Search for Event Sequence Classification(http://arxiv.org/abs/2401.03246)</code></li>
<li>Summary: <p>Neural Architecture Search (NAS) methods are widely used in various
industries to obtain high quality taskspecific solutions with minimal human
intervention. Event Sequences find widespread use in various industrial
applications including churn prediction customer segmentation fraud detection
and fault diagnosis among others. Such data consist of categorical and
real-valued components with irregular timestamps. Despite the usefulness of NAS
methods previous approaches only have been applied to other domains images
texts or time series. Our work addresses this limitation by introducing a novel
NAS algorithm SeqNAS specifically designed for event sequence classification.
We develop a simple yet expressive search space that leverages commonly used
building blocks for event sequence classification including multihead self
attention convolutions and recurrent cells. To perform the search we adopt
sequential Bayesian Optimization and utilize previously trained models as an
ensemble of teachers to augment knowledge distillation. As a result of our work
we demonstrate that our method surpasses state of the art NAS methods and
popular architectures suitable for sequence classification and holds great
potential for various industrial applications.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
