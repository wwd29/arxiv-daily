<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Evaluation of Game Design Framework Using a Gamified Browser-Based Application. (arXiv:2306.07463v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07463">http://arxiv.org/abs/2306.07463</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07463] Evaluation of Game Design Framework Using a Gamified Browser-Based Application](http://arxiv.org/abs/2306.07463) #secure</code></li>
<li>Summary: <p>Privacy Policy under GDPR law helps users understand how software developers
handle their personal data. GDPR privacy education must be considered a vital
aspect of combating privacy threats. In this paper, we present the design and
development of a gamified browser-based application aimed at motivating
software developers to enhance their secure coding behavior. To evaluate the
proposed game design framework through the developed framework, a think-aloud
study was carried out along with pre-and post-test. There was an improvement in
the software developers' secure coding behaviors through playing the game which
had GDPR privacy laws incorporated to enhance their knowledge of privacy.
</p></li>
</ul>

<h3>Title: How Secure is Your Website? A Comprehensive Investigation on CAPTCHA Providers and Solving Services. (arXiv:2306.07543v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07543">http://arxiv.org/abs/2306.07543</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07543] How Secure is Your Website? A Comprehensive Investigation on CAPTCHA Providers and Solving Services](http://arxiv.org/abs/2306.07543) #secure</code></li>
<li>Summary: <p>Completely Automated Public Turing Test To Tell Computers and Humans Apart
(CAPTCHA) has been implemented on many websites to identify between harmful
automated bots and legitimate users. However, the revenue generated by the bots
has turned circumventing CAPTCHAs into a lucrative business. Although earlier
studies provided information about text-based CAPTCHAs and the associated
CAPTCHA-solving services, a lot has changed in the past decade regarding
content, suppliers, and solvers of CAPTCHA. We have conducted a comprehensive
investigation of the latest third-party CAPTCHA providers and CAPTCHA-solving
services' attacks. We dug into the details of CAPTCHA-As-a-Service and the
latest CAPTCHA-solving services and carried out adversarial experiments on
CAPTCHAs and CAPTCHA solvers. The experiment results show a worrying fact: most
latest CAPTCHAs are vulnerable to both human solvers and automated solvers. New
CAPTCHAs based on hard AI problems and behavior analysis are needed to stop
CAPTCHA solvers.
</p></li>
</ul>

<h3>Title: SRATTA : Sample Re-ATTribution Attack of Secure Aggregation in Federated Learning. (arXiv:2306.07644v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07644">http://arxiv.org/abs/2306.07644</a></li>
<li>Code URL: <a href="https://github.com/owkin/sratta">https://github.com/owkin/sratta</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07644] SRATTA : Sample Re-ATTribution Attack of Secure Aggregation in Federated Learning](http://arxiv.org/abs/2306.07644) #secure</code></li>
<li>Summary: <p>We consider a cross-silo federated learning (FL) setting where a machine
learning model with a fully connected first layer is trained between different
clients and a central server using FedAvg, and where the aggregation step can
be performed with secure aggregation (SA). We present SRATTA an attack relying
only on aggregated models which, under realistic assumptions, (i) recovers data
samples from the different clients, and (ii) groups data samples coming from
the same client together. While sample recovery has already been explored in an
FL setting, the ability to group samples per client, despite the use of SA, is
novel. This poses a significant unforeseen security threat to FL and
effectively breaks SA. We show that SRATTA is both theoretically grounded and
can be used in practice on realistic models and datasets. We also propose
counter-measures, and claim that clients should play an active role to
guarantee their privacy during training.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Exploratory analysis of a measurement scale of an information security management system. (arXiv:2306.07367v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07367">http://arxiv.org/abs/2306.07367</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07367] Exploratory analysis of a measurement scale of an information security management system](http://arxiv.org/abs/2306.07367) #security</code></li>
<li>Summary: <p>This research shows the analysis of multiple factors that inhibit the
implementation of an Information Security Management System (ISMS). The
research data were collected from 143 respondents from two universities in
northeastern Mexico, in faculties of engineering in related areas. In this
study, the Information Security Management System Measurement Instrument
(IM-ISMS) was validated. A scale of 24 items was obtained, divided into four
factors: organizational policies and regulations, privacy, integrity and
authenticity. The results of this study agree with the results found by [10] in
which they pre-sent a model that complies with ISO/IEC 27002:2013 controls and
security and privacy criteria to improve the ISMS. [48], Mentioned that the
implementation of controls based on ISO standards can meet the requirements for
cybersecurity best practices.A scale of 24 items was obtained, divided into
four factors: organizational policies and regulations, privacy, integrity and
authenticity. This version of the instrument meets the criteria established for
its validity (KMO, Bartlett's test of sphericity). An extraction was performed
by the minimum residuals method, an oblique rotation was performed by the
promax method, when performing the rotation 17 of the 24 items were grouped in
the corresponding factor. The final reliability of the scale was calculated by
the Omega coefficient, in all the dimensions the coefficients were greater than
.70, therefore the re-liability of the instrument is good.
</p></li>
</ul>

<h3>Title: Space Cybersecurity Norms. (arXiv:2306.07441v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07441">http://arxiv.org/abs/2306.07441</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07441] Space Cybersecurity Norms](http://arxiv.org/abs/2306.07441) #security</code></li>
<li>Summary: <p>This paper addresses: Evolution of the space systems environment, including
space system proliferation and space systems as critical infrastructure Cyber
threats to, and vulnerabilities of, space systems Alternative approaches to
meeting these threats, and the significance of norms Approaches to the
development and reinforcement of norms for the cybersecurity of space systems.
</p></li>
</ul>

<h3>Title: SoK: Decoding the Super App Enigma: The Security Mechanisms, Threats, and Trade-offs in OS-alike Apps. (arXiv:2306.07495v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07495">http://arxiv.org/abs/2306.07495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07495] SoK: Decoding the Super App Enigma: The Security Mechanisms, Threats, and Trade-offs in OS-alike Apps](http://arxiv.org/abs/2306.07495) #security</code></li>
<li>Summary: <p>The super app paradigm, exemplified by platforms such as WeChat and AliPay,
has revolutionized the mobile app landscape by enabling third-party developers
to deploy add-ons within these apps. These add-ons, known as miniapps, leverage
user data hosted by the super app platforms to provide a wide range of
services, such as shopping and gaming. With the rise of miniapps, super apps
have transformed into "operating systems", offering encapsulated APIs to
miniapp developers as well as in-app miniapp stores for users to explore and
download miniapps. In this paper, we provide the first systematic study to
consolidate the current state of knowledge in this field from the security
perspective: the security measures, threats, and trade-offs of this paradigm.
Specifically, we summarize 13 security mechanisms and 10 security threats in
super app platforms, followed by a root cause analysis revealing that the
security assumptions still may be violated due to issues in underlying systems,
implementation of isolation, and vetting. Additionally, we also systematize
open problems and trade-offs that need to be addressed by future works to help
enhance the security and privacy of this new paradigm.
</p></li>
</ul>

<h3>Title: Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats. (arXiv:2306.07685v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07685">http://arxiv.org/abs/2306.07685</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07685] Few-shot Multi-domain Knowledge Rearming for Context-aware Defence against Advanced Persistent Threats](http://arxiv.org/abs/2306.07685) #security</code></li>
<li>Summary: <p>Advanced persistent threats (APTs) have novel features such as multi-stage
penetration, highly-tailored intention, and evasive tactics. APTs defense
requires fusing multi-dimensional Cyber threat intelligence data to identify
attack intentions and conducts efficient knowledge discovery strategies by
data-driven machine learning to recognize entity relationships. However,
data-driven machine learning lacks generalization ability on fresh or unknown
samples, reducing the accuracy and practicality of the defense model. Besides,
the private deployment of these APT defense models on heterogeneous
environments and various network devices requires significant investment in
context awareness (such as known attack entities, continuous network states,
and current security strategies). In this paper, we propose a few-shot
multi-domain knowledge rearming (FMKR) scheme for context-aware defense against
APTs. By completing multiple small tasks that are generated from different
network domains with meta-learning, the FMKR firstly trains a model with good
discrimination and generalization ability for fresh and unknown APT attacks. In
each FMKR task, both threat intelligence and local entities are fused into the
support/query sets in meta-learning to identify possible attack stages.
Secondly, to rearm current security strategies, an finetuning-based deployment
mechanism is proposed to transfer learned knowledge into the student model,
while minimizing the defense cost. Compared to multiple model replacement
strategies, the FMKR provides a faster response to attack behaviors while
consuming less scheduling cost. Based on the feedback from multiple real users
of the Industrial Internet of Things (IIoT) over 2 months, we demonstrate that
the proposed scheme can improve the defense satisfaction rate.
</p></li>
</ul>

<h3>Title: An Inverse Approach to Windows' Resource-Based Permission Mechanism for Access Permission Vulnerability Detection. (arXiv:2306.07734v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07734">http://arxiv.org/abs/2306.07734</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07734] An Inverse Approach to Windows' Resource-Based Permission Mechanism for Access Permission Vulnerability Detection](http://arxiv.org/abs/2306.07734) #security</code></li>
<li>Summary: <p>In organizations, employees work with information stored in files according
to their duties and responsibilities. Windows uses resource-based access
permissions that any permission for any user has to be set separately per
resource. This approach gets complicated as the number of resources and users
increase, and causes oversights in assigning permissions. Therefore, a special
mechanism is required to scrutinize what permissions any employee has on any
set of resources. This requirement is circumvented by reversing the Windows
approach in terms of user-accessible resources. This approach is implemented by
a program allowing quick and easy examination of any type of permissions
granted or denied to active directory users on any folder. In this way,
administrators can make sure there is no any missing or overlooked setting that
could cause a security vulnerability. This approach can easily be extended to
scrutinize other resources, and for other local or active directory objects.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: Urban Spatiotemporal Data Synthesis via Neural Disaggregation. (arXiv:2306.07292v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07292">http://arxiv.org/abs/2306.07292</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07292] Urban Spatiotemporal Data Synthesis via Neural Disaggregation](http://arxiv.org/abs/2306.07292) #privacy</code></li>
<li>Summary: <p>The level of granularity of open data often conflicts the benefits it can
provide. Less granular data can protect individual privacy, but to certain
degrees, sabotage the promise of open data to promote transparency and assist
research. Similar in the urban setting, aggregated urban data at high-level
geographic units can mask out the underline particularities of city dynamics
that may vary at lower areal levels. In this work, we aim to synthesize
fine-grained, high resolution urban data, by breaking down aggregated urban
data at coarse, low resolution geographic units. The goal is to increase the
usability and realize the values as much as possible of highly aggregated urban
data. To address the issue of simplicity of some traditional disaggregation
methods -- 1) we experimented with numerous neural-based models that are
capable of modeling intricate non-linear relationships among features. Neural
methods can also leverage both spatial and temporal information concurrently.
We showed that all neural methods perform better than traditional
disaggregation methods. Incorporating the temporal information further enhances
the results. 2) We proposed a training approach for disaggregation task,
Chain-of-Training (COT), that can be incorporated into any of the
training-based models. COT adds transitional disaggregation steps by
incorporating intermediate geographic dimensions, which enhances the
predictions at low geographic level and boosts the results at higher levels. 3)
We adapted the idea of reconstruction (REC) from super-resolution domain in our
disaggregation case -- after disaggregating from low to high geographic level,
we then re-aggregate back to the low level from our generated high level
values. Both strategies improved disaggregation results on three datasets and
two cities we tested on.
</p></li>
</ul>

<h3>Title: "Private Prediction Strikes Back!'' Private Kernelized Nearest Neighbors with Individual Renyi Filter. (arXiv:2306.07381v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07381">http://arxiv.org/abs/2306.07381</a></li>
<li>Code URL: <a href="https://github.com/jeremy43/ind_knn">https://github.com/jeremy43/ind_knn</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07381] "Private Prediction Strikes Back!'' Private Kernelized Nearest Neighbors with Individual Renyi Filter](http://arxiv.org/abs/2306.07381) #privacy</code></li>
<li>Summary: <p>Most existing approaches of differentially private (DP) machine learning
focus on private training. Despite its many advantages, private training lacks
the flexibility in adapting to incremental changes to the training dataset such
as deletion requests from exercising GDPR's right to be forgotten. We revisit a
long-forgotten alternative, known as private prediction, and propose a new
algorithm named Individual Kernelized Nearest Neighbor (Ind-KNN). Ind-KNN is
easily updatable over dataset changes and it allows precise control of the
R\'{e}nyi DP at an individual user level -- a user's privacy loss is measured
by the exact amount of her contribution to predictions; and a user is removed
if her prescribed privacy budget runs out. Our results show that Ind-KNN
consistently improves the accuracy over existing private prediction methods for
a wide range of $\epsilon$ on four vision and language tasks. We also
illustrate several cases under which Ind-KNN is preferable over private
training with NoisySGD.
</p></li>
</ul>

<h3>Title: Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings. (arXiv:2306.07959v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07959">http://arxiv.org/abs/2306.07959</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07959] Privacy Preserving Bayesian Federated Learning in Heterogeneous Settings](http://arxiv.org/abs/2306.07959) #privacy</code></li>
<li>Summary: <p>In several practical applications of federated learning (FL), the clients are
highly heterogeneous in terms of both their data and compute resources, and
therefore enforcing the same model architecture for each client is very
limiting. Moreover, the need for uncertainty quantification and data privacy
constraints are often particularly amplified for clients that have limited
local data. This paper presents a unified FL framework to simultaneously
address all these constraints and concerns, based on training customized local
Bayesian models that learn well even in the absence of large local datasets. A
Bayesian framework provides a natural way of incorporating supervision in the
form of prior distributions. We use priors in the functional (output) space of
the networks to facilitate collaboration across heterogeneous clients.
Moreover, formal differential privacy guarantees are provided for this
framework. Experiments on standard FL datasets demonstrate that our approach
outperforms strong baselines in both homogeneous and heterogeneous settings and
under strict privacy constraints, while also providing characterizations of
model uncertainties.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Marking anything: application of point cloud in extracting video target features. (arXiv:2306.07559v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07559">http://arxiv.org/abs/2306.07559</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07559] Marking anything: application of point cloud in extracting video target features](http://arxiv.org/abs/2306.07559) #protect</code></li>
<li>Summary: <p>Extracting retrievable features from video is of great significance for
structured video database construction, video copyright protection and fake
video rumor refutation. Inspired by point cloud data processing, this paper
proposes a method for marking anything (MA) in the video, which can extract the
contour features of any target in the video and convert it into a feature
vector with a length of 256 that can be retrieved. The algorithm uses YOLO-v8
algorithm, multi-object tracking algorithm and PointNet++ to extract contour of
the video detection target to form spatial point cloud data. Then extract the
point cloud feature vector and use it as the retrievable feature of the video
detection target. In order to verify the effectiveness and robustness of
contour feature, some datasets are crawled from Dou Yin and Kinetics-700
dataset as experimental data. For Dou Yin's homogenized videos, the proposed
contour features achieve retrieval accuracy higher than 97% in Top1 return
mode. For videos from Kinetics 700, the contour feature also showed good
robustness for partial clip mode video tracing.
</p></li>
</ul>

<h2>defense</h2>
<h2>attack</h2>
<h3>Title: Adversarial Attacks on the Interpretation of Neuron Activation Maximization. (arXiv:2306.07397v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07397">http://arxiv.org/abs/2306.07397</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07397] Adversarial Attacks on the Interpretation of Neuron Activation Maximization](http://arxiv.org/abs/2306.07397) #attack</code></li>
<li>Summary: <p>The internal functional behavior of trained Deep Neural Networks is
notoriously difficult to interpret. Activation-maximization approaches are one
set of techniques used to interpret and analyze trained deep-learning models.
These consist in finding inputs that maximally activate a given neuron or
feature map. These inputs can be selected from a data set or obtained by
optimization. However, interpretability methods may be subject to being
deceived. In this work, we consider the concept of an adversary manipulating a
model for the purpose of deceiving the interpretation. We propose an
optimization framework for performing this manipulation and demonstrate a
number of ways that popular activation-maximization interpretation techniques
associated with CNNs can be manipulated to change the interpretations, shedding
light on the reliability of these methods.
</p></li>
</ul>

<h3>Title: I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models. (arXiv:2306.07591v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07591">http://arxiv.org/abs/2306.07591</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07591] I See Dead People: Gray-Box Adversarial Attack on Image-To-Text Models](http://arxiv.org/abs/2306.07591) #attack</code></li>
<li>Summary: <p>Modern image-to-text systems typically adopt the encoder-decoder framework,
which comprises two main components: an image encoder, responsible for
extracting image features, and a transformer-based decoder, used for generating
captions. Taking inspiration from the analysis of neural networks' robustness
against adversarial perturbations, we propose a novel gray-box algorithm for
creating adversarial examples in image-to-text models. Unlike image
classification tasks that have a finite set of class labels, finding visually
similar adversarial examples in an image-to-text task poses greater challenges
because the captioning system allows for a virtually infinite space of possible
captions. In this paper, we present a gray-box adversarial attack on
image-to-text, both untargeted and targeted. We formulate the process of
discovering adversarial perturbations as an optimization problem that uses only
the image-encoder component, meaning the proposed attack is language-model
agnostic. Through experiments conducted on the ViT-GPT2 model, which is the
most-used image-to-text model in Hugging Face, and the Flickr30k dataset, we
demonstrate that our proposed attack successfully generates visually similar
adversarial examples, both with untargeted and targeted captions. Notably, our
attack operates in a gray-box manner, requiring no knowledge about the decoder
module. We also show that our attacks fool the popular open-source platform
Hugging Face.
</p></li>
</ul>

<h3>Title: Rethinking Adversarial Training with A Simple Baseline. (arXiv:2306.07613v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07613">http://arxiv.org/abs/2306.07613</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07613] Rethinking Adversarial Training with A Simple Baseline](http://arxiv.org/abs/2306.07613) #attack</code></li>
<li>Summary: <p>We report competitive results on RobustBench for CIFAR and SVHN using a
simple yet effective baseline approach. Our approach involves a training
protocol that integrates rescaled square loss, cyclic learning rates, and
erasing-based data augmentation. The outcomes we have achieved are comparable
to those of the model trained with state-of-the-art techniques, which is
currently the predominant choice for adversarial training. Our baseline,
referred to as SimpleAT, yields three novel empirical insights. (i) By
switching to square loss, the accuracy is comparable to that obtained by using
both de-facto training protocol plus data augmentation. (ii) One cyclic
learning rate is a good scheduler, which can effectively reduce the risk of
robust overfitting. (iii) Employing rescaled square loss during model training
can yield a favorable balance between adversarial and natural accuracy. In
general, our experimental results show that SimpleAT effectively mitigates
robust overfitting and consistently achieves the best performance at the end of
training. For example, on CIFAR-10 with ResNet-18, SimpleAT achieves
approximately 52% adversarial accuracy against the current strong AutoAttack.
Furthermore, SimpleAT exhibits robust performance on various image corruptions,
including those commonly found in CIFAR-10-C dataset. Finally, we assess the
effectiveness of these insights through two techniques: bias-variance analysis
and logit penalty methods. Our findings demonstrate that all of these simple
techniques are capable of reducing the variance of model predictions, which is
regarded as the primary contributor to robust overfitting. In addition, our
analysis also uncovers connections with various advanced state-of-the-art
methods.
</p></li>
</ul>

<h3>Title: Area is all you need: repeatable elements make stronger adversarial attacks. (arXiv:2306.07768v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07768">http://arxiv.org/abs/2306.07768</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07768] Area is all you need: repeatable elements make stronger adversarial attacks](http://arxiv.org/abs/2306.07768) #attack</code></li>
<li>Summary: <p>Over the last decade, deep neural networks have achieved state of the art in
computer vision tasks. These models, however, are susceptible to unusual
inputs, known as adversarial examples, that cause them to misclassify or
otherwise fail to detect objects. Here, we provide evidence that the increasing
success of adversarial attacks is primarily due to increasing their size. We
then demonstrate a method for generating the largest possible adversarial patch
by building a adversarial pattern out of repeatable elements. This approach
achieves a new state of the art in evading detection by YOLOv2 and YOLOv3.
Finally, we present an experiment that fails to replicate the prior success of
several attacks published in this field, and end with some comments on testing
and reproducibility.
</p></li>
</ul>

<h3>Title: Freaky Leaky SMS: Extracting User Locations by Analyzing SMS Timings. (arXiv:2306.07695v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07695">http://arxiv.org/abs/2306.07695</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07695] Freaky Leaky SMS: Extracting User Locations by Analyzing SMS Timings](http://arxiv.org/abs/2306.07695) #attack</code></li>
<li>Summary: <p>Short Message Service (SMS) remains one of the most popular communication
channels since its introduction in 2G cellular networks. In this paper, we
demonstrate that merely receiving silent SMS messages regularly opens a
stealthy side-channel that allows other regular network users to infer the
whereabouts of the SMS recipient. The core idea is that receiving an SMS
inevitably generates Delivery Reports whose reception bestows a timing attack
vector at the sender. We conducted experiments across various countries,
operators, and devices to show that an attacker can deduce the location of an
SMS recipient by analyzing timing measurements from typical receiver locations.
Our results show that, after training an ML model, the SMS sender can
accurately determine multiple locations of the recipient. For example, our
model achieves up to 96% accuracy for locations across different countries, and
86% for two locations within Belgium. Due to the way cellular networks are
designed, it is difficult to prevent Delivery Reports from being returned to
the originator making it challenging to thwart this covert attack without
making fundamental changes to the network architecture.
</p></li>
</ul>

<h3>Title: Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say "I don't know". (arXiv:2306.07796v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07796">http://arxiv.org/abs/2306.07796</a></li>
<li>Code URL: <a href="https://github.com/grezesf/fgn---research">https://github.com/grezesf/fgn---research</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07796] Finite Gaussian Neurons: Defending against adversarial attacks by making neural networks say "I don't know"](http://arxiv.org/abs/2306.07796) #attack</code></li>
<li>Summary: <p>Since 2014, artificial neural networks have been known to be vulnerable to
adversarial attacks, which can fool the network into producing wrong or
nonsensical outputs by making humanly imperceptible alterations to inputs.
While defenses against adversarial attacks have been proposed, they usually
involve retraining a new neural network from scratch, a costly task. In this
work, I introduce the Finite Gaussian Neuron (FGN), a novel neuron architecture
for artificial neural networks. My works aims to: - easily convert existing
models to Finite Gaussian Neuron architecture, - while preserving the existing
model's behavior on real data, - and offering resistance against adversarial
attacks. I show that converted and retrained Finite Gaussian Neural Networks
(FGNN) always have lower confidence (i.e., are not overconfident) in their
predictions over randomized and Fast Gradient Sign Method adversarial images
when compared to classical neural networks, while maintaining high accuracy and
confidence over real MNIST images. To further validate the capacity of Finite
Gaussian Neurons to protect from adversarial attacks, I compare the behavior of
FGNs to that of Bayesian Neural Networks against both randomized and
adversarial images, and show how the behavior of the two architectures differs.
Finally I show some limitations of the FGN models by testing them on the more
complex SPEECHCOMMANDS task, against the stronger Carlini-Wagner and Projected
Gradient Descent adversarial attacks.
</p></li>
</ul>

<h3>Title: Temporal Gradient Inversion Attacks with Robust Optimization. (arXiv:2306.07883v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07883">http://arxiv.org/abs/2306.07883</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07883] Temporal Gradient Inversion Attacks with Robust Optimization](http://arxiv.org/abs/2306.07883) #attack</code></li>
<li>Summary: <p>Federated Learning (FL) has emerged as a promising approach for collaborative
model training without sharing private data. However, privacy concerns
regarding information exchanged during FL have received significant research
attention. Gradient Inversion Attacks (GIAs) have been proposed to reconstruct
the private data retained by local clients from the exchanged gradients. While
recovering private data, the data dimensions and the model complexity increase,
which thwart data reconstruction by GIAs. Existing methods adopt prior
knowledge about private data to overcome those challenges. In this paper, we
first observe that GIAs with gradients from a single iteration fail to
reconstruct private data due to insufficient dimensions of leaked gradients,
complex model architectures, and invalid gradient information. We investigate a
Temporal Gradient Inversion Attack with a Robust Optimization framework, called
TGIAs-RO, which recovers private data without any prior knowledge by leveraging
multiple temporal gradients. To eliminate the negative impacts of outliers,
e.g., invalid gradients for collaborative optimization, robust statistics are
proposed. Theoretical guarantees on the recovery performance and robustness of
TGIAs-RO against invalid gradients are also provided. Extensive empirical
results on MNIST, CIFAR10, ImageNet and Reuters 21578 datasets show that the
proposed TGIAs-RO with 10 temporal gradients improves reconstruction
performance compared to state-of-the-art methods, even for large batch sizes
(up to 128), complex models like ResNet18, and large datasets like ImageNet
(224*224 pixels). Furthermore, the proposed attack method inspires further
exploration of privacy-preserving methods in the context of FL.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: Compositor: Bottom-up Clustering and Compositing for Robust Part and Object Segmentation. (arXiv:2306.07404v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07404">http://arxiv.org/abs/2306.07404</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07404] Compositor: Bottom-up Clustering and Compositing for Robust Part and Object Segmentation](http://arxiv.org/abs/2306.07404) #robust</code></li>
<li>Summary: <p>In this work, we present a robust approach for joint part and object
segmentation. Specifically, we reformulate object and part segmentation as an
optimization problem and build a hierarchical feature representation including
pixel, part, and object-level embeddings to solve it in a bottom-up clustering
manner. Pixels are grouped into several clusters where the part-level
embeddings serve as cluster centers. Afterwards, object masks are obtained by
compositing the part proposals. This bottom-up interaction is shown to be
effective in integrating information from lower semantic levels to higher
semantic levels. Based on that, our novel approach Compositor produces part and
object segmentation masks simultaneously while improving the mask quality.
Compositor achieves state-of-the-art performance on PartImageNet and
Pascal-Part by outperforming previous methods by around 0.9% and 1.3% on
PartImageNet, 0.4% and 1.7% on Pascal-Part in terms of part and object mIoU and
demonstrates better robustness against occlusion by around 4.4% and 7.1% on
part and object respectively. Code will be available at
https://github.com/TACJu/Compositor.
</p></li>
</ul>

<h3>Title: Instant Multi-View Head Capture through Learnable Registration. (arXiv:2306.07437v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07437">http://arxiv.org/abs/2306.07437</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07437] Instant Multi-View Head Capture through Learnable Registration](http://arxiv.org/abs/2306.07437) #robust</code></li>
<li>Summary: <p>Existing methods for capturing datasets of 3D heads in dense semantic
correspondence are slow, and commonly address the problem in two separate
steps; multi-view stereo (MVS) reconstruction followed by non-rigid
registration. To simplify this process, we introduce TEMPEH (Towards Estimation
of 3D Meshes from Performances of Expressive Heads) to directly infer 3D heads
in dense correspondence from calibrated multi-view images. Registering datasets
of 3D scans typically requires manual parameter tuning to find the right
balance between accurately fitting the scans surfaces and being robust to
scanning noise and outliers. Instead, we propose to jointly register a 3D head
dataset while training TEMPEH. Specifically, during training we minimize a
geometric loss commonly used for surface registration, effectively leveraging
TEMPEH as a regularizer. Our multi-view head inference builds on a volumetric
feature representation that samples and fuses features from each view using
camera calibration information. To account for partial occlusions and a large
capture volume that enables head movements, we use view- and surface-aware
feature fusion, and a spatial transformer-based head localization module,
respectively. We use raw MVS scans as supervision during training, but, once
trained, TEMPEH directly predicts 3D heads in dense correspondence without
requiring scans. Predicting one head takes about 0.3 seconds with a median
reconstruction error of 0.26 mm, 64% lower than the current state-of-the-art.
This enables the efficient capture of large datasets containing multiple people
and diverse facial motions. Code, model, and data are publicly available at
https://tempeh.is.tue.mpg.de.
</p></li>
</ul>

<h3>Title: Learning to Estimate 6DoF Pose from Limited Data: A Few-Shot, Generalizable Approach using RGB Images. (arXiv:2306.07598v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07598">http://arxiv.org/abs/2306.07598</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07598] Learning to Estimate 6DoF Pose from Limited Data: A Few-Shot, Generalizable Approach using RGB Images](http://arxiv.org/abs/2306.07598) #robust</code></li>
<li>Summary: <p>The accurate estimation of six degrees-of-freedom (6DoF) object poses is
essential for many applications in robotics and augmented reality. However,
existing methods for 6DoF pose estimation often depend on CAD templates or
dense support views, restricting their usefulness in realworld situations. In
this study, we present a new cascade framework named Cas6D for few-shot 6DoF
pose estimation that is generalizable and uses only RGB images. To address the
false positives of target object detection in the extreme few-shot setting, our
framework utilizes a selfsupervised pre-trained ViT to learn robust feature
representations. Then, we initialize the nearest top-K pose candidates based on
similarity score and refine the initial poses using feature pyramids to
formulate and update the cascade warped feature volume, which encodes context
at increasingly finer scales. By discretizing the pose search range using
multiple pose bins and progressively narrowing the pose search range in each
stage using predictions from the previous stage, Cas6D can overcome the large
gap between pose candidates and ground truth poses, which is a common failure
mode in sparse-view scenarios. Experimental results on the LINEMOD and GenMOP
datasets demonstrate that Cas6D outperforms state-of-the-art methods by 9.2%
and 3.8% accuracy (Proj-5) under the 32-shot setting compared to OnePose++ and
Gen6D.
</p></li>
</ul>

<h3>Title: UOD: Universal One-shot Detection of Anatomical Landmarks. (arXiv:2306.07615v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07615">http://arxiv.org/abs/2306.07615</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07615] UOD: Universal One-shot Detection of Anatomical Landmarks](http://arxiv.org/abs/2306.07615) #robust</code></li>
<li>Summary: <p>One-shot medical landmark detection gains much attention and achieves great
success for its label-efficient training process. However, existing one-shot
learning methods are highly specialized in a single domain and suffer domain
preference heavily in the situation of multi-domain unlabeled data. Moreover,
one-shot learning is not robust that it faces performance drop when annotating
a sub-optimal image. To tackle these issues, we resort to developing a
domain-adaptive one-shot landmark detection framework for handling multi-domain
medical images, named Universal One-shot Detection (UOD). UOD consists of two
stages and two corresponding universal models which are designed as
combinations of domain-specific modules and domain-shared modules. In the first
stage, a domain-adaptive convolution model is self-supervised learned to
generate pseudo landmark labels. In the second stage, we design a
domain-adaptive transformer to eliminate domain preference and build the global
context for multi-domain data. Even though only one annotated sample from each
domain is available for training, the domain-shared modules help UOD aggregate
all one-shot samples to detect more robust and accurate landmarks. We
investigated both qualitatively and quantitatively the proposed UOD on three
widely-used public X-ray datasets in different anatomical domains (i.e., head,
hand, chest) and obtained state-of-the-art performances in each domain.
</p></li>
</ul>

<h3>Title: Robustness of SAM: Segment Anything Under Corruptions and Beyond. (arXiv:2306.07713v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07713">http://arxiv.org/abs/2306.07713</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07713] Robustness of SAM: Segment Anything Under Corruptions and Beyond](http://arxiv.org/abs/2306.07713) #robust</code></li>
<li>Summary: <p>Segment anything model (SAM), as the name suggests, is claimed to be capable
of cutting out any object. SAM is a vision foundation model which demonstrates
impressive zero-shot transfer performance with the guidance of a prompt.
However, there is currently a lack of comprehensive evaluation of its
robustness performance under various types of corruptions. Prior works show
that SAM is biased towards texture (style) rather than shape, motivated by
which we start by investigating SAM's robustness against style transfer, which
is synthetic corruption. With the effect of corruptions interpreted as a style
change, we further evaluate its robustness on 15 common corruptions with 5
severity levels for each real-world corruption. Beyond the corruptions, we
further evaluate the SAM robustness on local occlusion and adversarial
perturbations. Overall, this work provides a comprehensive empirical study on
the robustness of the SAM under corruptions and beyond.
</p></li>
</ul>

<h3>Title: BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation. (arXiv:2306.07730v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07730">http://arxiv.org/abs/2306.07730</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07730] BeliefPPG: Uncertainty-aware Heart Rate Estimation from PPG signals via Belief Propagation](http://arxiv.org/abs/2306.07730) #robust</code></li>
<li>Summary: <p>We present a novel learning-based method that achieves state-of-the-art
performance on several heart rate estimation benchmarks extracted from
photoplethysmography signals (PPG). We consider the evolution of the heart rate
in the context of a discrete-time stochastic process that we represent as a
hidden Markov model. We derive a distribution over possible heart rate values
for a given PPG signal window through a trained neural network. Using belief
propagation, we incorporate the statistical distribution of heart rate changes
to refine these estimates in a temporal context. From this, we obtain a
quantized probability distribution over the range of possible heart rate values
that captures a meaningful and well-calibrated estimate of the inherent
predictive uncertainty. We show the robustness of our method on eight public
datasets with three different cross-validation experiments.
</p></li>
</ul>

<h3>Title: Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning. (arXiv:2306.07512v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07512">http://arxiv.org/abs/2306.07512</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07512] Noisy Positive-Unlabeled Learning with Self-Training for Speculative Knowledge Graph Reasoning](http://arxiv.org/abs/2306.07512) #robust</code></li>
<li>Summary: <p>This paper studies speculative reasoning task on real-world knowledge graphs
(KG) that contain both \textit{false negative issue} (i.e., potential true
facts being excluded) and \textit{false positive issue} (i.e., unreliable or
outdated facts being included). State-of-the-art methods fall short in the
speculative reasoning ability, as they assume the correctness of a fact is
solely determined by its presence in KG, making them vulnerable to false
negative/positive issues. The new reasoning task is formulated as a noisy
Positive-Unlabeled learning problem. We propose a variational framework, namely
nPUGraph, that jointly estimates the correctness of both collected and
uncollected facts (which we call \textit{label posterior}) and updates model
parameters during training. The label posterior estimation facilitates
speculative reasoning from two perspectives. First, it improves the robustness
of a label posterior-aware graph encoder against false positive links. Second,
it identifies missing facts to provide high-quality grounds of reasoning. They
are unified in a simple yet effective self-training procedure. Empirically,
extensive experiments on three benchmark KG and one Twitter dataset with
various degrees of false negative/positive cases demonstrate the effectiveness
of nPUGraph.
</p></li>
</ul>

<h3>Title: Tokenization with Factorized Subword Encoding. (arXiv:2306.07764v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07764">http://arxiv.org/abs/2306.07764</a></li>
<li>Code URL: <a href="https://github.com/ltgoslo/factorizer">https://github.com/ltgoslo/factorizer</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07764] Tokenization with Factorized Subword Encoding](http://arxiv.org/abs/2306.07764) #robust</code></li>
<li>Summary: <p>In recent years, language models have become increasingly larger and more
complex. However, the input representations for these models continue to rely
on simple and greedy subword tokenization methods. In this paper, we propose a
novel tokenization method that factorizes subwords onto discrete triplets using
a VQ-VAE model. The effectiveness of the proposed tokenization method, referred
to as the Factorizer, is evaluated on language modeling and morpho-syntactic
tasks for 7 diverse languages. Results indicate that this method is more
appropriate and robust for morphological tasks than the commonly used byte-pair
encoding (BPE) tokenization algorithm.
</p></li>
</ul>

<h3>Title: Adversarial Capsule Networks for Romanian Satire Detection and Sentiment Analysis. (arXiv:2306.07845v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07845">http://arxiv.org/abs/2306.07845</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07845] Adversarial Capsule Networks for Romanian Satire Detection and Sentiment Analysis](http://arxiv.org/abs/2306.07845) #robust</code></li>
<li>Summary: <p>Satire detection and sentiment analysis are intensively explored natural
language processing (NLP) tasks that study the identification of the satirical
tone from texts and extracting sentiments in relationship with their targets.
In languages with fewer research resources, an alternative is to produce
artificial examples based on character-level adversarial processes to overcome
dataset size limitations. Such samples are proven to act as a regularization
method, thus improving the robustness of models. In this work, we improve the
well-known NLP models (i.e., Convolutional Neural Networks, Long Short-Term
Memory (LSTM), Bidirectional LSTM, Gated Recurrent Units (GRUs), and
Bidirectional GRUs) with adversarial training and capsule networks. The
fine-tuned models are used for satire detection and sentiment analysis tasks in
the Romanian language. The proposed framework outperforms the existing methods
for the two tasks, achieving up to 99.08% accuracy, thus confirming the
improvements added by the capsule layers and the adversarial training in NLP
approaches.
</p></li>
</ul>

<h3>Title: BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information. (arXiv:2306.07934v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07934">http://arxiv.org/abs/2306.07934</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07934] BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information](http://arxiv.org/abs/2306.07934) #robust</code></li>
<li>Summary: <p>Automated reasoning with unstructured natural text is a key requirement for
many potential applications of NLP and for developing robust AI systems.
Recently, Language Models (LMs) have demonstrated complex reasoning capacities
even without any finetuning. However, existing evaluation for automated
reasoning assumes access to a consistent and coherent set of information over
which models reason. When reasoning in the real-world, the available
information is frequently inconsistent or contradictory, and therefore models
need to be equipped with a strategy to resolve such conflicts when they arise.
One widely-applicable way of resolving conflicts is to impose preferences over
information sources (e.g., based on source credibility or information recency)
and adopt the source with higher preference. In this paper, we formulate the
problem of reasoning with contradictory information guided by preferences over
sources as the classical problem of defeasible reasoning, and develop a dataset
called BoardgameQA for measuring the reasoning capacity of LMs in this setting.
BoardgameQA also incorporates reasoning with implicit background knowledge, to
better reflect reasoning problems in downstream applications. We benchmark
various LMs on BoardgameQA and the results reveal a significant gap in the
reasoning capacity of state-of-the-art LMs on this problem, showing that
reasoning with conflicting information does not surface out-of-the-box in LMs.
While performance can be improved with finetuning, it nevertheless remains
poor.
</p></li>
</ul>

<h3>Title: Theoretical Foundations of Adversarially Robust Learning. (arXiv:2306.07723v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07723">http://arxiv.org/abs/2306.07723</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07723] Theoretical Foundations of Adversarially Robust Learning](http://arxiv.org/abs/2306.07723) #robust</code></li>
<li>Summary: <p>Despite extraordinary progress, current machine learning systems have been
shown to be brittle against adversarial examples: seemingly innocuous but
carefully crafted perturbations of test examples that cause machine learning
predictors to misclassify. Can we learn predictors robust to adversarial
examples? and how? There has been much empirical interest in this contemporary
challenge in machine learning, and in this thesis, we address it from a
theoretical perspective.
</p></li>
</ul>

<p>In this thesis, we explore what robustness properties can we hope to
guarantee against adversarial examples and develop an understanding of how to
algorithmically guarantee them. We illustrate the need to go beyond traditional
approaches and principles such as empirical risk minimization and uniform
convergence, and make contributions that can be categorized as follows: (1)
introducing problem formulations capturing aspects of emerging practical
challenges in robust learning, (2) designing new learning algorithms with
provable robustness guarantees, and (3) characterizing the complexity of robust
learning and fundamental limitations on the performance of any algorithm.
</p>

<h3>Title: Composing Efficient, Robust Tests for Policy Selection. (arXiv:2306.07372v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07372">http://arxiv.org/abs/2306.07372</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07372] Composing Efficient, Robust Tests for Policy Selection](http://arxiv.org/abs/2306.07372) #robust</code></li>
<li>Summary: <p>Modern reinforcement learning systems produce many high-quality policies
throughout the learning process. However, to choose which policy to actually
deploy in the real world, they must be tested under an intractable number of
environmental conditions. We introduce RPOSST, an algorithm to select a small
set of test cases from a larger pool based on a relatively small number of
sample evaluations. RPOSST treats the test case selection problem as a
two-player game and optimizes a solution with provable $k$-of-$N$ robustness,
bounding the error relative to a test that used all the test cases in the pool.
Empirical results demonstrate that RPOSST finds a small set of test cases that
identify high quality policies in a toy one-shot game, poker datasets, and a
high-fidelity racing simulator.
</p></li>
</ul>

<h3>Title: Robust Reinforcement Learning through Efficient Adversarial Herding. (arXiv:2306.07408v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07408">http://arxiv.org/abs/2306.07408</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07408] Robust Reinforcement Learning through Efficient Adversarial Herding](http://arxiv.org/abs/2306.07408) #robust</code></li>
<li>Summary: <p>Although reinforcement learning (RL) is considered the gold standard for
policy design, it may not always provide a robust solution in various
scenarios. This can result in severe performance degradation when the
environment is exposed to potential disturbances. Adversarial training using a
two-player max-min game has been proven effective in enhancing the robustness
of RL agents. In this work, we extend the two-player game by introducing an
adversarial herd, which involves a group of adversaries, in order to address
($\textit{i}$) the difficulty of the inner optimization problem, and
($\textit{ii}$) the potential over pessimism caused by the selection of a
candidate adversary set that may include unlikely scenarios. We first prove
that adversarial herds can efficiently approximate the inner optimization
problem. Then we address the second issue by replacing the worst-case
performance in the inner optimization with the average performance over the
worst-$k$ adversaries. We evaluate the proposed method on multiple MuJoCo
environments. Experimental results demonstrate that our approach consistently
generates more robust policies.
</p></li>
</ul>

<h3>Title: On the Robustness of Removal-Based Feature Attributions. (arXiv:2306.07462v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07462">http://arxiv.org/abs/2306.07462</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07462] On the Robustness of Removal-Based Feature Attributions](http://arxiv.org/abs/2306.07462) #robust</code></li>
<li>Summary: <p>To explain complex models based on their inputs, many feature attribution
methods have been developed that assign importance scores to input features.
However, some recent work challenges the robustness of feature attributions by
showing that these methods are sensitive to input and model perturbations,
while other work addresses this robustness issue by proposing robust
attribution methods and model modifications. Nevertheless, previous work on
attribution robustness has focused primarily on gradient-based feature
attributions. In contrast, the robustness properties of removal-based
attribution methods are not comprehensively well understood. To bridge this
gap, we theoretically characterize the robustness of removal-based feature
attributions. Specifically, we provide a unified analysis of such methods and
prove upper bounds for the difference between intact and perturbed
attributions, under settings of both input and model perturbations. Our
empirical experiments on synthetic and real-world data validate our theoretical
results and demonstrate their practical implications.
</p></li>
</ul>

<h3>Title: PaVa: a novel Path-based Valley-seeking clustering algorithm. (arXiv:2306.07503v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07503">http://arxiv.org/abs/2306.07503</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07503] PaVa: a novel Path-based Valley-seeking clustering algorithm](http://arxiv.org/abs/2306.07503) #robust</code></li>
<li>Summary: <p>Clustering methods are being applied to a wider range of scenarios involving
more complex datasets, where the shapes of clusters tend to be arbitrary. In
this paper, we propose a novel Path-based Valley-seeking clustering algorithm
for arbitrarily shaped clusters. This work aims to seek the valleys among
clusters and then individually extract clusters. Three vital techniques are
used in this algorithm. First, path distance (minmax distance) is employed to
transform the irregular boundaries among clusters, that is density valleys,
into perfect spherical shells. Second, a suitable density measurement,
$k$-distance, is employed to make adjustment on Minimum Spanning Tree, by which
a robust minmax distance is calculated. Third, we seek the transformed density
valleys by determining their centers and radius. First, the clusters are
wrapped in spherical shells after the distance transformation, making the
extraction process efficient even with clusters of arbitrary shape. Second,
adjusted Minimum Spanning Tree enhances the robustness of minmax distance under
different kinds of noise. Last, the number of clusters does not need to be
inputted or decided manually due to the individual extraction process. After
applying the proposed algorithm to several commonly used synthetic datasets,
the results indicate that the Path-based Valley-seeking algorithm is accurate
and efficient. The algorithm is based on the dissimilarity of objects, so it
can be applied to a wide range of fields. Its performance on real-world
datasets illustrates its versatility.
</p></li>
</ul>

<h3>Title: Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective. (arXiv:2306.07528v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07528">http://arxiv.org/abs/2306.07528</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07528] Unified Off-Policy Learning to Rank: a Reinforcement Learning Perspective](http://arxiv.org/abs/2306.07528) #robust</code></li>
<li>Summary: <p>Off-policy Learning to Rank (LTR) aims to optimize a ranker from data
collected by a deployed logging policy. However, existing off-policy learning
to rank methods often make strong assumptions about how users generate the
click data, i.e., the click model, and hence need to tailor their methods
specifically under different click models. In this paper, we unified the
ranking process under general stochastic click models as a Markov Decision
Process (MDP), and the optimal ranking could be learned with offline
reinforcement learning (RL) directly. Building upon this, we leverage offline
RL techniques for off-policy LTR and propose the Click Model-Agnostic Unified
Off-policy Learning to Rank (CUOLR) method, which could be easily applied to a
wide range of click models. Through a dedicated formulation of the MDP, we show
that offline RL algorithms can adapt to various click models without complex
debiasing techniques and prior knowledge of the model. Results on various
large-scale datasets demonstrate that CUOLR consistently outperforms the
state-of-the-art off-policy learning to rank algorithms while maintaining
consistency and robustness under different click models.
</p></li>
</ul>

<h3>Title: Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs. (arXiv:2306.07699v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07699">http://arxiv.org/abs/2306.07699</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07699] Time-aware Graph Structure Learning via Sequence Prediction on Temporal Graphs](http://arxiv.org/abs/2306.07699) #robust</code></li>
<li>Summary: <p>Temporal Graph Learning, which aims to model the time-evolving nature of
graphs, has gained increasing attention and achieved remarkable performance
recently. However, in reality, graph structures are often incomplete and noisy,
which hinders temporal graph networks (TGNs) from learning informative
representations. Graph contrastive learning uses data augmentation to generate
plausible variations of existing data and learn robust representations.
However, rule-based augmentation approaches may be suboptimal as they lack
learnability and fail to leverage rich information from downstream tasks. To
address these issues, we propose a Time-aware Graph Structure Learning (TGSL)
approach via sequence prediction on temporal graphs, which learns better graph
structures for downstream tasks through adding potential temporal edges. In
particular, it predicts time-aware context embedding based on previously
observed interactions and uses the Gumble-Top-K to select the closest candidate
edges to this context embedding. Additionally, several candidate sampling
strategies are proposed to ensure both efficiency and diversity. Furthermore,
we jointly learn the graph structure and TGNs in an end-to-end manner and
perform inference on the refined graph. Extensive experiments on temporal link
prediction benchmarks demonstrate that TGSL yields significant gains for the
popular TGNs such as TGAT and GraphMixer, and it outperforms other contrastive
learning methods on temporal graphs. We will release the code in the future.
</p></li>
</ul>

<h3>Title: Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study. (arXiv:2306.07737v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07737">http://arxiv.org/abs/2306.07737</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07737] Robustness and Generalization Performance of Deep Learning Models on Cyber-Physical Systems: A Comparative Study](http://arxiv.org/abs/2306.07737) #robust</code></li>
<li>Summary: <p>Deep learning (DL) models have seen increased attention for time series
forecasting, yet the application on cyber-physical systems (CPS) is hindered by
the lacking robustness of these methods. Thus, this study evaluates the
robustness and generalization performance of DL architectures on multivariate
time series data from CPS. Our investigation focuses on the models' ability to
handle a range of perturbations, such as sensor faults and noise, and assesses
their impact on overall performance. Furthermore, we test the generalization
and transfer learning capabilities of these models by exposing them to
out-of-distribution (OOD) samples. These include deviations from standard
system operations, while the core dynamics of the underlying physical system
are preserved. Additionally, we test how well the models respond to several
data augmentation techniques, including added noise and time warping. Our
experimental framework utilizes a simulated three-tank system, proposed as a
novel benchmark for evaluating the robustness and generalization performance of
DL algorithms in CPS data contexts. The findings reveal that certain DL model
architectures and training techniques exhibit superior effectiveness in
handling OOD samples and various perturbations. These insights have significant
implications for the development of DL models that deliver reliable and robust
performance in real-world CPS applications.
</p></li>
</ul>

<h3>Title: Robustly Learning a Single Neuron via Sharpness. (arXiv:2306.07892v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07892">http://arxiv.org/abs/2306.07892</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07892] Robustly Learning a Single Neuron via Sharpness](http://arxiv.org/abs/2306.07892) #robust</code></li>
<li>Summary: <p>We study the problem of learning a single neuron with respect to the
$L_2^2$-loss in the presence of adversarial label noise. We give an efficient
algorithm that, for a broad family of activations including ReLUs, approximates
the optimal $L_2^2$-error within a constant factor. Our algorithm applies under
much milder distributional assumptions compared to prior work. The key
ingredient enabling our results is a novel connection to local error bounds
from optimization theory.
</p></li>
</ul>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: Action Recognition with Multi-stream Motion Modeling and Mutual Information Maximization. (arXiv:2306.07576v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07576">http://arxiv.org/abs/2306.07576</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07576] Action Recognition with Multi-stream Motion Modeling and Mutual Information Maximization](http://arxiv.org/abs/2306.07576) #extraction</code></li>
<li>Summary: <p>Action recognition has long been a fundamental and intriguing problem in
artificial intelligence. The task is challenging due to the high dimensionality
nature of an action, as well as the subtle motion details to be considered.
Current state-of-the-art approaches typically learn from articulated motion
sequences in the straightforward 3D Euclidean space. However, the vanilla
Euclidean space is not efficient for modeling important motion characteristics
such as the joint-wise angular acceleration, which reveals the driving force
behind the motion. Moreover, current methods typically attend to each channel
equally and lack theoretical constrains on extracting task-relevant features
from the input.
</p></li>
</ul>

<p>In this paper, we seek to tackle these challenges from three aspects: (1) We
propose to incorporate an acceleration representation, explicitly modeling the
higher-order variations in motion. (2) We introduce a novel Stream-GCN network
equipped with multi-stream components and channel attention, where different
representations (i.e., streams) supplement each other towards a more precise
action recognition while attention capitalizes on those important channels. (3)
We explore feature-level supervision for maximizing the extraction of
task-relevant information and formulate this into a mutual information loss.
Empirically, our approach sets the new state-of-the-art performance on three
benchmark datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. Our code is
anonymously released at https://github.com/ActionR-Group/Stream-GCN, hoping to
inspire the community.
</p>

<h3>Title: Continuous Cost Aggregation for Dual-Pixel Disparity Extraction. (arXiv:2306.07921v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07921">http://arxiv.org/abs/2306.07921</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07921] Continuous Cost Aggregation for Dual-Pixel Disparity Extraction](http://arxiv.org/abs/2306.07921) #extraction</code></li>
<li>Summary: <p>Recent works have shown that depth information can be obtained from
Dual-Pixel (DP) sensors. A DP arrangement provides two views in a single shot,
thus resembling a stereo image pair with a tiny baseline. However, the
different point spread function (PSF) per view, as well as the small disparity
range, makes the use of typical stereo matching algorithms problematic. To
address the above shortcomings, we propose a Continuous Cost Aggregation (CCA)
scheme within a semi-global matching framework that is able to provide accurate
continuous disparities from DP images. The proposed algorithm fits parabolas to
matching costs and aggregates parabola coefficients along image paths. The
aggregation step is performed subject to a quadratic constraint that not only
enforces the disparity smoothness but also maintains the quadratic form of the
total costs. This gives rise to an inherently efficient disparity propagation
scheme with a pixel-wise minimization in closed-form. Furthermore, the
continuous form allows for a robust multi-scale aggregation that better
compensates for the varying PSF. Experiments on DP data from both DSLR and
phone cameras show that the proposed scheme attains state-of-the-art
performance in DP disparity estimation.
</p></li>
</ul>

<h3>Title: Enhancing Topic Extraction in Recommender Systems with Entropy Regularization. (arXiv:2306.07403v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07403">http://arxiv.org/abs/2306.07403</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07403] Enhancing Topic Extraction in Recommender Systems with Entropy Regularization](http://arxiv.org/abs/2306.07403) #extraction</code></li>
<li>Summary: <p>In recent years, many recommender systems have utilized textual data for
topic extraction to enhance interpretability. However, our findings reveal a
noticeable deficiency in the coherence of keywords within topics, resulting in
low explainability of the model. This paper introduces a novel approach called
entropy regularization to address the issue, leading to more interpretable
topics extracted from recommender systems, while ensuring that the performance
of the primary task stays competitively strong. The effectiveness of the
strategy is validated through experiments on a variation of the probabilistic
matrix factorization model that utilizes textual data to extract item
embeddings. The experiment results show a significant improvement in topic
coherence, which is quantified by cosine similarity on word embeddings.
</p></li>
</ul>

<h3>Title: A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews. (arXiv:2306.07786v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07786">http://arxiv.org/abs/2306.07786</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07786] A Cloud-based Machine Learning Pipeline for the Efficient Extraction of Insights from Customer Reviews](http://arxiv.org/abs/2306.07786) #extraction</code></li>
<li>Summary: <p>The efficiency of natural language processing has improved dramatically with
the advent of machine learning models, particularly neural network-based
solutions. However, some tasks are still challenging, especially when
considering specific domains. In this paper, we present a cloud-based system
that can extract insights from customer reviews using machine learning methods
integrated into a pipeline. For topic modeling, our composite model uses
transformer-based neural networks designed for natural language processing,
vector embedding-based keyword extraction, and clustering. The elements of our
model have been integrated and further developed to meet better the
requirements of efficient information extraction, topic modeling of the
extracted information, and user needs. Furthermore, our system can achieve
better results than this task's existing topic modeling and keyword extraction
solutions. Our approach is validated and compared with other state-of-the-art
methods using publicly available datasets for benchmarking.
</p></li>
</ul>

<h3>Title: Multi-modal Representation Learning for Social Post Location Inference. (arXiv:2306.07935v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07935">http://arxiv.org/abs/2306.07935</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07935] Multi-modal Representation Learning for Social Post Location Inference](http://arxiv.org/abs/2306.07935) #extraction</code></li>
<li>Summary: <p>Inferring geographic locations via social posts is essential for many
practical location-based applications such as product marketing,
point-of-interest recommendation, and infector tracking for COVID-19. Unlike
image-based location retrieval or social-post text embedding-based location
inference, the combined effect of multi-modal information (i.e., post images,
text, and hashtags) for social post positioning receives less attention. In
this work, we collect real datasets of social posts with images, texts, and
hashtags from Instagram and propose a novel Multi-modal Representation Learning
Framework (MRLF) capable of fusing different modalities of social posts for
location inference. MRLF integrates a multi-head attention mechanism to enhance
location-salient information extraction while significantly improving location
inference compared with single domain-based methods. To overcome the noisy
user-generated textual content, we introduce a novel attention-based
character-aware module that considers the relative dependencies between
characters of social post texts and hashtags for flexible multi-model
information fusion. The experimental results show that MRLF can make accurate
location predictions and open a new door to understanding the multi-modal data
of social posts for online inference tasks.
</p></li>
</ul>

<h3>Title: A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation. (arXiv:2306.07304v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07304">http://arxiv.org/abs/2306.07304</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07304] A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation](http://arxiv.org/abs/2306.07304) #extraction</code></li>
<li>Summary: <p>In recent years, concept-based approaches have emerged as some of the most
promising explainability methods to help us interpret the decisions of
Artificial Neural Networks (ANNs). These methods seek to discover intelligible
visual 'concepts' buried within the complex patterns of ANN activations in two
key steps: (1) concept extraction followed by (2) importance estimation. While
these two steps are shared across methods, they all differ in their specific
implementations. Here, we introduce a unifying theoretical framework that
comprehensively defines and clarifies these two steps. This framework offers
several advantages as it allows us: (i) to propose new evaluation metrics for
comparing different concept extraction approaches; (ii) to leverage modern
attribution methods and evaluation metrics to extend and systematically
evaluate state-of-the-art concept-based approaches and importance estimation
techniques; (iii) to derive theoretical guarantees regarding the optimality of
such methods. We further leverage our framework to try to tackle a crucial
question in explainability: how to efficiently identify clusters of data points
that are classified based on a similar shared strategy. To illustrate these
findings and to highlight the main strategies of a model, we introduce a visual
representation called the strategic cluster graph. Finally, we present
https://serre-lab.github.io/Lens, a dedicated website that offers a complete
compilation of these visualizations for all classes of the ImageNet dataset.
</p></li>
</ul>

<h3>Title: FIRE: An Optimization Approach for Fast Interpretable Rule Extraction. (arXiv:2306.07432v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07432">http://arxiv.org/abs/2306.07432</a></li>
<li>Code URL: <a href="https://github.com/brianliu12437/firekdd2023">https://github.com/brianliu12437/firekdd2023</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07432] FIRE: An Optimization Approach for Fast Interpretable Rule Extraction](http://arxiv.org/abs/2306.07432) #extraction</code></li>
<li>Summary: <p>We present FIRE, Fast Interpretable Rule Extraction, an optimization-based
framework to extract a small but useful collection of decision rules from tree
ensembles. FIRE selects sparse representative subsets of rules from tree
ensembles, that are easy for a practitioner to examine. To further enhance the
interpretability of the extracted model, FIRE encourages fusing rules during
selection, so that many of the selected decision rules share common
antecedents. The optimization framework utilizes a fusion regularization
penalty to accomplish this, along with a non-convex sparsity-inducing penalty
to aggressively select rules. Optimization problems in FIRE pose a challenge to
off-the-shelf solvers due to problem scale and the non-convexity of the
penalties. To address this, making use of problem-structure, we develop a
specialized solver based on block coordinate descent principles; our solver
performs up to 40x faster than existing solvers. We show in our experiments
that FIRE outperforms state-of-the-art rule ensemble algorithms at building
sparse rule sets, and can deliver more interpretable models compared to
existing methods.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: GQFedWAvg: Optimization-Based Quantized Federated Learning in General Edge Computing Systems. (arXiv:2306.07497v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07497">http://arxiv.org/abs/2306.07497</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07497] GQFedWAvg: Optimization-Based Quantized Federated Learning in General Edge Computing Systems](http://arxiv.org/abs/2306.07497) #federate</code></li>
<li>Summary: <p>The optimal implementation of federated learning (FL) in practical edge
computing systems has been an outstanding problem. In this paper, we propose an
optimization-based quantized FL algorithm, which can appropriately fit a
general edge computing system with uniform or nonuniform computing and
communication resources at the workers. Specifically, we first present a new
random quantization scheme and analyze its properties. Then, we propose a
general quantized FL algorithm, namely GQFedWAvg. Specifically, GQFedWAvg
applies the proposed quantization scheme to quantize wisely chosen model
update-related vectors and adopts a generalized mini-batch stochastic gradient
descent (SGD) method with the weighted average local model updates in global
model aggregation. Besides, GQFedWAvg has several adjustable algorithm
parameters to flexibly adapt to the computing and communication resources at
the server and workers. We also analyze the convergence of GQFedWAvg. Next, we
optimize the algorithm parameters of GQFedWAvg to minimize the convergence
error under the time and energy constraints. We successfully tackle the
challenging non-convex problem using general inner approximation (GIA) and
multiple delicate tricks. Finally, we interpret GQFedWAvg's function principle
and show its considerable gains over existing FL algorithms using numerical
results.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Image Captioners Are Scalable Vision Learners Too. (arXiv:2306.07915v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07915">http://arxiv.org/abs/2306.07915</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07915] Image Captioners Are Scalable Vision Learners Too](http://arxiv.org/abs/2306.07915) #fair</code></li>
<li>Summary: <p>Contrastive pretraining on image-text pairs from the web is one of the most
popular large-scale pretraining strategies for vision backbones, especially in
the context of large multimodal models. At the same time, image captioning on
this type of data is commonly considered an inferior pretraining strategy. In
this paper, we perform a fair comparison of these two pretraining strategies,
carefully matching training data, compute, and model capacity. Using a standard
encoder-decoder transformer, we find that captioning alone is surprisingly
effective: on classification tasks, captioning produces vision encoders
competitive with contrastively pretrained encoders, while surpassing them on
vision &amp; language tasks. We further analyze the effect of the model
architecture and scale, as well as the pretraining data on the representation
quality, and find that captioning exhibits the same or better scaling behavior
along these axes. Overall our results show that plain image captioning is a
more powerful pretraining strategy than was previously believed.
</p></li>
</ul>

<h3>Title: Omega: Optimistic EMA Gradients. (arXiv:2306.07905v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07905">http://arxiv.org/abs/2306.07905</a></li>
<li>Code URL: <a href="https://github.com/juan43ramirez/omega">https://github.com/juan43ramirez/omega</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07905] Omega: Optimistic EMA Gradients](http://arxiv.org/abs/2306.07905) #fair</code></li>
<li>Summary: <p>Stochastic min-max optimization has gained interest in the machine learning
community with the advancements in GANs and adversarial training. Although game
optimization is fairly well understood in the deterministic setting, some
issues persist in the stochastic regime. Recent work has shown that stochastic
gradient descent-ascent methods such as the optimistic gradient are highly
sensitive to noise or can fail to converge. Although alternative strategies
exist, they can be prohibitively expensive. We introduce Omega, a method with
optimistic-like updates that mitigates the impact of noise by incorporating an
EMA of historic gradients in its update rule. We also explore a variation of
this algorithm that incorporates momentum. Although we do not provide
convergence guarantees, our experiments on stochastic games show that Omega
outperforms the optimistic gradient method when applied to linear players.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Parametric Implicit Face Representation for Audio-Driven Facial Reenactment. (arXiv:2306.07579v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07579">http://arxiv.org/abs/2306.07579</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07579] Parametric Implicit Face Representation for Audio-Driven Facial Reenactment](http://arxiv.org/abs/2306.07579) #interpretability</code></li>
<li>Summary: <p>Audio-driven facial reenactment is a crucial technique that has a range of
applications in film-making, virtual avatars and video conferences. Existing
works either employ explicit intermediate face representations (e.g., 2D facial
landmarks or 3D face models) or implicit ones (e.g., Neural Radiance Fields),
thus suffering from the trade-offs between interpretability and expressive
power, hence between controllability and quality of the results. In this work,
we break these trade-offs with our novel parametric implicit face
representation and propose a novel audio-driven facial reenactment framework
that is both controllable and can generate high-quality talking heads.
Specifically, our parametric implicit representation parameterizes the implicit
representation with interpretable parameters of 3D face models, thereby taking
the best of both explicit and implicit methods. In addition, we propose several
new techniques to improve the three components of our framework, including i)
incorporating contextual information into the audio-to-expression parameters
encoding; ii) using conditional image synthesis to parameterize the implicit
representation and implementing it with an innovative tri-plane structure for
efficient learning; iii) formulating facial reenactment as a conditional image
inpainting problem and proposing a novel data augmentation technique to improve
model generalizability. Extensive experiments demonstrate that our method can
generate more realistic results than previous methods with greater fidelity to
the identities and talking styles of speakers.
</p></li>
</ul>

<h3>Title: Knowledge-Prompted Estimator: A Novel Approach to Explainable Machine Translation Assessment. (arXiv:2306.07486v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07486">http://arxiv.org/abs/2306.07486</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07486] Knowledge-Prompted Estimator: A Novel Approach to Explainable Machine Translation Assessment](http://arxiv.org/abs/2306.07486) #interpretability</code></li>
<li>Summary: <p>Cross-lingual Machine Translation (MT) quality estimation plays a crucial
role in evaluating translation performance. GEMBA, the first MT quality
assessment metric based on Large Language Models (LLMs), employs one-step
prompting to achieve state-of-the-art (SOTA) in system-level MT quality
estimation; however, it lacks segment-level analysis. In contrast,
Chain-of-Thought (CoT) prompting outperforms one-step prompting by offering
improved reasoning and explainability. In this paper, we introduce
Knowledge-Prompted Estimator (KPE), a CoT prompting method that combines three
one-step prompting techniques, including perplexity, token-level similarity,
and sentence-level similarity. This method attains enhanced performance for
segment-level estimation compared with previous deep learning models and
one-step prompting approaches. Furthermore, supplementary experiments on
word-level visualized alignment demonstrate that our KPE method significantly
improves token alignment compared with earlier models and provides better
interpretability for MT quality estimation. Code will be released upon
publication.
</p></li>
</ul>

<h3>Title: Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations. (arXiv:2306.07919v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07919">http://arxiv.org/abs/2306.07919</a></li>
<li>Code URL: <a href="https://github.com/tianxiangzhao/imitationnoisydemon">https://github.com/tianxiangzhao/imitationnoisydemon</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07919] Skill Disentanglement for Imitation Learning from Suboptimal Demonstrations](http://arxiv.org/abs/2306.07919) #interpretability</code></li>
<li>Summary: <p>Imitation learning has achieved great success in many sequential
decision-making tasks, in which a neural agent is learned by imitating
collected human demonstrations. However, existing algorithms typically require
a large number of high-quality demonstrations that are difficult and expensive
to collect. Usually, a trade-off needs to be made between demonstration quality
and quantity in practice. Targeting this problem, in this work we consider the
imitation of sub-optimal demonstrations, with both a small clean demonstration
set and a large noisy set. Some pioneering works have been proposed, but they
suffer from many limitations, e.g., assuming a demonstration to be of the same
optimality throughout time steps and failing to provide any interpretation
w.r.t knowledge learned from the noisy set. Addressing these problems, we
propose {\method} by evaluating and imitating at the sub-demonstration level,
encoding action primitives of varying quality into different skills.
Concretely, {\method} consists of a high-level controller to discover skills
and a skill-conditioned module to capture action-taking policies, and is
trained following a two-phase pipeline by first discovering skills with all
demonstrations and then adapting the controller to only the clean set. A
mutual-information-based regularization and a dynamic sub-demonstration
optimality estimator are designed to promote disentanglement in the skill
space. Extensive experiments are conducted over two gym environments and a
real-world healthcare dataset to demonstrate the superiority of {\method} in
learning from sub-optimal demonstrations and its improved interpretability by
examining learned skills.
</p></li>
</ul>

<h2>explainability</h2>
<h3>Title: Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation. (arXiv:2306.07306v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07306">http://arxiv.org/abs/2306.07306</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07306] Active Globally Explainable Learning for Medical Images via Class Association Embedding and Cyclic Adversarial Generation](http://arxiv.org/abs/2306.07306) #explainability</code></li>
<li>Summary: <p>Explainability poses a major challenge to artificial intelligence (AI)
techniques. Current studies on explainable AI (XAI) lack the efficiency of
extracting global knowledge about the learning task, thus suffer deficiencies
such as imprecise saliency, context-aware absence and vague meaning. In this
paper, we propose the class association embedding (CAE) approach to address
these issues. We employ an encoder-decoder architecture to embed sample
features and separate them into class-related and individual-related style
vectors simultaneously. Recombining the individual-style code of a given sample
with the class-style code of another leads to a synthetic sample with preserved
individual characters but changed class assignment, following a cyclic
adversarial learning strategy. Class association embedding distills the global
class-related features of all instances into a unified domain with well
separation between classes. The transition rules between different classes can
be then extracted and further employed to individual instances. We then propose
an active XAI framework which manipulates the class-style vector of a certain
sample along guided paths towards the counter-classes, resulting in a series of
counter-example synthetic samples with identical individual characters.
Comparing these counterfactual samples with the original ones provides a
global, intuitive illustration to the nature of the classification tasks. We
adopt the framework on medical image classification tasks, which show that more
precise saliency maps with powerful context-aware representation can be
achieved compared with existing methods. Moreover, the disease pathology can be
directly visualized via traversing the paths in the class-style space.
</p></li>
</ul>

<h2>watermark</h2>
<h3>Title: Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis. (arXiv:2306.07754v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07754">http://arxiv.org/abs/2306.07754</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07754] Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis](http://arxiv.org/abs/2306.07754) #watermark</code></li>
<li>Summary: <p>Large text-to-image models have shown remarkable performance in synthesizing
high-quality images. In particular, the subject-driven model makes it possible
to personalize the image synthesis for a specific subject, e.g., a human face
or an artistic style, by fine-tuning the generic text-to-image model with a few
images from that subject. Nevertheless, misuse of subject-driven image
synthesis may violate the authority of subject owners. For example, malicious
users may use subject-driven synthesis to mimic specific artistic styles or to
create fake facial images without authorization. To protect subject owners
against such misuse, recent attempts have commonly relied on adversarial
examples to indiscriminately disrupt subject-driven image synthesis. However,
this essentially prevents any benign use of subject-driven synthesis based on
protected images.
</p></li>
</ul>

<p>In this paper, we take a different angle and aim at protection without
sacrificing the utility of protected images for general synthesis purposes.
Specifically, we propose GenWatermark, a novel watermark system based on
jointly learning a watermark generator and a detector. In particular, to help
the watermark survive the subject-driven synthesis, we incorporate the
synthesis process in learning GenWatermark by fine-tuning the detector with
synthesized images for a specific subject. This operation is shown to largely
improve the watermark detection accuracy and also ensure the uniqueness of the
watermark for each individual subject. Extensive experiments validate the
effectiveness of GenWatermark, especially in practical scenarios with unknown
models and text prompts (74% Acc.), as well as partial data watermarking (80%
Acc. for 1/4 watermarking). We also demonstrate the robustness of GenWatermark
to two potential countermeasures that substantially degrade the synthesis
quality.
</p>

<h2>diffusion</h2>
<h3>Title: Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing with Pre-Trained Diffusion Model. (arXiv:2306.07596v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07596">http://arxiv.org/abs/2306.07596</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07596] Paste, Inpaint and Harmonize via Denoising: Subject-Driven Image Editing with Pre-Trained Diffusion Model](http://arxiv.org/abs/2306.07596) #diffusion</code></li>
<li>Summary: <p>Text-to-image generative models have attracted rising attention for flexible
image editing via user-specified descriptions. However, text descriptions alone
are not enough to elaborate the details of subjects, often compromising the
subjects' identity or requiring additional per-subject fine-tuning. We
introduce a new framework called \textit{Paste, Inpaint and Harmonize via
Denoising} (PhD), which leverages an exemplar image in addition to text
descriptions to specify user intentions. In the pasting step, an off-the-shelf
segmentation model is employed to identify a user-specified subject within an
exemplar image which is subsequently inserted into a background image to serve
as an initialization capturing both scene context and subject identity in one.
To guarantee the visual coherence of the generated or edited image, we
introduce an inpainting and harmonizing module to guide the pre-trained
diffusion model to seamlessly blend the inserted subject into the scene
naturally. As we keep the pre-trained diffusion model frozen, we preserve its
strong image synthesis ability and text-driven ability, thus achieving
high-quality results and flexible editing with diverse texts. In our
experiments, we apply PhD to both subject-driven image editing tasks and
explore text-driven scene generation given a reference subject. Both
quantitative and qualitative comparisons with baseline methods demonstrate that
our approach achieves state-of-the-art performance in both tasks. More
qualitative results can be found at
\url{https://sites.google.com/view/phd-demo-page}.
</p></li>
</ul>

<h3>Title: Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data. (arXiv:2306.07881v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07881">http://arxiv.org/abs/2306.07881</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07881] Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data](http://arxiv.org/abs/2306.07881) #diffusion</code></li>
<li>Summary: <p>We present Viewset Diffusion: a framework for training image-conditioned 3D
generative models from 2D data. Image-conditioned 3D generative models allow us
to address the inherent ambiguity in single-view 3D reconstruction. Given one
image of an object, there is often more than one possible 3D volume that
matches the input image, because a single image never captures all sides of an
object. Deterministic models are inherently limited to producing one possible
reconstruction and therefore make mistakes in ambiguous settings. Modelling
distributions of 3D shapes is challenging because 3D ground truth data is often
not available. We propose to solve the issue of data availability by training a
diffusion model which jointly denoises a multi-view image set.We constrain the
output of Viewset Diffusion models to a single 3D volume per image set,
guaranteeing consistent geometry. Training is done through reconstruction
losses on renderings, allowing training with only three images per object. Our
design of architecture and training scheme allows our model to perform 3D
generation and generative, ambiguity-aware single-view reconstruction in a
feed-forward manner. Project page: szymanowiczs.github.io/viewset-diffusion.
</p></li>
</ul>

<h3>Title: Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation. (arXiv:2306.07954v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07954">http://arxiv.org/abs/2306.07954</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07954] Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation](http://arxiv.org/abs/2306.07954) #diffusion</code></li>
<li>Summary: <p>Large text-to-image diffusion models have exhibited impressive proficiency in
generating high-quality images. However, when applying these models to video
domain, ensuring temporal consistency across video frames remains a formidable
challenge. This paper proposes a novel zero-shot text-guided video-to-video
translation framework to adapt image models to videos. The framework includes
two parts: key frame translation and full video translation. The first part
uses an adapted diffusion model to generate key frames, with hierarchical
cross-frame constraints applied to enforce coherence in shapes, textures and
colors. The second part propagates the key frames to other frames with
temporal-aware patch matching and frame blending. Our framework achieves global
style and local texture temporal consistency at a low cost (without re-training
or optimization). The adaptation is compatible with existing image diffusion
techniques, allowing our framework to take advantage of them, such as
customizing a specific subject with LoRA, and introducing extra spatial
guidance with ControlNet. Extensive experimental results demonstrate the
effectiveness of our proposed framework over existing methods in rendering
high-quality and temporally-coherent videos.
</p></li>
</ul>

<h3>Title: Value function estimation using conditional diffusion models for control. (arXiv:2306.07290v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07290">http://arxiv.org/abs/2306.07290</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07290] Value function estimation using conditional diffusion models for control](http://arxiv.org/abs/2306.07290) #diffusion</code></li>
<li>Summary: <p>A fairly reliable trend in deep reinforcement learning is that the
performance scales with the number of parameters, provided a complimentary
scaling in amount of training data. As the appetite for large models increases,
it is imperative to address, sooner than later, the potential problem of
running out of high-quality demonstrations. In this case, instead of collecting
only new data via costly human demonstrations or risking a simulation-to-real
transfer with uncertain effects, it would be beneficial to leverage vast
amounts of readily-available low-quality data. Since classical control
algorithms such as behavior cloning or temporal difference learning cannot be
used on reward-free or action-free data out-of-the-box, this solution warrants
novel training paradigms for continuous control. We propose a simple algorithm
called Diffused Value Function (DVF), which learns a joint multi-step model of
the environment-robot interaction dynamics using a diffusion model. This model
can be efficiently learned from state sequences (i.e., without access to reward
functions nor actions), and subsequently used to estimate the value of each
action out-of-the-box. We show how DVF can be used to efficiently capture the
state visitation measure for multiple controllers, and show promising
qualitative and quantitative results on challenging robotics benchmarks.
</p></li>
</ul>

<h3>Title: G-invariant diffusion maps. (arXiv:2306.07350v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07350">http://arxiv.org/abs/2306.07350</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07350] G-invariant diffusion maps](http://arxiv.org/abs/2306.07350) #diffusion</code></li>
<li>Summary: <p>The diffusion maps embedding of data lying on a manifold have shown success
in tasks ranging from dimensionality reduction and clustering, to data
visualization. In this work, we consider embedding data sets which were sampled
from a manifold which is closed under the action of a continuous matrix group.
An example of such a data set are images who's planar rotations are arbitrary.
The G-invariant graph Laplacian, introduced in a previous work of the authors,
admits eigenfunctions in the form of tensor products between the elements of
the irreducible unitary representations of the group and eigenvectors of
certain matrices. We employ these eigenfunctions to derive diffusion maps that
intrinsically account for the group action on the data. In particular, we
construct both equivariant and invariant embeddings which can be used naturally
to cluster and align the data points. We demonstrate the effectiveness of our
construction with simulated data.
</p></li>
</ul>

<h3>Title: 3D molecule generation by denoising voxel grids. (arXiv:2306.07473v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07473">http://arxiv.org/abs/2306.07473</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07473] 3D molecule generation by denoising voxel grids](http://arxiv.org/abs/2306.07473) #diffusion</code></li>
<li>Summary: <p>We propose a new score-based approach to generate 3D molecules represented as
atomic densities on regular grids. First, we train a denoising neural network
that learns to map from a smooth distribution of noisy molecules to the
distribution of real molecules. Then, we follow the neural empirical Bayes
framework [Saremi and Hyvarinen, 2019] and generate molecules in two steps: (i)
sample noisy density grids from a smooth distribution via underdamped Langevin
Markov chain Monte Carlo, and (ii) recover the ``clean'' molecule by denoising
the noisy grid with a single step. Our method, VoxMol, generates molecules in a
fundamentally different way than the current state of the art (i.e., diffusion
models applied to atom point clouds). It differs in terms of the data
representation, the noise model, the network architecture and the generative
modeling algorithm. VoxMol achieves comparable results to state of the art on
unconditional 3D molecule generation while being simpler to train and faster to
generate molecules.
</p></li>
</ul>

<h3>Title: User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems. (arXiv:2306.07526v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07526">http://arxiv.org/abs/2306.07526</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07526] User-defined Event Sampling and Uncertainty Quantification in Diffusion Models for Physical Dynamical Systems](http://arxiv.org/abs/2306.07526) #diffusion</code></li>
<li>Summary: <p>Diffusion models are a class of probabilistic generative models that have
been widely used as a prior for image processing tasks like text conditional
generation and inpainting. We demonstrate that these models can be adapted to
make predictions and provide uncertainty quantification for chaotic dynamical
systems. In these applications, diffusion models can implicitly represent
knowledge about outliers and extreme events; however, querying that knowledge
through conditional sampling or measuring probabilities is surprisingly
difficult. Existing methods for conditional sampling at inference time seek
mainly to enforce the constraints, which is insufficient to match the
statistics of the distribution or compute the probability of the chosen events.
To achieve these ends, optimally one would use the conditional score function,
but its computation is typically intractable. In this work, we develop a
probabilistic approximation scheme for the conditional score function which
provably converges to the true distribution as the noise level decreases. With
this scheme we are able to sample conditionally on nonlinear userdefined events
at inference time, and matches data statistics even when sampling from the
tails of the distribution.
</p></li>
</ul>

<h3>Title: Hyperbolic Graph Diffusion Model for Molecule Generation. (arXiv:2306.07618v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07618">http://arxiv.org/abs/2306.07618</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07618] Hyperbolic Graph Diffusion Model for Molecule Generation](http://arxiv.org/abs/2306.07618) #diffusion</code></li>
<li>Summary: <p>Recently, diffusion models have achieved remarkable performance in data
generation, e.g., generating high-quality images. Nevertheless, chemistry
molecules often have complex non-Euclidean spatial structures, with the
behavior changing dynamically and unpredictably. Most existing diffusion models
highly rely on computing the probability distribution, i.e., Gaussian
distribution, in Euclidean space, which cannot capture internal non-Euclidean
structures of molecules, especially the hierarchical structures of the implicit
manifold surface represented by molecules. It has been observed that the
complex hierarchical structures in hyperbolic embedding space become more
prominent and easier to be captured. In order to leverage both the data
generation power of diffusion models and the strong capability to extract
complex geometric features of hyperbolic embedding, we propose to extend the
diffusion model to hyperbolic manifolds for molecule generation, namely,
Hyperbolic Graph Diffusion Model (HGDM). The proposed HGDM employs a hyperbolic
variational autoencoder to generate the hyperbolic hidden representation of
nodes and then a score-based hyperbolic graph neural network is used to learn
the distribution in hyperbolic space. Numerical experimental results show that
the proposed HGDM achieves higher performance on several molecular datasets,
compared with state-of-the-art methods.
</p></li>
</ul>

<h2>noise learning</h2>
<h2>data-free</h2>
<h2>transformer</h2>
<h3>Title: Learning to Mask and Permute Visual Tokens for Vision Transformer Pre-Training. (arXiv:2306.07346v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07346">http://arxiv.org/abs/2306.07346</a></li>
<li>Code URL: <a href="https://github.com/aimagelab/mapet">https://github.com/aimagelab/mapet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07346] Learning to Mask and Permute Visual Tokens for Vision Transformer Pre-Training](http://arxiv.org/abs/2306.07346) #transformer</code></li>
<li>Summary: <p>The use of self-supervised pre-training has emerged as a promising approach
to enhance the performance of visual tasks such as image classification. In
this context, recent approaches have employed the Masked Image Modeling
paradigm, which pre-trains a backbone by reconstructing visual tokens
associated with randomly masked image patches. This masking approach, however,
introduces noise into the input data during pre-training, leading to
discrepancies that can impair performance during the fine-tuning phase.
Furthermore, input masking neglects the dependencies between corrupted patches,
increasing the inconsistencies observed in downstream fine-tuning tasks. To
overcome these issues, we propose a new self-supervised pre-training approach,
named Masked and Permuted Vision Transformer (MaPeT), that employs
autoregressive and permuted predictions to capture intra-patch dependencies. In
addition, MaPeT employs auxiliary positional information to reduce the
disparity between the pre-training and fine-tuning phases. In our experiments,
we employ a fair setting to ensure reliable and meaningful comparisons and
conduct investigations on multiple visual tokenizers, including our proposed
$k$-CLIP which directly employs discretized CLIP features. Our results
demonstrate that MaPeT achieves competitive performance on ImageNet, compared
to baselines and competitors under the same model setting. Source code and
trained models are publicly available at: https://github.com/aimagelab/MaPeT.
</p></li>
</ul>

<h3>Title: Reviving Shift Equivariance in Vision Transformers. (arXiv:2306.07470v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07470">http://arxiv.org/abs/2306.07470</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07470] Reviving Shift Equivariance in Vision Transformers](http://arxiv.org/abs/2306.07470) #transformer</code></li>
<li>Summary: <p>Shift equivariance is a fundamental principle that governs how we perceive
the world - our recognition of an object remains invariant with respect to
shifts. Transformers have gained immense popularity due to their effectiveness
in both language and vision tasks. While the self-attention operator in vision
transformers (ViT) is permutation-equivariant and thus shift-equivariant, patch
embedding, positional encoding, and subsampled attention in ViT variants can
disrupt this property, resulting in inconsistent predictions even under small
shift perturbations. Although there is a growing trend in incorporating the
inductive bias of convolutional neural networks (CNNs) into vision
transformers, it does not fully address the issue. We propose an adaptive
polyphase anchoring algorithm that can be seamlessly integrated into vision
transformer models to ensure shift-equivariance in patch embedding and
subsampled attention modules, such as window attention and global subsampled
attention. Furthermore, we utilize depth-wise convolution to encode positional
information. Our algorithms enable ViT, and its variants such as Twins to
achieve 100% consistency with respect to input shift, demonstrate robustness to
cropping, flipping, and affine transformations, and maintain consistent
predictions even when the original models lose 20 percentage points on average
when shifted by just a few pixels with Twins' accuracy dropping from 80.57% to
62.40%.
</p></li>
</ul>

<h3>Title: Sea Ice Segmentation From SAR Data by Convolutional Transformer Networks. (arXiv:2306.07649v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07649">http://arxiv.org/abs/2306.07649</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07649] Sea Ice Segmentation From SAR Data by Convolutional Transformer Networks](http://arxiv.org/abs/2306.07649) #transformer</code></li>
<li>Summary: <p>Sea ice is a crucial component of the Earth's climate system and is highly
sensitive to changes in temperature and atmospheric conditions. Accurate and
timely measurement of sea ice parameters is important for understanding and
predicting the impacts of climate change. Nevertheless, the amount of satellite
data acquired over ice areas is huge, making the subjective measurements
ineffective. Therefore, automated algorithms must be used in order to fully
exploit the continuous data feeds coming from satellites. In this paper, we
present a novel approach for sea ice segmentation based on SAR satellite
imagery using hybrid convolutional transformer (ConvTr) networks. We show that
our approach outperforms classical convolutional networks, while being
considerably more efficient than pure transformer models. ConvTr obtained a
mean intersection over union (mIoU) of 63.68% on the AI4Arctic data set,
assuming an inference time of 120ms for a 400 x 400 squared km product.
</p></li>
</ul>

<h3>Title: A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks. (arXiv:2306.07303v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07303">http://arxiv.org/abs/2306.07303</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07303] A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks](http://arxiv.org/abs/2306.07303) #transformer</code></li>
<li>Summary: <p>Transformer is a deep neural network that employs a self-attention mechanism
to comprehend the contextual relationships within sequential data. Unlike
conventional neural networks or updated versions of Recurrent Neural Networks
(RNNs) such as Long Short-Term Memory (LSTM), transformer models excel in
handling long dependencies between input sequence elements and enable parallel
processing. As a result, transformer-based models have attracted substantial
interest among researchers in the field of artificial intelligence. This can be
attributed to their immense potential and remarkable achievements, not only in
Natural Language Processing (NLP) tasks but also in a wide range of domains,
including computer vision, audio and speech processing, healthcare, and the
Internet of Things (IoT). Although several survey papers have been published
highlighting the transformer's contributions in specific fields, architectural
differences, or performance evaluations, there is still a significant absence
of a comprehensive survey paper encompassing its major applications across
various domains. Therefore, we undertook the task of filling this gap by
conducting an extensive survey of proposed transformer models from 2017 to</li>
<li>Our survey encompasses the identification of the top five application
domains for transformer-based models, namely: NLP, Computer Vision,
Multi-Modality, Audio and Speech Processing, and Signal Processing. We analyze
the impact of highly influential transformer-based models in these domains and
subsequently classify them based on their respective tasks using a proposed
taxonomy. Our aim is to shed light on the existing potential and future
possibilities of transformers for enthusiastic researchers, thus contributing
to the broader understanding of this groundbreaking technology.
</p></li>
</ul>

<h3>Title: TART: A plug-and-play Transformer module for task-agnostic reasoning. (arXiv:2306.07536v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07536">http://arxiv.org/abs/2306.07536</a></li>
<li>Code URL: <a href="https://github.com/hazyresearch/tart">https://github.com/hazyresearch/tart</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07536] TART: A plug-and-play Transformer module for task-agnostic reasoning](http://arxiv.org/abs/2306.07536) #transformer</code></li>
<li>Summary: <p>Large language models (LLMs) exhibit in-context learning abilities which
enable the same model to perform several tasks without any task-specific
training. In contrast, traditional adaptation approaches, such as fine-tuning,
modify the underlying models for each specific task. In-context learning,
however, consistently underperforms task-specific tuning approaches even when
presented with the same examples. While most existing approaches (e.g., prompt
engineering) focus on the LLM's learned representations to patch this
performance gap, our analysis actually reveal that LLM representations contain
sufficient information to make good predictions. As such, we focus on the LLM's
reasoning abilities and demonstrate that this performance gap exists due to
their inability to perform simple probabilistic reasoning tasks. This raises an
intriguing question: Are LLMs actually capable of learning how to reason in a
task-agnostic manner? We answer this in the affirmative and propose TART which
generically improves an LLM's reasoning abilities using a synthetically trained
Transformer-based reasoning module. TART trains this reasoning module in a
task-agnostic manner using only synthetic logistic regression tasks and
composes it with an arbitrary real-world pre-trained model without any
additional training. With a single inference module, TART improves performance
across different model families (GPT-Neo, Pythia, BLOOM), model sizes (100M -
6B), tasks (14 NLP binary classification tasks), and even across different
modalities (audio and vision). Additionally, on the RAFT Benchmark, TART
improves GPT-Neo (125M)'s performance such that it outperforms BLOOM (176B),
and is within 4% of GPT-3 (175B). Our code and models are available at
https://github.com/HazyResearch/TART .
</p></li>
</ul>

<h3>Title: Is Anisotropy Inherent to Transformers?. (arXiv:2306.07656v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07656">http://arxiv.org/abs/2306.07656</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07656] Is Anisotropy Inherent to Transformers?](http://arxiv.org/abs/2306.07656) #transformer</code></li>
<li>Summary: <p>The representation degeneration problem is a phenomenon that is widely
observed among self-supervised learning methods based on Transformers. In NLP,
it takes the form of anisotropy, a singular property of hidden representations
which makes them unexpectedly close to each other in terms of angular distance
(cosine-similarity). Some recent works tend to show that anisotropy is a
consequence of optimizing the cross-entropy loss on long-tailed distributions
of tokens. We show in this paper that anisotropy can also be observed
empirically in language models with specific objectives that should not suffer
directly from the same consequences. We also show that the anisotropy problem
extends to Transformers trained on other modalities. Our observations tend to
demonstrate that anisotropy might actually be inherent to Transformers-based
models.
</p></li>
</ul>

<h2>generative</h2>
<h3>Title: ATT3D: Amortized Text-to-3D Object Synthesis. (arXiv:2306.07349v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07349">http://arxiv.org/abs/2306.07349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07349] ATT3D: Amortized Text-to-3D Object Synthesis](http://arxiv.org/abs/2306.07349) #generative</code></li>
<li>Summary: <p>Text-to-3D modelling has seen exciting progress by combining generative
text-to-image models with image-to-3D methods like Neural Radiance Fields.
DreamFusion recently achieved high-quality results but requires a lengthy,
per-prompt optimization to create 3D objects. To address this, we amortize
optimization over text prompts by training on many prompts simultaneously with
a unified model, instead of separately. With this, we share computation across
a prompt set, training in less time than per-prompt optimization. Our framework</li>
<li>Amortized text-to-3D (ATT3D) - enables knowledge-sharing between prompts to
generalize to unseen setups and smooth interpolations between text for novel
assets and simple animations.
</p></li>
</ul>

<h3>Title: Dynamically Masked Discriminator for Generative Adversarial Networks. (arXiv:2306.07716v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07716">http://arxiv.org/abs/2306.07716</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07716] Dynamically Masked Discriminator for Generative Adversarial Networks](http://arxiv.org/abs/2306.07716) #generative</code></li>
<li>Summary: <p>Training Generative Adversarial Networks (GANs) remains a challenging
problem. The discriminator trains the generator by learning the distribution of
real/generated data. However, the distribution of generated data changes
throughout the training process, which is difficult for the discriminator to
learn. In this paper, we propose a novel method for GANs from the viewpoint of
online continual learning. We observe that the discriminator model, trained on
historically generated data, often slows down its adaptation to the changes in
the new arrival generated data, which accordingly decreases the quality of
generated results. By treating the generated data in training as a stream, we
propose to detect whether the discriminator slows down the learning of new
knowledge in generated data. Therefore, we can explicitly enforce the
discriminator to learn new knowledge fast. Particularly, we propose a new
discriminator, which automatically detects its retardation and then dynamically
masks its features, such that the discriminator can adaptively learn the
temporally-vary distribution of generated data. Experimental results show our
method outperforms the state-of-the-art approaches.
</p></li>
</ul>

<h3>Title: Compositionally Equivariant Representation Learning. (arXiv:2306.07783v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07783">http://arxiv.org/abs/2306.07783</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07783] Compositionally Equivariant Representation Learning](http://arxiv.org/abs/2306.07783) #generative</code></li>
<li>Summary: <p>Deep learning models often need sufficient supervision (i.e. labelled data)
in order to be trained effectively. By contrast, humans can swiftly learn to
identify important anatomy in medical images like MRI and CT scans, with
minimal guidance. This recognition capability easily generalises to new images
from different medical facilities and to new tasks in different settings. This
rapid and generalisable learning ability is largely due to the compositional
structure of image patterns in the human brain, which are not well represented
in current medical models. In this paper, we study the utilisation of
compositionality in learning more interpretable and generalisable
representations for medical image segmentation. Overall, we propose that the
underlying generative factors that are used to generate the medical images
satisfy compositional equivariance property, where each factor is compositional
(e.g. corresponds to the structures in human anatomy) and also equivariant to
the task. Hence, a good representation that approximates well the ground truth
factor has to be compositionally equivariant. By modelling the compositional
representations with learnable von-Mises-Fisher (vMF) kernels, we explore how
different design and learning biases can be used to enforce the representations
to be more compositionally equivariant under un-, weakly-, and semi-supervised
settings. Extensive results show that our methods achieve the best performance
over several strong baselines on the task of semi-supervised domain-generalised
medical image segmentation. Code will be made publicly available upon
acceptance at https://github.com/vios-s.
</p></li>
</ul>

<h3>Title: SqueezeLLM: Dense-and-Sparse Quantization. (arXiv:2306.07629v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07629">http://arxiv.org/abs/2306.07629</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07629] SqueezeLLM: Dense-and-Sparse Quantization](http://arxiv.org/abs/2306.07629) #generative</code></li>
<li>Summary: <p>Generative Large Language Models (LLMs) have demonstrated remarkable results
for a wide range of tasks. However, deploying these models for inference has
been a significant challenge due to their unprecedented resource requirements.
This has forced existing deployment frameworks to use multi-GPU inference
pipelines, which are often complex and costly, or to use smaller and less
performant models. In this work, we demonstrate that the main bottleneck for
generative inference with LLMs is memory bandwidth, rather than compute,
specifically for single batch inference. While quantization has emerged as a
promising solution by representing model weights with reduced precision,
previous efforts have often resulted in notable performance degradation. To
address this, we introduce SqueezeLLM, a post-training quantization framework
that not only enables lossless compression to ultra-low precisions of up to
3-bit, but also achieves higher quantization performance under the same memory
constraint. Our framework incorporates two novel ideas: (i) sensitivity-based
non-uniform quantization, which searches for the optimal bit precision
assignment based on second-order information; and (ii) the Dense-and-Sparse
decomposition that stores outliers and sensitive weight values in an efficient
sparse format. When applied to the LLaMA models, our 3-bit quantization
significantly reduces the perplexity gap from the FP16 baseline by up to 2.1x
as compared to the state-of-the-art methods with the same memory requirement.
Furthermore, when deployed on an A6000 GPU, our quantized models achieve up to
2.3x speedup compared to the baseline. Our code is open-sourced and available
online.
</p></li>
</ul>

<h3>Title: Generated Graph Detection. (arXiv:2306.07758v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07758">http://arxiv.org/abs/2306.07758</a></li>
<li>Code URL: <a href="https://github.com/yvonnemamama/ggd">https://github.com/yvonnemamama/ggd</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07758] Generated Graph Detection](http://arxiv.org/abs/2306.07758) #generative</code></li>
<li>Summary: <p>Graph generative models become increasingly effective for data distribution
approximation and data augmentation. While they have aroused public concerns
about their malicious misuses or misinformation broadcasts, just as what
Deepfake visual and auditory media has been delivering to society. Hence it is
essential to regulate the prevalence of generated graphs. To tackle this
problem, we pioneer the formulation of the generated graph detection problem to
distinguish generated graphs from real ones. We propose the first framework to
systematically investigate a set of sophisticated models and their performance
in four classification scenarios. Each scenario switches between seen and
unseen datasets/generators during testing to get closer to real-world settings
and progressively challenge the classifiers. Extensive experiments evidence
that all the models are qualified for generated graph detection, with specific
models having advantages in specific scenarios. Resulting from the validated
generality and oblivion of the classifiers to unseen datasets/generators, we
draw a safe conclusion that our solution can sustain for a decent while to curb
generated graph misuses.
</p></li>
</ul>

<h3>Title: Multi-objective Molecular Optimization for Opioid Use Disorder Treatment Using Generative Network Complex. (arXiv:2306.07484v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07484">http://arxiv.org/abs/2306.07484</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07484] Multi-objective Molecular Optimization for Opioid Use Disorder Treatment Using Generative Network Complex](http://arxiv.org/abs/2306.07484) #generative</code></li>
<li>Summary: <p>Opioid Use Disorder (OUD) has emerged as a significant global public health
issue, with complex multifaceted conditions. Due to the lack of effective
treatment options for various conditions, there is a pressing need for the
discovery of new medications. In this study, we propose a deep generative model
that combines a stochastic differential equation (SDE)-based diffusion modeling
with the latent space of a pretrained autoencoder model. The molecular
generator enables efficient generation of molecules that are effective on
multiple targets, specifically the mu, kappa, and delta opioid receptors.
Furthermore, we assess the ADMET (absorption, distribution, metabolism,
excretion, and toxicity) properties of the generated molecules to identify
drug-like compounds. To enhance the pharmacokinetic properties of some lead
compounds, we employ a molecular optimization approach. We obtain a diverse set
of drug-like molecules. We construct binding affinity predictors by integrating
molecular fingerprints derived from autoencoder embeddings, transformer
embeddings, and topological Laplacians with advanced machine learning
algorithms. Further experimental studies are needed to evaluate the
pharmacological effects of these drug-like compounds for OUD treatment. Our
machine learning platform serves as a valuable tool in designing and optimizing
effective molecules for addressing OUD.
</p></li>
</ul>

<h2>large language model</h2>
<h3>Title: XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models. (arXiv:2306.07971v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07971">http://arxiv.org/abs/2306.07971</a></li>
<li>Code URL: <a href="https://github.com/mbzuai-oryx/xraygpt">https://github.com/mbzuai-oryx/xraygpt</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07971] XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models](http://arxiv.org/abs/2306.07971) #large language model</code></li>
<li>Summary: <p>The latest breakthroughs in large vision-language models, such as Bard and
GPT-4, have showcased extraordinary abilities in performing a wide range of
tasks. Such models are trained on massive datasets comprising billions of
public image-text pairs with diverse tasks. However, their performance on
task-specific domains, such as radiology, is still under-investigated and
potentially limited due to a lack of sophistication in understanding biomedical
images. On the other hand, conversational medical models have exhibited
remarkable success but have mainly focused on text-based analysis. In this
paper, we introduce XrayGPT, a novel conversational medical vision-language
model that can analyze and answer open-ended questions about chest radiographs.
Specifically, we align both medical visual encoder (MedClip) with a fine-tuned
large language model (Vicuna), using a simple linear transformation. This
alignment enables our model to possess exceptional visual conversation
abilities, grounded in a deep understanding of radiographs and medical domain
knowledge. To enhance the performance of LLMs in the medical context, we
generate ~217k interactive and high-quality summaries from free-text radiology
reports. These summaries serve to enhance the performance of LLMs through the
fine-tuning process. Our approach opens up new avenues the research for
advancing the automated analysis of chest radiographs. Our open-source demos,
models, and instruction sets are available at:
https://github.com/mbzuai-oryx/XrayGPT.
</p></li>
</ul>

<h3>Title: Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification. (arXiv:2306.07297v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07297">http://arxiv.org/abs/2306.07297</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07297] Medical Data Augmentation via ChatGPT: A Case Study on Medication Identification and Medication Event Classification](http://arxiv.org/abs/2306.07297) #large language model</code></li>
<li>Summary: <p>The identification of key factors such as medications, diseases, and
relationships within electronic health records and clinical notes has a wide
range of applications in the clinical field. In the N2C2 2022 competitions,
various tasks were presented to promote the identification of key factors in
electronic health records (EHRs) using the Contextualized Medication Event
Dataset (CMED). Pretrained large language models (LLMs) demonstrated
exceptional performance in these tasks. This study aims to explore the
utilization of LLMs, specifically ChatGPT, for data augmentation to overcome
the limited availability of annotated data for identifying the key factors in
EHRs. Additionally, different pre-trained BERT models, initially trained on
extensive datasets like Wikipedia and MIMIC, were employed to develop models
for identifying these key variables in EHRs through fine-tuning on augmented
datasets. The experimental results of two EHR analysis tasks, namely medication
identification and medication event classification, indicate that data
augmentation based on ChatGPT proves beneficial in improving performance for
both medication identification and medication event classification.
</p></li>
</ul>

<h3>Title: Lost in Translation: Large Language Models in Non-English Content Analysis. (arXiv:2306.07377v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07377">http://arxiv.org/abs/2306.07377</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07377] Lost in Translation: Large Language Models in Non-English Content Analysis](http://arxiv.org/abs/2306.07377) #large language model</code></li>
<li>Summary: <p>In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa,
Google's PaLM) have become the dominant approach for building AI systems to
analyze and generate language online. However, the automated systems that
increasingly mediate our interactions online -- such as chatbots, content
moderation systems, and search engines -- are primarily designed for and work
far more effectively in English than in the world's other 7,000 languages.
Recently, researchers and technology companies have attempted to extend the
capabilities of large language models into languages other than English by
building what are called multilingual language models.
</p></li>
</ul>

<p>In this paper, we explain how these multilingual language models work and
explore their capabilities and limits. Part I provides a simple technical
explanation of how large language models work, why there is a gap in available
data between English and other languages, and how multilingual language models
attempt to bridge that gap. Part II accounts for the challenges of doing
content analysis with large language models in general and multilingual
language models in particular. Part III offers recommendations for companies,
researchers, and policymakers to keep in mind when considering researching,
developing and deploying large and multilingual language models.
</p>

<h3>Title: Probing Quantifier Comprehension in Large Language Models. (arXiv:2306.07384v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07384">http://arxiv.org/abs/2306.07384</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07384] Probing Quantifier Comprehension in Large Language Models](http://arxiv.org/abs/2306.07384) #large language model</code></li>
<li>Summary: <p>With their increasing size, Large language models (LLMs) are becoming
increasingly good at language understanding tasks. But even with high
performance on specific downstream task, LLMs fail at simple linguistic tests
for negation or quantifier understanding. Previous work on testing capability
of LLMs on understanding quantifiers suggest that as the size of the models
increase, they get better at understanding most-type quantifiers but get
increasingly worse at understanding few-type quantifiers, thus presenting a
case of an inverse-scaling law. In this paper, we question the claims of
inverse scaling of few-type quantifier understanding in LLMs and show that it
is a result of inappropriate testing methodology. We also present alternate
methods to measure quantifier comprehension in LLMs and show that as the size
of the models increase, these behaviours are different from what is shown in
previous research. LLMs are consistently able to understand the difference
between the meaning of few-type and most-type quantifiers, but when a
quantifier is added to phrase, LLMs do not always take into account the meaning
of the quantifier. We in fact see an inverse scaling law for most-type
quantifiers, which is contrary to human psycho-linguistic experiments and
previous work, where the model's understanding of most-type quantifier gets
worse as the model size increases. We do this evaluation on models ranging from
125M-175B parameters, which suggests that LLMs do not do as well as expected
with quantifiers and statistical co-occurrence of words still takes precedence
over word meaning.
</p></li>
</ul>

<h3>Title: The economic trade-offs of large language models: A case study. (arXiv:2306.07402v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07402">http://arxiv.org/abs/2306.07402</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07402] The economic trade-offs of large language models: A case study](http://arxiv.org/abs/2306.07402) #large language model</code></li>
<li>Summary: <p>Contacting customer service via chat is a common practice. Because employing
customer service agents is expensive, many companies are turning to NLP that
assists human agents by auto-generating responses that can be used directly or
with modifications. Large Language Models (LLMs) are a natural fit for this use
case; however, their efficacy must be balanced with the cost of training and
serving them. This paper assesses the practical cost and impact of LLMs for the
enterprise as a function of the usefulness of the responses that they generate.
We present a cost framework for evaluating an NLP model's utility for this use
case and apply it to a single brand as a case study in the context of an
existing agent assistance product. We compare three strategies for specializing
an LLM - prompt engineering, fine-tuning, and knowledge distillation - using
feedback from the brand's customer service agents. We find that the usability
of a model's responses can make up for a large difference in inference cost for
our case study brand, and we extrapolate our findings to the broader enterprise
space.
</p></li>
</ul>

<h3>Title: Large Language Models Sometimes Generate Purely Negatively-Reinforced Text. (arXiv:2306.07567v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07567">http://arxiv.org/abs/2306.07567</a></li>
<li>Code URL: <a href="https://github.com/fabienroger/learning-from-negative-examples">https://github.com/fabienroger/learning-from-negative-examples</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07567] Large Language Models Sometimes Generate Purely Negatively-Reinforced Text](http://arxiv.org/abs/2306.07567) #large language model</code></li>
<li>Summary: <p>When using adversarial training, it is common practice to train against the
most egregious failures. However, this might imply using examples with
sensitive information (such as leaked passwords or security vulnerabilities) as
training data. One might assume that language models trained with gradient
descent never generate text snippets which were only present in examples
associated with the lowest possible reward. In this paper, we show that this
assumption is wrong: in some situations, large language models do learn from
such negatively-reinforced examples. We present a specific training setup that
enables Pythia-160M to generate passwords with a probability slightly greater
than chance, despite only showing it these passwords on examples where the
model is incentivized to not output these passwords. Our code is available at
https://github.com/FabienRoger/Learning-From-Negative-Examples
</p></li>
</ul>

<h3>Title: Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4. (arXiv:2306.07622v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07622">http://arxiv.org/abs/2306.07622</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07622] Human-Like Intuitive Behavior and Reasoning Biases Emerged in Language Models -- and Disappeared in GPT-4](http://arxiv.org/abs/2306.07622) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) are currently at the forefront of intertwining
AI systems with human communication and everyday life. Therefore, it is of
great importance to evaluate their emerging abilities. In this study, we show
that LLMs, most notably GPT-3, exhibit behavior that strikingly resembles
human-like intuition -- and the cognitive errors that come with it. However,
LLMs with higher cognitive capabilities, in particular ChatGPT and GPT-4,
learned to avoid succumbing to these errors and perform in a hyperrational
manner. For our experiments, we probe LLMs with the Cognitive Reflection Test
(CRT) as well as semantic illusions that were originally designed to
investigate intuitive decision-making in humans. Moreover, we probe how sturdy
the inclination for intuitive-like decision-making is. Our study demonstrates
that investigating LLMs with methods from psychology has the potential to
reveal otherwise unknown emergent traits.
</p></li>
</ul>

<h3>Title: NoCoLA: The Norwegian Corpus of Linguistic Acceptability. (arXiv:2306.07790v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07790">http://arxiv.org/abs/2306.07790</a></li>
<li>Code URL: <a href="https://github.com/ltgoslo/nocola">https://github.com/ltgoslo/nocola</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07790] NoCoLA: The Norwegian Corpus of Linguistic Acceptability](http://arxiv.org/abs/2306.07790) #large language model</code></li>
<li>Summary: <p>While there has been a surge of large language models for Norwegian in recent
years, we lack any tool to evaluate their understanding of grammaticality. We
present two new Norwegian datasets for this task. NoCoLA_class is a supervised
binary classification task where the goal is to discriminate between acceptable
and non-acceptable sentences. On the other hand, NoCoLA_zero is a purely
diagnostic task for evaluating the grammatical judgement of a language model in
a completely zero-shot manner, i.e. without any further training. In this
paper, we describe both datasets in detail, show how to use them for different
flavors of language models, and conduct a comparative study of the existing
Norwegian language models.
</p></li>
</ul>

<h3>Title: Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks. (arXiv:2306.07899v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07899">http://arxiv.org/abs/2306.07899</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07899] Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks](http://arxiv.org/abs/2306.07899) #large language model</code></li>
<li>Summary: <p>Large language models (LLMs) are remarkable data annotators. They can be used
to generate high-fidelity supervised training data, as well as survey and
experimental data. With the widespread adoption of LLMs, human gold--standard
annotations are key to understanding the capabilities of LLMs and the validity
of their results. However, crowdsourcing, an important, inexpensive way to
obtain human annotations, may itself be impacted by LLMs, as crowd workers have
financial incentives to use LLMs to increase their productivity and income. To
investigate this concern, we conducted a case study on the prevalence of LLM
usage by crowd workers. We reran an abstract summarization task from the
literature on Amazon Mechanical Turk and, through a combination of keystroke
detection and synthetic text classification, estimate that 33-46% of crowd
workers used LLMs when completing the task. Although generalization to other,
less LLM-friendly tasks is unclear, our results call for platforms,
researchers, and crowd workers to find new ways to ensure that human data
remain human, perhaps using the methodology proposed here as a stepping stone.
Code/data: https://github.com/epfl-dlab/GPTurk
</p></li>
</ul>

<h3>Title: Large Language Model Is Semi-Parametric Reinforcement Learning Agent. (arXiv:2306.07929v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07929">http://arxiv.org/abs/2306.07929</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07929] Large Language Model Is Semi-Parametric Reinforcement Learning Agent](http://arxiv.org/abs/2306.07929) #large language model</code></li>
<li>Summary: <p>Inspired by the insights in cognitive science with respect to human memory
and reasoning mechanism, a novel evolvable LLM-based (Large Language Model)
agent framework is proposed as REMEMBERER. By equipping the LLM with a
long-term experience memory, REMEMBERER is capable of exploiting the
experiences from the past episodes even for different task goals, which excels
an LLM-based agent with fixed exemplars or equipped with a transient working
memory. We further introduce Reinforcement Learning with Experience Memory
(RLEM) to update the memory. Thus, the whole system can learn from the
experiences of both success and failure, and evolve its capability without
fine-tuning the parameters of the LLM. In this way, the proposed REMEMBERER
constitutes a semi-parametric RL agent. Extensive experiments are conducted on
two RL task sets to evaluate the proposed framework. The average results with
different initialization and training sets exceed the prior SOTA by 4% and 2%
for the success rate on two task sets and demonstrate the superiority and
robustness of REMEMBERER.
</p></li>
</ul>

<h3>Title: Understanding Telecom Language Through Large Language Models. (arXiv:2306.07933v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07933">http://arxiv.org/abs/2306.07933</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07933] Understanding Telecom Language Through Large Language Models](http://arxiv.org/abs/2306.07933) #large language model</code></li>
<li>Summary: <p>The recent progress of artificial intelligence (AI) opens up new frontiers in
the possibility of automating many tasks involved in Telecom networks design,
implementation, and deployment. This has been further pushed forward with the
evolution of generative artificial intelligence (AI), including the emergence
of large language models (LLMs), which is believed to be the cornerstone toward
realizing self-governed, interactive AI agents. Motivated by this, in this
paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In
particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa
and GPT-2, to the Telecom domain languages, and demonstrate a use case for
identifying the 3rd Generation Partnership Project (3GPP) standard working
groups. We consider training the selected models on 3GPP technical documents
(Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years
2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model
achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP
working groups. The distilled BERT model with around 50% less parameters
achieves similar performance as others. This corroborates that fine-tuning
pretrained LLM can effectively identify the categories of Telecom language. The
developed framework shows a stepping stone towards realizing intent-driven and
self-evolving wireless networks from Telecom languages, and paves the way for
the implementation of generative AI in the Telecom domain.
</p></li>
</ul>

<h3>Title: GPT-Calls: Enhancing Call Segmentation and Tagging by Generating Synthetic Conversations via Large Language Models. (arXiv:2306.07941v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07941">http://arxiv.org/abs/2306.07941</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07941] GPT-Calls: Enhancing Call Segmentation and Tagging by Generating Synthetic Conversations via Large Language Models](http://arxiv.org/abs/2306.07941) #large language model</code></li>
<li>Summary: <p>Transcriptions of phone calls are of significant value across diverse fields,
such as sales, customer service, healthcare, and law enforcement. Nevertheless,
the analysis of these recorded conversations can be an arduous and
time-intensive process, especially when dealing with extended or multifaceted
dialogues. In this work, we propose a novel method, GPT-distilled Calls
Segmentation and Tagging (GPT-Calls), for efficient and accurate call
segmentation and topic extraction. GPT-Calls is composed of offline and online
phases. The offline phase is applied once to a given list of topics and
involves generating a distribution of synthetic sentences for each topic using
a GPT model and extracting anchor vectors. The online phase is applied to every
call separately and scores the similarity between the transcripted conversation
and the topic anchors found in the offline phase. Then, time domain analysis is
applied to the similarity scores to group utterances into segments and tag them
with topics. The proposed paradigm provides an accurate and efficient method
for call segmentation and topic extraction that does not require labeled data,
thus making it a versatile approach applicable to various domains. Our
algorithm operates in production under Dynamics 365 Sales Conversation
Intelligence, and our research is based on real sales conversations gathered
from various Dynamics 365 Sales tenants.
</p></li>
</ul>

<h3>Title: Questioning the Survey Responses of Large Language Models. (arXiv:2306.07951v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07951">http://arxiv.org/abs/2306.07951</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07951] Questioning the Survey Responses of Large Language Models](http://arxiv.org/abs/2306.07951) #large language model</code></li>
<li>Summary: <p>As large language models increase in capability, researchers have started to
conduct surveys of all kinds on these models with varying scientific
motivations. In this work, we examine what we can learn from a model's survey
responses on the basis of the well-established American Community Survey (ACS)
by the U.S. Census Bureau. Evaluating more than a dozen different models,
varying in size from a few hundred million to ten billion parameters, hundreds
of thousands of times each on questions from the ACS, we systematically
establish two dominant patterns. First, smaller models have a significant
position and labeling bias, for example, towards survey responses labeled with
the letter "A". This A-bias diminishes, albeit slowly, as model size increases.
Second, when adjusting for this labeling bias through randomized answer
ordering, models still do not trend toward US population statistics or those of
any cognizable population. Rather, models across the board trend toward
uniformly random aggregate statistics over survey responses. This pattern is
robust to various different ways of prompting the model, including what is the
de-facto standard. Our findings demonstrate that aggregate statistics of a
language model's survey responses lack the signals found in human populations.
This absence of statistical signal cautions about the use of survey responses
from large language models at present time.
</p></li>
</ul>

<h3>Title: arXiVeri: Automatic table verification with GPT. (arXiv:2306.07968v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07968">http://arxiv.org/abs/2306.07968</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07968] arXiVeri: Automatic table verification with GPT](http://arxiv.org/abs/2306.07968) #large language model</code></li>
<li>Summary: <p>Without accurate transcription of numerical data in scientific documents, a
scientist cannot draw accurate conclusions. Unfortunately, the process of
copying numerical data from one paper to another is prone to human error. In
this paper, we propose to meet this challenge through the novel task of
automatic table verification (AutoTV), in which the objective is to verify the
accuracy of numerical data in tables by cross-referencing cited sources. To
support this task, we propose a new benchmark, arXiVeri, which comprises
tabular data drawn from open-access academic papers on arXiv. We introduce
metrics to evaluate the performance of a table verifier in two key areas: (i)
table matching, which aims to identify the source table in a cited document
that corresponds to a target table, and (ii) cell matching, which aims to
locate shared cells between a target and source table and identify their row
and column indices accurately. By leveraging the flexible capabilities of
modern large language models (LLMs), we propose simple baselines for table
verification. Our findings highlight the complexity of this task, even for
state-of-the-art LLMs like OpenAI's GPT-4. The code and benchmark will be made
publicly available.
</p></li>
</ul>

<h2>segmentation</h2>
<h3>Title: Referring Camouflaged Object Detection. (arXiv:2306.07532v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07532">http://arxiv.org/abs/2306.07532</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07532] Referring Camouflaged Object Detection](http://arxiv.org/abs/2306.07532) #segmentation</code></li>
<li>Summary: <p>In this paper, we consider the problem of referring camouflaged object
detection (Ref-COD), a new task that aims to segment specified camouflaged
objects based on some form of reference, e.g., image, text. We first assemble a
large-scale dataset, called R2C7K, which consists of 7K images covering 64
object categories in real-world scenarios. Then, we develop a simple but strong
dual-branch framework, dubbed R2CNet, with a reference branch learning common
representations from the referring information and a segmentation branch
identifying and segmenting camouflaged objects under the guidance of the common
representations. In particular, we design a Referring Mask Generation module to
generate pixel-level prior mask and a Referring Feature Enrichment module to
enhance the capability of identifying camouflaged objects. Extensive
experiments show the superiority of our Ref-COD methods over their COD
counterparts in segmenting specified camouflaged objects and identifying the
main body of target objects. Our code and dataset are publicly available at
https://github.com/zhangxuying1004/RefCOD.
</p></li>
</ul>

<h3>Title: Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D Point Clouds via Signature Shape Identification. (arXiv:2306.07809v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07809">http://arxiv.org/abs/2306.07809</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07809] Low-Resource White-Box Semantic Segmentation of Supporting Towers on 3D Point Clouds via Signature Shape Identification](http://arxiv.org/abs/2306.07809) #segmentation</code></li>
<li>Summary: <p>Research in 3D semantic segmentation has been increasing performance metrics,
like the IoU, by scaling model complexity and computational resources, leaving
behind researchers and practitioners that (1) cannot access the necessary
resources and (2) do need transparency on the model decision mechanisms. In
this paper, we propose SCENE-Net, a low-resource white-box model for 3D point
cloud semantic segmentation. SCENE-Net identifies signature shapes on the point
cloud via group equivariant non-expansive operators (GENEOs), providing
intrinsic geometric interpretability. Our training time on a laptop is 85~min,
and our inference time is 20~ms. SCENE-Net has 11 trainable geometrical
parameters and requires fewer data than black-box models. SCENE--Net offers
robustness to noisy labeling and data imbalance and has comparable IoU to
state-of-the-art methods. With this paper, we release a 40~000 Km labeled
dataset of rural terrain point clouds and our code implementation.
</p></li>
</ul>

<h3>Title: PSSTRNet: Progressive Segmentation-guided Scene Text Removal Network. (arXiv:2306.07842v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07842">http://arxiv.org/abs/2306.07842</a></li>
<li>Code URL: <a href="https://github.com/guangtaolyu/psstrnet">https://github.com/guangtaolyu/psstrnet</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07842] PSSTRNet: Progressive Segmentation-guided Scene Text Removal Network](http://arxiv.org/abs/2306.07842) #segmentation</code></li>
<li>Summary: <p>Scene text removal (STR) is a challenging task due to the complex text fonts,
colors, sizes, and background textures in scene images. However, most previous
methods learn both text location and background inpainting implicitly within a
single network, which weakens the text localization mechanism and makes a lossy
background. To tackle these problems, we propose a simple Progressive
Segmentation-guided Scene Text Removal Network(PSSTRNet) to remove the text in
the image iteratively. It contains two decoder branches, a text segmentation
branch, and a text removal branch, with a shared encoder. The text segmentation
branch generates text mask maps as the guidance for the regional removal
branch. In each iteration, the original image, previous text removal result,
and text mask are input to the network to extract the rest part of the text
segments and cleaner text removal result. To get a more accurate text mask map,
an update module is developed to merge the mask map in the current and previous
stages. The final text removal result is obtained by adaptive fusion of results
from all previous stages. A sufficient number of experiments and ablation
studies conducted on the real and synthetic public datasets demonstrate our
proposed method achieves state-of-the-art performance. The source code of our
work is available at:
\href{https://github.com/GuangtaoLyu/PSSTRNet}{https://github.com/GuangtaoLyu/PSSTRNet.}
</p></li>
</ul>

<h3>Title: VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON. (arXiv:2306.07890v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07890">http://arxiv.org/abs/2306.07890</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07890] VISION Datasets: A Benchmark for Vision-based InduStrial InspectiON](http://arxiv.org/abs/2306.07890) #segmentation</code></li>
<li>Summary: <p>Despite progress in vision-based inspection algorithms, real-world industrial
challenges -- specifically in data availability, quality, and complex
production requirements -- often remain under-addressed. We introduce the
VISION Datasets, a diverse collection of 14 industrial inspection datasets,
uniquely poised to meet these challenges. Unlike previous datasets, VISION
brings versatility to defect detection, offering annotation masks across all
splits and catering to various detection methodologies. Our datasets also
feature instance-segmentation annotation, enabling precise defect
identification. With a total of 18k images encompassing 44 defect types, VISION
strives to mirror a wide range of real-world production scenarios. By
supporting two ongoing challenge competitions on the VISION Datasets, we hope
to foster further advancements in vision-based industrial inspection.
</p></li>
</ul>

<h3>Title: Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks. (arXiv:2306.07294v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2306.07294">http://arxiv.org/abs/2306.07294</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2306.07294] Expressivity Enhancement with Efficient Quadratic Neurons for Convolutional Neural Networks](http://arxiv.org/abs/2306.07294) #segmentation</code></li>
<li>Summary: <p>Convolutional neural networks (CNNs) have been successfully applied in a
range of fields such as image classification and object segmentation. To
improve their expressivity, various techniques, such as novel CNN
architectures, have been explored. However, the performance gain from such
techniques tends to diminish. To address this challenge, many researchers have
shifted their focus to increasing the non-linearity of neurons, the fundamental
building blocks of neural networks, to enhance the network expressivity.
Nevertheless, most of these approaches incur a large number of parameters and
thus formidable computation cost inevitably, impairing their efficiency to be
deployed in practice. In this work, an efficient quadratic neuron structure is
proposed to preserve the non-linearity with only negligible parameter and
computation cost overhead. The proposed quadratic neuron can maximize the
utilization of second-order computation information to improve the network
performance. The experimental results have demonstrated that the proposed
quadratic neuron can achieve a higher accuracy and a better computation
efficiency in classification tasks compared with both linear neurons and
non-linear neurons from previous works.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
