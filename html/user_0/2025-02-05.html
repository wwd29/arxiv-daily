<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-05</h1>
<h3>Title: Fine-tuning LLaMA 2 interference: a comparative study of language implementations for optimal efficiency</h3>
<ul>
<li><strong>Authors: </strong>Sazzad Hossain, Touhidul Alam Seyam, Avijit Chowdhury, Munis Xamidov, Rajib Ghose, Abhijit Pathak</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01651">https://arxiv.org/abs/2502.01651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01651">https://arxiv.org/pdf/2502.01651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01651]] Fine-tuning LLaMA 2 interference: a comparative study of language implementations for optimal efficiency(https://arxiv.org/abs/2502.01651)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This paper presents a comparative study aimed at optimizing Llama2 inference, a critical aspect of machine learning and natural language processing (NLP). We evaluate various programming languages and frameworks, including TensorFlow, PyTorch, Python, Mojo, C++, and Java, analyzing their performance in terms of speed, memory consumption, and ease of implementation through extensive benchmarking. Strengths and limitations of each approach are highlighted, along with proposed optimization strategies for parallel processing and hardware utilization. Furthermore, we investigate the Mojo SDK, a novel framework designed for large language model (LLM) inference on Apple Silicon, benchmarking its performance against implementations in C, C++, Rust, Zig, Go, and Julia. Our experiments, conducted on an Apple M1 Max, demonstrate Mojo SDK's competitive performance, ease of use, and seamless Python compatibility, positioning it as a strong alternative for LLM inference on Apple Silicon. We also discuss broader implications for LLM deployment on resource-constrained hardware and identify potential directions for future research.</li>
</ul>

<h3>Title: Hybrid Group Relative Policy Optimization: A Multi-Sample Approach to Enhancing Policy Optimization</h3>
<ul>
<li><strong>Authors: </strong>Soham Sane</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01652">https://arxiv.org/abs/2502.01652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01652">https://arxiv.org/pdf/2502.01652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01652]] Hybrid Group Relative Policy Optimization: A Multi-Sample Approach to Enhancing Policy Optimization(https://arxiv.org/abs/2502.01652)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Hybrid Group Relative Policy Optimization (Hybrid GRPO) is a reinforcement learning framework that extends Proximal Policy Optimization (PPO) and Group Relative Policy Optimization (GRPO) by incorporating empirical multi-sample action evaluation while preserving the stability of value function-based learning. Unlike DeepSeek GRPO, which eliminates the value function in favor of purely empirical reward estimation, Hybrid GRPO introduces a structured advantage computation method that balances empirical action sampling with bootstrapped value estimation. This approach enhances sample efficiency, improves learning stability, and mitigates variance amplification observed in purely empirical methods. A detailed mathematical comparison between PPO, DeepSeek GRPO, and Hybrid GRPO is presented, highlighting key differences in advantage estimation and policy updates. Experimental validation in a controlled reinforcement learning environment demonstrates that Hybrid GRPO achieves superior convergence speed, more stable policy updates, and improved sample efficiency compared to existing methods. Several extensions to Hybrid GRPO are explored, including entropy-regularized sampling, hierarchical multi-step sub-sampling, adaptive reward normalization, and value-based action selection. Beyond reinforcement learning in simulated environments, Hybrid GRPO provides a scalable framework for bridging the gap between large language models (LLMs) and real-world agent-based decision-making. By integrating structured empirical sampling with reinforcement learning stability mechanisms, Hybrid GRPO has potential applications in autonomous robotics, financial modeling, and AI-driven control systems. These findings suggest that Hybrid GRPO serves as a robust and adaptable reinforcement learning methodology, paving the way for further advancements in policy optimization.</li>
</ul>

<h3>Title: Predicting concentration levels of air pollutants by transfer learning and recurrent neural network</h3>
<ul>
<li><strong>Authors: </strong>Iat Hang Fong, Tengyue Li, Simon Fong, Raymond K. Wong, Antonio J. Tall√≥n-Ballesteros</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.NE, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01654">https://arxiv.org/abs/2502.01654</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01654">https://arxiv.org/pdf/2502.01654</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01654]] Predicting concentration levels of air pollutants by transfer learning and recurrent neural network(https://arxiv.org/abs/2502.01654)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>Air pollution (AP) poses a great threat to human health, and people are paying more attention than ever to its prediction. Accurate prediction of AP helps people to plan for their outdoor activities and aids protecting human health. In this paper, long-short term memory (LSTM) recurrent neural networks (RNNs) have been used to predict the future concentration of air pollutants (APS) in Macau. Additionally, meteorological data and data on the concentration of APS have been utilized. Moreover, in Macau, some air quality monitoring stations (AQMSs) have less observed data in quantity, and, at the same time, some AQMSs recorded less observed data of certain types of APS. Therefore, the transfer learning and pre-trained neural networks have been employed to assist AQMSs with less observed data to build a neural network with high prediction accuracy. The experimental sample covers a period longer than 12-year and includes daily measurements from several APS as well as other more classical meteorological values. Records from five stations, four out of them are AQMSs and the remaining one is an automatic weather station, have been prepared from the aforesaid period and eventually underwent to computational intelligence techniques to build and extract a prediction knowledge-based system. As shown by experimentation, LSTM RNNs initialized with transfer learning methods have higher prediction accuracy; it incurred shorter training time than randomly initialized recurrent neural networks.</li>
</ul>

<h3>Title: Improving Rule-based Reasoning in LLMs via Neurosymbolic Representations</h3>
<ul>
<li><strong>Authors: </strong>Varun Dhanraj, Chris Eliasmith</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01657">https://arxiv.org/abs/2502.01657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01657">https://arxiv.org/pdf/2502.01657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01657]] Improving Rule-based Reasoning in LLMs via Neurosymbolic Representations(https://arxiv.org/abs/2502.01657)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) continue to face challenges in reliably solving reasoning tasks, particularly tasks that involve precise rule following, as often found in mathematical reasoning tasks. This paper introduces a novel neurosymbolic method that improves LLM reasoning by encoding hidden states into neurosymbolic vectors, allowing for problem-solving within a neurosymbolic vector space. The results are decoded and combined with the original hidden state, boosting the model's performance on numerical reasoning tasks. By offloading computation through neurosymbolic representations, this method improves efficiency, reliability, and interpretability. Our experimental results demonstrate an average of $82.86\%$ lower cross entropy loss and $24.50$ times more problems correctly solved on a suite of mathematical reasoning problems compared to chain-of-thought prompting and supervised fine-tuning (LoRA), while at the same time not hindering the performance of the LLM on other tasks.</li>
</ul>

<h3>Title: Large Language Models' Accuracy in Emulating Human Experts' Evaluation of Public Sentiments about Heated Tobacco Products on Social Media</h3>
<ul>
<li><strong>Authors: </strong>Kwanho Kim, Soojong Kim</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01658">https://arxiv.org/abs/2502.01658</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01658">https://arxiv.org/pdf/2502.01658</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01658]] Large Language Models' Accuracy in Emulating Human Experts' Evaluation of Public Sentiments about Heated Tobacco Products on Social Media(https://arxiv.org/abs/2502.01658)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Sentiment analysis of alternative tobacco products on social media is important for tobacco control research. Large Language Models (LLMs) can help streamline the labor-intensive human sentiment analysis process. This study examined the accuracy of LLMs in replicating human sentiment evaluation of social media messages about heated tobacco products (HTPs). The research used GPT-3.5 and GPT-4 Turbo to classify 500 Facebook and 500 Twitter messages, including anti-HTPs, pro-HTPs, and neutral messages. The models evaluated each message up to 20 times, and their majority label was compared to human evaluators. Results showed that GPT-3.5 accurately replicated human sentiment 61.2% of the time for Facebook messages and 57.0% for Twitter messages. GPT-4 Turbo performed better, with 81.7% accuracy for Facebook and 77.0% for Twitter. Using three response instances, GPT-4 Turbo achieved 99% of the accuracy of twenty instances. GPT-4 Turbo also had higher accuracy for anti- and pro-HTPs messages compared to neutral ones. Misclassifications by GPT-3.5 often involved anti- or pro-HTPs messages being labeled as neutral or irrelevant, while GPT-4 Turbo showed improvements across all categories. In conclusion, LLMs can be used for sentiment analysis of HTP-related social media messages, with GPT-4 Turbo reaching around 80% accuracy compared to human experts. However, there's a risk of misrepresenting overall sentiment due to differences in accuracy across sentiment categories.</li>
</ul>

<h3>Title: Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques</h3>
<ul>
<li><strong>Authors: </strong>Nathaniel Tomczak, Sanmukh Kuppannagari</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.DC, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01659">https://arxiv.org/abs/2502.01659</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01659">https://arxiv.org/pdf/2502.01659</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01659]] Longer Attention Span: Increasing Transformer Context Length with Sparse Graph Processing Techniques(https://arxiv.org/abs/2502.01659)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformers have demonstrated great success in numerous domains including natural language processing and bioinformatics. This success stems from the use of the attention mechanism by these models in order to represent and propagate pairwise interactions between individual tokens of sequential data. However, the primary limitation of this operation is its quadratic memory and time complexity in relation to the input's context length - the length of a sequence over which the interactions need to be captured. This significantly limits the length of sequences that can be inferred upon by these models. Extensive research has been conducted to reduce the number of pairwise interactions to sub-quadratic in relation to the context length by introducing sparsity into the attention mechanism through the development of sparse attention masks. However, efficient implementations that achieve "true sparsity" are lacking. In this work, we address this issue by proposing a graph computing view of attention where tokens are perceived as nodes of the graph and the attention mask determines the edges of the graph. Using this view, we develop graph processing algorithms to implement the attention mechanism. Both theoretically and empirically, we demonstrate that our algorithms only perform the needed computations, i.e., they are work optimal. We also perform extensive experimentation using popular attention masks to explore the impact of sparsity on execution time and achievable context length. Our experiments demonstrate significant speedups in execution times compared to state-of-the-art attention implementations such as FlashAttention for large sequence lengths. We also demonstrate that our algorithms are able to achieve extremely long sequence lengths of as high as 160 million on a single NVIDIA A100 GPU (SXM4 80GB).</li>
</ul>

<h3>Title: Employee Turnover Prediction: A Cross-component Attention Transformer with Consideration of Competitor Influence and Contagious Effect</h3>
<ul>
<li><strong>Authors: </strong>Hao Liu (Deakin University), Yong Ge (The University of Arizona)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01660">https://arxiv.org/abs/2502.01660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01660">https://arxiv.org/pdf/2502.01660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01660]] Employee Turnover Prediction: A Cross-component Attention Transformer with Consideration of Competitor Influence and Contagious Effect(https://arxiv.org/abs/2502.01660)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Employee turnover refers to an individual's termination of employment from the current organization. It is one of the most persistent challenges for firms, especially those ones in Information Technology (IT) industry that confront high turnover rates. Effective prediction of potential employee turnovers benefits multiple stakeholders such as firms and online recruiters. Prior studies have focused on either the turnover prediction within a single firm or the aggregated employee movement among firms. How to predict the individual employees' turnovers among multiple firms has gained little attention in literature, and thus remains a great research challenge. In this study, we propose a novel deep learning approach based on job embeddedness theory to predict the turnovers of individual employees across different firms. Through extensive experimental evaluations using a real-world dataset, our developed method demonstrates superior performance over several state-of-the-art benchmark methods. Additionally, we estimate the cost saving for recruiters by using our turnover prediction solution and interpret the attributions of various driving factors to employee's turnover to showcase its practical business value.</li>
</ul>

<h3>Title: Speculative Ensemble: Fast Large Language Model Ensemble via Speculation</h3>
<ul>
<li><strong>Authors: </strong>Jiale Fu, Yuchu Jiang, Junkai Chen, Jiaming Fan, Xin Geng, Xu Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01662">https://arxiv.org/abs/2502.01662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01662">https://arxiv.org/pdf/2502.01662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01662]] Speculative Ensemble: Fast Large Language Model Ensemble via Speculation(https://arxiv.org/abs/2502.01662)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Ensemble methods enhance Large Language Models (LLMs) by combining multiple models but suffer from high computational costs. In this paper, we introduce Speculative Ensemble, a novel framework that accelerates LLM ensembles without sacrificing performance, inspired by Speculative Decoding-where a small proposal model generates tokens sequentially, and a larger target model verifies them in parallel. Our approach builds on two key insights: (1) the verification distribution can be the ensemble distribution of both the proposal and target models, and (2) alternating each model as the proposer and verifier can further enhance efficiency. We generalize this method to ensembles with n models and theoretically prove that SE is never slower than a standard ensemble, typically achieving faster speed. Extensive experiments demonstrate speed improvements of 1.11x-2.23x over standard ensemble techniques without compromising generation quality. Our code is available at this https URL</li>
</ul>

<h3>Title: Explainable AI for Sentiment Analysis of Human Metapneumovirus (HMPV) Using XLNet</h3>
<ul>
<li><strong>Authors: </strong>Md. Shahriar Hossain Apu, Md Saiful Islam, Tanjim Taharat Aurpa</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01663">https://arxiv.org/abs/2502.01663</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01663">https://arxiv.org/pdf/2502.01663</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01663]] Explainable AI for Sentiment Analysis of Human Metapneumovirus (HMPV) Using XLNet(https://arxiv.org/abs/2502.01663)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>In 2024, the outbreak of Human Metapneumovirus (HMPV) in China, which later spread to the UK and other countries, raised significant public concern. While HMPV typically causes mild symptoms, its effects on vulnerable individuals prompted health authorities to emphasize preventive measures. This paper explores how sentiment analysis can enhance our understanding of public reactions to HMPV by analyzing social media data. We apply transformer models, particularly XLNet, achieving 93.50% accuracy in sentiment classification. Additionally, we use explainable AI (XAI) through SHAP to improve model transparency.</li>
</ul>

<h3>Title: Leveraging Stable Diffusion for Monocular Depth Estimation via Image Semantic Encoding</h3>
<ul>
<li><strong>Authors: </strong>Jingming Xia, Guanqun Cao, Guang Ma, Yiben Luo, Qinzhao Li, John Oyekan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01666">https://arxiv.org/abs/2502.01666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01666">https://arxiv.org/pdf/2502.01666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01666]] Leveraging Stable Diffusion for Monocular Depth Estimation via Image Semantic Encoding(https://arxiv.org/abs/2502.01666)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, diffusion, generative</a></li>
<li><strong>Abstract: </strong>Monocular depth estimation involves predicting depth from a single RGB image and plays a crucial role in applications such as autonomous driving, robotic navigation, 3D reconstruction, etc. Recent advancements in learning-based methods have significantly improved depth estimation performance. Generative models, particularly Stable Diffusion, have shown remarkable potential in recovering fine details and reconstructing missing regions through large-scale training on diverse datasets. However, models like CLIP, which rely on textual embeddings, face limitations in complex outdoor environments where rich context information is needed. These limitations reduce their effectiveness in such challenging scenarios. Here, we propose a novel image-based semantic embedding that extracts contextual information directly from visual features, significantly improving depth prediction in complex environments. Evaluated on the KITTI and Waymo datasets, our method achieves performance comparable to state-of-the-art models while addressing the shortcomings of CLIP embeddings in handling outdoor scenes. By leveraging visual semantics directly, our method demonstrates enhanced robustness and adaptability in depth estimation tasks, showcasing its potential for application to other visual perception tasks.</li>
</ul>

<h3>Title: Refining Alignment Framework for Diffusion Models with Intermediate-Step Preference Ranking</h3>
<ul>
<li><strong>Authors: </strong>Jie Ren, Yuhang Zhang, Dongrui Liu, Xiaopeng Zhang, Qi Tian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01667">https://arxiv.org/abs/2502.01667</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01667">https://arxiv.org/pdf/2502.01667</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01667]] Refining Alignment Framework for Diffusion Models with Intermediate-Step Preference Ranking(https://arxiv.org/abs/2502.01667)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Direct preference optimization (DPO) has shown success in aligning diffusion models with human preference. Previous approaches typically assume a consistent preference label between final generations and noisy samples at intermediate steps, and directly apply DPO to these noisy samples for fine-tuning. However, we theoretically identify inherent issues in this assumption and its impacts on the effectiveness of preference alignment. We first demonstrate the inherent issues from two perspectives: gradient direction and preference order, and then propose a Tailored Preference Optimization (TailorPO) framework for aligning diffusion models with human preference, underpinned by some theoretical insights. Our approach directly ranks intermediate noisy samples based on their step-wise reward, and effectively resolves the gradient direction issues through a simple yet efficient design. Additionally, we incorporate the gradient guidance of diffusion models into preference alignment to further enhance the optimization effectiveness. Experimental results demonstrate that our method significantly improves the model's ability to generate aesthetically pleasing and human-preferred images.</li>
</ul>

<h3>Title: Semantic Communication based on Generative AI: A New Approach to Image Compression and Edge Optimization</h3>
<ul>
<li><strong>Authors: </strong>Francesco Pezone</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01675">https://arxiv.org/abs/2502.01675</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01675">https://arxiv.org/pdf/2502.01675</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01675]] Semantic Communication based on Generative AI: A New Approach to Image Compression and Edge Optimization(https://arxiv.org/abs/2502.01675)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>As digital technologies advance, communication networks face challenges in handling the vast data generated by intelligent devices. Autonomous vehicles, smart sensors, and IoT systems necessitate new paradigms. This thesis addresses these challenges by integrating semantic communication and generative models for optimized image compression and edge network resource allocation. Unlike bit-centric systems, semantic communication prioritizes transmitting meaningful data specifically selected to convey the meaning rather than obtain a faithful representation of the original data. The communication infrastructure can benefit to significant improvements in bandwidth efficiency and latency reduction. Central to this work is the design of semantic-preserving image compression using Generative Adversarial Networks and Denoising Diffusion Probabilistic Models. These models compress images by encoding only semantically relevant features, allowing for high-quality reconstruction with minimal transmission. Additionally, a Goal-Oriented edge network optimization framework is introduced, leveraging the Information Bottleneck principle and stochastic optimization to dynamically allocate resources and enhance efficiency. By integrating semantic communication into edge networks, this approach balances computational efficiency and communication effectiveness, making it suitable for real-time applications. The thesis compares semantic-aware models with conventional image compression techniques using classical and semantic evaluation metrics. Results demonstrate the potential of combining generative AI and semantic communication to create more efficient semantic-goal-oriented communication networks that meet the demands of modern data-driven applications.</li>
</ul>

<h3>Title: Benchmark on Peer Review Toxic Detection: A Challenging Task with a New Dataset</h3>
<ul>
<li><strong>Authors: </strong>Man Luo, Bradley Peterson, Rafael Gan, Hari Ramalingame, Navya Gangrade, Ariadne Dimarogona, Imon Banerjee, Phillip Howard</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01676">https://arxiv.org/abs/2502.01676</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01676">https://arxiv.org/pdf/2502.01676</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01676]] Benchmark on Peer Review Toxic Detection: A Challenging Task with a New Dataset(https://arxiv.org/abs/2502.01676)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Peer review is crucial for advancing and improving science through constructive criticism. However, toxic feedback can discourage authors and hinder scientific progress. This work explores an important but underexplored area: detecting toxicity in peer reviews. We first define toxicity in peer reviews across four distinct categories and curate a dataset of peer reviews from the OpenReview platform, annotated by human experts according to these definitions. Leveraging this dataset, we benchmark a variety of models, including a dedicated toxicity detection model, a sentiment analysis model, several open-source large language models (LLMs), and two closed-source LLMs. Our experiments explore the impact of different prompt granularities, from coarse to fine-grained instructions, on model performance. Notably, state-of-the-art LLMs like GPT-4 exhibit low alignment with human judgments under simple prompts but achieve improved alignment with detailed instructions. Moreover, the model's confidence score is a good indicator of better alignment with human judgments. For example, GPT-4 achieves a Cohen's Kappa score of 0.56 with human judgments, which increases to 0.63 when using only predictions with a confidence score higher than 95%. Overall, our dataset and benchmarks underscore the need for continued research to enhance toxicity detection capabilities of LLMs. By addressing this issue, our work aims to contribute to a healthy and responsible environment for constructive academic discourse and scientific collaboration.</li>
</ul>

<h3>Title: AI Scaling: From Up to Down and Out</h3>
<ul>
<li><strong>Authors: </strong>Yunke Wang, Yanxi Li, Chang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01677">https://arxiv.org/abs/2502.01677</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01677">https://arxiv.org/pdf/2502.01677</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01677]] AI Scaling: From Up to Down and Out(https://arxiv.org/abs/2502.01677)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>AI Scaling has traditionally been synonymous with Scaling Up, which builds larger and more powerful models. However, the growing demand for efficiency, adaptability, and collaboration across diverse applications necessitates a broader perspective. This position paper presents a holistic framework for AI scaling, encompassing Scaling Up, Scaling Down, and Scaling Out. It argues that while Scaling Up of models faces inherent bottlenecks, the future trajectory of AI scaling lies in Scaling Down and Scaling Out. These paradigms address critical technical and societal challenges, such as reducing carbon footprint, ensuring equitable access, and enhancing cross-domain collaboration. We explore transformative applications in healthcare, smart manufacturing, and content creation, demonstrating how AI Scaling can enable breakthroughs in efficiency, personalization, and global connectivity. Additionally, we highlight key challenges, including balancing model complexity with interpretability, managing resource constraints, and fostering ethical development. By synthesizing these approaches, we propose a unified roadmap that redefines the future of AI research and application, paving the way for advancements toward Artificial General Intelligence (AGI).</li>
</ul>

<h3>Title: LEAD: Large Foundation Model for EEG-Based Alzheimer's Disease Detection</h3>
<ul>
<li><strong>Authors: </strong>Yihe Wang, Nan Huang, Nadia Mammone, Marco Cecchi, Xiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01678">https://arxiv.org/abs/2502.01678</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01678">https://arxiv.org/pdf/2502.01678</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01678]] LEAD: Large Foundation Model for EEG-Based Alzheimer's Disease Detection(https://arxiv.org/abs/2502.01678)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Electroencephalogram (EEG) provides a non-invasive, highly accessible, and cost-effective solution for Alzheimer's Disease (AD) detection. However, existing methods, whether based on manual feature extraction or deep learning, face two major challenges: the lack of large-scale datasets for robust feature learning and evaluation, and poor detection performance due to inter-subject variations. To address these challenges, we curate an EEG-AD corpus containing 813 subjects, which forms the world's largest EEG-AD dataset to the best of our knowledge. Using this unique dataset, we propose LEAD, the first large foundation model for EEG-based AD detection. Our method encompasses an entire pipeline, from data selection and preprocessing to self-supervised contrastive pretraining, fine-tuning, and key setups such as subject-independent evaluation and majority voting for subject-level detection. We pre-train the model on 11 EEG datasets and unified fine-tune it on 5 AD datasets. Our self-supervised pre-training design includes sample-level and subject-level contrasting to extract useful general EEG features. Fine-tuning is performed on 5 channel-aligned datasets together. The backbone encoder incorporates temporal and channel embeddings to capture features across both temporal and spatial dimensions. Our method demonstrates outstanding AD detection performance, achieving up to a 9.86% increase in F1 score at the sample-level and up to a 9.31% at the subject-level compared to state-of-the-art methods. The results of our model strongly confirm the effectiveness of contrastive pre-training and channel-aligned unified fine-tuning for addressing inter-subject variation. The source code is at this https URL.</li>
</ul>

<h3>Title: Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Kamal Acharya, Mehul Lad, Liang Sun, Houbing Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01680">https://arxiv.org/abs/2502.01680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01680">https://arxiv.org/pdf/2502.01680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01680]] Neurosymbolic AI for Travel Demand Prediction: Integrating Decision Tree Rules into Neural Networks(https://arxiv.org/abs/2502.01680)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Travel demand prediction is crucial for optimizing transportation planning, resource allocation, and infrastructure development, ensuring efficient mobility and economic sustainability. This study introduces a Neurosymbolic Artificial Intelligence (Neurosymbolic AI) framework that integrates decision tree (DT)-based symbolic rules with neural networks (NNs) to predict travel demand, leveraging the interpretability of symbolic reasoning and the predictive power of neural learning. The framework utilizes data from diverse sources, including geospatial, economic, and mobility datasets, to build a comprehensive feature set. DTs are employed to extract interpretable if-then rules that capture key patterns, which are then incorporated as additional features into a NN to enhance its predictive capabilities. Experimental results show that the combined dataset, enriched with symbolic rules, consistently outperforms standalone datasets across multiple evaluation metrics, including Mean Absolute Error (MAE), \(R^2\), and Common Part of Commuters (CPC). Rules selected at finer variance thresholds (e.g., 0.0001) demonstrate superior effectiveness in capturing nuanced relationships, reducing prediction errors, and aligning with observed commuter patterns. By merging symbolic and neural learning paradigms, this Neurosymbolic approach achieves both interpretability and accuracy.</li>
</ul>

<h3>Title: DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale</h3>
<ul>
<li><strong>Authors: </strong>Ziyang Zheng, Shan Huang, Jianyuan Zhong, Zhengyuan Shi, Guohao Dai, Ningyi Xu, Qiang Xu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01681">https://arxiv.org/abs/2502.01681</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01681">https://arxiv.org/pdf/2502.01681</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01681]] DeepGate4: Efficient and Effective Representation Learning for Circuit Design at Scale(https://arxiv.org/abs/2502.01681)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Circuit representation learning has become pivotal in electronic design automation, enabling critical tasks such as testability analysis, logic reasoning, power estimation, and SAT solving. However, existing models face significant challenges in scaling to large circuits due to limitations like over-squashing in graph neural networks and the quadratic complexity of transformer-based models. To address these issues, we introduce DeepGate4, a scalable and efficient graph transformer specifically designed for large-scale circuits. DeepGate4 incorporates several key innovations: (1) an update strategy tailored for circuit graphs, which reduce memory complexity to sub-linear and is adaptable to any graph transformer; (2) a GAT-based sparse transformer with global and local structural encodings for AIGs; and (3) an inference acceleration CUDA kernel that fully exploit the unique sparsity patterns of AIGs. Our extensive experiments on the ITC99 and EPFL benchmarks show that DeepGate4 significantly surpasses state-of-the-art methods, achieving 15.5% and 31.1% performance improvements over the next-best models. Furthermore, the Fused-DeepGate4 variant reduces runtime by 35.1% and memory usage by 46.8%, making it highly efficient for large-scale circuit analysis. These results demonstrate the potential of DeepGate4 to handle complex EDA tasks while offering superior scalability and efficiency.</li>
</ul>

<h3>Title: LLM-Powered Benchmark Factory: Reliable, Generic, and Efficient</h3>
<ul>
<li><strong>Authors: </strong>Peiwen Yuan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01683">https://arxiv.org/abs/2502.01683</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01683">https://arxiv.org/pdf/2502.01683</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01683]] LLM-Powered Benchmark Factory: Reliable, Generic, and Efficient(https://arxiv.org/abs/2502.01683)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid advancement of large language models (LLMs) has led to a surge in both model supply and application demands. To facilitate effective matching between them, reliable, generic and efficient benchmark generators are widely needed. However, human annotators are constrained by inefficiency, and current LLM benchmark generators not only lack generalizability but also struggle with limited reliability, as they lack a comprehensive evaluation framework for validation and optimization. To fill this gap, we first propose an automated and unbiased evaluation framework, structured around four dimensions and ten criteria. Under this framework, we carefully analyze the advantages and weaknesses of directly prompting LLMs as generic benchmark generators. To enhance the reliability, we introduce a series of methods to address the identified weaknesses and integrate them as BenchMaker. Experiments across multiple LLMs and tasks confirm that BenchMaker achieves superior or comparable performance to human-annotated benchmarks on all metrics, highlighting its generalizability and reliability. More importantly, it delivers highly consistent evaluation results across 12 LLMs (0.967 Pearson correlation against MMLU-Pro), while taking only $0.005 and 0.38 minutes per sample.</li>
</ul>

<h3>Title: BrainOOD: Out-of-distribution Generalizable Brain Network Analysis</h3>
<ul>
<li><strong>Authors: </strong>Jiaxing Xu, Yongqiang Chen, Xia Dong, Mengcheng Lan, Tiancheng Huang, Qingtian Bian, James Cheng, Yiping Ke</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.NC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01688">https://arxiv.org/abs/2502.01688</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01688">https://arxiv.org/pdf/2502.01688</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01688]] BrainOOD: Out-of-distribution Generalizable Brain Network Analysis(https://arxiv.org/abs/2502.01688)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In neuroscience, identifying distinct patterns linked to neurological disorders, such as Alzheimer's and Autism, is critical for early diagnosis and effective intervention. Graph Neural Networks (GNNs) have shown promising in analyzing brain networks, but there are two major challenges in using GNNs: (1) distribution shifts in multi-site brain network data, leading to poor Out-of-Distribution (OOD) generalization, and (2) limited interpretability in identifying key brain regions critical to neurological disorders. Existing graph OOD methods, while effective in other domains, struggle with the unique characteristics of brain networks. To bridge these gaps, we introduce BrainOOD, a novel framework tailored for brain networks that enhances GNNs' OOD generalization and interpretability. BrainOOD framework consists of a feature selector and a structure extractor, which incorporates various auxiliary losses including an improved Graph Information Bottleneck (GIB) objective to recover causal subgraphs. By aligning structure selection across brain networks and filtering noisy features, BrainOOD offers reliable interpretations of critical brain regions. Our approach outperforms 16 existing methods and improves generalization to OOD subjects by up to 8.5%. Case studies highlight the scientific validity of the patterns extracted, which aligns with the findings in known neuroscience literature. We also propose the first OOD brain network benchmark, which provides a foundation for future research in this field. Our code is available at this https URL.</li>
</ul>

<h3>Title: HuViDPO:Enhancing Video Generation through Direct Preference Optimization for Human-Centric Alignment</h3>
<ul>
<li><strong>Authors: </strong>Lifan Jiang, Boxi Wu, Jiahui Zhang, Xiaotong Guan, Shuang Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01690">https://arxiv.org/abs/2502.01690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01690">https://arxiv.org/pdf/2502.01690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01690]] HuViDPO:Enhancing Video Generation through Direct Preference Optimization for Human-Centric Alignment(https://arxiv.org/abs/2502.01690)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>With the rapid development of AIGC technology, significant progress has been made in diffusion model-based technologies for text-to-image (T2I) and text-to-video (T2V). In recent years, a few studies have introduced the strategy of Direct Preference Optimization (DPO) into T2I tasks, significantly enhancing human preferences in generated images. However, existing T2V generation methods lack a well-formed pipeline with exact loss function to guide the alignment of generated videos with human preferences using DPO strategies. Additionally, challenges such as the scarcity of paired video preference data hinder effective model training. At the same time, the lack of training datasets poses a risk of insufficient flexibility and poor video generation quality in the generated videos. Based on those problems, our work proposes three targeted solutions in sequence. 1) Our work is the first to introduce the DPO strategy into the T2V tasks. By deriving a carefully structured loss function, we utilize human feedback to align video generation with human preferences. We refer to this new method as HuViDPO. 2) Our work constructs small-scale human preference datasets for each action category and fine-tune this model, improving the aesthetic quality of the generated videos while reducing training costs. 3) We adopt a First-Frame-Conditioned strategy, leveraging the rich in formation from the first frame to guide the generation of subsequent frames, enhancing flexibility in video generation. At the same time, we employ a SparseCausal Attention mechanism to enhance the quality of the generated this http URL details and examples can be accessed on our website: this https URL. this http URL.</li>
</ul>

<h3>Title: Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model</h3>
<ul>
<li><strong>Authors: </strong>Hadas Ben-Atya, Naama Gavrielov, Zvi Badash, Gili Focht, Ruth Cytter-Kuint, Talar Hagopian, Dan Turner, Moti Freiman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01691">https://arxiv.org/abs/2502.01691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01691">https://arxiv.org/pdf/2502.01691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01691]] Agent-Based Uncertainty Awareness Improves Automated Radiology Report Labeling with an Open-Source Large Language Model(https://arxiv.org/abs/2502.01691)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Reliable extraction of structured data from radiology reports using Large Language Models (LLMs) remains challenging, especially for complex, non-English texts like Hebrew. This study introduces an agent-based uncertainty-aware approach to improve the trustworthiness of LLM predictions in medical applications. We analyzed 9,683 Hebrew radiology reports from Crohn's disease patients (from 2010 to 2023) across three medical centers. A subset of 512 reports was manually annotated for six gastrointestinal organs and 15 pathological findings, while the remaining reports were automatically annotated using HSMP-BERT. Structured data extraction was performed using Llama 3.1 (Llama 3-8b-instruct) with Bayesian Prompt Ensembles (BayesPE), which employed six semantically equivalent prompts to estimate uncertainty. An Agent-Based Decision Model integrated multiple prompt outputs into five confidence levels for calibrated uncertainty and was compared against three entropy-based models. Performance was evaluated using accuracy, F1 score, precision, recall, and Cohen's Kappa before and after filtering high-uncertainty cases. The agent-based model outperformed the baseline across all metrics, achieving an F1 score of 0.3967, recall of 0.6437, and Cohen's Kappa of 0.3006. After filtering high-uncertainty cases (greater than or equal to 0.5), the F1 score improved to 0.4787, and Kappa increased to 0.4258. Uncertainty histograms demonstrated clear separation between correct and incorrect predictions, with the agent-based model providing the most well-calibrated uncertainty estimates. By incorporating uncertainty-aware prompt ensembles and an agent-based decision model, this approach enhances the performance and reliability of LLMs in structured data extraction from radiology reports, offering a more interpretable and trustworthy solution for high-stakes medical applications.</li>
</ul>

<h3>Title: Fast Direct: Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation</h3>
<ul>
<li><strong>Authors: </strong>Kim Yong Tan, Yueming Lyu, Ivor Tsang, Yew-Soon Ong</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01692">https://arxiv.org/abs/2502.01692</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01692">https://arxiv.org/pdf/2502.01692</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01692]] Fast Direct: Query-Efficient Online Black-box Guidance for Diffusion-model Target Generation(https://arxiv.org/abs/2502.01692)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Guided diffusion-model generation is a promising direction for customizing the generation process of a pre-trained diffusion-model to address the specific downstream tasks. Existing guided diffusion models either rely on training of the guidance model with pre-collected datasets or require the objective functions to be differentiable. However, for most real-world tasks, the offline datasets are often unavailable, and their objective functions are often not differentiable, such as image generation with human preferences, molecular generation for drug discovery, and material design. Thus, we need an \textbf{online} algorithm capable of collecting data during runtime and supporting a \textbf{black-box} objective function. Moreover, the \textbf{query efficiency} of the algorithm is also critical because the objective evaluation of the query is often expensive in the real-world scenarios. In this work, we propose a novel and simple algorithm, \textbf{Fast Direct}, for query-efficient online black-box target generation. Our Fast Direct builds a pseudo-target on the data manifold to update the noise sequence of the diffusion model with a universal direction, which is promising to perform query-efficient guided generation. Extensive experiments on twelve high-resolution ($\small {1024 \times 1024}$) image target generation tasks and six 3D-molecule target generation tasks show $\textbf{6}\times$ up to $\textbf{10}\times$ query efficiency improvement and $\textbf{11}\times$ up to $\textbf{44}\times$ query efficiency improvement, respectively. Our implementation is publicly available at: this https URL</li>
</ul>

<h3>Title: Graph Neural Networks for Identifying Steady-State Behavior in Complex Networks</h3>
<ul>
<li><strong>Authors: </strong>Priodyuti Pradhan, Amit Reza</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, nlin.AO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01693">https://arxiv.org/abs/2502.01693</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01693">https://arxiv.org/pdf/2502.01693</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01693]] Graph Neural Networks for Identifying Steady-State Behavior in Complex Networks(https://arxiv.org/abs/2502.01693)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>In complex systems, information propagation can be defined as diffused or delocalized, weakly localized, and strongly localized. Can a machine learning model learn the behavior of a linear dynamical system on networks? In this work, we develop a graph neural network framework for identifying the steady-state behavior of the linear dynamical system. We reveal that our model learns the different states with high accuracy. To understand the explainability of our model, we provide an analytical derivation for the forward and backward propagation of our framework. Finally, we use the real-world graphs in our model for validation.</li>
</ul>

<h3>Title: Multimodal Inverse Attention Network with Intrinsic Discriminant Feature Exploitation for Fake News Detection</h3>
<ul>
<li><strong>Authors: </strong>Tianlin Zhang, En Yu, Yi Shao, Shuai Li, Sujuan Hou, Jiande Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV, cs.IR, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01699">https://arxiv.org/abs/2502.01699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01699">https://arxiv.org/pdf/2502.01699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01699]] Multimodal Inverse Attention Network with Intrinsic Discriminant Feature Exploitation for Fake News Detection(https://arxiv.org/abs/2502.01699)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Multimodal fake news detection has garnered significant attention due to its profound implications for social security. While existing approaches have contributed to understanding cross-modal consistency, they often fail to leverage modal-specific representations and explicit discrepant features. To address these limitations, we propose a Multimodal Inverse Attention Network (MIAN), a novel framework that explores intrinsic discriminative features based on news content to advance fake news detection. Specifically, MIAN introduces a hierarchical learning module that captures diverse intra-modal relationships through local-to-global and local-to-local interactions, thereby generating enhanced unimodal representations to improve the identification of fake news at the intra-modal level. Additionally, a cross-modal interaction module employs a co-attention mechanism to establish and model dependencies between the refined unimodal representations, facilitating seamless semantic integration across modalities. To explicitly extract inconsistency features, we propose an inverse attention mechanism that effectively highlights the conflicting patterns and semantic deviations introduced by fake news in both intra- and inter-modality. Extensive experiments on benchmark datasets demonstrate that MIAN significantly outperforms state-of-the-art methods, underscoring its pivotal contribution to advancing social security through enhanced multimodal fake news detection.</li>
</ul>

<h3>Title: Learning with Differentially Private (Sliced) Wasserstein Gradients</h3>
<ul>
<li><strong>Authors: </strong>Cl√©ment Lalanne (IMT, ANITI), Jean-Michel Loubes (IMT, ANITI), David Rodr√≠guez-V√≠tores (UVa, IMUVA)</a></li>
<li><strong>Subjects: </strong>cs.LG, math.ST</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01701">https://arxiv.org/abs/2502.01701</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01701">https://arxiv.org/pdf/2502.01701</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01701]] Learning with Differentially Private (Sliced) Wasserstein Gradients(https://arxiv.org/abs/2502.01701)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>In this work, we introduce a novel framework for privately optimizing objectives that rely on Wasserstein distances between data-dependent empirical measures. Our main theoretical contribution is, based on an explicit formulation of the Wasserstein gradient in a fully discrete setting, a control on the sensitivity of this gradient to individual data points, allowing strong privacy guarantees at minimal utility cost. Building on these insights, we develop a deep learning approach that incorporates gradient and activations clipping, originally designed for DP training of problems with a finite-sum structure. We further demonstrate that privacy accounting methods extend to Wasserstein-based objectives, facilitating large-scale private training. Empirical results confirm that our framework effectively balances accuracy and privacy, offering a theoretically sound solution for privacy-preserving machine learning tasks relying on optimal transport distances such as Wasserstein distance or sliced-Wasserstein distance.</li>
</ul>

<h3>Title: Al-Khwarizmi: Discovering Physical Laws with Foundation Models</h3>
<ul>
<li><strong>Authors: </strong>Christopher E. Mower, Haitham Bou-Ammar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01702">https://arxiv.org/abs/2502.01702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01702">https://arxiv.org/pdf/2502.01702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01702]] Al-Khwarizmi: Discovering Physical Laws with Foundation Models(https://arxiv.org/abs/2502.01702)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Inferring physical laws from data is a central challenge in science and engineering, including but not limited to healthcare, physical sciences, biosciences, social sciences, sustainability, climate, and robotics. Deep networks offer high-accuracy results but lack interpretability, prompting interest in models built from simple components. The Sparse Identification of Nonlinear Dynamics (SINDy) method has become the go-to approach for building such modular and interpretable models. SINDy leverages sparse regression with L1 regularization to identify key terms from a library of candidate functions. However, SINDy's choice of candidate library and optimization method requires significant technical expertise, limiting its widespread applicability. This work introduces Al-Khwarizmi, a novel agentic framework for physical law discovery from data, which integrates foundational models with SINDy. Leveraging LLMs, VLMs, and Retrieval-Augmented Generation (RAG), our approach automates physical law discovery, incorporating prior knowledge and iteratively refining candidate solutions via reflection. Al-Khwarizmi operates in two steps: it summarizes system observations-comprising textual descriptions, raw data, and plots-followed by a secondary step that generates candidate feature libraries and optimizer configurations to identify hidden physics laws correctly. Evaluating our algorithm on over 198 models, we demonstrate state-of-the-art performance compared to alternatives, reaching a 20 percent increase against the best-performing alternative.</li>
</ul>

<h3>Title: QLESS: A Quantized Approach for Data Valuation and Selection in Large Language Model Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Moses Ananta, Muhammad Farid Adilazuarda, Zayd Muhammad Kawakibi Zuhri, Ayu Purwarianti, Alham Fikri Aji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01703">https://arxiv.org/abs/2502.01703</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01703">https://arxiv.org/pdf/2502.01703</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01703]] QLESS: A Quantized Approach for Data Valuation and Selection in Large Language Model Fine-Tuning(https://arxiv.org/abs/2502.01703)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) is often constrained by the computational costs of processing massive datasets. We propose \textbf{QLESS} (Quantized Low-rank Gradient Similarity Search), which integrates gradient quantization with the LESS framework to enable memory-efficient data valuation and selection. QLESS employs a two-step compression process: first, it obtains low-dimensional gradient representations through LoRA-based random projection; then, it quantizes these gradients to low-bitwidth representations. Experiments on multiple LLM architectures (LLaMA, Mistral, Qwen) and benchmarks (MMLU, BBH, TyDiQA) show that QLESS achieves comparable data selection performance to LESS while reducing memory usage by up to 16x. Even 1-bit gradient quantization preserves data valuation quality. These findings underscore QLESS as a practical, scalable approach to identifying informative examples within strict memory constraints.</li>
</ul>

<h3>Title: Progressive Binarization with Semi-Structured Pruning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Xianglong Yan, Tianao Zhang, Zhiteng Li, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01705">https://arxiv.org/abs/2502.01705</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01705">https://arxiv.org/pdf/2502.01705</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01705]] Progressive Binarization with Semi-Structured Pruning for LLMs(https://arxiv.org/abs/2502.01705)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have achieved remarkable success in natural language processing tasks, but their high computational and memory demands pose challenges for deployment on resource-constrained devices. Binarization, as an efficient compression method that reduces model weights to just 1 bit, significantly lowers both computational and memory requirements. Despite this, the binarized LLM still contains redundancy, which can be further compressed. Semi-structured pruning provides a promising approach to achieve this, which offers a better trade-off between model performance and hardware efficiency. However, simply combining binarization with semi-structured pruning can lead to a significant performance drop. To address this issue, we propose a Progressive Binarization with Semi-Structured Pruning (PBS$^2$P) method for LLM compression. We first propose a Stepwise semi-structured Pruning with Binarization Optimization (SPBO). Our optimization strategy significantly reduces the total error caused by pruning and binarization, even below that of the no-pruning scenario. Furthermore, we design a Coarse-to-Fine Search (CFS) method to select pruning elements more effectively. Extensive experiments demonstrate that PBS$^2$P achieves superior accuracy across various LLM families and evaluation metrics, noticeably outperforming state-of-the-art (SOTA) binary PTQ methods. The code and models will be available at this https URL.</li>
</ul>

<h3>Title: A Multi-Scale Feature Fusion Framework Integrating Frequency Domain and Cross-View Attention for Dual-View X-ray Security Inspections</h3>
<ul>
<li><strong>Authors: </strong>Shilong Hong, Yanzhou Zhou, Weichao Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01710">https://arxiv.org/abs/2502.01710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01710">https://arxiv.org/pdf/2502.01710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01710]] A Multi-Scale Feature Fusion Framework Integrating Frequency Domain and Cross-View Attention for Dual-View X-ray Security Inspections(https://arxiv.org/abs/2502.01710)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>With the rapid development of modern transportation systems and the exponential growth of logistics volumes, intelligent X-ray-based security inspection systems play a crucial role in public safety. Although single-view X-ray equipment is widely deployed, it struggles to accurately identify contraband in complex stacking scenarios due to strong viewpoint dependency and inadequate feature representation. To address this, we propose an innovative multi-scale interactive feature fusion framework tailored for dual-view X-ray security inspection image classification. The framework comprises three core modules: the Frequency Domain Interaction Module (FDIM) enhances frequency-domain features through Fourier transform; the Multi-Scale Cross-View Feature Enhancement (MSCFE) leverages cross-view attention mechanisms to strengthen feature interactions; and the Convolutional Attention Fusion Module (CAFM) efficiently fuses features by integrating channel attention with depthwise-separable convolutions. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches across multiple backbone architectures, particularly excelling in complex scenarios with occlusions and object stacking.</li>
</ul>

<h3>Title: MJ-VIDEO: Fine-Grained Benchmarking and Rewarding Video Preferences in Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Haibo Tong, Zhaoyang Wang, Zhaorun Chen, Haonian Ji, Shi Qiu, Siwei Han, Kexin Geng, Zhongkai Xue, Yiyang Zhou, Peng Xia, Mingyu Ding, Rafael Rafailov, Chelsea Finn, Huaxiu Yao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01719">https://arxiv.org/abs/2502.01719</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01719">https://arxiv.org/pdf/2502.01719</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01719]] MJ-VIDEO: Fine-Grained Benchmarking and Rewarding Video Preferences in Video Generation(https://arxiv.org/abs/2502.01719)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Recent advancements in video generation have significantly improved the ability to synthesize videos from text instructions. However, existing models still struggle with key challenges such as instruction misalignment, content hallucination, safety concerns, and bias. Addressing these limitations, we introduce MJ-BENCH-VIDEO, a large-scale video preference benchmark designed to evaluate video generation across five critical aspects: Alignment, Safety, Fineness, Coherence & Consistency, and Bias & Fairness. This benchmark incorporates 28 fine-grained criteria to provide a comprehensive evaluation of video preference. Building upon this dataset, we propose MJ-VIDEO, a Mixture-of-Experts (MoE)-based video reward model designed to deliver fine-grained reward. MJ-VIDEO can dynamically select relevant experts to accurately judge the preference based on the input text-video pair. This architecture enables more precise and adaptable preference judgments. Through extensive benchmarking on MJ-BENCH-VIDEO, we analyze the limitations of existing video reward models and demonstrate the superior performance of MJ-VIDEO in video preference assessment, achieving 17.58% and 15.87% improvements in overall and fine-grained preference judgments, respectively. Additionally, introducing MJ-VIDEO for preference tuning in video generation enhances the alignment performance.</li>
</ul>

<h3>Title: Evaluation of Large Language Models via Coupled Token Generation</h3>
<ul>
<li><strong>Authors: </strong>Nina Corvelo Benz, Stratis Tsirtsis, Eleni Straitouri, Ivi Chatzi, Ander Artola Velasco, Suhas Thejaswi, Manuel Gomez-Rodriguez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01754">https://arxiv.org/abs/2502.01754</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01754">https://arxiv.org/pdf/2502.01754</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01754]] Evaluation of Large Language Models via Coupled Token Generation(https://arxiv.org/abs/2502.01754)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>State of the art large language models rely on randomization to respond to a prompt. As an immediate consequence, a model may respond differently to the same prompt if asked multiple times. In this work, we argue that the evaluation and ranking of large language models should control for the randomization underpinning their functioning. Our starting point is the development of a causal model for coupled autoregressive generation, which allows different large language models to sample responses with the same source of randomness. Building upon our causal model, we first show that, on evaluations based on benchmark datasets, coupled autoregressive generation leads to the same conclusions as vanilla autoregressive generation but using provably fewer samples. However, we further show that, on evaluations based on (human) pairwise comparisons, coupled and vanilla autoregressive generation can surprisingly lead to different rankings when comparing more than two models, even with an infinite amount of samples. This suggests that the apparent advantage of a model over others in existing evaluation protocols may not be genuine but rather confounded by the randomness inherent to the generation process. To illustrate and complement our theoretical results, we conduct experiments with several large language models from the Llama family. We find that, across multiple knowledge areas from the popular MMLU benchmark dataset, coupled autoregressive generation requires up to 40% fewer samples to reach the same conclusions as vanilla autoregressive generation. Further, using data from the LMSYS Chatbot Arena platform, we find that the win-rates derived from pairwise comparisons by a strong large language model to prompts differ under coupled and vanilla autoregressive generation.</li>
</ul>

<h3>Title: Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA</h3>
<ul>
<li><strong>Authors: </strong>Shuangyi Chen, Yuanxin Guo, Yue Ju, Harik Dalal, Ashish Khisti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01755">https://arxiv.org/abs/2502.01755</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01755">https://arxiv.org/pdf/2502.01755</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01755]] Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA(https://arxiv.org/abs/2502.01755)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, federate, large language model</a></li>
<li><strong>Abstract: </strong>Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation (LoRA) optimize federated training by reducing computational and communication costs. We propose RoLoRA, a federated framework using alternating optimization to fine-tune LoRA adapters. Our approach emphasizes the importance of learning up and down projection matrices to enhance expressiveness and robustness. We use both theoretical analysis and extensive experiments to demonstrate the advantages of RoLoRA over prior approaches that either generate imperfect model updates or limit expressiveness of the model. We present theoretical analysis on a simplified linear model to demonstrate the importance of learning both down-projection and up-projection matrices in LoRA. We provide extensive experimental evaluations on a toy neural network on MNIST as well as large language models including RoBERTa-Large, Llama-2-7B on diverse tasks to demonstrate the advantages of RoLoRA over other methods.</li>
</ul>

<h3>Title: Hamming Attention Distillation: Binarizing Keys and Queries for Efficient Long-Context Transformers</h3>
<ul>
<li><strong>Authors: </strong>Mark Horton, Tergel Molom-Ochir, Peter Liu, Bhavna Gopal, Chiyue Wei, Cong Guo, Brady Taylor, Deliang Fan, Shan X. Wang, Hai Li, Yiran Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01770">https://arxiv.org/abs/2502.01770</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01770">https://arxiv.org/pdf/2502.01770</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01770]] Hamming Attention Distillation: Binarizing Keys and Queries for Efficient Long-Context Transformers(https://arxiv.org/abs/2502.01770)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pre-trained transformer models with extended context windows are notoriously expensive to run at scale, often limiting real-world deployment due to their high computational and memory requirements. In this paper, we introduce Hamming Attention Distillation (HAD), a novel framework that binarizes keys and queries in the attention mechanism to achieve significant efficiency gains. By converting keys and queries into {-1, +1} vectors and replacing dot-product operations with efficient Hamming distance computations, our method drastically reduces computational overhead. Additionally, we incorporate attention matrix sparsification to prune low-impact activations, which further reduces the cost of processing long-context sequences. \par Despite these aggressive compression strategies, our distilled approach preserves a high degree of representational power, leading to substantially improved accuracy compared to prior transformer binarization methods. We evaluate HAD on a range of tasks and models, including the GLUE benchmark, ImageNet, and QuALITY, demonstrating state-of-the-art performance among binarized Transformers while drastically reducing the computational costs of long-context inference. \par We implement HAD in custom hardware simulations, demonstrating superior performance characteristics compared to a custom hardware implementation of standard attention. HAD achieves just $\mathbf{1.78}\%$ performance losses on GLUE compared to $9.08\%$ in state-of-the-art binarization work, and $\mathbf{2.5}\%$ performance losses on ImageNet compared to $12.14\%$, all while targeting custom hardware with a $\mathbf{79}\%$ area reduction and $\mathbf{87}\%$ power reduction compared to its standard attention counterpart.</li>
</ul>

<h3>Title: On Bob Dylan: A Computational Perspective</h3>
<ul>
<li><strong>Authors: </strong>Prashant Garg</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01772">https://arxiv.org/abs/2502.01772</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01772">https://arxiv.org/pdf/2502.01772</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01772]] On Bob Dylan: A Computational Perspective(https://arxiv.org/abs/2502.01772)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style -- a constant refusal to conform to expectation and a penchant for reinventing his musical and lyrical identity. In this paper, I extend Sunstein's observations through a large-scale computational analysis of Dylan's lyrics from 1962 to 2012. Using o3-mini-high (a large language model), I extract concept-to-concept relationships from the lyrics and construct directed knowledge graphs that capture Dylan's thematic structure. I then quantify shifts in sentiment, metaphorical expression, thematic diversity, and network complexity over time. The results indicate that Dylan's lyrics increasingly rely on metaphor, display an evolving sentiment profile, and exhibit heightened dishabituation -- measured here as a growing variance in the network centrality of key concepts. I also find that references to movement, protest, and mythic imagery fluctuate in ways that align with well-known phases of Dylan's career, reflecting the dynamic and unpredictable quality of his art. These findings not only deepen our empirical understanding of Sunstein's thesis but also introduce a novel computational method for analyzing an artist's evolution-offering broader applicability to the study of cultural and creative change.</li>
</ul>

<h3>Title: Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity</h3>
<ul>
<li><strong>Authors: </strong>Haocheng Xi, Shuo Yang, Yilong Zhao, Chenfeng Xu, Muyang Li, Xiuyu Li, Yujun Lin, Han Cai, Jintao Zhang, Dacheng Li, Jianfei Chen, Ion Stoica, Kurt Keutzer, Song Han</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01776">https://arxiv.org/abs/2502.01776</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01776">https://arxiv.org/pdf/2502.01776</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01776]] Sparse VideoGen: Accelerating Video Diffusion Transformers with Spatial-Temporal Sparsity(https://arxiv.org/abs/2502.01776)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion Transformers (DiTs) dominate video generation but their high computational cost severely limits real-world applicability, usually requiring tens of minutes to generate a few seconds of video even on high-performance GPUs. This inefficiency primarily arises from the quadratic computational complexity of 3D Full Attention with respect to the context length. In this paper, we propose a training-free framework termed Sparse VideoGen (SVG) that leverages the inherent sparsity in 3D Full Attention to boost inference efficiency. We reveal that the attention heads can be dynamically classified into two groups depending on distinct sparse patterns: (1) Spatial Head, where only spatially-related tokens within each frame dominate the attention output, and (2) Temporal Head, where only temporally-related tokens across different frames dominate. Based on this insight, SVG proposes an online profiling strategy to capture the dynamic sparse patterns and predicts the type of attention head. Combined with a novel hardware-efficient tensor layout transformation and customized kernel implementations, SVG achieves up to 2.28x and 2.33x end-to-end speedup on CogVideoX-v1.5 and HunyuanVideo, respectively, while preserving generation quality.</li>
</ul>

<h3>Title: CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition</h3>
<ul>
<li><strong>Authors: </strong>Martijn Bartelds, Ananjan Nandi, Moussa Koulako Bala Doumbouya, Dan Jurafsky, Tatsunori Hashimoto, Karen Livescu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01777">https://arxiv.org/abs/2502.01777</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01777">https://arxiv.org/pdf/2502.01777</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01777]] CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition(https://arxiv.org/abs/2502.01777)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Modern deep learning models often achieve high overall performance, but consistently fail on specific subgroups. Group distributionally robust optimization (group DRO) addresses this problem by minimizing the worst-group loss, but it fails when group losses misrepresent performance differences between groups. This is common in domains like speech, where the widely used connectionist temporal classification (CTC) loss scales with input length and varies with linguistic and acoustic properties, leading to spurious differences between group losses. We present CTC-DRO, which addresses the shortcomings of the group DRO objective by smoothing the group weight update to prevent overemphasis on consistently high-loss groups, while using input length-matched batching to mitigate CTC's scaling issues. We evaluate CTC-DRO on the task of multilingual automatic speech recognition (ASR) across five language sets from the ML-SUPERB 2.0 benchmark. CTC-DRO consistently outperforms group DRO and CTC-based baseline models, reducing the worst-language error by up to 65.9% and the average error by up to 47.7%. CTC-DRO can be applied to ASR with minimal computational costs, and offers the potential for reducing group disparities in other domains with similar challenges.</li>
</ul>

<h3>Title: GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments</h3>
<ul>
<li><strong>Authors: </strong>Stavros Orfanoudakis, Nanda Kishor Panda, Peter Palensky, Pedro P. Vergara</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01778">https://arxiv.org/abs/2502.01778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01778">https://arxiv.org/pdf/2502.01778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01778]] GNN-DT: Graph Neural Network Enhanced Decision Transformer for Efficient Optimization in Dynamic Environments(https://arxiv.org/abs/2502.01778)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) methods used for solving real-world optimization problems often involve dynamic state-action spaces, larger scale, and sparse rewards, leading to significant challenges in convergence, scalability, and efficient exploration of the solution space. This study introduces GNN-DT, a novel Decision Transformer (DT) architecture that integrates Graph Neural Network (GNN) embedders with a novel residual connection between input and output tokens crucial for handling dynamic environments. By learning from previously collected trajectories, GNN-DT reduces dependence on accurate simulators and tackles the sparse rewards limitations of online RL algorithms. We evaluate GNN-DT on the complex electric vehicle (EV) charging optimization problem and prove that its performance is superior and requires significantly fewer training trajectories, thus improving sample efficiency compared to existing DT baselines. Furthermore, GNN-DT exhibits robust generalization to unseen environments and larger action spaces, addressing a critical gap in prior DT-based approaches</li>
</ul>

<h3>Title: AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene Analysis</h3>
<ul>
<li><strong>Authors: </strong>Basit Alawode, Iyyakutti Iyappan Ganapathi, Sajid Javed, Naoufel Werghi, Mohammed Bennamoun, Arif Mahmood</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01785">https://arxiv.org/abs/2502.01785</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01785">https://arxiv.org/pdf/2502.01785</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01785]] AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene Analysis(https://arxiv.org/abs/2502.01785)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, interpretability, segmentation</a></li>
<li><strong>Abstract: </strong>The preservation of aquatic biodiversity is critical in mitigating the effects of climate change. Aquatic scene understanding plays a pivotal role in aiding marine scientists in their decision-making processes. In this paper, we introduce AquaticCLIP, a novel contrastive language-image pre-training model tailored for aquatic scene understanding. AquaticCLIP presents a new unsupervised learning framework that aligns images and texts in aquatic environments, enabling tasks such as segmentation, classification, detection, and object counting. By leveraging our large-scale underwater image-text paired dataset without the need for ground-truth annotations, our model enriches existing vision-language models in the aquatic domain. For this purpose, we construct a 2 million underwater image-text paired dataset using heterogeneous resources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP, we propose a prompt-guided vision encoder that progressively aggregates patch features via learnable prompts, while a vision-guided mechanism enhances the language encoder by incorporating visual context. The model is optimized through a contrastive pretraining loss to align visual and textual modalities. AquaticCLIP achieves notable performance improvements in zero-shot settings across multiple underwater computer vision tasks, outperforming existing methods in both robustness and interpretability. Our model sets a new benchmark for vision-language applications in underwater environments. The code and dataset for AquaticCLIP are publicly available on GitHub at xxx.</li>
</ul>

<h3>Title: Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale</h3>
<ul>
<li><strong>Authors: </strong>Elisa Tsai, Neal Mangaokar, Boyuan Zheng, Haizhong Zheng, Atul Prakash</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01798">https://arxiv.org/abs/2502.01798</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01798">https://arxiv.org/pdf/2502.01798</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01798]] Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale(https://arxiv.org/abs/2502.01798)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, large language model</a></li>
<li><strong>Abstract: </strong>Terms and conditions for online shopping websites often contain terms that can have significant financial consequences for customers. Despite their impact, there is currently no comprehensive understanding of the types and potential risks associated with unfavorable financial terms. Furthermore, there are no publicly available detection systems or datasets to systematically identify or mitigate these terms. In this paper, we take the first steps toward solving this problem with three key contributions. \textit{First}, we introduce \textit{TermMiner}, an automated data collection and topic modeling pipeline to understand the landscape of unfavorable financial terms. \textit{Second}, we create \textit{ShopTC-100K}, a dataset of terms and conditions from shopping websites in the Tranco top 100K list, comprising 1.8 million terms from 8,251 websites. Consequently, we develop a taxonomy of 22 types from 4 categories of unfavorable financial terms -- spanning purchase, post-purchase, account termination, and legal aspects. \textit{Third}, we build \textit{TermLens}, an automated detector that uses Large Language Models (LLMs) to identify unfavorable financial terms. Fine-tuned on an annotated dataset, \textit{TermLens} achieves an F1 score of 94.6\% and a false positive rate of 2.3\% using GPT-4o. When applied to shopping websites from the Tranco top 100K, we find that 42.06\% of these sites contain at least one unfavorable financial term, with such terms being more prevalent on less popular websites. Case studies further highlight the financial risks and customer dissatisfaction associated with unfavorable financial terms, as well as the limitations of existing ecosystem defenses.</li>
</ul>

<h3>Title: Discovering Chunks in Neural Embeddings for Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Shuchen Wu, Stephan Alaniz, Eric Schulz, Zeynep Akata</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01803">https://arxiv.org/abs/2502.01803</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01803">https://arxiv.org/pdf/2502.01803</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01803]] Discovering Chunks in Neural Embeddings for Interpretability(https://arxiv.org/abs/2502.01803)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Understanding neural networks is challenging due to their high-dimensional, interacting components. Inspired by human cognition, which processes complex sensory data by chunking it into recurring entities, we propose leveraging this principle to interpret artificial neural population activities. Biological and artificial intelligence share the challenge of learning from structured, naturalistic data, and we hypothesize that the cognitive mechanism of chunking can provide insights into artificial systems. We first demonstrate this concept in recurrent neural networks (RNNs) trained on artificial sequences with imposed regularities, observing that their hidden states reflect these patterns, which can be extracted as a dictionary of chunks that influence network responses. Extending this to large language models (LLMs) like LLaMA, we identify similar recurring embedding states corresponding to concepts in the input, with perturbations to these states activating or inhibiting the associated concepts. By exploring methods to extract dictionaries of identifiable chunks across neural embeddings of varying complexity, our findings introduce a new framework for interpreting neural networks, framing their population activity as structured reflections of the data they process.</li>
</ul>

<h3>Title: Self-supervised Subgraph Neural Network With Deep Reinforcement Walk Exploration</h3>
<ul>
<li><strong>Authors: </strong>Jianming Huang, Hiroyuki Kasai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01809">https://arxiv.org/abs/2502.01809</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01809">https://arxiv.org/pdf/2502.01809</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01809]] Self-supervised Subgraph Neural Network With Deep Reinforcement Walk Exploration(https://arxiv.org/abs/2502.01809)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Graph data, with its structurally variable nature, represents complex real-world phenomena like chemical compounds, protein structures, and social networks. Traditional Graph Neural Networks (GNNs) primarily utilize the message-passing mechanism, but their expressive power is limited and their prediction lacks explainability. To address these limitations, researchers have focused on graph substructures. Subgraph neural networks (SGNNs) and GNN explainers have emerged as potential solutions, but each has its limitations. SGNNs computes graph representations based on the bags of subgraphs to enhance the expressive power. However, they often rely on predefined algorithm-based sampling strategies, which is inefficient. GNN explainers adopt data-driven approaches to generate important subgraphs to provide explanation. Nevertheless, their explanation is difficult to be translated into practical improvements on GNNs. To overcome these issues, we propose a novel self-supervised framework that integrates SGNNs with the generation approach of GNN explainers, named the Reinforcement Walk Exploration SGNN (RWE-SGNN). Our approach features a sampling model trained in an explainer fashion, optimizing subgraphs to enhance model performance. To achieve a data-driven sampling approach, unlike traditional subgraph generation approaches, we propose a novel walk exploration process, which efficiently extracts important substructures, simplifying the embedding process and avoiding isomorphism problems. Moreover, we prove that our proposed walk exploration process has equivalent generation capability to the traditional subgraph generation process. Experimental results on various graph datasets validate the effectiveness of our proposed method, demonstrating significant improvements in performance and precision.</li>
</ul>

<h3>Title: SelfCheckAgent: Zero-Resource Hallucination Detection in Generative Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Diyana Muhammed, Gollam Rabby, S√∂ren Auer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01812">https://arxiv.org/abs/2502.01812</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01812">https://arxiv.org/pdf/2502.01812</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01812]] SelfCheckAgent: Zero-Resource Hallucination Detection in Generative Large Language Models(https://arxiv.org/abs/2502.01812)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, generative, large language model</a></li>
<li><strong>Abstract: </strong>Detecting hallucinations in Large Language Models (LLMs) remains a critical challenge for their reliable deployment in real-world applications. To address this, we introduce SelfCheckAgent, a novel framework integrating three different agents: the Symbolic Agent, the Specialized Detection Agent, and the Contextual Consistency Agent. These agents provide a robust multi-dimensional approach to hallucination detection. Notable results include the Contextual Consistency Agent leveraging Llama 3.1 with Chain-of-Thought (CoT) to achieve outstanding performance on the WikiBio dataset, with NonFactual hallucination detection scoring 93.64%, Factual 70.26%, and Ranking 78.48% respectively. On the AIME dataset, GPT-4o with CoT excels in NonFactual detection with 94.89% but reveals trade-offs in Factual with 30.58% and Ranking with 30.68%, underscoring the complexity of hallucination detection in the complex mathematical domains. The framework also incorporates a triangulation strategy, which increases the strengths of the SelfCheckAgent, yielding significant improvements in real-world hallucination identification. The comparative analysis demonstrates SelfCheckAgent's applicability across diverse domains, positioning it as a crucial advancement for trustworthy LLMs. These findings highlight the potentiality of consistency-driven methodologies in detecting hallucinations in LLMs.</li>
</ul>

<h3>Title: Low Resource Video Super-resolution using Memory and Residual Deformable Convolutions</h3>
<ul>
<li><strong>Authors: </strong>Kavitha Viswanathan, Shashwat Pathak, Piyush Bharambe, Harsh Choudhary, Amit Sethi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01816">https://arxiv.org/abs/2502.01816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01816">https://arxiv.org/pdf/2502.01816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01816]] Low Resource Video Super-resolution using Memory and Residual Deformable Convolutions(https://arxiv.org/abs/2502.01816)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Transformer-based video super-resolution (VSR) models have set new benchmarks in recent years, but their substantial computational demands make most of them unsuitable for deployment on resource-constrained devices. Achieving a balance between model complexity and output quality remains a formidable challenge in VSR. Although lightweight models have been introduced to address this issue, they often struggle to deliver state-of-the-art performance. We propose a novel lightweight, parameter-efficient deep residual deformable convolution network for VSR. Unlike prior methods, our model enhances feature utilization through residual connections and employs deformable convolution for precise frame alignment, addressing motion dynamics effectively. Furthermore, we introduce a single memory tensor to capture information accrued from the past frames and improve motion estimation across frames. This design enables an efficient balance between computational cost and reconstruction quality. With just 2.3 million parameters, our model achieves state-of-the-art SSIM of 0.9175 on the REDS4 dataset, surpassing existing lightweight and many heavy models in both accuracy and resource efficiency. Architectural insights from our model pave the way for real-time VSR on streaming data.</li>
</ul>

<h3>Title: Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Hanyang Zhao, Haoxian Chen, Ji Zhang, David D. Yao, Wenpin Tang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.OC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01819">https://arxiv.org/abs/2502.01819</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01819">https://arxiv.org/pdf/2502.01819</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01819]] Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning(https://arxiv.org/abs/2502.01819)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Reinforcement learning from human feedback (RLHF), which aligns a diffusion model with input prompt, has become a crucial step in building reliable generative AI models. Most works in this area use a discrete-time formulation, which is prone to induced errors, and often not applicable to models with higher-order/black-box solvers. The objective of this study is to develop a disciplined approach to fine-tune diffusion models using continuous-time RL, formulated as a stochastic control problem with a reward function that aligns the end result (terminal state) with input prompt. The key idea is to treat score matching as controls or actions, and thereby making connections to policy optimization and regularization in continuous-time RL. To carry out this idea, we lay out a new policy optimization framework for continuous-time RL, and illustrate its potential in enhancing the value networks design space via leveraging the structural property of diffusion models. We validate the advantages of our method by experiments in downstream tasks of fine-tuning large-scale Text2Image models of Stable Diffusion v1.5.</li>
</ul>

<h3>Title: Firewalls to Secure Dynamic LLM Agentic Networks</h3>
<ul>
<li><strong>Authors: </strong>Sahar Abdelnabi, Amr Gomaa, Eugene Bagdasarian, Per Ola Kristensson, Reza Shokri</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01822">https://arxiv.org/abs/2502.01822</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01822">https://arxiv.org/pdf/2502.01822</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01822]] Firewalls to Secure Dynamic LLM Agentic Networks(https://arxiv.org/abs/2502.01822)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, privacy, defense</a></li>
<li><strong>Abstract: </strong>Future LLM agents are likely to communicate on behalf of users with other entity-representing agents on tasks that entail long-horizon plans with interdependent goals. Current work does not focus on such agentic networks, nor does it address their challenges. Thus, we first identify the required properties of agents' communication, which should be proactive and adaptable. It needs to satisfy 1) privacy: agents should not share more than what is needed for the task, and 2) security: the communication must preserve integrity and maintain utility against selfish entities. We design a use case (travel planning) as a testbed that exemplifies these requirements, and we show examples of how this can go wrong. Next, we propose a practical design, inspired by established network security principles, for constrained LLM agentic networks that balance adaptability, security, and privacy. Our framework automatically constructs and updates task-specific rules from prior simulations to build firewalls. We offer layers of defense to 1) convert free-form input to a task-specific protocol, 2) dynamically abstract users' data to a task-specific degree of permissiveness, and 3) self-correct the agents' trajectory.</li>
</ul>

<h3>Title: Efficient Denial of Service Attack Detection in IoT using Kolmogorov-Arnold Networks</h3>
<ul>
<li><strong>Authors: </strong>Oleksandr Kuznetsov</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01835">https://arxiv.org/abs/2502.01835</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01835">https://arxiv.org/pdf/2502.01835</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01835]] Efficient Denial of Service Attack Detection in IoT using Kolmogorov-Arnold Networks(https://arxiv.org/abs/2502.01835)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The proliferation of Internet of Things (IoT) devices has created a pressing need for efficient security solutions, particularly against Denial of Service (DoS) attacks. While existing detection approaches demonstrate high accuracy, they often require substantial computational resources, making them impractical for IoT deployment. This paper introduces a novel lightweight approach to DoS attack detection based on Kolmogorov-Arnold Networks (KANs). By leveraging spline-based transformations instead of traditional weight matrices, our solution achieves state-of-the-art detection performance while maintaining minimal resource requirements. Experimental evaluation on the CICIDS2017 dataset demonstrates 99.0% detection accuracy with only 0.19 MB memory footprint and 2.00 ms inference time per sample. Compared to existing solutions, KAN reduces memory requirements by up to 98% while maintaining competitive detection rates. The model's linear computational complexity ensures efficient scaling with input size, making it particularly suitable for large-scale IoT deployments. We provide comprehensive performance comparisons with recent approaches and demonstrate effectiveness across various DoS attack patterns. Our solution addresses the critical challenge of implementing sophisticated attack detection on resource-constrained devices, offering a practical approach to enhancing IoT security without compromising computational efficiency.</li>
</ul>

<h3>Title: Texture Image Synthesis Using Spatial GAN Based on Vision Transformers</h3>
<ul>
<li><strong>Authors: </strong>Elahe Salari, Zohreh Azimifar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01842">https://arxiv.org/abs/2502.01842</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01842">https://arxiv.org/pdf/2502.01842</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01842]] Texture Image Synthesis Using Spatial GAN Based on Vision Transformers(https://arxiv.org/abs/2502.01842)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, generative</a></li>
<li><strong>Abstract: </strong>Texture synthesis is a fundamental task in computer vision, whose goal is to generate visually realistic and structurally coherent textures for a wide range of applications, from graphics to scientific simulations. While traditional methods like tiling and patch-based techniques often struggle with complex textures, recent advancements in deep learning have transformed this field. In this paper, we propose ViT-SGAN, a new hybrid model that fuses Vision Transformers (ViTs) with a Spatial Generative Adversarial Network (SGAN) to address the limitations of previous methods. By incorporating specialized texture descriptors such as mean-variance (mu, sigma) and textons into the self-attention mechanism of ViTs, our model achieves superior texture synthesis. This approach enhances the model's capacity to capture complex spatial dependencies, leading to improved texture quality that is superior to state-of-the-art models, especially for regular and irregular textures. Comparison experiments with metrics such as FID, IS, SSIM, and LPIPS demonstrate the substantial improvement of ViT-SGAN, which underlines its efficiency in generating diverse realistic textures.</li>
</ul>

<h3>Title: UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping</h3>
<ul>
<li><strong>Authors: </strong>Aashish Rai, Dilin Wang, Mihir Jain, Nikolaos Sarafianos, Arthur Chen, Srinath Sridhar, Aayush Prakash</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01846">https://arxiv.org/abs/2502.01846</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01846">https://arxiv.org/pdf/2502.01846</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01846]] UVGS: Reimagining Unstructured 3D Gaussian Splatting using UV Mapping(https://arxiv.org/abs/2502.01846)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>3D Gaussian Splatting (3DGS) has demonstrated superior quality in modeling 3D objects and scenes. However, generating 3DGS remains challenging due to their discrete, unstructured, and permutation-invariant nature. In this work, we present a simple yet effective method to overcome these challenges. We utilize spherical mapping to transform 3DGS into a structured 2D representation, termed UVGS. UVGS can be viewed as multi-channel images, with feature dimensions as a concatenation of Gaussian attributes such as position, scale, color, opacity, and rotation. We further find that these heterogeneous features can be compressed into a lower-dimensional (e.g., 3-channel) shared feature space using a carefully designed multi-branch network. The compressed UVGS can be treated as typical RGB images. Remarkably, we discover that typical VAEs trained with latent diffusion models can directly generalize to this new representation without additional training. Our novel representation makes it effortless to leverage foundational 2D models, such as diffusion models, to directly model 3DGS. Additionally, one can simply increase the 2D UV resolution to accommodate more Gaussians, making UVGS a scalable solution compared to typical 3D backbones. This approach immediately unlocks various novel generation applications of 3DGS by inherently utilizing the already developed superior 2D generation capabilities. In our experiments, we demonstrate various unconditional, conditional generation, and inpainting applications of 3DGS based on diffusion models, which were previously non-trivial.</li>
</ul>

<h3>Title: Preparing for Kyber in Securing Intelligent Transportation Systems Communications: A Case Study on Fault-Enabled Chosen-Ciphertext Attack</h3>
<ul>
<li><strong>Authors: </strong>Kaiyuan Zhang, M Sabbir Salek, Antian Wang, Mizanur Rahman, Mashrur Chowdhury, Yingjie Lao</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01848">https://arxiv.org/abs/2502.01848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01848">https://arxiv.org/pdf/2502.01848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01848]] Preparing for Kyber in Securing Intelligent Transportation Systems Communications: A Case Study on Fault-Enabled Chosen-Ciphertext Attack(https://arxiv.org/abs/2502.01848)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, attack</a></li>
<li><strong>Abstract: </strong>Intelligent transportation systems (ITS) are characterized by wired or wireless communication among different entities, such as vehicles, roadside infrastructure, and traffic management infrastructure. These communications demand different levels of security, depending on how sensitive the data is. The national ITS reference architecture (ARC-IT) defines three security levels, i.e., high, moderate, and low-security levels, based on the different security requirements of ITS applications. In this study, we present a generalized approach to secure ITS communications using a standardized key encapsulation mechanism, known as Kyber, designed for post-quantum cryptography (PQC). We modified the encryption and decryption systems for ITS communications while mapping the security levels of ITS applications to the three versions of Kyber, i.e., Kyber-512, Kyber-768, and Kyber-1024. Then, we conducted a case study using a benchmark fault-enabled chosen-ciphertext attack to evaluate the security provided by the different Kyber versions. The encryption and decryption times observed for different Kyber security levels and the total number of iterations required to recover the secret key using the chosen-ciphertext attack are presented. Our analyses show that higher security levels increase the time required for a successful attack, with Kyber-512 being breached in 183 seconds, Kyber-768 in 337 seconds, and Kyber-1024 in 615 seconds. In addition, attack time instabilities are observed for Kyber-512, 768, and 1024 under 5,000, 6,000, and 8,000 inequalities, respectively. The relationships among the different Kyber versions, and the respective attack requirements and performances underscore the ITS communication security Kyber could provide in the PQC era.</li>
</ul>

<h3>Title: Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting</h3>
<ul>
<li><strong>Authors: </strong>Keyi Zhu, Jiajia Li, Kaixiang Zhang, Chaaran Arunachalam, Siddhartha Bhattacharya, Renfu Lu, Zhaojian Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01850">https://arxiv.org/abs/2502.01850</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01850">https://arxiv.org/pdf/2502.01850</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01850]] Foundation Model-Based Apple Ripeness and Size Estimation for Selective Harvesting(https://arxiv.org/abs/2502.01850)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Harvesting is a critical task in the tree fruit industry, demanding extensive manual labor and substantial costs, and exposing workers to potential hazards. Recent advances in automated harvesting offer a promising solution by enabling efficient, cost-effective, and ergonomic fruit picking within tight harvesting windows. However, existing harvesting technologies often indiscriminately harvest all visible and accessible fruits, including those that are unripe or undersized. This study introduces a novel foundation model-based framework for efficient apple ripeness and size estimation. Specifically, we curated two public RGBD-based Fuji apple image datasets, integrating expanded annotations for ripeness ("Ripe" vs. "Unripe") based on fruit color and image capture dates. The resulting comprehensive dataset, Fuji-Ripeness-Size Dataset, includes 4,027 images and 16,257 annotated apples with ripeness and size labels. Using Grounding-DINO, a language-model-based object detector, we achieved robust apple detection and ripeness classification, outperforming other state-of-the-art models. Additionally, we developed and evaluated six size estimation algorithms, selecting the one with the lowest error and variation for optimal performance. The Fuji-Ripeness-Size Dataset and the apple detection and size estimation algorithms are made publicly available, which provides valuable benchmarks for future studies in automated and selective harvesting.</li>
</ul>

<h3>Title: Security and Quality in LLM-Generated Code: A Multi-Language, Multi-Model Analysis</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Kharma, Soohyeon Choi, Mohammed AlKhanafseh, David Mohaisen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01853">https://arxiv.org/abs/2502.01853</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01853">https://arxiv.org/pdf/2502.01853</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01853]] Security and Quality in LLM-Generated Code: A Multi-Language, Multi-Model Analysis(https://arxiv.org/abs/2502.01853)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, large language model</a></li>
<li><strong>Abstract: </strong>Artificial Intelligence (AI)-driven code generation tools are increasingly used throughout the software development lifecycle to accelerate coding tasks. However, the security of AI-generated code using Large Language Models (LLMs) remains underexplored, with studies revealing various risks and weaknesses. This paper analyzes the security of code generated by LLMs across different programming languages. We introduce a dataset of 200 tasks grouped into six categories to evaluate the performance of LLMs in generating secure and maintainable code. Our research shows that while LLMs can automate code creation, their security effectiveness varies by language. Many models fail to utilize modern security features in recent compiler and toolkit updates, such as Java 17. Moreover, outdated methods are still commonly used, particularly in C++. This highlights the need for advancing LLMs to enhance security and quality while incorporating emerging best practices in programming languages.</li>
</ul>

<h3>Title: Reliability-Driven LiDAR-Camera Fusion for Robust 3D Object Detection</h3>
<ul>
<li><strong>Authors: </strong>Reza Sadeghian, Niloofar Hooshyaripour, Chris Joslin, WonSook Lee</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01856">https://arxiv.org/abs/2502.01856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01856">https://arxiv.org/pdf/2502.01856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01856]] Reliability-Driven LiDAR-Camera Fusion for Robust 3D Object Detection(https://arxiv.org/abs/2502.01856)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Accurate and robust 3D object detection is essential for autonomous driving, where fusing data from sensors like LiDAR and camera enhances detection accuracy. However, sensor malfunctions such as corruption or disconnection can degrade performance, and existing fusion models often struggle to maintain reliability when one modality fails. To address this, we propose ReliFusion, a novel LiDAR-camera fusion framework operating in the bird's-eye view (BEV) space. ReliFusion integrates three key components: the Spatio-Temporal Feature Aggregation (STFA) module, which captures dependencies across frames to stabilize predictions over time; the Reliability module, which assigns confidence scores to quantify the dependability of each modality under challenging conditions; and the Confidence-Weighted Mutual Cross-Attention (CW-MCA) module, which dynamically balances information from LiDAR and camera modalities based on these confidence scores. Experiments on the nuScenes dataset show that ReliFusion significantly outperforms state-of-the-art methods, achieving superior robustness and accuracy in scenarios with limited LiDAR fields of view and severe sensor malfunctions.</li>
</ul>

<h3>Title: Explaining Automatic Image Assessment</h3>
<ul>
<li><strong>Authors: </strong>Max Lisaius, Scott Wehrwein</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01873">https://arxiv.org/abs/2502.01873</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01873">https://arxiv.org/pdf/2502.01873</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01873]] Explaining Automatic Image Assessment(https://arxiv.org/abs/2502.01873)</code><input type="text"></li>
<li><strong>Keywords: </strong>explainability</a></li>
<li><strong>Abstract: </strong>Previous work in aesthetic categorization and explainability utilizes manual labeling and classification to explain aesthetic scores. These methods require a complex labeling process and are limited in size. Our proposed approach attempts to explain aesthetic assessment models through visualizing dataset trends and automatic categorization of visual aesthetic features through training neural networks on different versions of the same dataset. By evaluating the models adapted to each specific modality using existing and novel metrics, we can capture and visualize aesthetic features and trends.</li>
</ul>

<h3>Title: Latent Lexical Projection in Large Language Models: A Novel Approach to Implicit Representation Refinement</h3>
<ul>
<li><strong>Authors: </strong>Ziad Shaker, Brendan Ashdown, Hugo Fitzalan, Alistair Heathcote, Jocasta Huntington</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01882">https://arxiv.org/abs/2502.01882</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01882">https://arxiv.org/pdf/2502.01882</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01882]] Latent Lexical Projection in Large Language Models: A Novel Approach to Implicit Representation Refinement(https://arxiv.org/abs/2502.01882)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Generating semantically coherent text requires a robust internal representation of linguistic structures, which traditional embedding techniques often fail to capture adequately. A novel approach, Latent Lexical Projection (LLP), is introduced to refine lexical representations through a structured transformation into a latent space, thereby enhancing the alignment between input embeddings and their contextual meanings. The method integrates an optimized projection mechanism within an existing language model architecture, enabling more accurate token selection while maintaining syntactic integrity. Evaluations across multiple benchmarks indicate a reduction in perplexity and an increase in BLEU scores, suggesting improvements in predictive accuracy and fluency. The analysis of lexical diversity reveals a more varied vocabulary in generated text, addressing common issues of redundancy and repetitive phrase structures. Further assessments of entropy distributions demonstrate a decline in uncertainty during decoding, reflecting enhanced confidence in word selection. Additionally, long-range dependency retention exhibits measurable gains, with increased classification accuracy at extended token distances. Computational efficiency remains within manageable constraints, despite the added projection mechanism, highlighting the practicality of LLP for integration into existing architectures.</li>
</ul>

<h3>Title: A Privacy-Preserving Domain Adversarial Federated learning for multi-site brain functional connectivity analysis</h3>
<ul>
<li><strong>Authors: </strong>Yipu Zhang, Likai Wang, Kuan-Jui Su, Aiying Zhang, Hao Zhu, Xiaowen Liu, Hui Shen, Vince D. Calhoun, Yuping Wang, Hongwen Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01885">https://arxiv.org/abs/2502.01885</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01885">https://arxiv.org/pdf/2502.01885</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01885]] A Privacy-Preserving Domain Adversarial Federated learning for multi-site brain functional connectivity analysis(https://arxiv.org/abs/2502.01885)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, robust, federate</a></li>
<li><strong>Abstract: </strong>Resting-state functional magnetic resonance imaging (rs-fMRI) and its derived functional connectivity networks (FCNs) have become critical for understanding neurological disorders. However, collaborative analyses and the generalizability of models still face significant challenges due to privacy regulations and the non-IID (non-independent and identically distributed) property of multiple data sources. To mitigate these difficulties, we propose Domain Adversarial Federated Learning (DAFed), a novel federated deep learning framework specifically designed for non-IID fMRI data analysis in multi-site settings. DAFed addresses these challenges through feature disentanglement, decomposing the latent feature space into domain-invariant and domain-specific components, to ensure robust global learning while preserving local data specificity. Furthermore, adversarial training facilitates effective knowledge transfer between labeled and unlabeled datasets, while a contrastive learning module enhances the global representation of domain-invariant features. We evaluated DAFed on the diagnosis of ASD and further validated its generalizability in the classification of AD, demonstrating its superior classification accuracy compared to state-of-the-art methods. Additionally, an enhanced Score-CAM module identifies key brain regions and functional connectivity significantly associated with ASD and MCI, respectively, uncovering shared neurobiological patterns across sites. These findings highlight the potential of DAFed to advance multi-site collaborative research in neuroimaging while protecting data confidentiality.</li>
</ul>

<h3>Title: Displacement-Sparse Neural Optimal Transport</h3>
<ul>
<li><strong>Authors: </strong>Peter Chen, Yue Xie, Qingpeng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01889">https://arxiv.org/abs/2502.01889</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01889">https://arxiv.org/pdf/2502.01889</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01889]] Displacement-Sparse Neural Optimal Transport(https://arxiv.org/abs/2502.01889)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Optimal Transport (OT) theory seeks to determine the map $T:X \to Y$ that transports a source measure $P$ to a target measure $Q$, minimizing the cost $c(\mathbf{x}, T(\mathbf{x}))$ between $\mathbf{x}$ and its image $T(\mathbf{x})$. Building upon the Input Convex Neural Network OT solver and incorporating the concept of displacement-sparse maps, we introduce a sparsity penalty into the minimax Wasserstein formulation, promote sparsity in displacement vectors $\Delta(\mathbf{x}) := T(\mathbf{x}) - \mathbf{x}$, and enhance the interpretability of the resulting map. However, increasing sparsity often reduces feasibility, causing $T_{\#}(P)$ to deviate more significantly from the target measure. In low-dimensional settings, we propose a heuristic framework to balance the trade-off between sparsity and feasibility by dynamically adjusting the sparsity intensity parameter during training. For high-dimensional settings, we directly constrain the dimensionality of displacement vectors by enforcing $\dim(\Delta(\mathbf{x})) \leq l$, where $l < d$ for $X \subseteq \mathbb{R}^d$. Among maps satisfying this constraint, we aim to identify the most feasible one. This goal can be effectively achieved by adapting our low-dimensional heuristic framework without resorting to dimensionality reduction. We validate our method on both synthesized sc-RNA and real 4i cell perturbation datasets, demonstrating improvements over existing methods.</li>
</ul>

<h3>Title: Geometric Framework for 3D Cell Segmentation Correction</h3>
<ul>
<li><strong>Authors: </strong>Peter Chen, Bryan Chang, Olivia Annette Creasey, Julie Beth Sneddon, Yining Liu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01890">https://arxiv.org/abs/2502.01890</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01890">https://arxiv.org/pdf/2502.01890</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01890]] Geometric Framework for 3D Cell Segmentation Correction(https://arxiv.org/abs/2502.01890)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D cellular image segmentation methods are commonly divided into non-2D-based and 2D-based approaches, the latter reconstructing 3D shapes from the segmentation results of 2D layers. However, errors in 2D results often propagate, leading to oversegmentations in the final 3D results. To tackle this issue, we introduce an interpretable geometric framework that addresses the oversegmentations by correcting the 2D segmentation results based on geometric information from adjacent layers. Leveraging both geometric (layer-to-layer, 2D) and topological (3D shape) features, we use binary classification to determine whether neighboring cells should be stitched. We develop a pre-trained classifier on public plant cell datasets and validate its performance on animal cell datasets, confirming its effectiveness in correcting oversegmentations under the transfer learning setting. Furthermore, we demonstrate that our framework can be extended to correcting oversegmentation on non-2D-based methods. A clear pipeline is provided for end-users to build the pre-trained model to any labeled dataset.</li>
</ul>

<h3>Title: SimBEV: A Synthetic Multi-Task Multi-Sensor Driving Data Generation Tool and Dataset</h3>
<ul>
<li><strong>Authors: </strong>Goodarz Mehr, Azim Eskandarian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01894">https://arxiv.org/abs/2502.01894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01894">https://arxiv.org/pdf/2502.01894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01894]] SimBEV: A Synthetic Multi-Task Multi-Sensor Driving Data Generation Tool and Dataset(https://arxiv.org/abs/2502.01894)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Bird's-eye view (BEV) perception for autonomous driving has garnered significant attention in recent years, in part because BEV representation facilitates the fusion of multi-sensor data. This enables a variety of perception tasks including BEV segmentation, a concise view of the environment that can be used to plan a vehicle's trajectory. However, this representation is not fully supported by existing datasets, and creation of new datasets can be a time-consuming endeavor. To address this problem, in this paper we introduce SimBEV, an extensively configurable and scalable randomized synthetic data generation tool that incorporates information from multiple sources to capture accurate BEV ground truth data, supports a comprehensive array of sensors, and enables a variety of perception tasks including BEV segmentation and 3D object detection. We use SimBEV to create the SimBEV dataset, a large collection of annotated perception data from diverse driving scenarios.</li>
</ul>

<h3>Title: INTACT: Inducing Noise Tolerance through Adversarial Curriculum Training for LiDAR-based Safety-Critical Perception and Autonomy</h3>
<ul>
<li><strong>Authors: </strong>Nastaran Darabi, Divake Kumar, Sina Tayebati, Amit Ranjan Trivedi</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01896">https://arxiv.org/abs/2502.01896</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01896">https://arxiv.org/pdf/2502.01896</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01896]] INTACT: Inducing Noise Tolerance through Adversarial Curriculum Training for LiDAR-based Safety-Critical Perception and Autonomy(https://arxiv.org/abs/2502.01896)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In this work, we present INTACT, a novel two-phase framework designed to enhance the robustness of deep neural networks (DNNs) against noisy LiDAR data in safety-critical perception tasks. INTACT combines meta-learning with adversarial curriculum training (ACT) to systematically address challenges posed by data corruption and sparsity in 3D point clouds. The meta-learning phase equips a teacher network with task-agnostic priors, enabling it to generate robust saliency maps that identify critical data regions. The ACT phase leverages these saliency maps to progressively expose a student network to increasingly complex noise patterns, ensuring targeted perturbation and improved noise resilience. INTACT's effectiveness is demonstrated through comprehensive evaluations on object detection, tracking, and classification benchmarks using diverse datasets, including KITTI, Argoverse, and ModelNet40. Results indicate that INTACT improves model robustness by up to 20% across all tasks, outperforming standard adversarial and curriculum training methods. This framework not only addresses the limitations of conventional training strategies but also offers a scalable and efficient solution for real-world deployment in resource-constrained safety-critical systems. INTACT's principled integration of meta-learning and adversarial training establishes a new paradigm for noise-tolerant 3D perception in safety-critical applications. INTACT improved KITTI Multiple Object Tracking Accuracy (MOTA) by 9.6% (64.1% -> 75.1%) and by 12.4% under Gaussian noise (52.5% -> 73.7%). Similarly, KITTI mean Average Precision (mAP) rose from 59.8% to 69.8% (50% point drop) and 49.3% to 70.9% (Gaussian noise), highlighting the framework's ability to enhance deep learning model resilience in safety-critical object tracking scenarios.</li>
</ul>

<h3>Title: Conceptual Metaphor Theory as a Prompting Paradigm for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Oliver Kramer</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01901">https://arxiv.org/abs/2502.01901</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01901">https://arxiv.org/pdf/2502.01901</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01901]] Conceptual Metaphor Theory as a Prompting Paradigm for Large Language Models(https://arxiv.org/abs/2502.01901)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We introduce Conceptual Metaphor Theory (CMT) as a framework for enhancing large language models (LLMs) through cognitive prompting in complex reasoning tasks. CMT leverages metaphorical mappings to structure abstract reasoning, improving models' ability to process and explain intricate concepts. By incorporating CMT-based prompts, we guide LLMs toward more structured and human-like reasoning patterns. To evaluate this approach, we compare four native models (Llama3.2, Phi3, Gemma2, and Mistral) against their CMT-augmented counterparts on benchmark tasks spanning domain-specific reasoning, creative insight, and metaphor interpretation. Responses were automatically evaluated using the Llama3.3 70B model. Experimental results indicate that CMT prompting significantly enhances reasoning accuracy, clarity, and metaphorical coherence, outperforming baseline models across all evaluated tasks.</li>
</ul>

<h3>Title: Rethinking Homogeneity of Vision and Text Tokens in Large Vision-and-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Chia-Wen Kuo, Sijie Zhu, Fan Chen, Xiaohui Shen, Longyin Wen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01906">https://arxiv.org/abs/2502.01906</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01906">https://arxiv.org/pdf/2502.01906</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01906]] Rethinking Homogeneity of Vision and Text Tokens in Large Vision-and-Language Models(https://arxiv.org/abs/2502.01906)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large vision-and-language models (LVLMs) typically treat visual and textual embeddings as homogeneous inputs to a large language model (LLM). However, these inputs are inherently different: visual inputs are multi-dimensional and contextually rich, often pre-encoded by models like CLIP, while textual inputs lack this structure. In this paper, we propose Decomposed Attention (D-Attn), a novel method that processes visual and textual embeddings differently by decomposing the 1-D causal self-attention in LVLMs. After the attention decomposition, D-Attn diagonalizes visual-to-visual self-attention, reducing computation from $\mathcal{O}(|V|^2)$ to $\mathcal{O}(|V|)$ for $|V|$ visual embeddings without compromising performance. Moreover, D-Attn debiases positional encodings in textual-to-visual cross-attention, further enhancing visual understanding. Finally, we introduce an $\alpha$-weighting strategy to merge visual and textual information, maximally preserving the pre-trained LLM's capabilities with minimal modifications. Extensive experiments and rigorous analyses validate the effectiveness of D-Attn, demonstrating significant improvements on multiple image benchmarks while significantly reducing computational costs. Code, data, and models will be publicly available.</li>
</ul>

<h3>Title: Unlocking Efficient Large Inference Models: One-Bit Unrolling Tips the Scales</h3>
<ul>
<li><strong>Authors: </strong>Arian Eamaz, Farhang Yeganegi, Mojtaba Soltanalian</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01908">https://arxiv.org/abs/2502.01908</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01908">https://arxiv.org/pdf/2502.01908</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01908]] Unlocking Efficient Large Inference Models: One-Bit Unrolling Tips the Scales(https://arxiv.org/abs/2502.01908)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in Large Language Model (LLM) compression, such as BitNet and BitNet b1.58, have marked significant strides in reducing the computational demands of LLMs through innovative one-bit quantization techniques. We extend this frontier by looking at Large Inference Models (LIMs) that have become indispensable across various applications. However, their scale and complexity often come at a significant computational cost. We introduce a novel approach that leverages one-bit algorithm unrolling, effectively integrating information from the physical world in the model architecture. Our method achieves a bit-per-link rate significantly lower than the 1.58 bits reported in prior work, thanks to the natural sparsity that emerges in our network architectures. We numerically demonstrate that the proposed one-bit algorithm unrolling scheme can improve both training and test outcomes by effortlessly increasing the number of layers while substantially compressing the network. Additionally, we provide theoretical results on the generalization gap, convergence rate, stability, and sensitivity of our proposed one-bit algorithm unrolling.</li>
</ul>

<h3>Title: Anomaly Detection via Autoencoder Composite Features and NCE</h3>
<ul>
<li><strong>Authors: </strong>Yalin Liao, Austin J. Brockmeier</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01920">https://arxiv.org/abs/2502.01920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01920">https://arxiv.org/pdf/2502.01920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01920]] Anomaly Detection via Autoencoder Composite Features and NCE(https://arxiv.org/abs/2502.01920)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Unsupervised anomaly detection is a challenging task. Autoencoders (AEs) or generative models are often employed to model the data distribution of normal inputs and subsequently identify anomalous, out-of-distribution inputs by high reconstruction error or low likelihood, respectively. However, AEs may generalize and achieve small reconstruction errors on abnormal inputs. We propose a decoupled training approach for anomaly detection that both an AE and a likelihood model trained with noise contrastive estimation (NCE). After training the AE, NCE estimates a probability density function, to serve as the anomaly score, on the joint space of the AE's latent representation combined with features of the reconstruction quality. To further reduce the false negative rate in NCE we systematically varying the reconstruction features to augment the training and optimize the contrastive Gaussian noise distribution. Experimental assessments on multiple benchmark datasets demonstrate that the proposed approach matches the performance of prevalent state-of-the-art anomaly detection algorithms.</li>
</ul>

<h3>Title: LAST SToP For Modeling Asynchronous Time Series</h3>
<ul>
<li><strong>Authors: </strong>Shubham Gupta, Thibaut Durand, Graham Taylor, Lilian W. Bia≈Çokozowicz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01922">https://arxiv.org/abs/2502.01922</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01922">https://arxiv.org/pdf/2502.01922</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01922]] LAST SToP For Modeling Asynchronous Time Series(https://arxiv.org/abs/2502.01922)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>We present a novel prompt design for Large Language Models (LLMs) tailored to Asynchronous Time Series. Unlike regular time series, which assume values at evenly spaced time points, asynchronous time series consist of timestamped events occurring at irregular intervals, each described in natural language. Our approach effectively utilizes the rich natural language of event descriptions, allowing LLMs to benefit from their broad world knowledge for reasoning across different domains and tasks. This allows us to extend the scope of asynchronous time series analysis beyond forecasting to include tasks like anomaly detection and data imputation. We further introduce Stochastic Soft Prompting, a novel prompt-tuning mechanism that significantly improves model performance, outperforming existing fine-tuning methods such as QLoRA. Through extensive experiments on real world datasets, we demonstrate that our approach achieves state-of-the-art performance across different tasks and datasets.</li>
</ul>

<h3>Title: PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling</h3>
<ul>
<li><strong>Authors: </strong>Avery Ma, Yangchen Pan, Amir-massoud Farahmand</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CR, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01925">https://arxiv.org/abs/2502.01925</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01925">https://arxiv.org/pdf/2502.01925</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01925]] PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling(https://arxiv.org/abs/2502.01925)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Many-shot jailbreaking circumvents the safety alignment of large language models by exploiting their ability to process long input sequences. To achieve this, the malicious target prompt is prefixed with hundreds of fabricated conversational turns between the user and the model. These fabricated exchanges are randomly sampled from a pool of malicious questions and responses, making it appear as though the model has already complied with harmful instructions. In this paper, we present PANDAS: a hybrid technique that improves many-shot jailbreaking by modifying these fabricated dialogues with positive affirmations, negative demonstrations, and an optimized adaptive sampling method tailored to the target prompt's topic. Extensive experiments on AdvBench and HarmBench, using state-of-the-art LLMs, demonstrate that PANDAS significantly outperforms baseline methods in long-context scenarios. Through an attention analysis, we provide insights on how long-context vulnerabilities are exploited and show how PANDAS further improves upon many-shot jailbreaking.</li>
</ul>

<h3>Title: Distributionally Robust Direct Preference Optimization</h3>
<ul>
<li><strong>Authors: </strong>Zaiyan Xu, Sushil Vemuri, Kishan Panaganti, Dileep Kalathil, Rahul Jain, Deepak Ramachandran</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01930">https://arxiv.org/abs/2502.01930</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01930">https://arxiv.org/pdf/2502.01930</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01930]] Distributionally Robust Direct Preference Optimization(https://arxiv.org/abs/2502.01930)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>A major challenge in aligning large language models (LLMs) with human preferences is the issue of distribution shift. LLM alignment algorithms rely on static preference datasets, assuming that they accurately represent real-world user preferences. However, user preferences vary significantly across geographical regions, demographics, linguistic patterns, and evolving cultural trends. This preference distribution shift leads to catastrophic alignment failures in many real-world applications. We address this problem using the principled framework of distributionally robust optimization, and develop two novel distributionally robust direct preference optimization (DPO) algorithms, namely, Wasserstein DPO (WDPO) and Kullback-Leibler DPO (KLDPO). We characterize the sample complexity of learning the optimal policy parameters for WDPO and KLDPO. Moreover, we propose scalable gradient descent-style learning algorithms by developing suitable approximations for the challenging minimax loss functions of WDPO and KLDPO. Our empirical experiments demonstrate the superior performance of WDPO and KLDPO in substantially improving the alignment when there is a preference distribution shift.</li>
</ul>

<h3>Title: Query-Based and Unnoticeable Graph Injection Attack from Neighborhood Perspective</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Hai Huang, Yujie Xing, Xingquan Zuo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01936">https://arxiv.org/abs/2502.01936</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01936">https://arxiv.org/pdf/2502.01936</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01936]] Query-Based and Unnoticeable Graph Injection Attack from Neighborhood Perspective(https://arxiv.org/abs/2502.01936)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust</a></li>
<li><strong>Abstract: </strong>The robustness of Graph Neural Networks (GNNs) has become an increasingly important topic due to their expanding range of applications. Various attack methods have been proposed to explore the vulnerabilities of GNNs, ranging from Graph Modification Attacks (GMA) to the more practical and flexible Graph Injection Attacks (GIA). However, existing methods face two key challenges: (i) their reliance on surrogate models, which often leads to reduced attack effectiveness due to structural differences and prior biases, and (ii) existing GIA methods often sacrifice attack success rates in undefended settings to bypass certain defense models, thereby limiting their overall effectiveness. To overcome these limitations, we propose QUGIA, a Query-based and Unnoticeable Graph Injection Attack. QUGIA injects nodes by first selecting edges based on victim node connections and then generating node features using a Bayesian framework. This ensures that the injected nodes are similar to the original graph nodes, implicitly preserving homophily and making the attack more unnoticeable. Unlike previous methods, QUGIA does not rely on surrogate models, thereby avoiding performance degradation and achieving better generalization. Extensive experiments on six real-world datasets with diverse characteristics demonstrate that QUGIA achieves unnoticeable attacks and outperforms state-of-the-art attackers. The code will be released upon acceptance.</li>
</ul>

<h3>Title: Toward a Low-Cost Perception System in Autonomous Vehicles: A Spectrum Learning Approach</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Alsakabi, Aidan Erickson, John M. Dolan, Ozan K. Tonguz</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01940">https://arxiv.org/abs/2502.01940</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01940">https://arxiv.org/pdf/2502.01940</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01940]] Toward a Low-Cost Perception System in Autonomous Vehicles: A Spectrum Learning Approach(https://arxiv.org/abs/2502.01940)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present a cost-effective new approach for generating denser depth maps for Autonomous Driving (AD) and Autonomous Vehicles (AVs) by integrating the images obtained from deep neural network (DNN) 4D radar detectors with conventional camera RGB images. Our approach introduces a novel pixel positional encoding algorithm inspired by Bartlett's spatial spectrum estimation technique. This algorithm transforms both radar depth maps and RGB images into a unified pixel image subspace called the Spatial Spectrum, facilitating effective learning based on their similarities and differences. Our method effectively leverages high-resolution camera images to train radar depth map generative models, addressing the limitations of conventional radar detectors in complex vehicular environments, thus sharpening the radar output. We develop spectrum estimation algorithms tailored for radar depth maps and RGB images, a comprehensive training framework for data-driven generative models, and a camera-radar deployment scheme for AV operation. Our results demonstrate that our approach also outperforms the state-of-the-art (SOTA) by 27.95% in terms of Unidirectional Chamfer Distance (UCD).</li>
</ul>

<h3>Title: Can LLMs Maintain Fundamental Abilities under KV Cache Compression?</h3>
<ul>
<li><strong>Authors: </strong>Xiang Liu, Zhenheng Tang, Hong Chen, Peijie Dong, Zeyu Li, Xiuze Zhou, Bo Li, Xuming Hu, Xiaowen Chu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01941">https://arxiv.org/abs/2502.01941</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01941">https://arxiv.org/pdf/2502.01941</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01941]] Can LLMs Maintain Fundamental Abilities under KV Cache Compression?(https://arxiv.org/abs/2502.01941)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>This paper investigates an under-explored challenge in large language models (LLMs): the impact of KV cache compression methods on LLMs' fundamental capabilities. While existing methods achieve impressive compression ratios on long-context benchmarks, their effects on core model capabilities remain understudied. We present a comprehensive empirical study evaluating prominent KV cache compression methods across diverse tasks, spanning world knowledge, commonsense reasoning, arithmetic reasoning, code generation, safety, and long-context understanding and this http URL analysis reveals that KV cache compression methods exhibit task-specific performance degradation. Arithmetic reasoning tasks prove particularly sensitive to aggressive compression, with different methods showing performance drops of $17.4\%$-$43.3\%$. Notably, the DeepSeek R1 Distill model exhibits more robust compression tolerance compared to instruction-tuned models, showing only $9.67\%$-$25.53\%$ performance degradation. Based on our analysis of attention patterns and cross-task compression performance, we propose ShotKV, a novel compression approach that distinctly handles prefill and decoding phases while maintaining shot-level semantic coherence. Empirical results show that ShotKV achieves $9\%$-$18\%$ performance improvements on long-context generation tasks under aggressive compression ratios.</li>
</ul>

<h3>Title: Boundary-Driven Table-Filling with Cross-Granularity Contrastive Learning for Aspect Sentiment Triplet Extraction</h3>
<ul>
<li><strong>Authors: </strong>Qingling Li, Wushao Wen, Jinghui Qin</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01942">https://arxiv.org/abs/2502.01942</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01942">https://arxiv.org/pdf/2502.01942</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01942]] Boundary-Driven Table-Filling with Cross-Granularity Contrastive Learning for Aspect Sentiment Triplet Extraction(https://arxiv.org/abs/2502.01942)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>The Aspect Sentiment Triplet Extraction (ASTE) task aims to extract aspect terms, opinion terms, and their corresponding sentiment polarity from a given sentence. It remains one of the most prominent subtasks in fine-grained sentiment analysis. Most existing approaches frame triplet extraction as a 2D table-filling process in an end-to-end manner, focusing primarily on word-level interactions while often overlooking sentence-level representations. This limitation hampers the model's ability to capture global contextual information, particularly when dealing with multi-word aspect and opinion terms in complex sentences. To address these issues, we propose boundary-driven table-filling with cross-granularity contrastive learning (BTF-CCL) to enhance the semantic consistency between sentence-level representations and word-level representations. By constructing positive and negative sample pairs, the model is forced to learn the associations at both the sentence level and the word level. Additionally, a multi-scale, multi-granularity convolutional method is proposed to capture rich semantic information better. Our approach can capture sentence-level contextual information more effectively while maintaining sensitivity to local details. Experimental results show that the proposed method achieves state-of-the-art performance on public benchmarks according to the F1 score.</li>
</ul>

<h3>Title: DAMO: Data- and Model-aware Alignment of Multi-modal LLMs</h3>
<ul>
<li><strong>Authors: </strong>Jinda Lu, Junkang Wu, Jinghan Li, Xiaojun Jia, Shuo Wang, YiFan Zhang, Junfeng Fang, Xiang Wang, Xiangnan He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01943">https://arxiv.org/abs/2502.01943</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01943">https://arxiv.org/pdf/2502.01943</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01943]] DAMO: Data- and Model-aware Alignment of Multi-modal LLMs(https://arxiv.org/abs/2502.01943)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Direct Preference Optimization (DPO) has shown effectiveness in aligning multi-modal large language models (MLLM) with human preferences. However, existing methods exhibit an imbalanced responsiveness to the data of varying hardness, tending to overfit on the easy-to-distinguish data while underfitting on the hard-to-distinguish data. In this paper, we propose Data- and Model-aware DPO (DAMO) to dynamically adjust the optimization process from two key aspects: (1) a data-aware strategy that incorporates data hardness, and (2) a model-aware strategy that integrates real-time model responses. By combining the two strategies, DAMO enables the model to effectively adapt to data with varying levels of hardness. Extensive experiments on five benchmarks demonstrate that DAMO not only significantly enhances the trustworthiness, but also improves the effectiveness over general tasks. For instance, on the Object HalBench, our DAMO-7B reduces response-level and mentioned-level hallucination by 90.0% and 95.3%, respectively, surpassing the performance of GPT-4V.</li>
</ul>

<h3>Title: On the Emergence of Position Bias in Transformers</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Wu, Yifei Wang, Stefanie Jegelka, Ali Jadbabaie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01951">https://arxiv.org/abs/2502.01951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01951">https://arxiv.org/pdf/2502.01951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01951]] On the Emergence of Position Bias in Transformers(https://arxiv.org/abs/2502.01951)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent studies have revealed various manifestations of position bias in transformer architectures, from the "lost-in-the-middle" phenomenon to attention sinks, yet a comprehensive theoretical understanding of how attention masks and positional encodings shape these biases remains elusive. This paper introduces a novel graph-theoretic framework to analyze position bias in multi-layer attention. Modeling attention masks as directed graphs, we quantify how tokens interact with contextual information based on their sequential positions. We uncover two key insights: First, causal masking inherently biases attention toward earlier positions, as tokens in deeper layers attend to increasingly more contextualized representations of earlier tokens. Second, we characterize the competing effects of the causal mask and relative positional encodings, such as the decay mask and rotary positional encoding (RoPE): while both mechanisms introduce distance-based decay within individual attention maps, their aggregate effect across multiple attention layers -- coupled with the causal mask -- leads to a trade-off between the long-term decay effects and the cumulative importance of early sequence positions. Through controlled numerical experiments, we not only validate our theoretical findings but also reproduce position biases observed in real-world LLMs. Our framework offers a principled foundation for understanding positional biases in transformers, shedding light on the complex interplay of attention mechanism components and guiding more informed architectural design.</li>
</ul>

<h3>Title: Constrained belief updates explain geometric structures in transformer representations</h3>
<ul>
<li><strong>Authors: </strong>Mateusz Piotrowski, Paul M. Riechers, Daniel Filan, Adam S. Shai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01954">https://arxiv.org/abs/2502.01954</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01954">https://arxiv.org/pdf/2502.01954</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01954]] Constrained belief updates explain geometric structures in transformer representations(https://arxiv.org/abs/2502.01954)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>What computational structures emerge in transformers trained on next-token prediction? In this work, we provide evidence that transformers implement constrained Bayesian belief updating -- a parallelized version of partial Bayesian inference shaped by architectural constraints. To do this, we integrate the model-agnostic theory of optimal prediction with mechanistic interpretability to analyze transformers trained on a tractable family of hidden Markov models that generate rich geometric patterns in neural activations. We find that attention heads carry out an algorithm with a natural interpretation in the probability simplex, and create representations with distinctive geometric structure. We show how both the algorithmic behavior and the underlying geometry of these representations can be theoretically predicted in detail -- including the attention pattern, OV-vectors, and embedding vectors -- by modifying the equations for optimal future token predictions to account for the architectural constraints of attention. Our approach provides a principled lens on how gradient descent resolves the tension between optimal prediction and architectural design.</li>
</ul>

<h3>Title: MATCNN: Infrared and Visible Image Fusion Method Based on Multi-scale CNN with Attention Transformer</h3>
<ul>
<li><strong>Authors: </strong>Jingjing Liu, Li Zhang, Xiaoyang Zeng, Wanquan Liu, Jianhua Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01959">https://arxiv.org/abs/2502.01959</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01959">https://arxiv.org/pdf/2502.01959</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01959]] MATCNN: Infrared and Visible Image Fusion Method Based on Multi-scale CNN with Attention Transformer(https://arxiv.org/abs/2502.01959)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer</a></li>
<li><strong>Abstract: </strong>While attention-based approaches have shown considerable progress in enhancing image fusion and addressing the challenges posed by long-range feature dependencies, their efficacy in capturing local features is compromised by the lack of diverse receptive field extraction techniques. To overcome the shortcomings of existing fusion methods in extracting multi-scale local features and preserving global features, this paper proposes a novel cross-modal image fusion approach based on a multi-scale convolutional neural network with attention Transformer (MATCNN). MATCNN utilizes the multi-scale fusion module (MSFM) to extract local features at different scales and employs the global feature extraction module (GFEM) to extract global features. Combining the two reduces the loss of detail features and improves the ability of global feature representation. Simultaneously, an information mask is used to label pertinent details within the images, aiming to enhance the proportion of preserving significant information in infrared images and background textures in visible images in fused images. Subsequently, a novel optimization algorithm is developed, leveraging the mask to guide feature extraction through the integration of content, structural similarity index measurement, and global feature loss. Quantitative and qualitative evaluations are conducted across various datasets, revealing that MATCNN effectively highlights infrared salient targets, preserves additional details in visible images, and achieves better fusion results for cross-modal images. The code of MATCNN will be available at this https URL.</li>
</ul>

<h3>Title: MPIC: Position-Independent Multimodal Context Caching System for Efficient MLLM Serving</h3>
<ul>
<li><strong>Authors: </strong>Shiju Zhao, Junhao Hu, Rongxiao Huang, Jiaqi Zheng, Guihai Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01960">https://arxiv.org/abs/2502.01960</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01960">https://arxiv.org/pdf/2502.01960</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01960]] MPIC: Position-Independent Multimodal Context Caching System for Efficient MLLM Serving(https://arxiv.org/abs/2502.01960)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The context caching technique is employed to accelerate the Multimodal Large Language Model (MLLM) inference by prevailing serving platforms currently. However, this approach merely reuses the Key-Value (KV) cache of the initial sequence of prompt, resulting in full KV cache recomputation even if the prefix differs slightly. This becomes particularly inefficient in the context of interleaved text and images, as well as multimodal retrieval-augmented generation. This paper proposes position-independent caching as a more effective approach for multimodal information management. We have designed and implemented a caching system, named MPIC, to address both system-level and algorithm-level challenges. MPIC stores the KV cache on local or remote disks when receiving multimodal data, and calculates and loads the KV cache in parallel during inference. To mitigate accuracy degradation, we have incorporated integrated reuse and recompute mechanisms within the system. The experimental results demonstrate that MPIC can achieve up to 54% reduction in response time compared to existing context caching systems, while maintaining negligible or no accuracy loss.</li>
</ul>

<h3>Title: Memory Efficient Transformer Adapter for Dense Predictions</h3>
<ul>
<li><strong>Authors: </strong>Dong Zhang, Rui Yan, Pingcheng Dong, Kwang-Ting Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01962">https://arxiv.org/abs/2502.01962</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01962">https://arxiv.org/pdf/2502.01962</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01962]] Memory Efficient Transformer Adapter for Dense Predictions(https://arxiv.org/abs/2502.01962)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, segmentation</a></li>
<li><strong>Abstract: </strong>While current Vision Transformer (ViT) adapter methods have shown promising accuracy, their inference speed is implicitly hindered by inefficient memory access operations, e.g., standard normalization and frequent reshaping. In this work, we propose META, a simple and fast ViT adapter that can improve the model's memory efficiency and decrease memory time consumption by reducing the inefficient memory access operations. Our method features a memory-efficient adapter block that enables the common sharing of layer normalization between the self-attention and feed-forward network layers, thereby reducing the model's reliance on normalization operations. Within the proposed block, the cross-shaped self-attention is employed to reduce the model's frequent reshaping operations. Moreover, we augment the adapter block with a lightweight convolutional branch that can enhance local inductive biases, particularly beneficial for the dense prediction tasks, e.g., object detection, instance segmentation, and semantic segmentation. The adapter block is finally formulated in a cascaded manner to compute diverse head features, thereby enriching the variety of feature representations. Empirically, extensive evaluations on multiple representative datasets validate that META substantially enhances the predicted quality, while achieving a new state-of-the-art accuracy-efficiency trade-off. Theoretically, we demonstrate that META exhibits superior generalization capability and stronger adaptability.</li>
</ul>

<h3>Title: Optimizing Spot Instance Reliability and Security Using Cloud-Native Data and Tools</h3>
<ul>
<li><strong>Authors: </strong>Shubham Malhotra</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC, cs.ET, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01966">https://arxiv.org/abs/2502.01966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01966">https://arxiv.org/pdf/2502.01966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01966]] Optimizing Spot Instance Reliability and Security Using Cloud-Native Data and Tools(https://arxiv.org/abs/2502.01966)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, security, robust</a></li>
<li><strong>Abstract: </strong>This paper represents "Cloudlab", a comprehensive, cloud - native laboratory designed to support network security research and training. Built on Google Cloud and adhering to GitOps methodologies, Cloudlab facilitates the the creation, testing, and deployment of secure, containerized workloads using Kubernetes and serverless architectures. The lab integrates tools like Palo Alto Networks firewalls, Bridgecrew for "Security as Code," and automated GitHub workflows to establish a robust Continuous Integration/Continuous Machine Learning pipeline. By providing an adaptive and scalable environment, Cloudlab supports advanced security concepts such as role-based access control, Policy as Code, and container security. This initiative enables data scientists and engineers to explore cutting-edge practices in a dynamic cloud-native ecosystem, fostering innovation and improving operational resilience in modern IT infrastructures.</li>
</ul>

<h3>Title: Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Jinlong Pang, Na Di, Zhaowei Zhu, Jiaheng Wei, Hao Cheng, Chen Qian, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01968">https://arxiv.org/abs/2502.01968</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01968">https://arxiv.org/pdf/2502.01968</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01968]] Token Cleaning: Fine-Grained Data Selection for LLM Supervised Fine-Tuning(https://arxiv.org/abs/2502.01968)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent studies show that in supervised fine-tuning (SFT) of large language models (LLMs), data quality matters more than quantity. While most data cleaning methods concentrate on filtering entire samples, the quality of individual tokens within a sample can vary significantly. After pre-training, even in high-quality samples, patterns or phrases that are not task-related can be redundant or uninformative. Continuing to fine-tune on these patterns may offer limited benefit and even degrade downstream task performance. In this paper, we investigate token quality from a noisy-label perspective and propose a generic token cleaning pipeline for SFT tasks. Our method filters out uninformative tokens while preserving those carrying key task-specific information. Specifically, we first evaluate token quality by examining the influence of model updates on each token, then apply a threshold-based separation. The token influence can be measured in a single pass with a fixed reference model or iteratively with self-evolving reference models. The benefits and limitations of both methods are analyzed theoretically by error upper bounds. Extensive experiments show that our framework consistently improves performance across multiple downstream tasks.</li>
</ul>

<h3>Title: CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing</h3>
<ul>
<li><strong>Authors: </strong>Wenhao Zheng, Yixiao Chen, Weitong Zhang, Souvik Kundu, Yun Li, Zhengzhong Liu, Eric P. Xing, Hongyi Wang, Huaxiu Yao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01976">https://arxiv.org/abs/2502.01976</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01976">https://arxiv.org/pdf/2502.01976</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01976]] CITER: Collaborative Inference for Efficient Large Language Model Decoding with Token-Level Routing(https://arxiv.org/abs/2502.01976)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models have achieved remarkable success in various tasks but suffer from high computational costs during inference, limiting their deployment in resource-constrained applications. To address this issue, we propose a novel CITER (\textbf{C}ollaborative \textbf{I}nference with \textbf{T}oken-l\textbf{E}vel \textbf{R}outing) framework that enables efficient collaboration between small and large language models (SLMs & LLMs) through a token-level routing strategy. Specifically, CITER routes non-critical tokens to an SLM for efficiency and routes critical tokens to an LLM for generalization quality. We formulate router training as a policy optimization, where the router receives rewards based on both the quality of predictions and the inference costs of generation. This allows the router to learn to predict token-level routing scores and make routing decisions based on both the current token and the future impact of its decisions. To further accelerate the reward evaluation process, we introduce a shortcut which significantly reduces the costs of the reward estimation and improving the practicality of our approach. Extensive experiments on five benchmark datasets demonstrate that CITER reduces the inference costs while preserving high-quality generation, offering a promising solution for real-time and resource-constrained applications.</li>
</ul>

<h3>Title: AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs</h3>
<ul>
<li><strong>Authors: </strong>Hongxin Li, Jingfan Chen, Jingran Su, Yuntao Chen, Qing Li, Zhaoxiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01977">https://arxiv.org/abs/2502.01977</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01977">https://arxiv.org/pdf/2502.01977</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01977]] AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs(https://arxiv.org/abs/2502.01977)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>User interface understanding with vision-language models has received much attention due to its potential for enabling next-generation software automation. However, existing UI datasets either only provide large-scale context-free element annotations or contextualized functional descriptions for elements at a much smaller scale. In this work, we propose the \methodname{} pipeline for automatically annotating UI elements with detailed functionality descriptions at scale. Specifically, we leverage large language models (LLMs) to infer element functionality by comparing the UI content changes before and after simulated interactions with specific UI elements. To improve annotation quality, we propose LLM-aided rejection and verification, eliminating invalid and incorrect annotations without human labor. We construct an \methodname{}-704k dataset using the proposed pipeline, featuring multi-resolution, multi-device screenshots, diverse data domains, and detailed functionality annotations that have never been provided by previous datasets. Human evaluation shows that the AutoGUI pipeline achieves annotation correctness comparable to trained human annotators. Extensive experimental results show that our \methodname{}-704k dataset remarkably enhances VLM's UI grounding capabilities, exhibits significant scaling effects, and outperforms existing web pre-training data types. We envision AutoGUI as a scalable pipeline for generating massive data to build GUI-oriented VLMs. AutoGUI dataset can be viewed at this anonymous URL: this https URL.</li>
</ul>

<h3>Title: Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Derek Yotheringhay, Beatrix Nightingale, Maximilian Featherstone, Edmund Worthington, Hugo Ashdown</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01979">https://arxiv.org/abs/2502.01979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01979">https://arxiv.org/pdf/2502.01979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01979]] Gradient-Regularized Latent Space Modulation in Large Language Models for Structured Contextual Synthesis(https://arxiv.org/abs/2502.01979)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative, large language model</a></li>
<li><strong>Abstract: </strong>Generating structured textual content requires mechanisms that enforce coherence, stability, and adherence to predefined constraints while maintaining semantic fidelity. Conventional approaches often rely on rule-based heuristics or fine-tuning strategies that lack flexibility and generalizability across diverse tasks. The incorporation of Gradient-Regularized Latent Space Modulation (GRLSM) introduces a novel paradigm for guiding text generation through the application of structured constraints within the latent space. The integration of gradient-based regularization mitigates abrupt variations in latent representations, ensuring a smoother encoding process that enhances structural consistency and logical progression within generated sequences. Comparative evaluations demonstrate that latent space modulation leads to a reduction in perplexity, increased coherence scores, and improved structural alignment across multiple domains. Stability assessments further indicate that the imposition of spectral norm constraints facilitates more controlled variations in generated text, preserving semantic consistency under input perturbations. Empirical results confirm that structured latent space constraints not only refine the organization of generated outputs but also enhance interpretability through more predictable and reliable synthesis patterns. Performance metrics illustrate that the GRLSM framework substantially reduces structural inconsistencies while preserving the generative flexibility inherent in neural models.</li>
</ul>

<h3>Title: Generative Data Mining with Longtail-Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>David S. Hayden, Mao Ye, Timur Garipov, Gregory P. Meyer, Carl Vondrick, Zhao Chen, Yuning Chai, Eric Wolff, Siddhartha S. Srinivasa</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01980">https://arxiv.org/abs/2502.01980</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01980">https://arxiv.org/pdf/2502.01980</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01980]] Generative Data Mining with Longtail-Guided Diffusion(https://arxiv.org/abs/2502.01980)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>It is difficult to anticipate the myriad challenges that a predictive model will encounter once deployed. Common practice entails a reactive, cyclical approach: model deployment, data mining, and retraining. We instead develop a proactive longtail discovery process by imagining additional data during training. In particular, we develop general model-based longtail signals, including a differentiable, single forward pass formulation of epistemic uncertainty that does not impact model parameters or predictive performance but can flag rare or hard inputs. We leverage these signals as guidance to generate additional training data from a latent diffusion model in a process we call Longtail Guidance (LTG). Crucially, we can perform LTG without retraining the diffusion model or the predictive model, and we do not need to expose the predictive model to intermediate diffusion states. Data generated by LTG exhibit semantically meaningful variation, yield significant generalization improvements on image classification benchmarks, and can be analyzed to proactively discover, explain, and address conceptual gaps in a predictive model.</li>
</ul>

<h3>Title: DCT-Mamba3D: Spectral Decorrelation and Spatial-Spectral Feature Extraction for Hyperspectral Image Classification</h3>
<ul>
<li><strong>Authors: </strong>Weijia Cao, Xiaofei Yang, Yicong Zhou, Zheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01986">https://arxiv.org/abs/2502.01986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01986">https://arxiv.org/pdf/2502.01986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01986]] DCT-Mamba3D: Spectral Decorrelation and Spatial-Spectral Feature Extraction for Hyperspectral Image Classification(https://arxiv.org/abs/2502.01986)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, extraction</a></li>
<li><strong>Abstract: </strong>Hyperspectral image classification presents challenges due to spectral redundancy and complex spatial-spectral dependencies. This paper proposes a novel framework, DCT-Mamba3D, for hyperspectral image classification. DCT-Mamba3D incorporates: (1) a 3D spectral-spatial decorrelation module that applies 3D discrete cosine transform basis functions to reduce both spectral and spatial redundancy, enhancing feature clarity across dimensions; (2) a 3D-Mamba module that leverages a bidirectional state-space model to capture intricate spatial-spectral dependencies; and (3) a global residual enhancement module that stabilizes feature representation, improving robustness and convergence. Extensive experiments on benchmark datasets show that our DCT-Mamba3D outperforms the state-of-the-art methods in challenging scenarios such as the same object in different spectra and different objects in the same spectra.</li>
</ul>

<h3>Title: T-SCEND: Test-time Scalable MCTS-enhanced Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Tao Zhang, Jia-Shu Pan, Ruiqi Feng, Tailin Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01989">https://arxiv.org/abs/2502.01989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01989">https://arxiv.org/pdf/2502.01989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01989]] T-SCEND: Test-time Scalable MCTS-enhanced Diffusion Model(https://arxiv.org/abs/2502.01989)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>We introduce Test-time Scalable MCTS-enhanced Diffusion Model (T-SCEND), a novel framework that significantly improves diffusion model's reasoning capabilities with better energy-based training and scaling up test-time computation. We first show that na√Øvely scaling up inference budget for diffusion models yields marginal gain. To address this, the training of T-SCEND consists of a novel linear-regression negative contrastive learning objective to improve the performance-energy consistency of the energy landscape, and a KL regularization to reduce adversarial sampling. During inference, T-SCEND integrates the denoising process with a novel hybrid Monte Carlo Tree Search (hMCTS), which sequentially performs best-of-N random search and MCTS as denoising proceeds. On challenging reasoning tasks of Maze and Sudoku, we demonstrate the effectiveness of T-SCEND's training objective and scalable inference method. In particular, trained with Maze sizes of up to $6\times6$, our T-SCEND solves $88\%$ of Maze problems with much larger sizes of $15\times15$, while standard diffusion completely this http URL to reproduce the experiments can be found at this https URL.</li>
</ul>

<h3>Title: Rethinking Timesteps Samplers and Prediction Types</h3>
<ul>
<li><strong>Authors: </strong>Bin Xie, Gady Agam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01990">https://arxiv.org/abs/2502.01990</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01990">https://arxiv.org/pdf/2502.01990</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01990]] Rethinking Timesteps Samplers and Prediction Types(https://arxiv.org/abs/2502.01990)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models suffer from the huge consumption of time and resources to train. For example, diffusion models need hundreds of GPUs to train for several weeks for a high-resolution generative task to meet the requirements of an extremely large number of iterations and a large batch size. Training diffusion models become a millionaire's game. With limited resources that only fit a small batch size, training a diffusion model always fails. In this paper, we investigate the key reasons behind the difficulties of training diffusion models with limited resources. Through numerous experiments and demonstrations, we identified a major factor: the significant variation in the training losses across different timesteps, which can easily disrupt the progress made in previous iterations. Moreover, different prediction types of $x_0$ exhibit varying effectiveness depending on the task and timestep. We hypothesize that using a mixed-prediction approach to identify the most accurate $x_0$ prediction type could potentially serve as a breakthrough in addressing this issue. In this paper, we outline several challenges and insights, with the hope of inspiring further research aimed at tackling the limitations of training diffusion models with constrained resources, particularly for high-resolution tasks.</li>
</ul>

<h3>Title: Can LLMs Assist Annotators in Identifying Morality Frames? -- Case Study on Vaccination Debate on Social Media</h3>
<ul>
<li><strong>Authors: </strong>Tunazzina Islam, Dan Goldwasser</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY, cs.HC, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01991">https://arxiv.org/abs/2502.01991</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01991">https://arxiv.org/pdf/2502.01991</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01991]] Can LLMs Assist Annotators in Identifying Morality Frames? -- Case Study on Vaccination Debate on Social Media(https://arxiv.org/abs/2502.01991)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Nowadays, social media is pivotal in shaping public discourse, especially on polarizing issues like vaccination, where diverse moral perspectives influence individual opinions. In NLP, data scarcity and complexity of psycholinguistic tasks such as identifying morality frames makes relying solely on human annotators costly, time-consuming, and prone to inconsistency due to cognitive load. To address these issues, we leverage large language models (LLMs), which are adept at adapting new tasks through few-shot learning, utilizing a handful of in-context examples coupled with explanations that connect examples to task principles. Our research explores LLMs' potential to assist human annotators in identifying morality frames within vaccination debates on social media. We employ a two-step process: generating concepts and explanations with LLMs, followed by human evaluation using a "think-aloud" tool. Our study shows that integrating LLMs into the annotation process enhances accuracy, reduces task difficulty, lowers cognitive load, suggesting a promising avenue for human-AI collaboration in complex psycholinguistic tasks.</li>
</ul>

<h3>Title: One Diffusion Step to Real-World Super-Resolution via Flow Trajectory Distillation</h3>
<ul>
<li><strong>Authors: </strong>Jianze Li, Jiezhang Cao, Yong Guo, Wenbo Li, Yulun Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.01993">https://arxiv.org/abs/2502.01993</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.01993">https://arxiv.org/pdf/2502.01993</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.01993]] One Diffusion Step to Real-World Super-Resolution via Flow Trajectory Distillation(https://arxiv.org/abs/2502.01993)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion models (DMs) have significantly advanced the development of real-world image super-resolution (Real-ISR), but the computational cost of multi-step diffusion models limits their application. One-step diffusion models generate high-quality images in a one sampling step, greatly reducing computational overhead and inference latency. However, most existing one-step diffusion methods are constrained by the performance of the teacher model, where poor teacher performance results in image artifacts. To address this limitation, we propose FluxSR, a novel one-step diffusion Real-ISR technique based on flow matching models. We use the state-of-the-art diffusion model FLUX.1-dev as both the teacher model and the base model. First, we introduce Flow Trajectory Distillation (FTD) to distill a multi-step flow matching model into a one-step Real-ISR. Second, to improve image realism and address high-frequency artifact issues in generated images, we propose TV-LPIPS as a perceptual loss and introduce Attention Diversification Loss (ADL) as a regularization term to reduce token similarity in transformer, thereby eliminating high-frequency artifacts. Comprehensive experiments demonstrate that our method outperforms existing one-step diffusion-based Real-ISR methods. The code and model will be released at this https URL.</li>
</ul>

<h3>Title: Reasoning Bias of Next Token Prediction Training</h3>
<ul>
<li><strong>Authors: </strong>Pengxiao Lin, Zhongwang Zhang, Zhi-Qin John Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02007">https://arxiv.org/abs/2502.02007</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02007">https://arxiv.org/pdf/2502.02007</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02007]] Reasoning Bias of Next Token Prediction Training(https://arxiv.org/abs/2502.02007)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Since the inception of Large Language Models (LLMs), the quest to efficiently train them for superior reasoning capabilities has been a pivotal challenge. The dominant training paradigm for LLMs is based on next token prediction (NTP). Alternative methodologies, called Critical Token Prediction (CTP), focused exclusively on specific critical tokens (such as the answer in Q\&A dataset), aiming to reduce the overfitting of extraneous information and noise. Contrary to initial assumptions, our research reveals that despite NTP's exposure to noise during training, it surpasses CTP in reasoning ability. We attribute this counterintuitive outcome to the regularizing influence of noise on the training dynamics. Our empirical analysis shows that NTP-trained models exhibit enhanced generalization and robustness across various benchmark reasoning datasets, demonstrating greater resilience to perturbations and achieving flatter loss minima. These findings illuminate that NTP is instrumental in fostering reasoning abilities during pretraining, whereas CTP is more effective for finetuning, thereby enriching our comprehension of optimal training strategies in LLM development.</li>
</ul>

<h3>Title: Layer by Layer: Uncovering Hidden Representations in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Oscar Skean, Md Rifat Arefin, Dan Zhao, Niket Patel, Jalal Naghiyev, Yann LeCun, Ravid Shwartz-Ziv</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02013">https://arxiv.org/abs/2502.02013</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02013">https://arxiv.org/pdf/2502.02013</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02013]] Layer by Layer: Uncovering Hidden Representations in Language Models(https://arxiv.org/abs/2502.02013)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, large language model</a></li>
<li><strong>Abstract: </strong>From extracting features to generating text, the outputs of large language models (LLMs) typically rely on their final layers, following the conventional wisdom that earlier layers capture only low-level cues. However, our analysis shows that intermediate layers can encode even richer representations, often improving performance on a wide range of downstream tasks. To explain and quantify these hidden-layer properties, we propose a unified framework of representation quality metrics based on information theory, geometry, and invariance to input perturbations. Our framework highlights how each model layer balances information compression and signal preservation, revealing why mid-depth embeddings can exceed the last layer's performance. Through extensive experiments on 32 text-embedding tasks and comparisons across model architectures (transformers, state-space models) and domains (language, vision), we demonstrate that intermediate layers consistently provide stronger features. These findings challenge the standard focus on final-layer embeddings and open new directions for model analysis and optimization, including strategic use of mid-layer representations for more robust and accurate AI systems.</li>
</ul>

<h3>Title: Analytical Lyapunov Function Discovery: An RL-based Generative Approach</h3>
<ul>
<li><strong>Authors: </strong>Haohan Zou, Jie Feng, Hao Zhao, Yuanyuan Shi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.SC, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02014">https://arxiv.org/abs/2502.02014</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02014">https://arxiv.org/pdf/2502.02014</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02014]] Analytical Lyapunov Function Discovery: An RL-based Generative Approach(https://arxiv.org/abs/2502.02014)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer, generative</a></li>
<li><strong>Abstract: </strong>Despite advances in learning-based methods, finding valid Lyapunov functions for nonlinear dynamical systems remains challenging. Current neural network approaches face two main issues: challenges in scalable verification and limited interpretability. To address these, we propose an end-to-end framework using transformers to construct analytical Lyapunov functions (local), which simplifies formal verification, enhances interpretability, and provides valuable insights for control engineers. Our framework consists of a transformer-based trainer that generates candidate Lyapunov functions and a falsifier that verifies candidate expressions and refines the model via risk-seeking policy gradient. Unlike Alfarano et al. (2024), which utilizes pre-training and seeks global Lyapunov functions for low-dimensional systems, our model is trained from scratch via reinforcement learning (RL) and succeeds in finding local Lyapunov functions for high-dimensional and non-polynomial systems. Given the analytical nature of the candidates, we employ efficient optimization methods for falsification during training and formal verification tools for the final verification. We demonstrate the efficiency of our approach on a range of nonlinear dynamical systems with up to ten dimensions and show that it can discover Lyapunov functions not previously identified in the control literature.</li>
</ul>

<h3>Title: A Periodic Bayesian Flow for Material Generation</h3>
<ul>
<li><strong>Authors: </strong>Hanlin Wu, Yuxuan Song, Jingjing Gong, Ziyao Cao, Yawen Ouyang, Jianbing Zhang, Hao Zhou, Wei-Ying Ma, Jingjing Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02016">https://arxiv.org/abs/2502.02016</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02016">https://arxiv.org/pdf/2502.02016</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02016]] A Periodic Bayesian Flow for Material Generation(https://arxiv.org/abs/2502.02016)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Generative modeling of crystal data distribution is an important yet challenging task due to the unique periodic physical symmetry of crystals. Diffusion-based methods have shown early promise in modeling crystal distribution. More recently, Bayesian Flow Networks were introduced to aggregate noisy latent variables, resulting in a variance-reduced parameter space that has been shown to be advantageous for modeling Euclidean data distributions with structural constraints (Song et al., 2023). Inspired by this, we seek to unlock its potential for modeling variables located in non-Euclidean manifolds e.g. those within crystal structures, by overcoming challenging theoretical issues. We introduce CrysBFN, a novel crystal generation method by proposing a periodic Bayesian flow, which essentially differs from the original Gaussian-based BFN by exhibiting non-monotonic entropy dynamics. To successfully realize the concept of periodic Bayesian flow, CrysBFN integrates a new entropy conditioning mechanism and empirically demonstrates its significance compared to time-conditioning. Extensive experiments over both crystal ab initio generation and crystal structure prediction tasks demonstrate the superiority of CrysBFN, which consistently achieves new state-of-the-art on all benchmarks. Surprisingly, we found that CrysBFN enjoys a significant improvement in sampling efficiency, e.g., ~100x speedup 10 v.s. 2000 steps network forwards) compared with previous diffusion-based methods on MP-20 dataset. Code is available at this https URL.</li>
</ul>

<h3>Title: ContinuouSP: Generative Model for Crystal Structure Prediction with Invariance and Continuity</h3>
<ul>
<li><strong>Authors: </strong>Yuji Tone, Masatoshi Hanai, Mitsuaki Kawamura, Kenjiro Taura, Toyotaro Suzumura</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02026">https://arxiv.org/abs/2502.02026</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02026">https://arxiv.org/pdf/2502.02026</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02026]] ContinuouSP: Generative Model for Crystal Structure Prediction with Invariance and Continuity(https://arxiv.org/abs/2502.02026)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The discovery of new materials using crystal structure prediction (CSP) based on generative machine learning models has become a significant research topic in recent years. In this paper, we study invariance and continuity in the generative machine learning for CSP. We propose a new model, called ContinuouSP, which effectively handles symmetry and periodicity in crystals. We clearly formulate the invariance and the continuity, and construct a model based on the energy-based model. Our preliminary evaluation demonstrates the effectiveness of this model with the CSP task.</li>
</ul>

<h3>Title: Fine-tuning Language Models for Recipe Generation: A Comparative Analysis and Benchmark Study</h3>
<ul>
<li><strong>Authors: </strong>Anneketh Vij, Changhao Liu, Rahul Anil Nair, Theo Ho, Edward Shi, Ayan Bhowmick</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02028">https://arxiv.org/abs/2502.02028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02028">https://arxiv.org/pdf/2502.02028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02028]] Fine-tuning Language Models for Recipe Generation: A Comparative Analysis and Benchmark Study(https://arxiv.org/abs/2502.02028)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This research presents an exploration and study of the recipe generation task by fine-tuning various very small language models, with a focus on developing robust evaluation metrics and comparing across different language models the open-ended task of recipe generation. This study presents extensive experiments with multiple model architectures, ranging from T5-small (Raffel et al., 2023) and SmolLM-135M (Allal et al., 2024) to Phi-2 (Research, 2023),implementing both traditional NLP metrics and custom domain-specific evaluation metrics. Our novel evaluation framework incorporates recipe-specific metrics for assessing content quality and introduces an approach to allergen substitution. The results indicate that, while larger models generally perform better on standard metrics, the relationship between model size and recipe quality is more nuanced when considering domain-specific metrics. We find that SmolLM-360M and SmolLM-1.7B demonstrate comparable performance despite their size difference, while Phi-2 shows limitations in recipe generation despite its larger parameter count. Our comprehensive evaluation framework and allergen substitution system provide valuable insights for future work in recipe generation and broader NLG tasks that require domain expertise and safety considerations.</li>
</ul>

<h3>Title: MORPH-LER: Log-Euclidean Regularization for Population-Aware Image Registration</h3>
<ul>
<li><strong>Authors: </strong>Mokshagna Sai Teja Karanam, Krithika Iyer, Sarang Joshi, Shireen Elhabian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02029">https://arxiv.org/abs/2502.02029</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02029">https://arxiv.org/pdf/2502.02029</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02029]] MORPH-LER: Log-Euclidean Regularization for Population-Aware Image Registration(https://arxiv.org/abs/2502.02029)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Spatial transformations that capture population-level morphological statistics are critical for medical image analysis. Commonly used smoothness regularizers for image registration fail to integrate population statistics, leading to anatomically inconsistent transformations. Inverse consistency regularizers promote geometric consistency but lack population morphometrics integration. Regularizers that constrain deformation to low-dimensional manifold methods address this. However, they prioritize reconstruction over interpretability and neglect diffeomorphic properties, such as group composition and inverse consistency. We introduce MORPH-LER, a Log-Euclidean regularization framework for population-aware unsupervised image registration. MORPH-LER learns population morphometrics from spatial transformations to guide and regularize registration networks, ensuring anatomically plausible deformations. It features a bottleneck autoencoder that computes the principal logarithm of deformation fields via iterative square-root predictions. It creates a linearized latent space that respects diffeomorphic properties and enforces inverse consistency. By integrating a registration network with a diffeomorphic autoencoder, MORPH-LER produces smooth, meaningful deformation fields. The framework offers two main contributions: (1) a data-driven regularization strategy that incorporates population-level anatomical statistics to enhance transformation validity and (2) a linearized latent space that enables compact and interpretable deformation fields for efficient population morphometrics analysis. We validate MORPH-LER across two families of deep learning-based registration networks, demonstrating its ability to produce anatomically accurate, computationally efficient, and statistically meaningful transformations on the OASIS-1 brain imaging dataset.</li>
</ul>

<h3>Title: SMTFL: Secure Model Training to Untrusted Participants in Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Zhihui Zhao, Xiaorong Dong, Yimo Ren, Jianhua Wang, Dan Yu, Hongsong Zhu, Yongle Chen</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.DC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02038">https://arxiv.org/abs/2502.02038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02038">https://arxiv.org/pdf/2502.02038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02038]] SMTFL: Secure Model Training to Untrusted Participants in Federated Learning(https://arxiv.org/abs/2502.02038)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, privacy, attack, federate</a></li>
<li><strong>Abstract: </strong>Federated learning is an essential distributed model training technique. However, threats such as gradient inversion attacks and poisoning attacks pose significant risks to the privacy of training data and the model correctness. We propose a novel approach called SMTFL to achieve secure model training in federated learning without relying on trusted participants. To safeguard gradients privacy against gradient inversion attacks, clients are dynamically grouped, allowing one client's gradient to be divided to obfuscate the gradients of other clients within the group. This method incorporates checks and balances to reduce the collusion for inferring specific client data. To detect poisoning attacks from malicious clients, we assess the impact of aggregated gradients on the global model's performance, enabling effective identification and exclusion of malicious clients. Each client's gradients are encrypted and stored, with decryption collectively managed by all clients. The detected poisoning gradients are invalidated from the global model through a unlearning method. To our best knowledge, we present the first practical secure aggregation scheme, which does not require trusted participants, avoids the performance degradation associated with traditional noise-injection, and aviods complex cryptographic operations during gradient aggregation. Evaluation results are encouraging based on four datasets and two models: SMTFL is effective against poisoning attacks and gradient inversion attacks, achieving an accuracy rate of over 95% in locating malicious clients, while keeping the false positive rate for honest clients within 5%. The model accuracy is also nearly restored to its pre-attack state when SMTFL is deployed.</li>
</ul>

<h3>Title: M2R2: Mixture of Multi-Rate Residuals for Efficient Transformer Inference</h3>
<ul>
<li><strong>Authors: </strong>Nikhil Bhendawade, Mahyar Najibi, Devang Naik, Irina Belousova</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02040">https://arxiv.org/abs/2502.02040</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02040">https://arxiv.org/pdf/2502.02040</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02040]] M2R2: Mixture of Multi-Rate Residuals for Efficient Transformer Inference(https://arxiv.org/abs/2502.02040)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Residual transformations enhance the representational depth and expressive power of large language models (LLMs). However, applying static residual transformations across all tokens in auto-regressive generation leads to a suboptimal trade-off between inference efficiency and generation fidelity. Existing methods, including Early Exiting, Skip Decoding, and Mixture-of-Depth address this by modulating the residual transformation based on token-level complexity. Nevertheless, these approaches predominantly consider the distance traversed by tokens through the model layers, neglecting the underlying velocity of residual evolution. We introduce Mixture of Multi-rate Residuals (M2R2), a framework that dynamically modulates residual velocity to improve early alignment, enhancing inference efficiency. Evaluations on reasoning oriented tasks such as Koala, Self-Instruct, WizardLM, and MT-Bench show M2R2 surpasses state-of-the-art distance-based strategies, balancing generation quality and speedup. In self-speculative decoding setup, M2R2 achieves up to 2.8x speedups on MT-Bench, outperforming methods like 2-model speculative decoding, Medusa, LookAhead Decoding, and DEED. In Mixture-of-Experts (MoE) architectures, integrating early residual alignment with ahead-of-time expert loading into high-bandwidth memory (HBM) accelerates decoding, reduces expert-switching bottlenecks, and achieves a 2.9x speedup, making it highly effective in resource-constrained environments.</li>
</ul>

<h3>Title: Contextual Memory Reweaving in Large Language Models Using Layered Latent State Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Frederick Dillon, Gregor Halvorsen, Simon Tattershall, Magnus Rowntree, Gareth Vanderpool</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02046">https://arxiv.org/abs/2502.02046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02046">https://arxiv.org/pdf/2502.02046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02046]] Contextual Memory Reweaving in Large Language Models Using Layered Latent State Reconstruction(https://arxiv.org/abs/2502.02046)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Memory retention challenges in deep neural architectures have ongoing limitations in the ability to process and recall extended contextual information. Token dependencies degrade as sequence length increases, leading to a decline in coherence and factual consistency across longer outputs. A structured approach is introduced to mitigate this issue through the reweaving of latent states captured at different processing layers, reinforcing token representations over extended sequences. The proposed Contextual Memory Reweaving framework incorporates a Layered Latent State Reconstruction mechanism to systematically integrate past contextual embeddings without introducing external memory modules. Experimental results demonstrate improvements in recall accuracy across a range of sequence lengths, with notable gains in the retention of rarely occurring tokens and numerical reasoning consistency. Further analysis of computational efficiency indicates that the additional processing overhead remains within acceptable thresholds, enabling scalability across different model sizes. Evaluations in long-form text generation and ambiguous query resolution highlight the capacity of memory reweaving to enhance continuity and reduce inconsistencies over extended outputs. Attention weight distributions reveal more structured allocation patterns, suggesting that reweaved latent states contribute to improved contextual awareness. The findings establish a framework for refining memory retention mechanisms in language models, addressing long-standing challenges in handling complex, multi-step reasoning tasks.</li>
</ul>

<h3>Title: Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning</h3>
<ul>
<li><strong>Authors: </strong>Georgios Margaritis, Periklis Petridis, Dimitris J. Bertsimas</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02048">https://arxiv.org/abs/2502.02048</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02048">https://arxiv.org/pdf/2502.02048</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02048]] Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning(https://arxiv.org/abs/2502.02048)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning (ML), natural language processing (NLP), and foundational models have shown promise for real-life applications in critical, albeit compute-constrainted fields like healthcare. In such areas, combining foundational models with supervised ML offers potential for automating tasks like diagnosis and treatment planning, but the limited availability of onsite computational resources pose significant challenges before applying these technologies effectively: Current approaches either yield subpar results when using pretrained models without task-specific adaptation, or require substantial computational resources for fine-tuning, which is often a barrier to entry in such environments. This renders them inaccessible in applications where performance and quality standards are high, but computational resources are scarce. To bridge the gap between best-in-class performance and accessibility, we propose a novel method for adapting foundational, multimodal embeddings to downstream tasks, without the need of expensive fine-tuning processes. Our method leverages frozen embeddings from Large Language Models (LLMs) and Vision Models, and uses contrastive learning to train a small, task-specific nonlinear projection that can be used in the downstream task, without having to fine-tune the original foundational models. We show that this efficient procedure leads to significant performance improvements across various downstream tasks, and perhaps more importantly with minimal computational overhead, offering a practical solution for the use of advanced, foundational ML models in resource-constrained settings.</li>
</ul>

<h3>Title: CASIM: Composite Aware Semantic Injection for Text to Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Che-Jui Chang, Qingze Tony Liu, Honglu Zhou, Vladimir Pavlovic, Mubbasir Kapadia</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02063">https://arxiv.org/abs/2502.02063</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02063">https://arxiv.org/pdf/2502.02063</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02063]] CASIM: Composite Aware Semantic Injection for Text to Motion Generation(https://arxiv.org/abs/2502.02063)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in generative modeling and tokenization have driven significant progress in text-to-motion generation, leading to enhanced quality and realism in generated motions. However, effectively leveraging textual information for conditional motion generation remains an open challenge. We observe that current approaches, primarily relying on fixed-length text embeddings (e.g., CLIP) for global semantic injection, struggle to capture the composite nature of human motion, resulting in suboptimal motion quality and controllability. To address this limitation, we propose the Composite Aware Semantic Injection Mechanism (CASIM), comprising a composite-aware semantic encoder and a text-motion aligner that learns the dynamic correspondence between text and motion tokens. Notably, CASIM is model and representation-agnostic, readily integrating with both autoregressive and diffusion-based methods. Experiments on HumanML3D and KIT benchmarks demonstrate that CASIM consistently improves motion quality, text-motion alignment, and retrieval scores across state-of-the-art methods. Qualitative analyses further highlight the superiority of our composite-aware approach over fixed-length semantic injection, enabling precise motion control from text prompts and stronger generalization to unseen text inputs.</li>
</ul>

<h3>Title: Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign</h3>
<ul>
<li><strong>Authors: </strong>Ruisi Zhang, Neusha Javidnia, Nojan Sheybani, Farinaz Koushanfar</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02068">https://arxiv.org/abs/2502.02068</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02068">https://arxiv.org/pdf/2502.02068</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02068]] Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign(https://arxiv.org/abs/2502.02068)</code><input type="text"></li>
<li><strong>Keywords: </strong>secure, attack, robust, extraction, watermark, large language model</a></li>
<li><strong>Abstract: </strong>This paper introduces RoSe, the first-of-its-kind ML/Crypto codesign watermarking framework that regulates LLM-generated code to avoid intellectual property rights violations and inappropriate misuse in software development. High-quality watermarks adhering to the detectability-fidelity-robustness tri-objective are limited due to codes' low-entropy nature. Watermark verification, however, often needs to reveal the signature and requires re-encoding new ones for code reuse, which potentially compromising the system's usability. To overcome these challenges, RoSe obtains high-quality watermarks by training the watermark insertion and extraction modules end-to-end to ensure (i) unaltered watermarked code functionality and (ii) enhanced detectability and robustness leveraging pre-trained CodeT5 as the insertion backbone to enlarge the code syntactic and variable rename transformation search space. In the deployment, RoSe uses zero-knowledge proofs for secure verification without revealing the underlying signatures. Extensive evaluations demonstrated RoSe achieves high detection accuracy while preserving the code functionality. RoSe is also robust against attacks and provides efficient secure watermark verification.</li>
</ul>

<h3>Title: LoRA-TTT: Low-Rank Test-Time Training for Vision-Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yuto Kojima, Jiarui Xu, Xueyan Zou, Xiaolong Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02069">https://arxiv.org/abs/2502.02069</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02069">https://arxiv.org/pdf/2502.02069</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02069]] LoRA-TTT: Low-Rank Test-Time Training for Vision-Language Models(https://arxiv.org/abs/2502.02069)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The rapid advancements in vision-language models (VLMs), such as CLIP, have intensified the need to address distribution shifts between training and testing datasets. Although prior Test-Time Training (TTT) techniques for VLMs have demonstrated robust performance, they predominantly rely on tuning text prompts, a process that demands substantial computational resources and is heavily dependent on entropy-based loss. In this paper, we propose LoRA-TTT, a novel TTT method that leverages Low-Rank Adaptation (LoRA), applied exclusively to the image encoder of VLMs. By introducing LoRA and updating only its parameters during test time, our method offers a simple yet effective TTT approach, retaining the model's initial generalization capability while achieving substantial performance gains with minimal memory and runtime overhead. Additionally, we introduce a highly efficient reconstruction loss tailored for TTT. Our method can adapt to diverse domains by combining these two losses, without increasing memory consumption or runtime. Extensive experiments on two benchmarks, covering 15 datasets, demonstrate that our method improves the zero-shot top-1 accuracy of CLIP-ViT-B/16 by an average of 5.79% on the OOD benchmark and 1.36% on the fine-grained benchmark, efficiently surpassing test-time prompt tuning, without relying on any external models or cache.</li>
</ul>

<h3>Title: ASCenD-BDS: Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping</h3>
<ul>
<li><strong>Authors: </strong>Rajiv Bahl, Venkatesan N, Parimal Aglawe, Aastha Sarasapalli, Bhavya Kancharla, Chaitanya kolukuluri, Harish Mohite, Japneet Hora, Kiran Kakollu, Rahul Diman, Shubham Kapale, Sri Bhagya Kathula, Vamsikrishna Motru, Yogeshwar Reddy</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02072">https://arxiv.org/abs/2502.02072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02072">https://arxiv.org/pdf/2502.02072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02072]] ASCenD-BDS: Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping(https://arxiv.org/abs/2502.02072)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>The rapid evolution of Large Language Models (LLMs) has transformed natural language processing but raises critical concerns about biases inherent in their deployment and use across diverse linguistic and sociocultural contexts. This paper presents a framework named ASCenD BDS (Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping). The framework presents approach to detecting bias, discrimination, stereotyping across various categories such as gender, caste, age, disability, socioeconomic status, linguistic variations, etc., using an approach which is Adaptive, Stochastic and Context-Aware. The existing frameworks rely heavily on usage of datasets to generate scenarios for detection of Bias, Discrimination and Stereotyping. Examples include datasets such as Civil Comments, Wino Gender, WinoBias, BOLD, CrowS Pairs and BBQ. However, such an approach provides point solutions. As a result, these datasets provide a finite number of scenarios for assessment. The current framework overcomes this limitation by having features which enable Adaptability, Stochasticity, Context Awareness. Context awareness can be customized for any nation or culture or sub-culture (for example an organization's unique culture). In this paper, context awareness in the Indian context has been established. Content has been leveraged from Indian Census 2011 to have a commonality of categorization. A framework has been developed using Category, Sub-Category, STEM, X-Factor, Synonym to enable the features for Adaptability, Stochasticity and Context awareness. The framework has been described in detail in Section 3. Overall 800 plus STEMs, 10 Categories, 31 unique SubCategories were developed by a team of consultants at Saint Fox Consultancy Private Ltd. The concept has been tested out in SFCLabs as part of product development.</li>
</ul>

<h3>Title: Rethinking stance detection: A theoretically-informed research agenda for user-level inference using language models</h3>
<ul>
<li><strong>Authors: </strong>Prasanta Bhattacharya, Hong Zhang, Yiming Cao, Wei Gao, Brandon Siyuan Loh, Joseph J.P. Simons, Liang Ze Wong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02074">https://arxiv.org/abs/2502.02074</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02074">https://arxiv.org/pdf/2502.02074</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02074]] Rethinking stance detection: A theoretically-informed research agenda for user-level inference using language models(https://arxiv.org/abs/2502.02074)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Stance detection has emerged as a popular task in natural language processing research, enabled largely by the abundance of target-specific social media data. While there has been considerable research on the development of stance detection models, datasets, and application, we highlight important gaps pertaining to (i) a lack of theoretical conceptualization of stance, and (ii) the treatment of stance at an individual- or user-level, as opposed to message-level. In this paper, we first review the interdisciplinary origins of stance as an individual-level construct to highlight relevant attributes (e.g., psychological features) that might be useful to incorporate in stance detection models. Further, we argue that recent pre-trained and large language models (LLMs) might offer a way to flexibly infer such user-level attributes and/or incorporate them in modelling stance. To better illustrate this, we briefly review and synthesize the emerging corpus of studies on using LLMs for inferring stance, and specifically on incorporating user attributes in such tasks. We conclude by proposing a four-point agenda for pursuing stance detection research that is theoretically informed, inclusive, and practically impactful.</li>
</ul>

<h3>Title: Position Paper: Building Trust in Synthetic Data for Clinical AI</h3>
<ul>
<li><strong>Authors: </strong>Krishan Agyakari Raja Babu, Supriti Mulay, Om Prabhu, Mohanasankar Sivaprakasam</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02076">https://arxiv.org/abs/2502.02076</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02076">https://arxiv.org/pdf/2502.02076</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02076]] Position Paper: Building Trust in Synthetic Data for Clinical AI(https://arxiv.org/abs/2502.02076)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, generative, segmentation</a></li>
<li><strong>Abstract: </strong>Deep generative models and synthetic medical data have shown significant promise in addressing key challenges in healthcare, such as privacy concerns, data bias, and the scarcity of realistic datasets. While research in this area has grown rapidly and demonstrated substantial theoretical potential, its practical adoption in clinical settings remains limited. Despite the benefits synthetic data offers, questions surrounding its reliability and credibility persist, leading to a lack of trust among clinicians. This position paper argues that fostering trust in synthetic medical data is crucial for its clinical adoption. It aims to spark a discussion on the viability of synthetic medical data in clinical practice, particularly in the context of current advancements in AI. We present empirical evidence from brain tumor segmentation to demonstrate that the quality, diversity, and proportion of synthetic data directly impact trust in clinical AI models. Our findings provide insights to improve the deployment and acceptance of synthetic data-driven AI systems in real-world clinical workflows.</li>
</ul>

<h3>Title: Improving Power Plant CO2 Emission Estimation with Deep Learning and Satellite/Simulated Data</h3>
<ul>
<li><strong>Authors: </strong>Dibyabha Deb, Kamal Das</a></li>
<li><strong>Subjects: </strong>cs.CV, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02083">https://arxiv.org/abs/2502.02083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02083">https://arxiv.org/pdf/2502.02083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02083]] Improving Power Plant CO2 Emission Estimation with Deep Learning and Satellite/Simulated Data(https://arxiv.org/abs/2502.02083)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect</a></li>
<li><strong>Abstract: </strong>CO2 emissions from power plants, as significant super emitters, contribute substantially to global warming. Accurate quantification of these emissions is crucial for effective climate mitigation strategies. While satellite-based plume inversion offers a promising approach, challenges arise from data limitations and the complexity of atmospheric conditions. This study addresses these challenges by (a) expanding the available dataset through the integration of NO2 data from Sentinel-5P, generating continuous XCO2 maps, and incorporating real satellite observations from OCO-2/3 for over 71 power plants in data-scarce regions; and (b) employing a customized U-Net model capable of handling diverse spatio-temporal resolutions for emission rate estimation. Our results demonstrate significant improvements in emission rate accuracy compared to previous methods. By leveraging this enhanced approach, we can enable near real-time, precise quantification of major CO2 emission sources, supporting environmental protection initiatives and informing regulatory frameworks.</li>
</ul>

<h3>Title: IPO: Iterative Preference Optimization for Text-to-Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Xiaomeng Yang, Zhiyu Tan, Xuecheng Nie, Hao Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02088">https://arxiv.org/abs/2502.02088</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02088">https://arxiv.org/pdf/2502.02088</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02088]] IPO: Iterative Preference Optimization for Text-to-Video Generation(https://arxiv.org/abs/2502.02088)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Video foundation models have achieved significant advancement with the help of network upgrade as well as model scale-up. However, they are still hard to meet requirements of applications due to unsatisfied generation quality. To solve this problem, we propose to align video foundation models with human preferences from the perspective of post-training in this paper. Consequently, we introduce an Iterative Preference Optimization strategy to enhance generated video quality by incorporating human feedback. Specifically, IPO exploits a critic model to justify video generations for pairwise ranking as in Direct Preference Optimization or point-wise scoring as in Kahneman-Tversky Optimization. Given this, IPO optimizes video foundation models with guidance of signals from preference feedback, which helps improve generated video quality in subject consistency, motion smoothness and aesthetic quality, etc. In addition, IPO incorporates the critic model with the multi-modality large language model, which enables it to automatically assign preference labels without need of retraining or relabeling. In this way, IPO can efficiently perform multi-round preference optimization in an iterative manner, without the need of tediously manual labeling. Comprehensive experiments demonstrate that the proposed IPO can effectively improve the video generation quality of a pretrained model and help a model with only 2B parameters surpass the one with 5B parameters. Besides, IPO achieves new state-of-the-art performance on VBench benchmark. We will release our source codes, models as well as dataset to advance future research and applications.</li>
</ul>

<h3>Title: Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization</h3>
<ul>
<li><strong>Authors: </strong>Yixiao Chen, Shikun Sun, Jianshu Li, Ruoyu Li, Zhe Li, Junliang Xing</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02096">https://arxiv.org/abs/2502.02096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02096">https://arxiv.org/pdf/2502.02096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02096]] Dual-Flow: Transferable Multi-Target, Instance-Agnostic Attacks via In-the-wild Cascading Flow Optimization(https://arxiv.org/abs/2502.02096)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack, robust, generative</a></li>
<li><strong>Abstract: </strong>Adversarial attacks are widely used to evaluate model robustness, and in black-box scenarios, the transferability of these attacks becomes crucial. Existing generator-based attacks have excellent generalization and transferability due to their instance-agnostic nature. However, when training generators for multi-target tasks, the success rate of transfer attacks is relatively low due to the limitations of the model's capacity. To address these challenges, we propose a novel Dual-Flow framework for multi-target instance-agnostic adversarial attacks, utilizing Cascading Distribution Shift Training to develop an adversarial velocity function. Extensive experiments demonstrate that Dual-Flow significantly improves transferability over previous multi-target generative attacks. For example, it increases the success rate from Inception-v3 to ResNet-152 by 34.58%. Furthermore, our attack method, such as adversarially trained models, shows substantially stronger robustness against defense mechanisms.</li>
</ul>

<h3>Title: VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images</h3>
<ul>
<li><strong>Authors: </strong>Zaid Ilyas, Arooba Maqsood, Afsah Saleem, Erchuan Zhang, David Suter, Parminder Raina, Jonathan M. Hodgson, John T. Schousboe, William D. Leslie, Joshua R. Lewis, Syed Zulqarnain Gilani</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02097">https://arxiv.org/abs/2502.02097</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02097">https://arxiv.org/pdf/2502.02097</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02097]] VerteNet -- A Multi-Context Hybrid CNN Transformer for Accurate Vertebral Landmark Localization in Lateral Spine DXA Images(https://arxiv.org/abs/2502.02097)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Lateral Spine Image (LSI) analysis is important for medical diagnosis, treatment planning, and detailed spinal health assessments. Although modalities like Computed Tomography and Digital X-ray Imaging are commonly used, Dual Energy X-ray Absorptiometry (DXA) is often preferred due to lower radiation exposure, seamless capture, and cost-effectiveness. Accurate Vertebral Landmark Localization (VLL) on LSIs is important to detect spinal conditions like kyphosis and lordosis, as well as assessing Abdominal Aortic Calcification (AAC) using Inter-Vertebral Guides (IVGs). Nonetheless, few automated VLL methodologies have concentrated on DXA LSIs. We present VerteNet, a hybrid CNN-Transformer model featuring a novel dual-resolution attention mechanism in self and cross-attention domains, referred to as Dual Resolution Self-Attention (DRSA) and Dual Resolution Cross-Attention (DRCA). These mechanisms capture the diverse frequencies in DXA images by operating at two different feature map resolutions. Additionally, we design a Multi-Context Feature Fusion Block (MCFB) that efficiently integrates the features using DRSA and DRCA. We train VerteNet on 620 DXA LSIs from various machines and achieve superior results compared to existing methods. We also design an algorithm that utilizes VerteNet's predictions in estimating the Region of Interest (ROI) to detect potential abdominal aorta cropping, where inadequate soft tissue hinders calcification assessment. Additionally, we present a small proof-of-concept study to show that IVGs generated from VLL information can improve inter-reader correlation in AAC scoring, addressing two key areas of disagreement in expert AAC-24 scoring: IVG placement and quality control for full abdominal aorta assessment. The code for this work can be found at this https URL.</li>
</ul>

<h3>Title: Concept-Aware Latent and Explicit Knowledge Integration for Enhanced Cognitive Diagnosis</h3>
<ul>
<li><strong>Authors: </strong>Yawen Chen, Jiande Sun, Jing Li, Huaxiang Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02104">https://arxiv.org/abs/2502.02104</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02104">https://arxiv.org/pdf/2502.02104</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02104]] Concept-Aware Latent and Explicit Knowledge Integration for Enhanced Cognitive Diagnosis(https://arxiv.org/abs/2502.02104)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Cognitive diagnosis can infer the students' mastery of specific knowledge concepts based on historical response logs. However, the existing cognitive diagnostic models (CDMs) represent students' proficiency via a unidimensional perspective, which can't assess the students' mastery on each knowledge concept comprehensively. Moreover, the Q-matrix binarizes the relationship between exercises and knowledge concepts, and it can't represent the latent relationship between exercises and knowledge concepts. Especially, when the granularity of knowledge attributes refines increasingly, the Q-matrix becomes incomplete correspondingly and the sparse binary representation (0/1) fails to capture the intricate relationships among knowledge concepts. To address these issues, we propose a Concept-aware Latent and Explicit Knowledge Integration model for cognitive diagnosis (CLEKI-CD). Specifically, a multidimensional vector is constructed according to the students' mastery and exercise difficulty for each knowledge concept from multiple perspectives, which enhances the representation capabilities of the model. Moreover, a latent Q-matrix is generated by our proposed attention-based knowledge aggregation method, and it can uncover the coverage degree of exercises over latent knowledge. The latent Q-matrix can supplement the sparse explicit Q-matrix with the inherent relationships among knowledge concepts, and mitigate the knowledge coverage problem. Furthermore, we employ a combined cognitive diagnosis layer to integrate both latent and explicit knowledge, further enhancing cognitive diagnosis performance. Extensive experiments on real-world datasets demonstrate that CLEKI-CD outperforms the state-of-the-art models. The proposed CLEKI-CD is promising in practical applications in the field of intelligent education, as it exhibits good interpretability with diagnostic results.</li>
</ul>

<h3>Title: Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care</h3>
<ul>
<li><strong>Authors: </strong>Yuxiao Cheng, Xinxin Song, Ziqian Wang, Qin Zhong, Kunlun He, Jinli Suo</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02109">https://arxiv.org/abs/2502.02109</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02109">https://arxiv.org/pdf/2502.02109</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02109]] Causally-informed Deep Learning towards Explainable and Generalizable Outcomes Prediction in Critical Care(https://arxiv.org/abs/2502.02109)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>Recent advances in deep learning (DL) have prompted the development of high-performing early warning score (EWS) systems, predicting clinical deteriorations such as acute kidney injury, acute myocardial infarction, or circulatory failure. DL models have proven to be powerful tools for various tasks but come with the cost of lacking interpretability and limited generalizability, hindering their clinical applications. To develop a practical EWS system applicable to various outcomes, we propose causally-informed explainable early prediction model, which leverages causal discovery to identify the underlying causal relationships of prediction and thus owns two unique advantages: demonstrating the explicit interpretation of the prediction while exhibiting decent performance when applied to unfamiliar environments. Benefiting from these features, our approach achieves superior accuracy for 6 different critical deteriorations and achieves better generalizability across different patient groups, compared to various baseline algorithms. Besides, we provide explicit causal pathways to serve as references for assistant clinical diagnosis and potential interventions. The proposed approach enhances the practical application of deep learning in various medical scenarios.</li>
</ul>

<h3>Title: On the Guidance of Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Ruiqi Feng, Tailin Wu, Chenglei Yu, Wenhao Deng, Peiyan Hu</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02150">https://arxiv.org/abs/2502.02150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02150">https://arxiv.org/pdf/2502.02150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02150]] On the Guidance of Flow Matching(https://arxiv.org/abs/2502.02150)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Flow matching has shown state-of-the-art performance in various generative tasks, ranging from image generation to decision-making, where guided generation is pivotal. However, the guidance of flow matching is more general than and thus substantially different from that of its predecessor, diffusion models. Therefore, the challenge in guidance for general flow matching remains largely underexplored. In this paper, we propose the first framework of general guidance for flow matching. From this framework, we derive a family of guidance techniques that can be applied to general flow matching. These include a new training-free asymptotically exact guidance, novel training losses for training-based guidance, and two classes of approximate guidance that cover classical gradient guidance methods as special cases. We theoretically investigate these different methods to give a practical guideline for choosing suitable methods in different scenarios. Experiments on synthetic datasets, image inverse problems, and offline reinforcement learning demonstrate the effectiveness of our proposed guidance methods and verify the correctness of our flow matching guidance framework. Code to reproduce the experiments can be found at this https URL.</li>
</ul>

<h3>Title: Progressive Correspondence Regenerator for Robust 3D Registration</h3>
<ul>
<li><strong>Authors: </strong>Guiyu Zhao, Sheng Ao, Ye Zhang, Kai Xu Yulan Guo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02163">https://arxiv.org/abs/2502.02163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02163">https://arxiv.org/pdf/2502.02163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02163]] Progressive Correspondence Regenerator for Robust 3D Registration(https://arxiv.org/abs/2502.02163)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Obtaining enough high-quality correspondences is crucial for robust registration. Existing correspondence refinement methods mostly follow the paradigm of outlier removal, which either fails to correctly identify the accurate correspondences under extreme outlier ratios, or select too few correct correspondences to support robust registration. To address this challenge, we propose a novel approach named Regor, which is a progressive correspondence regenerator that generates higher-quality matches whist sufficiently robust for numerous outliers. In each iteration, we first apply prior-guided local grouping and generalized mutual matching to generate the local region correspondences. A powerful center-aware three-point consistency is then presented to achieve local correspondence correction, instead of removal. Further, we employ global correspondence refinement to obtain accurate correspondences from a global perspective. Through progressive iterations, this process yields a large number of high-quality correspondences. Extensive experiments on both indoor and outdoor datasets demonstrate that the proposed Regor significantly outperforms existing outlier removal techniques. More critically, our approach obtain 10 times more correct correspondences than outlier removal methods. As a result, our method is able to achieve robust registration even with weak features. The code will be released.</li>
</ul>

<h3>Title: Multilingual Attribute Extraction from News Web Pages</h3>
<ul>
<li><strong>Authors: </strong>Pavel Bedrin, Maksim Varlamov, Alexander Yatskov</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02167">https://arxiv.org/abs/2502.02167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02167">https://arxiv.org/pdf/2502.02167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02167]] Multilingual Attribute Extraction from News Web Pages(https://arxiv.org/abs/2502.02167)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction</a></li>
<li><strong>Abstract: </strong>This paper addresses the challenge of automatically extracting attributes from news article web pages across multiple languages. Recent neural network models have shown high efficacy in extracting information from semi-structured web pages. However, these models are predominantly applied to domains like e-commerce and are pre-trained using English data, complicating their application to web pages in other languages. We prepared a multilingual dataset comprising 3,172 marked-up news web pages across six languages (English, German, Russian, Chinese, Korean, and Arabic) from 161 websites. The dataset is publicly available on GitHub. We fine-tuned the pre-trained state-of-the-art model, MarkupLM, to extract news attributes from these pages and evaluated the impact of translating pages into English on extraction quality. Additionally, we pre-trained another state-of-the-art model, DOM-LM, on multilingual data and fine-tuned it on our dataset. We compared both fine-tuned models to existing open-source news data extraction tools, achieving superior extraction metrics.</li>
</ul>

<h3>Title: Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge</h3>
<ul>
<li><strong>Authors: </strong>Daniel Tamayo, Aitor Gonzalez-Agirre, Javier Hernando, Marta Villegas</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02173">https://arxiv.org/abs/2502.02173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02173">https://arxiv.org/pdf/2502.02173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02173]] Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge(https://arxiv.org/abs/2502.02173)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>Recent research has explored methods for updating and modifying factual knowledge in large language models, often focusing on specific multi-layer perceptron blocks. This study expands on this work by examining the effectiveness of existing knowledge editing methods across languages and delving into the role of attention mechanisms in this process. Drawing from the insights gained, we propose Mass-Editing Memory with Attention in Transformers (MEMAT), a method that achieves significant improvements in all metrics while requiring minimal parameter modifications. MEMAT delivers a remarkable 10% increase in magnitude metrics, benefits languages not included in the training data and also demonstrates a high degree of portability. Our code and data are at this https URL.</li>
</ul>

<h3>Title: Sequence models for continuous cell cycle stage prediction from brightfield images</h3>
<ul>
<li><strong>Authors: </strong>Louis-Alexandre Leger, Maxine Leonardi, Andrea Salati, Felix Naef, Martin Weigert</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02182">https://arxiv.org/abs/2502.02182</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02182">https://arxiv.org/pdf/2502.02182</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02182]] Sequence models for continuous cell cycle stage prediction from brightfield images(https://arxiv.org/abs/2502.02182)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Understanding cell cycle dynamics is crucial for studying biological processes such as growth, development and disease progression. While fluorescent protein reporters like the Fucci system allow live monitoring of cell cycle phases, they require genetic engineering and occupy additional fluorescence channels, limiting broader applicability in complex experiments. In this study, we conduct a comprehensive evaluation of deep learning methods for predicting continuous Fucci signals using non-fluorescence brightfield imaging, a widely available label-free modality. To that end, we generated a large dataset of 1.3 M images of dividing RPE1 cells with full cell cycle trajectories to quantitatively compare the predictive performance of distinct model categories including single time-frame models, causal state space models and bidirectional transformer models. We show that both causal and transformer-based models significantly outperform single- and fixed frame approaches, enabling the prediction of visually imperceptible transitions like G1/S within 1h resolution. Our findings underscore the importance of sequence models for accurate predictions of cell cycle dynamics and highlight their potential for label-free imaging.</li>
</ul>

<h3>Title: Generative Kernel Spectral Clustering</h3>
<ul>
<li><strong>Authors: </strong>David Winant, Sonny Achten, Johan A. K. Suykens</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02185">https://arxiv.org/abs/2502.02185</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02185">https://arxiv.org/pdf/2502.02185</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02185]] Generative Kernel Spectral Clustering(https://arxiv.org/abs/2502.02185)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Modern clustering approaches often trade interpretability for performance, particularly in deep learning-based methods. We present Generative Kernel Spectral Clustering (GenKSC), a novel model combining kernel spectral clustering with generative modeling to produce both well-defined clusters and interpretable representations. By augmenting weighted variance maximization with reconstruction and clustering losses, our model creates an explorable latent space where cluster characteristics can be visualized through traversals along cluster directions. Results on MNIST and FashionMNIST datasets demonstrate the model's ability to learn meaningful cluster representations.</li>
</ul>

<h3>Title: ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Nissim Maruani, Wang Yifan, Matthew Fisher, Pierre Alliez, Mathieu Desbrun</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02187">https://arxiv.org/abs/2502.02187</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02187">https://arxiv.org/pdf/2502.02187</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02187]] ShapeShifter: 3D Variations Using Multiscale and Sparse Point-Voxel Diffusion(https://arxiv.org/abs/2502.02187)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>This paper proposes ShapeShifter, a new 3D generative model that learns to synthesize shape variations based on a single reference model. While generative methods for 3D objects have recently attracted much attention, current techniques often lack geometric details and/or require long training times and large resources. Our approach remedies these issues by combining sparse voxel grids and point, normal, and color sampling within a multiscale neural architecture that can be trained efficiently and in parallel. We show that our resulting variations better capture the fine details of their original input and can handle more general types of surfaces than previous SDF-based methods. Moreover, we offer interactive generation of 3D shape variants, allowing more human control in the design loop if needed.</li>
</ul>

<h3>Title: Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition</h3>
<ul>
<li><strong>Authors: </strong>Fei Wang, Kun Li, Yiqi Nie, Zhangling Duan, Peng Zou, Zhiliang Wu, Yuwei Wang, Yanyan Wei</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02196">https://arxiv.org/abs/2502.02196</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02196">https://arxiv.org/pdf/2502.02196</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02196]] Exploiting Ensemble Learning for Cross-View Isolated Sign Language Recognition(https://arxiv.org/abs/2502.02196)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>In this paper, we present our solution to the Cross-View Isolated Sign Language Recognition (CV-ISLR) challenge held at WWW 2025. CV-ISLR addresses a critical issue in traditional Isolated Sign Language Recognition (ISLR), where existing datasets predominantly capture sign language videos from a frontal perspective, while real-world camera angles often vary. To accurately recognize sign language from different viewpoints, models must be capable of understanding gestures from multiple angles, making cross-view recognition challenging. To address this, we explore the advantages of ensemble learning, which enhances model robustness and generalization across diverse views. Our approach, built on a multi-dimensional Video Swin Transformer model, leverages this ensemble strategy to achieve competitive performance. Finally, our solution ranked 3rd in both the RGB-based ISLR and RGB-D-based ISLR tracks, demonstrating the effectiveness in handling the challenges of cross-view recognition. The code is available at: this https URL.</li>
</ul>

<h3>Title: When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks</h3>
<ul>
<li><strong>Authors: </strong>Felix Drinkall, Janet B. Pierrehumbert, Stefan Zohren</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CE, cs.LG, q-fin.CP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02199">https://arxiv.org/abs/2502.02199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02199">https://arxiv.org/pdf/2502.02199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02199]] When Dimensionality Hurts: The Role of LLM Embedding Compression for Noisy Regression Tasks(https://arxiv.org/abs/2502.02199)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable success in language modelling due to scaling laws found in model size and the hidden dimension of the model's text representation. Yet, we demonstrate that compressed representations of text can yield better performance in LLM-based regression tasks. In this paper, we compare the relative performance of embedding compression in three different signal-to-noise contexts: financial return prediction, writing quality assessment and review scoring. Our results show that compressing embeddings, in a minimally supervised manner using an autoencoder's hidden representation, can mitigate overfitting and improve performance on noisy tasks, such as financial return prediction; but that compression reduces performance on tasks that have high causal dependencies between the input and target data. Our results suggest that the success of interpretable compressed representations such as sentiment may be due to a regularising effect.</li>
</ul>

<h3>Title: From Uncertain to Safe: Conformal Fine-Tuning of Diffusion Models for Safe PDE Control</h3>
<ul>
<li><strong>Authors: </strong>Peiyan Hu, Xiaowei Qian, Wenhao Deng, Rui Wang, Haodong Feng, Ruiqi Feng, Tao Zhang, Long Wei, Yue Wang, Zhi-Ming Ma, Tailin Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02205">https://arxiv.org/abs/2502.02205</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02205">https://arxiv.org/pdf/2502.02205</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02205]] From Uncertain to Safe: Conformal Fine-Tuning of Diffusion Models for Safe PDE Control(https://arxiv.org/abs/2502.02205)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>The application of deep learning for partial differential equation (PDE)-constrained control is gaining increasing attention. However, existing methods rarely consider safety requirements crucial in real-world applications. To address this limitation, we propose Safe Diffusion Models for PDE Control (SafeDiffCon), which introduce the uncertainty quantile as model uncertainty quantification to achieve optimal control under safety constraints through both post-training and inference phases. Firstly, our approach post-trains a pre-trained diffusion model to generate control sequences that better satisfy safety constraints while achieving improved control objectives via a reweighted diffusion loss, which incorporates the uncertainty quantile estimated using conformal prediction. Secondly, during inference, the diffusion model dynamically adjusts both its generation process and parameters through iterative guidance and fine-tuning, conditioned on control targets while simultaneously integrating the estimated uncertainty quantile. We evaluate SafeDiffCon on three control tasks: 1D Burgers' equation, 2D incompressible fluid, and controlled nuclear fusion problem. Results demonstrate that SafeDiffCon is the only method that satisfies all safety constraints, whereas other classical and deep learning baselines fail. Furthermore, while adhering to safety constraints, SafeDiffCon achieves the best control performance.</li>
</ul>

<h3>Title: On the Expressivity of Selective State-Space Layers: A Multivariate Polynomial Approach</h3>
<ul>
<li><strong>Authors: </strong>Edo Cohen-Karlik, Itamar Zimerman, Liane Galanti, Ido Atad, Amir Globerson, Lior Wolf</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02209">https://arxiv.org/abs/2502.02209</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02209">https://arxiv.org/pdf/2502.02209</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02209]] On the Expressivity of Selective State-Space Layers: A Multivariate Polynomial Approach(https://arxiv.org/abs/2502.02209)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Recent advances in efficient sequence modeling have introduced selective state-space layers, a key component of the Mamba architecture, which have demonstrated remarkable success in a wide range of NLP and vision tasks. While Mamba's empirical performance has matched or surpassed SoTA transformers on such diverse benchmarks, the theoretical foundations underlying its powerful representational capabilities remain less explored. In this work, we investigate the expressivity of selective state-space layers using multivariate polynomials, and prove that they surpass linear transformers in expressiveness. Consequently, our findings reveal that Mamba offers superior representational power over linear attention-based models for long sequences, while not sacrificing their generalization. Our theoretical insights are validated by a comprehensive set of empirical experiments on various datasets.</li>
</ul>

<h3>Title: InterLCM: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration</h3>
<ul>
<li><strong>Authors: </strong>Senmao Li, Kai Wang, Joost van de Weijer, Fahad Shahbaz Khan, Chun-Le Guo, Shiqi Yang, Yaxing Wang, Jian Yang, Ming-Ming Cheng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02215">https://arxiv.org/abs/2502.02215</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02215">https://arxiv.org/pdf/2502.02215</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02215]] InterLCM: Low-Quality Images as Intermediate States of Latent Consistency Models for Effective Blind Face Restoration(https://arxiv.org/abs/2502.02215)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion priors have been used for blind face restoration (BFR) by fine-tuning diffusion models (DMs) on restoration datasets to recover low-quality images. However, the naive application of DMs presents several key limitations. (i) The diffusion prior has inferior semantic consistency (e.g., ID, structure and color.), increasing the difficulty of optimizing the BFR model; (ii) reliance on hundreds of denoising iterations, preventing the effective cooperation with perceptual losses, which is crucial for faithful restoration. Observing that the latent consistency model (LCM) learns consistency noise-to-data mappings on the ODE-trajectory and therefore shows more semantic consistency in the subject identity, structural information and color preservation, we propose InterLCM to leverage the LCM for its superior semantic consistency and efficiency to counter the above issues. Treating low-quality images as the intermediate state of LCM, InterLCM achieves a balance between fidelity and quality by starting from earlier LCM steps. LCM also allows the integration of perceptual loss during training, leading to improved restoration quality, particularly in real-world scenarios. To mitigate structural and semantic uncertainties, InterLCM incorporates a Visual Module to extract visual features and a Spatial Encoder to capture spatial details, enhancing the fidelity of restored images. Extensive experiments demonstrate that InterLCM outperforms existing approaches in both synthetic and real-world datasets while also achieving faster inference speed.</li>
</ul>

<h3>Title: Flatten Graphs as Sequences: Transformers are Scalable Graph Generators</h3>
<ul>
<li><strong>Authors: </strong>Dexiong Chen, Markus Krimmel, Karsten Borgwardt</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02216">https://arxiv.org/abs/2502.02216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02216">https://arxiv.org/pdf/2502.02216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02216]] Flatten Graphs as Sequences: Transformers are Scalable Graph Generators(https://arxiv.org/abs/2502.02216)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>We introduce AutoGraph, a novel autoregressive framework for generating large attributed graphs using decoder-only transformers. At the core of our approach is a reversible "flattening" process that transforms graphs into random sequences. By sampling and learning from these sequences, AutoGraph enables transformers to model and generate complex graph structures in a manner akin to natural language. In contrast to diffusion models that rely on computationally intensive node features, our approach operates exclusively on these sequences. The sampling complexity and sequence length scale linearly with the number of edges, making AutoGraph highly scalable for generating large sparse graphs. Empirically, AutoGraph achieves state-of-the-art performance across diverse synthetic and molecular graph generation benchmarks, while delivering a 100-fold generation and a 3-fold training speedup compared to leading diffusion models. Additionally, it demonstrates promising transfer capabilities and supports substructure-conditioned generation without additional fine-tuning. By extending language modeling techniques to graph generation, this work paves the way for developing graph foundation models.</li>
</ul>

<h3>Title: Exploring the latent space of diffusion models directly through singular value decomposition</h3>
<ul>
<li><strong>Authors: </strong>Li Wang, Boyan Gao, Yanran Li, Zhao Wang, Xiaosong Yang, David A. Clifton, Jun Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.MM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02225">https://arxiv.org/abs/2502.02225</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02225">https://arxiv.org/pdf/2502.02225</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02225]] Exploring the latent space of diffusion models directly through singular value decomposition(https://arxiv.org/abs/2502.02225)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Despite the groundbreaking success of diffusion models in generating high-fidelity images, their latent space remains relatively under-explored, even though it holds significant promise for enabling versatile and interpretable image editing capabilities. The complicated denoising trajectory and high dimensionality of the latent space make it extremely challenging to interpret. Existing methods mainly explore the feature space of U-Net in Diffusion Models (DMs) instead of the latent space itself. In contrast, we directly investigate the latent space via Singular Value Decomposition (SVD) and discover three useful properties that can be used to control generation results without the requirements of data collection and maintain identity fidelity generated images. Based on these properties, we propose a novel image editing framework that is capable of learning arbitrary attributes from one pair of latent codes destined by text prompts in Stable Diffusion Models. To validate our approach, extensive experiments are conducted to demonstrate its effectiveness and flexibility in image editing. We will release our codes soon to foster further research and applications in this area.</li>
</ul>

<h3>Title: A Robust Remote Photoplethysmography Method</h3>
<ul>
<li><strong>Authors: </strong>Alexey Protopopov</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02229">https://arxiv.org/abs/2502.02229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02229">https://arxiv.org/pdf/2502.02229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02229]] A Robust Remote Photoplethysmography Method(https://arxiv.org/abs/2502.02229)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>Remote photoplethysmography (rPPG) is a method for measuring a subjects heart rate remotely using a camera. Factors such as subject movement, ambient light level, makeup etc. complicate such measurements by distorting the observed pulse. Recent works on this topic have proposed a variety of approaches for accurately measuring heart rate in humans, however these methods were tested in ideal conditions, where the subject does not make significant movements and all measurements are taken at the same level of illumination. In more realistic conditions these methods suffer from decreased accuracy. The study proposes a more robust method that is less susceptible to distortions and has minimal hardware requirements. The proposed method uses a combination of mathematical transforms to calculate the subjects heart rate. It performs best when used with a camera that has been modified by removing its infrared filter, although using an unmodified camera is also possible. The method was tested on 26 videos taken from 19 volunteers of varying gender and age. The obtained results were compared to reference data and the average mean absolute error was found to be at 1.95 beats per minute, which is noticeably better than the results from previous works. The remote photoplethysmography method proposed in the present article is more resistant to distortions than methods from previous publications and thus allows one to remotely and accurately measure the subjects heart rate without imposing any significant limitations on the subjects behavior.</li>
</ul>

<h3>Title: An Attack-Driven Incident Response and Defense System (ADIRDS)</h3>
<ul>
<li><strong>Authors: </strong>Anthony Cheuk Tung Lai, Siu Ming Yiu, Ping Fan Ke, Alan Ho</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02230">https://arxiv.org/abs/2502.02230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02230">https://arxiv.org/pdf/2502.02230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02230]] An Attack-Driven Incident Response and Defense System (ADIRDS)(https://arxiv.org/abs/2502.02230)</code><input type="text"></li>
<li><strong>Keywords: </strong>defense, attack</a></li>
<li><strong>Abstract: </strong>One of the major goals of incident response is to help an organization or a system owner to quickly identify and halt the attacks to minimize the damages (and financial loss) to the system being attacked. Typical incident responses rely very much on the log information captured by the system during the attacks and if needed, may need to isolate the victim from the network to avoid further destructive attacks. However, there are real cases that there are insufficient log records/information for the incident response team to identify the attacks and their origins while the attacked system cannot be stopped due to service requirements (zero downtime online systems) such as online gaming sites. Typical incident response procedures and industrial standards do not provide an adequate solution to address this scenario. In this paper, being motivated by a real case, we propose a solution, called "Attack-Driven Incident Response and Defense System (ADIRDS)" to tackle this problem. ADIRDS is an online monitoring system to run with the real system. By modeling the real system as a graph, critical nodes/assets of the system are closely monitored. Instead of relying on the original logging system, evidence will be collected from the attack technique perspectives. To migrate the risks, realistic honeypots with very similar business context as the real system are deployed to trap the attackers. We successfully apply this system to a real case. Based on our experiments, we verify that our new approach of designing the realistic honeypots is effective, 38 unique attacker's IP addresses were captured. We also compare the performance of our realistic honey with both low and high interactive honeypots proposed in the literature, the results found that our proposed honeypot can successfully cheat the attackers to attack our honeypot, which verifies that our honeypot is more effective.</li>
</ul>

<h3>Title: Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning</h3>
<ul>
<li><strong>Authors: </strong>Bangzhen Liu, Chenxi Zheng, Xuemiao Xu, Cheng Xu, Huaidong Zhang, Shengfeng He</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02247">https://arxiv.org/abs/2502.02247</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02247">https://arxiv.org/pdf/2502.02247</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02247]] Rotation-Adaptive Point Cloud Domain Generalization via Intricate Orientation Learning(https://arxiv.org/abs/2502.02247)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>The vulnerability of 3D point cloud analysis to unpredictable rotations poses an open yet challenging problem: orientation-aware 3D domain generalization. Cross-domain robustness and adaptability of 3D representations are crucial but not easily achieved through rotation augmentation. Motivated by the inherent advantages of intricate orientations in enhancing generalizability, we propose an innovative rotation-adaptive domain generalization framework for 3D point cloud analysis. Our approach aims to alleviate orientational shifts by leveraging intricate samples in an iterative learning process. Specifically, we identify the most challenging rotation for each point cloud and construct an intricate orientation set by optimizing intricate orientations. Subsequently, we employ an orientation-aware contrastive learning framework that incorporates an orientation consistency loss and a margin separation loss, enabling effective learning of categorically discriminative and generalizable features with rotation consistency. Extensive experiments and ablations conducted on 3D cross-domain benchmarks firmly establish the state-of-the-art performance of our proposed approach in the context of orientation-aware 3D domain generalization.</li>
</ul>

<h3>Title: Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Atharva Mangeshkumar Agrawal, Rutika Pandurang Shinde, Vasanth Kumar Bhukya, Ashmita Chakraborty, Sagar Bharat Shah, Tanmay Shukla, Sree Pradeep Kumar Relangi, Nilesh Mutyam</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02249">https://arxiv.org/abs/2502.02249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02249">https://arxiv.org/pdf/2502.02249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02249]] Conversation AI Dialog for Medicare powered by Finetuning and Retrieval Augmented Generation(https://arxiv.org/abs/2502.02249)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown impressive capabilities in natural language processing tasks, including dialogue generation. This research aims to conduct a novel comparative analysis of two prominent techniques, fine-tuning with LoRA (Low-Rank Adaptation) and the Retrieval-Augmented Generation (RAG) framework, in the context of doctor-patient chat conversations with multiple datasets of mixed medical domains. The analysis involves three state-of-the-art models: Llama-2, GPT, and the LSTM model. Employing real-world doctor-patient dialogues, we comprehensively evaluate the performance of models, assessing key metrics such as language quality (perplexity, BLEU score), factual accuracy (fact-checking against medical knowledge bases), adherence to medical guidelines, and overall human judgments (coherence, empathy, safety). The findings provide insights into the strengths and limitations of each approach, shedding light on their suitability for healthcare applications. Furthermore, the research investigates the robustness of the models in handling diverse patient queries, ranging from general health inquiries to specific medical conditions. The impact of domain-specific knowledge integration is also explored, highlighting the potential for enhancing LLM performance through targeted data augmentation and retrieval strategies.</li>
</ul>

<h3>Title: UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Tao Zhang, Jinyong Wen, Zhen Chen, Kun Ding, Shiming Xiang, Chunhong Pan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02257">https://arxiv.org/abs/2502.02257</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02257">https://arxiv.org/pdf/2502.02257</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02257]] UNIP: Rethinking Pre-trained Attention Patterns for Infrared Semantic Segmentation(https://arxiv.org/abs/2502.02257)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Pre-training techniques significantly enhance the performance of semantic segmentation tasks with limited training data. However, the efficacy under a large domain gap between pre-training (e.g. RGB) and fine-tuning (e.g. infrared) remains underexplored. In this study, we first benchmark the infrared semantic segmentation performance of various pre-training methods and reveal several phenomena distinct from the RGB domain. Next, our layerwise analysis of pre-trained attention maps uncovers that: (1) There are three typical attention patterns (local, hybrid, and global); (2) Pre-training tasks notably influence the pattern distribution across layers; (3) The hybrid pattern is crucial for semantic segmentation as it attends to both nearby and foreground elements; (4) The texture bias impedes model generalization in infrared tasks. Building on these insights, we propose UNIP, a UNified Infrared Pre-training framework, to enhance the pre-trained model performance. This framework uses the hybrid-attention distillation NMI-HAD as the pre-training target, a large-scale mixed dataset InfMix for pre-training, and a last-layer feature pyramid network LL-FPN for fine-tuning. Experimental results show that UNIP outperforms various pre-training methods by up to 13.5\% in average mIoU on three infrared segmentation tasks, evaluated using fine-tuning and linear probing metrics. UNIP-S achieves performance on par with MAE-L while requiring only 1/10 of the computational cost. Furthermore, UNIP significantly surpasses state-of-the-art (SOTA) infrared or RGB segmentation methods and demonstrates broad potential for application in other modalities, such as RGB and depth. Our code is available at this https URL.</li>
</ul>

<h3>Title: Adversarial ML Problems Are Getting Harder to Solve and to Evaluate</h3>
<ul>
<li><strong>Authors: </strong>Javier Rando, Jie Zhang, Nicholas Carlini, Florian Tram√®r</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02260">https://arxiv.org/abs/2502.02260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02260">https://arxiv.org/pdf/2502.02260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02260]] Adversarial ML Problems Are Getting Harder to Solve and to Evaluate(https://arxiv.org/abs/2502.02260)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In the past decade, considerable research effort has been devoted to securing machine learning (ML) models that operate in adversarial settings. Yet, progress has been slow even for simple "toy" problems (e.g., robustness to small adversarial perturbations) and is often hindered by non-rigorous evaluations. Today, adversarial ML research has shifted towards studying larger, general-purpose language models. In this position paper, we argue that the situation is now even worse: in the era of LLMs, the field of adversarial ML studies problems that are (1) less clearly defined, (2) harder to solve, and (3) even more challenging to evaluate. As a result, we caution that yet another decade of work on adversarial ML may fail to produce meaningful progress.</li>
</ul>

<h3>Title: Exact Sequence Classification with Hardmax Transformers</h3>
<ul>
<li><strong>Authors: </strong>Albert Alcalde, Giovanni Fantuzzi, Enrique Zuazua</a></li>
<li><strong>Subjects: </strong>cs.LG, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02270">https://arxiv.org/abs/2502.02270</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02270">https://arxiv.org/pdf/2502.02270</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02270]] Exact Sequence Classification with Hardmax Transformers(https://arxiv.org/abs/2502.02270)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>We prove that hardmax attention transformers perfectly classify datasets of $N$ labeled sequences in $\mathbb{R}^d$, $d\geq 2$. Specifically, given $N$ sequences with an arbitrary but finite length in $\mathbb{R}^d$, we construct a transformer with $\mathcal{O}(N)$ blocks and $\mathcal{O}(Nd)$ parameters perfectly classifying this dataset. Our construction achieves the best complexity estimate to date, independent of the length of the sequences, by innovatively alternating feed-forward and self-attention layers and by capitalizing on the clustering effect inherent to the latter. Our novel constructive method also uses low-rank parameter matrices within the attention mechanism, a common practice in real-life transformer implementations. Consequently, our analysis holds twofold significance: it substantially advances the mathematical theory of transformers and it rigorously justifies their exceptional real-world performance in sequence classification tasks.</li>
</ul>

<h3>Title: Evalita-LLM: Benchmarking Large Language Models on Italian</h3>
<ul>
<li><strong>Authors: </strong>Bernardo Magnini, Roberto Zanoli, Michele Resta, Martin Cimmino, Paolo Albano, Marco Madeddu, Viviana Patti</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02289">https://arxiv.org/abs/2502.02289</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02289">https://arxiv.org/pdf/2502.02289</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02289]] Evalita-LLM: Benchmarking Large Language Models on Italian(https://arxiv.org/abs/2502.02289)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair, generative, large language model</a></li>
<li><strong>Abstract: </strong>We describe Evalita-LLM, a new benchmark designed to evaluate Large Language Models (LLMs) on Italian tasks. The distinguishing and innovative features of Evalita-LLM are the following: (i) all tasks are native Italian, avoiding issues of translating from Italian and potential cultural biases; (ii) in addition to well established multiple-choice tasks, the benchmark includes generative tasks, enabling more natural interaction with LLMs; (iii) all tasks are evaluated against multiple prompts, this way mitigating the model sensitivity to specific prompts and allowing a fairer and objective evaluation. We propose an iterative methodology, where candidate tasks and candidate prompts are validated against a set of LLMs used for development. We report experimental results from the benchmark's development phase, and provide performance statistics for several state-of-the-art LLMs.</li>
</ul>

<h3>Title: FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection</h3>
<ul>
<li><strong>Authors: </strong>Daniele Lunghi, Yannick Molinghen, Alkis Simitsis, Tom Lenaerts, Gianluca Bontempi</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02290">https://arxiv.org/abs/2502.02290</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02290">https://arxiv.org/pdf/2502.02290</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02290]] FRAUD-RLA: A new reinforcement learning adversarial attack against credit card fraud detection(https://arxiv.org/abs/2502.02290)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Adversarial attacks pose a significant threat to data-driven systems, and researchers have spent considerable resources studying them. Despite its economic relevance, this trend largely overlooked the issue of credit card fraud detection. To address this gap, we propose a new threat model that demonstrates the limitations of existing attacks and highlights the necessity to investigate new approaches. We then design a new adversarial attack for credit card fraud detection, employing reinforcement learning to bypass classifiers. This attack, called FRAUD-RLA, is designed to maximize the attacker's reward by optimizing the exploration-exploitation tradeoff and working with significantly less required knowledge than competitors. Our experiments, conducted on three different heterogeneous datasets and against two fraud detection systems, indicate that FRAUD-RLA is effective, even considering the severe limitations imposed by our threat model.</li>
</ul>

<h3>Title: Density Ratio Estimation with Conditional Probability Paths</h3>
<ul>
<li><strong>Authors: </strong>Hanlin Yu, Arto Klami, Aapo Hyv√§rinen, Anna Korba, Omar Chehab</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02300">https://arxiv.org/abs/2502.02300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02300">https://arxiv.org/pdf/2502.02300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02300]] Density Ratio Estimation with Conditional Probability Paths(https://arxiv.org/abs/2502.02300)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Density ratio estimation in high dimensions can be reframed as integrating a certain quantity, the time score, over probability paths which interpolate between the two densities. In practice, the time score has to be estimated based on samples from the two densities. However, existing methods for this problem remain computationally expensive and can yield inaccurate estimates. Inspired by recent advances in generative modeling, we introduce a novel framework for time score estimation, based on a conditioning variable. Choosing the conditioning variable judiciously enables a closed-form objective function. We demonstrate that, compared to previous approaches, our approach results in faster learning of the time score and competitive or better estimation accuracies of the density ratio on challenging tasks. Furthermore, we establish theoretical guarantees on the error of the estimated density ratio.</li>
</ul>

<h3>Title: UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training</h3>
<ul>
<li><strong>Authors: </strong>Jiawei Qin, Xucong Zhang, Yusuke Sugano</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02307">https://arxiv.org/abs/2502.02307</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02307">https://arxiv.org/pdf/2502.02307</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02307]] UniGaze: Towards Universal Gaze Estimation via Large-scale Pre-Training(https://arxiv.org/abs/2502.02307)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Despite decades of research on data collection and model architectures, current gaze estimation models face significant challenges in generalizing across diverse data domains. While recent advances in self-supervised pre-training have shown remarkable potential for improving model generalization in various vision tasks, their effectiveness in gaze estimation remains unexplored due to the geometric nature of the gaze regression task. We propose UniGaze, which leverages large-scale, in-the-wild facial datasets through self-supervised pre-training for gaze estimation. We carefully curate multiple facial datasets that capture diverse variations in identity, lighting, background, and head poses. By directly applying Masked Autoencoder (MAE) pre-training on normalized face images with a Vision Transformer (ViT) backbone, our UniGaze learns appropriate feature representations within the specific input space required by downstream gaze estimation models. Through comprehensive experiments using challenging cross-dataset evaluation and novel protocols, including leave-one-dataset-out and joint-dataset settings, we demonstrate that UniGaze significantly improves generalization across multiple data domains while minimizing reliance on costly labeled data. The source code and pre-trained models will be released upon acceptance.</li>
</ul>

<h3>Title: Review of Demographic Bias in Face Recognition</h3>
<ul>
<li><strong>Authors: </strong>Ketan Kotwal, Sebastien Marcel</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02309">https://arxiv.org/abs/2502.02309</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02309">https://arxiv.org/pdf/2502.02309</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02309]] Review of Demographic Bias in Face Recognition(https://arxiv.org/abs/2502.02309)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Demographic bias in face recognition (FR) has emerged as a critical area of research, given its impact on fairness, equity, and reliability across diverse applications. As FR technologies are increasingly deployed globally, disparities in performance across demographic groups -- such as race, ethnicity, and gender -- have garnered significant attention. These biases not only compromise the credibility of FR systems but also raise ethical concerns, especially when these technologies are employed in sensitive domains. This review consolidates extensive research efforts providing a comprehensive overview of the multifaceted aspects of demographic bias in FR. We systematically examine the primary causes, datasets, assessment metrics, and mitigation approaches associated with demographic disparities in FR. By categorizing key contributions in these areas, this work provides a structured approach to understanding and addressing the complexity of this issue. Finally, we highlight current advancements and identify emerging challenges that need further investigation. This article aims to provide researchers with a unified perspective on the state-of-the-art while emphasizing the critical need for equitable and trustworthy FR systems.</li>
</ul>

<h3>Title: DIME:Diffusion-Based Maximum Entropy Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Onur Celik, Zechu Li, Denis Blessing, Ge Li, Daniel Palanicek, Jan Peters, Georgia Chalvatzaki, Gerhard Neumann</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02316">https://arxiv.org/abs/2502.02316</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02316">https://arxiv.org/pdf/2502.02316</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02316]] DIME:Diffusion-Based Maximum Entropy Reinforcement Learning(https://arxiv.org/abs/2502.02316)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Maximum entropy reinforcement learning (MaxEnt-RL) has become the standard approach to RL due to its beneficial exploration properties. Traditionally, policies are parameterized using Gaussian distributions, which significantly limits their representational capacity. Diffusion-based policies offer a more expressive alternative, yet integrating them into MaxEnt-RL poses challenges--primarily due to the intractability of computing their marginal entropy. To overcome this, we propose Diffusion-Based Maximum Entropy RL (DIME). DIME leverages recent advances in approximate inference with diffusion models to derive a lower bound on the maximum entropy objective. Additionally, we propose a policy iteration scheme that provably converges to the optimal diffusion policy. Our method enables the use of expressive diffusion-based policies while retaining the principled exploration benefits of MaxEnt-RL, significantly outperforming other diffusion-based methods on challenging high-dimensional control benchmarks. It is also competitive with state-of-the-art non-diffusion based RL methods while requiring fewer algorithmic design choices and smaller update-to-data ratios, reducing computational complexity.</li>
</ul>

<h3>Title: Event-aided Semantic Scene Completion</h3>
<ul>
<li><strong>Authors: </strong>Shangwei Guo, Hao Shi, Song Wang, Xiaoting Yin, Kailun Yang, Kaiwei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02334">https://arxiv.org/abs/2502.02334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02334">https://arxiv.org/pdf/2502.02334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02334]] Event-aided Semantic Scene Completion(https://arxiv.org/abs/2502.02334)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Autonomous driving systems rely on robust 3D scene understanding. Recent advances in Semantic Scene Completion (SSC) for autonomous driving underscore the limitations of RGB-based approaches, which struggle under motion blur, poor lighting, and adverse weather. Event cameras, offering high dynamic range and low latency, address these challenges by providing asynchronous data that complements RGB inputs. We present DSEC-SSC, the first real-world benchmark specifically designed for event-aided SSC, which includes a novel 4D labeling pipeline for generating dense, visibility-aware labels that adapt dynamically to object motion. Our proposed RGB-Event fusion framework, EvSSC, introduces an Event-aided Lifting Module (ELM) that effectively bridges 2D RGB-Event features to 3D space, enhancing view transformation and the robustness of 3D volume construction across SSC models. Extensive experiments on DSEC-SSC and simulated SemanticKITTI-E demonstrate that EvSSC is adaptable to both transformer-based and LSS-based SSC architectures. Notably, evaluations on SemanticKITTI-C demonstrate that EvSSC achieves consistently improved prediction accuracy across five degradation modes and both In-domain and Out-of-domain settings, achieving up to a 52.5% relative improvement in mIoU when the image sensor partially fails. Additionally, we quantitatively and qualitatively validate the superiority of EvSSC under motion blur and extreme weather conditions, where autonomous driving is challenged. The established datasets and our codebase will be made publicly at this https URL.</li>
</ul>

<h3>Title: Target Attack Backdoor Malware Analysis and Attribution</h3>
<ul>
<li><strong>Authors: </strong>Anthony Cheuk Tung Lai, Vitaly Kamluk, Alan Ho, Ping Fan Ke, Byron Wai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02335">https://arxiv.org/abs/2502.02335</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02335">https://arxiv.org/pdf/2502.02335</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02335]] Target Attack Backdoor Malware Analysis and Attribution(https://arxiv.org/abs/2502.02335)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack</a></li>
<li><strong>Abstract: </strong>Backdoor Malware are installed by an attacker on the victim's server(s) for authorized access. A customized backdoor is weaponized to execute unauthorized system, database and application commands to access the user credentials and confidential digital assets. Recently, we discovered and analyzed a targeted persistent module backdoor in Web Server in an online business company that was undetectable by their deployed Anti-Virus software for a year. This led us to carry out research to detect this specific type of persistent module backdoor installed in Web servers. Other than typical Malware static analysis, we carry out analysis with binary similarity, strings, and command obfuscation over the backdoor, resulting in the Target Attack Backdoor Malware Analysis Matrix (TABMAX) for organizations to detect this sophisticated target attack backdoor instead of a general one which can be detected by Anti-Virus detectors. Our findings show that backdoor malware can be designed with different APIs, commands, strings, and query language on top of preferred libraries used by typical Malware.</li>
</ul>

<h3>Title: Rule-ATT&CK Mapper (RAM): Mapping SIEM Rules to TTPs Using LLMs</h3>
<ul>
<li><strong>Authors: </strong>Prasanna N. Wudali, Moshe Kravchik, Ehud Malul, Parth A. Gandhi, Yuval Elovici, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02337">https://arxiv.org/abs/2502.02337</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02337">https://arxiv.org/pdf/2502.02337</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02337]] Rule-ATT&CK Mapper (RAM): Mapping SIEM Rules to TTPs Using LLMs(https://arxiv.org/abs/2502.02337)</code><input type="text"></li>
<li><strong>Keywords: </strong>security, attack</a></li>
<li><strong>Abstract: </strong>The growing frequency of cyberattacks has heightened the demand for accurate and efficient threat detection systems. SIEM platforms are important for analyzing log data and detecting adversarial activities through rule-based queries, also known as SIEM rules. The efficiency of the threat analysis process relies heavily on mapping these SIEM rules to the relevant attack techniques in the MITRE ATT&CK framework. Inaccurate annotation of SIEM rules can result in the misinterpretation of attacks, increasing the likelihood that threats will be overlooked. Existing solutions for annotating SIEM rules with MITRE ATT&CK technique labels have notable limitations: manual annotation of SIEM rules is both time-consuming and prone to errors, and ML-based approaches mainly focus on annotating unstructured free text sources rather than structured data like SIEM rules. Structured data often contains limited information, further complicating the annotation process and making it a challenging task. To address these challenges, we propose Rule-ATT&CK Mapper (RAM), a novel framework that leverages LLMs to automate the mapping of structured SIEM rules to MITRE ATT&CK techniques. RAM's multi-stage pipeline, which was inspired by the prompt chaining technique, enhances mapping accuracy without requiring LLM pre-training or fine-tuning. Using the Splunk Security Content dataset, we evaluate RAM's performance using several LLMs, including GPT-4-Turbo, Qwen, IBM Granite, and Mistral. Our evaluation highlights GPT-4-Turbo's superior performance, which derives from its enriched knowledge base, and an ablation study emphasizes the importance of external contextual knowledge in overcoming the limitations of LLMs' implicit knowledge for domain-specific tasks. These findings demonstrate RAM's potential in automating cybersecurity workflows and provide valuable insights for future advancements in this field.</li>
</ul>

<h3>Title: Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking</h3>
<ul>
<li><strong>Authors: </strong>Jinyang Wu, Mingkuan Feng, Shuai Zhang, Ruihan Jin, Feihu Che, Zengqi Wen, Jianhua Tao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02339">https://arxiv.org/abs/2502.02339</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02339">https://arxiv.org/pdf/2502.02339</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02339]] Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking(https://arxiv.org/abs/2502.02339)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, large language model</a></li>
<li><strong>Abstract: </strong>Multimodal large language models (MLLMs) exhibit impressive capabilities but still face challenges in complex visual reasoning. While recent efforts attempt to enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking through explicit search structures or teacher-guided distillation, they often struggle to balance performance and efficiency. A critical limitation is their heavy reliance on extensive data and search spaces, resulting in low-efficiency implicit insight extraction and data utilization. To address this, we propose AStar, an Automated Structured thinking paradigm for multimodal reasoning via Monte Carlo Tree Search (MCTS). AStar automatically derives high-level cognitive reasoning patterns from limited data using MCTS-powered hierarchical structures. Building on these explicit patterns, we design a unified reasoning framework that seamlessly integrates models' internal reasoning capabilities and external reasoning guidelines, enabling efficient inference with minimal tree iterations. This novel paradigm strikes a compelling balance between performance and efficiency. Extensive experiments demonstrate AStar's effectiveness, achieving superior accuracy (54.0$\%$) on the MathVerse benchmark with a 7B backbone, surpassing GPT-4o (50.2$\%$) while maintaining substantial data and computational efficiency.</li>
</ul>

<h3>Title: Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Shutong Duan, Jingyun Yang, Yang Tan, Guoqing Zhang, Yang Li, Xiao-Ping Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02340">https://arxiv.org/abs/2502.02340</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02340">https://arxiv.org/pdf/2502.02340</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02340]] Transfer Risk Map: Mitigating Pixel-level Negative Transfer in Medical Segmentation(https://arxiv.org/abs/2502.02340)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, segmentation</a></li>
<li><strong>Abstract: </strong>How to mitigate negative transfer in transfer learning is a long-standing and challenging issue, especially in the application of medical image segmentation. Existing methods for reducing negative transfer focus on classification or regression tasks, ignoring the non-uniform negative transfer risk in different image regions. In this work, we propose a simple yet effective weighted fine-tuning method that directs the model's attention towards regions with significant transfer risk for medical semantic segmentation. Specifically, we compute a transferability-guided transfer risk map to quantify the transfer hardness for each pixel and the potential risks of negative transfer. During the fine-tuning phase, we introduce a map-weighted loss function, normalized with image foreground size to counter class imbalance. Extensive experiments on brain segmentation datasets show our method significantly improves the target task performance, with gains of 4.37% on FeTS2021 and 1.81% on iSeg2019, avoiding negative transfer across modalities and tasks. Meanwhile, a 2.9% gain under a few-shot scenario validates the robustness of our approach.</li>
</ul>

<h3>Title: SHIELD: APT Detection and Intelligent Explanation Using LLM</h3>
<ul>
<li><strong>Authors: </strong>Parth Atulbhai Gandhi, Prasanna N. Wudali, Yonatan Amaru, Yuval Elovici, Asaf Shabtai</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02342">https://arxiv.org/abs/2502.02342</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02342">https://arxiv.org/pdf/2502.02342</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02342]] SHIELD: APT Detection and Intelligent Explanation Using LLM(https://arxiv.org/abs/2502.02342)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, interpretability, large language model</a></li>
<li><strong>Abstract: </strong>Advanced persistent threats (APTs) are sophisticated cyber attacks that can remain undetected for extended periods, making their mitigation particularly challenging. Given their persistence, significant effort is required to detect them and respond effectively. Existing provenance-based attack detection methods often lack interpretability and suffer from high false positive rates, while investigation approaches are either supervised or limited to known attacks. To address these challenges, we introduce SHIELD, a novel approach that combines statistical anomaly detection and graph-based analysis with the contextual analysis capabilities of large language models (LLMs). SHIELD leverages the implicit knowledge of LLMs to uncover hidden attack patterns in provenance data, while reducing false positives and providing clear, interpretable attack descriptions. This reduces analysts' alert fatigue and makes it easier for them to understand the threat landscape. Our extensive evaluation demonstrates SHIELD's effectiveness and computational efficiency in real-world scenarios. SHIELD was shown to outperform state-of-the-art methods, achieving higher precision and recall. SHIELD's integration of anomaly detection, LLM-driven contextual analysis, and advanced graph-based correlation establishes a new benchmark for APT detection.</li>
</ul>

<h3>Title: MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Ziyan Guo, Zeyu Hu, Na Zhao, De Wen Soh</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02358">https://arxiv.org/abs/2502.02358</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02358">https://arxiv.org/pdf/2502.02358</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02358]] MotionLab: Unified Human Motion Generation and Editing via the Motion-Condition-Motion Paradigm(https://arxiv.org/abs/2502.02358)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Human motion generation and editing are key components of computer graphics and vision. However, current approaches in this field tend to offer isolated solutions tailored to specific tasks, which can be inefficient and impractical for real-world applications. While some efforts have aimed to unify motion-related tasks, these methods simply use different modalities as conditions to guide motion generation. Consequently, they lack editing capabilities, fine-grained control, and fail to facilitate knowledge sharing across tasks. To address these limitations and provide a versatile, unified framework capable of handling both human motion generation and editing, we introduce a novel paradigm: Motion-Condition-Motion, which enables the unified formulation of diverse tasks with three concepts: source motion, condition, and target this http URL on this paradigm, we propose a unified framework, MotionLab, which incorporates rectified flows to learn the mapping from source motion to target motion, guided by the specified this http URL MotionLab, we introduce the 1) MotionFlow Transformer to enhance conditional generation and editing without task-specific modules; 2) Aligned Rotational Position Encoding} to guarantee the time synchronization between source motion and target motion; 3) Task Specified Instruction Modulation; and 4) Motion Curriculum Learning for effective multi-task learning and knowledge sharing across tasks. Notably, our MotionLab demonstrates promising generalization capabilities and inference efficiency across multiple benchmarks for human motion. Our code and additional video results are available at: this https URL.</li>
</ul>

<h3>Title: Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sagnik Mukherjee, Abhinav Chinta, Takyoung Kim, Tarun Anoop Sharma, Dilek Hakkani Tur</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02362">https://arxiv.org/abs/2502.02362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02362">https://arxiv.org/pdf/2502.02362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02362]] Premise-Augmented Reasoning Chains Improve Error Identification in Math reasoning with LLMs(https://arxiv.org/abs/2502.02362)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Chain-of-Thought (CoT) prompting enhances mathematical reasoning in large language models (LLMs) by enabling detailed step-by-step solutions. However, due to the verbosity of LLMs, the resulting reasoning chains can be long, making it harder to verify the reasoning steps and trace issues resulting from dependencies between the steps that may be farther away in the sequence of steps. Importantly, mathematical reasoning allows each step to be derived from a small set of premises, which are a subset of the preceding steps in the reasoning chain. In this paper, we present a framework that identifies the premises for each step, to improve the evaluation of reasoning. We restructure conventional linear reasoning chains into Premise Augmented Reasoning Chains (PARC) by introducing premise links, resulting in a directed acyclic graph where the nodes are the steps and the edges are the premise links. Through experiments with a PARC-based dataset that we built, namely PERL (Premises and ERrors identification in LLMs), we demonstrate that LLMs can reliably identify premises within complex reasoning chains. In particular, even open-source LLMs achieve 90% recall in premise identification. We also show that PARC helps to identify errors in reasoning chains more reliably. The accuracy of error identification improves by 6% to 16% absolute when step-by-step verification is carried out in PARC under the premises. Our findings highlight the utility of premise-centric representations in addressing complex problem-solving tasks and open new avenues for improving the reliability of LLM-based reasoning evaluations.</li>
</ul>

<h3>Title: Field Matching: an Electrostatic Paradigm to Generate and Transfer Data</h3>
<ul>
<li><strong>Authors: </strong>Alexander Kolesov, Manukhov Stepan, Vladimir V. Palyulin, Alexander Korotin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02367">https://arxiv.org/abs/2502.02367</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02367">https://arxiv.org/pdf/2502.02367</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02367]] Field Matching: an Electrostatic Paradigm to Generate and Transfer Data(https://arxiv.org/abs/2502.02367)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose Electrostatic Field Matching (EFM), a novel method that is suitable for both generative modeling and distribution transfer tasks. Our approach is inspired by the physics of an electrical capacitor. We place source and target distributions on the capacitor plates and assign them positive and negative charges, respectively. We then learn the electrostatic field of the capacitor using a neural network approximator. To map the distributions to each other, we start at one plate of the capacitor and move the samples along the learned electrostatic field lines until they reach the other plate. We theoretically justify that this approach provably yields the distribution transfer. In practice, we demonstrate the performance of our EFM in toy and image data experiments.</li>
</ul>

<h3>Title: STAIR: Improving Safety Alignment with Introspective Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yichi Zhang, Siyuan Zhang, Yao Huang, Zeyu Xia, Zhengwei Fang, Xiao Yang, Ranjie Duan, Dong Yan, Yinpeng Dong, Jun Zhu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02384">https://arxiv.org/abs/2502.02384</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02384">https://arxiv.org/pdf/2502.02384</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02384]] STAIR: Improving Safety Alignment with Introspective Reasoning(https://arxiv.org/abs/2502.02384)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, large language model</a></li>
<li><strong>Abstract: </strong>Ensuring the safety and harmlessness of Large Language Models (LLMs) has become equally critical as their performance in applications. However, existing safety alignment methods typically suffer from safety-performance trade-offs and the susceptibility to jailbreak attacks, primarily due to their reliance on direct refusals for malicious queries. In this paper, we propose STAIR, a novel framework that integrates SafeTy Alignment with Itrospective Reasoning. We enable LLMs to identify safety risks through step-by-step analysis by self-improving chain-of-thought (CoT) reasoning with safety awareness. STAIR first equips the model with a structured reasoning capability and then advances safety alignment via iterative preference optimization on step-level reasoning data generated using our newly proposed Safety-Informed Monte Carlo Tree Search (SI-MCTS). We further train a process reward model on this data to guide test-time searches for improved responses. Extensive experiments show that STAIR effectively mitigates harmful outputs while better preserving helpfulness, compared to instinctive alignment strategies. With test-time scaling, STAIR achieves a safety performance comparable to Claude-3.5 against popular jailbreak attacks. Relevant resources in this work are available at this https URL.</li>
</ul>

<h3>Title: SoK: Understanding zk-SNARKs: The Gap Between Research and Practice</h3>
<ul>
<li><strong>Authors: </strong>Junkai Liang, Daqi Hu, Pengfei Wu, Yunbo Yang, Qingni Shen, Zhonghai Wu</a></li>
<li><strong>Subjects: </strong>cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02387">https://arxiv.org/abs/2502.02387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02387">https://arxiv.org/pdf/2502.02387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02387]] SoK: Understanding zk-SNARKs: The Gap Between Research and Practice(https://arxiv.org/abs/2502.02387)</code><input type="text"></li>
<li><strong>Keywords: </strong>security</a></li>
<li><strong>Abstract: </strong>Zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs) are a powerful tool for proving computation correctness, attracting significant interest from researchers, developers, and users. However, the complexity of zk-SNARKs has created gaps between these groups, hindering progress. Researchers focus on constructing efficient proving systems with stronger security and new properties, while developers and users prioritize toolchains, usability, and compatibility. In this work, we provide a comprehensive study of zk-SNARK, from theory to practice, pinpointing gaps and limitations. We first present a master recipe that unifies the main steps in converting a program into a zk-SNARK. We then classify existing zk-SNARKs according to their key techniques. Our classification addresses the main difference in practically valuable properties between existing zk-SNARK schemes. We survey over 40 zk-SNARKs since 2013 and provide a reference table listing their categories and properties. Following the steps in master recipe, we then survey 11 general-purpose popular used libraries. We elaborate on these libraries' usability, compatibility, efficiency and limitations. Since installing and executing these zk-SNARK systems is challenging, we also provide a completely virtual environment in which to run the compiler for each of them. We identify that the proving system is the primary focus in cryptography academia. In contrast, the constraint system presents a bottleneck in industry. To bridge this gap, we offer recommendations and advocate for the opensource community to enhance documentation, standardization and compatibility.</li>
</ul>

<h3>Title: CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Jianfeng Pan, Senyou Deng, Shaomang Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02390">https://arxiv.org/abs/2502.02390</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02390">https://arxiv.org/pdf/2502.02390</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02390]] CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning(https://arxiv.org/abs/2502.02390)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Research on LLM technologies is rapidly emerging, with most of them employing a 'fast thinking' approach to inference. Most LLMs generate the final result based solely on a single query and LLM's reasoning capabilities. However, with the advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing attention because its process is closer to the human thought process. Inspired by the human ability to constantly associate and replenish knowledge during thinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework, which introduces an innovative synergy between the Monte Carlo Tree Search (MCTS) algorithm and a dynamic mechanism for integrating new key information, termed 'associative memory'. By combining the structured exploration capabilities of MCTS with the adaptive learning capacity of associative memory, CoAT significantly expands the LLM search space, enabling our framework to explore diverse reasoning pathways and dynamically update its knowledge base in real-time. This allows the framework to not only revisit and refine earlier inferences but also adaptively incorporate evolving information, ensuring that the final output is both accurate and comprehensive. To validate the effectiveness of our framework, we conducted extensive experiments across a range of generative and reasoning tasks. These experiments demonstrated that our framework outperforms conventional inference processes on accuracy, coherence, and diversity. The framework's ability to iteratively expand its search space while retaining contextually relevant information results.</li>
</ul>

<h3>Title: FewTopNER: Integrating Few-Shot Learning with Topic Modeling and Named Entity Recognition in a Multilingual Framework</h3>
<ul>
<li><strong>Authors: </strong>Ibrahim Bouabdallaoui, Fatima Guerouate, Samya Bouhaddour, Chaimae Saadi, Mohammed Sbihi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02391">https://arxiv.org/abs/2502.02391</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02391">https://arxiv.org/pdf/2502.02391</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02391]] FewTopNER: Integrating Few-Shot Learning with Topic Modeling and Named Entity Recognition in a Multilingual Framework(https://arxiv.org/abs/2502.02391)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We introduce FewTopNER, a novel framework that integrates few-shot named entity recognition (NER) with topic-aware contextual modeling to address the challenges of cross-lingual and low-resource scenarios. FewTopNER leverages a shared multilingual encoder based on XLM-RoBERTa, augmented with language-specific calibration mechanisms, to generate robust contextual embeddings. The architecture comprises a prototype-based entity recognition branch, employing BiLSTM and Conditional Random Fields for sequence labeling, and a topic modeling branch that extracts document-level semantic features through hybrid probabilistic and neural methods. A cross-task bridge facilitates dynamic bidirectional attention and feature fusion between entity and topic representations, thereby enhancing entity disambiguation by incorporating global semantic context. Empirical evaluations on multilingual benchmarks across English, French, Spanish, German, and Italian demonstrate that FewTopNER significantly outperforms existing state-of-the-art few-shot NER models. In particular, the framework achieves improvements of 2.5-4.0 percentage points in F1 score and exhibits enhanced topic coherence, as measured by normalized pointwise mutual information. Ablation studies further confirm the critical contributions of the shared encoder and cross-task integration mechanisms to the overall performance. These results underscore the efficacy of incorporating topic-aware context into few-shot NER and highlight the potential of FewTopNER for robust cross-lingual applications in low-resource settings.</li>
</ul>

<h3>Title: Lower Bounds for Chain-of-Thought Reasoning in Hard-Attention Transformers</h3>
<ul>
<li><strong>Authors: </strong>Alireza Amiri, Xinting Huang, Mark Rofin, Michael Hahn</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02393">https://arxiv.org/abs/2502.02393</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02393">https://arxiv.org/pdf/2502.02393</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02393]] Lower Bounds for Chain-of-Thought Reasoning in Hard-Attention Transformers(https://arxiv.org/abs/2502.02393)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Chain-of-thought reasoning and scratchpads have emerged as critical tools for enhancing the computational capabilities of transformers. While theoretical results show that polynomial-length scratchpads can extend transformers' expressivity from $TC^0$ to $PTIME$, their required length remains poorly understood. Empirical evidence even suggests that transformers need scratchpads even for many problems in $TC^0$, such as Parity or Multiplication, challenging optimistic bounds derived from circuit complexity. In this work, we initiate the study of systematic lower bounds for the number of CoT steps across different algorithmic problems, in the hard-attention regime. We study a variety of algorithmic problems, and provide bounds that are tight up to logarithmic factors. Overall, these results contribute to emerging understanding of the power and limitations of chain-of-thought reasoning.</li>
</ul>

<h3>Title: LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Tzu-Tao Chang, Shivaram Venkataraman</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.DC, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02406">https://arxiv.org/abs/2502.02406</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02406">https://arxiv.org/pdf/2502.02406</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02406]] LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models(https://arxiv.org/abs/2502.02406)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Cross-attention is commonly adopted in multimodal large language models (MLLMs) for integrating visual information into the language backbone. However, in applications with large visual inputs, such as video understanding, processing a large number of visual tokens in cross-attention layers leads to high memory demands and often necessitates distributed computation across multiple GPUs. Existing distributed attention mechanisms face significant communication overheads, making cross-attention layers a critical bottleneck for efficient training and inference of MLLMs. To address this, we propose LV-XAttn, a distributed, exact cross-attention mechanism with minimal communication overhead. We observe that in applications involving large visual inputs the size of the query block is typically much smaller than that of the key-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally on each GPU and exchange smaller query blocks across GPUs. We also introduce an efficient activation recomputation technique enabling support for longer visual context. We theoretically analyze the communication benefits of LV-XAttn and show that it can achieve speedups for a wide range of models. Our evaluations with mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to 5.58$\times$ end-to-end speedup compared to existing approaches.</li>
</ul>

<h3>Title: Avoiding spurious sharpness minimization broadens applicability of SAM</h3>
<ul>
<li><strong>Authors: </strong>Sidak Pal Singh, Hossein Mobahi, Atish Agarwala, Yann Dauphin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02407">https://arxiv.org/abs/2502.02407</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02407">https://arxiv.org/pdf/2502.02407</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02407]] Avoiding spurious sharpness minimization broadens applicability of SAM(https://arxiv.org/abs/2502.02407)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks. However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget. We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself. We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation. Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements. Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale). On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs).</li>
</ul>

<h3>Title: Extending SEEDS to a Supervoxel Algorithm for Medical Image Analysis</h3>
<ul>
<li><strong>Authors: </strong>Chenhui Zhao, Yan Jiang, Todd C. Hollon</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02409">https://arxiv.org/abs/2502.02409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02409">https://arxiv.org/pdf/2502.02409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02409]] Extending SEEDS to a Supervoxel Algorithm for Medical Image Analysis(https://arxiv.org/abs/2502.02409)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>In this work, we extend the SEEDS superpixel algorithm from 2D images to 3D volumes, resulting in 3D SEEDS, a faster, better, and open-source supervoxel algorithm for medical image analysis. We compare 3D SEEDS with the widely used supervoxel algorithm SLIC on 13 segmentation tasks across 10 organs. 3D SEEDS accelerates supervoxel generation by a factor of 10, improves the achievable Dice score by +6.5%, and reduces the under-segmentation error by -0.16%. The code is available at this https URL</li>
</ul>

<h3>Title: Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Jan Schuchardt, Mina Dalirrooyfard, Jed Guzelkabaagac, Anderson Schneider, Yuriy Nevmyvaka, Stephan G√ºnnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02410">https://arxiv.org/abs/2502.02410</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02410">https://arxiv.org/pdf/2502.02410</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02410]] Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting(https://arxiv.org/abs/2502.02410)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy</a></li>
<li><strong>Abstract: </strong>Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees.</li>
</ul>

<h3>Title: Towards Fast Graph Generation via Autoregressive Noisy Filtration Modeling</h3>
<ul>
<li><strong>Authors: </strong>Markus Krimmel, Jenna Wiens, Karsten Borgwardt, Dexiong Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02415">https://arxiv.org/abs/2502.02415</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02415">https://arxiv.org/pdf/2502.02415</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02415]] Towards Fast Graph Generation via Autoregressive Noisy Filtration Modeling(https://arxiv.org/abs/2502.02415)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Graph generative models often face a critical trade-off between learning complex distributions and achieving fast generation speed. We introduce Autoregressive Noisy Filtration Modeling (ANFM), a novel approach that addresses both challenges. ANFM leverages filtration, a concept from topological data analysis, to transform graphs into short sequences of monotonically increasing subgraphs. This formulation extends the sequence families used in previous autoregressive models. To learn from these sequences, we propose a novel autoregressive graph mixer model. Our experiments suggest that exposure bias might represent a substantial hurdle in autoregressive graph generation and we introduce two mitigation strategies to address it: noise augmentation and a reinforcement learning approach. Incorporating these techniques leads to substantial performance gains, making ANFM competitive with state-of-the-art diffusion models across diverse synthetic and real-world datasets. Notably, ANFM produces remarkably short sequences, achieving a 100-fold speedup in generation time compared to diffusion models. This work marks a significant step toward high-throughput graph generation.</li>
</ul>

<h3>Title: CVKAN: Complex-Valued Kolmogorov-Arnold Networks</h3>
<ul>
<li><strong>Authors: </strong>Matthias Wolff, Florian Eilers, Xiaoyi Jiang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02417">https://arxiv.org/abs/2502.02417</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02417">https://arxiv.org/pdf/2502.02417</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02417]] CVKAN: Complex-Valued Kolmogorov-Arnold Networks(https://arxiv.org/abs/2502.02417)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability</a></li>
<li><strong>Abstract: </strong>In this work we propose CKAN, a complex-valued KAN, to join the intrinsic interpretability of KANs and the advantages of Complex-Valued Neural Networks (CVNNs). We show how to transfer a KAN and the necessary associated mechanisms into the complex domain. To confirm that CKAN meets expectations we conduct experiments on symbolic complex-valued function fitting and physically meaningful formulae as well as on a more realistic dataset from knot theory. Our proposed CKAN is more stable and performs on par or better than real-valued KANs while requiring less parameters and a shallower network architecture, making it more explainable.</li>
</ul>

<h3>Title: Activation-Informed Merging of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Amin Heyrani Nobari, Kaveh Alimohammadi, Ali ArjomandBigdeli, Akash Srivastava, Faez Ahmed, Navid Azizan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02421">https://arxiv.org/abs/2502.02421</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02421">https://arxiv.org/pdf/2502.02421</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02421]] Activation-Informed Merging of Large Language Models(https://arxiv.org/abs/2502.02421)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, large language model</a></li>
<li><strong>Abstract: </strong>Model merging, a method that combines the parameters and embeddings of multiple fine-tuned large language models (LLMs), offers a promising approach to enhance model performance across various tasks while maintaining computational efficiency. This paper introduces Activation-Informed Merging (AIM), a technique that integrates the information from the activation space of LLMs into the merging process to improve performance and robustness. AIM is designed as a flexible, complementary solution that is applicable to any existing merging method. It aims to preserve critical weights from the base model, drawing on principles from continual learning~(CL) and model compression. Utilizing a task-agnostic calibration set, AIM selectively prioritizes essential weights during merging. We empirically demonstrate that AIM significantly enhances the performance of merged models across multiple benchmarks. Our findings suggest that considering the activation-space information can provide substantial advancements in the model merging strategies for LLMs with up to 40\% increase in benchmark performance.</li>
</ul>

<h3>Title: TransformDAS: Mapping {\Phi}-OTDR Signals to Riemannian Manifold for Robust Classification</h3>
<ul>
<li><strong>Authors: </strong>Jiaju Kang, Puyu Han, Yang Chun, Xu Wang, Luqi Gong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02428">https://arxiv.org/abs/2502.02428</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02428">https://arxiv.org/pdf/2502.02428</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02428]] TransformDAS: Mapping {\Phi}-OTDR Signals to Riemannian Manifold for Robust Classification(https://arxiv.org/abs/2502.02428)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer, generative</a></li>
<li><strong>Abstract: </strong>Phase-sensitive optical time-domain reflectometry ({\Phi}-OTDR) is a widely used distributed fiber optic sensing system in engineering. Machine learning algorithms for {\Phi}-OTDR event classification require high volumes and quality of datasets; however, high-quality datasets are currently extremely scarce in the field, leading to a lack of robustness in models, which is manifested by higher false alarm rates in real-world scenarios. One promising approach to address this issue is to augment existing data using generative models combined with a small amount of real-world data. We explored mapping both {\Phi}-OTDR features in a GAN-based generative pipeline and signal features in a Transformer classifier to hyperbolic space to seek more effective model generalization. The results indicate that state-of-the-art models exhibit stronger generalization performance and lower false alarm rates in real-world scenarios when trained on augmented datasets. TransformDAS, in particular, demonstrates the best classification performance, highlighting the benefits of Riemannian manifold mapping in {\Phi}-OTDR data generation and model classification.</li>
</ul>

<h3>Title: Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment</h3>
<ul>
<li><strong>Authors: </strong>Yaling Shen, Zhixiong Zhuang, Kun Yuan, Maria-Irina Nicolae, Nassir Navab, Nicolas Padoy, Mario Fritz</a></li>
<li><strong>Subjects: </strong>cs.CR, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02438">https://arxiv.org/abs/2502.02438</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02438">https://arxiv.org/pdf/2502.02438</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02438]] Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment(https://arxiv.org/abs/2502.02438)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, protect, attack, steal, large language model</a></li>
<li><strong>Abstract: </strong>Medical multimodal large language models (MLLMs) are becoming an instrumental part of healthcare systems, assisting medical personnel with decision making and results analysis. Models for radiology report generation are able to interpret medical imagery, thus reducing the workload of radiologists. As medical data is scarce and protected by privacy regulations, medical MLLMs represent valuable intellectual property. However, these assets are potentially vulnerable to model stealing, where attackers aim to replicate their functionality via black-box access. So far, model stealing for the medical domain has focused on classification; however, existing attacks are not effective against MLLMs. In this paper, we introduce Adversarial Domain Alignment (ADA-STEAL), the first stealing attack against medical MLLMs. ADA-STEAL relies on natural images, which are public and widely available, as opposed to their medical counterparts. We show that data augmentation with adversarial noise is sufficient to overcome the data distribution gap between natural images and the domain-specific distribution of the victim MLLM. Experiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that Adversarial Domain Alignment enables attackers to steal the medical MLLM without any access to medical data.</li>
</ul>

<h3>Title: Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haoran Ye, Tianze Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02444">https://arxiv.org/abs/2502.02444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02444">https://arxiv.org/pdf/2502.02444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02444]] Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models(https://arxiv.org/abs/2502.02444)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, large language model</a></li>
<li><strong>Abstract: </strong>Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics. Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values. Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored. This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems. Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs. For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge AI priorities. Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values.</li>
</ul>

<h3>Title: Sparse Data Generation Using Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Phil Ostheimer, Mayank Nagda, Marius Kloft, Sophie Fellenz</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02448">https://arxiv.org/abs/2502.02448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02448">https://arxiv.org/pdf/2502.02448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02448]] Sparse Data Generation Using Diffusion Models(https://arxiv.org/abs/2502.02448)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Sparse data is ubiquitous, appearing in numerous domains, from economics and recommender systems to astronomy and biomedical sciences. However, efficiently and realistically generating sparse data remains a significant challenge. We introduce Sparse Data Diffusion (SDD), a novel method for generating sparse data. SDD extends continuous state-space diffusion models by explicitly modeling sparsity through the introduction of Sparsity Bits. Empirical validation on image data from various domains-including two scientific applications, physics and biology-demonstrates that SDD achieves high fidelity in representing data sparsity while preserving the quality of the generated data.</li>
</ul>

<h3>Title: TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes</h3>
<ul>
<li><strong>Authors: </strong>Xingcheng Zhou, Konstantinos Larintzakis, Hao Guo, Walter Zimmer, Mingyu Liu, Hu Cao, Jiajie Zhang, Venkatnarayanan Lakshminarasimhan, Leah Strand, Alois C. Knoll</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02449">https://arxiv.org/abs/2502.02449</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02449">https://arxiv.org/pdf/2502.02449</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02449]] TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes(https://arxiv.org/abs/2502.02449)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We present TUMTraffic-VideoQA, a novel dataset and benchmark designed for spatio-temporal video understanding in complex roadside traffic scenarios. The dataset comprises 1,000 videos, featuring 85,000 multiple-choice QA pairs, 2,300 object captioning, and 5,700 object grounding annotations, encompassing diverse real-world conditions such as adverse weather and traffic anomalies. By incorporating tuple-based spatio-temporal object expressions, TUMTraffic-VideoQA unifies three essential tasks-multiple-choice video question answering, referred object captioning, and spatio-temporal object grounding-within a cohesive evaluation framework. We further introduce the TUMTraffic-Qwen baseline model, enhanced with visual token sampling strategies, providing valuable insights into the challenges of fine-grained spatio-temporal reasoning. Extensive experiments demonstrate the dataset's complexity, highlight the limitations of existing models, and position TUMTraffic-VideoQA as a robust foundation for advancing research in intelligent transportation systems. The dataset and benchmark are publicly available to facilitate further exploration.</li>
</ul>

<h3>Title: Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study</h3>
<ul>
<li><strong>Authors: </strong>Calvin Yixiang Cheng, Scott A Hale</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02451">https://arxiv.org/abs/2502.02451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02451">https://arxiv.org/pdf/2502.02451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02451]] Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study(https://arxiv.org/abs/2502.02451)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>This study explores computational approaches for measuring moral foundations (MFs) in non-English corpora. Since most resources are developed primarily for English, cross-linguistic applications of moral foundation theory remain limited. Using Chinese as a case study, this paper evaluates the effectiveness of applying English resources to machine translated text, local language lexicons, multilingual language models, and large language models (LLMs) in measuring MFs in non-English texts. The results indicate that machine translation and local lexicon approaches are insufficient for complex moral assessments, frequently resulting in a substantial loss of cultural information. In contrast, multilingual models and LLMs demonstrate reliable cross-language performance with transfer learning, with LLMs excelling in terms of data efficiency. Importantly, this study also underscores the need for human-in-the-loop validation of automated MF assessment, as the most advanced models may overlook cultural nuances in cross-language measurements. The findings highlight the potential of LLMs for cross-language MF measurements and other complex multilingual deductive coding tasks.</li>
</ul>

<h3>Title: IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning</h3>
<ul>
<li><strong>Authors: </strong>Quan Zhang, Yuxin Qi, Xi Tang, Jinwei Fang, Xi Lin, Ke Zhang, Chun Yuan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02454">https://arxiv.org/abs/2502.02454</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02454">https://arxiv.org/pdf/2502.02454</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02454]] IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning(https://arxiv.org/abs/2502.02454)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Using extensive training data from SA-1B, the Segment Anything Model (SAM) has demonstrated exceptional generalization and zero-shot capabilities, attracting widespread attention in areas such as medical image segmentation and remote sensing image segmentation. However, its performance in the field of image manipulation detection remains largely unexplored and unconfirmed. There are two main challenges in applying SAM to image manipulation detection: a) reliance on manual prompts, and b) the difficulty of single-view information in supporting cross-dataset generalization. To address these challenges, we develops a cross-view prompt learning paradigm called IMDPrompter based on SAM. Benefiting from the design of automated prompts, IMDPrompter no longer relies on manual guidance, enabling automated detection and localization. Additionally, we propose components such as Cross-view Feature Perception, Optimal Prompt Selection, and Cross-View Prompt Consistency, which facilitate cross-view perceptual learning and guide SAM to generate accurate masks. Extensive experimental results from five datasets (CASIA, Columbia, Coverage, IMD2020, and NIST16) validate the effectiveness of our proposed method.</li>
</ul>

<h3>Title: SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency</h3>
<ul>
<li><strong>Authors: </strong>Qianhao Yuan, Yanjiang Liu, Yaojie Lu, Hongyu Lin, Ben He, Xianpei Han, Le Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02458">https://arxiv.org/abs/2502.02458</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02458">https://arxiv.org/pdf/2502.02458</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02458]] SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency(https://arxiv.org/abs/2502.02458)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models (MLLMs) mainly fall into two architectures, each involving a trade-off between training and inference efficiency: embedding space alignment (e.g., LLaVA-1.5) is inefficient during inference, while cross-attention space alignment (e.g., Flamingo) is inefficient in training. In this paper, we compare these two architectures and identify the key factors for building efficient MLLMs. A primary difference between them lies in how attention is applied to visual tokens, particularly in their interactions with each other. To investigate whether attention among visual tokens is necessary, we propose a new self-attention mechanism, NAAViT (\textbf{N}o \textbf{A}ttention \textbf{A}mong \textbf{Vi}sual \textbf{T}okens), which eliminates this type of attention. Our pilot experiment on LLaVA-1.5 shows that attention among visual tokens is highly redundant. Based on these insights, we introduce SAISA (\textbf{S}elf-\textbf{A}ttention \textbf{I}nput \textbf{S}pace \textbf{A}lignment), a novel architecture that enhance both training and inference efficiency. SAISA directly aligns visual features with the input spaces of NAAViT self-attention blocks, reducing computational overhead in both self-attention blocks and feed-forward networks (FFNs). Using the same configuration as LLaVA-1.5, SAISA reduces inference FLOPs by 66\% and training budget by 26\%, while achieving superior performance in terms of accuracy. Comprehensive ablation studies further validate the effectiveness of SAISA across various LLMs and visual encoders. The code and model will be publicly available at this https URL.</li>
</ul>

<h3>Title: Towards Consistent and Controllable Image Synthesis for Face Editing</h3>
<ul>
<li><strong>Authors: </strong>Mengting Wei, Tuomas Varanka, Yante Li, Xingxun Jiang, Huai-Qian Khor, Guoying Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02465">https://arxiv.org/abs/2502.02465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02465">https://arxiv.org/pdf/2502.02465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02465]] Towards Consistent and Controllable Image Synthesis for Face Editing(https://arxiv.org/abs/2502.02465)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Current face editing methods mainly rely on GAN-based techniques, but recent focus has shifted to diffusion-based models due to their success in image reconstruction. However, diffusion models still face challenges in manipulating fine-grained attributes and preserving consistency of attributes that should remain unchanged. To address these issues and facilitate more convenient editing of face images, we propose a novel approach that leverages the power of Stable-Diffusion models and crude 3D face models to control the lighting, facial expression and head pose of a portrait photo. We observe that this task essentially involve combinations of target background, identity and different face attributes. We aim to sufficiently disentangle the control of these factors to enable high-quality of face editing. Specifically, our method, coined as RigFace, contains: 1) A Spatial Arrtibute Encoder that provides presise and decoupled conditions of background, pose, expression and lighting; 2) An Identity Encoder that transfers identity features to the denoising UNet of a pre-trained Stable-Diffusion model; 3) An Attribute Rigger that injects those conditions into the denoising UNet. Our model achieves comparable or even superior performance in both identity preservation and photorealism compared to existing face editing models.</li>
</ul>

<h3>Title: Modular Training of Neural Networks aids Interpretability</h3>
<ul>
<li><strong>Authors: </strong>Satvik Golechha, Maheep Chaudhary, Joan Velja, Alessandro Abate, Nandi Schoots</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02470">https://arxiv.org/abs/2502.02470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02470">https://arxiv.org/pdf/2502.02470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02470]] Modular Training of Neural Networks aids Interpretability(https://arxiv.org/abs/2502.02470)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, transformer</a></li>
<li><strong>Abstract: </strong>An approach to improve neural network interpretability is via clusterability, i.e., splitting a model into disjoint clusters that can be studied independently. We define a measure for clusterability and show that pre-trained models form highly enmeshed clusters via spectral graph clustering. We thus train models to be more modular using a ``clusterability loss'' function that encourages the formation of non-interacting clusters. Using automated interpretability techniques, we show that our method can help train models that are more modular and learn different, disjoint, and smaller circuits. We investigate CNNs trained on MNIST and CIFAR, small transformers trained on modular addition, and language models. Our approach provides a promising direction for training neural networks that learn simpler functions and are easier to interpret.</li>
</ul>

<h3>Title: Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification</h3>
<ul>
<li><strong>Authors: </strong>Valentina Vadori, Antonella Peruffo, Jean-Marie Gra√Øc, Livio Finos, Enrico Grisan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02471">https://arxiv.org/abs/2502.02471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02471">https://arxiv.org/pdf/2502.02471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02471]] Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification(https://arxiv.org/abs/2502.02471)</code><input type="text"></li>
<li><strong>Keywords: </strong>extraction, transformer, segmentation</a></li>
<li><strong>Abstract: </strong>Recent advancements in foundation models have transformed computer vision, driving significant performance improvements across diverse domains, including digital histopathology. However, the advantages of domain-specific histopathology foundation models over general-purpose models for specialized tasks such as cell analysis remain underexplored. This study investigates the representation learning gap between these two categories by analyzing multi-level patch embeddings applied to cell instance segmentation and classification. We implement an encoder-decoder architecture with a consistent decoder and various encoders. These include convolutional, vision transformer (ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M, representing general-purpose foundation models. These are compared against ViT encoders from the recently released UNI, Virchow2, and Prov-GigaPath foundation models, trained on patches extracted from hundreds of thousands of histopathology whole-slide images. The decoder integrates patch embeddings from different encoder depths via skip connections to generate semantic and distance maps. These maps are then post-processed to create instance segmentation masks where each label corresponds to an individual cell and to perform cell-type classification. All encoders remain frozen during training to assess their pre-trained feature extraction capabilities. Using the PanNuke and CoNIC histopathology datasets, and the newly introduced Nissl-stained CytoDArk0 dataset for brain cytoarchitecture studies, we evaluate instance-level detection, segmentation accuracy, and cell-type classification. This study provides insights into the comparative strengths and limitations of general-purpose vs. histopathology foundation models, offering guidance for model selection in cell-focused histopathology and brain cytoarchitecture analysis workflows.</li>
</ul>

<h3>Title: Stable Port-Hamiltonian Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Fabian J. Roth, Dominik K. Klein, Maximilian Kannapinn, Jan Peters, Oliver Weeger</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02480">https://arxiv.org/abs/2502.02480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02480">https://arxiv.org/pdf/2502.02480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02480]] Stable Port-Hamiltonian Neural Networks(https://arxiv.org/abs/2502.02480)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>In recent years, nonlinear dynamic system identification using artificial neural networks has garnered attention due to its manifold potential applications in virtually all branches of science and engineering. However, purely data-driven approaches often struggle with extrapolation and may yield physically implausible forecasts. Furthermore, the learned dynamics can exhibit instabilities, making it difficult to apply such models safely and robustly. This article proposes stable port-Hamiltonian neural networks, a machine learning architecture that incorporates the physical biases of energy conservation or dissipation while guaranteeing global Lyapunov stability of the learned dynamics. Evaluations with illustrative examples and real-world measurement data demonstrate the model's ability to generalize from sparse data, outperforming purely data-driven approaches and avoiding instability issues. In addition, the model's potential for data-driven surrogate modeling is highlighted in application to multi-physics simulation data.</li>
</ul>

<h3>Title: Multilingual Machine Translation with Open Large Language Models at Practical Scale: An Empirical Study</h3>
<ul>
<li><strong>Authors: </strong>Menglong Cui, Pengzhi Gao, Wei Liu, Jian Luan, BinWang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02481">https://arxiv.org/abs/2502.02481</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02481">https://arxiv.org/pdf/2502.02481</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02481]] Multilingual Machine Translation with Open Large Language Models at Practical Scale: An Empirical Study(https://arxiv.org/abs/2502.02481)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown continuously improving multilingual capabilities, and even small-scale open-source models have demonstrated rapid performance enhancement. In this paper, we systematically explore the abilities of open LLMs with less than ten billion parameters to handle multilingual machine translation (MT) tasks. We conduct comprehensive evaluations on six popular LLMs and find that models like Gemma2-9B exhibit impressive multilingual translation capabilities. We then introduce the Parallel-First Monolingual-Second (PFMS) data mixing strategy in the continual pretraining stage to further enhance the MT performance and present GemmaX2-28, a 9B model achieving top-tier multilingual translation performance across 28 languages. Specifically, GemmaX2-28 consistently outperforms the state-of-the-art (SOTA) models such as TowerInstruct and XALMA and achieves competitive performance with Google Translate and GPT-4-turbo.</li>
</ul>

<h3>Title: Distributional Diffusion Models with Scoring Rules</h3>
<ul>
<li><strong>Authors: </strong>Valentin De Bortoli, Alexandre Galashov, J. Swaroop Guntupalli, Guangyao Zhou, Kevin Murphy, Arthur Gretton, Arnaud Doucet</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02483">https://arxiv.org/abs/2502.02483</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02483">https://arxiv.org/pdf/2502.02483</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02483]] Distributional Diffusion Models with Scoring Rules(https://arxiv.org/abs/2502.02483)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted. The corresponding reverse process progressively "denoises" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to accomplish sample generation by learning the posterior {\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule. We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps.</li>
</ul>

<h3>Title: Do Graph Diffusion Models Accurately Capture and Generate Substructure Distributions?</h3>
<ul>
<li><strong>Authors: </strong>Xiyuan Wang, Yewei Liu, Lexi Pang, Siwei Chen, Muhan Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02488">https://arxiv.org/abs/2502.02488</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02488">https://arxiv.org/pdf/2502.02488</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02488]] Do Graph Diffusion Models Accurately Capture and Generate Substructure Distributions?(https://arxiv.org/abs/2502.02488)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, transformer</a></li>
<li><strong>Abstract: </strong>Diffusion models have gained popularity in graph generation tasks; however, the extent of their expressivity concerning the graph distributions they can learn is not fully understood. Unlike models in other domains, popular backbones for graph diffusion models, such as Graph Transformers, do not possess universal expressivity to accurately model the distribution scores of complex graph data. Our work addresses this limitation by focusing on the frequency of specific substructures as a key characteristic of target graph distributions. When evaluating existing models using this metric, we find that they fail to maintain the distribution of substructure counts observed in the training set when generating new graphs. To address this issue, we establish a theoretical connection between the expressivity of Graph Neural Networks (GNNs) and the overall performance of graph diffusion models, demonstrating that more expressive GNN backbones can better capture complex distribution patterns. By integrating advanced GNNs into the backbone architecture, we achieve significant improvements in substructure generation.</li>
</ul>

<h3>Title: A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Edward Ellis, Andrew Bulpitt, Nasim Parsa, Michael F Byrne, Sharib Ali</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02489">https://arxiv.org/abs/2502.02489</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02489">https://arxiv.org/pdf/2502.02489</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02489]] A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation(https://arxiv.org/abs/2502.02489)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>Ultrasound (US) imaging is clinically invaluable due to its noninvasive and safe nature. However, interpreting US images is challenging, requires significant expertise, and time, and is often prone to errors. Deep learning offers assistive solutions such as segmentation. Supervised methods rely on large, high-quality, and consistently labeled datasets, which are challenging to curate. Moreover, these methods tend to underperform on out-of-distribution data, limiting their clinical utility. Self-supervised learning (SSL) has emerged as a promising alternative, leveraging unlabeled data to enhance model performance and generalisability. We introduce a contrastive SSL approach tailored for B-mode US images, incorporating a novel Relation Contrastive Loss (RCL). RCL encourages learning of distinct features by differentiating positive and negative sample pairs through a learnable metric. Additionally, we propose spatial and frequency-based augmentation strategies for the representation learning on US images. Our approach significantly outperforms traditional supervised segmentation methods across three public breast US datasets, particularly in data-limited scenarios. Notable improvements on the Dice similarity metric include a 4% increase on 20% and 50% of the BUSI dataset, nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4% and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively. Furthermore, we demonstrate superior generalisability on the out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6% compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST training data, respectively. Our research highlights that domain-inspired SSL can improve US segmentation, especially under data-limited conditions.</li>
</ul>

<h3>Title: VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models</h3>
<ul>
<li><strong>Authors: </strong>Hila Chefer, Uriel Singer, Amit Zohar, Yuval Kirstain, Adam Polyak, Yaniv Taigman, Lior Wolf, Shelly Sheynin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02492">https://arxiv.org/abs/2502.02492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02492">https://arxiv.org/pdf/2502.02492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02492]] VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models(https://arxiv.org/abs/2502.02492)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Despite tremendous recent progress, generative video models still struggle to capture real-world motion, dynamics, and physics. We show that this limitation arises from the conventional pixel reconstruction objective, which biases models toward appearance fidelity at the expense of motion coherence. To address this, we introduce VideoJAM, a novel framework that instills an effective motion prior to video generators, by encouraging the model to learn a joint appearance-motion representation. VideoJAM is composed of two complementary units. During training, we extend the objective to predict both the generated pixels and their corresponding motion from a single learned representation. During inference, we introduce Inner-Guidance, a mechanism that steers the generation toward coherent motion by leveraging the model's own evolving motion prediction as a dynamic guidance signal. Notably, our framework can be applied to any video model with minimal adaptations, requiring no modifications to the training data or scaling of the model. VideoJAM achieves state-of-the-art performance in motion coherence, surpassing highly competitive proprietary models while also enhancing the perceived visual quality of the generations. These findings emphasize that appearance and motion can be complementary and, when effectively integrated, enhance both the visual quality and the coherence of video generation. Project website: this https URL</li>
</ul>

<h3>Title: EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization</h3>
<ul>
<li><strong>Authors: </strong>Yize Wu, Ke Gao, Yanjun Wu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02493">https://arxiv.org/abs/2502.02493</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02493">https://arxiv.org/pdf/2502.02493</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02493]] EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization(https://arxiv.org/abs/2502.02493)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Speculative decoding is an effective and lossless method for Large Language Model (LLM) inference acceleration. It employs a smaller model to generate a draft token sequence, which is then verified by the original base model. In multi-GPU systems, inference latency can be further reduced through tensor parallelism (TP), while the optimal TP size of the draft model is typically smaller than that of the base model, leading to GPU idling during the drafting stage. To solve this problem, we propose EasySpec, a layer-parallel speculation strategy that optimizes the efficiency of multi-GPU this http URL breaks the sequential execution order of layers in the drafting model, enabling multi-layer parallelization across devices, albeit with some induced approximation errors. After each drafting-and-verification iteration, the draft model's key-value (KV) cache is calibrated in a single forward pass, preventing long-term error accumulation at minimal additional latency. We evaluated EasySpec on several mainstream open-source LLMs, using smaller versions of models from the same series as drafters. The results demonstrate that EasySpec can achieve a peak speedup of 4.17x compared to vanilla decoding, while preserving the original distribution of the base LLMs. Specifically, the drafting stage can be accelerated by up to 1.62x with a maximum accuracy drop of only 7%, requiring no training or fine-tuning on the draft models.</li>
</ul>

<h3>Title: Learning to generate physical ocean states: Towards hybrid climate modeling</h3>
<ul>
<li><strong>Authors: </strong>Etienne Meunier, David Kamm, Guillaume Gachon, Redouane Lguensat, Julie Deshayes</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02499">https://arxiv.org/abs/2502.02499</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02499">https://arxiv.org/pdf/2502.02499</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02499]] Learning to generate physical ocean states: Towards hybrid climate modeling(https://arxiv.org/abs/2502.02499)</code><input type="text"></li>
<li><strong>Keywords: </strong>interpretability, generative</a></li>
<li><strong>Abstract: </strong>Ocean General Circulation Models require extensive computational resources to reach equilibrium states, while deep learning emulators, despite offering fast predictions, lack the physical interpretability and long-term stability necessary for climate scientists to understand climate sensitivity (to greenhouse gas emissions) and mechanisms of abrupt % variability such as tipping points. We propose to take the best from both worlds by leveraging deep generative models to produce physically consistent oceanic states that can serve as initial conditions for climate projections. We assess the viability of this hybrid approach through both physical metrics and numerical experiments, and highlight the benefits of enforcing physical constraints during generation. Although we train here on ocean variables from idealized numerical simulations, we claim that this hybrid approach, combining the computational efficiency of deep learning with the physical accuracy of numerical models, can effectively reduce the computational burden of running climate models to equilibrium, and reduce uncertainties in climate projections by minimizing drifts in baseline simulations.</li>
</ul>

<h3>Title: Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction</h3>
<ul>
<li><strong>Authors: </strong>Ruochen Li, Tanqiu Qiao, Stamos Katsigiannis, Zhanxing Zhu, Hubert P. H. Shum</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02504">https://arxiv.org/abs/2502.02504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02504">https://arxiv.org/pdf/2502.02504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02504]] Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction(https://arxiv.org/abs/2502.02504)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer</a></li>
<li><strong>Abstract: </strong>Pedestrian trajectory prediction aims to forecast future movements based on historical paths. Spatial-temporal (ST) methods often separately model spatial interactions among pedestrians and temporal dependencies of individuals. They overlook the direct impacts of interactions among different pedestrians across various time steps (i.e., high-order cross-time interactions). This limits their ability to capture ST inter-dependencies and hinders prediction performance. To address these limitations, we propose UniEdge with three major designs. Firstly, we introduce a unified ST graph data structure that simplifies high-order cross-time interactions into first-order relationships, enabling the learning of ST inter-dependencies in a single step. This avoids the information loss caused by multi-step aggregation. Secondly, traditional GNNs focus on aggregating pedestrian node features, neglecting the propagation of implicit interaction patterns encoded in edge features. We propose the Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph network that jointly models explicit N2N social interactions among pedestrians and implicit E2E influence propagation across these interaction patterns. Finally, to overcome the limited receptive fields and challenges in capturing long-range dependencies of auto-regressive architectures, we introduce a transformer encoder-based predictor that enables global modeling of temporal correlation. UniEdge outperforms state-of-the-arts on multiple datasets, including ETH, UCY, and SDD.</li>
</ul>

<h3>Title: Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search</h3>
<ul>
<li><strong>Authors: </strong>Maohao Shen, Guangtao Zeng, Zhenting Qi, Zhang-Wei Hong, Zhenfang Chen, Wei Lu, Gregory Wornell, Subhro Das, David Cox, Chuang Gan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02508">https://arxiv.org/abs/2502.02508</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02508">https://arxiv.org/pdf/2502.02508</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02508]] Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search(https://arxiv.org/abs/2502.02508)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated remarkable reasoning capabilities across diverse domains. Recent studies have shown that increasing test-time computation enhances LLMs' reasoning capabilities. This typically involves extensive sampling at inference time guided by an external LLM verifier, resulting in a two-player system. Despite external guidance, the effectiveness of this system demonstrates the potential of a single LLM to tackle complex tasks. Thus, we pose a new research problem: Can we internalize the searching capabilities to fundamentally enhance the reasoning abilities of a single LLM? This work explores an orthogonal direction focusing on post-training LLMs for autoregressive searching (i.e., an extended reasoning process with self-reflection and self-exploration of new strategies). To achieve this, we propose the Chain-of-Action-Thought (COAT) reasoning and a two-stage training paradigm: 1) a small-scale format tuning stage to internalize the COAT reasoning format and 2) a large-scale self-improvement stage leveraging reinforcement learning. Our approach results in Satori, a 7B LLM trained on open-source models and data. Extensive empirical evaluations demonstrate that Satori achieves state-of-the-art performance on mathematical reasoning benchmarks while exhibits strong generalization to out-of-domain tasks. Code, data, and models will be fully open-sourced.</li>
</ul>

<h3>Title: Generative Modeling on Lie Groups via Euclidean Generalized Score Matching</h3>
<ul>
<li><strong>Authors: </strong>Marco Bertolini, Tuan Le, Djork-Arn√© Clevert</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02513">https://arxiv.org/abs/2502.02513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02513">https://arxiv.org/pdf/2502.02513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02513]] Generative Modeling on Lie Groups via Euclidean Generalized Score Matching(https://arxiv.org/abs/2502.02513)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>We extend Euclidean score-based diffusion processes to generative modeling on Lie groups. Through the formalism of Generalized Score Matching, our approach yields a Langevin dynamics which decomposes as a direct sum of Lie algebra representations, enabling generative processes on Lie groups while operating in Euclidean space. Unlike equivariant models, which restrict the space of learnable functions by quotienting out group orbits, our method can model any target distribution on any (non-Abelian) Lie group. Standard score matching emerges as a special case of our framework when the Lie group is the translation group. We prove that our generalized generative processes arise as solutions to a new class of paired stochastic differential equations (SDEs), introduced here for the first time. We validate our approach through experiments on diverse data types, demonstrating its effectiveness in real-world applications such as SO(3)-guided molecular conformer generation and modeling ligand-specific global SE(3) transformations for molecular docking, showing improvement in comparison to Riemannian diffusion on the group itself. We show that an appropriate choice of Lie group enhances learning efficiency by reducing the effective dimensionality of the trajectory space and enables the modeling of transitions between complex data distributions. Additionally, we demonstrate the universality of our approach by deriving how it extends to flow matching.</li>
</ul>

<h3>Title: Privacy Attacks on Image AutoRegressive Models</h3>
<ul>
<li><strong>Authors: </strong>Antoni Kowalczuk, Jan Dubi≈Ñski, Franziska Boenisch, Adam Dziedzic</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02514">https://arxiv.org/abs/2502.02514</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02514">https://arxiv.org/pdf/2502.02514</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02514]] Privacy Attacks on Image AutoRegressive Models(https://arxiv.org/abs/2502.02514)</code><input type="text"></li>
<li><strong>Keywords: </strong>privacy, attack, membership infer, diffusion</a></li>
<li><strong>Abstract: </strong>Image autoregressive (IAR) models have surpassed diffusion models (DMs) in both image quality (FID: 1.48 vs. 1.58) and generation speed. However, their privacy risks remain largely unexplored. To address this, we conduct a comprehensive privacy analysis comparing IARs to DMs. We develop a novel membership inference attack (MIA) that achieves a significantly higher success rate in detecting training images (TPR@FPR=1%: 86.38% for IARs vs. 4.91% for DMs). Using this MIA, we perform dataset inference (DI) and find that IARs require as few as six samples to detect dataset membership, compared to 200 for DMs, indicating higher information leakage. Additionally, we extract hundreds of training images from an IAR (e.g., 698 from VAR-d30). Our findings highlight a fundamental privacy-utility trade-off: while IARs excel in generation quality and speed, they are significantly more vulnerable to privacy attacks. This suggests that incorporating techniques from DMs, such as per-token probability modeling using diffusion, could help mitigate IARs' privacy risks. Our code is available at this https URL.</li>
</ul>

<h3>Title: Brief analysis of DeepSeek R1 and it's implications for Generative AI</h3>
<ul>
<li><strong>Authors: </strong>Sarah Mercer, Samuel Spillard, Daniel P. Martin</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02523">https://arxiv.org/abs/2502.02523</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02523">https://arxiv.org/pdf/2502.02523</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02523]] Brief analysis of DeepSeek R1 and it's implications for Generative AI(https://arxiv.org/abs/2502.02523)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In late January 2025, DeepSeek released their new reasoning model (DeepSeek R1); which was developed at a fraction of the cost yet remains competitive with OpenAI's models, despite the US's GPU export ban. This report discusses the model, and what its release means for the field of Generative AI more widely. We briefly discuss other models released from China in recent weeks, their similarities; innovative use of Mixture of Experts (MoE), Reinforcement Learning (RL) and clever engineering appear to be key factors in the capabilities of these models. This think piece has been written to a tight time-scale, providing broad coverage of the topic, and serves as introductory material for those looking to understand the model's technical advancements, as well as it's place in the ecosystem. Several further areas of research are identified.</li>
</ul>

<h3>Title: Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation</h3>
<ul>
<li><strong>Authors: </strong>Jian Liu, Wei Sun, Hui Yang, Pengchao Deng, Chongpei Liu, Nicu Sebe, Hossein Rahmani, Ajmal Mian</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02525">https://arxiv.org/abs/2502.02525</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02525">https://arxiv.org/pdf/2502.02525</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02525]] Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation(https://arxiv.org/abs/2502.02525)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>Nine-degrees-of-freedom (9-DoF) object pose and size estimation is crucial for enabling augmented reality and robotic manipulation. Category-level methods have received extensive research attention due to their potential for generalization to intra-class unknown objects. However, these methods require manual collection and labeling of large-scale real-world training data. To address this problem, we introduce a diffusion-based paradigm for domain-generalized category-level 9-DoF object pose estimation. Our motivation is to leverage the latent generalization ability of the diffusion model to address the domain generalization challenge in object pose estimation. This entails training the model exclusively on rendered synthetic data to achieve generalization to real-world scenes. We propose an effective diffusion model to redefine 9-DoF object pose estimation from a generative perspective. Our model does not require any 3D shape priors during training or inference. By employing the Denoising Diffusion Implicit Model, we demonstrate that the reverse diffusion process can be executed in as few as 3 steps, achieving near real-time performance. Finally, we design a robotic grasping system comprising both hardware and software components. Through comprehensive experiments on two benchmark datasets and the real-world robotic system, we show that our method achieves state-of-the-art domain generalization performance. Our code will be made public at this https URL.</li>
</ul>

<h3>Title: Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies</h3>
<ul>
<li><strong>Authors: </strong>Han Zhou, Xingchen Wan, Ruoxi Sun, Hamid Palangi, Shariq Iqbal, Ivan Vuliƒá, Anna Korhonen, Sercan √ñ. Arƒ±k</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02533">https://arxiv.org/abs/2502.02533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02533">https://arxiv.org/pdf/2502.02533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02533]] Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies(https://arxiv.org/abs/2502.02533)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems.</li>
</ul>

<h3>Title: Adaptive Self-improvement LLM Agentic System for ML Library Development</h3>
<ul>
<li><strong>Authors: </strong>Genghan Zhang, Weixin Liang, Olivia Hsu, Kunle Olukotun</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02534">https://arxiv.org/abs/2502.02534</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02534">https://arxiv.org/pdf/2502.02534</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02534]] Adaptive Self-improvement LLM Agentic System for ML Library Development(https://arxiv.org/abs/2502.02534)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for experienced human programmers and 2) there are limited code examples because of the esoteric and evolving nature of ASPLs. Therefore, LLMs need complex reasoning with limited data in order to complete this task. To address these challenges, we introduce an adaptive self-improvement agentic system. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\times$ over a baseline single LLM.</li>
</ul>

<h3>Title: Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks</h3>
<ul>
<li><strong>Authors: </strong>Huiqun Huang, Cong Chen, Jean-Philippe Monteuuis, Jonathan Petit, Fei Miao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02537">https://arxiv.org/abs/2502.02537</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02537">https://arxiv.org/pdf/2502.02537</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02537]] Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks(https://arxiv.org/abs/2502.02537)</code><input type="text"></li>
<li><strong>Keywords: </strong>attack, robust</a></li>
<li><strong>Abstract: </strong>Collaborative Object Detection (COD) and collaborative perception can integrate data or features from various entities, and improve object detection accuracy compared with individual perception. However, adversarial attacks pose a potential threat to the deep learning COD models, and introduce high output uncertainty. With unknown attack models, it becomes even more challenging to improve COD resiliency and quantify the output uncertainty for highly dynamic perception scenes such as autonomous vehicles. In this study, we propose the Trusted Uncertainty Quantification in Collaborative Perception framework (TUQCP). TUQCP leverages both adversarial training and uncertainty quantification techniques to enhance the adversarial robustness of existing COD models. More specifically, TUQCP first adds perturbations to the shared information of randomly selected agents during object detection collaboration by adversarial training. TUQCP then alleviates the impacts of adversarial attacks by providing output uncertainty estimation through learning-based module and uncertainty calibration through conformal prediction. Our framework works for early and intermediate collaboration COD models and single-agent object detection models. We evaluate TUQCP on V2X-Sim, a comprehensive collaborative perception dataset for autonomous driving, and demonstrate a 80.41% improvement in object detection accuracy compared to the baselines under the same adversarial attacks. TUQCP demonstrates the importance of uncertainty quantification to COD under adversarial attacks.</li>
</ul>

<h3>Title: OVERTHINKING: Slowdown Attacks on Reasoning LLMs</h3>
<ul>
<li><strong>Authors: </strong>Abhinav Kumar, Jaechul Roh, Ali Naseh, Marzena Karpinska, Mohit Iyyer, Amir Houmansadr, Eugene Bagdasarian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02542">https://arxiv.org/abs/2502.02542</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02542">https://arxiv.org/pdf/2502.02542</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02542]] OVERTHINKING: Slowdown Attacks on Reasoning LLMs(https://arxiv.org/abs/2502.02542)</code><input type="text"></li>
<li><strong>Keywords: </strong>protect, defense, attack</a></li>
<li><strong>Abstract: </strong>We increase overhead for applications that rely on reasoning LLMs-we force models to spend an amplified number of reasoning tokens, i.e., "overthink", to respond to the user query while providing contextually correct answers. The adversary performs an OVERTHINK attack by injecting decoy reasoning problems into the public content that is used by the reasoning LLM (e.g., for RAG applications) during inference time. Due to the nature of our decoy problems (e.g., a Markov Decision Process), modified texts do not violate safety guardrails. We evaluated our attack across closed-(OpenAI o1, o1-mini, o3-mini) and open-(DeepSeek R1) weights reasoning models on the FreshQA and SQuAD datasets. Our results show up to 46x slowdown and high transferability of the attack across models. To protect applications, we discuss and implement defenses leveraging LLM-based and system design approaches. Finally, we discuss societal, financial, and energy impacts of OVERTHINK attack which could amplify the costs for third party applications operating reasoning models.</li>
</ul>

<h3>Title: Addressing Label Shift in Distributed Learning via Entropy Regularization</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wu, Changkyu Choi, Xiangcheng Cao, Volkan Cevher, Ali Ramezani-Kebrya</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02544">https://arxiv.org/abs/2502.02544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02544">https://arxiv.org/pdf/2502.02544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02544]] Addressing Label Shift in Distributed Learning via Entropy Regularization(https://arxiv.org/abs/2502.02544)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>We address the challenge of minimizing true risk in multi-node distributed learning. These systems are frequently exposed to both inter-node and intra-node label shifts, which present a critical obstacle to effectively optimizing model performance while ensuring that data remains confined to each node. To tackle this, we propose the Versatile Robust Label Shift (VRLS) method, which enhances the maximum likelihood estimation of the test-to-train label density ratio. VRLS incorporates Shannon entropy-based regularization and adjusts the density ratio during training to better handle label shifts at the test time. In multi-node learning environments, VRLS further extends its capabilities by learning and adapting density ratios across nodes, effectively mitigating label shifts and improving overall model performance. Experiments conducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness of VRLS, outperforming baselines by up to 20% in imbalanced settings. These results highlight the significant improvements VRLS offers in addressing label shifts. Our theoretical analysis further supports this by establishing high-probability bounds on estimation errors.</li>
</ul>

<h3>Title: Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Junha Lee, Chunghyun Park, Jaesung Choe, Yu-Chiang Frank Wang, Jan Kautz, Minsu Cho, Chris Choy</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02548">https://arxiv.org/abs/2502.02548</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02548">https://arxiv.org/pdf/2502.02548</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02548]] Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation(https://arxiv.org/abs/2502.02548)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>We tackle open-vocabulary 3D scene understanding by introducing a novel data generation pipeline and training framework. Our method addresses three critical requirements for effective training: precise 3D region segmentation, comprehensive textual descriptions, and sufficient dataset scale. By leveraging state-of-the-art open-vocabulary image segmentation models and region-aware Vision-Language Models, we develop an automatic pipeline that generates high-quality 3D mask-text pairs. Applying this pipeline to multiple 3D scene datasets, we create Mosaic3D-5.6M, a dataset of over 30K annotated scenes with 5.6M mask-text pairs, significantly larger than existing datasets. Building upon this data, we propose Mosaic3D, a foundation model combining a 3D encoder trained with contrastive learning and a lightweight mask decoder for open-vocabulary 3D semantic and instance segmentation. Our approach achieves state-of-the-art results on open-vocabulary 3D semantic and instance segmentation tasks including ScanNet200, Matterport3D, and ScanNet++, with ablation studies validating the effectiveness of our large-scale training data.</li>
</ul>

<h3>Title: Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for Microbiome Analysis</h3>
<ul>
<li><strong>Authors: </strong>Haonan Zhu, Andre R. Goncalves, Camilo Valdes, Hiranmayi Ranganathan, Boya Zhang, Jose Manuel Mart√≠, Car Reen Kok, Monica K. Borucki, Nisha J. Mulakken, James B. Thissen, Crystal Jaing, Alfred Hero, Nicholas A. Be</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM, stat.AP, stat.CO, stat.ME</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02552">https://arxiv.org/abs/2502.02552</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02552">https://arxiv.org/pdf/2502.02552</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02552]] Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for Microbiome Analysis(https://arxiv.org/abs/2502.02552)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust</a></li>
<li><strong>Abstract: </strong>This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks. We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution. We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile. Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods. Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks. Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics. Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results.</li>
</ul>

<h3>Title: Learning the RoPEs: Better 2D and 3D Position Encodings with STRING</h3>
<ul>
<li><strong>Authors: </strong>Connor Schenck, Isaac Reid, Mithun George Jacob, Alex Bewley, Joshua Ainslie, David Rendleman, Deepali Jain, Mohit Sharma, Avinava Dubey, Ayzaan Wahid, Sumeet Singh, Rene Wagner, Tianli Ding, Chuyuan Fu, Arunkumar Byravan, Jake Varley, Alexey Gritsenko, Matthias Minderer, Dmitry Kalashnikov, Jonathan Tompson, Vikas Sindhwani, Krzysztof Choromanski</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CV, cs.RO, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02562">https://arxiv.org/abs/2502.02562</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02562">https://arxiv.org/pdf/2502.02562</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02562]] Learning the RoPEs: Better 2D and 3D Position Encodings with STRING(https://arxiv.org/abs/2502.02562)</code><input type="text"></li>
<li><strong>Keywords: </strong>transformer, large language model</a></li>
<li><strong>Abstract: </strong>We introduce STRING: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers. We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods.</li>
</ul>

<h3>Title: Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach</h3>
<ul>
<li><strong>Authors: </strong>Tianyang Xie, Yong Ge</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02567">https://arxiv.org/abs/2502.02567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02567">https://arxiv.org/pdf/2502.02567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02567]] Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach(https://arxiv.org/abs/2502.02567)</code><input type="text"></li>
<li><strong>Keywords: </strong>fair</a></li>
<li><strong>Abstract: </strong>Survival analysis, a vital tool for predicting the time to event, has been used in many domains such as healthcare, criminal justice, and finance. Like classification tasks, survival analysis can exhibit bias against disadvantaged groups, often due to biases inherent in data or algorithms. Several studies in both the IS and CS communities have attempted to address fairness in survival analysis. However, existing methods often overlook the importance of prediction fairness at pre-defined evaluation time points, which is crucial in real-world applications where decision making often hinges on specific time frames. To address this critical research gap, we introduce a new fairness concept: equalized odds (EO) in survival analysis, which emphasizes prediction fairness at pre-defined time points. To achieve the EO fairness in survival analysis, we propose a Conditional Mutual Information Augmentation (CMIA) approach, which features a novel fairness regularization term based on conditional mutual information and an innovative censored data augmentation technique. Our CMIA approach can effectively balance prediction accuracy and fairness, and it is applicable to various survival models. We evaluate the CMIA approach against several state-of-the-art methods within three different application domains, and the results demonstrate that CMIA consistently reduces prediction disparity while maintaining good accuracy and significantly outperforms the other competing methods across multiple datasets and survival models (e.g., linear COX, deep AFT).</li>
</ul>

<h3>Title: Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement</h3>
<ul>
<li><strong>Authors: </strong>Soheil Abbasloo</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02573">https://arxiv.org/abs/2502.02573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02573">https://arxiv.org/pdf/2502.02573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02573]] Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement(https://arxiv.org/abs/2502.02573)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem-solving, a crucial, ubiquitous, and complex domain. This paper explores the proficiency of LLMs in handling Sequential Optimization Problems (SOPs). We introduce WorldGen, a dynamic framework for generating unseen SOPs with controllable complexities, to evaluate LLM performance. Our initial observations reveal that while LLMs perform well on simple SOPs, their performance significantly degrades with increased complexity. Motivated by this, we revisit philosophical hypotheses on reasoning to enhance LLM performance. Inspired by the influential framework of Hegelian Dialectics, we propose ACE, demonstrating how the performance of LLMs in SOP contexts can be significantly improved without any retraining or further fine-tuning.</li>
</ul>

<h3>Title: A comparison of translation performance between DeepL and Supertext</h3>
<ul>
<li><strong>Authors: </strong>Alex Fl√ºckiger, Chantal Amrhein, Tim Graf, Philippe Schl√§pfer, Florian Schottmann, Samuel L√§ubli</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02577">https://arxiv.org/abs/2502.02577</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02577">https://arxiv.org/pdf/2502.02577</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02577]] A comparison of translation performance between DeepL and Supertext(https://arxiv.org/abs/2502.02577)</code><input type="text"></li>
<li><strong>Keywords: </strong>large language model</a></li>
<li><strong>Abstract: </strong>As strong machine translation (MT) systems are increasingly based on large language models (LLMs), reliable quality benchmarking requires methods that capture their ability to leverage extended context. This study compares two commercial MT systems -- DeepL and Supertext -- by assessing their performance on unsegmented texts. We evaluate translation quality across four language directions with professional translators assessing segments with full document-level context. While segment-level assessments indicate no strong preference between the systems in most cases, document-level analysis reveals a preference for Supertext in three out of four language directions, suggesting superior consistency across longer texts. We advocate for more context-sensitive evaluation methodologies to ensure that MT quality assessments reflect real-world usability. We release all evaluation data and scripts for further analysis and reproduction at this https URL.</li>
</ul>

<h3>Title: Open Materials Generation with Stochastic Interpolants</h3>
<ul>
<li><strong>Authors: </strong>Philipp Hoellmer, Thomas Egg, Maya M. Martirossyan, Eric Fuemmeler, Amit Gupta, Zeren Shui, Pawan Prakash, Adrian Roitberg, Mingjie Liu, George Karypis, Mark Transtrum, Richard G. Hennig, Ellad B. Tadmor, Stefano Martiniani</a></li>
<li><strong>Subjects: </strong>cs.LG, cond-mat.mtrl-sci</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02582">https://arxiv.org/abs/2502.02582</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02582">https://arxiv.org/pdf/2502.02582</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02582]] Open Materials Generation with Stochastic Interpolants(https://arxiv.org/abs/2502.02582)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion, generative</a></li>
<li><strong>Abstract: </strong>The discovery of new materials is essential for enabling technological advancements. Computational approaches for predicting novel materials must effectively learn the manifold of stable crystal structures within an infinite design space. We introduce Open Materials Generation (OMG), a unifying framework for the generative design and discovery of inorganic crystalline materials. OMG employs stochastic interpolants (SI) to bridge an arbitrary base distribution to the target distribution of inorganic crystals via a broad class of tunable stochastic processes, encompassing both diffusion models and flow matching as special cases. In this work, we adapt the SI framework by integrating an equivariant graph representation of crystal structures and extending it to account for periodic boundary conditions in unit cell representations. Additionally, we couple the SI flow over spatial coordinates and lattice vectors with discrete flow matching for atomic species. We benchmark OMG's performance on two tasks: Crystal Structure Prediction (CSP) for specified compositions, and 'de novo' generation (DNG) aimed at discovering stable, novel, and unique structures. In our ground-up implementation of OMG, we refine and extend both CSP and DNG metrics compared to previous works. OMG establishes a new state-of-the-art in generative modeling for materials discovery, outperforming purely flow-based and diffusion-based implementations. These results underscore the importance of designing flexible deep learning frameworks to accelerate progress in materials science.</li>
</ul>

<h3>Title: Spatio-temporal transformer to support automatic sign language translation</h3>
<ul>
<li><strong>Authors: </strong>Christian Ruiz, Fabio Martinez</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02587">https://arxiv.org/abs/2502.02587</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02587">https://arxiv.org/pdf/2502.02587</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02587]] Spatio-temporal transformer to support automatic sign language translation(https://arxiv.org/abs/2502.02587)</code><input type="text"></li>
<li><strong>Keywords: </strong>robust, transformer</a></li>
<li><strong>Abstract: </strong>Sign Language Translation (SLT) systems support hearing-impaired people communication by finding equivalences between signed and spoken languages. This task is however challenging due to multiple sign variations, complexity in language and inherent richness of expressions. Computational approaches have evidenced capabilities to support SLT. Nonetheless, these approaches remain limited to cover gestures variability and support long sequence translations. This paper introduces a Transformer-based architecture that encodes spatio-temporal motion gestures, preserving both local and long-range spatial information through the use of multiple convolutional and attention mechanisms. The proposed approach was validated on the Colombian Sign Language Translation Dataset (CoL-SLTD) outperforming baseline approaches, and achieving a BLEU4 of 46.84%. Additionally, the proposed approach was validated on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T), achieving a BLEU4 score of 30.77%, demonstrating its robustness and effectiveness in handling real-world variations</li>
</ul>

<h3>Title: Calibrated Multi-Preference Optimization for Aligning Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Kyungmin Lee, Xiaohang Li, Qifei Wang, Junfeng He, Junjie Ke, Ming-Hsuan Yang, Irfan Essa, Jinwoo Shin, Feng Yang, Yinxiao Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02588">https://arxiv.org/abs/2502.02588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02588">https://arxiv.org/pdf/2502.02588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02588]] Calibrated Multi-Preference Optimization for Aligning Diffusion Models(https://arxiv.org/abs/2502.02588)</code><input type="text"></li>
<li><strong>Keywords: </strong>diffusion</a></li>
<li><strong>Abstract: </strong>Aligning text-to-image (T2I) diffusion models with preference optimization is valuable for human-annotated datasets, but the heavy cost of manual data collection limits scalability. Using reward models offers an alternative, however, current preference optimization methods fall short in exploiting the rich information, as they only consider pairwise preference distribution. Furthermore, they lack generalization to multi-preference scenarios and struggle to handle inconsistencies between rewards. To address this, we present Calibrated Preference Optimization (CaPO), a novel method to align T2I diffusion models by incorporating the general preference from multiple reward models without human annotated data. The core of our approach involves a reward calibration method to approximate the general preference by computing the expected win-rate against the samples generated by the pretrained models. Additionally, we propose a frontier-based pair selection method that effectively manages the multi-preference distribution by selecting pairs from Pareto frontiers. Finally, we use regression loss to fine-tune diffusion models to match the difference between calibrated rewards of a selected pair. Experimental results show that CaPO consistently outperforms prior methods, such as Direct Preference Optimization (DPO), in both single and multi-reward settings validated by evaluation on T2I benchmarks, including GenEval and T2I-Compbench.</li>
</ul>

<h3>Title: COCONut-PanCap: Joint Panoptic Segmentation and Grounded Captions for Fine-Grained Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Xueqing Deng, Qihang Yu, Ali Athar, Chenglin Yang, Linjie Yang, Xiaojie Jin, Xiaohui Shen, Liang-Chieh Chen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02589">https://arxiv.org/abs/2502.02589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02589">https://arxiv.org/pdf/2502.02589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02589]] COCONut-PanCap: Joint Panoptic Segmentation and Grounded Captions for Fine-Grained Understanding and Generation(https://arxiv.org/abs/2502.02589)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative, segmentation</a></li>
<li><strong>Abstract: </strong>This paper introduces the COCONut-PanCap dataset, created to enhance panoptic segmentation and grounded image captioning. Building upon the COCO dataset with advanced COCONut panoptic masks, this dataset aims to overcome limitations in existing image-text datasets that often lack detailed, scene-comprehensive descriptions. The COCONut-PanCap dataset incorporates fine-grained, region-level captions grounded in panoptic segmentation masks, ensuring consistency and improving the detail of generated captions. Through human-edited, densely annotated descriptions, COCONut-PanCap supports improved training of vision-language models (VLMs) for image understanding and generative models for text-to-image tasks. Experimental results demonstrate that COCONut-PanCap significantly boosts performance across understanding and generation tasks, offering complementary benefits to large-scale datasets. This dataset sets a new benchmark for evaluating models on joint panoptic segmentation and grounded captioning tasks, addressing the need for high-quality, detailed image-text annotations in multi-modal learning.</li>
</ul>

<h3>Title: Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling</h3>
<ul>
<li><strong>Authors: </strong>Xiaowen Qiu, Jincheng Yang, Yian Wang, Zhehuan Chen, Yufei Wang, Tsun-Hsuan Wang, Zhou Xian, Chuang Gan</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.RO</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.02590">https://arxiv.org/abs/2502.02590</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.02590">https://arxiv.org/pdf/2502.02590</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.02590]] Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling(https://arxiv.org/abs/2502.02590)</code><input type="text"></li>
<li><strong>Keywords: </strong>segmentation</a></li>
<li><strong>Abstract: </strong>3D articulated objects modeling has long been a challenging problem, since it requires to capture both accurate surface geometries and semantically meaningful and spatially precise structures, parts, and joints. Existing methods heavily depend on training data from a limited set of handcrafted articulated object categories (e.g., cabinets and drawers), which restricts their ability to model a wide range of articulated objects in an open-vocabulary context. To address these limitations, we propose Articulate Anymesh, an automated framework that is able to convert any rigid 3D mesh into its articulated counterpart in an open-vocabulary manner. Given a 3D mesh, our framework utilizes advanced Vision-Language Models and visual prompting techniques to extract semantic information, allowing for both the segmentation of object parts and the construction of functional joints. Our experiments show that Articulate Anymesh can generate large-scale, high-quality 3D articulated objects, including tools, toys, mechanical devices, and vehicles, significantly expanding the coverage of existing 3D articulated object datasets. Additionally, we show that these generated assets can facilitate the acquisition of new articulated object manipulation skills in simulation, which can then be transferred to a real robotic system. Our Github website is this https URL.</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
