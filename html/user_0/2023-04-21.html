<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>secure</h2>
<h3>Title: Securing Neural Networks with Knapsack Optimization. (arXiv:2304.10442v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10442">http://arxiv.org/abs/2304.10442</a></li>
<li>Code URL: <a href="https://github.com/yg320/secure_inference">https://github.com/yg320/secure_inference</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10442] Securing Neural Networks with Knapsack Optimization](http://arxiv.org/abs/2304.10442) #secure</code></li>
<li>Summary: <p>Deep learning inference brings together the data and the Convolutional Neural
Network (CNN). This is problematic in case the user wants to preserve the
privacy of the data and the service provider does not want to reveal the
weights of his CNN. Secure Inference allows the two parties to engage in a
protocol that preserves their respective privacy concerns, while revealing only
the inference result to the user. This is known as Multi-Party Computation
(MPC). A major bottleneck of MPC algorithms is communication, as the parties
must send data back and forth. The linear component of a CNN (i.e.
convolutions) can be done efficiently with minimal communication, but the
non-linear part (i.e., ReLU) requires the bulk of communication bandwidth. We
propose two ways to accelerate Secure Inference. The first is based on the
observation that the ReLU outcome of many convolutions is highly correlated.
Therefore, we replace the per pixel ReLU operation by a ReLU operation per
patch. Each layer in the network will benefit from a patch of a different size
and we devise an algorithm to choose the optimal set of patch sizes through a
novel reduction of the problem to a knapsack problem. The second way to
accelerate Secure Inference is based on cutting the number of bit comparisons
required for a secure ReLU operation. We demonstrate the cumulative effect of
these tools in the semi-honest secure 3-party setting for four problems:
Classifying ImageNet using ResNet50 backbone, classifying CIFAR100 using
ResNet18 backbone, semantic segmentation of ADE20K using MobileNetV2 backbone
and semantic segmentation of Pascal VOC 2012 using ResNet50 backbone. Our
source code is publicly available:
$\href{https://github.com/yg320/secure_inference}{\text{https://github.com/yg320/secure_inference}}$
</p></li>
</ul>

<h3>Title: Vulnerability of Finitely-long Blockchains in Securing Data. (arXiv:2304.09965v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09965">http://arxiv.org/abs/2304.09965</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09965] Vulnerability of Finitely-long Blockchains in Securing Data](http://arxiv.org/abs/2304.09965) #secure</code></li>
<li>Summary: <p>Recently, blockchain has been applied in various fields to secure data
exchanges and storage in decentralized systems. In a blockchain application
where the task of the application which makes use of the data stored in a
blockchain has to be accomplished by a time instant, the employed blockchain is
essentially finitely-long. In this paper, we consider a general finitely-long
blockchain model which is generalized from most existing works on finitely-long
blockchain applications, and take the first step towards characterizing the
vulnerability of finitely-long blockchains in securing data against
double-spending attacks. For the first time, we develop a general closed-form
expression for the probability of success in launching a double-spending attack
on a finitely-long blockchain. This probability essentially characterizes the
vulnerability of finitely-long blockchains. Then, we prove that the probability
of success in launching a double-spending attack on a finitely-long blockchain
is no greater than that on an infinitely-long blockchain, which implies that
finitely-long blockchains are less vulnerable to double-spending attacks than
infinitely-long blockchains. Moreover, we show that unlike infinitely-long
blockchains which can be surely paralyzed by a 51% attack, finitely-long
blockchains are more resistant to 51% attacks.
</p></li>
</ul>

<h3>Title: Securing Semantic Communications with Physical-layer Semantic Encryption and Obfuscation. (arXiv:2304.10147v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10147">http://arxiv.org/abs/2304.10147</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10147] Securing Semantic Communications with Physical-layer Semantic Encryption and Obfuscation](http://arxiv.org/abs/2304.10147) #secure</code></li>
<li>Summary: <p>Deep learning based semantic communication(DLSC) systems have shown great
potential of making wireless networks significantly more efficient by only
transmitting the semantics of the data. However, the open nature of wireless
channel and fragileness of neural models cause DLSC systems extremely
vulnerable to various attacks. Traditional wireless physical layer key (PLK),
which relies on reciprocal channel and randomness characteristics between two
legitimate users, holds the promise of securing DLSC. The main challenge lies
in generating secret keys in the static environment with ultra-low/zero rate.
Different from prior efforts that use relays or reconfigurable intelligent
surfaces (RIS) to manipulate wireless channels, this paper proposes a novel
physical layer semantic encryption scheme by exploring the randomness of
bilingual evaluation understudy (BLEU) scores in the field of machine
translation, and additionally presents a novel semantic obfuscation mechanism
to provide further physical layer protections. Specifically, 1) we calculate
the BLEU scores and corresponding weights of the DLSC system. Then, we generate
semantic keys (SKey) by feeding the weighted sum of the scores into a hash
function. 2) Equipped with the SKey, our proposed subcarrier obfuscation is
able to further secure semantic communications with a dynamic dummy data
insertion mechanism. Experiments show the effectiveness of our method,
especially in the static wireless environment.
</p></li>
</ul>

<h3>Title: Censoring chemical data to mitigate dual use risk. (arXiv:2304.10510v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10510">http://arxiv.org/abs/2304.10510</a></li>
<li>Code URL: <a href="https://github.com/ur-whitelab/chem-dual-use">https://github.com/ur-whitelab/chem-dual-use</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10510] Censoring chemical data to mitigate dual use risk](http://arxiv.org/abs/2304.10510) #secure</code></li>
<li>Summary: <p>The dual use of machine learning applications, where models can be used for
both beneficial and malicious purposes, presents a significant challenge. This
has recently become a particular concern in chemistry, where chemical datasets
containing sensitive labels (e.g. toxicological information) could be used to
develop predictive models that identify novel toxins or chemical warfare
agents. To mitigate dual use risks, we propose a model-agnostic method of
selectively noising datasets while preserving the utility of the data for
training deep neural networks in a beneficial region. We evaluate the
effectiveness of the proposed method across least squares, a multilayer
perceptron, and a graph neural network. Our findings show selectively noised
datasets can induce model variance and bias in predictions for sensitive labels
with control, suggesting the safe sharing of datasets containing sensitive
information is feasible. We also find omitting sensitive data often increases
model variance sufficiently to mitigate dual use. This work is proposed as a
foundation for future research on enabling more secure and collaborative data
sharing practices and safer machine learning applications in chemistry.
</p></li>
</ul>

<h2>security</h2>
<h3>Title: Social Distance Detection Using Deep Learning And Risk Management System. (arXiv:2304.10259v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10259">http://arxiv.org/abs/2304.10259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10259] Social Distance Detection Using Deep Learning And Risk Management System](http://arxiv.org/abs/2304.10259) #security</code></li>
<li>Summary: <p>An outbreak of the coronavirus disease which occurred three years later and
it has hit the world again with many evolutions. The effects on the human race
have already been profound. We can only safeguard ourselves against this
pandemic by mandating a "Face Mask" also maintaining the "Social Distancing."
The necessity of protective face masks in all gatherings is required by many
civil institutions in India. As a result of the substantial human resource
utilization, personally examining the whole country with a huge population like
India, to determine whether the execution of mask wearing and social distance
maintained is unfeasible. The COVID-19 Social Distancing Detector System is a
single-stage detector that employs deep learning to integrate high-end semantic
data to a CNN module in order to maintain social distances and simultaneously
monitor violations within a specified region. By deploying current Security
footages, CCTV cameras, and computer vision (CV), it will also be able to
identify those who are experiencing the calamity of social separation.
Providing tools for safety and security, this technology disposes the need for
a labor-force based surveillance system, yet a manual governing body is still
required to monitor, track, and inform on the violations that are committed.
Any sort of infrastructure, including universities, hospitals, offices of the
government, schools, and building sites, can employ the technology. Therefore,
the risk management system created to report and analyze video streams along
with the social distance detector system might help to ensure our protection
and security as well as the security of our loved ones. Furthermore, we will
discuss about deployment and improvement of the project overall.
</p></li>
</ul>

<h3>Title: Cyber Security in Smart Manufacturing (Threats, Landscapes Challenges). (arXiv:2304.10180v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10180">http://arxiv.org/abs/2304.10180</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10180] Cyber Security in Smart Manufacturing (Threats, Landscapes Challenges)](http://arxiv.org/abs/2304.10180) #security</code></li>
<li>Summary: <p>Industry 4.0 is a blend of the hyper-connected digital industry within two
world of Information Technology (IT) and Operational Technology (OT). With this
amalgamate opportunity, smart manufacturing involves production assets with the
manufacturing equipment having its own intelligence, while the system-wide
intelligence is provided by the cyber layer. However Smart manufacturing now
becomes one of the prime targets of cyber threats due to vulnerabilities in the
existing process of operation. Since smart manufacturing covers a vast area of
production industries from cyber physical system to additive manufacturing, to
autonomous vehicles, to cloud based IIoT (Industrial IoT), to robotic
production, cyber threat stands out with this regard questioning about how to
connect manufacturing resources by network, how to integrate a whole process
chain for a factory production etc. Cybersecurity confidentiality, integrity
and availability expose their essential existence for the proper operational
thread model known as digital thread ensuring secure manufacturing. In this
work, a literature survey is presented from the existing threat models, attack
vectors and future challenges over the digital thread of smart manufacturing.
</p></li>
</ul>

<h3>Title: ORIGAMI: A flexible state channels design for public blockchain systems. (arXiv:2304.10313v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10313">http://arxiv.org/abs/2304.10313</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10313] ORIGAMI: A flexible state channels design for public blockchain systems](http://arxiv.org/abs/2304.10313) #security</code></li>
<li>Summary: <p>Public blockchain systems offer security guarantees that cannot be matched by
any centralised system. This offering has attracted a lot of interest and has
exposed a significant limitation of most blockchain designs with regards to
scalability. One of the scaling solutions proposed is state channels which
enables serving given applications with minimum number of transactions.
Existing state channels designs set multiple compatibility requirements for
applications to be deployed. Origami is a novel state channels design which
removes most of the requirements of existing approaches, while it also offers a
number of new features. Origami enables dynamic groups of users to interact in
an unordered way completely off-chain after an initial on-boarding on-chain
transaction. The proposed design is analysed in detail and compared to existing
schemes, while a formal security analysis validates the security properties it
offers.
</p></li>
</ul>

<h3>Title: Too sick for surveillance: Can federal HIV service data improve federal HIV surveillance efforts?. (arXiv:2304.10023v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10023">http://arxiv.org/abs/2304.10023</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10023] Too sick for surveillance: Can federal HIV service data improve federal HIV surveillance efforts?](http://arxiv.org/abs/2304.10023) #security</code></li>
<li>Summary: <p>Introduction: The value of integrating federal HIV services data with HIV
surveillance is currently unknown. Upstream and complete case capture is
essential in preventing future HIV transmission. Methods: This study integrated
Ryan White, Social Security Disability Insurance, Medicare, Children Health
Insurance Programs and Medicaid demographic aggregates from 2005 to 2018 for
people living with HIV and compared them with Centers for Disease Control and
Prevention HIV surveillance by demographic aggregate. Surveillance Unknown,
Service Known (SUSK) candidate aggregates were identified from aggregates where
services aggregate volumes exceeded surveillance aggregate volumes. A
distribution approach and a deep learning model series were used to identify
SUSK candidate aggregates where surveillance cases exceeded services cases in
aggregate. Results: Medicare had the most candidate SUSK aggregates. Medicaid
may have candidate SUSK aggregates where cases approach parity with
surveillance. Deep learning was able to detect candidate SUSK aggregates even
where surveillance cases exceed service cases. Conclusions: Integration of CMS
case level records with HIV surveillance records can increase case discovery
and life course model quality; especially for cases who die after seeking HIV
services but before they become surveillance cases. The ethical implications
for both the availability and reuse of clinical HIV Data without the knowledge
and consent of the persons described remains an opportunity for the development
of big data ethics in public health research. Future work should develop big
data ethics to support researchers and assure their subjects that information
which describes them is not misused.
</p></li>
</ul>

<h2>privacy</h2>
<h3>Title: eTag: Class-Incremental Learning with Embedding Distillation and Task-Oriented Generation. (arXiv:2304.10103v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10103">http://arxiv.org/abs/2304.10103</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10103] eTag: Class-Incremental Learning with Embedding Distillation and Task-Oriented Generation](http://arxiv.org/abs/2304.10103) #privacy</code></li>
<li>Summary: <p>Class-Incremental Learning (CIL) aims to solve the neural networks'
catastrophic forgetting problem, which refers to the fact that once the network
updates on a new task, its performance on previously-learned tasks drops
dramatically. Most successful CIL methods incrementally train a feature
extractor with the aid of stored exemplars, or estimate the feature
distribution with the stored prototypes. However, the stored exemplars would
violate the data privacy concerns, while the stored prototypes might not
reasonably be consistent with a proper feature distribution, hindering the
exploration of real-world CIL applications. In this paper, we propose a method
of \textit{e}mbedding distillation and \textit{Ta}sk-oriented
\textit{g}eneration (\textit{eTag}) for CIL, which requires neither the
exemplar nor the prototype. Instead, eTag achieves a data-free manner to train
the neural networks incrementally. To prevent the feature extractor from
forgetting, eTag distills the embeddings of the network's intermediate blocks.
Additionally, eTag enables a generative network to produce suitable features,
fitting the needs of the top incremental classifier. Experimental results
confirmed that our proposed eTag considerably outperforms the state-of-the-art
methods on CIFAR-100 and ImageNet-sub\footnote{Our code is available in the
Supplementary Materials.
</p></li>
</ul>

<h3>Title: Location Privacy Protection Game against Adversary through Multi-user Cooperative Obfuscation. (arXiv:2304.10477v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10477">http://arxiv.org/abs/2304.10477</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10477] Location Privacy Protection Game against Adversary through Multi-user Cooperative Obfuscation](http://arxiv.org/abs/2304.10477) #privacy</code></li>
<li>Summary: <p>In location-based services(LBSs), it is promising for users to crowdsource
and share their Point-of-Interest(PoI) information with each other in a common
cache to reduce query frequency and preserve location privacy. Yet most studies
on multi-user privacy preservation overlook the opportunity of leveraging their
service flexibility. This paper is the first to study multiple users' strategic
cooperation against an adversary's optimal inference attack, by leveraging
mutual service flexibility. We formulate the multi-user privacy cooperation
against the adversary as a max-min adversarial game and solve it in a linear
program. Unlike the vast literature, even if a user finds the cached
information useful, we prove it beneficial to still query the platform to
further confuse the adversary. As the linear program's computational complexity
still increases superlinearly with the number of users' possible locations, we
propose a binary obfuscation scheme in two opposite spatial directions to
achieve guaranteed performance with only constant complexity. Perhaps
surprisingly, a user with a greater service flexibility should query with a
less obfuscated location to add confusion. Finally, we provide guidance on the
optimal query sequence among LBS users. Simulation results show that our
crowdsourced privacy protection scheme greatly improves users' privacy as
compared with existing approaches.
</p></li>
</ul>

<h2>protect</h2>
<h3>Title: Jedi: Entropy-based Localization and Removal of Adversarial Patches. (arXiv:2304.10029v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10029">http://arxiv.org/abs/2304.10029</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10029] Jedi: Entropy-based Localization and Removal of Adversarial Patches](http://arxiv.org/abs/2304.10029) #protect</code></li>
<li>Summary: <p>Real-world adversarial physical patches were shown to be successful in
compromising state-of-the-art models in a variety of computer vision
applications. Existing defenses that are based on either input gradient or
features analysis have been compromised by recent GAN-based attacks that
generate naturalistic patches. In this paper, we propose Jedi, a new defense
against adversarial patches that is resilient to realistic patch attacks. Jedi
tackles the patch localization problem from an information theory perspective;
leverages two new ideas: (1) it improves the identification of potential patch
regions using entropy analysis: we show that the entropy of adversarial patches
is high, even in naturalistic patches; and (2) it improves the localization of
adversarial patches, using an autoencoder that is able to complete patch
regions from high entropy kernels. Jedi achieves high-precision adversarial
patch localization, which we show is critical to successfully repair the
images. Since Jedi relies on an input entropy analysis, it is model-agnostic,
and can be applied on pre-trained off-the-shelf models without changes to the
training or inference of the protected models. Jedi detects on average 90% of
adversarial patches across different benchmarks and recovers up to 94% of
successful patch attacks (Compared to 75% and 65% for LGS and Jujutsu,
respectively).
</p></li>
</ul>

<h3>Title: Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers. (arXiv:2304.09948v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09948">http://arxiv.org/abs/2304.09948</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09948] Catch Me If You Can: Identifying Fraudulent Physician Reviews with Large Language Models Using Generative Pre-Trained Transformers](http://arxiv.org/abs/2304.09948) #protect</code></li>
<li>Summary: <p>The proliferation of fake reviews of doctors has potentially detrimental
consequences for patient well-being and has prompted concern among consumer
protection groups and regulatory bodies. Yet despite significant advancements
in the fields of machine learning and natural language processing, there
remains limited comprehension of the characteristics differentiating fraudulent
from authentic reviews. This study utilizes a novel pre-labeled dataset of
38048 physician reviews to establish the effectiveness of large language models
in classifying reviews. Specifically, we compare the performance of traditional
ML models, such as logistic regression and support vector machines, to
generative pre-trained transformer models. Furthermore, we use GPT4, the newest
model in the GPT family, to uncover the key dimensions along which fake and
genuine physician reviews differ. Our findings reveal significantly superior
performance of GPT-3 over traditional ML models in this context. Additionally,
our analysis suggests that GPT3 requires a smaller training sample than
traditional models, suggesting its appropriateness for tasks with scarce
training data. Moreover, the superiority of GPT3 performance increases in the
cold start context i.e., when there are no prior reviews of a doctor. Finally,
we employ GPT4 to reveal the crucial dimensions that distinguish fake physician
reviews. In sharp contrast to previous findings in the literature that were
obtained using simulated data, our findings from a real-world dataset show that
fake reviews are generally more clinically detailed, more reserved in
sentiment, and have better structure and grammar than authentic ones.
</p></li>
</ul>

<h2>defense</h2>
<h3>Title: Diversifying the High-level Features for better Adversarial Transferability. (arXiv:2304.10136v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10136">http://arxiv.org/abs/2304.10136</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10136] Diversifying the High-level Features for better Adversarial Transferability](http://arxiv.org/abs/2304.10136) #defense</code></li>
<li>Summary: <p>Given the great threat of adversarial attacks against Deep Neural Networks
(DNNs), numerous works have been proposed to boost transferability to attack
real-world applications. However, existing attacks often utilize advanced
gradient calculation or input transformation but ignore the white-box model.
Inspired by the fact that DNNs are over-parameterized for superior performance,
we propose diversifying the high-level features (DHF) for more transferable
adversarial examples. In particular, DHF perturbs the high-level features by
randomly transforming the high-level features and mixing them with the feature
of benign samples when calculating the gradient at each iteration. Due to the
redundancy of parameters, such transformation does not affect the
classification performance but helps identify the invariant features across
different models, leading to much better transferability. Empirical evaluations
on ImageNet dataset show that DHF could effectively improve the transferability
of existing momentum-based attacks. Incorporated into the input
transformation-based attacks, DHF generates more transferable adversarial
examples and outperforms the baselines with a clear margin when attacking
several defense models, showing its generalization to various attacks and high
effectiveness for boosting transferability.
</p></li>
</ul>

<h2>attack</h2>
<h3>Title: Safety Assessment of Chinese Large Language Models. (arXiv:2304.10436v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10436">http://arxiv.org/abs/2304.10436</a></li>
<li>Code URL: <a href="https://github.com/thu-coai/safety-prompts">https://github.com/thu-coai/safety-prompts</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10436] Safety Assessment of Chinese Large Language Models](http://arxiv.org/abs/2304.10436) #attack</code></li>
<li>Summary: <p>With the rapid popularity of large language models such as ChatGPT and GPT-4,
a growing amount of attention is paid to their safety concerns. These models
may generate insulting and discriminatory content, reflect incorrect social
values, and may be used for malicious purposes such as fraud and dissemination
of misleading information. Evaluating and enhancing their safety is
particularly essential for the wide application of large language models
(LLMs). To further promote the safe deployment of LLMs, we develop a Chinese
LLM safety assessment benchmark. Our benchmark explores the comprehensive
safety performance of LLMs from two perspectives: 8 kinds of typical safety
scenarios and 6 types of more challenging instruction attacks. Our benchmark is
based on a straightforward process in which it provides the test prompts and
evaluates the safety of the generated responses from the evaluated model. In
evaluation, we utilize the LLM's strong evaluation ability and develop it as a
safety evaluator by prompting. On top of this benchmark, we conduct safety
assessments and analyze 15 LLMs including the OpenAI GPT series and other
well-known Chinese LLMs, where we observe some interesting findings. For
example, we find that instruction attacks are more likely to expose safety
issues of all LLMs. Moreover, to promote the development and deployment of
safe, responsible, and ethical AI, we publicly release SafetyPrompts including
100k augmented prompts and responses by LLMs.
</p></li>
</ul>

<h3>Title: BackCache: Mitigating Contention-Based Cache Timing Attacks by Hiding Cache Line Evictions. (arXiv:2304.10268v1 [cs.CR])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10268">http://arxiv.org/abs/2304.10268</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10268] BackCache: Mitigating Contention-Based Cache Timing Attacks by Hiding Cache Line Evictions](http://arxiv.org/abs/2304.10268) #attack</code></li>
<li>Summary: <p>Caches are used to reduce the speed differential between the CPU and memory
to improve the performance of modern processors. However, attackers can use
contention-based cache timing attacks to steal sensitive information from
victim processes through carefully designed cache eviction sets. And L1 data
cache attacks are widely exploited and pose a significant privacy and
confidentiality threat. Existing hardware-based countermeasures mainly focus on
cache partitioning, randomization, and cache line flushing, which unfortunately
either incur high overhead or can be circumvented by sophisticated attacks. In
this paper, we propose a novel hardware-software co-design called BackCache
with the idea of always achieving cache hits instead of cache misses to
mitigate contention-based cache timing attacks on the L1 data cache. BackCache
places the evicted cache lines from the L1 data cache into a fully-associative
backup cache to hide the evictions. To improve the security of BackCache, we
introduce a randomly used replacement policy (RURP) and a dynamic backup cache
resizing mechanism. We also present a theoretical security analysis to
demonstrate the effectiveness of BackCache. Our evaluation on the gem5
simulator shows that BackCache can degrade the performance by 1.33%, 7.34%, and
7.59% For OS kernel, single-thread, and multi-thread benchmarks.
</p></li>
</ul>

<h2>robust</h2>
<h3>Title: A robust and interpretable deep learning framework for multi-modal registration via keypoints. (arXiv:2304.09941v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09941">http://arxiv.org/abs/2304.09941</a></li>
<li>Code URL: <a href="https://github.com/evanmy/keymorph">https://github.com/evanmy/keymorph</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09941] A robust and interpretable deep learning framework for multi-modal registration via keypoints](http://arxiv.org/abs/2304.09941) #robust</code></li>
<li>Summary: <p>We present KeyMorph, a deep learning-based image registration framework that
relies on automatically detecting corresponding keypoints. State-of-the-art
deep learning methods for registration often are not robust to large
misalignments, are not interpretable, and do not incorporate the symmetries of
the problem. In addition, most models produce only a single prediction at
test-time. Our core insight which addresses these shortcomings is that
corresponding keypoints between images can be used to obtain the optimal
transformation via a differentiable closed-form expression. We use this
observation to drive the end-to-end learning of keypoints tailored for the
registration task, and without knowledge of ground-truth keypoints. This
framework not only leads to substantially more robust registration but also
yields better interpretability, since the keypoints reveal which parts of the
image are driving the final alignment. Moreover, KeyMorph can be designed to be
equivariant under image translations and/or symmetric with respect to the input
image ordering. Finally, we show how multiple deformation fields can be
computed efficiently and in closed-form at test time corresponding to different
transformation variants. We demonstrate the proposed framework in solving 3D
affine and spline-based registration of multi-modal brain MRI scans. In
particular, we show registration accuracy that surpasses current
state-of-the-art methods, especially in the context of large displacements. Our
code is available at https://github.com/evanmy/keymorph.
</p></li>
</ul>

<h3>Title: Recognizability Embedding Enhancement for Very Low-Resolution Face Recognition and Quality Estimation. (arXiv:2304.10066v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10066">http://arxiv.org/abs/2304.10066</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10066] Recognizability Embedding Enhancement for Very Low-Resolution Face Recognition and Quality Estimation](http://arxiv.org/abs/2304.10066) #robust</code></li>
<li>Summary: <p>Very low-resolution face recognition (VLRFR) poses unique challenges, such as
tiny regions of interest and poor resolution due to extreme standoff distance
or wide viewing angle of the acquisition devices. In this paper, we study
principled approaches to elevate the recognizability of a face in the embedding
space instead of the visual quality. We first formulate a robust learning-based
face recognizability measure, namely recognizability index (RI), based on two
criteria: (i) proximity of each face embedding against the unrecognizable faces
cluster center and (ii) closeness of each face embedding against its positive
and negative class prototypes. We then devise an index diversion loss to push
the hard-to-recognize face embedding with low RI away from unrecognizable faces
cluster to boost the RI, which reflects better recognizability. Additionally, a
perceptibility attention mechanism is introduced to attend to the most
recognizable face regions, which offers better explanatory and discriminative
traits for embedding learning. Our proposed model is trained end-to-end and
simultaneously serves recognizability-aware embedding learning and face quality
estimation. To address VLRFR, our extensive evaluations on three challenging
low-resolution datasets and face quality assessment demonstrate the superiority
of the proposed model over the state-of-the-art methods.
</p></li>
</ul>

<h3>Title: SCoDA: Domain Adaptive Shape Completion for Real Scans. (arXiv:2304.10179v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10179">http://arxiv.org/abs/2304.10179</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10179] SCoDA: Domain Adaptive Shape Completion for Real Scans](http://arxiv.org/abs/2304.10179) #robust</code></li>
<li>Summary: <p>3D shape completion from point clouds is a challenging task, especially from
scans of real-world objects. Considering the paucity of 3D shape ground truths
for real scans, existing works mainly focus on benchmarking this task on
synthetic data, e.g. 3D computer-aided design models. However, the domain gap
between synthetic and real data limits the generalizability of these methods.
Thus, we propose a new task, SCoDA, for the domain adaptation of real scan
shape completion from synthetic data. A new dataset, ScanSalon, is contributed
with a bunch of elaborate 3D models created by skillful artists according to
scans. To address this new task, we propose a novel cross-domain feature fusion
method for knowledge transfer and a novel volume-consistent self-training
framework for robust learning from real data. Extensive experiments prove our
method is effective to bring an improvement of 6%~7% mIoU.
</p></li>
</ul>

<h3>Title: Indian Sign Language Recognition Using Mediapipe Holistic. (arXiv:2304.10256v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10256">http://arxiv.org/abs/2304.10256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10256] Indian Sign Language Recognition Using Mediapipe Holistic](http://arxiv.org/abs/2304.10256) #robust</code></li>
<li>Summary: <p>Deaf individuals confront significant communication obstacles on a daily
basis. Their inability to hear makes it difficult for them to communicate with
those who do not understand sign language. Moreover, it presents difficulties
in educational, occupational, and social contexts. By providing alternative
communication channels, technology can play a crucial role in overcoming these
obstacles. One such technology that can facilitate communication between deaf
and hearing individuals is sign language recognition. We will create a robust
system for sign language recognition in order to convert Indian Sign Language
to text or speech. We will evaluate the proposed system and compare CNN and
LSTM models. Since there are both static and gesture sign languages, a robust
model is required to distinguish between them. In this study, we discovered
that a CNN model captures letters and characters for recognition of static sign
language better than an LSTM model, but it outperforms CNN by monitoring hands,
faces, and pose in gesture sign language phrases and sentences. The creation of
a text-to-sign language paradigm is essential since it will enhance the sign
language-dependent deaf and hard-of-hearing population's communication skills.
Even though the sign-to-text translation is just one side of communication, not
all deaf or hard-of-hearing people are proficient in reading or writing text.
Some may have difficulty comprehending written language due to educational or
literacy issues. Therefore, a text-to-sign language paradigm would allow them
to comprehend text-based information and participate in a variety of social,
educational, and professional settings.
</p></li>
</ul>

<p>Keywords: deaf and hard-of-hearing, DHH, Indian sign language, CNN, LSTM,
static and gesture sign languages, text-to-sign language model, MediaPipe
Holistic, sign language recognition, SLR, SLT
</p>

<h3>Title: OOD-CV-v2: An extended Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images. (arXiv:2304.10266v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10266">http://arxiv.org/abs/2304.10266</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10266] OOD-CV-v2: An extended Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images](http://arxiv.org/abs/2304.10266) #robust</code></li>
<li>Summary: <p>Enhancing the robustness of vision algorithms in real-world scenarios is
challenging. One reason is that existing robustness benchmarks are limited, as
they either rely on synthetic data or ignore the effects of individual nuisance
factors. We introduce OOD-CV-v2, a benchmark dataset that includes
out-of-distribution examples of 10 object categories in terms of pose, shape,
texture, context and the weather conditions, and enables benchmarking of models
for image classification, object detection, and 3D pose estimation. In addition
to this novel dataset, we contribute extensive experiments using popular
baseline methods, which reveal that: 1) Some nuisance factors have a much
stronger negative effect on the performance compared to others, also depending
on the vision task. 2) Current approaches to enhance robustness have only
marginal effects, and can even reduce robustness. 3) We do not observe
significant differences between convolutional and transformer architectures. We
believe our dataset provides a rich test bed to study robustness and will help
push forward research in this area.
</p></li>
</ul>

<p>Our dataset can be accessed from <a href="http://www.ood-cv.org/challenge.html">this http URL</a>
</p>

<h3>Title: Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review. (arXiv:2304.10410v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10410">http://arxiv.org/abs/2304.10410</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10410] Radar-Camera Fusion for Object Detection and Semantic Segmentation in Autonomous Driving: A Comprehensive Review](http://arxiv.org/abs/2304.10410) #robust</code></li>
<li>Summary: <p>Driven by deep learning techniques, perception technology in autonomous
driving has developed rapidly in recent years. To achieve accurate and robust
perception capabilities, autonomous vehicles are often equipped with multiple
sensors, making sensor fusion a crucial part of the perception system. Among
these fused sensors, radars and cameras enable a complementary and
cost-effective perception of the surrounding environment regardless of lighting
and weather conditions. This review aims to provide a comprehensive guideline
for radar-camera fusion, particularly concentrating on perception tasks related
to object detection and semantic segmentation. Based on the principles of the
radar and camera sensors, we delve into the data processing process and
representations, followed by an in-depth analysis and summary of radar-camera
fusion datasets. In the review of methodologies in radar-camera fusion, we
address interrogative questions, including "why to fuse", "what to fuse",
"where to fuse", "when to fuse", and "how to fuse", subsequently discussing
various challenges and potential research directions within this domain. To
ease the retrieval and comparison of datasets and fusion methods, we also
provide an interactive website:
https://XJTLU-VEC.github.io/Radar-Camera-Fusion.
</p></li>
</ul>

<h3>Title: Certified Adversarial Robustness Within Multiple Perturbation Bounds. (arXiv:2304.10446v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10446">http://arxiv.org/abs/2304.10446</a></li>
<li>Code URL: <a href="https://github.com/val-iisc/nu-certified-robustness">https://github.com/val-iisc/nu-certified-robustness</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10446] Certified Adversarial Robustness Within Multiple Perturbation Bounds](http://arxiv.org/abs/2304.10446) #robust</code></li>
<li>Summary: <p>Randomized smoothing (RS) is a well known certified defense against
adversarial attacks, which creates a smoothed classifier by predicting the most
likely class under random noise perturbations of inputs during inference. While
initial work focused on robustness to $\ell_2$ norm perturbations using noise
sampled from a Gaussian distribution, subsequent works have shown that
different noise distributions can result in robustness to other $\ell_p$ norm
bounds as well. In general, a specific noise distribution is optimal for
defending against a given $\ell_p$ norm based attack. In this work, we aim to
improve the certified adversarial robustness against multiple perturbation
bounds simultaneously. Towards this, we firstly present a novel
\textit{certification scheme}, that effectively combines the certificates
obtained using different noise distributions to obtain optimal results against
multiple perturbation bounds. We further propose a novel \textit{training noise
distribution} along with a \textit{regularized training scheme} to improve the
certification within both $\ell_1$ and $\ell_2$ perturbation norms
simultaneously. Contrary to prior works, we compare the certified robustness of
different training algorithms across the same natural (clean) accuracy, rather
than across fixed noise levels used for training and certification. We also
empirically invalidate the argument that training and certifying the classifier
with the same amount of noise gives the best results. The proposed approach
achieves improvements on the ACR (Average Certified Radius) metric across both
$\ell_1$ and $\ell_2$ perturbation bounds.
</p></li>
</ul>

<h3>Title: GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models. (arXiv:2304.09875v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09875">http://arxiv.org/abs/2304.09875</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09875] GREAT Score: Global Robustness Evaluation of Adversarial Perturbation using Generative Models](http://arxiv.org/abs/2304.09875) #robust</code></li>
<li>Summary: <p>Current studies on adversarial robustness mainly focus on aggregating local
robustness results from a set of data samples to evaluate and rank different
models. However, the local statistics may not well represent the true global
robustness of the underlying unknown data distribution. To address this
challenge, this paper makes the first attempt to present a new framework,
called GREAT Score , for global robustness evaluation of adversarial
perturbation using generative models. Formally, GREAT Score carries the
physical meaning of a global statistic capturing a mean certified attack-proof
perturbation level over all samples drawn from a generative model. For
finite-sample evaluation, we also derive a probabilistic guarantee on the
sample complexity and the difference between the sample mean and the true mean.
GREAT Score has several advantages: (1) Robustness evaluations using GREAT
Score are efficient and scalable to large models, by sparing the need of
running adversarial attacks. In particular, we show high correlation and
significantly reduced computation cost of GREAT Score when compared to the
attack-based model ranking on RobustBench (Croce,et. al. 2021). (2) The use of
generative models facilitates the approximation of the unknown data
distribution. In our ablation study with different generative adversarial
networks (GANs), we observe consistency between global robustness evaluation
and the quality of GANs. (3) GREAT Score can be used for remote auditing of
privacy-sensitive black-box models, as demonstrated by our robustness
evaluation on several online facial recognition services.
</p></li>
</ul>

<h3>Title: Robust Deep Reinforcement Learning Scheduling via Weight Anchoring. (arXiv:2304.10176v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10176">http://arxiv.org/abs/2304.10176</a></li>
<li>Code URL: <a href="https://github.com/steffengra/dl_lottery">https://github.com/steffengra/dl_lottery</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10176] Robust Deep Reinforcement Learning Scheduling via Weight Anchoring](http://arxiv.org/abs/2304.10176) #robust</code></li>
<li>Summary: <p>Questions remain on the robustness of data-driven learning methods when
crossing the gap from simulation to reality. We utilize weight anchoring, a
method known from continual learning, to cultivate and fixate desired behavior
in Neural Networks. Weight anchoring may be used to find a solution to a
learning problem that is nearby the solution of another learning problem.
Thereby, learning can be carried out in optimal environments without neglecting
or unlearning desired behavior. We demonstrate this approach on the example of
learning mixed QoS-efficient discrete resource scheduling with infrequent
priority messages. Results show that this method provides performance
comparable to the state of the art of augmenting a simulation environment,
alongside significantly increased robustness and steerability.
</p></li>
</ul>

<h3>Title: SREL: Severity Rating Ensemble Learning for Non-Destructive Fault Diagnosis of Cu Interconnects using S-parameter Patterns. (arXiv:2304.10207v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10207">http://arxiv.org/abs/2304.10207</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10207] SREL: Severity Rating Ensemble Learning for Non-Destructive Fault Diagnosis of Cu Interconnects using S-parameter Patterns](http://arxiv.org/abs/2304.10207) #robust</code></li>
<li>Summary: <p>As operating frequencies and clock speeds in processors have increased over
the years, interconnects affect both the reliability and performance of entire
electronic systems. Fault detection and diagnosis of the interconnects are
crucial for prognostics and health management (PHM) of electronics. However,
existing research works utilizing electrical signals as prognostic factors have
limitations, such as the inability to distinguish the root cause of defects,
which eventually requires additional destructive evaluation, and vulnerability
to noise that results in a false alarm. Herein, we realize the non-destructive
detection and diagnosis of defects in Cu interconnects, achieving early
detection, high diagnostic accuracy, and noise robustness. To the best of our
knowledge, this study first simultaneously analyzes the root cause and severity
using electrical signal patterns. In this paper, we experimentally show that
S-parameter patterns have the ability for fault diagnosis and they are
effective input data for learning algorithms. Furthermore, we propose a novel
severity rating ensemble learning (SREL) approach to enhance diagnostic
accuracy and noise-robustness. Our method, with a maximum accuracy of 99.3%,
outperforms conventional machine learning and multi-class convolutional neural
networks (CNN) as additional noise levels increase.
</p></li>
</ul>

<h3>Title: Efficient Deep Reinforcement Learning Requires Regulating Overfitting. (arXiv:2304.10466v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10466">http://arxiv.org/abs/2304.10466</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10466] Efficient Deep Reinforcement Learning Requires Regulating Overfitting](http://arxiv.org/abs/2304.10466) #robust</code></li>
<li>Summary: <p>Deep reinforcement learning algorithms that learn policies by trial-and-error
must learn from limited amounts of data collected by actively interacting with
the environment. While many prior works have shown that proper regularization
techniques are crucial for enabling data-efficient RL, a general understanding
of the bottlenecks in data-efficient RL has remained unclear. Consequently, it
has been difficult to devise a universal technique that works well across all
domains. In this paper, we attempt to understand the primary bottleneck in
sample-efficient deep RL by examining several potential hypotheses such as
non-stationarity, excessive action distribution shift, and overfitting. We
perform thorough empirical analysis on state-based DeepMind control suite (DMC)
tasks in a controlled and systematic way to show that high temporal-difference
(TD) error on the validation set of transitions is the main culprit that
severely affects the performance of deep RL algorithms, and prior methods that
lead to good performance do in fact, control the validation TD error to be low.
This observation gives us a robust principle for making deep RL efficient: we
can hill-climb on the validation TD error by utilizing any form of
regularization techniques from supervised learning. We show that a simple
online model selection method that targets the validation TD error is effective
across state-based DMC and Gym tasks.
</p></li>
</ul>

<h3>Title: Multidimensional Uncertainty Quantification for Deep Neural Networks. (arXiv:2304.10527v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10527">http://arxiv.org/abs/2304.10527</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10527] Multidimensional Uncertainty Quantification for Deep Neural Networks](http://arxiv.org/abs/2304.10527) #robust</code></li>
<li>Summary: <p>Deep neural networks (DNNs) have received tremendous attention and achieved
great success in various applications, such as image and video analysis,
natural language processing, recommendation systems, and drug discovery.
However, inherent uncertainties derived from different root causes have been
realized as serious hurdles for DNNs to find robust and trustworthy solutions
for real-world problems. A lack of consideration of such uncertainties may lead
to unnecessary risk. For example, a self-driving autonomous car can misdetect a
human on the road. A deep learning-based medical assistant may misdiagnose
cancer as a benign tumor.
</p></li>
</ul>

<p>In this work, we study how to measure different uncertainty causes for DNNs
and use them to solve diverse decision-making problems more effectively. In the
first part of this thesis, we develop a general learning framework to quantify
multiple types of uncertainties caused by different root causes, such as
vacuity (i.e., uncertainty due to a lack of evidence) and dissonance (i.e.,
uncertainty due to conflicting evidence), for graph neural networks. We provide
a theoretical analysis of the relationships between different uncertainty
types. We further demonstrate that dissonance is most effective for
misclassification detection and vacuity is most effective for
Out-of-Distribution (OOD) detection. In the second part of the thesis, we study
the significant impact of OOD objects on semi-supervised learning (SSL) for
DNNs and develop a novel framework to improve the robustness of existing SSL
algorithms against OODs. In the last part of the thesis, we create a general
learning framework to quantity multiple uncertainty types for multi-label
temporal neural networks. We further develop novel uncertainty fusion operators
to quantify the fused uncertainty of a subsequence for early event detection.
</p>

<h2>biometric</h2>
<h2>steal</h2>
<h2>extraction</h2>
<h3>Title: DCN-T: Dual Context Network with Transformer for Hyperspectral Image Classification. (arXiv:2304.09915v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09915">http://arxiv.org/abs/2304.09915</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09915] DCN-T: Dual Context Network with Transformer for Hyperspectral Image Classification](http://arxiv.org/abs/2304.09915) #extraction</code></li>
<li>Summary: <p>Hyperspectral image (HSI) classification is challenging due to spatial
variability caused by complex imaging conditions. Prior methods suffer from
limited representation ability, as they train specially designed networks from
scratch on limited annotated data. We propose a tri-spectral image generation
pipeline that transforms HSI into high-quality tri-spectral images, enabling
the use of off-the-shelf ImageNet pretrained backbone networks for feature
extraction. Motivated by the observation that there are many homogeneous areas
with distinguished semantic and geometric properties in HSIs, which can be used
to extract useful contexts, we propose an end-to-end segmentation network named
DCN-T. It adopts transformers to effectively encode regional adaptation and
global aggregation spatial contexts within and between the homogeneous areas
discovered by similarity-based clustering. To fully exploit the rich spectrums
of the HSI, we adopt an ensemble approach where all segmentation results of the
tri-spectral images are integrated into the final prediction through a voting
scheme. Extensive experiments on three public benchmarks show that our proposed
method outperforms state-of-the-art methods for HSI classification.
</p></li>
</ul>

<h3>Title: Anything-3D: Towards Single-view Anything Reconstruction in the Wild. (arXiv:2304.10261v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10261">http://arxiv.org/abs/2304.10261</a></li>
<li>Code URL: <a href="https://github.com/anything-of-anything/anything-3d">https://github.com/anything-of-anything/anything-3d</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10261] Anything-3D: Towards Single-view Anything Reconstruction in the Wild](http://arxiv.org/abs/2304.10261) #extraction</code></li>
<li>Summary: <p>3D reconstruction from a single-RGB image in unconstrained real-world
scenarios presents numerous challenges due to the inherent diversity and
complexity of objects and environments. In this paper, we introduce
Anything-3D, a methodical framework that ingeniously combines a series of
visual-language models and the Segment-Anything object segmentation model to
elevate objects to 3D, yielding a reliable and versatile system for single-view
conditioned 3D reconstruction task. Our approach employs a BLIP model to
generate textural descriptions, utilizes the Segment-Anything model for the
effective extraction of objects of interest, and leverages a text-to-image
diffusion model to lift object into a neural radiance field. Demonstrating its
ability to produce accurate and detailed 3D reconstructions for a wide array of
objects, \emph{Anything-3D\footnotemark[2]} shows promise in addressing the
limitations of existing methodologies. Through comprehensive experiments and
evaluations on various datasets, we showcase the merits of our approach,
underscoring its potential to contribute meaningfully to the field of 3D
reconstruction. Demos and code will be available at
\href{https://github.com/Anything-of-anything/Anything-3D}{https://github.com/Anything-of-anything/Anything-3D}.
</p></li>
</ul>

<h3>Title: Breast cancer detection using deep learning. (arXiv:2304.10386v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10386">http://arxiv.org/abs/2304.10386</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10386] Breast cancer detection using deep learning](http://arxiv.org/abs/2304.10386) #extraction</code></li>
<li>Summary: <p>Objective: This paper proposes a deep learning model for breast cancer
detection from reconstructed images of microwave imaging scan data and aims to
improve the accuracy and efficiency of breast tumor detection, which could have
a significant impact on breast cancer diagnosis and treatment. Methods: Our
framework consists of different convolutional neural network (CNN)
architectures for feature extraction and a region-based CNN for tumor
detection. We use 7 different architectures: DenseNet201, ResNet50,
InceptionV3, InceptionResNetV3, MobileNetV2, NASNetMobile and NASNetLarge and
compare its performance to find the best architecture out of the seven. An
experimental dataset of MRI-derived breast phantoms was used. Results:
NASNetLarge is the best architecture which can be used for the CNN model with
accuracy of 88.41% and loss of 27.82%. Given that the model's AUC is 0.786, it
can be concluded that it is suitable for use in its present form, while it
could be improved upon and trained on other datasets that are comparable.
Impact: One of the main causes of death in women is breast cancer, and early
identification is essential for enhancing the results for patients. Due to its
non-invasiveness and capacity to produce high-resolution images, microwave
imaging is a potential tool for breast cancer screening. The complexity of
tumors makes it difficult to adequately detect them in microwave images. The
results of this research show that deep learning has a lot of potential for
breast cancer detection in microwave images
</p></li>
</ul>

<h3>Title: Prompt-Learning for Cross-Lingual Relation Extraction. (arXiv:2304.10354v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10354">http://arxiv.org/abs/2304.10354</a></li>
<li>Code URL: <a href="https://github.com/hsu-chia-ming/prompt-xre">https://github.com/hsu-chia-ming/prompt-xre</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10354] Prompt-Learning for Cross-Lingual Relation Extraction](http://arxiv.org/abs/2304.10354) #extraction</code></li>
<li>Summary: <p>Relation Extraction (RE) is a crucial task in Information Extraction, which
entails predicting relationships between entities within a given sentence.
However, extending pre-trained RE models to other languages is challenging,
particularly in real-world scenarios where Cross-Lingual Relation Extraction
(XRE) is required. Despite recent advancements in Prompt-Learning, which
involves transferring knowledge from Multilingual Pre-trained Language Models
(PLMs) to diverse downstream tasks, there is limited research on the effective
use of multilingual PLMs with prompts to improve XRE. In this paper, we present
a novel XRE algorithm based on Prompt-Tuning, referred to as Prompt-XRE. To
evaluate its effectiveness, we design and implement several prompt templates,
including hard, soft, and hybrid prompts, and empirically test their
performance on competitive multilingual PLMs, specifically mBART. Our extensive
experiments, conducted on the low-resource ACE05 benchmark across multiple
languages, demonstrate that our Prompt-XRE algorithm significantly outperforms
both vanilla multilingual PLMs and other existing models, achieving
state-of-the-art performance in XRE. To further show the generalization of our
Prompt-XRE on larger data scales, we construct and release a new XRE dataset-
WMT17-EnZh XRE, containing 0.9M English-Chinese pairs extracted from WMT 2017
parallel corpus. Experiments on WMT17-EnZh XRE also show the effectiveness of
our Prompt-XRE against other competitive baselines. The code and newly
constructed dataset are freely available at
\url{https://github.com/HSU-CHIA-MING/Prompt-XRE}.
</p></li>
</ul>

<h2>membership infer</h2>
<h2>federate</h2>
<h3>Title: Model Pruning Enables Localized and Efficient Federated Learning for Yield Forecasting and Data Sharing. (arXiv:2304.09876v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09876">http://arxiv.org/abs/2304.09876</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09876] Model Pruning Enables Localized and Efficient Federated Learning for Yield Forecasting and Data Sharing](http://arxiv.org/abs/2304.09876) #federate</code></li>
<li>Summary: <p>Federated Learning (FL) presents a decentralized approach to model training
in the agri-food sector and offers the potential for improved machine learning
performance, while ensuring the safety and privacy of individual farms or data
silos. However, the conventional FL approach has two major limitations. First,
the heterogeneous data on individual silos can cause the global model to
perform well for some clients but not all, as the update direction on some
clients may hinder others after they are aggregated. Second, it is lacking with
respect to the efficiency perspective concerning communication costs during FL
and large model sizes. This paper proposes a new technical solution that
utilizes network pruning on client models and aggregates the pruned models.
This method enables local models to be tailored to their respective data
distribution and mitigate the data heterogeneity present in agri-food data.
Moreover, it allows for more compact models that consume less data during
transmission. We experiment with a soybean yield forecasting dataset and find
that this approach can improve inference performance by 15.5% to 20% compared
to FedAvg, while reducing local model sizes by up to 84% and the data volume
communicated between the clients and the server by 57.1% to 64.7%.
</p></li>
</ul>

<h3>Title: Federated Compositional Deep AUC Maximization. (arXiv:2304.10101v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10101">http://arxiv.org/abs/2304.10101</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10101] Federated Compositional Deep AUC Maximization](http://arxiv.org/abs/2304.10101) #federate</code></li>
<li>Summary: <p>Federated learning has attracted increasing attention due to the promise of
balancing privacy and large-scale learning; numerous approaches have been
proposed. However, most existing approaches focus on problems with balanced
data, and prediction performance is far from satisfactory for many real-world
applications where the number of samples in different classes is highly
imbalanced. To address this challenging problem, we developed a novel federated
learning method for imbalanced data by directly optimizing the area under curve
(AUC) score. In particular, we formulate the AUC maximization problem as a
federated compositional minimax optimization problem, develop a local
stochastic compositional gradient descent ascent with momentum algorithm, and
provide bounds on the computational and communication complexities of our
algorithm. To the best of our knowledge, this is the first work to achieve such
favorable theoretical results. Finally, extensive experimental results confirm
the efficacy of our method.
</p></li>
</ul>

<h2>fair</h2>
<h3>Title: Introducing Construct Theory as a Standard Methodology for Inclusive AI Models. (arXiv:2304.09867v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.09867">http://arxiv.org/abs/2304.09867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.09867] Introducing Construct Theory as a Standard Methodology for Inclusive AI Models](http://arxiv.org/abs/2304.09867) #fair</code></li>
<li>Summary: <p>Construct theory in social psychology, developed by George Kelly are mental
constructs to predict and anticipate events. Constructs are how humans
interpret, curate, predict and validate data; information. AI today is biased
because it is trained with a narrow construct as defined by the training data
labels. Machine Learning algorithms for facial recognition discriminate against
darker skin colors and in the ground breaking research papers (Buolamwini, Joy
and Timnit Gebru. Gender Shades: Intersectional Accuracy Disparities in
Commercial Gender Classification. FAT (2018), the inclusion of phenotypic
labeling is proposed as a viable solution. In Construct theory, phenotype is
just one of the many subelements that make up the construct of a face. In this
paper, we present 15 main elements of the construct of face, with 50
subelements and tested Google Cloud Vision API and Microsoft Cognitive Services
API using FairFace dataset that currently has data for 7 races, genders and
ages, and we retested against FairFace Plus dataset curated by us. Our results
show exactly where they have gaps for inclusivity. Based on our experiment
results, we propose that validated, inclusive constructs become industry
standards for AI ML models going forward.
</p></li>
</ul>

<h3>Title: On the Independence of Association Bias and Empirical Fairness in Language Models. (arXiv:2304.10153v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10153">http://arxiv.org/abs/2304.10153</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10153] On the Independence of Association Bias and Empirical Fairness in Language Models](http://arxiv.org/abs/2304.10153) #fair</code></li>
<li>Summary: <p>The societal impact of pre-trained language models has prompted researchers
to probe them for strong associations between protected attributes and
value-loaded terms, from slur to prestigious job titles. Such work is said to
probe models for bias or fairness-or such probes 'into representational biases'
are said to be 'motivated by fairness'-suggesting an intimate connection
between bias and fairness. We provide conceptual clarity by distinguishing
between association biases (Caliskan et al., 2022) and empirical fairness (Shen
et al., 2022) and show the two can be independent. Our main contribution,
however, is showing why this should not come as a surprise. To this end, we
first provide a thought experiment, showing how association bias and empirical
fairness can be completely orthogonal. Next, we provide empirical evidence that
there is no correlation between bias metrics and fairness metrics across the
most widely used language models. Finally, we survey the sociological and
psychological literature and show how this literature provides ample support
for expecting these metrics to be uncorrelated.
</p></li>
</ul>

<h2>interpretability</h2>
<h3>Title: Learning Bottleneck Concepts in Image Classification. (arXiv:2304.10131v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10131">http://arxiv.org/abs/2304.10131</a></li>
<li>Code URL: <a href="https://github.com/wbw520/botcl">https://github.com/wbw520/botcl</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10131] Learning Bottleneck Concepts in Image Classification](http://arxiv.org/abs/2304.10131) #interpretability</code></li>
<li>Summary: <p>Interpreting and explaining the behavior of deep neural networks is critical
for many tasks. Explainable AI provides a way to address this challenge, mostly
by providing per-pixel relevance to the decision. Yet, interpreting such
explanations may require expert knowledge. Some recent attempts toward
interpretability adopt a concept-based framework, giving a higher-level
relationship between some concepts and model decisions. This paper proposes
Bottleneck Concept Learner (BotCL), which represents an image solely by the
presence/absence of concepts learned through training over the target task
without explicit supervision over the concepts. It uses self-supervision and
tailored regularizers so that learned concepts can be human-understandable.
Using some image classification tasks as our testbed, we demonstrate BotCL's
potential to rebuild neural networks for better interpretability. Code is
available at https://github.com/wbw520/BotCL and a simple demo is available at
https://botcl.liangzhili.com/.
</p></li>
</ul>

<h3>Title: Interpretability for Conditional Coordinated Behavior in Multi-Agent Reinforcement Learning. (arXiv:2304.10375v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10375">http://arxiv.org/abs/2304.10375</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10375] Interpretability for Conditional Coordinated Behavior in Multi-Agent Reinforcement Learning](http://arxiv.org/abs/2304.10375) #interpretability</code></li>
<li>Summary: <p>We propose a model-free reinforcement learning architecture, called
distributed attentional actor architecture after conditional attention (DA6-X),
to provide better interpretability of conditional coordinated behaviors. The
underlying principle involves reusing the saliency vector, which represents the
conditional states of the environment, such as the global position of agents.
Hence, agents with DA6-X flexibility built into their policy exhibit superior
performance by considering the additional information in the conditional states
during the decision-making process. The effectiveness of the proposed method
was experimentally evaluated by comparing it with conventional methods in an
objects collection game. By visualizing the attention weights from DA6-X, we
confirmed that agents successfully learn situation-dependent coordinated
behaviors by correctly identifying various conditional states, leading to
improved interpretability of agents along with superior performance.
</p></li>
</ul>

<h2>explainability</h2>
<h2>watermark</h2>
<h2>diffusion</h2>
<h3>Title: A data augmentation perspective on diffusion models and retrieval. (arXiv:2304.10253v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10253">http://arxiv.org/abs/2304.10253</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10253] A data augmentation perspective on diffusion models and retrieval](http://arxiv.org/abs/2304.10253) #diffusion</code></li>
<li>Summary: <p>Diffusion models excel at generating photorealistic images from text-queries.
Naturally, many approaches have been proposed to use these generative abilities
to augment training datasets for downstream tasks, such as classification.
However, diffusion models are themselves trained on large noisily supervised,
but nonetheless, annotated datasets. It is an open question whether the
generalization capabilities of diffusion models beyond using the additional
data of the pre-training process for augmentation lead to improved downstream
performance. We perform a systematic evaluation of existing methods to generate
images from diffusion models and study new extensions to assess their benefit
for data augmentation. While we find that personalizing diffusion models
towards the target data outperforms simpler prompting strategies, we also show
that using the training data of the diffusion model alone, via a simple nearest
neighbor retrieval procedure, leads to even stronger downstream performance.
Overall, our study probes the limitations of diffusion models for data
augmentation but also highlights its potential in generating new training data
to improve performance on simple downstream vision tasks.
</p></li>
</ul>

<h3>Title: Not Only Generative Art: Stable Diffusion for Content-Style Disentanglement in Art Analysis. (arXiv:2304.10278v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10278">http://arxiv.org/abs/2304.10278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10278] Not Only Generative Art: Stable Diffusion for Content-Style Disentanglement in Art Analysis](http://arxiv.org/abs/2304.10278) #diffusion</code></li>
<li>Summary: <p>The duality of content and style is inherent to the nature of art. For
humans, these two elements are clearly different: content refers to the objects
and concepts in the piece of art, and style to the way it is expressed. This
duality poses an important challenge for computer vision. The visual appearance
of objects and concepts is modulated by the style that may reflect the author's
emotions, social trends, artistic movement, etc., and their deep comprehension
undoubtfully requires to handle both. A promising step towards a general
paradigm for art analysis is to disentangle content and style, whereas relying
on human annotations to cull a single aspect of artworks has limitations in
learning semantic concepts and the visual appearance of paintings. We thus
present GOYA, a method that distills the artistic knowledge captured in a
recent generative model to disentangle content and style. Experiments show that
synthetically generated images sufficiently serve as a proxy of the real
distribution of artworks, allowing GOYA to separately represent the two
elements of art while keeping more information than existing methods.
</p></li>
</ul>

<h3>Title: Collaborative Diffusion for Multi-Modal Face Generation and Editing. (arXiv:2304.10530v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10530">http://arxiv.org/abs/2304.10530</a></li>
<li>Code URL: <a href="https://github.com/ziqihuangg/collaborative-diffusion">https://github.com/ziqihuangg/collaborative-diffusion</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10530] Collaborative Diffusion for Multi-Modal Face Generation and Editing](http://arxiv.org/abs/2304.10530) #diffusion</code></li>
<li>Summary: <p>Diffusion models arise as a powerful generative tool recently. Despite the
great progress, existing diffusion models mainly focus on uni-modal control,
i.e., the diffusion process is driven by only one modality of condition. To
further unleash the users' creativity, it is desirable for the model to be
controllable by multiple modalities simultaneously, e.g., generating and
editing faces by describing the age (text-driven) while drawing the face shape
(mask-driven). In this work, we present Collaborative Diffusion, where
pre-trained uni-modal diffusion models collaborate to achieve multi-modal face
generation and editing without re-training. Our key insight is that diffusion
models driven by different modalities are inherently complementary regarding
the latent denoising steps, where bilateral connections can be established
upon. Specifically, we propose dynamic diffuser, a meta-network that adaptively
hallucinates multi-modal denoising steps by predicting the spatial-temporal
influence functions for each pre-trained uni-modal model. Collaborative
Diffusion not only collaborates generation capabilities from uni-modal
diffusion models, but also integrates multiple uni-modal manipulations to
perform multi-modal editing. Extensive qualitative and quantitative experiments
demonstrate the superiority of our framework in both image quality and
condition consistency.
</p></li>
</ul>

<h3>Title: Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs. (arXiv:2304.10532v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10532">http://arxiv.org/abs/2304.10532</a></li>
<li>Code URL: <a href="https://github.com/ethanweber/nerfbusters">https://github.com/ethanweber/nerfbusters</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10532] Nerfbusters: Removing Ghostly Artifacts from Casually Captured NeRFs](http://arxiv.org/abs/2304.10532) #diffusion</code></li>
<li>Summary: <p>Casually captured Neural Radiance Fields (NeRFs) suffer from artifacts such
as floaters or flawed geometry when rendered outside the camera trajectory.
Existing evaluation protocols often do not capture these effects, since they
usually only assess image quality at every 8th frame of the training capture.
To push forward progress in novel-view synthesis, we propose a new dataset and
evaluation procedure, where two camera trajectories are recorded of the scene:
one used for training, and the other for evaluation. In this more challenging
in-the-wild setting, we find that existing hand-crafted regularizers do not
remove floaters nor improve scene geometry. Thus, we propose a 3D
diffusion-based method that leverages local 3D priors and a novel density-based
score distillation sampling loss to discourage artifacts during NeRF
optimization. We show that this data-driven prior removes floaters and improves
scene geometry for casual captures.
</p></li>
</ul>

<h3>Title: Farm3D: Learning Articulated 3D Animals by Distilling 2D Diffusion. (arXiv:2304.10535v1 [cs.CV])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10535">http://arxiv.org/abs/2304.10535</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10535] Farm3D: Learning Articulated 3D Animals by Distilling 2D Diffusion](http://arxiv.org/abs/2304.10535) #diffusion</code></li>
<li>Summary: <p>We present Farm3D, a method to learn category-specific 3D reconstructors for
articulated objects entirely from "free" virtual supervision from a pre-trained
2D diffusion-based image generator. Recent approaches can learn, given a
collection of single-view images of an object category, a monocular network to
predict the 3D shape, albedo, illumination and viewpoint of any object
occurrence. We propose a framework using an image generator like Stable
Diffusion to generate virtual training data for learning such a reconstruction
network from scratch. Furthermore, we include the diffusion model as a score to
further improve learning. The idea is to randomise some aspects of the
reconstruction, such as viewpoint and illumination, generating synthetic views
of the reconstructed 3D object, and have the 2D network assess the quality of
the resulting image, providing feedback to the reconstructor. Different from
work based on distillation which produces a single 3D asset for each textual
prompt in hours, our approach produces a monocular reconstruction network that
can output a controllable 3D asset from a given image, real or generated, in
only seconds. Our network can be used for analysis, including monocular
reconstruction, or for synthesis, generating articulated assets for real-time
applications such as video games.
</p></li>
</ul>

<h3>Title: Prediction of the evolution of the nuclear reactor core parameters using artificial neural network. (arXiv:2304.10337v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2304.10337">http://arxiv.org/abs/2304.10337</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2304.10337] Prediction of the evolution of the nuclear reactor core parameters using artificial neural network](http://arxiv.org/abs/2304.10337) #diffusion</code></li>
<li>Summary: <p>A nuclear reactor based on MIT BEAVRS benchmark was used as a typical power
generating Pressurized Water Reactor (PWR). The PARCS v3.2 nodal-diffusion core
simulator was used as a full-core reactor physics solver to emulate the
operation of a reactor and to generate training, and validation data for the
ANN. The ANN was implemented with dedicated Python 3.8 code with Google's
TensorFlow 2.0 library. The effort was based to a large extent on the process
of appropriate automatic transformation of data generated by PARCS simulator,
which was later used in the process of the ANN development. Various methods
that allow obtaining better accuracy of the ANN predicted results were studied,
such as trying different ANN architectures to find the optimal number of
neurons in the hidden layers of the network. Results were later compared with
the architectures proposed in the literature. For the selected best
architecture predictions were made for different core parameters and their
dependence on core loading patterns. In this study, a special focus was put on
the prediction of the fuel cycle length for a given core loading pattern, as it
can be considered one of the targets for plant economic operation. For
instance, the length of a single fuel cycle depending on the initial core
loading pattern was predicted with very good accuracy (>99%). This work
contributes to the exploration of the usefulness of neural networks in solving
nuclear reactor design problems. Thanks to the application of ANN, designers
can avoid using an excessive amount of core simulator runs and more rapidly
explore the space of possible solutions before performing more detailed design
considerations.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
