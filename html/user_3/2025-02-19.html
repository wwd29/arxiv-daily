<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-02-19</h1>
<h3>Title: TastepepAI, An artificial intelligence platform for taste peptide de novo design</h3>
<ul>
<li><strong>Authors: </strong>Jianda Yue, Tingting Li, Jian Ouyang, Jiawei Xu, Hua Tan, Zihui Chen, Changsheng Han, Huanyu Li, Songping Liang, Zhonghua Liu, Zhonghua Liu, Ying Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12167">https://arxiv.org/abs/2502.12167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12167">https://arxiv.org/pdf/2502.12167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12167]] TastepepAI, An artificial intelligence platform for taste peptide de novo design(https://arxiv.org/abs/2502.12167)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Taste peptides have emerged as promising natural flavoring agents attributed to their unique organoleptic properties, high safety profile, and potential health benefits. However, the de novo identification of taste peptides derived from animal, plant, or microbial sources remains a time-consuming and resource-intensive process, significantly impeding their widespread application in the food industry. Here, we present TastePepAI, a comprehensive artificial intelligence framework for customized taste peptide design and safety assessment. As the key element of this framework, a loss-supervised adaptive variational autoencoder (LA-VAE) is implemented to efficiently optimizes the latent representation of sequences during training and facilitates the generation of target peptides with desired taste profiles. Notably, our model incorporates a novel taste-avoidance mechanism, allowing for selective flavor exclusion. Subsequently, our in-house developed toxicity prediction algorithm (SpepToxPred) is integrated in the framework to undergo rigorous safety evaluation of generated peptides. Using this integrated platform, we successfully identified 73 peptides exhibiting sweet, salty, and umami, significantly expanding the current repertoire of taste peptides. This work demonstrates the potential of TastePepAI in accelerating taste peptide discovery for food applications and provides a versatile framework adaptable to broader peptide engineering challenges.</li>
<li><strong>摘要：</strong>味道肽已成为有希望的天然调味剂，其独特的有机疗法，高安全性和潜在的健康益处。但是，从从动物，植物或微生物来源衍生出的味道肽的从头识别仍然是一个耗时且资源密集的过程，这极大地阻碍了其在食品行业中的广泛应用。在这里，我们提出了Tastepepai，这是一个综合的人工智能框架，用于定制的味道肽设计和安全评估。作为该框架的关键要素，实施了一个监督损失的自适应变分自动编码器（LA-VAE），以有效地优化训练过程中序列的潜在序列的潜在表示，并促进具有所需味觉曲线的目标肽的产生。值得注意的是，我们的模型结合了一种新型的避免味道机制，可以选择性味道排除。随后，我们内部开发的毒性预测算法（SpeptoxPred）集成在框架中，以经过严格的安全性评估，对生成的肽进行了严格的安全评估。使用这个集成的平台，我们成功地确定了73种表现出甜，咸和鲜味的肽，从而显着扩大了当前味道肽的曲目。这项工作证明了Tastepepai在加速食品应用中发现味道肽的潜力，并提供了一种可以适应更广泛的肽工程挑战的多功能框架。</li>
</ul>

<h3>Title: Spatiotemporal Graph Neural Networks in short term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?</h3>
<ul>
<li><strong>Authors: </strong>Quoc Viet Nguyen, Joaquin Delgado Fernandez, Sergio Potenciano Menci</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12175">https://arxiv.org/abs/2502.12175</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12175">https://arxiv.org/pdf/2502.12175</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12175]] Spatiotemporal Graph Neural Networks in short term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?(https://arxiv.org/abs/2502.12175)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Short term Load Forecasting (STLF) plays an important role in traditional and modern power systems. Most STLF models predominantly exploit temporal dependencies from historical data to predict future consumption. Nowadays, with the widespread deployment of smart meters, their data can contain spatiotemporal dependencies. In particular, their consumption data is not only correlated to historical values but also to the values of neighboring smart meters. This new characteristic motivates researchers to explore and experiment with new models that can effectively integrate spatiotemporal interrelations to increase forecasting performance. Spatiotemporal Graph Neural Networks (STGNNs) can leverage such interrelations by modeling relationships between smart meters as a graph and using these relationships as additional features to predict future energy consumption. While extensively studied in other spatiotemporal forecasting domains such as traffic, environments, or renewable energy generation, their application to load forecasting remains relatively unexplored, particularly in scenarios where the graph structure is not inherently available. This paper overviews the current literature focusing on STGNNs with application in STLF. Additionally, from a technical perspective, it also benchmarks selected STGNN models for STLF at the residential and aggregate levels. The results indicate that incorporating graph features can improve forecasting accuracy at the residential level; however, this effect is not reflected at the aggregate level</li>
<li><strong>摘要：</strong>短期负载预测（STLF）在传统和现代电力系统中起着重要作用。大多数STLF模型主要从历史数据中利用时间依赖性来预测未来的消费。如今，随着智能电表的广泛部署，它们的数据可以包含时空依赖性。特别是，它们的消耗数据不仅与历史价值相关，而且与相邻智能电表的值相关。这种新的特征促使研究人员探索和尝试新模型，这些新模型可以有效地整合时空相互关系以提高预测性能。时空图神经网络（STGNN）可以通过建模智能仪之间的关系并将这些关系用作预测未来能源消耗的其他特征来利用这种相互关系。虽然在其他时空预测域（例如流量，环境或可再生能源生成）中进行了广泛的研究，但它们用于加载预测的应用仍然相对未探索，尤其是在固有可用的图形结构的情况下。本文概述了当前的文献，重点是STLF中的STGNN。此外，从技术角度来看，它还基准在住宅和总级别上选择了STGNN的STGNN模型。结果表明，合并图形功能可以提高住宅水平的预测准确性。但是，这种效果在总级别不会反映</li>
</ul>

<h3>Title: Direct Preference Optimization-Enhanced Multi-Guided Diffusion Model for Traffic Scenario Generation</h3>
<ul>
<li><strong>Authors: </strong>Seungjun Yu, Kisung Kim, Daejung Kim, Haewook Han, Jinhan Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12178">https://arxiv.org/abs/2502.12178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12178">https://arxiv.org/pdf/2502.12178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12178]] Direct Preference Optimization-Enhanced Multi-Guided Diffusion Model for Traffic Scenario Generation(https://arxiv.org/abs/2502.12178)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion-based models are recognized for their effectiveness in using real-world driving data to generate realistic and diverse traffic scenarios. These models employ guided sampling to incorporate specific traffic preferences and enhance scenario realism. However, guiding the sampling process to conform to traffic rules and preferences can result in deviations from real-world traffic priors and potentially leading to unrealistic behaviors. To address this challenge, we introduce a multi-guided diffusion model that utilizes a novel training strategy to closely adhere to traffic priors, even when employing various combinations of guides. This model adopts a multi-task learning framework, enabling a single diffusion model to process various guide inputs. For increased guided sampling precision, our model is fine-tuned using the Direct Preference Optimization (DPO) algorithm. This algorithm optimizes preferences based on guide scores, effectively navigating the complexities and challenges associated with the expensive and often non-differentiable gradient calculations during the guided sampling fine-tuning process. Evaluated using the nuScenes dataset our model provides a strong baseline for balancing realism, diversity and controllability in the traffic scenario generation.</li>
<li><strong>摘要：</strong>基于扩散的模型在使用现实世界驱动数据以生成现实和多样化的交通情况方面的有效性而闻名。这些模型采用有指导的抽样来纳入特定的流量偏好并增强场景现实主义。但是，指导抽样过程符合交通规则和偏好可能会导致现实世界中的流量差异，并可能导致不现实的行为。为了应对这一挑战，我们介绍了一个多引导的扩散模型，该模型即使采用各种指南组合，也利用一种新颖的培训策略密切遵守交通先验。该模型采用多任务学习框架，使一个单个扩散模型可以处理各种指南输入。为了提高引导采样精度，使用直接优先优化（DPO）算法对我们的模型进行微调。该算法根据指南分数优化了偏好，有效地导航了与引导采样微调过程中昂贵且通常不可差的梯度计算相关的复杂性和挑战。使用Nuscenes数据集进行评估，我们的模型为在交通场景生成中平衡现实主义，多样性和可控性提供了强大的基准。</li>
</ul>

<h3>Title: E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor Ligand Activity Prediction</h3>
<ul>
<li><strong>Authors: </strong>Jiacheng Xie, Yingrui Ji, Linghuan Zeng, Xi Xiao, Gaofei Chen, Lijing Zhu, Joyanta Jyoti Mondal, Jiansheng Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12186">https://arxiv.org/abs/2502.12186</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12186">https://arxiv.org/pdf/2502.12186</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12186]] E2CB2former: Effecitve and Explainable Transformer for CB2 Receptor Ligand Activity Prediction(https://arxiv.org/abs/2502.12186)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate prediction of CB2 receptor ligand activity is pivotal for advancing drug discovery targeting this receptor, which is implicated in inflammation, pain management, and neurodegenerative conditions. Although conventional machine learning and deep learning techniques have shown promise, their limited interpretability remains a significant barrier to rational drug design. In this work, we introduce CB2former, a framework that combines a Graph Convolutional Network with a Transformer architecture to predict CB2 receptor ligand activity. By leveraging the Transformer's self attention mechanism alongside the GCN's structural learning capability, CB2former not only enhances predictive performance but also offers insights into the molecular features underlying receptor activity. We benchmark CB2former against diverse baseline models including Random Forest, Support Vector Machine, K Nearest Neighbors, Gradient Boosting, Extreme Gradient Boosting, Multilayer Perceptron, Convolutional Neural Network, and Recurrent Neural Network and demonstrate its superior performance with an R squared of 0.685, an RMSE of 0.675, and an AUC of 0.940. Moreover, attention weight analysis reveals key molecular substructures influencing CB2 receptor activity, underscoring the model's potential as an interpretable AI tool for drug discovery. This ability to pinpoint critical molecular motifs can streamline virtual screening, guide lead optimization, and expedite therapeutic development. Overall, our results showcase the transformative potential of advanced AI approaches exemplified by CB2former in delivering both accurate predictions and actionable molecular insights, thus fostering interdisciplinary collaboration and innovation in drug discovery.</li>
<li><strong>摘要：</strong>CB2受体配体活性的准确预测对于推进针对该受体的药物发现至关重要，这与炎症，疼痛管理和神经退行性疾病有关。尽管传统的机器学习和深度学习技术已经显示出希望，但其有限的解释性仍然是理性药物设计的重要障碍。在这项工作中，我们介绍了CB2Former，该框架将图形卷积网络与变压器体系结构相结合，以预测CB2受体配体活动。通过利用Transformer的自我关注机制以及GCN的结构学习能力，CB2Former不仅增强了预测性能，而且还提供了对受体活性基于的分子特征的见解。我们基准针对各种基线模型进行基准测试，包括随机森林，支持向量机，K最近的邻居，梯度提升，极端梯度增强，多层式求助者，卷积神经网络和经常性神经网络，并以0.685，A平方为0.685，A平方，A平方RMSE为0.675，AUC为0.940。此外，注意力重量分析揭示了影响CB2受体活性的关键分子子结构，从而强调了该模型作为药物发现的可解释的AI工具的潜力。这种指出关键分子基序的能力可以简化虚拟筛选，指导铅优化和加快治疗性开发。总体而言，我们的结果展示了CB2Former在提供准确的预测和可操作的分子见解方面举例说明的高级AI方法的变革潜力，从而促进了跨学科的协作和药物发现中的创新。</li>
</ul>

<h3>Title: Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling</h3>
<ul>
<li><strong>Authors: </strong>Haoyu Lei, Kaiwen Zhou, Yinchuan Li, Zhitang Chen, Farzan Farnia</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12188">https://arxiv.org/abs/2502.12188</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12188">https://arxiv.org/pdf/2502.12188</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12188]] Boosting Generalization in Diffusion-Based Neural Combinatorial Solver via Energy-guided Sampling(https://arxiv.org/abs/2502.12188)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion-based Neural Combinatorial Optimization (NCO) has demonstrated effectiveness in solving NP-complete (NPC) problems by learning discrete diffusion models for solution generation, eliminating hand-crafted domain knowledge. Despite their success, existing NCO methods face significant challenges in both cross-scale and cross-problem generalization, and high training costs compared to traditional solvers. While recent studies have introduced training-free guidance approaches that leverage pre-defined guidance functions for zero-shot conditional generation, such methodologies have not been extensively explored in combinatorial optimization. To bridge this gap, we propose a general energy-guided sampling framework during inference time that enhances both the cross-scale and cross-problem generalization capabilities of diffusion-based NCO solvers without requiring additional training. We provide theoretical analysis that helps understanding the cross-problem transfer capability. Our experimental results demonstrate that a diffusion solver, trained exclusively on the Traveling Salesman Problem (TSP), can achieve competitive zero-shot solution generation on TSP variants, such as Prize Collecting TSP (PCTSP) and the Orienteering Problem (OP), through energy-guided sampling across different problem scales.</li>
<li><strong>摘要：</strong>基于扩散的神经组合优化（NCO）通过学习解决溶液生成的离散扩散模型，消除了手工制作的域知识，证明了在解决NP完整问题（NPC）问题方面具有有效性。尽管他们成功了，但现有的NCO方法在跨尺度和跨问题概括方面都面临着重大挑战，与传统求解器相比，高训练成本。尽管最近的研究引入了无培训的指导方法，以利用预定的有条件产生的预定指导功能，但在组合优化中尚未广泛探索此类方法。为了弥合这一差距，我们在推理期间提出了一个一般的能量引导的采样框架，可以增强基于扩散的NCO求解器的跨尺度和跨问题概括能力，而无需进行额外的培训。我们提供理论分析，有助于理解跨问题的传递能力。我们的实验结果表明，专门针对旅行推销员问题（TSP）培训的扩散求解器可以在TSP变体上实现竞争性的零发溶液生成，例如奖品收集TSP（PCTSP）（PCTSP）和定向服务问题（OP），Energy，Energy，Energy Erigineering问题（OP） - 在不同的问题量表上进行采样。</li>
</ul>

<h3>Title: GeneralizeFormer: Layer-Adaptive Model Generation across Test-Time Distribution Shifts</h3>
<ul>
<li><strong>Authors: </strong>Sameer Ambekar, Zehao Xiao, Xiantong Zhen, Cees G. M. Snoek</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12195">https://arxiv.org/abs/2502.12195</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12195">https://arxiv.org/pdf/2502.12195</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12195]] GeneralizeFormer: Layer-Adaptive Model Generation across Test-Time Distribution Shifts(https://arxiv.org/abs/2502.12195)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>We consider the problem of test-time domain generalization, where a model is trained on several source domains and adjusted on target domains never seen during training. Different from the common methods that fine-tune the model or adjust the classifier parameters online, we propose to generate multiple layer parameters on the fly during inference by a lightweight meta-learned transformer, which we call \textit{GeneralizeFormer}. The layer-wise parameters are generated per target batch without fine-tuning or online adjustment. By doing so, our method is more effective in dynamic scenarios with multiple target distributions and also avoids forgetting valuable source distribution characteristics. Moreover, by considering layer-wise gradients, the proposed method adapts itself to various distribution shifts. To reduce the computational and time cost, we fix the convolutional parameters while only generating parameters of the Batch Normalization layers and the linear classifier. Experiments on six widely used domain generalization datasets demonstrate the benefits and abilities of the proposed method to efficiently handle various distribution shifts, generalize in dynamic scenarios, and avoid forgetting.</li>
<li><strong>摘要：</strong>我们考虑了测试时间域概括的问题，其中模型是在几个源域上训练的，并在训练过程中从未见过的目标域进行了调整。不同于对模型进行微调或在线调整分类器参数的常见方法，我们建议在推理过程中通过轻巧的元学习变压器在推理过程中即时生成多层参数，我们将其称为\ textit {enlyizeFormer}。层的参数是每个目标批次生成的，而无需微调或在线调整。通过这样做，我们的方法在具有多个目标分布的动态场景中更有效，并且还避免忘记有价值的源分布特征。此外，通过考虑层的梯度，提出的方法适应了各种分布变化。为了降低计算和时间成本，我们修复了卷积参数，而仅生成批处理层和线性分类器的参数。在六个广泛使用的域概括数据集上进行的实验证明了提出的方法的好处和能力，以有效处理各种分布变化，在动态场景中概括并避免忘记。</li>
</ul>

<h3>Title: An Interpretable Automated Mechanism Design Framework with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiayuan Liu, Mingyu Guo, Vincent Conitzer</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.GT, cs.NE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12203">https://arxiv.org/abs/2502.12203</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12203">https://arxiv.org/pdf/2502.12203</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12203]] An Interpretable Automated Mechanism Design Framework with Large Language Models(https://arxiv.org/abs/2502.12203)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Mechanism design has long been a cornerstone of economic theory, with traditional approaches relying on mathematical derivations. Recently, automated approaches, including differentiable economics with neural networks, have emerged for designing payments and allocations. While both analytical and automated methods have advanced the field, they each face significant weaknesses: mathematical derivations are not automated and often struggle to scale to complex problems, while automated and especially neural-network-based approaches suffer from limited interpretability. To address these challenges, we introduce a novel framework that reformulates mechanism design as a code generation task. Using large language models (LLMs), we generate heuristic mechanisms described in code and evolve them to optimize over some evaluation metrics while ensuring key design criteria (e.g., strategy-proofness) through a problem-specific fixing process. This fixing process ensures any mechanism violating the design criteria is adjusted to satisfy them, albeit with some trade-offs in performance metrics. These trade-offs are factored in during the LLM-based evolution process. The code generation capabilities of LLMs enable the discovery of novel and interpretable solutions, bridging the symbolic logic of mechanism design and the generative power of modern AI. Through rigorous experimentation, we demonstrate that LLM-generated mechanisms achieve competitive performance while offering greater interpretability compared to previous approaches. Notably, our framework can rediscover existing manually designed mechanisms and provide insights into neural-network based solutions through Programming-by-Example. These results highlight the potential of LLMs to not only automate but also enhance the transparency and scalability of mechanism design, ensuring safe deployment of the mechanisms in society.</li>
<li><strong>摘要：</strong>长期以来，机理设计一直是经济理论的基石，传统方法依赖数学推导。最近，出现了自动化方法，包括具有神经网络的可微分经济学，用于设计付款和分配。尽管分析方法和自动化方法都已经提高了该领域，但它们每个都面临着重要的弱点：数学推导不是自动化的，并且经常难以扩展到复杂的问题，而自动化，尤其是基于神经网络的方法的方法有限。为了应对这些挑战，我们引入了一个新颖的框架，将机制设计重新定义为代码生成任务。使用大型语言模型（LLM），我们生成了代码中描述的启发式机制，并将其进化以优化某些评估指标，同时通过特定于问题的修复过程确保关键设计标准（例如，防止策略 - 防止策略，防止策略，可以防止策略。此修复过程可确保对违反设计标准的任何机制进行调整以使它们满意，尽管在性能指标上取决了一些权衡。这些权衡是在基于LLM的进化过程中考虑的。 LLMS的代码生成能力可以发现新颖和可解释的解决方案，桥接机制设计的象征性逻辑和现代AI的生成力量。通过严格的实验，我们证明了LLM生成的机制可实现竞争性能，同时与以前的方法相比提供了更大的可解释性。值得注意的是，我们的框架可以重新发现现有的手动设计机制，并通过示例编程对基于神经网络的解决方案提供见解。这些结果强调了LLM不仅可以自动化，还可以提高机制设计的透明度和可扩展性，从而确保社会机制的安全部署。</li>
</ul>

<h3>Title: PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN</h3>
<ul>
<li><strong>Authors: </strong>Jiayu Zhang, Zhiyu Zhu, Xinyi Wang, Silin Liao, Zhibo Jin, Flora D. Salim, Huaming Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12207">https://arxiv.org/abs/2502.12207</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12207">https://arxiv.org/pdf/2502.12207</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12207]] PAR-AdvGAN: Improving Adversarial Attack Capability with Progressive Auto-Regression AdvGAN(https://arxiv.org/abs/2502.12207)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Deep neural networks have demonstrated remarkable performance across various domains. However, they are vulnerable to adversarial examples, which can lead to erroneous predictions. Generative Adversarial Networks (GANs) can leverage the generators and discriminators model to quickly produce high-quality adversarial examples. Since both modules train in a competitive and simultaneous manner, GAN-based algorithms like AdvGAN can generate adversarial examples with better transferability compared to traditional methods. However, the generation of perturbations is usually limited to a single iteration, preventing these examples from fully exploiting the potential of the methods. To tackle this issue, we introduce a novel approach named Progressive Auto-Regression AdvGAN (PAR-AdvGAN). It incorporates an auto-regressive iteration mechanism within a progressive generation network to craft adversarial examples with enhanced attack capability. We thoroughly evaluate our PAR-AdvGAN method with a large-scale experiment, demonstrating its superior performance over various state-of-the-art black-box adversarial attacks, as well as the original this http URL, PAR-AdvGAN significantly accelerates the adversarial example generation, i.e., achieving the speeds of up to 335.5 frames per second on Inception-v3 model, outperforming the gradient-based transferable attack algorithms. Our code is available at: this https URL</li>
<li><strong>摘要：</strong>深度神经网络在各个领域都表现出了出色的性能。但是，它们容易受到对抗性例子的影响，这可能会导致错误的预测。生成的对抗网络（GAN）可以利用发电机和鉴别器模型快速产生高质量的对抗示例。由于两个模块都以竞争性和同时的方式进行训练，因此与传统方法相比，基于GAN的算法可以生成具有更好可传递性的对抗性示例。但是，扰动的产生通常仅限于一次迭代，从而阻止了这些示例充分利用方法的潜力。为了解决这个问题，我们介绍了一种新颖的方法，名为“渐进自动回归Advgan”（Par-Advgan）。它在渐进的生成网络中结合了自动回归迭代机制，以增强攻击能力来制作对抗性示例。我们通过大规模实验彻底评估我们的par-advgan方法，证明了其优于各种最新的黑盒对抗攻击以及原始此HTTP URL的表现优越，Par-Advgan可显着加速对抗性。示例生成，即实现Inception-V3模型每秒最多335.5帧的速度，表现优于基于梯度的可转移攻击算法。我们的代码可用：此HTTPS URL</li>
</ul>

<h3>Title: Per-channel autoregressive linear prediction padding in tiled CNN processing of 2D spatial data</h3>
<ul>
<li><strong>Authors: </strong>Olli Niemitalo, Otto Rosenberg, Nathaniel Narra, Olli Koskela, Iivari Kunttu (HAMK Häme University of Applied Sciences)</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12300">https://arxiv.org/abs/2502.12300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12300">https://arxiv.org/pdf/2502.12300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12300]] Per-channel autoregressive linear prediction padding in tiled CNN processing of 2D spatial data(https://arxiv.org/abs/2502.12300)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution</a></li>
<li><strong>Abstract: </strong>We present linear prediction as a differentiable padding method. For each channel, a stochastic autoregressive linear model is fitted to the padding input by minimizing its noise terms in the least-squares sense. The padding is formed from the expected values of the autoregressive model given the known pixels. We trained the convolutional RVSR super-resolution model from scratch on satellite image data, using different padding methods. Linear prediction padding slightly reduced the mean square super-resolution error compared to zero and replication padding, with a moderate increase in time cost. Linear prediction padding better approximated satellite image data and RVSR feature map data. With zero padding, RVSR appeared to use more of its capacity to compensate for the high approximation error. Cropping the network output by a few pixels reduced the super-resolution error and the effect of the choice of padding method on the error, favoring output cropping with the faster replication and zero padding methods, for the studied workload.</li>
<li><strong>摘要：</strong>我们将线性预测作为一种可区分的填充方法。对于每个通道，通过在最小二乘中最小化其噪声项，将随机自回归线性模型拟合到填充输入中。填充是由鉴于已知像素的自回归模型的预期值形成的。我们使用不同的填充方法在卫星图像数据上从头开始训练了卷积RVSR超分辨率模型。与零和复制填充相比，线性预测填充略微降低了均方根超分辨率的误差，时间成本中等增加。线性预测填充更好近似卫星图像数据和RVSR特征图数据。使用零填充物，RVSR似乎使用更多的能力来补偿高近似误差。通过几个像素裁剪网络输出可减少超分辨率误差和选择填充方法对错误的影响，从而在研究工作负载中以更快的复制和零填充方法的速度进行裁剪。</li>
</ul>

<h3>Title: From Gaming to Research: GTA V for Synthetic Data Generation for Robotics and Navigations</h3>
<ul>
<li><strong>Authors: </strong>Matteo Scucchia, Matteo Ferrara, Davide Maltoni</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12303">https://arxiv.org/abs/2502.12303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12303">https://arxiv.org/pdf/2502.12303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12303]] From Gaming to Research: GTA V for Synthetic Data Generation for Robotics and Navigations(https://arxiv.org/abs/2502.12303)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>In computer vision, the development of robust algorithms capable of generalizing effectively in real-world scenarios more and more often requires large-scale datasets collected under diverse environmental conditions. However, acquiring such datasets is time-consuming, costly, and sometimes unfeasible. To address these limitations, the use of synthetic data has gained attention as a viable alternative, allowing researchers to generate vast amounts of data while simulating various environmental contexts in a controlled setting. In this study, we investigate the use of synthetic data in robotics and navigation, specifically focusing on Simultaneous Localization and Mapping (SLAM) and Visual Place Recognition (VPR). In particular, we introduce a synthetic dataset created using the virtual environment of the video game Grand Theft Auto V (GTA V), along with an algorithm designed to generate a VPR dataset, without human supervision. Through a series of experiments centered on SLAM and VPR, we demonstrate that synthetic data derived from GTA V are qualitatively comparable to real-world data. Furthermore, these synthetic data can complement or even substitute real-world data in these applications. This study sets the stage for the creation of large-scale synthetic datasets, offering a cost-effective and scalable solution for future research and development.</li>
<li><strong>摘要：</strong>在计算机视觉中，能够在现实世界中有效概括的强大算法的开发越来越多地需要在各种环境条件下收集的大规模数据集。但是，获取此类数据集是耗时的，昂贵的，有时是不可行的。为了解决这些局限性，合成数据的使用已成为可行的替代方案，使研究人员能够生成大量数据，同时在受控的环境中模拟各种环境环境。在这项研究中，我们研究了合成数据在机器人技术和导航中的使用，特别关注同时定位和映射（SLAM）和Visual Plote识别（VPR）。特别是，我们介绍了一个使用视频游戏Grand Theft Auto V（GTA V）的虚拟环境创建的合成数据集，以及一个算法，旨在生成VPR数据集的算法，而无需人为监督。通过以SLAM和VPR为中心的一系列实验，我们证明了从GTA V得出的合成数据在质量上与现实世界中的数据相当。此外，这些合成数据可以在这些应用程序中补充甚至替代现实世界数据。这项研究为创建大规模合成数据集的创建奠定了基础，为未来的研究和开发提供了一种经济高效且可扩展的解决方案。</li>
</ul>

<h3>Title: QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Jiajun Zhou, Yifan Yang, Kai Zhen, Ziyue Liu, Yequan Zhao, Ershad Banijamali, Athanasios Mouchtaris, Ngai Wong, Zheng Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12346">https://arxiv.org/abs/2502.12346</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12346">https://arxiv.org/pdf/2502.12346</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12346]] QuZO: Quantized Zeroth-Order Fine-Tuning for Large Language Models(https://arxiv.org/abs/2502.12346)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Language Models (LLMs) are often quantized to lower precision to reduce the memory cost and latency in inference. However, quantization often degrades model performance, thus fine-tuning is required for various down-stream tasks. Traditional fine-tuning methods such as stochastic gradient descent and Adam optimization require backpropagation, which are error-prone in the low-precision settings. To overcome these limitations, we propose the Quantized Zeroth-Order (QuZO) framework, specifically designed for fine-tuning LLMs through low-precision (e.g., 4- or 8-bit) forward passes. Our method can avoid the error-prone low-precision straight-through estimator, and utilizes optimized stochastic rounding to mitigate the increased bias. QuZO simplifies the training process, while achieving results comparable to first-order methods in ${\rm FP}8$ and superior accuracy in ${\rm INT}8$ and ${\rm INT}4$ training. Experiments demonstrate that low-bit training QuZO achieves performance comparable to MeZO optimization on GLUE, Multi-Choice, and Generation tasks, while reducing memory cost by $2.94 \times$ in LLaMA2-7B fine-tuning compared to quantized first-order methods.</li>
<li><strong>摘要：</strong>语言模型（LLM）通常被量化为降低精度，以降低记忆成本和推理的延迟。但是，量化通常会降低模型性能，因此各种下游任务需要进行微调。传统的微调方法，例如随机梯度下降和ADAM优化，需要反向传播，这在低精度设置中容易出错。为了克服这些局限性，我们提出了量化的零阶（Quzo）框架，该框架是专门设计用于通过低精确（例如4--或8位）正向通行的微调LLM的。我们的方法可以避免容易出错的低精度直通估计器，并利用优化的随机舍入来减轻偏见的增加。 Quzo简化了训练过程，同时获得与$ {\ rm fp} 8 $中的一阶方法相当的结果和$ {\ rm int} 8 $和$ {\ rm int} 4 $训练的卓越精度。实验表明，低位训练Quzo的性能与胶水，多选择和发电任务的MEZO优化相当，而与量化的一阶方法相比，Llama2-7B微调中的记忆成本降低了$ 2.94 \ times $。</li>
</ul>

<h3>Title: ScriptoriumWS: A Code Generation Assistant for Weak Supervision</h3>
<ul>
<li><strong>Authors: </strong>Tzu-Heng Huang, Catherine Cao, Spencer Schoenberg, Harit Vishwakarma, Nicholas Roberts, Frederic Sala</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12366">https://arxiv.org/abs/2502.12366</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12366">https://arxiv.org/pdf/2502.12366</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12366]] ScriptoriumWS: A Code Generation Assistant for Weak Supervision(https://arxiv.org/abs/2502.12366)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Weak supervision is a popular framework for overcoming the labeled data bottleneck: the need to obtain labels for training data. In weak supervision, multiple noisy-but-cheap sources are used to provide guesses of the label and are aggregated to produce high-quality pseudolabels. These sources are often expressed as small programs written by domain experts -- and so are expensive to obtain. Instead, we argue for using code-generation models to act as coding assistants for crafting weak supervision sources. We study prompting strategies to maximize the quality of the generated sources, settling on a multi-tier strategy that incorporates multiple types of information. We explore how to best combine hand-written and generated sources. Using these insights, we introduce ScriptoriumWS, a weak supervision system that, when compared to hand-crafted sources, maintains accuracy and greatly improves coverage.</li>
<li><strong>摘要：</strong>弱监督是克服标记的数据瓶颈的流行框架：需要获得培训数据的标签。在弱的监督中，使用多个嘈杂但廉价的来源来提供标签的猜测，并汇总以产生高质量的伪标记。这些来源通常以域专家编写的小计划表示，因此获得昂贵。取而代之的是，我们主张使用代码生成模型充当编码助手，以制定弱监管来源。我们研究提示策略以最大化生成的来源的质量，并基于包含多种信息的多层策略。我们探索如何最好地结合手写和生成的来源。使用这些见解，我们介绍了Scriptoriumws，这是一个薄弱的监督系统，与手工制作的来源相比，它保持准确性并大大改善覆盖范围。</li>
</ul>

<h3>Title: Multi Image Super Resolution Modeling for Earth System Models</h3>
<ul>
<li><strong>Authors: </strong>Ehsan Zeraatkar, Salah A Faroughi, Jelena Tešić</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12427">https://arxiv.org/abs/2502.12427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12427">https://arxiv.org/pdf/2502.12427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12427]] Multi Image Super Resolution Modeling for Earth System Models(https://arxiv.org/abs/2502.12427)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution, generative</a></li>
<li><strong>Abstract: </strong>Super-resolution (SR) techniques are essential for improving Earth System Model (ESM) data's spatial resolution, which helps better understand complex environmental processes. This paper presents a new algorithm, ViFOR, which combines Vision Transformers (ViT) and Implicit Neural Representation Networks (INRs) to generate High-Resolution (HR) images from Low-Resolution (LR) inputs. ViFOR introduces a novel integration of Fourier-based activation functions within the Vision Transformer architecture, enabling it to effectively capture global context and high-frequency details critical for accurate SR reconstruction. The results show that ViFOR outperforms state-of-the-art methods such as ViT, Sinusoidal Representation Networks (SIREN), and SR Generative Adversarial Networks (SRGANs) based on metrics like Peak Signal-to-Noise Ratio (PSNR) and Mean Squared Error (MSE) both for global as well as the local imagery. ViFOR improves PSNR of up to 4.18 dB, 1.56 dB, and 1.73 dB over ViT for full images in the Source Temperature, Shortwave, and Longwave Flux.</li>
<li><strong>摘要：</strong>超分辨率（SR）技术对于改善地球系统模型（ESM）数据的空间分辨率至关重要，这有助于更好地理解复杂的环境过程。本文提出了一种新的算法Vifor，该算法结合了视觉变压器（VIT）和隐式神经表示网络（INRS），以从低分辨率（LR）输入中生成高分辨率（HR）图像。 Vifor在视觉变压器体系结构中引入了基于傅立叶的激活功能的新颖集成，使其能够有效捕获全球上下文和高频细节，对于准确的SR重建至关重要。结果表明，基于峰值信噪比（PSNR）等指标，VIT，正弦表示网络（Siren）和SR生成对抗网络（SRGAN）（SRGANS）均优于最先进的方法，例如VIT，SINUSOIDAL代表网络（Siren）和SR生成对抗网络（SRGANS）全局和本地图像的错误（MSE）。 VIFOR在VIT，短波和Longwave Flux的完整图像上提高了高达4.18 dB，1.56 dB和1.73 dB的PSNR。</li>
</ul>

<h3>Title: SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered CPUs</h3>
<ul>
<li><strong>Authors: </strong>Ahmed F. AbouElhamayed, Jordan Dotzel, Yash Akhauri, Chi-Chih Chang, Sameh Gobriel, J. Pablo Muñoz, Vui Seng Chua, Nilesh Jain, Mohamed S. Abdelfattah</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR, cs.PF</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12444">https://arxiv.org/abs/2502.12444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12444">https://arxiv.org/pdf/2502.12444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12444]] SparAMX: Accelerating Compressed LLMs Token Generation on AMX-powered CPUs(https://arxiv.org/abs/2502.12444)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Large language models have high compute, latency, and memory requirements. While specialized accelerators such as GPUs and TPUs typically run these workloads, CPUs are more widely available and consume less energy. Accelerating LLMs with CPUs enables broader AI access at a lower cost and power consumption. This acceleration potential for CPUs is especially relevant during the memory-bound decoding stage of LLM inference, which processes one token at a time and is becoming increasingly utilized with reasoning models. We utilize Advanced Matrix Extensions (AMX) support on the latest Intel CPUs together with unstructured sparsity to achieve a $1.42 \times$ reduction in end-to-end latency compared to the current PyTorch implementation by applying our technique in linear layers. We provide a set of open-source customized sparse kernels that can speed up any PyTorch model by automatically replacing all linear layers with our custom sparse implementation. Furthermore, we demonstrate for the first time the use of unstructured sparsity in the attention computation achieving a $1.14 \times$ speedup over the current systems without compromising accuracy. Code: this https URL</li>
<li><strong>摘要：</strong>大型语言模型具有较高的计算，延迟和内存要求。尽管GPU和TPU等专业加速器通常运行这些工作负载，但CPU的可用性更广泛，消耗能量更少。使用CPU加速LLM可以以较低的成本和功耗允许更广泛的AI访问。在LLM推理的记忆结合解码阶段，CPU的这种加速潜力尤其重要，该阶段一次处理一个令牌，并且正在越来越多地通过推理模型使用。与当前的Pytorch实现相比，我们在最新的Intel CPU上使用了高级矩阵扩展（AMX）支持，以实现端到端潜伏期的$ 1.42 \ times $减少。我们提供了一组开源定制的稀疏内核，可以通过自动替换所有线性层，使用我们的自定义稀疏实现来加快任何Pytorch模型。此外，我们首次证明了在注意力计算中使用非结构化的稀疏性在当前系统上达到$ 1.14 \ times $速度而不会损害准确性。代码：此HTTPS URL</li>
</ul>

<h3>Title: Not-So-Optimal Transport Flows for 3D Point Cloud Generation</h3>
<ul>
<li><strong>Authors: </strong>Ka-Hei Hui, Chao Liu, Xiaohui Zeng, Chi-Wing Fu, Arash Vahdat</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12456">https://arxiv.org/abs/2502.12456</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12456">https://arxiv.org/pdf/2502.12456</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12456]] Not-So-Optimal Transport Flows for 3D Point Cloud Generation(https://arxiv.org/abs/2502.12456)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Learning generative models of 3D point clouds is one of the fundamental problems in 3D generative learning. One of the key properties of point clouds is their permutation invariance, i.e., changing the order of points in a point cloud does not change the shape they represent. In this paper, we analyze the recently proposed equivariant OT flows that learn permutation invariant generative models for point-based molecular data and we show that these models scale poorly on large point clouds. Also, we observe learning (equivariant) OT flows is generally challenging since straightening flow trajectories makes the learned flow model complex at the beginning of the trajectory. To remedy these, we propose not-so-optimal transport flow models that obtain an approximate OT by an offline OT precomputation, enabling an efficient construction of OT pairs for training. During training, we can additionally construct a hybrid coupling by combining our approximate OT and independent coupling to make the target flow models easier to learn. In an extensive empirical study, we show that our proposed model outperforms prior diffusion- and flow-based approaches on a wide range of unconditional generation and shape completion on the ShapeNet benchmark.</li>
<li><strong>摘要：</strong>3D点云的学习生成模型是3D生成学习中的基本问题之一。点云的关键属性之一是它们的置换不变性，即更改点云中点的顺序不会改变它们代表的形状。在本文中，我们分析了最近提出的模棱两可的OT流量，这些流量学习了基于点的分子数据的排列不变生成模型，并且我们表明这些模型在大点云上的扩展很差。同样，我们观察到学习（均等）的OT流通常具有挑战性，因为拉直的流量轨迹使学习的流程模型在轨迹开头变得复杂。为了解决这些问题，我们提出了不太最佳的运输流量模型，该模型通过离线OT预成立获得了近似的OT，从而有效地构造了OT对进行训练。在训练过程中，我们可以通过组合大概的OT和独立耦合来构建混合耦合，从而使目标流程模型更易于学习。在一项广泛的实证研究中，我们表明，我们提出的模型优于先前的扩散和基于流动的方法，在Shapenet基准上的各种无条件生成和形状完成上都超过了基于流动的方法。</li>
</ul>

<h3>Title: Computational-Statistical Tradeoffs at the Next-Token Prediction Barrier: Autoregressive and Imitation Learning under Misspecification</h3>
<ul>
<li><strong>Authors: </strong>Dhruv Rohatgi, Adam Block, Audrey Huang, Akshay Krishnamurthy, Dylan J. Foster</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12465">https://arxiv.org/abs/2502.12465</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12465">https://arxiv.org/pdf/2502.12465</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12465]] Computational-Statistical Tradeoffs at the Next-Token Prediction Barrier: Autoregressive and Imitation Learning under Misspecification(https://arxiv.org/abs/2502.12465)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Next-token prediction with the logarithmic loss is a cornerstone of autoregressive sequence modeling, but, in practice, suffers from error amplification, where errors in the model compound and generation quality degrades as sequence length $H$ increases. From a theoretical perspective, this phenomenon should not appear in well-specified settings, and, indeed, a growing body of empirical work hypothesizes that misspecification, where the learner is not sufficiently expressive to represent the target distribution, may be the root cause. Under misspecification -- where the goal is to learn as well as the best-in-class model up to a multiplicative approximation factor $C\geq 1$ -- we confirm that $C$ indeed grows with $H$ for next-token prediction, lending theoretical support to this empirical hypothesis. We then ask whether this mode of error amplification is avoidable algorithmically, computationally, or information-theoretically, and uncover inherent computational-statistical tradeoffs. We show: (1) Information-theoretically, one can avoid error amplification and achieve $C=O(1)$. (2) Next-token prediction can be made robust so as to achieve $C=\tilde O(H)$, representing moderate error amplification, but this is an inherent barrier: any next-token prediction-style objective must suffer $C=\Omega(H)$. (3) For the natural testbed of autoregressive linear models, no computationally efficient algorithm can achieve sub-polynomial approximation factor $C=e^{(\log H)^{1-\Omega(1)}}$; however, at least for binary token spaces, one can smoothly trade compute for statistical power and improve on $C=\Omega(H)$ in sub-exponential time. Our results have consequences in the more general setting of imitation learning, where the widely-used behavior cloning algorithm generalizes next-token prediction.</li>
<li><strong>摘要：</strong>对数损失的下一步预测是自回归序列建模的基石，但实际上，遇到了错误扩增，其中模型复合和发电质量的错误会随着序列长度的增加而降低$ h $。从理论的角度来看，这种现象不应出现在明确的环境中，而且实际上，越来越多的经验工作假设，在学习者不足以表达不足以代表目标分布的情况下，可能是根本原因。在错误指定下 - 目标是学习以及最佳的课堂模型，直至乘法近似因子$ c \ geq 1 $  - 我们确认$ c $的确会随着$ h $而增长预测，对这一经验假设的理论支持。然后，我们询问这种错误放大模式是否可以从计算上，计算或信息上避免算法，并发现固有的计算统计折衷方案。我们显示：（1）从理论上讲，可以避免错误放大并实现$ C = O（1）$。 （2）可以做出稳健的预测，以实现$ c = \ tilde o（h）$，代表中度错误放大，但这是一个固有的障碍：任何下一步的预测式目标都必须遭受$ c = \ Omega（H）$。 （3）对于自回归线性模型的天然测试床，没有计算有效的算法可以实现亚多物种近似因子$ c = e^{（\ log h）^{1- \ omega（1- \ omega（1）}} $;但是，至少对于二进制代币空间，可以在亚指数时间内平稳地交易统计功率，并在$ c = \ omega（h）$上提高。我们的结果在模仿学习的更一般的环境中产生了后果，在这种情况下，广泛使用的行为克隆算法概括了下一句话的预测。</li>
</ul>

<h3>Title: MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Yutong Wang, Pengliang Ji, Chaoqun Yang, Kaixin Li, Ming Hu, Jiaoyang Li, Guillaume Sartoretti</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12468">https://arxiv.org/abs/2502.12468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12468">https://arxiv.org/pdf/2502.12468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12468]] MCTS-Judge: Test-Time Scaling in LLM-as-a-Judge for Code Correctness Evaluation(https://arxiv.org/abs/2502.12468)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The LLM-as-a-Judge paradigm shows promise for evaluating generative content but lacks reliability in reasoning-intensive scenarios, such as programming. Inspired by recent advances in reasoning models and shifts in scaling laws, we pioneer bringing test-time computation into LLM-as-a-Judge, proposing MCTS-Judge, a resource-efficient, System-2 thinking framework for code correctness evaluation. MCTS-Judge leverages Monte Carlo Tree Search (MCTS) to decompose problems into simpler, multi-perspective evaluations. Through a node-selection strategy that combines self-assessment based on historical actions in the current trajectory and the Upper Confidence Bound for Trees based on prior rollouts, MCTS-Judge balances global optimization and refinement of the current trajectory. We further designed a high-precision, unit-test-level reward mechanism to encourage the Large Language Model (LLM) to perform line-by-line analysis. Extensive experiments on three benchmarks and five LLMs demonstrate the effectiveness of MCTS-Judge, which improves the base model's accuracy from 41% to 80%, surpassing the o1-series models with 3x fewer tokens. Further evaluations validate the superiority of its reasoning trajectory in logic, analytics, thoroughness, and overall quality, while revealing the test-time scaling law of the LLM-as-a-Judge paradigm.</li>
<li><strong>摘要：</strong>LLM-AS-A-Gudge范式显示出评估生成内容的希望，但在推理密集型方案（例如编程）中缺乏可靠性。受推理模型的最新进展和缩放定律的转变的启发，我们开创了将测试时间计算带入LLM-AS-A-Gudge，提出了MCTS-Gudge，这是一个资源效率高，系统-System-System-System-2思维框架，用于代码正确性评估。 MCTS法官利用蒙特卡洛树搜索（MCT）将问题分解为更简单的多人评估。通过一种节点选择策略，该策略根据当前轨迹中的历史动作和基于先前的推出，MCTS判断力平衡了全局优化和当前轨迹的完善，从而结合了自我评估。我们进一步设计了一种高精度，单位测试级的奖励机制，以鼓励大型语言模型（LLM）进行逐线分析。对三个基准和五个LLM的广泛实验证明了MCT-Gudge的有效性，这将基本模型的准确性从41％提高到80％，超过了少3倍令牌的O1系列模型。进一步的评估证实了其推理轨迹在逻辑，分析，彻底和整体质量方面的优越性，同时揭示了LLM-AS-A-A-A-Gudge范式的测试时间缩放定律。</li>
</ul>

<h3>Title: RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm</h3>
<ul>
<li><strong>Authors: </strong>Tiancheng Gu, Kaicheng Yang, Chaoyi Zhang, Yin Xie, Xiang An, Ziyong Feng, Dongnan Liu, Weidong Cai, Jiankang Deng</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12513">https://arxiv.org/abs/2502.12513</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12513">https://arxiv.org/pdf/2502.12513</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12513]] RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm(https://arxiv.org/abs/2502.12513)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>After pre-training on extensive image-text pairs, Contrastive Language-Image Pre-training (CLIP) demonstrates promising performance on a wide variety of benchmarks. However, a substantial volume of non-paired data, such as multimodal interleaved documents, remains underutilized for vision-language representation learning. To fully leverage these unpaired documents, we initially establish a Real-World Data Extraction pipeline to extract high-quality images and texts. Then we design a hierarchical retrieval method to efficiently associate each image with multiple semantically relevant realistic texts. To further enhance fine-grained visual information, we propose an image semantic augmented generation module for synthetic text production. Furthermore, we employ a semantic balance sampling strategy to improve dataset diversity, enabling better learning of long-tail concepts. Based on these innovations, we construct RealSyn, a dataset combining realistic and synthetic texts, available in three scales: 15M, 30M, and 100M. Extensive experiments demonstrate that RealSyn effectively advances vision-language representation learning and exhibits strong scalability. Models pre-trained on RealSyn achieve state-of-the-art performance on multiple downstream tasks. To facilitate future research, the RealSyn dataset and pre-trained model weights are released at this https URL.</li>
<li><strong>摘要：</strong>在广泛的图像文本对进行预训练之后，对比的语言图像预训练（剪辑）在各种基准上都表现出有希望的表现。但是，大量的非生产数据（例如多模式交错文档）仍未用于视觉表示学习。为了充分利用这些未配对的文档，我们最初建立了一个现实世界中的数据提取管道来提取高质量的图像和文本。然后，我们设计了一种分层检索方法，以有效地将每个图像与多个语义相关的现实文本相关联。为了进一步增强细粒度的视觉信息，我们提出了一个图像语义增强生成模块，用于合成文本生产。此外，我们采用语义平衡采样策略来改善数据集多样性，从而更好地学习长尾概念。基于这些创新，我们构建了一个结合现实和合成文本的数据集，分为三个尺度：15m，30m和100m。广泛的实验表明，Rearsyn有效地提高了视觉表示的学习并表现出强大的可扩展性。在Realsyn进行的预训练的模型在多个下游任务上实现了最新的性能。为了促进未来的研究，在此HTTPS URL上发布了Rearsyn数据集和预训练的模型权重。</li>
</ul>

<h3>Title: MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment Retrieval Within Long Videos</h3>
<ul>
<li><strong>Authors: </strong>Huaying Yuan, Jian Ni, Yueze Wang, Junjie Zhou, Zhengyang Liang, Zheng Liu, Zhao Cao, Zhicheng Dou, Ji-Rong Wen</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12558">https://arxiv.org/abs/2502.12558</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12558">https://arxiv.org/pdf/2502.12558</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12558]] MomentSeeker: A Comprehensive Benchmark and A Strong Baseline For Moment Retrieval Within Long Videos(https://arxiv.org/abs/2502.12558)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Retrieval augmented generation (RAG) holds great promise in addressing challenges associated with long video understanding. These methods retrieve useful moments from long videos for their presented tasks, thereby enabling multimodal large language models (MLLMs) to generate high-quality answers in a cost-effective way. In this work, we present MomentSeeker, a comprehensive benchmark to evaluate retrieval models' performance in handling general long-video moment retrieval (LVMR) tasks. MomentSeeker offers three key advantages. First, it incorporates long videos of over 500 seconds on average, making it the first benchmark specialized for long-video moment retrieval. Second, it covers a wide range of task categories (including Moment Search, Caption Alignment, Image-conditioned Moment Search, and Video-conditioned Moment Search) and diverse application scenarios (e.g., sports, movies, cartoons, and ego), making it a comprehensive tool for assessing retrieval models' general LVMR performance. Additionally, the evaluation tasks are carefully curated through human annotation, ensuring the reliability of assessment. We further fine-tune an MLLM-based LVMR retriever on synthetic data, which demonstrates strong performance on our benchmark. We perform extensive experiments with various popular multimodal retrievers based on our benchmark, whose results highlight the challenges of LVMR and limitations for existing methods. Our created resources will be shared with community to advance future research in this field.</li>
<li><strong>摘要：</strong>检索增强发电（RAG）在解决与长期视频理解相关的挑战方面具有巨大的希望。这些方法从长视频中获取了有用的时刻，以完成其呈现的任务，从而使多模式大型语言模型（MLLMS）以具有成本效益的方式生成高质量的答案。在这项工作中，我们介绍了MomentSeeker，这是一个全面的基准，旨在评估检索模型在处理一般远程Video Moment检索（LVMR）任务时的性能。 MomentSeeker提供了三个关键优势。首先，它平均包含了长500秒的长视频，这使其成为第一个专门用于Longvideo Moment检索的基准。其次，它涵盖了广泛的任务类别（包括时刻搜索，字幕对齐，图像条件时刻的搜索以及视频条件的时刻搜索）和各种应用程序场景（例如，体育，电影，电影，卡通和自我）评估检索模型的一般LVMR性能的综合工具。此外，评估任务是通过人类注释仔细策划的，从而确保了评估的可靠性。我们进一步调整了基于MLLM的LVMR回收师的合成数据，这表明我们的基准表现出强烈的性能。我们基于我们的基准，对各种流行的多模式检索器进行了广泛的实验，其结果突出了LVMR的挑战以及现有方法的局限性。我们创建的资源将与社区共享，以推进该领域的未来研究。</li>
</ul>

<h3>Title: DeltaDiff: A Residual-Guided Diffusion Model for Enhanced Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Chao Yang, Yong Fan, Cheng Lu, Zhijing Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12567">https://arxiv.org/abs/2502.12567</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12567">https://arxiv.org/pdf/2502.12567</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12567]] DeltaDiff: A Residual-Guided Diffusion Model for Enhanced Image Super-Resolution(https://arxiv.org/abs/2502.12567)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution, generation</a></li>
<li><strong>Abstract: </strong>Recently, the application of diffusion models in super-resolution tasks has become a popular research direction. Existing work is focused on fully migrating diffusion models to SR tasks. The diffusion model is proposed in the field of image generation, so in order to make the generated results diverse, the diffusion model combines random Gaussian noise and distributed sampling to increase the randomness of the model. However, the essence of super-resolution tasks requires the model to generate high-resolution images with fidelity. Excessive addition of random factors can result in the model generating detailed information that does not belong to the HR image. To address this issue, we propose a new diffusion model called Deltadiff, which uses only residuals between images for diffusion, making the entire diffusion process more stable. The experimental results show that our method surpasses state-of-the-art models and generates results with better fidelity. Our code and model are publicly available at this https URL</li>
<li><strong>摘要：</strong>最近，扩散模型在超分辨率任务中的应用已成为流行的研究方向。现有的工作集中在将扩散模型完全迁移到SR任务上。扩散模型是在图像生成领域提出的，因此为了使生成的结果多样化，扩散模型结合了随机的高斯噪声和分布式采样，以增加模型的随机性。但是，超分辨率任务的本质要求模型以富裕性生成高分辨率图像。过度添加随机因素可能会导致模型生成不属于HR图像的详细信息。为了解决这个问题，我们提出了一个称为Deltadiff的新扩散模型，该模型仅在图像之间使用残差进行扩散，从而使整个扩散过程更加稳定。实验结果表明，我们的方法超过了最先进的模型，并以更好的保真度生成结果。我们的代码和模型在此HTTPS URL上公开可用</li>
</ul>

<h3>Title: GVTNet: Graph Vision Transformer For Face Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Chao Yang, Yong Fan, Cheng Lu, Minghao Yuan, Zhijing Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12570">https://arxiv.org/abs/2502.12570</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12570">https://arxiv.org/pdf/2502.12570</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12570]] GVTNet: Graph Vision Transformer For Face Super-Resolution(https://arxiv.org/abs/2502.12570)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution</a></li>
<li><strong>Abstract: </strong>Recent advances in face super-resolution research have utilized the Transformer architecture. This method processes the input image into a series of small patches. However, because of the strong correlation between different facial components in facial images. When it comes to super-resolution of low-resolution images, existing algorithms cannot handle the relationships between patches well, resulting in distorted facial components in the super-resolution results. To solve the problem, we propose a transformer architecture based on graph neural networks called graph vision transformer network. We treat each patch as a graph node and establish an adjacency matrix based on the information between patches. In this way, the patch only interacts between neighboring patches, further processing the relationship of facial components. Quantitative and visualization experiments have underscored the superiority of our algorithm over state-of-the-art techniques. Through detailed comparisons, we have demonstrated that our algorithm possesses more advanced super-resolution capabilities, particularly in enhancing facial components. The PyTorch code is available at this https URL</li>
<li><strong>摘要：</strong>面对超分辨率研究的最新进展利用了变压器体系结构。此方法将输入图像处理为一系列小贴片。但是，由于面部图像中不同面部成分之间的相关性很强。当涉及到低分辨率图像的超分辨率时，现有算法无法很好地处理贴片之间的关系，从而导致超分辨率结果中的面部成分扭曲。为了解决问题，我们提出了一个基于图形神经网络的变压器体系结构，称为Graph Vision Transformer网络。我们将每个贴片视为图形节点，并根据补丁之间的信息建立邻接矩阵。通过这种方式，补丁仅在相邻的补丁之间进行交互，从而进一步处理面部成分的关系。定量和可视化实验强调了我们算法优于最先进的技术。通过详细的比较，我们证明了我们的算法具有更先进的超分辨率功能，尤其是在增强面部成分方面。 Pytorch代码可在此HTTPS URL上找到</li>
</ul>

<h3>Title: HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading</h3>
<ul>
<li><strong>Authors: </strong>Cheng Luo, Zefan Cai, Hanshi Sun, Jinqi Xiao, Bo Yuan, Wen Xiao, Junjie Hu, Jiawei Zhao, Beidi Chen, Anima Anandkumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12574">https://arxiv.org/abs/2502.12574</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12574">https://arxiv.org/pdf/2502.12574</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12574]] HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading(https://arxiv.org/abs/2502.12574)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Transformer-based large language models (LLMs) demonstrate impressive performance in long context generation. Extending the context length has disproportionately shifted the memory footprint of LLMs during inference to the key-value cache (KV cache). In this paper, we propose HEADINFER, which offloads the KV cache to CPU RAM while avoiding the need to fully store the KV cache for any transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise offloading strategy, maintaining only selective attention heads KV cache on the GPU while computing attention output dynamically. Through roofline analysis, we demonstrate that HEADINFER maintains computational efficiency while significantly reducing memory footprint. We evaluate HEADINFER on the Llama-3-8B model with a 1-million-token sequence, reducing the GPU memory footprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage from 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline inference. Notably, HEADINFER enables 4-million-token inference with an 8B model on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without approximation methods.</li>
<li><strong>摘要：</strong>基于变压器的大型语言模型（LLMS）在长篇小说生成中表现出令人印象深刻的表现。扩展上下文长度的时间不成比例地将LLMS的内存足迹转移到了键值缓存（KV CACH）。在本文中，我们提出了HeadInfer，该文件将KV缓存卸载到CPU RAM，同时避免需要将KV缓存完全存储在GPU上的任何变压器层。 HeadInfer采用了细粒度的额外卸载策略，在动态计算注意力输出的同时，仅保持选择性注意力头在GPU上的KV缓存。通过屋顶线分析，我们证明了HeadInfer保持计算效率，同时显着降低了内存足迹。我们以100万token序列评估了Llama-3-8b模型上的Headinfer，将KV Cache的GPU内存足迹从128 GB降低到1 GB，总GPU存储器的总使用率从207 GB到17 GB，从而实现了A与BF16基线推断相比，减少了92％。值得注意的是，HeadInfer在具有24GB内存的单个消费者GPU上使用8B模型启用了400万次推理（例如，NVIDIA RTX 4090），没有近似方法。</li>
</ul>

<h3>Title: CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Minghao Fu, Guo-Hua Wang, Liangfu Cao, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12579">https://arxiv.org/abs/2502.12579</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12579">https://arxiv.org/pdf/2502.12579</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12579]] CHATS: Combining Human-Aligned Optimization and Test-Time Sampling for Text-to-Image Generation(https://arxiv.org/abs/2502.12579)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Diffusion models have emerged as a dominant approach for text-to-image generation. Key components such as the human preference alignment and classifier-free guidance play a crucial role in ensuring generation quality. However, their independent application in current text-to-image models continues to face significant challenges in achieving strong text-image alignment, high generation quality, and consistency with human aesthetic standards. In this work, we for the first time, explore facilitating the collaboration of human performance alignment and test-time sampling to unlock the potential of text-to-image models. Consequently, we introduce CHATS (Combining Human-Aligned optimization and Test-time Sampling), a novel generative framework that separately models the preferred and dispreferred distributions and employs a proxy-prompt-based sampling strategy to utilize the useful information contained in both distributions. We observe that CHATS exhibits exceptional data efficiency, achieving strong performance with only a small, high-quality funetuning dataset. Extensive experiments demonstrate that CHATS surpasses traditional preference alignment methods, setting new state-of-the-art across various standard benchmarks.</li>
<li><strong>摘要：</strong>扩散模型已成为文本到图像生成的主要方法。关键组成部分，例如人类的偏好一致性和无分类器指导在确保发电质量方面起着至关重要的作用。但是，它们在当前文本形象模型中的独立应用在实现强大的文本图像一致性，高发电质量以及与人类美学标准的一致性方面继续面临重大挑战。在这项工作中，我们首次探索了促进人类绩效一致性和测试时间抽样的协作，以释放文本对图像模型的潜力。因此，我们介绍了聊天（结合了人类一致的优化和测试时间抽样），这是一个新颖的生成框架，分别对首选和分配的分布进行了建模，并采用了基于代理促进的采样策略来利用两个分布中包含的有用信息。我们观察到，聊天表现出卓越的数据效率，仅使用一个小的高质量的娱乐数据集实现了强劲的性能。广泛的实验表明，聊天超过了传统的偏好对准方法，在各种标准基准中设定了新的最新方法。</li>
</ul>

<h3>Title: Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining</h3>
<ul>
<li><strong>Authors: </strong>Jinfan Hu, Zhiyuan You, Jinjin Gu, Kaiwen Zhu, Tianfan Xue, Chao Dong</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12600">https://arxiv.org/abs/2502.12600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12600">https://arxiv.org/pdf/2502.12600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12600]] Revisiting the Generalization Problem of Low-level Vision Models Through the Lens of Image Deraining(https://arxiv.org/abs/2502.12600)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generalization remains a significant challenge for low-level vision models, which often struggle with unseen degradations in real-world scenarios despite their success in controlled benchmarks. In this paper, we revisit the generalization problem in low-level vision models. Image deraining is selected as a case study due to its well-defined and easily decoupled structure, allowing for more effective observation and analysis. Through comprehensive experiments, we reveal that the generalization issue is not primarily due to limited network capacity but rather the failure of existing training strategies, which leads networks to overfit specific degradation patterns. Our findings show that guiding networks to focus on learning the underlying image content, rather than the degradation patterns, is key to improving generalization. We demonstrate that balancing the complexity of background images and degradations in the training data helps networks better fit the image distribution. Furthermore, incorporating content priors from pre-trained generative models significantly enhances generalization. Experiments on both image deraining and image denoising validate the proposed strategies. We believe the insights and solutions will inspire further research and improve the generalization of low-level vision models.</li>
<li><strong>摘要：</strong>对于低级视觉模型来说，概括仍然是一个重大挑战，尽管他们在受控的基准中成功，但在现实世界中，在现实世界中通常会在现实情况下遇到任何艰难的挑战。在本文中，我们在低级视觉模型中重新审视了概括问题。由于其定义明确且易于脱钩的结构，因此选择了图像DEDANES作为案例研究，从而可以进行更有效的观察和分析。通过全面的实验，我们揭示了概括问题并不是由于网络容量有限，而是现有培训策略的失败，这导致网络过度适合特定的降级模式。我们的发现表明，指导网络专注于学习基础图像内容而不是降解模式，这是改善概括的关键。我们证明，平衡背景图像的复杂性和培训数据中的降解有助于网络更好地适合图像分布。此外，结合了预训练的生成模型的内容先验会显着增强概括。对图像降低和图像的实验验证了提出的策略。我们认为，见解和解决方案将激发进一步的研究并改善低级视力模型的概括。</li>
</ul>

<h3>Title: Disentangling Long-Short Term State Under Unknown Interventions for Online Time Series Forecasting</h3>
<ul>
<li><strong>Authors: </strong>Ruichu Cai, Haiqin Huang, Zhifang Jiang, Zijian Li, Changze Zhou, Yuequn Liu, Yuming Liu, Zhifeng Hao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12603">https://arxiv.org/abs/2502.12603</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12603">https://arxiv.org/pdf/2502.12603</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12603]] Disentangling Long-Short Term State Under Unknown Interventions for Online Time Series Forecasting(https://arxiv.org/abs/2502.12603)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Current methods for time series forecasting struggle in the online scenario, since it is difficult to preserve long-term dependency while adapting short-term changes when data are arriving sequentially. Although some recent methods solve this problem by controlling the updates of latent states, they cannot disentangle the long/short-term states, leading to the inability to effectively adapt to nonstationary. To tackle this challenge, we propose a general framework to disentangle long/short-term states for online time series forecasting. Our idea is inspired by the observations where short-term changes can be led by unknown interventions like abrupt policies in the stock market. Based on this insight, we formalize a data generation process with unknown interventions on short-term states. Under mild assumptions, we further leverage the independence of short-term states led by unknown interventions to establish the identification theory to achieve the disentanglement of long/short-term states. Built on this theory, we develop a long short-term disentanglement model (LSTD) to extract the long/short-term states with long/short-term encoders, respectively. Furthermore, the LSTD model incorporates a smooth constraint to preserve the long-term dependencies and an interrupted dependency constraint to enforce the forgetting of short-term dependencies, together boosting the disentanglement of long/short-term states. Experimental results on several benchmark datasets show that our \textbf{LSTD} model outperforms existing methods for online time series forecasting, validating its efficacy in real-world applications.</li>
<li><strong>摘要：</strong>时间序列的当前方法在在线方案中预测斗争，因为在数据依次到达时，很难保留长期依赖性，同时适应短期变化。尽管最近的一些方法通过控制潜在状态的更新来解决此问题，但它们无法解散长/短期状态，从而导致无法有效适应非平稳性。为了应对这一挑战，我们提出了一个通用框架，以将在线时间序列预测的长期/短期状态删除。我们的想法的灵感来自于观察结果，即短期变化可以由诸如股票市场的突然政策之类的未知干预措施引起。基于这种见解，我们将数据生成过程正式化，并在短期状态下采取未知干预措施。在温和的假设下，我们进一步利用了由未知干预措施领导的短期状态的独立性，以建立识别理论，以实现长/短期状态的分离。基于该理论，我们开发了长期的短期解开模型（LSTD），分别用长/短期编码器提取长/短期状态。此外，LSTD模型结合了平稳的约束，以保留长期依赖性和中断的依赖性约束，以实施忘记短期依赖性，从而加强了长期/短期状态的分散。几个基准数据集的实验结果表明，我们的\ textBf {lstd}模型优于在线时间序列预测的现有方法，从而验证了其在现实世界应用程序中的效果。</li>
</ul>

<h3>Title: MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Sihyun Yu, Meera Hahn, Dan Kondratyuk, Jinwoo Shin, Agrim Gupta, José Lezama, Irfan Essa, David Ross, Jonathan Huang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12632">https://arxiv.org/abs/2502.12632</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12632">https://arxiv.org/pdf/2502.12632</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12632]] MALT Diffusion: Memory-Augmented Latent Transformers for Any-Length Video Generation(https://arxiv.org/abs/2502.12632)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion models are successful for synthesizing high-quality videos but are limited to generating short clips (e.g., 2-10 seconds). Synthesizing sustained footage (e.g. over minutes) still remains an open research question. In this paper, we propose MALT Diffusion (using Memory-Augmented Latent Transformers), a new diffusion model specialized for long video generation. MALT Diffusion (or just MALT) handles long videos by subdividing them into short segments and doing segment-level autoregressive generation. To achieve this, we first propose recurrent attention layers that encode multiple segments into a compact memory latent vector; by maintaining this memory vector over time, MALT is able to condition on it and continuously generate new footage based on a long temporal context. We also present several training techniques that enable the model to generate frames over a long horizon with consistent quality and minimal degradation. We validate the effectiveness of MALT through experiments on long video benchmarks. We first perform extensive analysis of MALT in long-contextual understanding capability and stability using popular long video benchmarks. For example, MALT achieves an FVD score of 220.4 on 128-frame video generation on UCF-101, outperforming the previous state-of-the-art of 648.4. Finally, we explore MALT's capabilities in a text-to-video generation setting and show that it can produce long videos compared with recent techniques for long text-to-video generation.</li>
<li><strong>摘要：</strong>扩散模型成功地综合了高质量的视频，但仅限于生成短夹（例如2-10秒）。综合持续录像（例如，在几分钟内）仍然是一个开放的研究问题。在本文中，我们提出了麦芽扩散（使用内存增强潜在变压器），这是一种专门用于长视频生成的新扩散模型。麦芽扩散（或只是麦芽）通过将它们细分为短段并进行细分级自回归产生来处理长视频。为了实现这一目标，我们首先提出了重复的注意层，将多个段编码为紧凑的内存潜在向量。通过随着时间的推移维护此内存向量，麦芽能够在其上调节并根据长时间的上下文不断生成新的素材。我们还提出了几种训练技术，使该模型能够在较长的地平线上生成框架，并具有一致的质量和最小的退化。我们通过在长期视频基准上实验来验证麦芽的有效性。我们首先使用流行的长视频基准对麦芽进行了大量的分析，以长期理解的能力和稳定性进行了广泛的分析。例如，麦芽在UCF-101上的128帧视频生成上的FVD得分为220.4，表现优于先前的648.4最新时间。最后，我们在文本到视频生成环境中探索了麦芽的功能，并表明它可以与最新文本到视频生成技术相比，可以产生长时间的视频。</li>
</ul>

<h3>Title: RecDreamer: Consistent Text-to-3D Generation via Uniform Score Distillation</h3>
<ul>
<li><strong>Authors: </strong>Chenxi Zheng, Yihong Lin, Bangzhen Liu, Xuemiao Xu, Yongwei Nie, Shengfeng He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12640">https://arxiv.org/abs/2502.12640</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12640">https://arxiv.org/pdf/2502.12640</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12640]] RecDreamer: Consistent Text-to-3D Generation via Uniform Score Distillation(https://arxiv.org/abs/2502.12640)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Current text-to-3D generation methods based on score distillation often suffer from geometric inconsistencies, leading to repeated patterns across different poses of 3D assets. This issue, known as the Multi-Face Janus problem, arises because existing methods struggle to maintain consistency across varying poses and are biased toward a canonical pose. While recent work has improved pose control and approximation, these efforts are still limited by this inherent bias, which skews the guidance during generation. To address this, we propose a solution called RecDreamer, which reshapes the underlying data distribution to achieve a more consistent pose representation. The core idea behind our method is to rectify the prior distribution, ensuring that pose variation is uniformly distributed rather than biased toward a canonical form. By modifying the prescribed distribution through an auxiliary function, we can reconstruct the density of the distribution to ensure compliance with specific marginal constraints. In particular, we ensure that the marginal distribution of poses follows a uniform distribution, thereby eliminating the biases introduced by the prior knowledge. We incorporate this rectified data distribution into existing score distillation algorithms, a process we refer to as uniform score distillation. To efficiently compute the posterior distribution required for the auxiliary function, RecDreamer introduces a training-free classifier that estimates pose categories in a plug-and-play manner. Additionally, we utilize various approximation techniques for noisy states, significantly improving system performance. Our experimental results demonstrate that RecDreamer effectively mitigates the Multi-Face Janus problem, leading to more consistent 3D asset generation across different poses.</li>
<li><strong>摘要：</strong>基于得分蒸馏的当前文本到3D生成方法通常会遇到几何不一致，从而导致3D资产不同姿势的重复模式。由于现有的方法难以在不同的姿势中保持一致性，并偏向于规范的姿势，因此出现了这个问题，称为多面性问题。尽管最近的工作改善了姿势控制和近似，但这些努力仍然受到这种固有的偏见的限制，这种偏见偏向于发电期间的指导。为了解决这个问题，我们提出了一个称为RecDreamer的解决方案，该解决方案重塑了基础数据分布以实现更一致的姿势表示。我们方法背后的核心思想是纠正先前的分布，确保姿势变化均匀分布，而不是偏向于规范形式。通过通过辅助函数修改规定的分布，我们可以重建分布的密度，以确保符合特定的边缘约束。特别是，我们确保姿势的边际分布遵循统一的分布，从而消除了先验知识引入的偏见。我们将此整流的数据分布纳入现有的得分蒸馏算法中，这一过程称为统一分数蒸馏。为了有效地计算辅助功能所需的后验分布，RecDreamer引入了无训练分类器，该分类器以插件的方式估算姿势类别。此外，我们为嘈杂状态使用了各种近似技术，从而显着提高了系统性能。我们的实验结果表明，恢复者有效地减轻了多面Janus问题，从而导致不同姿势的3D资产产生更加一致。</li>
</ul>

<h3>Title: 3D Shape-to-Image Brownian Bridge Diffusion for Brain MRI Synthesis from Cortical Surfaces</h3>
<ul>
<li><strong>Authors: </strong>Fabian Bongratz, Yitong Li, Sama Elbaroudy, Christian Wachinger</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12742">https://arxiv.org/abs/2502.12742</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12742">https://arxiv.org/pdf/2502.12742</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12742]] 3D Shape-to-Image Brownian Bridge Diffusion for Brain MRI Synthesis from Cortical Surfaces(https://arxiv.org/abs/2502.12742)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Despite recent advances in medical image generation, existing methods struggle to produce anatomically plausible 3D structures. In synthetic brain magnetic resonance images (MRIs), characteristic fissures are often missing, and reconstructed cortical surfaces appear scattered rather than densely convoluted. To address this issue, we introduce Cor2Vox, the first diffusion model-based method that translates continuous cortical shape priors to synthetic brain MRIs. To achieve this, we leverage a Brownian bridge process which allows for direct structured mapping between shape contours and medical images. Specifically, we adapt the concept of the Brownian bridge diffusion model to 3D and extend it to embrace various complementary shape representations. Our experiments demonstrate significant improvements in the geometric accuracy of reconstructed structures compared to previous voxel-based approaches. Moreover, Cor2Vox excels in image quality and diversity, yielding high variation in non-target structures like the skull. Finally, we highlight the capability of our approach to simulate cortical atrophy at the sub-voxel level. Our code is available at this https URL.</li>
<li><strong>摘要：</strong>尽管医学图像产生的最新进展，但现有的方法却难以产生解剖学上合理的3D结构。在合成大脑磁共振图像（MRI）中，通常缺少特征裂缝，重建的皮质表面显得散射而不是密集的曲折。为了解决这个问题，我们介绍了Cor2Vox，这是第一个基于扩散模型的方法，将连续的皮质形状先验转换为合成脑MRIS。为了实现这一目标，我们利用了布朗桥工艺，该过程允许在形状轮廓和医学图像之间进行直接结构化映射。具体而言，我们将布朗桥扩散模型的概念调整为3D，并将其扩展以包含各种互补形状表示。与以前的基于体素的方法相比，我们的实验表明，重建结构的几何准确性有显着提高。此外，Cor2Vox在图像质量和多样性方面表现出色，在诸如头骨之类的非目标结构中产生了较高的变化。最后，我们强调了在亚素水平上模拟皮质萎缩的方法的能力。我们的代码可在此HTTPS URL上找到。</li>
</ul>

<h3>Title: Architect of the Bits World: Masked Autoregressive Modeling for Circuit Generation Guided by Truth Table</h3>
<ul>
<li><strong>Authors: </strong>Haoyuan Wu, Haisheng Zheng, Shoubo Hu, Zhuolun He, Bei Yu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12751">https://arxiv.org/abs/2502.12751</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12751">https://arxiv.org/pdf/2502.12751</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12751]] Architect of the Bits World: Masked Autoregressive Modeling for Circuit Generation Guided by Truth Table(https://arxiv.org/abs/2502.12751)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Logic synthesis, a critical stage in electronic design automation (EDA), optimizes gate-level circuits to minimize power consumption and area occupancy in integrated circuits (ICs). Traditional logic synthesis tools rely on human-designed heuristics, often yielding suboptimal results. Although differentiable architecture search (DAS) has shown promise in generating circuits from truth tables, it faces challenges such as high computational complexity, convergence to local optima, and extensive hyperparameter tuning. Consequently, we propose a novel approach integrating conditional generative models with DAS for circuit generation. Our approach first introduces CircuitVQ, a circuit tokenizer trained based on our Circuit AutoEncoder We then develop CircuitAR, a masked autoregressive model leveraging CircuitVQ as the tokenizer. CircuitAR can generate preliminary circuit structures from truth tables, which guide DAS in producing functionally equivalent circuits. Notably, we observe the scalability and emergent capability in generating complex circuit structures of our CircuitAR models. Extensive experiments also show the superior performance of our method. This research bridges the gap between probabilistic generative models and precise circuit generation, offering a robust solution for logic synthesis.</li>
<li><strong>摘要：</strong>逻辑合成是电子设计自动化（EDA）的关键阶段，它优化了栅极级电路，以最大程度地减少综合电路（ICS）中的功耗和面积占用率。传统的逻辑合成工具依赖于人类设计的启发式方法，通常会产生次优的结果。尽管可区分的体系结构搜索（DAS）在从真实表中生成电路方面表现出了希望，但它面临着诸如高计算复杂性，融合到本地Optima以及广泛的超参数调整等挑战。因此，我们提出了一种新颖的方法，将条件生成模型与DAS集成了电路生成。我们的方法首先引入电路VQ，这是一种经过电路自动编码器训练的电路令牌，然后我们开发了电路，这是一种掩盖的自动回归模型，将电路VQ作为令牌为标记。电路可以从真实表产生初步电路结构，这些电路表指导DAS生成功能等效电路。值得注意的是，我们观察到我们电路模型的复杂电路结构的可伸缩性和紧急能力。广泛的实验还显示了我们方法的出色性能。这项研究弥合了概率生成模型与精确电路产生之间的差距，为逻辑合成提供了强大的解决方案。</li>
</ul>

<h3>Title: High-Fidelity Novel View Synthesis via Splatting-Guided Diffusion</h3>
<ul>
<li><strong>Authors: </strong>Xiang Zhang, Yang Zhang, Lukas Mehl, Markus Gross, Christopher Schroers</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12752">https://arxiv.org/abs/2502.12752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12752">https://arxiv.org/pdf/2502.12752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12752]] High-Fidelity Novel View Synthesis via Splatting-Guided Diffusion(https://arxiv.org/abs/2502.12752)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Despite recent advances in Novel View Synthesis (NVS), generating high-fidelity views from single or sparse observations remains a significant challenge. Existing splatting-based approaches often produce distorted geometry due to splatting errors. While diffusion-based methods leverage rich 3D priors to achieve improved geometry, they often suffer from texture hallucination. In this paper, we introduce SplatDiff, a pixel-splatting-guided video diffusion model designed to synthesize high-fidelity novel views from a single image. Specifically, we propose an aligned synthesis strategy for precise control of target viewpoints and geometry-consistent view synthesis. To mitigate texture hallucination, we design a texture bridge module that enables high-fidelity texture generation through adaptive feature fusion. In this manner, SplatDiff leverages the strengths of splatting and diffusion to generate novel views with consistent geometry and high-fidelity details. Extensive experiments verify the state-of-the-art performance of SplatDiff in single-view NVS. Additionally, without extra training, SplatDiff shows remarkable zero-shot performance across diverse tasks, including sparse-view NVS and stereo video conversion.</li>
<li><strong>摘要：</strong>尽管新型视图合成（NVS）的最新进展，但从单一观察或稀疏观测中产生高保真视图仍然是一个重大挑战。现有的基于脱落的方法通常由于碎片错误而产生扭曲的几何形状。基于扩散的方法利用丰富的3D先验来实现改进的几何形状，但它们通常会遭受质地幻觉。在本文中，我们介绍了Splatdiff，这是一种像素切成引导的视频扩散模型，旨在从单个图像中综合高保真小说的视图。具体而言，我们提出了一种对齐的合成策略，以精确控制目标观点和几何符合视图的综合。为了减轻质地幻觉，我们设计了一个纹理桥模块，该模块可以通过自适应特征融合来实现高保真纹理的生成。通过这种方式，Splatdiff利用了脱落和扩散的优势，以产生具有一致的几何形状和高保真细节的新颖观点。广泛的实验验证了单视NVS中Splatdiff的最新性能。此外，如果没有额外的培训，Splatdiff在各种任务中都表现出了零拍的出色表现，包括稀疏视图NVS和立体视频转换。</li>
</ul>

<h3>Title: One-bit Compressed Sensing using Generative Models</h3>
<ul>
<li><strong>Authors: </strong>Swatantra Kafle, Geethu Joseph, Pramod K. Varshney</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12762">https://arxiv.org/abs/2502.12762</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12762">https://arxiv.org/pdf/2502.12762</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12762]] One-bit Compressed Sensing using Generative Models(https://arxiv.org/abs/2502.12762)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper addresses the classical problem of one-bit compressed sensing using a deep learning-based reconstruction algorithm that leverages a trained generative model to enhance the signal reconstruction performance. The generator, a pre-trained neural network, learns to map from a low-dimensional latent space to a higher-dimensional set of sparse vectors. This generator is then used to reconstruct sparse vectors from their one-bit measurements by searching over its range. The presented algorithm provides an excellent reconstruction performance because the generative model can learn additional structural information about the signal beyond sparsity. Furthermore, we provide theoretical guarantees on the reconstruction accuracy and sample complexity of the algorithm. Through numerical experiments using three publicly available image datasets, MNIST, Fashion-MNIST, and Omniglot, we demonstrate the superior performance of the algorithm compared to other existing algorithms and show that our algorithm can recover both the amplitude and the direction of the signal from one-bit measurements.</li>
<li><strong>摘要：</strong>本文使用基于深度学习的重建算法来解决一位压缩感测的经典问题，该算法利用训练有素的生成模型来增强信号重建性能。发电机是一种预先训练的神经网络，学会了从低维的潜在空间映射到较高维度的稀疏矢量集。然后，该发电机通过搜索其范围来从其一次性测量中重建稀疏向量。提出的算法提供了出色的重建性能，因为生成模型可以学习有关稀疏性信号的其他结构信息。此外，我们提供理论保证，以重建准确性和样品复杂性。通过使用三个公开可用的图像数据集，MNIST，时尚态和Omniglot进行的数值实验，我们证明了与其他现有算法相比，算法的出色性能，并表明我们的算法可以从一个幅度和信号方向恢复一个方向 - 位测量。</li>
</ul>

<h3>Title: Learning Counterfactually Fair Models via Improved Generation with Neural Causal Models</h3>
<ul>
<li><strong>Authors: </strong>Krishn Vishwas Kher, Aditya Varun V, Shantanu Das, SakethaNath Jagarlapudi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12796">https://arxiv.org/abs/2502.12796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12796">https://arxiv.org/pdf/2502.12796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12796]] Learning Counterfactually Fair Models via Improved Generation with Neural Causal Models(https://arxiv.org/abs/2502.12796)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>One of the main concerns while deploying machine learning models in real-world applications is fairness. Counterfactual fairness has emerged as an intuitive and natural definition of fairness. However, existing methodologies for enforcing counterfactual fairness seem to have two limitations: (i) generating counterfactual samples faithful to the underlying causal graph, and (ii) as we argue in this paper, existing regularizers are mere proxies and do not directly enforce the exact definition of counterfactual fairness. In this work, our aim is to mitigate both issues. Firstly, we propose employing Neural Causal Models (NCMs) for generating the counterfactual samples. For implementing the abduction step in NCMs, the posteriors of the exogenous variables need to be estimated given a counterfactual query, as they are not readily available. As a consequence, $\mathcal{L}_3$ consistency with respect to the underlying causal graph cannot be guaranteed in practice due to the estimation errors involved. To mitigate this issue, we propose a novel kernel least squares loss term that enforces the $\mathcal{L}_3$ constraints explicitly. Thus, we obtain an improved counterfactual generation suitable for the counterfactual fairness task. Secondly, we propose a new MMD-based regularizer term that explicitly enforces the counterfactual fairness conditions into the base model while training. We show an improved trade-off between counterfactual fairness and generalization over existing baselines on synthetic and benchmark datasets.</li>
<li><strong>摘要：</strong>在现实世界应用程序中部署机器学习模型的主要问题之一是公平。反事实公平已成为公平的直观自然的定义。但是，现有的实施反事实公平的方法似乎有两个局限性：（i）生成忠于基本因果图的反事实样本，（ii）正如我们在本文中所说的，现有的正规机构仅是代理，并且不直接强制强制执行确切的规定。反事实公平的定义。在这项工作中，我们的目标是减轻这两个问题。首先，我们建议采用神经因果模型（NCM）生成反事实样本。为了在NCMS中实施绑架步骤，在反事实查询的情况下，需要估算外源变量的后代，因为它们不容易获得。结果，由于所涉及的估计错误，在实践中不能保证相对于基本因果图的$ \ Mathcal {L} _3 $一致性。为了减轻此问题，我们提出了一个新颖的内核最小二乘损失项，该损失术语可以明确地强制执行$ \ Mathcal {l} _3 $。因此，我们获得了适合反事实公平任务的改进的反事实。其次，我们提出了一个新的基于MMD的正规术语，该术语在训练时明确地将反事实公平条件强化到基本模型中。我们在合成和基准数据集上的现有基准对反事实公平性和概括之间的权衡得到了改善。</li>
</ul>

<h3>Title: CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image</h3>
<ul>
<li><strong>Authors: </strong>Kaixin Yao, Longwen Zhang, Xinhao Yan, Yan Zeng, Qixuan Zhang, Lan Xu, Wei Yang, Jiayuan Gu, Jingyi Yu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12894">https://arxiv.org/abs/2502.12894</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12894">https://arxiv.org/pdf/2502.12894</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12894]] CAST: Component-Aligned 3D Scene Reconstruction from an RGB Image(https://arxiv.org/abs/2502.12894)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Recovering high-quality 3D scenes from a single RGB image is a challenging task in computer graphics. Current methods often struggle with domain-specific limitations or low-quality object generation. To address these, we propose CAST (Component-Aligned 3D Scene Reconstruction from a Single RGB Image), a novel method for 3D scene reconstruction and recovery. CAST starts by extracting object-level 2D segmentation and relative depth information from the input image, followed by using a GPT-based model to analyze inter-object spatial relationships. This enables the understanding of how objects relate to each other within the scene, ensuring more coherent reconstruction. CAST then employs an occlusion-aware large-scale 3D generation model to independently generate each object's full geometry, using MAE and point cloud conditioning to mitigate the effects of occlusions and partial object information, ensuring accurate alignment with the source image's geometry and texture. To align each object with the scene, the alignment generation model computes the necessary transformations, allowing the generated meshes to be accurately placed and integrated into the scene's point cloud. Finally, CAST incorporates a physics-aware correction step that leverages a fine-grained relation graph to generate a constraint graph. This graph guides the optimization of object poses, ensuring physical consistency and spatial coherence. By utilizing Signed Distance Fields (SDF), the model effectively addresses issues such as occlusions, object penetration, and floating objects, ensuring that the generated scene accurately reflects real-world physical interactions. CAST can be leveraged in robotics, enabling efficient real-to-simulation workflows and providing realistic, scalable simulation environments for robotic systems.</li>
<li><strong>摘要：</strong>从单个RGB图像中恢复高质量的3D场景是计算机图形中的一项具有挑战性的任务。当前的方法通常在特定领域的局限性或低质量的对象生成方面困难。为了解决这些问题，我们提出了铸造（从单个RGB图像中与组件一致的3D场景重建），这是一种用于3D场景重建和恢复的新方法。铸件首先从输入图像中提取对象级2D分割和相对深度信息，然后使用基于GPT的模型来分析对象间空间关系。这使人们可以理解对象在场景中之间相互关系，从而确保更连贯的重建。然后，使用MAE和点云调理来减轻闭塞和部分对象信息的效果，以确保与源图像的几何形状和纹理的准确对齐。为了使每个对象与场景保持一致，对齐生成模型计算必要的转换，从而使生成的网格被准确地放置并集成到场景的点云中。最后，Cast结合了一个物理感知的校正步骤，该步骤利用细粒的关系图生成约束图。该图指导对象姿势的优化，确保物理一致性和空间连贯性。通过利用签名的距离字段（SDF），该模型有效地解决了诸如遮挡，对象穿透和浮动对象等问题，从而确保生成的场景准确地反映了现实世界的物理交互。可以用机器人技术利用铸件，从而有效地实现实际仿真工作流，并为机器人系统提供现实，可扩展的仿真环境。</li>
</ul>

<h3>Title: Probabilistic neural operators for functional uncertainty quantification</h3>
<ul>
<li><strong>Authors: </strong>Christopher Bülte, Philipp Scholl, Gitta Kutyniok</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12902">https://arxiv.org/abs/2502.12902</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12902">https://arxiv.org/pdf/2502.12902</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12902]] Probabilistic neural operators for functional uncertainty quantification(https://arxiv.org/abs/2502.12902)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Neural operators aim to approximate the solution operator of a system of differential equations purely from data. They have shown immense success in modeling complex dynamical systems across various domains. However, the occurrence of uncertainties inherent in both model and data has so far rarely been taken into account\textemdash{}a critical limitation in complex, chaotic systems such as weather forecasting. In this paper, we introduce the probabilistic neural operator (PNO), a framework for learning probability distributions over the output function space of neural operators. PNO extends neural operators with generative modeling based on strictly proper scoring rules, integrating uncertainty information directly into the training process. We provide a theoretical justification for the approach and demonstrate improved performance in quantifying uncertainty across different domains and with respect to different baselines. Furthermore, PNO requires minimal adjustment to existing architectures, shows improved performance for most probabilistic prediction tasks, and leads to well-calibrated predictive distributions and adequate uncertainty representations even for long dynamical trajectories. Implementing our approach into large-scale models for physical applications can lead to improvements in corresponding uncertainty quantification and extreme event identification, ultimately leading to a deeper understanding of the prediction of such surrogate models.</li>
<li><strong>摘要：</strong>神经操作员旨在近似于数据的微分方程系统的解决方案操作员。他们在建模各个领域的复杂动力系统方面表现出了巨大的成功。但是，到目前为止，在模型和数据中固有的不确定性的发生很少考虑到\ textemdash {}在复杂的混乱系统（例如天气预报）中的关键限制。在本文中，我们介绍了概率神经操作员（PNO），这是一个在神经操作员输出功能空间上学习概率分布的框架。 PNO基于严格的适当评分规则，通过生成建模扩展神经操作员，将不确定性信息直接集成到培训过程中。我们为该方法提供了理论上的理由，并在量化不同领域的不确定性以及相对于不同基层方面的不确定性方面表现出改善的性能。此外，PNO需要对现有体系结构的最小调整，显示出大多数概率预测任务的性能，并导致良好的预测性分布和足够的不确定性表示，即使对于长时间的动态轨迹也是如此。将我们的方法实施到大规模的物理应用模型中可以改善相应的不确定性量化和极端事件识别，最终导致对这种替代模型的预测有了更深入的了解。</li>
</ul>

<h3>Title: Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options</h3>
<ul>
<li><strong>Authors: </strong>Lakshmi Nair, Ian Trase, Mark Kim</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12929">https://arxiv.org/abs/2502.12929</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12929">https://arxiv.org/pdf/2502.12929</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12929]] Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options(https://arxiv.org/abs/2502.12929)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>We present a novel reasoning approach called Flow-of-Options (FoO), designed to address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs to systematically explore a diverse range of possibilities in their reasoning, as demonstrated by an FoO-based agentic system for autonomously solving Machine Learning tasks (AutoML). Our framework outperforms state-of-the-art baselines, achieving improvements of 38.2% - 69.2% on standard data science tasks, and 37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost under $1 per task, our framework is well-suited for cost-sensitive applications. Beyond classification and regression, we illustrate the broader applicability of our FoO-based agentic system to tasks such as reinforcement learning and image generation. Our framework presents significant advancements compared to current state-of-the-art agentic systems for AutoML, due to the benefits of FoO in enforcing diversity in LLM solutions through compressed, explainable representations that also support long-term memory when combined with case-based reasoning.</li>
<li><strong>摘要：</strong>我们提出了一种称为选项流（FOO）的新型推理方法，旨在解决大语模型（LLMS）中的内在偏见。 FOO使LLM可以系统地探索其推理中各种可能性的可能性，如基于Foo的代理系统用于自主解决机器学习任务（AUTOML）所证明的那样。我们的框架的表现优于最先进的基线，在标准数据科学任务上取得了38.2％-69.2％的改善，在治疗化学任务方面，提高了37.4％-47.9％。每项任务的整体运营成本低于1美元，我们的框架非常适合对成本敏感的应用程序。除了分类和回归外，我们还说明了基于FOO的代理系统对诸如增强学习和图像生成等任务的更广泛的适用性。与当前的AutoML最新代理系统相比，我们的框架提出了重大进步推理。</li>
</ul>

<h3>Title: Guaranteed Conditional Diffusion: 3D Block-based Models for Scientific Data Compression</h3>
<ul>
<li><strong>Authors: </strong>Jaemoon Lee, Xiao Li, Liangji Zhu, Sanjay Ranka, Anand Rangarajan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12951">https://arxiv.org/abs/2502.12951</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12951">https://arxiv.org/pdf/2502.12951</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12951]] Guaranteed Conditional Diffusion: 3D Block-based Models for Scientific Data Compression(https://arxiv.org/abs/2502.12951)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>This paper proposes a new compression paradigm -- Guaranteed Conditional Diffusion with Tensor Correction (GCDTC) -- for lossy scientific data compression. The framework is based on recent conditional diffusion (CD) generative models, and it consists of a conditional diffusion model, tensor correction, and error guarantee. Our diffusion model is a mixture of 3D conditioning and 2D denoising U-Net. The approach leverages a 3D block-based compressing module to address spatiotemporal correlations in structured scientific data. Then, the reverse diffusion process for 2D spatial data is conditioned on the ``slices'' of content latent variables produced by the compressing module. After training, the denoising decoder reconstructs the data with zero noise and content latent variables, and thus it is entirely deterministic. The reconstructed outputs of the CD model are further post-processed by our tensor correction and error guarantee steps to control and ensure a maximum error distortion, which is an inevitable requirement in lossy scientific data compression. Our experiments involving two datasets generated by climate and chemical combustion simulations show that our framework outperforms standard convolutional autoencoders and yields competitive compression quality with an existing scientific data compression algorithm.</li>
<li><strong>摘要：</strong>本文提出了一种新的压缩范式 - 通过张量校正（GCDTC）保证有条件扩散 - 用于有损科学数据压缩。该框架基于最近的条件扩散（CD）生成模型，它由条件扩散模型，张量校正和错误保证组成。我们的扩散模型是3D调节和2D denoising U-NET的混合物。该方法利用基于3D块的压缩模块来解决结构化科学数据中的时空相关性。然后，2D空间数据的反向扩散过程在压缩模块产生的内容潜在变量的``切片''上进行了调节。训练后，denoising解码器将用零噪声和内容潜在变量重建数据，因此完全是确定性的。 CD模型的重建输出通过我们的张量校正和错误保证控制和确保最大误差失真的步骤进一步进行了处理，这是有损科学数据压缩的必然要求。我们的实验涉及由气候和化学燃烧模拟生成的两个数据集，表明我们的框架的表现优于标准卷积自动编码器，并使用现有的科学数据压缩算法产生竞争性压缩质量。</li>
</ul>

<h3>Title: Electron flow matching for generative reaction mechanism prediction obeying conservation laws</h3>
<ul>
<li><strong>Authors: </strong>Joonyoung F. Joung, Mun Hong Fong, Nicholas Casetti, Jordan P. Liles, Ne S. Dassanayake, Connor W. Coley</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12979">https://arxiv.org/abs/2502.12979</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12979">https://arxiv.org/pdf/2502.12979</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12979]] Electron flow matching for generative reaction mechanism prediction obeying conservation laws(https://arxiv.org/abs/2502.12979)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Central to our understanding of chemical reactivity is the principle of mass conservation, which is fundamental for ensuring physical consistency, balancing equations, and guiding reaction design. However, data-driven computational models for tasks such as reaction product prediction rarely abide by this most basic constraint. In this work, we recast the problem of reaction prediction as a problem of electron redistribution using the modern deep generative framework of flow matching. Our model, FlowER, overcomes limitations inherent in previous approaches by enforcing exact mass conservation, thereby resolving hallucinatory failure modes, recovering mechanistic reaction sequences for unseen substrate scaffolds, and generalizing effectively to out-of-domain reaction classes with extremely data-efficient fine-tuning. FlowER additionally enables estimation of thermodynamic or kinetic feasibility and manifests a degree of chemical intuition in reaction prediction tasks. This inherently interpretable framework represents a significant step in bridging the gap between predictive accuracy and mechanistic understanding in data-driven reaction outcome prediction.</li>
<li><strong>摘要：</strong>我们对化学反应性的理解的核心是质量保护的原理，这对于确保身体一致性，平衡方程和指导反应设计至关重要。但是，针对诸如反应产品预测等任务的数据驱动计算模型很少遵守这一最基本的约束。在这项工作中，我们使用现代的流量匹配框架来重述反应预测的问题作为电子重新分布的问题。我们的模型“花”通过执行精确的质量保护来克服以前方法固有的局限调谐。花还可以估计热力学或动力学可行性，并在反应预测任务中表现出一定程度的化学直觉。这种可解释的框架代表了弥合数据驱动反应结果预测中预测精度和机理理解之间的差距的重要一步。</li>
</ul>

<h3>Title: Towards Variational Flow Matching on General Geometries</h3>
<ul>
<li><strong>Authors: </strong>Olga Zaghen, Floor Eijkelboom, Alison Pouplin, Erik J. Bekkers</a></li>
<li><strong>Subjects: </strong>cs.LG, math.DG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12981">https://arxiv.org/abs/2502.12981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12981">https://arxiv.org/pdf/2502.12981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12981]] Towards Variational Flow Matching on General Geometries(https://arxiv.org/abs/2502.12981)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce Riemannian Gaussian Variational Flow Matching (RG-VFM), an extension of Variational Flow Matching (VFM) that leverages Riemannian Gaussian distributions for generative modeling on structured manifolds. We derive a variational objective for probability flows on manifolds with closed-form geodesics, making RG-VFM comparable - though fundamentally different to Riemannian Flow Matching (RFM) in this geometric setting. Experiments on a checkerboard dataset wrapped on the sphere demonstrate that RG-VFM captures geometric structure more effectively than Euclidean VFM and baseline methods, establishing it as a robust framework for manifold-aware generative modeling.</li>
<li><strong>摘要：</strong>我们介绍了Riemannian Gaussian变分流匹配（RG-VFM），这是一个利用Riemannian Gaussian分布的变异流匹配（VFM）的扩展，用于在结构化歧管上产生建模。我们得出了具有封闭形式的大地测量的流动概率流的变异目标，使RG-VFM具有可比性 - 尽管与Riemannian流动匹配（RFM）在此几何环境中根本不同。包裹在球体上的棋盘数据集上的实验表明，与欧几里得VFM和基线方法相比，RG-VFM更有效地捕获几何结构，并将其确立为多种变化生成模型的强大框架。</li>
</ul>

<h3>Title: PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization</h3>
<ul>
<li><strong>Authors: </strong>Nicolas Talabot, Olivier Clerc, Arda Cinar Demirtas, Doruk Oner, Pascal Fua</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.12985">https://arxiv.org/abs/2502.12985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.12985">https://arxiv.org/pdf/2502.12985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.12985]] PartSDF: Part-Based Implicit Neural Representation for Composite 3D Shape Parametrization and Optimization(https://arxiv.org/abs/2502.12985)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Accurate 3D shape representation is essential in engineering applications such as design, optimization, and simulation. In practice, engineering workflows require structured, part-aware representations, as objects are inherently designed as assemblies of distinct components. However, most existing methods either model shapes holistically or decompose them without predefined part structures, limiting their applicability in real-world design tasks. We propose PartSDF, a supervised implicit representation framework that explicitly models composite shapes with independent, controllable parts while maintaining shape consistency. Despite its simple single-decoder architecture, PartSDF outperforms both supervised and unsupervised baselines in reconstruction and generation tasks. We further demonstrate its effectiveness as a structured shape prior for engineering applications, enabling precise control over individual components while preserving overall coherence. Code available at this https URL.</li>
<li><strong>摘要：</strong>准确的3D形状表示在工程应用中至关重要，例如设计，优化和仿真。在实践中，工程工作流程需要结构化的部分意识表示，因为对象本质上设计为不同组件的组件。但是，大多数现有的方法要么模型可以整体塑造，要么将它们分解而没有预定义的零件结构，从而限制了它们在现实世界设计任务中的适用性。我们提出了PartsDF，这是一个有监督的隐式表示框架，该框架具有独立，可控零件的复合形状，同时保持形状一致性。尽管具有简单的单一模块架构，但Partdf在重建和生成任务中均优胜于监督和无监督的基线。我们进一步证明了其作为工程应用程序的结构化形状的有效性，可以精确控制单个组件，同时保持整体连贯性。可在此HTTPS URL上找到代码。</li>
</ul>

<h3>Title: Personalized Image Generation with Deep Generative Models: A Decade Survey</h3>
<ul>
<li><strong>Authors: </strong>Yuxiang Wei, Yiheng Zheng, Yabo Zhang, Ming Liu, Zhilong Ji, Lei Zhang, Wangmeng Zuo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.13081">https://arxiv.org/abs/2502.13081</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.13081">https://arxiv.org/pdf/2502.13081</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.13081]] Personalized Image Generation with Deep Generative Models: A Decade Survey(https://arxiv.org/abs/2502.13081)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Recent advancements in generative models have significantly facilitated the development of personalized content creation. Given a small set of images with user-specific concept, personalized image generation allows to create images that incorporate the specified concept and adhere to provided text descriptions. Due to its wide applications in content creation, significant effort has been devoted to this field in recent years. Nonetheless, the technologies used for personalization have evolved alongside the development of generative models, with their distinct and interrelated components. In this survey, we present a comprehensive review of generalized personalized image generation across various generative models, including traditional GANs, contemporary text-to-image diffusion models, and emerging multi-model autoregressive models. We first define a unified framework that standardizes the personalization process across different generative models, encompassing three key components, i.e., inversion spaces, inversion methods, and personalization schemes. This unified framework offers a structured approach to dissecting and comparing personalization techniques across different generative architectures. Building upon this unified framework, we further provide an in-depth analysis of personalization techniques within each generative model, highlighting their unique contributions and innovations. Through comparative analysis, this survey elucidates the current landscape of personalized image generation, identifying commonalities and distinguishing features among existing methods. Finally, we discuss the open challenges in the field and propose potential directions for future research. We keep tracing related works at this https URL.</li>
<li><strong>摘要：</strong>生成模型的最新进展显着促进了个性化内容创建的发展。给定一组具有特定用户概念的图像，个性化的图像生成允许创建包含指定概念并遵守提供文本描述的图像。由于其在内容创建中的广泛应用，近年来已经致力于这一领域。尽管如此，用于个性化的技术与生成模型的发展以及其独特和相互关联的组件一起发展。在这项调查中，我们对各种生成模型的广义个性化图像产生进行了全面综述，包括传统的gan，当代文本对图像扩散模型以及新兴的多模型自动回归模型。我们首先定义了一个统一的框架，该框架标准化了跨不同生成模型的个性化过程，其中包括三个关键组件，即反转空间，反转方法和个性化方案。这个统一的框架提供了一种结构化方法，可以解剖和比较不同生成体系结构的个性化技术。在这个统一的框架的基础上，我们进一步提供了对每个生成模型中个性化技术的深入分析，突出了它们的独特贡献和创新。通过比较分析，这项调查阐明了个性化图像生成的当前景观，确定了现有方法之间的共同点和区分特征。最后，我们讨论了该领域的公开挑战，并提出了未来研究的潜在方向。我们在此HTTPS URL上一直在追踪相关的作品。</li>
</ul>

<h3>Title: Is Noise Conditioning Necessary for Denoising Generative Models?</h3>
<ul>
<li><strong>Authors: </strong>Qiao Sun, Zhicheng Jiang, Hanhong Zhao, Kaiming He</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.13129">https://arxiv.org/abs/2502.13129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.13129">https://arxiv.org/pdf/2502.13129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.13129]] Is Noise Conditioning Necessary for Denoising Generative Models?(https://arxiv.org/abs/2502.13129)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>It is widely believed that noise conditioning is indispensable for denoising diffusion models to work successfully. This work challenges this belief. Motivated by research on blind image denoising, we investigate a variety of denoising-based generative models in the absence of noise conditioning. To our surprise, most models exhibit graceful degradation, and in some cases, they even perform better without noise conditioning. We provide a theoretical analysis of the error caused by removing noise conditioning and demonstrate that our analysis aligns with empirical observations. We further introduce a noise-unconditional model that achieves a competitive FID of 2.23 on CIFAR-10, significantly narrowing the gap to leading noise-conditional models. We hope our findings will inspire the community to revisit the foundations and formulations of denoising generative models.</li>
<li><strong>摘要：</strong>人们普遍认为，噪声调节是必不可少的，即可成功地进行扩散模型。这项工作挑战了这种信念。在没有噪声调节的情况下，我们研究了对盲图像denoising的研究，我们研究了各种基于脱氧的生成模型。令我们惊讶的是，大多数模型都会表现出优雅的降级，在某些情况下，它们甚至在没有噪音调理的情况下表现更好。我们提供了理论分析，以消除噪声调理引起的误差，并证明我们的分析与经验观察一致。我们进一步介绍了一个噪声矛盾模型，该模型在CIFAR-10上实现了2.23的竞争性FID，从而大大缩小了领先的噪声条件模型的差距。我们希望我们的发现能够激发社区重新审视denoising生成模型的基础和表述。</li>
</ul>

<h3>Title: AV-Flow: Transforming Text to Audio-Visual Human-like Interactions</h3>
<ul>
<li><strong>Authors: </strong>Aggelina Chatziagapi, Louis-Philippe Morency, Hongyu Gong, Michael Zollhoefer, Dimitris Samaras, Alexander Richard</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.13133">https://arxiv.org/abs/2502.13133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.13133">https://arxiv.org/pdf/2502.13133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.13133]] AV-Flow: Transforming Text to Audio-Visual Human-like Interactions(https://arxiv.org/abs/2502.13133)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce AV-Flow, an audio-visual generative model that animates photo-realistic 4D talking avatars given only text input. In contrast to prior work that assumes an existing speech signal, we synthesize speech and vision jointly. We demonstrate human-like speech synthesis, synchronized lip motion, lively facial expressions and head pose; all generated from just text characters. The core premise of our approach lies in the architecture of our two parallel diffusion transformers. Intermediate highway connections ensure communication between the audio and visual modalities, and thus, synchronized speech intonation and facial dynamics (e.g., eyebrow motion). Our model is trained with flow matching, leading to expressive results and fast inference. In case of dyadic conversations, AV-Flow produces an always-on avatar, that actively listens and reacts to the audio-visual input of a user. Through extensive experiments, we show that our method outperforms prior work, synthesizing natural-looking 4D talking avatars. Project page: this https URL</li>
<li><strong>摘要：</strong>我们介绍了AV-Flow，这是一种视听生成模型，它仅给出了文本输入，可以使照片真实的4D Talking Avatars动画。与假定现有语音信号的先前工作相反，我们共同综合语音和愿景。我们展示了类似人类的语音综合，同步的唇部运动，活泼的面部表情和头部姿势。全部都是由文本字符产生的。我们方法的核心前提在于我们两个平行扩散变压器的架构。中间高速公路连接确保音频和视觉方式之间的通信，从而确定语音语调和面部动力学（例如，眉毛运动）。我们的模型经过流量匹配的训练，从而导致表达性结果和快速推断。如果进行二元对话，AV-Flow会产生一个始终的头像，积极倾听并对用户的视听输入做出反应。通过广泛的实验，我们表明我们的方法表现优于先前的工作，从而综合了看起来自然的4D说话化身。项目页面：此HTTPS URL</li>
</ul>

<h3>Title: Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions</h3>
<ul>
<li><strong>Authors: </strong>Taedong Yun, Eric Yang, Mustafa Safdari, Jong Ha Lee, Vaishnavi Vinod Kumar, S. Sara Mahdavi, Jonathan Amar, Derek Peyton, Reut Aharony, Andreas Michaelides, Logan Schneider, Isaac Galatzer-Levy, Yugang Jia, John Canny, Arthur Gretton, Maja Matarić</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2502.13135">https://arxiv.org/abs/2502.13135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2502.13135">https://arxiv.org/pdf/2502.13135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2502.13135]] Sleepless Nights, Sugary Days: Creating Synthetic Users with Health Conditions for Realistic Coaching Agent Interactions(https://arxiv.org/abs/2502.13135)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We present an end-to-end framework for generating synthetic users for evaluating interactive agents designed to encourage positive behavior changes, such as in health and lifestyle coaching. The synthetic users are grounded in health and lifestyle conditions, specifically sleep and diabetes management in this study, to ensure realistic interactions with the health coaching agent. Synthetic users are created in two stages: first, structured data are generated grounded in real-world health and lifestyle factors in addition to basic demographics and behavioral attributes; second, full profiles of the synthetic users are developed conditioned on the structured data. Interactions between synthetic users and the coaching agent are simulated using generative agent-based models such as Concordia, or directly by prompting a language model. Using two independently-developed agents for sleep and diabetes coaching as case studies, the validity of this framework is demonstrated by analyzing the coaching agent's understanding of the synthetic users' needs and challenges. Finally, through multiple blinded evaluations of user-coach interactions by human experts, we demonstrate that our synthetic users with health and behavioral attributes more accurately portray real human users with the same attributes, compared to generic synthetic users not grounded in such attributes. The proposed framework lays the foundation for efficient development of conversational agents through extensive, realistic, and grounded simulated interactions.</li>
<li><strong>摘要：</strong>我们提出了一个端到端框架，用于生成合成用户，以评估旨在鼓励积极行为改变（例如健康和生活方式教练）的交互式代理。合成用户基于健康和生活方式条件，特别是睡眠和糖尿病管理，以确保与健康教练代理人进行现实的互动。合成用户分为两个阶段：首先生成的结构化数据是基于现实世界的健康和生活方式因素，而基本的人口统计和行为属性除了基本的健康和生活方式因素之外；其次，根据结构化数据开发了合成用户的完整概况。合成用户与教练代理之间的交互是使用基于生成代理的模型（例如Concordia）或直接提示语言模型来模拟的。通过分析教练代理人对合成用户的需求和挑战的理解，使用两个独立发展的代理人进行睡眠和糖尿病教练作为案例研究。最后，通过人类专家对用户教练互动的多次盲目评估，我们证明了具有健康和行为属性的合成用户更准确地描绘了具有相同属性的真实人用户，而不是基于此类属性的通用合成用户。拟议的框架通过广泛，现实和接地的模拟相互作用为对话剂有效地开发奠定了基础。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
