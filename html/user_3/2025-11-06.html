<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-11-06</h1>
<h3>Title: Generative Hints</h3>
<ul>
<li><strong>Authors: </strong>Andy Dimnaku, Abdullah Yusuf Kavranoğlu, Yaser Abu-Mostafa</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02933">https://arxiv.org/abs/2511.02933</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02933">https://arxiv.org/pdf/2511.02933</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02933]] Generative Hints(https://arxiv.org/abs/2511.02933)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Data augmentation is widely used in vision to introduce variation and mitigate overfitting, through enabling models to learn invariant properties, such as spatial invariance. However, these properties are not fully captured by data augmentation alone, since it attempts to learn the property on transformations of the training data only. We propose generative hints, a training methodology that directly enforces known invariances in the entire input space. Our approach leverages a generative model trained on the training set to approximate the input distribution and generate unlabeled images, which we refer to as virtual examples. These virtual examples are used to enforce functional properties known as hints. In generative hints, although the training dataset is fully labeled, the model is trained in a semi-supervised manner on both the classification and hint objectives, using the unlabeled virtual examples to guide the model in learning the desired hint. Across datasets, architectures, and loss functions, generative hints consistently outperform standard data augmentation when learning the same property. On popular fine-grained visual classification benchmarks, we achieved up to 1.78% top-1 accuracy improvement (0.63% on average) over fine-tuned models with data augmentation and an average performance boost of 1.286% on the CheXpert X-ray dataset.</li>
<li><strong>摘要：</strong>数据增强广泛应用于视觉领域，通过使模型能够学习空间不变性等不变属性来引入变化并减轻过度拟合。然而，这些属性并不能仅通过数据增强来完全捕获，因为它试图仅通过训练数据的转换来学习属性。我们提出了生成提示，这是一种直接在整个输入空间中强制执行已知不变性的训练方法。我们的方法利用在训练集上训练的生成模型来近似输入分布并生成未标记的图像，我们将其称为虚拟示例。这些虚拟示例用于强制执行称为提示的功能属性。在生成提示中，虽然训练数据集是完全标记的，但模型是在分类和提示目标上以半监督的方式进行训练，使用未标记的虚拟示例来指导模型学习所需的提示。在数据集、架构和损失函数中，在学习相同属性时，生成提示始终优于标准数据增强。在流行的细粒度视觉分类基准上，我们通过数据增强的微调模型实现了高达 1.78% 的 top-1 准确率提升（平均 0.63%），并且在 CheXpert X 射线数据集上的平均性能提升了 1.286%。</li>
</ul>

<h3>Title: ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology</h3>
<ul>
<li><strong>Authors: </strong>Srikumar Sastry, Subash Khanal, Aayush Dhakal, Jiayu Lin, Dan Cher, Phoenix Jarosz, Nathan Jacobs</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02946">https://arxiv.org/abs/2511.02946</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02946">https://arxiv.org/pdf/2511.02946</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02946]] ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology(https://arxiv.org/abs/2511.02946)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>We introduce ProM3E, a probabilistic masked multimodal embedding model for any-to-any generation of multimodal representations for ecology. ProM3E is based on masked modality reconstruction in the embedding space, learning to infer missing modalities given a few context modalities. By design, our model supports modality inversion in the embedding space. The probabilistic nature of our model allows us to analyse the feasibility of fusing various modalities for given downstream tasks, essentially learning what to fuse. Using these features of our model, we propose a novel cross-modal retrieval approach that mixes inter-modal and intra-modal similarities to achieve superior performance across all retrieval tasks. We further leverage the hidden representation from our model to perform linear probing tasks and demonstrate the superior representation learning capability of our model. All our code, datasets and model will be released at this https URL.</li>
<li><strong>摘要：</strong>我们引入了 ProM3E，这是一种概率屏蔽多模态嵌入模型，用于生态学中任意生成的多模态表示。 ProM3E 基于嵌入空间中的屏蔽模态重建，学习在给定一些上下文模态的情况下推断缺失的模态。根据设计，我们的模型支持嵌入空间中的模态反转。我们模型的概率性质使我们能够分析针对给定下游任务融合各种模式的可行性，本质上是学习融合什么。利用我们模型的这些特征，我们提出了一种新颖的跨模式检索方法，该方法混合了模式间和模式内的相似性，以在所有检索任务中实现卓越的性能。我们进一步利用模型中的隐藏表示来执行线性探测任务，并展示我们模型的卓越表示学习能力。我们所有的代码、数据集和模型都将在此 https URL 发布。</li>
</ul>

<h3>Title: Inference-Time Personalized Alignment with a Few User Preference Queries</h3>
<ul>
<li><strong>Authors: </strong>Victor-Alexandru Pădurean, Parameswaran Kamalaruban, Nachiket Kotalwar, Alkis Gotovos, Adish Singla</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02966">https://arxiv.org/abs/2511.02966</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02966">https://arxiv.org/pdf/2511.02966</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02966]] Inference-Time Personalized Alignment with a Few User Preference Queries(https://arxiv.org/abs/2511.02966)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>We study the problem of aligning a generative model's response with a user's preferences. Recent works have proposed several different formulations for personalized alignment; however, they either require a large amount of user preference queries or require that the preference be explicitly specified as a text input. In this paper, we propose a novel inference-time personalized alignment method, UserAlign, that elicits the user's preferences with a few queries as pairwise response comparisons. In particular, UserAlign builds on the theoretical framework of best-arm identification in logistic bandits and selects a personalized response from a fixed pool of the model's generated responses. The key idea is to consider the user's feedback consistent and noise-free, and incorporate it into the theoretical framework to identify the best response quickly. Experimental results across several tasks, involving personalized text and image generation, showcase the effectiveness of UserAlign in achieving personalized alignment.</li>
<li><strong>摘要：</strong>我们研究将生成模型的响应与用户的偏好保持一致的问题。最近的工作提出了几种不同的个性化对齐方案；然而，它们要么需要大量的用户偏好查询，要么需要将偏好明确指定为文本输入。在本文中，我们提出了一种新颖的推理时个性化对齐方法 UserAlign，该方法通过一些查询作为成对响应比较来引出用户的偏好。特别是，UserAlign 建立在后勤强盗最佳臂识别的理论框架之上，并从模型生成的固定响应池中选择个性化响应。关键思想是考虑用户反馈的一致性和无噪音，并将其纳入理论框架中以快速识别最佳响应。涉及个性化文本和图像生成的多个任务的实验结果展示了 UserAlign 在实现个性化对齐方面的有效性。</li>
</ul>

<h3>Title: SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics</h3>
<ul>
<li><strong>Authors: </strong>Ailar Mahdizadeh, Puria Azadi Moghadam, Xiangteng He, Shahriar Mirabbasi, Panos Nasiopoulos, Leonid Sigal</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.02996">https://arxiv.org/abs/2511.02996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.02996">https://arxiv.org/pdf/2511.02996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.02996]] SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics(https://arxiv.org/abs/2511.02996)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have demonstrated strong cross-modal capabilities, yet most work remains limited to 2D data and assumes binary supervision (i.e., positive vs. negative pairs), overlooking the continuous and structured dependencies present in volumetric data such as CT. Existing approaches often treat volumetric scans as independent 2D slices, compromising spatial coherence and underutilizing rich clinical semantics. We propose SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework that integrates (i) volumetric spatial semantics to preserve anatomical structure and (ii) domain-aware, knowledge-infused semantics (e.g., radiological ontologies) to guide alignment. This yields structurally consistent and semantically grounded representations under limited supervision, demonstrating strong cross-task transferability (retrieval, report generation, and classification), and cross-domain generalizability with consistent gains without further fine-tuning. In particular, compared to the previous state of the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval, improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an out-of-domain external dataset, we observe consistent gains, indicating the cross-task and cross-domain generalization ability of SCALE-VLP.</li>
<li><strong>摘要：</strong>视觉语言模型 (VLM) 已表现出强大的跨模态功能，但大多数工作仍然仅限于 2D 数据，并假设二元监督（即正与负对），忽略了 CT 等体积数据中存在的连续和结构化依赖关系。现有方法通常将体积扫描视为独立的二维切片，从而损害了空间连贯性并且未充分利用丰富的临床语义。我们提出了 SCALE-VLP，一种软加权对比视觉语言预训练框架，它集成了（i）体积空间语义以保留解剖结构和（ii）领域感知、知识注入语义（例如放射学本体）以指导对齐。这在有限的监督下产生了结构一致和语义基础的表示，展示了强大的跨任务可转移性（检索、报告生成和分类），以及跨域通用性，无需进一步微调即可获得一致的收益。特别是，与之前的最新技术相比，SCALE-VLP 的 top-1 CT 报告检索提高了 4.3 倍，异常分类提高了 10 个百分点，报告生成达到了 ROUGE-L 0.44 和 BERT-F1 0.89。此外，在域外外部数据集的零样本评估中，我们观察到一致的增益，表明 SCALE-VLP 的跨任务和跨域泛化能力。</li>
</ul>

<h3>Title: Discrete Bayesian Sample Inference for Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Ole Petersen, Marcel Kollovieh, Marten Lienen, Stephan Günnemann</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03015">https://arxiv.org/abs/2511.03015</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03015">https://arxiv.org/pdf/2511.03015</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03015]] Discrete Bayesian Sample Inference for Graph Generation(https://arxiv.org/abs/2511.03015)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Generating graph-structured data is crucial in applications such as molecular generation, knowledge graphs, and network analysis. However, their discrete, unordered nature makes them difficult for traditional generative models, leading to the rise of discrete diffusion and flow matching models. In this work, we introduce GraphBSI, a novel one-shot graph generative model based on Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI iteratively refines a belief over graphs in the continuous space of distribution parameters, naturally handling discrete structures. Further, we state BSI as a stochastic differential equation (SDE) and derive a noise-controlled family of SDEs that preserves the marginal distributions via an approximation of the score function. Our theoretical analysis further reveals the connection to Bayesian Flow Networks and Diffusion models. Finally, in our empirical evaluation, we demonstrate state-of-the-art performance on molecular and synthetic graph generation, outperforming existing one-shot graph generative models on the standard benchmarks Moses and GuacaMol.</li>
<li><strong>摘要：</strong>生成图结构数据对于分子生成、知识图和网络分析等应用至关重要。然而，它们的离散、无序性质使得它们难以用于传统的生成模型，从而导致离散扩散和流动匹配模型的兴起。在这项工作中，我们介绍了 GraphBSI，一种基于贝叶斯样本推理（BSI）的新型一次性图生成模型。 GraphBSI 不是直接进化样本，而是迭代地完善分布参数连续空间中图的信念，自然地处理离散结构。此外，我们将 BSI 表述为随机微分方程 (SDE)，并推导了噪声控制的 SDE 系列，该系列通过得分函数的近似保留了边缘分布。我们的理论分析进一步揭示了与贝叶斯流网络和扩散模型的联系。最后，在我们的实证评估中，我们展示了分子和合成图生成方面最先进的性能，在标准基准 Moses 和 GuacaMol 上优于现有的一次性图生成模型。</li>
</ul>

<h3>Title: Leveraging Discrete Function Decomposability for Scientific Design</h3>
<ul>
<li><strong>Authors: </strong>James C. Bowden, Sergey Levine, Jennifer Listgarten</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03032">https://arxiv.org/abs/2511.03032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03032">https://arxiv.org/pdf/2511.03032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03032]] Leveraging Discrete Function Decomposability for Scientific Design(https://arxiv.org/abs/2511.03032)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>In the era of AI-driven science and engineering, we often want to design discrete objects in silico according to user-specified properties. For example, we may wish to design a protein to bind its target, arrange components within a circuit to minimize latency, or find materials with certain properties. Given a property predictive model, in silico design typically involves training a generative model over the design space (e.g., protein sequence space) to concentrate on designs with the desired properties. Distributional optimization -- which can be formalized as an estimation of distribution algorithm or as reinforcement learning policy optimization -- finds the generative model that maximizes an objective function in expectation. Optimizing a distribution over discrete-valued designs is in general challenging because of the combinatorial nature of the design space. However, many property predictors in scientific applications are decomposable in the sense that they can be factorized over design variables in a way that could in principle enable more effective optimization. For example, amino acids at a catalytic site of a protein may only loosely interact with amino acids of the rest of the protein to achieve maximal catalytic activity. Current distributional optimization algorithms are unable to make use of such decomposability structure. Herein, we propose and demonstrate use of a new distributional optimization algorithm, Decomposition-Aware Distributional Optimization (DADO), that can leverage any decomposability defined by a junction tree on the design variables, to make optimization more efficient. At its core, DADO employs a soft-factorized "search distribution" -- a learned generative model -- for efficient navigation of the search space, invoking graph message-passing to coordinate optimization across linked factors.</li>
<li><strong>摘要：</strong>在人工智能驱动的科学和工程时代，我们经常希望根据用户指定的属性在计算机中设计离散对象。例如，我们可能希望设计一种蛋白质来结合其目标，在电路中排列组件以最大限度地减少延迟，或者找到具有某些特性的材料。给定属性预测模型，计算机设计通常涉及在设计空间（例如蛋白质序列空间）上训练生成模型，以专注于具有所需属性的设计。分布优化——可以形式化为分布算法的估计或强化学习策略优化——找到最大化期望目标函数的生成模型。由于设计空间的组合性质，优化离散值设计的分布通常具有挑战性。然而，科学应用中的许多属性预测变量都是可分解的，因为它们可以以原则上可以实现更有效优化的方式对设计变量进行因式分解。例如，蛋白质催化位点处的氨基酸可能仅与蛋白质其余部分的氨基酸松散地相互作用以实现最大催化活性。当前的分布式优化算法无法利用这种可分解结构。在此，我们提出并演示了一种新的分布优化算法——分解感知分布优化（DADO）的使用，该算法可以利用设计变量上的连接树定义的任何可分解性，使优化更加高效。 DADO 的核心是采用软因子化的“搜索分布”（一种学习生成模型）来高效导航搜索空间，调用图形消息传递来协调链接因子之间的优化。</li>
</ul>

<h3>Title: Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies</h3>
<ul>
<li><strong>Authors: </strong>Gaia Grosso, Sai Sumedh R. Hindupur, Thomas Fel, Samuel Bright-Thonney, Philip Harris, Demba Ba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03095">https://arxiv.org/abs/2511.03095</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03095">https://arxiv.org/pdf/2511.03095</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03095]] Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies(https://arxiv.org/abs/2511.03095)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Modern artificial intelligence has revolutionized our ability to extract rich and versatile data representations across scientific disciplines. Yet, the statistical properties of these representations remain poorly controlled, causing misspecified anomaly detection (AD) methods to falter. Weak or rare signals can remain hidden within the apparent regularity of normal data, creating a gap in our ability to detect and interpret anomalies. We examine this gap and identify a set of structural desiderata for detection methods operating under minimal prior information: sparsity, to enforce parsimony; locality, to preserve geometric sensitivity; and competition, to promote efficient allocation of model capacity. These principles define a class of self-organizing local kernels that adaptively partition the representation space around regions of statistical imbalance. As an instantiation of these principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained within a semi-supervised Neyman--Pearson framework to locally model the likelihood ratio between a sample that may contain anomalies and a nominal, anomaly-free reference. We provide theoretical insights into the mechanisms that drive detection and self-organization in the proposed model, and demonstrate the effectiveness of this approach on realistic high-dimensional problems of scientific discovery, open-world novelty detection, intrusion detection, and generative-model validation. Our applications span both the natural- and computer-science domains. We demonstrate that ensembles containing only a handful of kernels can identify statistically significant anomalous locations within representation spaces of thousands of dimensions, underscoring both the interpretability, efficiency and scalability of the proposed approach.</li>
<li><strong>摘要：</strong>现代人工智能彻底改变了我们跨科学学科提取丰富且通用的数据表示的能力。然而，这些表示的统计特性仍然控制不佳，导致错误指定的异常检测（AD）方法失效。微弱或罕见的信号可能隐藏在正常数据的明显规律中，从而在我们检测和解释异常的能力方面造成差距。我们研究了这一差距，并确定了在最少先验信息下运行的检测方法的一组结构需求：稀疏性，以强制简约；局部性，以保持几何敏感性；和竞争，促进车型产能高效配置。这些原则定义了一类自组织局部内核，它们自适应地划分统计不平衡区域周围的表示空间。作为这些原则的实例，我们引入了 SparKer，这是一种在半监督 Neyman-Pearson 框架内训练的稀疏高斯核集合，用于对可能包含异常的样本与名义上的无异常参考之间的似然比进行局部建模。我们对所提出的模型中驱动检测和自组织的机制提供了理论见解，并证明了该方法在科学发现、开放世界新颖性检测、入侵检测和生成模型验证等现实高维问题上的有效性。我们的应用涵盖自然科学和计算机科学领域。我们证明，仅包含少数内核的集成可以识别数千维表示空间内统计上显着的异常位置，强调了所提出方法的可解释性、效率和可扩展性。</li>
</ul>

<h3>Title: FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation</h3>
<ul>
<li><strong>Authors: </strong>Jiameng Chen, Yida Xiong, Kun Li, Hongzhi Zhang, Xiantao Cai, Wenbin Hu, Jia Wu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03113">https://arxiv.org/abs/2511.03113</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03113">https://arxiv.org/pdf/2511.03113</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03113]] FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation(https://arxiv.org/abs/2511.03113)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Computational antibody design holds immense promise for therapeutic discovery, yet existing generative models are fundamentally limited by two core challenges: (i) a lack of dynamical consistency, which yields physically implausible structures, and (ii) poor generalization due to data scarcity and structural bias. We introduce FP-AbDiff, the first antibody generator to enforce Fokker-Planck Equation (FPE) physics along the entire generative trajectory. Our method minimizes a novel FPE residual loss over the mixed manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising scores to assemble into a globally coherent probability flow. This physics-informed regularizer is synergistically integrated with deep biological priors within a state-of-the-art SE(3)-equivariant diffusion framework. Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean Square Deviation of 0.99 Å when superposing on the variable region, a 25% improvement over the previous state-of-the-art model, AbX, and the highest reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored in the more challenging six-CDR co-design task, where our model delivers consistently superior geometric precision, cutting the average full-chain Root Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By aligning generative dynamics with physical laws, FP-AbDiff enhances robustness and generalizability, establishing a principled approach for physically faithful and functionally viable antibody design.</li>
<li><strong>摘要：</strong>计算抗体设计为治疗发现带来了巨大希望，但现有的生成模型从根本上受到两个核心挑战的限制：（i）缺乏动态一致性，从而产生物理上难以置信的结构；（ii）由于数据稀缺和结构偏差，泛化能力较差。我们推出了 FP-AbDiff，这是第一个在整个生成轨迹上强制执行 Fokker-Planck 方程 (FPE) 物理原理的抗体生成器。我们的方法最大限度地减少了 CDR 几何混合流形 (R^3 x SO(3)) 上的新型 FPE 残余损失，迫使本地学习的去噪分数组装成全局相干的概率流。这种基于物理的正则化器在最先进的 SE(3) 等变扩散框架内与深层生物学先验协同集成。对 RAbD 基准的严格评估证实 FP-AbDiff 建立了新的最先进技术。在 de novo CDR-H3 设计中，叠加在可变区上时，其平均均方根偏差为 0.99 Å，比之前最先进的模型 AbX 提高了 25%，并且报告的最高接触氨基酸回收率为 39.91%。这种优势在更具挑战性的六 CDR 协同设计任务中得到了强调，我们的模型始终提供卓越的几何精度，将平均全链均方根偏差降低约 15%，最重要的是，在功能主导的 CDR-H3 环上实现了最高的全链氨基酸回收率 (45.67%)。通过将生成动力学与物理定律结合起来，FP-AbDiff 增强了鲁棒性和普遍性，为物理忠实且功能可行的抗体设计建立了原则性方法。</li>
</ul>

<h3>Title: From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation</h3>
<ul>
<li><strong>Authors: </strong>Najrin Sultana, Md Rafi Ur Rashid, Kang Gu, Shagufta Mehnaz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03128">https://arxiv.org/abs/2511.03128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03128">https://arxiv.org/pdf/2511.03128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03128]] From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation(https://arxiv.org/abs/2511.03128)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>LLMs can provide substantial zero-shot performance on diverse tasks using a simple task prompt, eliminating the need for training or fine-tuning. However, when applying these models to sensitive tasks, it is crucial to thoroughly assess their robustness against adversarial inputs. In this work, we introduce Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack frameworks designed to systematically generate dynamic and adaptive adversarial examples by leveraging the understanding of the LLMs. We produce subtle and natural-looking adversarial inputs that preserve semantic similarity to the original text while effectively deceiving the target LLM. By utilizing an automated, LLM-driven pipeline, we eliminate the dependence on external heuristics. Our attacks evolve with the advancements in LLMs and demonstrate strong transferability across models unknown to the attacker. Overall, this work provides a systematic approach for the self-assessment of an LLM's robustness. We release our code and data at this https URL.</li>
<li><strong>摘要：</strong>法学硕士可以使用简单的任务提示在不同的任务上提供大量的零样本性能，从而无需培训或微调。然而，当将这些模型应用于敏感任务时，彻底评估它们针对对抗性输入的鲁棒性至关重要。在这项工作中，我们介绍了静态欺骗器（StaDec）和动态欺骗器（DyDec），这两种创新的攻击框架旨在利用对法学硕士的理解来系统地生成动态和自适应对抗示例。我们产生微妙且自然的对抗性输入，保留与原始文本的语义相似性，同时有效地欺骗目标法学硕士。通过利用自动化的、法学硕士驱动的管道，我们消除了对外部启发法的依赖。我们的攻击随着法学硕士的进步而发展，并在攻击者未知的模型之间表现出强大的可转移性。总的来说，这项工作为法学硕士稳健性的自我评估提供了一种系统的方法。我们在此 https URL 发布我们的代码和数据。</li>
</ul>

<h3>Title: Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction</h3>
<ul>
<li><strong>Authors: </strong>Atif Hassan, Tarun Kumar, Ashish Mishra, Sergey Serebryakov, Satish Kumar Mopur, Phanidhar Koganti, Murthy Chelankuri, Ramanagopal Vogety, Suparna Bhattacharya, Martin Foltin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03149">https://arxiv.org/abs/2511.03149</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03149">https://arxiv.org/pdf/2511.03149</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03149]] Forecast2Anomaly (F2A): Adapting Multivariate Time Series Foundation Models for Anomaly Prediction(https://arxiv.org/abs/2511.03149)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Forecasting anomalies (anomaly prediction) in multivariate time series from different real-world, dynamic, and complex systems is vital for preempting critical failures, leading to a substantial minimization in operational costs and human labor. Yet, existing methods are limited to specific systems while failing to generalize to evolving anomaly patterns over time. In contrast, pretrained Time Series Foundation Models (TSFMs) have recently demonstrated strong generalization and zero-shot forecasting capabilities. However, their potential remains untapped for anomaly prediction, a task fundamentally different from forecasting normal behavior. Thus, we present Forecast2Anomaly (F2A), a novel framework that empowers TSFMs with anomaly prediction abilities through two key innovations. First, we propose a joint forecast-anomaly loss that fine-tunes TSFMs to accurately forecast future signals even at anomalous time points. Second, we introduce a Retrieval-Augmented Generation (RAG) module that retrieves historically relevant horizons and conditions predictions on them. This component dynamically adapts to distributional shifts at inference time, enabling F2A to track evolving anomalies without requiring model updates. By combining targeted fine-tuning with dynamic retrieval, F2A bridges the gap between robust TSFM zero-shot forecasting and zero-shot anomaly prediction. Extensive experiments across 16 diverse datasets and multiple TSFM backbones show that F2A consistently outperforms state-of-the-art methods, offering a scalable, zero-shot anomaly prediction solution for real-world applications.</li>
<li><strong>摘要：</strong>预测来自不同现实世界、动态和复杂系统的多元时间序列中的异常对于预防关键故障至关重要，从而大大减少运营成本和人力。然而，现有方法仅限于特定系统，而无法推广到随时间演变的异常模式。相比之下，预训练的时间序列基础模型（TSFM）最近表现出了强大的泛化和零样本预测能力。然而，它们在异常预测方面的潜力尚未开发，这是一项与预测正常行为根本不同的任务。因此，我们提出了 Forecast2Anomaly (F2A)，这是一个新颖的框架，通过两项关键创新赋予 TSFM 异常预测能力。首先，我们提出了一种联合预测异常损失，可以微调 TSFM，即使在异常时间点也能准确预测未来信号。其次，我们引入了检索增强生成（RAG）模块，该模块检索历史相关的地平线和条件预测。该组件动态适应推理时的分布变化，使 F2A 能够跟踪不断变化的异常情况，而无需更新模型。通过将有针对性的微调与动态检索相结合，F2A 弥补了稳健的 TSFM 零样本预测和零样本异常预测之间的差距。跨越 16 个不同数据集和多个 TSFM 主干的广泛实验表明，F2A 始终优于最先进的方法，为现实世界的应用提供可扩展的零样本异常预测解决方案。</li>
</ul>

<h3>Title: Finetuning-Free Personalization of Text to Image Generation via Hypernetworks</h3>
<ul>
<li><strong>Authors: </strong>Sagar Shrestha, Gopal Sharma, Luowei Zhou, Suren Kumar</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03156">https://arxiv.org/abs/2511.03156</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03156">https://arxiv.org/pdf/2511.03156</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03156]] Finetuning-Free Personalization of Text to Image Generation via Hypernetworks(https://arxiv.org/abs/2511.03156)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Personalizing text-to-image diffusion models has traditionally relied on subject-specific fine-tuning approaches such as DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and slow at inference. Recent adapter- and encoder-based methods attempt to reduce this overhead but still depend on additional fine-tuning or large backbone models for satisfactory results. In this work, we revisit an orthogonal direction: fine-tuning-free personalization via Hypernetworks that predict LoRA-adapted weights directly from subject images. Prior hypernetwork-based approaches, however, suffer from costly data generation or unstable attempts to mimic base model optimization trajectories. We address these limitations with an end-to-end training objective, stabilized by a simple output regularization, yielding reliable and effective hypernetworks. Our method removes the need for per-subject optimization at test time while preserving both subject fidelity and prompt alignment. To further enhance compositional generalization at inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG), which combines the compositional strengths of the base diffusion model with the subject fidelity of personalized models during sampling. Extensive experiments on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves strong personalization performance and highlights the promise of hypernetworks as a scalable and effective direction for open-category personalization.</li>
<li><strong>摘要：</strong>个性化文本到图像的扩散模型传统上依赖于特定于主题的微调方法，例如 DreamBooth~\cite{ruiz2023dreambooth}，这些方法计算成本高且推理速度慢。最近基于适配器和编码器的方法试图减少这种开销，但仍然依赖于额外的微调或大型骨干模型来获得满意的结果。在这项工作中，我们重新审视了一个正交方向：通过超网络进行免微调个性化，直接从主题图像预测 LoRA 适应权重。然而，先前基于超网络的方法面临着昂贵的数据生成或模仿基础模型优化轨迹的不稳定尝试。我们通过端到端训练目标来解决这些限制，通过简单的输出正则化来稳定，从而产生可靠且有效的超网络。我们的方法消除了在测试时对每个主题进行优化的需要，同时保留了主题保真度和及时对齐。为了进一步增强推理时的组合泛化，我们引入了混合模型无分类器指导（HM-CFG），它将基础扩散模型的组合优势与采样过程中个性化模型的主题保真度结合起来。在 CelebA-HQ、AFHQ-v2 和 DreamBench 上进行的大量实验表明，我们的方法实现了强大的个性化性能，并强调了超网络作为开放类别个性化的可扩展且有效方向的前景。</li>
</ul>

<h3>Title: Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation</h3>
<ul>
<li><strong>Authors: </strong>Pengyu Jie, Wanquan Liu, Rui He, Yihui Wen, Deyu Meng, Chenqiang Gao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03219">https://arxiv.org/abs/2511.03219</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03219">https://arxiv.org/pdf/2511.03219</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03219]] Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation(https://arxiv.org/abs/2511.03219)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Augmentation for dense prediction typically relies on either sample mixing or generative synthesis. Mixing improves robustness but misaligned masks yield soft label ambiguity. Diffusion synthesis increases apparent diversity but, when trained as common samples, overlooks the structural benefit of mask conditioning and introduces synthetic-real domain shift. We propose a paired, diffusion-guided paradigm that fuses the strengths of both. For each real image, a synthetic counterpart is generated under the same mask and the pair is used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which mixes only image appearance while supervision always uses the original hard mask. This produces a continuous family of intermediate samples that smoothly bridges synthetic and real appearances under shared geometry, enlarging diversity without compromising pixel-level semantics. To keep learning aligned with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the mixing strength and the loss weight of mixed samples over training, gradually re-anchoring optimization to real data and mitigating distributional bias. Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC 2017, the approach achieves state-of-the-art segmentation performance and consistent gains over baselines. The results show that combining label-preserving mixing with diffusion-driven diversity, together with adaptive re-anchoring, yields robust and generalizable endoscopic segmentation.</li>
<li><strong>摘要：</strong>密集预测的增强通常依赖于样本混合或生成合成。混合提高了鲁棒性，但未对齐的掩模会产生软标签模糊性。扩散合成增加了明显的多样性，但是当作为普通样本进行训练时，它忽略了掩模调节的结构优势并引入了合成-真实域偏移。我们提出了一种配对的、扩散引导的范式，融合了两者的优势。对于每个真实图像，在相同掩模下生成合成对应物，并将该对用作掩模一致配对混合（MCPMix）的可控输入，该混合仅混合图像外观，而监督始终使用原始硬掩模。这产生了一系列连续的中间样本，可以在共享几何结构下平滑地连接合成外观和真实外观，从而在不影响像素级语义的情况下扩大多样性。为了保持学习与真实数据保持一致，真实锚定可学习退火（RLA）在训练过程中自适应调整混合强度和混合样本的损失权重，逐渐重新锚定优化到真实数据并减轻分布偏差。在 Kvasir-SEG、PICCOLO、CVC-ClinicDB、私人 NPC-LES 队列和 ISIC 2017 中，该方法实现了最先进的分割性能和相对于基线的一致增益。结果表明，将标签保留混合与扩散驱动的多样性相结合，再加上自适应重新锚定，可以产生稳健且可概括的内窥镜分割。</li>
</ul>

<h3>Title: Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Sichen Guo, Wenjie Li, Yuanyang Liu, Guangwei Gao, Jian Yang, Chia-Wen Lin</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03232">https://arxiv.org/abs/2511.03232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03232">https://arxiv.org/pdf/2511.03232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03232]] Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution(https://arxiv.org/abs/2511.03232)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution</a></li>
<li><strong>Abstract: </strong>Recently, Mamba-based super-resolution (SR) methods have demonstrated the ability to capture global receptive fields with linear complexity, addressing the quadratic computational cost of Transformer-based SR approaches. However, existing Mamba-based methods lack fine-grained transitions across different modeling scales, which limits the efficiency of feature representation. In this paper, we propose T-PMambaSR, a lightweight SR framework that integrates window-based self-attention with Progressive Mamba. By enabling interactions among receptive fields of different scales, our method establishes a fine-grained modeling paradigm that progressively enhances feature representation with linear complexity. Furthermore, we introduce an Adaptive High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost during Transformer and Mamba processing. Extensive experiments demonstrate that T-PMambaSR progressively enhances the model's receptive field and expressiveness, yielding better performance than recent Transformer- or Mamba-based methods while incurring lower computational cost. Our codes will be released after acceptance.</li>
<li><strong>摘要：</strong>最近，基于 Mamba 的超分辨率 (SR) 方法展示了以线性复杂度捕获全局感受野的能力，解决了基于 Transformer 的 SR 方法的二次计算成本问题。然而，现有的基于 Mamba 的方法缺乏跨不同建模尺度的细粒度过渡，这限制了特征表示的效率。在本文中，我们提出了 T-PMambaSR，一种轻量级 SR 框架，它将基于窗口的自注意力与渐进式 Mamba 集成在一起。通过实现不同尺度的感受野之间的交互，我们的方法建立了一种细粒度的建模范例，以线性复杂度逐步增强特征表示。此外，我们引入了自适应高频细化模块（AHFRM）来恢复 Transformer 和 Mamba 处理期间丢失的高频细节。大量实验表明，T-PMambaSR 逐渐增强了模型的感受野和表达能力，比最近基于 Transformer 或 Mamba 的方法具有更好的性能，同时计算成本更低。我们的代码将在接受后发布。</li>
</ul>

<h3>Title: A unified physics-informed generative operator framework for general inverse problems</h3>
<ul>
<li><strong>Authors: </strong>Gang Bao, Yaohua Zang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03241">https://arxiv.org/abs/2511.03241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03241">https://arxiv.org/pdf/2511.03241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03241]] A unified physics-informed generative operator framework for general inverse problems(https://arxiv.org/abs/2511.03241)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Solving inverse problems governed by partial differential equations (PDEs) is central to science and engineering, yet remains challenging when measurements are sparse, noisy, or when the underlying coefficients are high-dimensional or discontinuous. Existing deep learning approaches either require extensive labeled datasets or are limited to specific measurement types, often leading to failure in such regimes and restricting their practical applicability. Here, a novel generative neural operator framework, IGNO, is introduced to overcome these limitations. IGNO unifies the solution of inverse problems from both point measurements and operator-valued data without labeled training pairs. This framework encodes high-dimensional, potentially discontinuous coefficient fields into a low-dimensional latent space, which drives neural operator decoders to reconstruct both coefficients and PDE solutions. Training relies purely on physics constraints through PDE residuals, while inversion proceeds via efficient gradient-based optimization in latent space, accelerated by an a priori normalizing flow model. Across a diverse set of challenging inverse problems, including recovery of discontinuous coefficients from solution-based measurements and the EIT problem with operator-based measurements, IGNO consistently achieves accurate, stable, and scalable inversion even under severe noise. It consistently outperforms the state-of-the-art method under varying noise levels and demonstrates strong generalization to out-of-distribution targets. These results establish IGNO as a unified and powerful framework for tackling challenging inverse problems across computational science domains.</li>
<li><strong>摘要：</strong>解决偏微分方程 (PDE) 控制的反问题是科学和工程的核心，但当测量稀疏、有噪声或基础系数是高维或不连续时，仍然具有挑战性。现有的深度学习方法要么需要大量标记数据集，要么仅限于特定的测量类型，通常会导致此类机制的失败并限制其实际适用性。在这里，引入了一种新颖的生成神经算子框架 IGNO 来克服这些限制。 IGNO 统一了来自点测量和操作员值数据的反演问题的解决方案，无需标记训练对。该框架将高维、可能不连续的系数场编码到低维潜在空间中，这驱动神经算子解码器重建系数和 PDE 解决方案。训练纯粹依赖于偏微分方程残差的物理约束，而反演则通过潜在空间中基于梯度的高效优化进行，并通过先验归一化流模型加速。在一系列具有挑战性的反演问题中，包括从基于解的测量中恢复不连续系数以及基于算子测量的 EIT 问题，IGNO 即使在严重的噪声下也能始终实现准确、稳定和可扩展的反演。它在不同的噪声水平下始终优于最先进的方法，并对分布外目标表现出强大的泛化能力。这些结果将 IGNO 确立为一个统一且强大的框架，用于解决跨计算科学领域的挑战性逆问题。</li>
</ul>

<h3>Title: Generative deep learning for foundational video translation in ultrasound</h3>
<ul>
<li><strong>Authors: </strong>Nikolina Tomic Roshni Bhatnagar, Sarthak Jain, Connor Lau, Tien-Yu Liu, Laura Gambini, Rima Arnaout</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03255">https://arxiv.org/abs/2511.03255</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03255">https://arxiv.org/pdf/2511.03255</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03255]] Generative deep learning for foundational video translation in ultrasound(https://arxiv.org/abs/2511.03255)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.</li>
<li><strong>摘要：</strong>深度学习 (DL) 有潜力彻底改变整个医学领域的图像采集和解释，但是，需要注意数据不平衡和缺失。超声数据提出了一个特殊的挑战，因为除了不同的视图和结构之外，它还包括几种在临床研究中经常不平衡的子模式，例如灰度和彩色血流多普勒 (CFD)。图像翻译可以帮助平衡数据集，但迄今为止对于超声子模态来说仍具有挑战性。在这里，我们提出了一种用于超声 CFD 灰度视频翻译的生成方法，该方法在 54,975 个视频上进行训练并在 8,368 个视频上进行测试。该方法开发利用了像素级、对抗性和感知损失，并利用了两个网络：一个用于重建解剖结构，另一个用于降噪以实现逼真的超声成像。合成视频和真实视频之间的平均成对 SSIM 为 0.91+/-0.04。在深度学习分类和分割任务中，以及由盲法临床专家评估时，合成视频与真实视频没有什么区别：真实视频的 F1 分数为 0.9，合成视频的 F1 分数为 0.89；真实分割和合成分割之间的 Dice 得分为 0.97。临床医生区分真实视频和合成视频的总体准确度为 54+/-6% (42-61%)，表明合成视频真实。尽管仅在心脏视频上进行训练，但该模型在跨越多个临床领域的超声上运行良好（平均 SSIM 0.91+/-0.05），展示了基础能力。这些数据共同扩展了回顾性收集的成像的实用性，并增强了医学成像的数据集设计工具箱。</li>
</ul>

<h3>Title: IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Bingyang Guo, Hongjie Li, Ruiyun Yu, Hanzhe Liang, Jinbao Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03267">https://arxiv.org/abs/2511.03267</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03267">https://arxiv.org/pdf/2511.03267</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03267]] IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection(https://arxiv.org/abs/2511.03267)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>3D anomaly detection (3D-AD) plays a critical role in industrial manufacturing, particularly in ensuring the reliability and safety of core equipment components. Although existing 3D datasets like Real3D-AD and MVTec 3D-AD offer broad application support, they fall short in capturing the complexities and subtle defects found in real industrial environments. This limitation hampers precise anomaly detection research, especially for industrial equipment components (IEC) such as bearings, rings, and bolts. To address this challenge, we have developed a point cloud anomaly detection dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is directly collected from actual production lines, ensuring high fidelity and relevance. Compared to existing datasets, IEC3D-AD features significantly improved point cloud resolution and defect annotation granularity, facilitating more demanding anomaly detection tasks. Furthermore, inspired by generative 2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This paradigm generates synthetic point cloud samples based on geometric morphological analysis, then reduces the margin and increases the overlap between normal and abnormal point-level features through spatial discrepancy optimization. Extensive experiments demonstrate the effectiveness of our method on both IEC3D-AD and other datasets.</li>
<li><strong>摘要：</strong>3D异常检测（3D-AD）在工业制造中发挥着至关重要的作用，特别是在确保核心设备部件的可靠性和安全性方面。尽管 Real3D-AD 和 MVTec 3D-AD 等现有 3D 数据集提供了广泛的应用支持，但它们在捕获真实工业环境中发现的复杂性和细微缺陷方面存在不足。这种限制阻碍了精确的异常检测研究，特别是对于轴承、环和螺栓等工业设备部件 (IEC)。为了应对这一挑战，我们开发了针对实际工业场景的点云异常检测数据集（IEC3D-AD）。该数据集直接从实际生产线采集，确保高保真度和相关性。与现有数据集相比，IEC3D-AD 显着提高了点云分辨率和缺陷注释粒度，有助于执行更苛刻的异常检测任务。此外，受生成 2D-AD 方法的启发，我们在 IEC3D-AD 上引入了一种新颖的 3D-AD 范式（GMANet）。该范式基于几何形态分析生成合成点云样本，然后通过空间差异优化减少余量并增加正常和异常点级特征之间的重叠。大量实验证明了我们的方法在 IEC3D-AD 和其他数据集上的有效性。</li>
</ul>

<h3>Title: Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising</h3>
<ul>
<li><strong>Authors: </strong>Shuangquan Lyu, Steven Mao, Yue Ma</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03272">https://arxiv.org/abs/2511.03272</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03272">https://arxiv.org/pdf/2511.03272</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03272]] Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising(https://arxiv.org/abs/2511.03272)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Generating long videos remains a fundamental challenge, and achieving high controllability in video inpainting and outpainting is particularly demanding. To address both of these challenges simultaneously and achieve controllable video inpainting and outpainting for long video clips, we introduce a novel and unified approach for long video inpainting and outpainting that extends text-to-video diffusion models to generate arbitrarily long, spatially edited videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked region video synthesis, and employs an overlap-and-blend temporal co-denoising strategy with high-order solvers to maintain consistency across long sequences. In contrast to prior work that struggles with fixed-length clips or exhibits stitching artifacts, our system enables arbitrarily long video generation and editing without noticeable seams or drift. We validate our approach on challenging inpainting/outpainting tasks including editing or adding objects over hundreds of frames and demonstrate superior performance to baseline methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and perceptual realism (LPIPS). Our method enables practical long-range video editing with minimal overhead, achieved a balance between parameter efficient and superior performance.</li>
<li><strong>摘要：</strong>生成长视频仍然是一个基本挑战，并且在视频修复和修复中实现高可控性尤为困难。为了同时解决这两个挑战并实现长视频剪辑的可控视频修复和修复，我们引入了一种新颖且统一的长视频修复和修复方法，该方法扩展了文本到视频的扩散模型，以生成任意长的、高保真度的空间编辑视频。我们的方法利用 LoRA 来有效地微调大型预训练视频扩散模型，例如用于屏蔽区域视频合成的阿里巴巴 Wan 2.1，并采用重叠和混合时间共同去噪策略与高阶求解器来保持长序列的一致性。与之前的工作相比，我们的系统可以生成和编辑任意长的视频，而不会出现明显的接缝或漂移。我们在具有挑战性的修复/修复任务上验证了我们的方法，包括在数百帧上编辑或添加对象，并在质量 (PSNR/SSIM) 和感知真实感 (LPIPS) 方面展示了优于 Wan 2.1 模型和 VACE 等基线方法的性能。我们的方法能够以最小的开销实现实际的远程视频编辑，实现参数效率和卓越性能之间的平衡。</li>
</ul>

<h3>Title: Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models</h3>
<ul>
<li><strong>Authors: </strong>Minghao Fu, Guo-Hua Wang, Tianyu Cui, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03317">https://arxiv.org/abs/2511.03317</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03317">https://arxiv.org/pdf/2511.03317</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03317]] Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models(https://arxiv.org/abs/2511.03317)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Text-to-image diffusion models deliver high-quality images, yet aligning them with human preferences remains challenging. We revisit diffusion-based Direct Preference Optimization (DPO) for these models and identify a critical pathology: enlarging the preference margin does not necessarily improve generation quality. In particular, the standard Diffusion-DPO objective can increase the reconstruction error of both winner and loser branches. Consequently, degradation of the less-preferred outputs can become sufficiently severe that the preferred branch is also adversely affected even as the margin grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule that preserves the winner by adaptively scaling the loser gradient according to its alignment with the winner gradient. A first-order analysis yields a closed-form scaling coefficient that guarantees the error of the preferred output is non-increasing at each optimization step. Our method is simple, model-agnostic, broadly compatible with existing DPO-style alignment frameworks and adds only marginal computational overhead. Across standard text-to-image benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning baselines on automated preference, aesthetic, and prompt alignment metrics. Code is publicly available at this https URL.</li>
<li><strong>摘要：</strong>文本到图像的扩散模型可提供高质量的图像，但使其与人类偏好保持一致仍然具有挑战性。我们重新审视这些模型的基于扩散的直接偏好优化（DPO），并确定了一个关键的病态：扩大偏好幅度并不一定会提高发电质量。特别是，标准 Diffusion-DPO 目标会增加获胜者分支和失败者分支的重建误差。因此，不太优选的输出的退化可能变得非常严重，即使裕度增长，优选的分支也会受到不利影响。为了解决这个问题，我们引入了 Diffusion-SDPO，这是一种受保护的更新规则，通过根据失败者梯度与获胜者梯度的对齐情况自适应缩放失败者梯度来保留获胜者。一阶分析产生一个封闭形式的缩放系数，保证首选输出的误差在每个优化步骤中不增加。我们的方法很简单，与模型无关，与现有的 DPO 式对齐框架广泛兼容，并且仅增加了少量的计算开销。在标准文本到图像基准测试中，Diffusion-SDPO 在自动偏好、美观和提示对齐指标方面比偏好学习基线提供了一致的增益。代码可通过此 https URL 公开获取。</li>
</ul>

<h3>Title: UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions</h3>
<ul>
<li><strong>Authors: </strong>Guozhen Zhang, Zixiang Zhou, Teng Hu, Ziqiao Peng, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03334">https://arxiv.org/abs/2511.03334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03334">https://arxiv.org/pdf/2511.03334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03334]] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions(https://arxiv.org/abs/2511.03334)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Due to the lack of effective cross-modal modeling, existing open-source audio-video generation methods often exhibit compromised lip synchronization and insufficient semantic consistency. To mitigate these drawbacks, we propose UniAVGen, a unified framework for joint audio and video generation. UniAVGen is anchored in a dual-branch joint synthesis architecture, incorporating two parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which enables bidirectional, temporally aligned cross-attention, thus ensuring precise spatiotemporal synchronization and semantic consistency. Furthermore, this cross-modal interaction is augmented by a Face-Aware Modulation module, which dynamically prioritizes salient regions in the interaction process. To enhance generative fidelity during inference, we additionally introduce Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint synthesis design enables seamless unification of pivotal audio-video tasks within a single model, such as joint audio-video generation and continuation, video-to-audio dubbing, and audio-driven video synthesis. Comprehensive experiments validate that, with far fewer training samples (1.3M vs. 30.1M), UniAVGen delivers overall advantages in audio-video synchronization, timbre consistency, and emotion consistency.</li>
<li><strong>摘要：</strong>由于缺乏有效的跨模态建模，现有的开源音视频生成方法经常表现出唇形同步受损和语义一致性不足的问题。为了减轻这些缺点，我们提出了 UniAVGen，这是一个用于联合音频和视频生成的统一框架。 UniAVGen 以双分支联合合成架构为基础，结合两个并行的扩散变压器 (DiT) 来构建一个有凝聚力的跨模态潜在空间。其核心在于非对称跨模态交互机制，可实现双向、时间对齐的交叉注意力，从而确保精确的时空同步和语义一致性。此外，这种跨模式交互通过面部感知调制模块得到增强，该模块动态地优先考虑交互过程中的显着区域。为了增强推理过程中的生成保真度，我们还引入了模态感知无分类器指导，这是一种显式放大跨模态相关信号的新颖策略。值得注意的是，UniAVGen 强大的联合合成设计可以在单个模型中无缝统一关键音频-视频任务，例如联合音频-视频生成和延续、视频到音频配音以及音频驱动的视频合成。综合实验验证，在训练样本少得多的情况下（1.3M vs. 30.1M），UniAVGen 在音视频同步、音色一致性和情感一致性方面具有整体优势。</li>
</ul>

<h3>Title: POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding</h3>
<ul>
<li><strong>Authors: </strong>Mihriban Kocak Balik, Pekka Marttinen, Negar Safinianaini</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03464">https://arxiv.org/abs/2511.03464</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03464">https://arxiv.org/pdf/2511.03464</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03464]] POEMS: Product of Experts for Interpretable Multi-omic Integration using Sparse Decoding(https://arxiv.org/abs/2511.03464)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Integrating different molecular layers, i.e., multiomics data, is crucial for unraveling the complexity of diseases; yet, most deep generative models either prioritize predictive performance at the expense of interpretability or enforce interpretability by linearizing the decoder, thereby weakening the network's nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS: Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding, an unsupervised probabilistic framework that preserves predictive performance while providing interpretability. POEMS provides interpretability without linearizing any part of the network by 1) mapping features to latent factors using sparse connections, which directly translates to biomarker discovery, 2) allowing for cross-omic associations through a shared latent space using product of experts model, and 3) reporting contributions of each omic by a gating network that adaptively computes their influence in the representation learning. Additionally, we present an efficient sparse decoder. In a cancer subtyping case study, POEMS achieves competitive clustering and classification performance while offering our novel set of interpretations, demonstrating that biomarker based insight and predictive accuracy can coexist in multiomics representation learning.</li>
<li><strong>摘要：</strong>整合不同的分子层，即多组学数据，对于揭示疾病的复杂性至关重要；然而，大多数深度生成模型要么以牺牲可解释性为代价来优先考虑预测性能，要么通过线性化解码器来增强可解释性，从而削弱网络的非线性表达能力。为了克服这种权衡，我们引入了 POEMS：使用稀疏解码进行可解释多组学集成的专家产品，这是一种无监督的概率框架，可以在提供可解释性的同时保留预测性能。 POEMS 通过以下方式提供可解释性，无需线性化网络的任何部分：1）使用稀疏连接将特征映射到潜在因素，这直接转化为生物标志物发现，2）使用专家模型的乘积通过共享潜在空间允许跨组学关联，3）通过门控网络报告每个组学的贡献，该门控网络自适应地计算它们在表示学习中的影响。此外，我们提出了一种高效的稀疏解码器。在癌症亚型分型案例研究中，POEMS 实现了有竞争力的聚类和分类性能，同时提供了我们新颖的解释集，证明基于生物标志物的洞察力和预测准确性可以在多组学表示学习中共存。</li>
</ul>

<h3>Title: RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse</h3>
<ul>
<li><strong>Authors: </strong>Yinsicheng Jiang, Yeqi Huang, Liang Cheng, Cheng Deng, Xuan Sun, Luo Mai</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03475">https://arxiv.org/abs/2511.03475</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03475">https://arxiv.org/pdf/2511.03475</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03475]] RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse(https://arxiv.org/abs/2511.03475)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation (RAG) enhances large language models (LLMs) with retrieved context but often suffers from downgraded prefill performance as modern applications demand longer and more complex inputs. Existing caching techniques either preserve accuracy with low cache reuse or improve reuse at the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG system that achieves high cache reuse without sacrificing accuracy through accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items across concurrent sessions and multi-turn interactions, using efficient context indexing, ordering, and de-duplication to maximize reuse, while lightweight contextual hints maintain reasoning fidelity. It integrates seamlessly with existing LLM inference engines and improves their prefill performance by 1.5-3X over state-of-the-art methods, while preserving or even enhancing reasoning accuracy across diverse RAG and agentic AI workloads. Our code is released at: this https URL.</li>
<li><strong>摘要：</strong>检索增强生成 (RAG) 通过检索上下文增强了大型语言模型 (LLM)，但由于现代应用程序需要更长、更复杂的输入，因此常常会受到预填充性能下降的影响。现有的缓存技术要么通过低缓存重用来保持准确性，要么以降低推理质量为代价来提高重用。我们提出了 RAGBoost，这是一种高效的 RAG 系统，它通过保留准确性的上下文重用来实现高缓存重用，而不会牺牲准确性。 RAGBoost 检测并发会话和多轮交互中重叠检索的项目，使用高效的上下文索引、排序和重复数据删除来最大限度地重用，同时轻量级上下文提示保持推理保真度。它与现有的 LLM 推理引擎无缝集成，并将其预填充性能比最先进的方法提高 1.5-3 倍，同时保持甚至增强跨不同 RAG 和代理 AI 工作负载的推理准确性。我们的代码发布于：此 https URL。</li>
</ul>

<h3>Title: Human Mesh Modeling for Anny Body</h3>
<ul>
<li><strong>Authors: </strong>Romain Brégier, Guénolé Fiche, Laura Bravo-Sánchez, Thomas Lucas, Matthieu Armando, Philippe Weinzaepfel, Grégory Rogez, Fabien Baradel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03589">https://arxiv.org/abs/2511.03589</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03589">https://arxiv.org/pdf/2511.03589</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03589]] Human Mesh Modeling for Anny Body(https://arxiv.org/abs/2511.03589)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Parametric body models are central to many human-centric tasks, yet existing models often rely on costly 3D scans and learned shape spaces that are proprietary and demographically narrow. We introduce Anny, a simple, fully differentiable, and scan-free human body model grounded in anthropometric knowledge from the MakeHuman community. Anny defines a continuous, interpretable shape space, where phenotype parameters (e.g. gender, age, height, weight) control blendshapes spanning a wide range of human forms -- across ages (from infants to elders), body types, and proportions. Calibrated using WHO population statistics, it provides realistic and demographically grounded human shape variation within a single unified model. Thanks to its openness and semantic control, Anny serves as a versatile foundation for 3D human modeling -- supporting millimeter-accurate scan fitting, controlled synthetic data generation, and Human Mesh Recovery (HMR). We further introduce Anny-One, a collection of 800k photorealistic humans generated with Anny, showing that despite its simplicity, HMR models trained with Anny can match the performance of those trained with scan-based body models, while remaining interpretable and broadly representative. The Anny body model and its code are released under the Apache 2.0 license, making Anny an accessible foundation for human-centric 3D modeling.</li>
<li><strong>摘要：</strong>参数化人体模型是许多以人为中心的任务的核心，但现有模型通常依赖于昂贵的 3D 扫描和学习的形状空间，这些形状空间是专有的且人口统计范围狭窄。我们介绍 Anny，这是一个简单、完全可微且免扫描的人体模型，它基于 MakeHuman 社区的人体测量知识。 Anny 定义了一个连续的、可解释的形状空间，其中表型参数（例如性别、年龄、身高、体重）控制跨越各种人类形态的混合形状——跨越年龄（从婴儿到老年人）、体型和比例。它使用世界卫生组织人口统计数据进行校准，在单一统一模型中提供现实且基于人口统计的人体形状变化。凭借其开放性和语义控制，Anny 成为 3D 人体建模的多功能基础——支持毫米级精确的扫描拟合、受控合成数据生成和人体网格恢复 (HMR)。我们进一步介绍了 Anny-One，这是用 Anny 生成的 80 万个逼真的人体集合，表明尽管很简单，但用 Anny 训练的 HMR 模型可以与用基于扫描的身体模型训练的模型相匹配，同时保持可解释性和广泛的代表性。 Anny 身体模型及其代码根据 Apache 2.0 许可证发布，使 Anny 成为以人为中心的 3D 建模的可访问基础。</li>
</ul>

<h3>Title: SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Mahek Desai, Apoorva Rumale, Marjan Asadinia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03661">https://arxiv.org/abs/2511.03661</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03661">https://arxiv.org/pdf/2511.03661</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03661]] SHIELD: Securing Healthcare IoT with Efficient Machine Learning Techniques for Anomaly Detection(https://arxiv.org/abs/2511.03661)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.</li>
<li><strong>摘要：</strong>物联网设备在医疗保健中的集成带来了重大的安全性和可靠性挑战，增加了对网络威胁和操作异常的敏感性。本研究提出了一个机器学习驱动的框架，用于 (1) 检测恶意网络攻击和 (2) 识别有故障的设备异常，利用包含 200,000 条记录的数据集。通过三种学习方法评估八种机器学习模型：监督学习（XGBoost、K 最近邻 (K-NN)）、半监督学习（生成对抗网络 (GAN)、变分自动编码器 (VAE)）和无监督学习（一类支持向量机 (SVM)、隔离森林、图神经网络 (GNN) 和长短期记忆 (LSTM)）自动编码器）。综合评估针对 F1 分数、精确度、召回率、准确度、ROC-AUC、计算效率等多个指标进行。 XGBoost 以最小的计算开销（0.04 秒）实现了 99% 的异常检测准确率，而隔离森林有效地平衡了精度和召回率。 LSTM 自动编码器表现不佳，精度较低，延迟较高。对于攻击检测，KNN 以最低的计算成本（0.05 秒）实现了近乎完美的精度、召回率和 F1 分数，其次是 VAE，准确率高达 97%。 GAN 显示出最高的计算成本、最低的准确度和 ROC-AUC。这些发现通过有效的异常检测策略增强了物联网支持的医疗保健安全。通过改进网络威胁和设备故障的早期检测，该框架有可能防止数据泄露，最大限度地减少系统停机时间，并确保医疗设备的持续安全运行，最终维护患者的健康和对物联网驱动的医疗保健解决方案的信任。</li>
</ul>

<h3>Title: AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing</h3>
<ul>
<li><strong>Authors: </strong>Mohsen Ahmadzadeh, Kaichang Chen, Georges Gielen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03697">https://arxiv.org/abs/2511.03697</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03697">https://arxiv.org/pdf/2511.03697</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03697]] AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing(https://arxiv.org/abs/2511.03697)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.</li>
<li><strong>摘要：</strong>模拟/混合信号电路是将电子设备与物理世界连接起来的关键。然而，他们的设计仍然很大程度上是手工制作的过程，导致设计周期长且容易出错。虽然最近兴起的基于人工智能的强化学习和生成人工智能创造了自动化这项任务的新技术，但需要进行许多耗时的模拟是阻碍整体效率的关键瓶颈。此外，最终的设计解决方案缺乏可解释性，阻碍了这些工具的广泛采用。为了解决这些问题，提出了一种新颖的代理人工智能框架，用于样本高效且可解释的模拟电路尺寸调整。它采用多代理工作流程，其中基于大语言模型 (LLM) 的专业代理协作解释电路拓扑、理解设计目标，并通过人类可解释的推理迭代地改进电路的设计参数以实现目标。自适应模拟策略创建了可产生高采样效率的智能控制。 AnaFlow 框架针对不同复杂度的两个电路进行了演示，并且能够完全自动完成大小调整任务，这与纯贝叶斯优化和强化学习方法不同。系统从优化历史中学习，以避免过去的错误并加速收敛。固有的可解释性使其成为模拟设计空间探索的强大工具和模拟 EDA 的新范式，其中人工智能代理充当透明的设计助手。</li>
</ul>

<h3>Title: Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards</h3>
<ul>
<li><strong>Authors: </strong>Guanning Zeng, Zhaoyi Zhou, Daman Arora, Andrea Zanette</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2511.03710">https://arxiv.org/abs/2511.03710</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2511.03710">https://arxiv.org/pdf/2511.03710</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2511.03710]] Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards(https://arxiv.org/abs/2511.03710)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for post-training large reasoning models (LRMs) using policy-gradient methods such as GRPO. To stabilize training, these methods typically center trajectory rewards by subtracting the empirical mean for each prompt. Statistically, this centering acts as a control variate (or baseline), reducing the variance of the policy-gradient estimator. Typically, the mean reward is estimated using per-prompt empirical averages for each prompt in a batch. Drawing inspiration from Stein's paradox, we propose using shrinkage estimators that combine per-prompt and across-prompt means to improve the overall per-prompt mean estimation accuracy -- particularly in the low-generation regime typical of RLVR. Theoretically, we construct a shrinkage-based baseline that provably yields lower-variance policy-gradient estimators across algorithms. Our proposed baseline serves as a drop-in replacement for existing per-prompt mean baselines, requiring no additional hyper-parameters or computation. Empirically, shrinkage baselines consistently outperform standard empirical-mean baselines, leading to lower-variance gradient updates and improved training stability.</li>
<li><strong>摘要：</strong>具有可验证奖励的强化学习 (RLVR) 已成为使用 GRPO 等策略梯度方法进行训练后大型推理模型 (LRM) 的强大范例。为了稳定训练，这些方法通常通过减去每个提示的经验平均值来集中轨迹奖励。从统计上讲，这种中心化充当控制变量（或基线），减少了策略梯度估计量的方差。通常，平均奖励是使用批次中每个提示的每个提示的经验平均值来估计的。受 Stein 悖论的启发，我们建议使用收缩估计器，将每个提示和跨提示方法结合起来，以提高整体每个提示均值估计的准确性 - 特别是在 RLVR 典型的低生成机制中。理论上，我们构建了一个基于收缩的基线，可证明在算法中产生较低方差的策略梯度估计器。我们提出的基线可以直接替代现有的按提示平均基线，不需要额外的超参数或计算。根据经验，收缩基线始终优于标准经验平均基线，从而导致较低方差的梯度更新并提高训练稳定性。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
