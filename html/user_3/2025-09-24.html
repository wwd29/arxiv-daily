<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-09-24</h1>
<h3>Title: Solve it with EASE</h3>
<ul>
<li><strong>Authors: </strong>Adam Viktorin, Tomas Kadavy, Jozef Kovac, Michal Pluhacek, Roman Senkerik</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18108">https://arxiv.org/abs/2509.18108</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18108">https://arxiv.org/pdf/2509.18108</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18108]] Solve it with EASE(https://arxiv.org/abs/2509.18108)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative, quality assessment</a></li>
<li><strong>Abstract: </strong>This paper presents EASE (Effortless Algorithmic Solution Evolution), an open-source and fully modular framework for iterative algorithmic solution generation leveraging large language models (LLMs). EASE integrates generation, testing, analysis, and evaluation into a reproducible feedback loop, giving users full control over error handling, analysis, and quality assessment. Its architecture supports the orchestration of multiple LLMs in complementary roles-such as generator, analyst, and evaluator. By abstracting the complexity of prompt design and model management, EASE provides a transparent and extensible platform for researchers and practitioners to co-design algorithms and other generative solutions across diverse domains.</li>
<li><strong>摘要：</strong>本文提供了轻松（轻松的算法解决方案进化），这是一个开源和完全模块化的框架，用于迭代算法解决方案生成利用大型语言模型（LLMS）。 Ease将生成，测试，分析和评估集成到可再现的反馈循环中，从而使用户完全控制错误处理，分析和质量评估。它的体系结构支持互补角色中多个LLM的编排，例如生成器，分析师和评估器。通过抽象迅速设计和模型管理的复杂性，Ease为研究人员和从业人员提供了一个透明且可扩展的平台，以共同设计算法和其他不同领域的其他生成解决方案。</li>
</ul>

<h3>Title: Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization</h3>
<ul>
<li><strong>Authors: </strong>Nathan Egbuna, Saatvik Gaur, Sunishchal Dev, Ashwinee Panda, Maheep Chaudhary</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18116">https://arxiv.org/abs/2509.18116</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18116">https://arxiv.org/pdf/2509.18116</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18116]] Amortized Latent Steering: Low-Cost Alternative to Test-Time Optimization(https://arxiv.org/abs/2509.18116)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Test-time optimization remains impractical at scale due to prohibitive inference costs\textemdash techniques like iterative refinement and multi-step verification can require $10$--$100\times$ more compute per query than standard decoding. Latent space test-time optimization methods like LatentSeek offer a more direct approach by steering hidden representations, but still demand expensive per-query optimization loops with multiple backward passes. We propose Amortized Latent Steering (ALS), which collapses this iterative optimization into a single offline-computed vector applied at constant cost during inference. ALS computes the mean difference between hidden states from successful versus unsuccessful generations, then uses this direction to calibrate the model's hidden representations: when decoding drifts away from the success manifold, ALS nudges activations back toward it. Across GSM8K and MATH-$500$ benchmarks, ALS achieves $2$--$5\times$ speedup over iterative methods while matching or surpassing greedy Chain-of-Thought (CoT) and Self-Consistency baselines, yielding up to 101\% improvement in efficiency--accuracy trade-off. These results show that much of latent optimization's benefit can be captured offline, making sophisticated reasoning techniques viable for production deployment. Code is available at~\href{this https URL}{this https URL}</li>
<li><strong>摘要：</strong>由于推理成本过高\ TextEmdash技术（如迭代精炼和多步验证），测试时间优化仍然不切实际，而多步验证可能需要$ 10 $  -  $ 100 \ $ 100 \ times $每查询的计算比标准解码多。潜在的空间测试时间优化方法（例如LatentSeek）通过转向隐藏的表示形式提供了更直接的方法，但仍然需要具有多个向后传球的昂贵的每次传输优化循环。我们提出了摊销的潜在转向（ALS），该转向（ALS）将这种迭代优化倒入一个单个离线计算的向量，该矢量在推理过程中以恒定的成本应用。 ALS计算从成功与失败的世代中隐藏状态之间的平均差异，然后使用此方向校准模型的隐藏表示形式：当解码从成功歧管上偏离成功歧管时，ALS将激活朝向其。在GSM8K和MATH- $ 500 $基准中，ALS可实现$ 2 $  -  $ 5 \ $ 5 \ times $ $速度比迭代方法加速，同时匹配或超过贪婪的贪婪链（COT）（COT）和自以为是的基准，并在效率上提高了101 \％的提高效率 - 效率-11 \％。这些结果表明，潜在优化的大部分好处都可以离线捕获，从而使复杂的推理技术适合生产部署。代码可在〜\ href {此https url} {此https url}</li>
</ul>

<h3>Title: A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Thanh Linh Nguyen, Quoc-Viet Pham</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE, cs.DC, cs.GT</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18120">https://arxiv.org/abs/2509.18120</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18120">https://arxiv.org/pdf/2509.18120</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18120]] A Coopetitive-Compatible Data Generation Framework for Cross-silo Federated Learning(https://arxiv.org/abs/2509.18120)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Cross-silo federated learning (CFL) enables organizations (e.g., hospitals or banks) to collaboratively train artificial intelligence (AI) models while preserving data privacy by keeping data local. While prior work has primarily addressed statistical heterogeneity across organizations, a critical challenge arises from economic competition, where organizations may act as market rivals, making them hesitant to participate in joint training due to potential utility loss (i.e., reduced net benefit). Furthermore, the combined effects of statistical heterogeneity and inter-organizational competition on organizational behavior and system-wide social welfare remain underexplored. In this paper, we propose CoCoGen, a coopetitive-compatible data generation framework, leveraging generative AI (GenAI) and potential game theory to model, analyze, and optimize collaborative learning under heterogeneous and competitive settings. Specifically, CoCoGen characterizes competition and statistical heterogeneity through learning performance and utility-based formulations and models each training round as a weighted potential game. We then derive GenAI-based data generation strategies that maximize social welfare. Experimental results on the Fashion-MNIST dataset reveal how varying heterogeneity and competition levels affect organizational behavior and demonstrate that CoCoGen consistently outperforms baseline methods.</li>
<li><strong>摘要：</strong>跨性别联盟学习（CFL）使组织（例如，医院或银行）可以协作培训人工智能（AI）模型，同时通过保持数据本地化来保护数据隐私。虽然先前的工作主要解决了整个组织之间的统计异质性，但经济竞争引起了一个关键的挑战，组织可能是市场竞争对手，使他们由于潜在的公用事业损失而犹豫不决地参加联合培训（即净福利降低）。此外，统计异质性和组织间竞争对组织行为和系统范围内的社会福利的综合影响尚未得到充实。在本文中，我们提出了Cocogen，Cocogen是一个竞争兼容的数据生成框架，利用生成AI（Genai）和潜在的游戏理论来建模，分析和优化异构和竞争性的环境下的协作学习。具体而言，Cocogen通过学习性能和基于公用事业的配方和模型每个训练作为加权潜在的游戏来表征竞争和统计异质性。然后，我们得出基于Genai的数据生成策略，以最大化社会福利。关于时尚记器数据集的实验结果揭示了异质性和竞争水平的不同影响组织行为，并证明Cocogen始终超过基线方法。</li>
</ul>

<h3>Title: Prediction of Coffee Ratings Based On Influential Attributes Using SelectKBest and Optimal Hyperparameters</h3>
<ul>
<li><strong>Authors: </strong>Edmund Agyemang, Lawrence Agbota, Vincent Agbenyeavu, Peggy Akabuah, Bismark Bimpong, Christopher Attafuah</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18124">https://arxiv.org/abs/2509.18124</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18124">https://arxiv.org/pdf/2509.18124</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18124]] Prediction of Coffee Ratings Based On Influential Attributes Using SelectKBest and Optimal Hyperparameters(https://arxiv.org/abs/2509.18124)</code><input type="text"></li>
<li><strong>Keywords: </strong>quality assessment</a></li>
<li><strong>Abstract: </strong>This study explores the application of supervised machine learning algorithms to predict coffee ratings based on a combination of influential textual and numerical attributes extracted from user reviews. Through careful data preprocessing including text cleaning, feature extraction using TF-IDF, and selection with SelectKBest, the study identifies key factors contributing to coffee quality assessments. Six models (Decision Tree, KNearest Neighbors, Multi-layer Perceptron, Random Forest, Extra Trees, and XGBoost) were trained and evaluated using optimized hyperparameters. Model performance was assessed primarily using F1-score, Gmean, and AUC metrics. Results demonstrate that ensemble methods (Extra Trees, Random Forest, and XGBoost), as well as Multi-layer Perceptron, consistently outperform simpler classifiers (Decision Trees and K-Nearest Neighbors) in terms of evaluation metrics such as F1 scores, G-mean and AUC. The findings highlight the essence of rigorous feature selection and hyperparameter tuning in building robust predictive systems for sensory product evaluation, offering a data driven approach to complement traditional coffee cupping by expertise of trained professionals.</li>
<li><strong>摘要：</strong>这项研究探讨了受监督的机器学习算法的应用，以根据从用户评论中提取的有影响力的文本和数值属性组合来预测咖啡评分。通过仔细的数据预处理，包括文本清洁，使用TF-IDF提取特征，并选择SelectKBest，该研究确定了有助于咖啡质量评估的关键因素。使用优化的超参数训练并评估了六种型号（决策树，最邻居的邻居，多层感知者，随机森林，额外的树木和Xgboost）。主要使用F1分数，Gmean和AUC指标评估模型性能。结果表明，在评估指标（例如F1分数，g-mean and auc）等方面，合奏方法（额外的树木，随机森林和XGBoost）以及多层感知器，始终超过更简单的分类器（决策树和K-Nearest邻居）。这些发现突出了对感官产品评估构建强大的预测系统的严格特征选择和超参数调整的本质，从而提供了一种数据驱动的方法，可以通过训练有素的专业人士的专业知识来补充传统的咖啡拔罐。</li>
</ul>

<h3>Title: ConceptFlow: Hierarchical and Fine-grained Concept-Based Explanation for Convolutional Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Xinyu Mu, Hui Dou, Furao Shen, Jian Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18147">https://arxiv.org/abs/2509.18147</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18147">https://arxiv.org/pdf/2509.18147</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18147]] ConceptFlow: Hierarchical and Fine-grained Concept-Based Explanation for Convolutional Neural Networks(https://arxiv.org/abs/2509.18147)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Concept-based interpretability for Convolutional Neural Networks (CNNs) aims to align internal model representations with high-level semantic concepts, but existing approaches largely overlook the semantic roles of individual filters and the dynamic propagation of concepts across layers. To address these limitations, we propose ConceptFlow, a concept-based interpretability framework that simulates the internal "thinking path" of a model by tracing how concepts emerge and evolve across layers. ConceptFlow comprises two key components: (i) concept attentions, which associate each filter with relevant high-level concepts to enable localized semantic interpretation, and (ii) conceptual pathways, derived from a concept transition matrix that quantifies how concepts propagate and transform between filters. Together, these components offer a unified and structured view of internal model reasoning. Experimental results demonstrate that ConceptFlow yields semantically meaningful insights into model reasoning, validating the effectiveness of concept attentions and conceptual pathways in explaining decision behavior. By modeling hierarchical conceptual pathways, ConceptFlow provides deeper insight into the internal logic of CNNs and supports the generation of more faithful and human-aligned explanations.</li>
<li><strong>摘要：</strong>基于概念的卷积神经网络（CNN）的解释性旨在使内部模型表示与高级语义概念保持一致，但是现有方法在很大程度上忽略了单个过滤器的语义角色和跨层概念的动态传播。为了解决这些局限性，我们提出了概念流，这是一个基于概念的可解释性框架，通过追踪概念如何在各个层中出现和发展来模拟模型的内部“思维路径”。概念流包括两个关键组成部分：（i）概念关注，它们将每个过滤器与相关的高级概念相关联，以实现局部语义解释，（ii）概念途径，这些概念途径源自概念过渡矩阵，该概念过渡矩阵量化概念如何在滤波器之间传播和转换。这些组件一起提供了内部模型推理的统一和结构化的视图。实验结果表明，概念流对模型推理产生了有意义的见解，从而验证了概念关注和概念途径在解释决策行为中的有效性。通过建模层次结构概念途径，ConceptFlow提供了对CNN的内部逻辑的更深入的见解，并支持了更忠实和人类一致的解释的产生。</li>
</ul>

<h3>Title: A deep reinforcement learning platform for antibiotic discovery</h3>
<ul>
<li><strong>Authors: </strong>Hanqun Cao, Marcelo D. T. Torres, Jingjie Zhang, Zijun Gao, Fang Wu, Chunbin Gu, Jure Leskovec, Yejin Choi, Cesar de la Fuente-Nunez, Guangyong Chen, Pheng-Ann Heng</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18153">https://arxiv.org/abs/2509.18153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18153">https://arxiv.org/pdf/2509.18153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18153]] A deep reinforcement learning platform for antibiotic discovery(https://arxiv.org/abs/2509.18153)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Antimicrobial resistance (AMR) is projected to cause up to 10 million deaths annually by 2050, underscoring the urgent need for new antibiotics. Here we present ApexAmphion, a deep-learning framework for de novo design of antibiotics that couples a 6.4-billion-parameter protein language model with reinforcement learning. The model is first fine-tuned on curated peptide data to capture antimicrobial sequence regularities, then optimised with proximal policy optimization against a composite reward that combines predictions from a learned minimum inhibitory concentration (MIC) classifier with differentiable physicochemical objectives. In vitro evaluation of 100 designed peptides showed low MIC values (nanomolar range in some cases) for all candidates (100% hit rate). Moreover, 99 our of 100 compounds exhibited broad-spectrum antimicrobial activity against at least two clinically relevant bacteria. The lead molecules killed bacteria primarily by potently targeting the cytoplasmic membrane. By unifying generation, scoring and multi-objective optimization with deep reinforcement learning in a single pipeline, our approach rapidly produces diverse, potent candidates, offering a scalable route to peptide antibiotics and a platform for iterative steering toward potency and developability within hours.</li>
<li><strong>摘要：</strong>预计到2050年，抗菌耐药性（AMR）每年将每年造成多达1000万人死亡，这强调了对新抗生素的迫切需求。在这里，我们提出了Apexamphion，这是一个抗生素从头设计的深度学习框架，它与增强学习结合了6.4亿参数蛋白质语言模型。该模型首先在精心策划的肽数据上进行微调以捕获抗菌序列规律性，然后对近端策略优化优化，以优化复合奖励，该复合奖励结合了从学习的最小抑制浓度（MIC）分类器与可不同的物理化学目标的预测。对100种设计肽的体外评估显示所有候选物的MIC值低（纳摩尔范围）（100％HIT率）。此外，我们的100种化合物中有99种对至少两种临床相关细菌表现出广泛的抗菌活性。铅分子主要通过靶向细胞质膜而杀死细菌。通过在单个管道中通过深入的强化学习来统一生成，评分和多目标优化，我们的方法迅速产生了多样化的，有效的候选者，为肽抗生素提供了可扩展的途径，并提供了迭代方向，用于迭代方向朝着效力和开发性方向转向。</li>
</ul>

<h3>Title: DSFT: Inspiring Diffusion Large Language Models to Comprehend Mathematical and Logical Patterns</h3>
<ul>
<li><strong>Authors: </strong>Ranfei Chen, Ming Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18164">https://arxiv.org/abs/2509.18164</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18164">https://arxiv.org/pdf/2509.18164</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18164]] DSFT: Inspiring Diffusion Large Language Models to Comprehend Mathematical and Logical Patterns(https://arxiv.org/abs/2509.18164)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs) have emerged as a new architecture following auto regressive models. Their denoising process offers a powerful generative advantage, but they present significant challenges in learning and understanding numerically sensitive mathematical and order-sensitive logical tasks. Current training methods, including pre-training, fine-tuning, and reinforcement learning, focus primarily on improving general knowledge retention and reasoning abilities, but lack a comprehensive understanding of mathematical and logical patterns. We propose DSFT, a simple yet effective Diffusion SFT strategy, by adjusting the masking strategy and loss function, guiding models to understand mathematical and logical patterns. This strategy can be flexibly combined with pre-training, reinforcement learning, and other training methods. Validated on models such as LLaDA and Dream series, we prove that DSFT on small-scale data can achieve improvements of 5-10% and approximately 2% on mathematical and logical problems, respectively. This inspiring masking approach offers insights for future learning of specific patterns, which can be easily and efficiently combined with other training methods and applied to various dLLMs. Our code is publicly available at this https URL</li>
<li><strong>摘要：</strong>扩散大语言模型（DLLM）已成为自动回归模型的新体系结构。他们的降级过程提供了强大的生成优势，但是他们在学习和理解数字敏感的数学和对秩序敏感的逻辑任务方面提出了重大挑战。当前的培训方法，包括预训练，微调和强化学习，主要集中于提高常识性保留和推理能力，但对数学和逻辑模式缺乏全面的理解。我们通过调整掩盖策略和损失函数，指导模型来了解数学和逻辑模式，提出DSFT，这是一种简单而有效的扩散SFT策略。该策略可以与预训练，增强学习和其他培训方法相结合。在Llada和Dream系列等模型上验证，我们证明，在小规模数据上的DSFT可以在数学和逻辑问题上分别提高5-10％和大约2％。这种鼓舞人心的掩蔽方法为未来学习特定模式提供了见解，可以轻松有效地将其与其他培训方法结合在一起，并应用于各种DLLM。我们的代码在此HTTPS URL上公开可用</li>
</ul>

<h3>Title: MobiGPT: A Foundation Model for Mobile Wireless Networks</h3>
<ul>
<li><strong>Authors: </strong>Xiaoqian Qi, Haoye Chai, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18166">https://arxiv.org/abs/2509.18166</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18166">https://arxiv.org/pdf/2509.18166</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18166]] MobiGPT: A Foundation Model for Mobile Wireless Networks(https://arxiv.org/abs/2509.18166)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>With the rapid development of mobile communication technologies, future mobile networks will offer vast services and resources for commuting, production, daily life, and entertainment. Accurate and efficient forecasting of mobile data (e.g., cell traffic, user behavior, channel quality) helps operators monitor network state changes, orchestrate wireless resources, and schedule infrastructure and users, thereby improving supply efficiency and service quality. However, current forecasting paradigms rely on customized designs with tailored models for exclusive data types. Such approaches increase complexity and deployment costs under large-scale, heterogeneous networks involving base stations, users, and channels. In this paper, we design a foundation model for mobile data forecasting, MobiGPT, with a unified structure capable of forecasting three data types: base station traffic, user app usage, and channel quality. We propose a soft-prompt learning method to help the model understand features of different data types, and introduce a temporal masking mechanism to guide the model through three forecasting tasks: short-term prediction, long-term prediction, and distribution generation, supporting diverse optimization scenarios. Evaluations on real-world datasets with over 100,000 samples show that MobiGPT achieves accurate multi-type forecasting. Compared to existing models, it improves forecasting accuracy by 27.37%, 20.08%, and 7.27%, reflecting strong generalization. Moreover, MobiGPT exhibits superior zero/few-shot performance in unseen scenarios, with over 21.51% improvement, validating its strong transferability as a foundation model.</li>
<li><strong>摘要：</strong>随着移动通信技术的快速发展，未来的移动网络将为通勤，生产，日常生活和娱乐提供丰富的服务和资源。准确有效的移动数据预测（例如，单元流量，用户行为，渠道质量）可帮助操作员监视网络状态变化，协调无线资源，并安排基础架构和用户，从而提高供应效率和服务质量。但是，当前的预测范例依赖于具有针对独家数据类型的定制模型的定制设计。这种方法在涉及基站，用户和渠道的大规模，异质网络下增加了复杂性和部署成本。在本文中，我们设计了一个用于移动数据预测的基础模型，即Mobigpt，其统一结构能够预测三种数据类型：基站流量，用户应用程序的使用和频道质量。我们提出了一种软提出的学习方法，以帮助模型了解不同数据类型的特征，并引入时间掩盖机制，以通过三个预测任务来指导模型：短期预测，长期预测和分配产生，支持各种优化方案。对现实世界中数据集的评估超过100,000个样本表明，Mobigpt实现了准确的多类型预测。与现有模型相比，它的预测准确性提高了27.37％，20.08％和7.27％，反映了强烈的概括。此外，Mobigpt在看不见的情况下表现出较高的零/几分性能，提高了21.51％，从而证实了其作为基础模型的强大可传递性。</li>
</ul>

<h3>Title: PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Hengbo Xiao, Jingyuan Fan, Xin Tong, Jingzhao Zhang, Chao Lu, Guannan He</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CE, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18169">https://arxiv.org/abs/2509.18169</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18169">https://arxiv.org/pdf/2509.18169</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18169]] PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning(https://arxiv.org/abs/2509.18169)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Complex systems typically rely on high-precision numerical computation to support decisions, but current large language models (LLMs) cannot yet incorporate such computations as an intrinsic and interpretable capability with existing architectures. Mainstream multi-agent approaches can leverage external experts, but inevitably introduce communication overhead and suffer from inefficient multimodal emergent capability and limited scalability. To this end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and inference architecture for integrating computation and reasoning. Instead of the workflow paradigm of tool invocation, PiMoE endogenously integrates computational capabilities into neural networks after separately training experts, a text-to-computation module, and a router. At inference, the router directs computation and reasoning at the token level, thereby enabling iterative alternation within a single chain of thought. We evaluate PiMoE on two reasoning-computation tasks against LLM finetuning and the multi-agent system approaches. Results show that the PiMoE architecture achieves not only higher accuracy than directly finetuning LLMs but also significant improvements in response latency, token usage, and GPU energy consumption compared with mainstream multi-agent approaches. PiMoE offers an efficient, interpretable, and scalable paradigm for next-generation scientific or industrial intelligent systems.</li>
<li><strong>摘要：</strong>复杂的系统通常依靠高精度数值计算来支持决策，但是当前的大型语言模型（LLMS）仍无法将这些计算与现有体系结构相结合。主流多机构方法可以利用外部专家，但不可避免地引入沟通开销，并遭受效率低下的多模式紧急功能和有限的可扩展性。为此，我们提出了Pimoe（专家的物理分离的混合物），这是一种培训和推理结构，用于整合计算和推理。 Pimoe不是工具调用的工作流范式，而是在分别培训专家，文本到计算模块和路由器之后将计算能力整合到神经网络中。在推断时，路由器将计算和推理指向令牌级别，从而在单个思想链中实现了迭代的交替。我们评估PIMOE针对LLM FINETUNT和多代理系统方法的两项推理计算任务。结果表明，与主流多代理方法相比，PIMOE架构不仅比直接填充LLM的LLM具有更高的准确性，而且还具有显着改善的响应潜伏期，令牌使用和GPU能量消耗。 Pimoe为下一代科学或工业智能系统提供了有效，可解释和可扩展的范式。</li>
</ul>

<h3>Title: SBVR: Summation of BitVector Representation for Efficient LLM Quantization</h3>
<ul>
<li><strong>Authors: </strong>Wonjun Bang, Jongseok Park, Hongseung Yu, Kyungmin Bin, Kyunghan Lee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18172">https://arxiv.org/abs/2509.18172</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18172">https://arxiv.org/pdf/2509.18172</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18172]] SBVR: Summation of BitVector Representation for Efficient LLM Quantization(https://arxiv.org/abs/2509.18172)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>With the advent of large language models (LLMs), numerous Post-Training Quantization (PTQ) strategies have been proposed to alleviate deployment barriers created by their enormous parameter counts. Quantization achieves compression by limiting the number of representable points in the data. Therefore, the key to achieving efficient quantization is selecting the optimal combination of representation points, or codes, for the given data. Existing PTQ solutions adopt two major approaches to this problem: Round-To-Nearest (RTN)-based methods and codebook-based methods. RTN-based methods map LLM weights onto uniformly distributed integer grids, failing to account for the Gaussian-like weight distribution of LLM weights. Codebook-based methods mitigate this issue by constructing distribution-aware codebooks; however, they suffer from random and strided memory access patterns, resulting in degraded inference speed that is exacerbated by the limited size of GPU L1 cache. To overcome these limitations, we propose a novel LLM quantization method, SBVR (Summation of BitVector Representation), that enables Gaussian-like code representation in a hardware-friendly manner for fast inference. SBVR maps weight values to non-uniform representation points whose distribution follows the actual distribution of LLM weights, enabling more accurate compression. Additionally, we design a custom CUDA kernel that allows matrix-vector multiplication directly in the SBVR format without decompression, thereby enabling high-performance execution of SBVR-compressed models. Our evaluations of SBVR on various models demonstrate state-of-the-art perplexity and accuracy benchmark performance while delivering a 2.21x- 3.04x end-to-end token-generation speedup over naive FP16 models in the 4-bit quantization regime.</li>
<li><strong>摘要：</strong>随着大语言模型（LLM）的出现，已经提出了许多培训后量化（PTQ）策略来减轻其巨大参数计数所产生的部署障碍。量化通过限制数据中代表点的数量来实现压缩。因此，实现有效量化的关键是为给定数据选择表示点或代码的最佳组合。现有的PTQ解决方案采用了这一问题的两种主要方法：基于圆头化的方法（RTN）方法和基于代码的方法。基于RTN的方法将LLM的权重映射到均匀分布的整数网格上，无法说明LLM权重的高斯样重量分布。基于密码的方法通过构建分发意见的代码手册来减轻此问题；但是，它们患有随机和障碍的内存访问模式，导致推理速度降解，这会因GPU L1缓存的有限尺寸而加剧。为了克服这些局限性，我们提出了一种新颖的LLM量化方法SBVR（BitVector表示的总和），该方法可以以硬件友好的方式以快速推断为高斯式的代码表示。 SBVR将权重值映射到非均匀表示点，其分布遵循LLM权重的实际分布，从而更准确地压缩。此外，我们设计了一个自定义的CUDA内核，该内核直接以SBVR格式直接以SBVR格式进行减压，从而实现了SBVR压缩模型的高性能执行。我们对SBVR在各种模型上的评估表明，在4位量化方案中，在幼稚的FP16模型上提供了2.21x-3.04x的端到端代币加速度，同时提供了最新的困惑和准确性的基准性能。</li>
</ul>

<h3>Title: TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route</h3>
<ul>
<li><strong>Authors: </strong>Hongyi Luo, Qing Cheng, Daniel Matos, Hari Krishna Gadi, Yanfeng Zhang, Lu Liu, Yongliang Wang, Niclas Zeller, Daniel Cremers, Liqiu Meng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18173">https://arxiv.org/abs/2509.18173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18173">https://arxiv.org/pdf/2509.18173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18173]] TurnBack: A Geospatial Route Cognition Benchmark for Large Language Models through Reverse Route(https://arxiv.org/abs/2509.18173)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Humans can interpret geospatial information through natural language, while the geospatial cognition capabilities of Large Language Models (LLMs) remain underexplored. Prior research in this domain has been constrained by non-quantifiable metrics, limited evaluation datasets and unclear research hierarchies. Therefore, we propose a large-scale benchmark and conduct a comprehensive evaluation of the geospatial route cognition of LLMs. We create a large-scale evaluation dataset comprised of 36000 routes from 12 metropolises worldwide. Then, we introduce PathBuilder, a novel tool for converting natural language instructions into navigation routes, and vice versa, bridging the gap between geospatial information and natural language. Finally, we propose a new evaluation framework and metrics to rigorously assess 11 state-of-the-art (SOTA) LLMs on the task of route reversal. The benchmark reveals that LLMs exhibit limitation to reverse routes: most reverse routes neither return to the starting point nor are similar to the optimal route. Additionally, LLMs face challenges such as low robustness in route generation and high confidence for their incorrect answers. Code\ \&\ Data available here: \href{this https URL}{TurnBack.}</li>
<li><strong>摘要：</strong>人类可以通过自然语言来解释地理空间信息，而大语言模型（LLMS）的地理空间认知能力仍然没有被忽视。该领域的先前研究受到不可量化的指标，有限的评估数据集和不清楚的研究层次结构的限制。因此，我们提出了一个大规模的基准，并对LLM的地理空间途径认知进行了全面评估。我们创建了一个大规模评估数据集，该数据集由来自全球12个大都市的36000条路线组成。然后，我们介绍了Pathbuilder，这是一种新颖的工具，用于将自然语言指令转换为导航路线，反之亦然，从而弥合了地理空间信息和自然语言之间的差距。最后，我们提出了一个新的评估框架和指标，以严格评估11个最先进的LLMS（SOTA）LLM，以实现路线逆转的任务。基准测试表明，LLMS对反向路线表现出限制：大多数反向路由既不返回到起点，也不类似于最佳路线。此外，LLMS面临挑战，例如在路线生成中的鲁棒性低以及对他们不正确的答案的信心。代码\ \ \＆\数据可在此处提供：\ href {此https url} {turnback。}</li>
</ul>

<h3>Title: The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes</h3>
<ul>
<li><strong>Authors: </strong>Sai Varun Kodathala, Rakesh Vunnam</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18179">https://arxiv.org/abs/2509.18179</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18179">https://arxiv.org/pdf/2509.18179</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18179]] The Describe-Then-Generate Bottleneck: How VLM Descriptions Alter Image Generation Outcomes(https://arxiv.org/abs/2509.18179)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>With the increasing integration of multimodal AI systems in creative workflows, understanding information loss in vision-language-vision pipelines has become important for evaluating system limitations. However, the degradation that occurs when visual content passes through textual intermediation remains poorly quantified. In this work, we provide empirical analysis of the describe-then-generate bottleneck, where natural language serves as an intermediate representation for visual information. We generated 150 image pairs through the describe-then-generate pipeline and applied existing metrics (LPIPS, SSIM, and color distance) to measure information preservation across perceptual, structural, and chromatic dimensions. Our evaluation reveals that 99.3% of samples exhibit substantial perceptual degradation and 91.5% demonstrate significant structural information loss, providing empirical evidence that the describe-then-generate bottleneck represents a measurable and consistent limitation in contemporary multimodal systems.</li>
<li><strong>摘要：</strong>随着多模式AI系统在创意工作流程中的越来越多的集成，了解视觉语言视觉管道中的信息丢失对于评估系统局限性变得很重要。然而，当视觉内容通过文本中介化的降解仍然很差。在这项工作中，我们提供了描述 - 生成瓶颈的经验分析，其中自然语言是视觉信息的中间表示。我们通过描述 - 生成的管道生成了150个图像对，并应用了现有的指标（LPIPS，SSIM和颜色距离），以测量跨感知，结构和色度尺寸的信息保存。我们的评估表明，99.3％的样品表现出大量的感知降解，而91.5％的样本表现出明显的结构信息损失，提供了经验证据，表明描述 - 生成的瓶颈代表了当代多模态系统中可测量且一致的限制。</li>
</ul>

<h3>Title: HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing</h3>
<ul>
<li><strong>Authors: </strong>Junseong Shin, Seungwoo Chung, Yunjeong Yang, Tae Hyun Kim</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18190">https://arxiv.org/abs/2509.18190</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18190">https://arxiv.org/pdf/2509.18190</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18190]] HazeFlow: Revisit Haze Physical Model as ODE and Non-Homogeneous Haze Generation for Real-World Dehazing(https://arxiv.org/abs/2509.18190)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Dehazing involves removing haze or fog from images to restore clarity and improve visibility by estimating atmospheric scattering effects. While deep learning methods show promise, the lack of paired real-world training data and the resulting domain gap hinder generalization to real-world scenarios. In this context, physics-grounded learning becomes crucial; however, traditional methods based on the Atmospheric Scattering Model (ASM) often fall short in handling real-world complexities and diverse haze patterns. To solve this problem, we propose HazeFlow, a novel ODE-based framework that reformulates ASM as an ordinary differential equation (ODE). Inspired by Rectified Flow (RF), HazeFlow learns an optimal ODE trajectory to map hazy images to clean ones, enhancing real-world dehazing performance with only a single inference step. Additionally, we introduce a non-homogeneous haze generation method using Markov Chain Brownian Motion (MCBM) to address the scarcity of paired real-world data. By simulating realistic haze patterns through MCBM, we enhance the adaptability of HazeFlow to diverse real-world scenarios. Through extensive experiments, we demonstrate that HazeFlow achieves state-of-the-art performance across various real-world dehazing benchmark datasets.</li>
<li><strong>摘要：</strong>飞机涉及从图像中去除雾霾或雾，以恢复清晰度并通过估计大气散射效应来提高可见度。尽管深度学习方法表现出希望，但缺乏配对的现实培训数据以及由此产生的域间隙阻碍对现实世界情景的概括。在这种情况下，物理学的学习变得至关重要。但是，基于大气散射模型（ASM）的传统方法通常在处理现实世界中的复杂性和多样化的雾霾模式方面通常不足。为了解决这个问题，我们提出了Hazeflow，这是一种基于ODE的新型框架，将ASM重新定义为普通的微分方程（ODE）。受Hazeflow的启发，Hazeflow学习了一个最佳的ODE轨迹，以将朦胧的图像映射到清洁图像，从而通过单个推理步骤来增强现实世界中的脱掩护性能。此外，我们使用马尔可夫链布朗运动（MCBM）引入了一种非均匀的雾兹生成方法，以解决配对现实世界数据的稀缺性。通过通过MCBM模拟逼真的雾度模式，我们增强了雾化对各种现实世界情景的适应性。通过广泛的实验，我们证明了Hazeflow在各种现实世界中的基准数据集中实现最先进的性能。</li>
</ul>

<h3>Title: FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yuxuan Cai, Xiaozhuan Liang, Xinghua Wang, Jin Ma, Haijin Liang, Jinwen Luo, Xinyu Zuo, Lisheng Duan, Yuyang Yin, Xi Chen</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18362">https://arxiv.org/abs/2509.18362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18362">https://arxiv.org/pdf/2509.18362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18362]] FastMTP: Accelerating LLM Inference with Enhanced Multi-Token Prediction(https://arxiv.org/abs/2509.18362)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>As large language models (LLMs) become increasingly powerful, the sequential nature of autoregressive generation creates a fundamental throughput bottleneck that limits the practical deployment. While Multi-Token Prediction (MTP) has demonstrated remarkable benefits for model training efficiency and performance, its inherent potential for inference acceleration remains largely unexplored. This paper introduces FastMTP, a simple yet effective method that improves multi-step draft quality by aligning MTP training with its inference pattern, significantly enhancing speculative decoding performance. Our approach fine-tunes a single MTP head with position-shared weights on self-distilled data, enabling it to capture dependencies among consecutive future tokens and maintain high acceptance rates across multiple recursive draft steps. By integrating language-aware dynamic vocabulary compression into the MTP head, we further reduce computational overhead in the drafting process. Experimental results across seven diverse benchmarks demonstrate that FastMTP achieves an average of 2.03x speedup compared to standard next token prediction with lossless output quality, outperforming vanilla MTP by 82%. FastMTP requires only lightweight training and seamlessly integrates with existing inference frameworks, offering a practical and rapidly deployable solution for accelerating LLM inference.</li>
<li><strong>摘要：</strong>随着大型语言模型（LLMS）变得越来越强大，自回归产生的顺序性质创造了限制实际部署的基本吞吐量瓶颈。虽然多语预测（MTP）在模型训练效率和性能方面表现出了显着的好处，但其固有的推理加速潜力仍然在很大程度上没有探索。本文介绍了FastMTP，这是一种简单而有效的方法，它通过将MTP培训与推理模式保持一致，从而提高了多步骤草稿质量，从而大大提高了投机性解码性能。我们的方法微调单个MTP头部具有自缩放数据的位置共享权重，从而使其能够捕获连续的未来代币之间的依赖性，并在多个递归草稿步骤中保持较高的接受率。通过将语言感知的动态词汇压缩整合到MTP头部，我们进一步减少了起草过程中的计算开销。七个不同基准测试的实验结果表明，与隔壁的标记预测相比，FASTMTP平均达到2.03倍的速度，无损失的产出质量，超过82％的Vanilla MTP。 FastMTP仅需要轻巧的培训，并与现有推理框架无缝集成，提供实用且可快速可部署的解决方案，以加速LLM推理。</li>
</ul>

<h3>Title: Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors</h3>
<ul>
<li><strong>Authors: </strong>Chang Liu, Ladda Thiamwong, Yanjie Fu, Rui Xie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18433">https://arxiv.org/abs/2509.18433</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18433">https://arxiv.org/pdf/2509.18433</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18433]] Diffusion Policies with Offline and Inverse Reinforcement Learning for Promoting Physical Activity in Older Adults Using Wearable Sensors(https://arxiv.org/abs/2509.18433)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Utilizing offline reinforcement learning (RL) with real-world clinical data is getting increasing attention in AI for healthcare. However, implementation poses significant challenges. Defining direct rewards is difficult, and inverse RL (IRL) struggles to infer accurate reward functions from expert behavior in complex environments. Offline RL also encounters challenges in aligning learned policies with observed human behavior in healthcare applications. To address challenges in applying offline RL to physical activity promotion for older adults at high risk of falls, based on wearable sensor activity monitoring, we introduce Kolmogorov-Arnold Networks and Diffusion Policies for Offline Inverse Reinforcement Learning (KANDI). By leveraging the flexible function approximation in Kolmogorov-Arnold Networks, we estimate reward functions by learning free-living environment behavior from low-fall-risk older adults (experts), while diffusion-based policies within an Actor-Critic framework provide a generative approach for action refinement and efficiency in offline RL. We evaluate KANDI using wearable activity monitoring data in a two-arm clinical trial from our Physio-feedback Exercise Program (PEER) study, emphasizing its practical application in a fall-risk intervention program to promote physical activity among older adults. Additionally, KANDI outperforms state-of-the-art methods on the D4RL benchmark. These results underscore KANDI's potential to address key challenges in offline RL for healthcare applications, offering an effective solution for activity promotion intervention strategies in healthcare.</li>
<li><strong>摘要：</strong>使用现实世界中的临床数据利用离线增强学习（RL）正在越来越多的人AI关注医疗保健。但是，实施构成了重大挑战。定义直接奖励很困难，并且逆RL（IRL）努力从复杂环境中的专家行为中推断出准确的奖励功能。离线RL还遇到了使学到的政策与在医疗保健应用中观察到的人类行为保持一致的挑战。为了应对可穿戴传感器活动监控，将离线RL应用于跌落高风险的老年人的体育活动促进挑战，我们引入了Kolmogorov-Arnold网络和离线逆增强学习（Kandi）的扩散政策（Kandi）。通过利用Kolmogorov-Arnold网络中的灵活函数近似，我们通过从低迷风险的老年人（专家）学习自由生活环境行为来估算奖励功能，而在Actor-Critic框架内基于扩散的策略为行动和效率提供了在离线RL中的动作和效率的生成方法。我们在我们的Physio Feedback锻炼计划（PEER）研究的两臂临床试验中使用可穿戴活动监测数据评估了Kandi，并强调了其在降落风险干预计划中的实际应用，以促进老年人的体育活动。此外，Kandi在D4RL基准测试上优于最先进的方法。这些结果强调了坎迪（Kandi）在医疗保健应用中解决关键挑战的潜力，为医疗保健中的活动促进干预策略提供了有效的解决方案。</li>
</ul>

<h3>Title: Discrete-time diffusion-like models for speech synthesis</h3>
<ul>
<li><strong>Authors: </strong>Xiaozhou Tan, Minghui Zhao, Mattias Cross, Anton Ragni</a></li>
<li><strong>Subjects: </strong>cs.LG, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18470">https://arxiv.org/abs/2509.18470</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18470">https://arxiv.org/pdf/2509.18470</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18470]] Discrete-time diffusion-like models for speech synthesis(https://arxiv.org/abs/2509.18470)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion models have attracted a lot of attention in recent years. These models view speech generation as a continuous-time process. For efficient training, this process is typically restricted to additive Gaussian noising, which is limiting. For inference, the time is typically discretized, leading to the mismatch between continuous training and discrete sampling conditions. Recently proposed discrete-time processes, on the other hand, usually do not have these limitations, may require substantially fewer inference steps, and are fully consistent between training/inference conditions. This paper explores some diffusion-like discrete-time processes and proposes some new variants. These include processes applying additive Gaussian noise, multiplicative Gaussian noise, blurring noise and a mixture of blurring and Gaussian noises. The experimental results suggest that discrete-time processes offer comparable subjective and objective speech quality to their widely popular continuous counterpart, with more efficient and consistent training and inference schemas.</li>
<li><strong>摘要：</strong>近年来，扩散模型引起了很多关注。这些模型将语音生成视为连续时间过程。为了进行有效的培训，此过程通常仅限于加性高斯noisision，这是有限的。对于推断，时间通常是离散的，导致连续训练和离散抽样条件之间的不匹配。另一方面，最近提出的离散时间过程通常没有这些局限性，可能需要更少的推理步骤，并且在训练/推理条件之间完全一致。本文探讨了一些类似扩散的离散时间过程，并提出了一些新变体。这些包括应用加斯噪声，乘法高斯噪声，模糊噪声以及模糊和高斯噪音的混合物的过程。实验结果表明，离散的时间流程提供了与其广泛流行的连续对应物的可比主观和客观语音质量，并具有更有效，一致的培训和推理模式。</li>
</ul>

<h3>Title: SimpleFold: Folding Proteins is Simpler than You Think</h3>
<ul>
<li><strong>Authors: </strong>Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Josh Susskind, Miguel Angel Bautista</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18480">https://arxiv.org/abs/2509.18480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18480">https://arxiv.org/pdf/2509.18480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18480]] SimpleFold: Folding Proteins is Simpler than You Think(https://arxiv.org/abs/2509.18480)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.</li>
<li><strong>摘要：</strong>蛋白质折叠模型通常通过将整合域知识与建筑块和训练管道的结合结合在一起，从而实现了开创性的结果。尽管如此，鉴于在不同但相关的问题上生成模型的成功，质疑这些建筑设计是否是构建性能模型的必要条件是很自然的。在本文中，我们介绍了SimpleFold，这是仅使用通用变压器块的第一个基于流量匹配的蛋白质折叠模型。蛋白质折叠模型通常采用涉及三角形更新，明确的对表示或为此特定领域策划的多个培训目标的计算昂贵模块。取而代之的是，SimpleFold使用具有自适应层的标准变压器块，并通过具有附加结构术语的生成流量匹配目标进行训练。我们将SimpleFold缩放到3B参数，并在大约9m蒸馏蛋白结构以及实验性PDB数据上对其进行训练。在标准折叠基准测试中，与最先进的基准相比，SimpleFold-3B可以实现竞争性能，此外，SimpleFold在集合预测中表现出强大的性能，对于通过确定性重建目标训练的模型通常很难。由于其通用体系结构，SimpleFold显示了部署和推断消费者级硬件的效率。 SimpleFold挑战了对蛋白质折叠中复杂域特异性体系结构设计的依赖，从而为未来的进步打开了替代设计空间。</li>
</ul>

<h3>Title: Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment</h3>
<ul>
<li><strong>Authors: </strong>Wenjie Liu, Hongmin Liu, Lixin Zhang, Bin Fan</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18502">https://arxiv.org/abs/2509.18502</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18502">https://arxiv.org/pdf/2509.18502</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18502]] Source-Free Domain Adaptive Semantic Segmentation of Remote Sensing Images with Diffusion-Guided Label Enrichment(https://arxiv.org/abs/2509.18502)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution</a></li>
<li><strong>Abstract: </strong>Research on unsupervised domain adaptation (UDA) for semantic segmentation of remote sensing images has been extensively conducted. However, research on how to achieve domain adaptation in practical scenarios where source domain data is inaccessible namely, source-free domain adaptation (SFDA) remains limited. Self-training has been widely used in SFDA, which requires obtaining as many high-quality pseudo-labels as possible to train models on target domain data. Most existing methods optimize the entire pseudo-label set to obtain more supervisory information. However, as pseudo-label sets often contain substantial noise, simultaneously optimizing all labels is challenging. This limitation undermines the effectiveness of optimization approaches and thus restricts the performance of self-training. To address this, we propose a novel pseudo-label optimization framework called Diffusion-Guided Label Enrichment (DGLE), which starts from a few easily obtained high-quality pseudo-labels and propagates them to a complete set of pseudo-labels while ensuring the quality of newly generated labels. Firstly, a pseudo-label fusion method based on confidence filtering and super-resolution enhancement is proposed, which utilizes cross-validation of details and contextual information to obtain a small number of high-quality pseudo-labels as initial seeds. Then, we leverage the diffusion model to propagate incomplete seed pseudo-labels with irregular distributions due to its strong denoising capability for randomly distributed noise and powerful modeling capacity for complex distributions, thereby generating complete and high-quality pseudo-labels. This method effectively avoids the difficulty of directly optimizing the complete set of pseudo-labels, significantly improves the quality of pseudo-labels, and thus enhances the model's performance in the target domain.</li>
<li><strong>摘要：</strong>对遥感图像的语义分割的无监督域适应性（UDA）的研究已得到广泛进行。但是，在源域数据无法访问的实际情况下，如何实现域适应性的研究仍然有限。自我训练已在SFDA中广泛使用，这需要获得尽可能多的高质量伪标签，以在目标域数据上训练模型。大多数现有方法都优化了整个伪标签设置以获取更多监督信息。但是，由于伪标签集通常包含大量噪声，因此同时优化所有标签都是具有挑战性的。这种限制破坏了优化方法的有效性，从而限制了自我训练的表现。为了解决这个问题，我们提出了一个新型的伪标签优化框架，称为扩散引导的标签富集（DGLE），该框架从几个轻松获得的高质量伪标签开始，并将它们传播到一套完整的伪标签，同时确保新生成的标签的质量。首先，提出了一种基于置信度过滤和超分辨率增强的伪标签融合方法，该方法利用细节和上下文信息的交叉验证来获得少量的高质量伪标记作为初始种子。然后，我们利用扩散模型来传播具有不规则分布的不完整种子伪标签，因为它具有强大的降解能力，可随机分布式噪声以及用于复杂分布的强大建模能力，从而产生完整和高质量的伪标记。该方法有效地避免了直接优化伪标签集的困难，从而显着提高了伪标签的质量，从而提高了模型在目标域中的性能。</li>
</ul>

<h3>Title: Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning</h3>
<ul>
<li><strong>Authors: </strong>Jiaxin Dai, Xiang Xiang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18504">https://arxiv.org/abs/2509.18504</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18504">https://arxiv.org/pdf/2509.18504</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18504]] Hyperbolic Coarse-to-Fine Few-Shot Class-Incremental Learning(https://arxiv.org/abs/2509.18504)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>In the field of machine learning, hyperbolic space demonstrates superior representation capabilities for hierarchical data compared to conventional Euclidean space. This work focuses on the Coarse-To-Fine Few-Shot Class-Incremental Learning (C2FSCIL) task. Our study follows the Knowe approach, which contrastively learns coarse class labels and subsequently normalizes and freezes the classifier weights of learned fine classes in the embedding space. To better interpret the "coarse-to-fine" paradigm, we propose embedding the feature extractor into hyperbolic space. Specifically, we employ the Poincaré ball model of hyperbolic space, enabling the feature extractor to transform input images into feature vectors within the Poincaré ball instead of Euclidean space. We further introduce hyperbolic contrastive loss and hyperbolic fully-connected layers to facilitate model optimization and classification in hyperbolic space. Additionally, to enhance performance under few-shot conditions, we implement maximum entropy distribution in hyperbolic space to estimate the probability distribution of fine-class feature vectors. This allows generation of augmented features from the distribution to mitigate overfitting during training with limited samples. Experiments on C2FSCIL benchmarks show that our method effectively improves both coarse and fine class accuracies.</li>
<li><strong>摘要：</strong>在机器学习领域，双曲线空间与传统的欧几里得空间相比，表现出层次数据的较高表示能力。这项工作重点介绍了粗到1的几次课程学习（C2FSCIL）任务。我们的研究遵循了知识方法，该方法对比学习了粗糙的类标签，随后将其归一化并冻结了在嵌入空间中学到的优良类的分类器权重。为了更好地解释“粗到五”范式，我们建议将特征提取器嵌入双曲线空间中。具体而言，我们采用双曲线空间的庞加莱球模型，使特征提取器能够将输入图像转换为庞加莱球内的特征向量而不是欧几里得空间。我们进一步引入双曲线对比损失和双曲线完全连接的层，以促进双曲线空间中的模型优化和分类。此外，为了在几乎没有射击条件下提高性能，我们在双曲线空间中实施了最大的熵分布，以估计高级特征向量的概率分布。这允许生成增强功能，从分布到有限的样本训练期间减轻过度拟合。在C2FSCIL基准上进行的实验表明，我们的方法有效地改善了粗级和精细的精度。</li>
</ul>

<h3>Title: APRIL: Active Partial Rollouts in Reinforcement Learning to tame long-tail generation</h3>
<ul>
<li><strong>Authors: </strong>Yuzhen Zhou, Jiajun Li, Yusheng Su, Gowtham Ramesh, Zilin Zhu, Xiang Long, Chenyang Zhao, Jin Pan, Xiaodong Yu, Ze Wang, Kangrui Du, Jialian Wu, Ximeng Sun, Jiang Liu, Qiaolin Yu, Hao Chen, Zicheng Liu, Emad Barsoum</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18521">https://arxiv.org/abs/2509.18521</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18521">https://arxiv.org/pdf/2509.18521</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18521]] APRIL: Active Partial Rollouts in Reinforcement Learning to tame long-tail generation(https://arxiv.org/abs/2509.18521)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) has become a cornerstone in advancing large-scale pre-trained language models (LLMs). Successive generations, including GPT-o series, DeepSeek-R1, Kimi-K1.5, Grok 4, and GLM-4.5, have relied on large-scale RL training to enhance reasoning and coding capabilities. To meet the community's growing RL needs, numerous RL frameworks have been proposed. Most of these frameworks primarily rely on inference engines for rollout generation and training engines for policy updates. However, RL training remains computationally expensive, with rollout generation accounting for more than 90% of total runtime. In addition, its efficiency is often constrained by the long-tail distribution of rollout response lengths, where a few lengthy responses stall entire batches, leaving GPUs idle and underutilized. As model and rollout sizes continue to grow, this bottleneck increasingly limits scalability. To address this challenge, we propose Active Partial Rollouts in Reinforcement Learning (APRIL), which mitigates long-tail inefficiency. In the rollout phase, APRIL over-provisions rollout requests, terminates once the target number of responses is reached, and recycles incomplete responses for continuation in future steps. This strategy ensures that no rollouts are discarded while substantially reducing GPU idle time. Experiments show that APRIL improves rollout throughput by at most 44% across commonly used RL algorithms (GRPO, DAPO, GSPO), accelerates convergence, and achieves at most 8% higher final accuracy across tasks. Moreover, APRIL is both framework and hardware agnostic, already integrated into the slime RL framework, and deployable on NVIDIA and AMD GPUs alike. Taken together, this work unifies system-level and algorithmic considerations in proposing APRIL, with the aim of advancing RL training efficiency and inspiring further optimizations in RL systems.</li>
<li><strong>摘要：</strong>增强学习（RL）已成为推进大规模预训练的语言模型（LLMS）的基石。包括GPT-O系列，DeepSeek-R1，Kimi-K1.5，Grok 4和GLM-4.5的后代已依靠大规模的RL培训来增强推理和编码功能。为了满足社区日益增长的RL需求，已经提出了许多RL框架。这些框架中的大多数主要依靠推理引擎进行推出生成和培训引擎以进行政策更新。但是，RL培训在计算上仍然保持昂贵，推出生成占总运行时的90％以上。此外，它的效率通常受到推出响应长度的长尾分布的限制，其中一些冗长的响应使整个批次陷入僵局，使GPU闲置且未充分利用。随着模型和推出尺寸的不断增长，这种瓶颈越来越限制可扩展性。为了应对这一挑战，我们建议在增强学习（4月）中积极的部分推广，从而减轻长尾效率低下。在推出阶段，四月提供的推出请求过多，一旦达到目标数量的响应次数，就会终止响应的数量，并且在以后的步骤中回收了不完整的响应。该策略可确保在大大减少GPU闲置时间的同时，不会丢弃推广。实验表明，四月在常用的RL算法（GRPO，DAPO，GSPO）中最多提高了44％的推出吞吐量，加速了收敛性，并且在整个任务中最大的最终精度最多提高了8％。此外，April既是框架又是硬件不可知论，已经集成到Slime RL框架中，并且可以在NVIDIA和AMD GPUS上部署。综上所述，这项工作在提议4月份中统一了系统级和算法的考虑，目的是提高RL培训效率并激发RL系统中的进一步优化。</li>
</ul>

<h3>Title: SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models</h3>
<ul>
<li><strong>Authors: </strong>Yujia Liu, Dingquan Li, Tiejun Huang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18546">https://arxiv.org/abs/2509.18546</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18546">https://arxiv.org/pdf/2509.18546</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18546]] SEGA: A Transferable Signed Ensemble Gaussian Black-Box Attack against No-Reference Image Quality Assessment Models(https://arxiv.org/abs/2509.18546)</code><input type="text"></li>
<li><strong>Keywords: </strong>quality assessment</a></li>
<li><strong>Abstract: </strong>No-Reference Image Quality Assessment (NR-IQA) models play an important role in various real-world applications. Recently, adversarial attacks against NR-IQA models have attracted increasing attention, as they provide valuable insights for revealing model vulnerabilities and guiding robust system design. Some effective attacks have been proposed against NR-IQA models in white-box settings, where the attacker has full access to the target model. However, these attacks often suffer from poor transferability to unknown target models in more realistic black-box scenarios, where the target model is inaccessible. This work makes the first attempt to address the challenge of low transferability in attacking NR-IQA models by proposing a transferable Signed Ensemble Gaussian black-box Attack (SEGA). The main idea is to approximate the gradient of the target model by applying Gaussian smoothing to source models and ensembling their smoothed gradients. To ensure the imperceptibility of adversarial perturbations, SEGA further removes inappropriate perturbations using a specially designed perturbation filter mask. Experimental results on the CLIVE dataset demonstrate the superior transferability of SEGA, validating its effectiveness in enabling successful transfer-based black-box attacks against NR-IQA models.</li>
<li><strong>摘要：</strong>无参考图像质量评估（NR-IQA）模型在各种现实世界应用中起着重要作用。最近，针对NR-IQA模型的对抗性攻击引起了人们越来越多的关注，因为它们为揭示模型脆弱性和指导强大的系统设计提供了宝贵的见解。在白框设置中，已经提出了一些有效的攻击，其中攻击者可以完全访问目标模型。但是，这些攻击在更现实的黑盒情景中通常会遭受向未知目标模型的可传递性，而目标模型无法访问。这项工作首次尝试通过提出可转让的签名合奏Gaussian Black-Box攻击（SEGA）来解决攻击NR-IQA模型中低传递性的挑战。主要思想是通过将高斯平滑度应用于源模型并结合其平滑梯度来近似目标模型的梯度。为了确保对抗性扰动的易无用性，SEGA使用专门设计的扰动滤膜进一步消除了不适当的扰动。 CLIVE数据集的实验结果证明了SEGA的出色传递性，验证了其在成功基于转移的黑盒攻击NR-IQA模型方面的有效性。</li>
</ul>

<h3>Title: Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia</h3>
<ul>
<li><strong>Authors: </strong>Niharika Tewari, Nguyen Linh Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Tabinda Sarwar, Veeky Baths, Feng Xia</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18568">https://arxiv.org/abs/2509.18568</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18568">https://arxiv.org/pdf/2509.18568</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18568]] Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia(https://arxiv.org/abs/2509.18568)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Dementia is a progressive neurodegenerative disorder with multiple etiologies, including Alzheimer's disease, Parkinson's disease, frontotemporal dementia, and vascular dementia. Its clinical and biological heterogeneity makes diagnosis and subtype differentiation highly challenging. Graph Neural Networks (GNNs) have recently shown strong potential in modeling brain connectivity, but their limited robustness, data scarcity, and lack of interpretability constrain clinical adoption. Explainable Graph Neural Networks (XGNNs) have emerged to address these barriers by combining graph-based learning with interpretability, enabling the identification of disease-relevant biomarkers, analysis of brain network disruptions, and provision of transparent insights for clinicians. This paper presents the first comprehensive review dedicated to XGNNs in dementia research. We examine their applications across Alzheimer's disease, Parkinson's disease, mild cognitive impairment, and multi-disease diagnosis. A taxonomy of explainability methods tailored for dementia-related tasks is introduced, alongside comparisons of existing models in clinical scenarios. We also highlight challenges such as limited generalizability, underexplored domains, and the integration of Large Language Models (LLMs) for early detection. By outlining both progress and open problems, this review aims to guide future work toward trustworthy, clinically meaningful, and scalable use of XGNNs in dementia research.</li>
<li><strong>摘要：</strong>痴呆症是一种进行性神经退行性疾病，具有多种病因，包括阿尔茨海默氏病，帕金森氏病，额颞痴呆和血管性痴呆。它的临床和生物异质性使诊断和亚型分化高度挑战。图神经网络（GNN）最近在建模大脑连接性方面表现出强大的潜力，但是它们的鲁棒性，数据稀缺和缺乏可解释性限制了临床采用。可解释的图形神经网络（XGNN）已经出现，通过将基于图的学​​习与可解释性相结合，能够鉴定与疾病相关的生物标志物，大脑网络破坏分析以及为临床医生提供透明见解，从而解决这些障碍。本文介绍了专门针对痴呆症研究中XGNN的首次全面评论。我们检查了它们在阿尔茨海默氏病，帕金森氏病，轻度认知障碍和多疾病诊断中的应用。引入了针对痴呆症相关任务的解释性方法的分类法，以及在临床方案中现有模型的比较。我们还重点介绍了诸如有限的概括性，未置换的域以及大语模型（LLMS）以供早期检测的挑战。通过概述进度和开放问题，这项综述旨在指导未来的工作，以实现可信赖，临床意义且可扩展的XGNN在痴呆症研究中使用。</li>
</ul>

<h3>Title: Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought</h3>
<ul>
<li><strong>Authors: </strong>Yuhan Wang, Cheng Liu, Zihan Zhao, Weichao Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18571">https://arxiv.org/abs/2509.18571</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18571">https://arxiv.org/pdf/2509.18571</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18571]] Live-E2T: Real-time Threat Monitoring in Video via Deduplicated Event Reasoning and Chain-of-Thought(https://arxiv.org/abs/2509.18571)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Real-time threat monitoring identifies threatening behaviors in video streams and provides reasoning and assessment of threat events through explanatory text. However, prevailing methodologies, whether based on supervised learning or generative models, struggle to concurrently satisfy the demanding requirements of real-time performance and decision explainability. To bridge this gap, we introduce Live-E2T, a novel framework that unifies these two objectives through three synergistic mechanisms. First, we deconstruct video frames into structured Human-Object-Interaction-Place semantic tuples. This approach creates a compact, semantically focused representation, circumventing the information degradation common in conventional feature compression. Second, an efficient online event deduplication and updating mechanism is proposed to filter spatio-temporal redundancies, ensuring the system's real time responsiveness. Finally, we fine-tune a Large Language Model using a Chain-of-Thought strategy, endow it with the capability for transparent and logical reasoning over event sequences to produce coherent threat assessment reports. Extensive experiments on benchmark datasets, including XD-Violence and UCF-Crime, demonstrate that Live-E2T significantly outperforms state-of-the-art methods in terms of threat detection accuracy, real-time efficiency, and the crucial dimension of explainability.</li>
<li><strong>摘要：</strong>实时威胁监控可以确定视频流中的威胁行为，并通过解释性文本提供了威胁事件的推理和评估。但是，无论是基于监督的学习还是生成模型，都在努力满足实时绩效和决策解释性的要求。为了弥合这一差距，我们介绍了Live-E2T，这是一个新颖的框架，该框架通过三种协同机制统一了这两个目标。首先，我们将视频帧解构为结构化的人类对象相互作用的语义元组。这种方法创建了一个紧凑的语义集中表示形式，从而规避传统特征压缩中常见的信息降解。其次，提出了有效的在线事件重复数据删除和更新机制，以过滤时空冗余，以确保系统的实时响应能力。最后，我们使用经过思考的策略微调了大型语言模型，并具有对事件序列进行透明和逻辑推理的能力，以产生连贯的威胁评估报告。在包括XD-Violence和UCF-Crime在内的基准数据集上进行的广泛实验表明，Live-E2T在威胁检测准确性，实时效率和解释性的至关重要方面都显着超过最先进的方法。</li>
</ul>

<h3>Title: DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation</h3>
<ul>
<li><strong>Authors: </strong>Mingchun Sun, Rongqiang Zhao, Jie Liu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18584">https://arxiv.org/abs/2509.18584</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18584">https://arxiv.org/pdf/2509.18584</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18584]] DS-Diffusion: Data Style-Guided Diffusion Model for Time-Series Generation(https://arxiv.org/abs/2509.18584)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion models are the mainstream approach for time series generation tasks. However, existing diffusion models for time series generation require retraining the entire framework to introduce specific conditional guidance. There also exists a certain degree of distributional bias between the generated data and the real data, which leads to potential model biases in downstream tasks. Additionally, the complexity of diffusion models and the latent spaces leads to an uninterpretable inference process. To address these issues, we propose the data style-guided diffusion model (DS-Diffusion). In the DS-Diffusion, a diffusion framework based on style-guided kernels is developed to avoid retraining for specific conditions. The time-information based hierarchical denoising mechanism (THD) is developed to reduce the distributional bias between the generated data and the real data. Furthermore, the generated samples can clearly indicate the data style from which they originate. We conduct comprehensive evaluations using multiple public datasets to validate our approach. Experimental results show that, compared to the state-of-the-art model such as ImagenTime, the predictive score and the discriminative score decrease by 5.56% and 61.55%, respectively. The distributional bias between the generated data and the real data is further reduced, the inference process is also more interpretable. Moreover, by eliminating the need to retrain the diffusion model, the flexibility and adaptability of the model to specific conditions are also enhanced.</li>
<li><strong>摘要：</strong>扩散模型是时间序列生成任务的主流方法。但是，时间序列生成的现有扩散模型需要重新培训整个框架以引入特定的条件指导。生成的数据与真实数据之间也存在一定程度的分布偏差，这导致下游任务中的潜在模型偏差。另外，扩散模型和潜在空间的复杂性导致了不可解释的推理过程。为了解决这些问题，我们提出了数据样式引导的扩散模型（DS扩散）。在DS扩散中，开发了一个基于样式引导核的扩散框架，以避免在特定条件下进行重新培训。开发了基于时间信息的层次授予机制（THD），以减少生成的数据与真实数据之间的分布偏差。此外，生成的样品可以清楚地指出它们起源的数据样式。我们使用多个公共数据集进行全面的评估来验证我们的方法。实验结果表明，与最新的模型（例如成像时间）相比，预测评分和判别评分分别降低了5.56％和61.55％。生成的数据与实际数据之间的分布偏差进一步降低，推理过程也更容易解释。此外，通过消除重新培训模型的需求，该模型对特定条件的灵活性和适应性也得到了增强。</li>
</ul>

<h3>Title: SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution</h3>
<ul>
<li><strong>Authors: </strong>Xiaoman Wu, Lubin Gan, Siying Wu, Jing Zhang, Yunwei Ou, Xiaoyan Sun</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18593">https://arxiv.org/abs/2509.18593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18593">https://arxiv.org/pdf/2509.18593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18593]] SSCM: A Spatial-Semantic Consistent Model for Multi-Contrast MRI Super-Resolution(https://arxiv.org/abs/2509.18593)</code><input type="text"></li>
<li><strong>Keywords: </strong>restoration, super-resolution</a></li>
<li><strong>Abstract: </strong>Multi-contrast Magnetic Resonance Imaging super-resolution (MC-MRI SR) aims to enhance low-resolution (LR) contrasts leveraging high-resolution (HR) references, shortening acquisition time and improving imaging efficiency while preserving anatomical details. The main challenge lies in maintaining spatial-semantic consistency, ensuring anatomical structures remain well-aligned and coherent despite structural discrepancies and motion between the target and reference images. Conventional methods insufficiently model spatial-semantic consistency and underuse frequency-domain information, which leads to poor fine-grained alignment and inadequate recovery of high-frequency details. In this paper, we propose the Spatial-Semantic Consistent Model (SSCM), which integrates a Dynamic Spatial Warping Module for inter-contrast spatial alignment, a Semantic-Aware Token Aggregation Block for long-range semantic consistency, and a Spatial-Frequency Fusion Block for fine structure restoration. Experiments on public and private datasets show that SSCM achieves state-of-the-art performance with fewer parameters while ensuring spatially and semantically consistent reconstructions.</li>
<li><strong>摘要：</strong>多对比度磁共振成像超分辨率（MC-MRI SR）旨在增强低分辨率（LR）的对比，对比高分辨率（HR）参考，缩短获取时间和提高成像效率，同时保留解剖学细节。主要的挑战在于保持空间语义的一致性，确保尽管目标和参考图像之间存在结构差异和运动，但仍保持解剖结构保持良好和连贯。常规方法不足以模拟空间语义的一致性和不足的频域信息，从而导致细粒度对齐不良和高频细节的恢复不足。在本文中，我们提出了空间语义一致模型（SSCM），该模型集成了一个动态的空间翘曲模块，以进行对比间空间对齐，这是一种语义感知的令牌集合块，以实现长距离语义的一致性，以及用于良好结构恢复的空间频率融合块。公共和私人数据集的实验表明，SSCM以更少的参数实现最先进的性能，同时确保在空间和语义上一致的重建。</li>
</ul>

<h3>Title: OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhuoxiao Chen, Hongyang Yu, Ying Xu, Yadan Luo, Long Duong, Yuan-Fang Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18600">https://arxiv.org/abs/2509.18600</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18600">https://arxiv.org/pdf/2509.18600</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18600]] OraPO: Oracle-educated Reinforcement Learning for Data-efficient and Factual Radiology Report Generation(https://arxiv.org/abs/2509.18600)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Radiology report generation (RRG) aims to automatically produce clinically faithful reports from chest X-ray images. Prevailing work typically follows a scale-driven paradigm, by multi-stage training over large paired corpora and oversized backbones, making pipelines highly data- and compute-intensive. In this paper, we propose Oracle-educated GRPO {OraPO) with a FactScore-based reward (FactS) to tackle the RRG task under constrained budgets. OraPO enables single-stage, RL-only training by converting failed GRPO explorations on rare or difficult studies into direct preference supervision via a lightweight oracle step. FactS grounds learning in diagnostic evidence by extracting atomic clinical facts and checking entailment against ground-truth labels, yielding dense, interpretable sentence-level rewards. Together, OraPO and FactS create a compact and powerful framework that significantly improves learning efficiency on clinically challenging cases, setting the new SOTA performance on the CheXpert Plus dataset (0.341 in F1) with 2--3 orders of magnitude less training data using a small base VLM on modest hardware.</li>
<li><strong>摘要：</strong>放射学报告生成（RRG）旨在自动从胸部X射线图像中生成临床忠实的报告。盛行的工作通常遵循规模驱动的范式，通过对大型配对语料库和超大骨架的多阶段培训，使管道高度数据和计算密集型。在本文中，我们提出了基于FactScore的奖励（事实），建议在有限的预算下解决RRG任务。 Orapo通过将失败的GRPO探索转换为罕见或困难的研究，通过轻量级的Oracle步骤将失败的GRPO探索转换为直接偏好监督，从而实现了单级，仅RL训练。事实通过提取原子临床事实并检查基于地面真相标签的诊断证据中的学习，从而产生致密的，可解释的句子级别的回报。 Orapo和事实共同创建了一个紧凑而有力的框架，可显着提高临床挑战性案例的学习效率，从而在Chexpert Plus Plus数据集（F1中的0.341）上设置新的SOTA性能，并使用小型基础VLM在适度的硬件上使用小的基本VLM，并使用2---3个数量级的培训数据降低了2--3个数量级。</li>
</ul>

<h3>Title: Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation</h3>
<ul>
<li><strong>Authors: </strong>Xu Liu, Yibo Lu, Xinxian Wang, Xinyu Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18602">https://arxiv.org/abs/2509.18602</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18602">https://arxiv.org/pdf/2509.18602</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18602]] Training-Free Multi-Style Fusion Through Reference-Based Adaptive Modulation(https://arxiv.org/abs/2509.18602)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>We propose Adaptive Multi-Style Fusion (AMSF), a reference-based training-free framework that enables controllable fusion of multiple reference styles in diffusion models. Most of the existing reference-based methods are limited by (a) acceptance of only one style image, thus prohibiting hybrid aesthetics and scalability to more styles, and (b) lack of a principled mechanism to balance several stylistic influences. AMSF mitigates these challenges by encoding all style images and textual hints with a semantic token decomposition module that is adaptively injected into every cross-attention layer of an frozen diffusion model. A similarity-aware re-weighting module then recalibrates, at each denoising step, the attention allocated to every style component, yielding balanced and user-controllable blends without any fine-tuning or external adapters. Both qualitative and quantitative evaluations show that AMSF produces multi-style fusion results that consistently outperform the state-of-the-art approaches, while its fusion design scales seamlessly to two or more styles. These capabilities position AMSF as a practical step toward expressive multi-style generation in diffusion models.</li>
<li><strong>摘要：</strong>我们提出了自适应多式融合（AMSF），这是一个基于参考的无培训框架，可在扩散模型中对多种参考样式进行可控的融合。大多数现有的基于参考的方法都受（a）仅接受一个样式图像的限制，从而禁止混合美学和对更多样式的可扩展性，以及（b）缺乏平衡几种风格影响的原则机制。 AMSF通过使用语义令牌分解模块编码所有样式图像和文本提示来缓解这些挑战，该模块可自适应地注入冷冻扩散模型的每个跨注意层。然后，一个相似性的重新加权模块在每个DeNoising步骤中都重新校准，将注意力分配给每个样式组件，产生平衡和用户控制的混合物，而无需任何微调或外部适配器。定性评估和定量评估都表明，AMSF会产生多式融合结果，从而始终优于最先进的方法，而其融合设计则无缝地缩放到两种或更多样式。这些功能将AMSF定位为迈向扩散模型中表达多式生成的实用步骤。</li>
</ul>

<h3>Title: Flow marching for a generative PDE foundation model</h3>
<ul>
<li><strong>Authors: </strong>Zituo Chen, Sili Deng</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18611">https://arxiv.org/abs/2509.18611</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18611">https://arxiv.org/pdf/2509.18611</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18611]] Flow marching for a generative PDE foundation model(https://arxiv.org/abs/2509.18611)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Pretraining on large-scale collections of PDE-governed spatiotemporal trajectories has recently shown promise for building generalizable models of dynamical systems. Yet most existing PDE foundation models rely on deterministic Transformer architectures, which lack generative flexibility for many science and engineering applications. We propose Flow Marching, an algorithm that bridges neural operator learning with flow matching motivated by an analysis of error accumulation in physical dynamical systems, and we build a generative PDE foundation model on top of it. By jointly sampling the noise level and the physical time step between adjacent states, the model learns a unified velocity field that transports a noisy current state toward its clean successor, reducing long-term rollout drift while enabling uncertainty-aware ensemble generations. Alongside this core algorithm, we introduce a Physics-Pretrained Variational Autoencoder (P2VAE) to embed physical states into a compact latent space, and an efficient Flow Marching Transformer (FMT) that combines a diffusion-forcing scheme with latent temporal pyramids, achieving up to 15x greater computational efficiency than full-length video diffusion models and thereby enabling large-scale pretraining at substantially reduced cost. We curate a corpus of ~2.5M trajectories across 12 distinct PDE families and train suites of P2VAEs and FMTs at multiple scales. On downstream evaluation, we benchmark on unseen Kolmogorov turbulence with few-shot adaptation, demonstrate long-term rollout stability over deterministic counterparts, and present uncertainty-stratified ensemble results, highlighting the importance of generative PDE foundation models for real-world applications.</li>
<li><strong>摘要：</strong>在大规模的PDE州时空轨迹上进行了预处理，最近显示出有望构建动态系统的可通用模型。然而，大多数现有的PDE基础模型都依赖于确定性的变压器体系结构，这些结构缺乏许多科学和工程应用程序的生成灵活性。我们提出了流程，这是一种算法，该算法将神经操作员学习与流动匹配，该流程匹配是通过分析物理动力学系统中错误积累的分析，并且我们在其上构建了生成的PDE基础模型。通过共同采样噪声水平和相邻状态之间的物理时间步长，该模型学习了一个统一的速度场，该速度场将嘈杂的当前状态传输到其干净的后继者，从而减少了长期的推出漂移，同时使不确定性吸引了一代。除了该核心算法外，我们还引入了物理学预言的变异自动编码器（P2VAE），将物理状态嵌入到一个紧凑的潜在空间中，并有效的流动变压器（FMT）结合了扩散式方案，该方案将扩散型方案与潜在的较大的较大的范围延伸到更大的范围，从而达到更大的计算范围，从而达到15x的良好范围，以达到15x的范围，以达到15x的范围，以达到15倍的范围。大大降低了成本。我们在12个不同的PDE家族中策划了约250万个轨迹的语料库，并在多个尺度上策划了P2VAES和FMT的套件。在下游评估中，我们基于看不见的kolmogorov湍流，几乎没有射击适应，证明了对确定性对应物的长期推出稳定性，并提出了不确定性分层的集合结果，强调了生成PDE基础模型对现实世界应用的重要性。</li>
</ul>

<h3>Title: Prompt-Guided Dual Latent Steering for Inversion Problems</h3>
<ul>
<li><strong>Authors: </strong>Yichen Wu, Xu Liu, Chenxuan Zhao, Xinyu Wu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18619">https://arxiv.org/abs/2509.18619</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18619">https://arxiv.org/pdf/2509.18619</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18619]] Prompt-Guided Dual Latent Steering for Inversion Problems(https://arxiv.org/abs/2509.18619)</code><input type="text"></li>
<li><strong>Keywords: </strong>super-resolution, generative</a></li>
<li><strong>Abstract: </strong>Inverting corrupted images into the latent space of diffusion models is challenging. Current methods, which encode an image into a single latent vector, struggle to balance structural fidelity with semantic accuracy, leading to reconstructions with semantic drift, such as blurred details or incorrect attributes. To overcome this, we introduce Prompt-Guided Dual Latent Steering (PDLS), a novel, training-free framework built upon Rectified Flow models for their stable inversion paths. PDLS decomposes the inversion process into two complementary streams: a structural path to preserve source integrity and a semantic path guided by a prompt. We formulate this dual guidance as an optimal control problem and derive a closed-form solution via a Linear Quadratic Regulator (LQR). This controller dynamically steers the generative trajectory at each step, preventing semantic drift while ensuring the preservation of fine detail without costly, per-image optimization. Extensive experiments on FFHQ-1K and ImageNet-1K under various inversion tasks, including Gaussian deblurring, motion deblurring, super-resolution and freeform inpainting, demonstrate that PDLS produces reconstructions that are both more faithful to the original image and better aligned with the semantic information than single-latent baselines.</li>
<li><strong>摘要：</strong>将损坏的图像倒入扩散模型的潜在空间很具有挑战性。当前的方法将图像编码为单个潜在向量，难以平衡结构保真度和语义精度，从而导致具有语义漂移的重建，例如模糊的细节或不正确的属性。为了克服这一点，我们介绍了迅速引入的双重潜在转向（PDLS），这是一个新颖的，无训练的框架，建立在其稳定反转路径的整流流模型上。 PDLS将反转过程分解为两个互补流：保留源完整性的结构路径和以提示为指导的语义路径。我们将此双重指导作为最佳控制问题，并通过线性二次调节器（LQR）得出封闭形式的解决方案。该控制器在每个步骤都动态地引导生成轨迹，以防止语义漂移，同时确保细节保存而无需代价高昂的每图像优化。在各种反转任务下进行了有关FFHQ-1K和Imagenet-1K的广泛实验，包括高斯脱毛，运动去除，超级分辨率和自由形式的介绍，这表明PDLS会产生重建，这些重建既忠实于原始图像，又比单层基础更忠于原始图像。</li>
</ul>

<h3>Title: Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation</h3>
<ul>
<li><strong>Authors: </strong>Yuanhuiyi Lyu, Chi Kit Wong, Chenfei Liao, Lutao Jiang, Xu Zheng, Zexin Lu, Linfeng Zhang, Xuming Hu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18639">https://arxiv.org/abs/2509.18639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18639">https://arxiv.org/pdf/2509.18639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18639]] Understanding-in-Generation: Reinforcing Generative Capability of Unified Model via Infusing Understanding into Generation(https://arxiv.org/abs/2509.18639)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Recent works have made notable advancements in enhancing unified models for text-to-image generation through the Chain-of-Thought (CoT). However, these reasoning methods separate the processes of understanding and generation, which limits their ability to guide the reasoning of unified models in addressing the deficiencies of their generative capabilities. To this end, we propose a novel reasoning framework for unified models, Understanding-in-Generation (UiG), which harnesses the robust understanding capabilities of unified models to reinforce their performance in image generation. The core insight of our UiG is to integrate generative guidance by the strong understanding capabilities during the reasoning process, thereby mitigating the limitations of generative abilities. To achieve this, we introduce "Image Editing" as a bridge to infuse understanding into the generation process. Initially, we verify the generated image and incorporate the understanding of unified models into the editing instructions. Subsequently, we enhance the generated image step by step, gradually infusing the understanding into the generation process. Our UiG framework demonstrates a significant performance improvement in text-to-image generation over existing text-to-image reasoning methods, e.g., a 3.92% gain on the long prompt setting of the TIIF benchmark. The project code: this https URL</li>
<li><strong>摘要：</strong>最近的作品在通过思想链（COT）增强统一的文本到图像生成模型方面取得了显着进步。但是，这些推理方法将理解和生成过程分开，这限制了他们指导统一模型推理的能力，以解决其生成能力的缺陷。为此，我们为统一模型，理解生成（UIG）提出了一个新颖的推理框架，该框架利用了统一模型的强大理解能力来增强其在图像生成中的性能。 UIG的核心见解是通过在推理过程中的强大理解能力来整合生成性指导，从而减轻生成能力的局限性。为了实现这一目标，我们将“图像编辑”介绍为注入生成过程的桥梁。最初，我们验证生成的图像，并将对统一模型的理解纳入编辑指令。随后，我们逐步增强生成的图像，逐渐将理解注入生成过程中。我们的UIG框架表明，与现有文本对图像推理方法相比，文本到图像生成的性能有了显着改善，例如，在TIIF基准测试的长时间设置上，增益为3.92％。项目代码：此HTTPS URL</li>
</ul>

<h3>Title: AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping</h3>
<ul>
<li><strong>Authors: </strong>Zedong Zhang, Ying Tai, Jianjun Qian, Jian Yang, Jun Li</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18699">https://arxiv.org/abs/2509.18699</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18699">https://arxiv.org/pdf/2509.18699</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18699]] AGSwap: Overcoming Category Boundaries in Object Fusion via Adaptive Group Swapping(https://arxiv.org/abs/2509.18699)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Fusing cross-category objects to a single coherent object has gained increasing attention in text-to-image (T2I) generation due to its broad applications in virtual reality, digital media, film, and gaming. However, existing methods often produce biased, visually chaotic, or semantically inconsistent results due to overlapping artifacts and poor integration. Moreover, progress in this field has been limited by the absence of a comprehensive benchmark dataset. To address these problems, we propose \textbf{Adaptive Group Swapping (AGSwap)}, a simple yet highly effective approach comprising two key components: (1) Group-wise Embedding Swapping, which fuses semantic attributes from different concepts through feature manipulation, and (2) Adaptive Group Updating, a dynamic optimization mechanism guided by a balance evaluation score to ensure coherent synthesis. Additionally, we introduce \textbf{Cross-category Object Fusion (COF)}, a large-scale, hierarchically structured dataset built upon ImageNet-1K and WordNet. COF includes 95 superclasses, each with 10 subclasses, enabling 451,250 unique fusion pairs. Extensive experiments demonstrate that AGSwap outperforms state-of-the-art compositional T2I methods, including GPT-Image-1 using simple and complex prompts.</li>
<li><strong>摘要：</strong>由于其在虚拟现实，数字媒体，电影和游戏中的广泛应用，将跨类别对象融合到单个连贯的对象上，引起了文本对图像（T2i）生成的关注。但是，由于重叠的伪影和整合不良，现有方法通常会产生偏见，视觉混乱或语义上不一致的结果。此外，由于缺乏全面的基准数据集，该领域的进展受到了限制。为了解决这些问题，我们提出\ textbf {自适应组交换（AGSWAP）}，这是一种简单而有效的方法，构成了两个关键组成部分：（1）群组嵌入交换，它通过特征操纵来融合不同概念的语义属性，以及（2）通过更新的自适应组来确保动态构成的脉冲评估，以确保平衡综合性。此外，我们介绍了\ textbf {cross-catemory对象融合（COF）}，这是一个构建在ImagEnet-1K和WordNet上的大规模，层次结构化的数据集。 COF包括95个超类，每个类别有10个子类，可实现451,250个独特的融合对。广泛的实验表明，AGSWAP的表现优于最先进的组成T2I方法，包括使用简单和复杂的提示，包括GPT-Image-1。</li>
</ul>

<h3>Title: FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation</h3>
<ul>
<li><strong>Authors: </strong>Zhaorui Wang, Yi Gu, Deming Zhou, Renjing Xu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18759">https://arxiv.org/abs/2509.18759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18759">https://arxiv.org/pdf/2509.18759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18759]] FixingGS: Enhancing 3D Gaussian Splatting via Training-Free Score Distillation(https://arxiv.org/abs/2509.18759)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Recently, 3D Gaussian Splatting (3DGS) has demonstrated remarkable success in 3D reconstruction and novel view synthesis. However, reconstructing 3D scenes from sparse viewpoints remains highly challenging due to insufficient visual information, which results in noticeable artifacts persisting across the 3D representation. To address this limitation, recent methods have resorted to generative priors to remove artifacts and complete missing content in under-constrained areas. Despite their effectiveness, these approaches struggle to ensure multi-view consistency, resulting in blurred structures and implausible details. In this work, we propose FixingGS, a training-free method that fully exploits the capabilities of the existing diffusion model for sparse-view 3DGS reconstruction enhancement. At the core of FixingGS is our distillation approach, which delivers more accurate and cross-view coherent diffusion priors, thereby enabling effective artifact removal and inpainting. In addition, we propose an adaptive progressive enhancement scheme that further refines reconstructions in under-constrained regions. Extensive experiments demonstrate that FixingGS surpasses existing state-of-the-art methods with superior visual quality and reconstruction performance. Our code will be released publicly.</li>
<li><strong>摘要：</strong>最近，3D高斯脱落（3DGS）在3D重建和新型视图合成中取得了显着的成功。但是，由于视觉信息不足，从稀疏观点重建3D场景仍然充满挑战，这导致在3D表示中持续存在明显的伪像。为了解决这一局限性，最近的方法已诉诸于生成先验，以消除未约束区域中的伪像和完全缺失的内容。尽管它们有效，但这些方法仍在努力确保多视图的一致性，从而导致结构模糊和令人难以置信的细节。在这项工作中，我们提出了FixingGs，这是一种无训练的方法，可完全利用稀疏视图3DGS重建增强的现有扩散模型的功能。 Fixinggs的核心是我们的蒸馏方法，它提供了更准确和跨视图相干的扩散先验，从而实现了有效的伪像去除和涂料。此外，我们提出了一种自适应渐进式增强方案，该方案进一步完善了不足约束区域的重建。广泛的实验表明，Fixinggs超过了具有出色视觉质量和重建性能的现有最新方法。我们的代码将公开发布。</li>
</ul>

<h3>Title: Towards Application Aligned Synthetic Surgical Image Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Danush Kumar Venkatesh, Stefanie Speidel</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18796">https://arxiv.org/abs/2509.18796</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18796">https://arxiv.org/pdf/2509.18796</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18796]] Towards Application Aligned Synthetic Surgical Image Synthesis(https://arxiv.org/abs/2509.18796)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>The scarcity of annotated surgical data poses a significant challenge for developing deep learning systems in computer-assisted interventions. While diffusion models can synthesize realistic images, they often suffer from data memorization, resulting in inconsistent or non-diverse samples that may fail to improve, or even harm, downstream performance. We introduce \emph{Surgical Application-Aligned Diffusion} (SAADi), a new framework that aligns diffusion models with samples preferred by downstream models. Our method constructs pairs of \emph{preferred} and \emph{non-preferred} synthetic images and employs lightweight fine-tuning of diffusion models to align the image generation process with downstream objectives explicitly. Experiments on three surgical datasets demonstrate consistent gains of $7$--$9\%$ in classification and $2$--$10\%$ in segmentation tasks, with the considerable improvements observed for underrepresented classes. Iterative refinement of synthetic samples further boosts performance by $4$--$10\%$. Unlike baseline approaches, our method overcomes sample degradation and establishes task-aware alignment as a key principle for mitigating data scarcity and advancing surgical vision applications.</li>
<li><strong>摘要：</strong>带注释的手术数据的稀缺性为在计算机辅助干预措施中开发深度学习系统带来了重大挑战。尽管扩散模型可以综合逼真的图像，但它们通常会遭受数据记忆的困扰，从而导致不一致或非多样性样本可能无法改善甚至损害下游性能。我们介绍了\ emph {手术应用一致的扩散}（SAADI），这是一个将扩散模型与下游模型首选的样品对齐的新框架。我们的方法构建了\ emph {preferred}和\ emph {非偏爱}的合成图像对，并采用扩散模型的轻巧微调来明确将图像生成过程与下游目标对齐。三个手术数据集的实验表明，分类的$ 7 $  -  $ 9 \％$  -  $ 2 $  -  $ 10 \％$ $ $ $ $ $ 10 \％$ $ $ $ $ $ 10 \％$ $ $ $ 10 \％$ $ $  -  $ 10 \％$ $ $  -  $ 10 \％$ $ $  -  $ 10 \％$ $。合成样本的迭代精致进一步提高了$ 4 $  -  $ 10 \％$。与基线方法不同，我们的方法克服了样本降级，并确定了任务意识的一致性，作为减轻数据稀缺和推进手术视觉应用的关键原则。</li>
</ul>

<h3>Title: Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Yanzuo Lu, Xin Xia, Manlin Zhang, Huafeng Kuang, Jianbin Zheng, Yuxi Ren, Xuefeng Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18824">https://arxiv.org/abs/2509.18824</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18824">https://arxiv.org/pdf/2509.18824</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18824]] Hyper-Bagel: A Unified Acceleration Framework for Multimodal Understanding and Generation(https://arxiv.org/abs/2509.18824)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Unified multimodal models have recently attracted considerable attention for their remarkable abilities in jointly understanding and generating diverse content. However, as contexts integrate increasingly numerous interleaved multimodal tokens, the iterative processes of diffusion denoising and autoregressive decoding impose significant computational overhead. To address this, we propose Hyper-Bagel, a unified acceleration framework designed to simultaneously speed up both multimodal understanding and generation tasks. Our approach uses a divide-and-conquer strategy, employing speculative decoding for next-token prediction and a multi-stage distillation process for diffusion denoising. The framework delivers substantial performance gains, achieving over a 2x speedup in multimodal understanding. For generative tasks, our resulting lossless 6-NFE model yields a 16.67x speedup in text-to-image generation and a 22x speedup in image editing, all while preserving the high-quality output of the original model. We further develop a highly efficient 1-NFE model that enables near real-time interactive editing and generation. By combining advanced adversarial distillation with human feedback learning, this model achieves ultimate cost-effectiveness and responsiveness, making complex multimodal interactions seamless and instantaneous.</li>
<li><strong>摘要：</strong>统一的多模型模型最近因其在共同理解和产生多种内容方面的非凡能力而引起了极大的关注。但是，随着上下文综合越来越多的交织多模式令牌，扩散降解和自回归解码的迭代过程构成了明显的计算开销。为了解决这个问题，我们提出了Hyper-Bagel，这是一个统一的加速框架，旨在同时加快多模式理解和生成任务。我们的方法采用了分裂和纠纷策略，采用投机性解码来进行下一步预测，以及用于扩散的多阶段蒸馏过程。该框架可实现大量的性能，在多模式理解方面取得了2倍的速度。对于生成任务，我们由此产生的无损6-NFE模型在文本到图像生成中产生16.67倍的加速，图像编辑中的22倍加速，同时保留了原始模型的高质量输出。我们进一步开发了一种高效的1-NFE模型，该模型可以接近实时交互式编辑和生成。通过将先进的对抗蒸馏与人类反馈学习相结合，该模型可以实现最终的成本效益和响应能力，从而使复杂的多模式相互作用无缝且瞬时。</li>
</ul>

<h3>Title: MoiréNet: A Compact Dual-Domain Network for Image Demoiréing</h3>
<ul>
<li><strong>Authors: </strong>Shuwei Guo, Simin Luan, Yan Ke, Zeyd Boukhers, John See, Cong Yang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18910">https://arxiv.org/abs/2509.18910</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18910">https://arxiv.org/pdf/2509.18910</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18910]] MoiréNet: A Compact Dual-Domain Network for Image Demoiréing(https://arxiv.org/abs/2509.18910)</code><input type="text"></li>
<li><strong>Keywords: </strong>restoration</a></li>
<li><strong>Abstract: </strong>Moiré patterns arise from spectral aliasing between display pixel lattices and camera sensor grids, manifesting as anisotropic, multi-scale artifacts that pose significant challenges for digital image demoiréing. We propose MoiréNet, a convolutional neural U-Net-based framework that synergistically integrates frequency and spatial domain features for effective artifact removal. MoiréNet introduces two key components: a Directional Frequency-Spatial Encoder (DFSE) that discerns moiré orientation via directional difference convolution, and a Frequency-Spatial Adaptive Selector (FSAS) that enables precise, feature-adaptive suppression. Extensive experiments demonstrate that MoiréNet achieves state-of-the-art performance on public and actively used datasets while being highly parameter-efficient. With only 5.513M parameters, representing a 48% reduction compared to ESDNet-L, MoiréNet combines superior restoration quality with parameter efficiency, making it well-suited for resource-constrained applications including smartphone photography, industrial imaging, and augmented reality.</li>
<li><strong>摘要：</strong>Moiré图案是由显示像素晶格和相机传感器网格之间的光谱混叠，表现为各向异性，多尺度的文物，对数字图像演示构成了重大挑战。我们提出了Moirénet，这是一种基于卷积的神经U-NET框架，该框架协同整合了频率和空间域特征，以有效地去除伪影。 Moirénet引入了两个关键组件：一个定向频率空间编码器（DFSE），该编码器通过方向差卷积辨别Moiré取向，以及一个频率空间自适应选择器（FSA），可实现精确的特征自适应抑制。广泛的实验表明，Moirénet在公共和积极使用的数据集上实现了最先进的性能，同时高度参数效率。 Moirénet只有5.513亿个参数，与ESDNET-L相比，降低了48％，将出色的恢复质量与参数效率相结合，非常适合用于资源受限的应用程序，包括智能手机摄影，工业成像和增强现实。</li>
</ul>

<h3>Title: LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models</h3>
<ul>
<li><strong>Authors: </strong>Amirhesam Aghanouri, Cristina Olaverri-Monreal</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18917">https://arxiv.org/abs/2509.18917</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18917">https://arxiv.org/pdf/2509.18917</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18917]] LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models(https://arxiv.org/abs/2509.18917)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Autonomous vehicles (AVs) are expected to revolutionize transportation by improving efficiency and safety. Their success relies on 3D vision systems that effectively sense the environment and detect traffic agents. Among sensors AVs use to create a comprehensive view of surroundings, LiDAR provides high-resolution depth data enabling accurate object detection, safe navigation, and collision avoidance. However, collecting real-world LiDAR data is time-consuming and often affected by noise and sparsity due to adverse weather or sensor limitations. This work applies a denoising diffusion probabilistic model (DDPM), enhanced with novel noise scheduling and time-step embedding techniques to generate high-quality synthetic data for augmentation, thereby improving performance across a range of computer vision tasks, particularly in AV perception. These modifications impact the denoising process and the model's temporal awareness, allowing it to produce more realistic point clouds based on the projection. The proposed method was extensively evaluated under various configurations using the IAMCV and KITTI-360 datasets, with four performance metrics compared against state-of-the-art (SOTA) methods. The results demonstrate the model's superior performance over most existing baselines and its effectiveness in mitigating the effects of noisy and sparse LiDAR data, producing diverse point clouds with rich spatial relationships and structural detail.</li>
<li><strong>摘要：</strong>预计自动驾驶汽车（AV）将通过提高效率和安全性彻底改变运输。他们的成功依赖于有效感知环境并检测交通代理的3D视觉系统。在传感器中，AV用于创建周围环境的全面视图，LIDAR提供了高分辨率的深度数据，从而实现了准确的对象检测，安全导航和避免碰撞。但是，收集现实世界中的LIDAR数据是耗时的，并且由于不利的天气或传感器限制而经常受噪声和稀疏性的影响。这项工作采用了deno的扩散概率模型（DDPM），通过新颖的噪声调度和时间步长嵌入技术增强，以生成高质量的合成数据以增强，从而改善了一系列计算机视觉任务的性能，尤其是在AV感知中。这些修改会影响denoising过程和模型的时间意识，从而可以根据投影产生更现实的点云。使用IAMCV和KITTI-360数据集对所提出的方法进行了各种配置的广泛评估，并将四个性能指标与最新的ART（SOTA）方法进行了比较。结果证明了该模型优于大多数现有基线的卓越性能及其在减轻嘈杂和稀疏的LiDAR数据影响方面的有效性，从而产生具有丰富空间关系和结构细节的不同点云。</li>
</ul>

<h3>Title: Generative data augmentation for biliary tract detection on intraoperative images</h3>
<ul>
<li><strong>Authors: </strong>Cristina Iacono, Mariarosaria Meola, Federica Conte, Laura Mecozzi, Umberto Bracale, Pietro Falco, Fanny Ficuciello</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.18958">https://arxiv.org/abs/2509.18958</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.18958">https://arxiv.org/pdf/2509.18958</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.18958]] Generative data augmentation for biliary tract detection on intraoperative images(https://arxiv.org/abs/2509.18958)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Cholecystectomy is one of the most frequently performed procedures in gastrointestinal surgery, and the laparoscopic approach is the gold standard for symptomatic cholecystolithiasis and acute cholecystitis. In addition to the advantages of a significantly faster recovery and better cosmetic results, the laparoscopic approach bears a higher risk of bile duct injury, which has a significant impact on quality of life and survival. To avoid bile duct injury, it is essential to improve the intraoperative visualization of the bile duct. This work aims to address this problem by leveraging a deep-learning approach for the localization of the biliary tract from white-light images acquired during the surgical procedures. To this end, the construction and annotation of an image database to train the Yolo detection algorithm has been employed. Besides classical data augmentation techniques, the paper proposes Generative Adversarial Network (GAN) for the generation of a synthetic portion of the training dataset. Experimental results have been discussed along with ethical considerations.</li>
<li><strong>摘要：</strong>胆囊切除术是胃肠道手术中最常执行的手术之一，腹腔镜方法是有症状性胆囊炎和急性胆囊炎的黄金标准。除了获得更快恢复速度和更好化妆品结果的优势外，腹腔镜方法还具有更高的胆管损伤风险，这对生活质量和生存产生了重大影响。为避免胆管损伤，必须改善胆管的术中可视化。这项工作旨在通过利用一种深入学习方法来解决此问题，以从手术过程中获得的白光图像从白光图像中定位。为此，已经采用了图像数据库的构建和注释来训练YOLO检测算法。除经典数据增强技术外，该论文还提出了生成培训数据集合成部分的生成对抗网络（GAN）。已经讨论了实验结果以及道德考虑。</li>
</ul>

<h3>Title: VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Eiki Murata, Lingfang Zhang, Ayako Sato, So Fukuda, Ziqi Yin, Wentao Hu, Keisuke Nakao, Yusuke Nakamura, Sebastian Zwirner, Yi-Chia Chen, Hiroyuki Otomo, Hiroki Ouchi, Daisuke Kawahara</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19002">https://arxiv.org/abs/2509.19002</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19002">https://arxiv.org/pdf/2509.19002</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19002]] VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction(https://arxiv.org/abs/2509.19002)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications.</li>
<li><strong>摘要：</strong>多模式大语言模型（MLLM）的最新进展具有显着增强的视频理解功能，为实用应用开辟了新的可能性。然而，当前的视频基准主要集中在室内场景或短期室外活动上，留下了与长途旅行相关的挑战。掌握扩展的地理空间轨迹对于下一代MLLM至关重要，这是实现现实世界中的任务（例如体现-AI计划和导航）。为了弥合这一差距，我们提出了Vir Bench，这是一个新颖的基准测试，该基准由200个旅行视频组成，这些视频将行程重建作为一项挑战的任务，旨在评估和推动MLLMS的地理空间 - 暂时性智能。实验结果表明，最新的MLLM，包括专有的MLLM，难以获得高分，强调了处理跨越空间和时间尺度的视频的困难。此外，我们进行了深入的案例研究，在该研究中，我们开发了一种原型旅行计划，该剂利用了Vir Bench获得的见解。代理商明显改进的行程建议验证了我们的评估协议不仅有效地基准模型，还可以转化为面向用户的应用程序中的具体性能提高。</li>
</ul>

<h3>Title: OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment</h3>
<ul>
<li><strong>Authors: </strong>Teng Xiao, Zuchao Li, Lefei Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19018">https://arxiv.org/abs/2509.19018</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19018">https://arxiv.org/pdf/2509.19018</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19018]] OmniBridge: Unified Multimodal Understanding, Generation, and Retrieval via Latent Space Alignment(https://arxiv.org/abs/2509.19018)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Recent advances in multimodal large language models (LLMs) have led to significant progress in understanding, generation, and retrieval tasks. However, current solutions often treat these tasks in isolation or require training LLMs from scratch, resulting in high computational costs and limited generalization across modalities. In this work, we present OmniBridge, a unified and modular multimodal framework that supports vision-language understanding, generation, and retrieval within a unified architecture. OmniBridge adopts a language-centric design that reuses pretrained LLMs and introduces a lightweight bidirectional latent alignment module. To address the challenge of task interference, we propose a two-stage decoupled training strategy: supervised fine-tuning and latent space alignment for aligning LLM behavior with multimodal reasoning, and semantic-guided diffusion training to align cross-modal latent spaces via learnable query embeddings. Extensive experiments across a wide range of benchmarks demonstrate that OmniBridge achieves competitive or state-of-the-art performance in all three tasks. Moreover, our results highlight the effectiveness of latent space alignment for unifying multimodal modeling under a shared representation space. Code and models are released at this https URL.</li>
<li><strong>摘要：</strong>多模式大语言模型（LLM）的最新进展导致了理解，生成和检索任务的重大进展。但是，当前的解决方案通常会孤立地处理这些任务，或者需要从头开始培训LLM，从而导致高度计算成本和跨模式的概括有限。在这项工作中，我们提出了Omnibridge，这是一个统一的模块化多模式框架，该框架支持统一体系结构中的视觉理解，生成和检索。 Omnibridge采用了一种以语言为中心的设计，该设计重新验证了LLMS，并引入了轻巧的双向潜在对齐模块。为了应对任务干扰的挑战，我们提出了一个两阶段的脱钩训练策略：监督的微调和潜在空间对齐，以使LLM行为与多模式推理保持一致，并通过可学习的查询嵌入来使跨模式潜在的潜在潜在空间保持一致。在各种基准测试中进行的广泛实验表明，Omnibridge在所有三个任务中都能在所有三个任务中实现竞争性或最先进的表现。此外，我们的结果突出了潜在空间对齐对于在共享表示空间下统一多模式建模的有效性。代码和模型在此HTTPS URL上发布。</li>
</ul>

<h3>Title: Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model</h3>
<ul>
<li><strong>Authors: </strong>Ioannis Sarafis, Alexandros Papadopoulos, Anastasios Delopoulos</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19028">https://arxiv.org/abs/2509.19028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19028">https://arxiv.org/pdf/2509.19028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19028]] Weakly Supervised Food Image Segmentation using Vision Transformers and Segment Anything Model(https://arxiv.org/abs/2509.19028)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>In this paper, we propose a weakly supervised semantic segmentation approach for food images which takes advantage of the zero-shot capabilities and promptability of the Segment Anything Model (SAM) along with the attention mechanisms of Vision Transformers (ViTs). Specifically, we use class activation maps (CAMs) from ViTs to generate prompts for SAM, resulting in masks suitable for food image segmentation. The ViT model, a Swin Transformer, is trained exclusively using image-level annotations, eliminating the need for pixel-level annotations during training. Additionally, to enhance the quality of the SAM-generated masks, we examine the use of image preprocessing techniques in combination with single-mask and multi-mask SAM generation strategies. The methodology is evaluated on the FoodSeg103 dataset, generating an average of 2.4 masks per image (excluding background), and achieving an mIoU of 0.54 for the multi-mask scenario. We envision the proposed approach as a tool to accelerate food image annotation tasks or as an integrated component in food and nutrition tracking applications.</li>
<li><strong>摘要：</strong>在本文中，我们为食物图像提出了一种弱监督的语义分割方法，该方法利用了零拍的能力和段的任何模型（SAM）以及视觉变压器（VITS）的注意机制。具体而言，我们使用VIT的类激活图（CAM）来生成SAM提示，从而产生适合食物图像分割的掩模。 VIT模型是一种SWIN变压器，仅使用图像级注释进行训练，从而消除了训练过程中对像素级注释的需求。此外，为了提高SAM生成的面具的质量，我们研究了图像预处理技术与单罩和多面罩SAM生成策略的使用。该方法在FoodSeg103数据集上进行评估，每个图像平均产生2.4个掩码（不包括背景），并为多面罩方案实现0.54的MIOU。我们将提出的方法设想为加速食物图像注释任务或食品和营养跟踪应用中的综合组成部分。</li>
</ul>

<h3>Title: Improving Credit Card Fraud Detection through Transformer-Enhanced GAN Oversampling</h3>
<ul>
<li><strong>Authors: </strong>Kashaf Ul Emaan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19032">https://arxiv.org/abs/2509.19032</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19032">https://arxiv.org/pdf/2509.19032</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19032]] Improving Credit Card Fraud Detection through Transformer-Enhanced GAN Oversampling(https://arxiv.org/abs/2509.19032)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Detection of credit card fraud is an acute issue of financial security because transaction datasets are highly lopsided, with fraud cases being only a drop in the ocean. Balancing datasets using the most popular methods of traditional oversampling such as the Synthetic Minority Oversampling Technique (SMOTE) generally create simplistic synthetic samples that are not readily applicable to complex fraud patterns. Recent industry advances that include Conditional Tabular Generative Adversarial Networks (CTGAN) and Tabular Variational Autoencoders (TVAE) have demonstrated increased efficiency in tabular synthesis, yet all these models still exhibit issues with high-dimensional dependence modelling. Now we will present our hybrid approach where we use a Generative Adversarial Network (GAN) with a Transformer encoder block to produce realistic fraudulent transactions samples. The GAN architecture allows training realistic generators adversarial, and the Transformer allows the model to learn rich feature interactions by self-attention. Such a hybrid strategy overcomes the limitations of SMOTE, CTGAN, and TVAE by producing a variety of high-quality synthetic minority classes samples. We test our algorithm on the publicly-available Credit Card Fraud Detection dataset and compare it to conventional and generative resampling strategies with a variety of classifiers, such as Logistic Regression (LR), Random Forest (RF), Extreme Gradient Boosting (XGBoost), and Support Vector Machine (SVM). Findings indicate that our Transformer-based GAN shows substantial gains in Recall, F1-score and Area Under the Receiver Operating Characteristic Curve (AUC), which indicates that it is effective in overcoming the severe class imbalance inherent in the task of fraud detection.</li>
<li><strong>摘要：</strong>信用卡欺诈的检测是财务安全的一个严重问题，因为交易数据集高度偏斜，欺诈案件仅在海洋中有所下降。使用最流行的传统过采样方法（例如综合少数民族过采样技术（SMOTE））平衡数据集通常会创建简单的合成样本，这些样本不容易适用于复杂的欺诈模式。最近的行业进步，包括条件表格生成的对抗网络（CTGAN）和表格变异自动编码器（TVAE）表明在表格合成中的效率提高，但所有这些模型仍然表现出具有高维依赖性建模的问题。现在，我们将介绍混合方法，在其中使用具有变压器编码器块的生成对抗网络（GAN）来生成现实的欺诈交易样本。 GAN体系结构允许训练现实的发电机对抗性，而变压器则可以通过自我注意力来学习丰富的特征相互作用。这种混合策略通过生产各种高质量的合成少数族裔样本来克服SMOTE，CTGAN和TVAE的局限性。我们在公共可用的信用卡欺诈检测数据集上测试了算法，并将其与常规和生成的重新采样策略与各种分类器进行比较，例如Logistic Recression（LR），随机森林（RF），极端梯度增强（XGBOOST）（XGBOOST）以及支持向量机（SVM）。调查结果表明，我们基于变压器的GAN在接收器操作特征曲线（AUC）下的召回，F1得分和面积显示出可观的收益，这表明它有效克服了欺诈检测任务中固有的严重类失衡。</li>
</ul>

<h3>Title: Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks</h3>
<ul>
<li><strong>Authors: </strong>Yang Li, Chenyu Wang, Tingrui Wang, Yongwei Wang, Haonan Li, Zhunga Liu, Quan Pan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19044">https://arxiv.org/abs/2509.19044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19044">https://arxiv.org/pdf/2509.19044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19044]] Latent Danger Zone: Distilling Unified Attention for Cross-Architecture Black-box Attacks(https://arxiv.org/abs/2509.19044)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Black-box adversarial attacks remain challenging due to limited access to model internals. Existing methods often depend on specific network architectures or require numerous queries, resulting in limited cross-architecture transferability and high query costs. To address these limitations, we propose JAD, a latent diffusion model framework for black-box adversarial attacks. JAD generates adversarial examples by leveraging a latent diffusion model guided by attention maps distilled from both a convolutional neural network (CNN) and a Vision Transformer (ViT) models. By focusing on image regions that are commonly sensitive across architectures, this approach crafts adversarial perturbations that transfer effectively between different model types. This joint attention distillation strategy enables JAD to be architecture-agnostic, achieving superior attack generalization across diverse models. Moreover, the generative nature of the diffusion framework yields high adversarial sample generation efficiency by reducing reliance on iterative queries. Experiments demonstrate that JAD offers improved attack generalization, generation efficiency, and cross-architecture transferability compared to existing methods, providing a promising and effective paradigm for black-box adversarial attacks.</li>
<li><strong>摘要：</strong>由于访问模型内​​部设备有限，黑框对抗攻击仍然具有挑战性。现有方法通常取决于特定的网络体系结构或需要大量查询，从而导致跨架结构的可转移性和高查询成本有限。为了解决这些限制，我们提出了JAD，这是黑框对抗攻击的潜在扩散模型框架。 JAD通过利用从卷积神经网络（CNN）和视觉变压器（VIT）模型的注意力图引导的潜在扩散模型来产生对抗示例。通过专注于通常在架构上敏感的图像区域，这种方法可以在不同模型类型之间有效地转移对抗性扰动。这种联合注意力蒸馏策略使JAD能够成为建筑 - 敏锐的剂量，从而实现了各种模型的卓越攻击概括。此外，扩散框架的生成性质通过降低迭代查询的依赖，从而产生高对抗性样品的产生效率。实验表明，与现有方法相比，JAD提供了改进的攻击概括，发电效率和跨架结构的转移性，为黑盒对抗性攻击提供了有希望且有效的范式。</li>
</ul>

<h3>Title: Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Wang, Jun Zhao, Xinyi Liu, Yanbo Liu, Xuyang Cao, Chao Li, Zhuoyun Liu, Qintian Sun, Fangru Zhou, Haoqiang Xing, Zhenhong Yang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19090">https://arxiv.org/abs/2509.19090</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19090">https://arxiv.org/pdf/2509.19090</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19090]] Citrus-V: Advancing Medical Foundation Models with Unified Medical Image Grounding for Clinical Reasoning(https://arxiv.org/abs/2509.19090)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Medical imaging provides critical evidence for clinical diagnosis, treatment planning, and surgical decisions, yet most existing imaging models are narrowly focused and require multiple specialized networks, limiting their generalization. Although large-scale language and multimodal models exhibit strong reasoning and multi-task capabilities, real-world clinical applications demand precise visual grounding, multimodal integration, and chain-of-thought reasoning. We introduce Citrus-V, a multimodal medical foundation model that combines image analysis with textual reasoning. The model integrates detection, segmentation, and multimodal chain-of-thought reasoning, enabling pixel-level lesion localization, structured report generation, and physician-like diagnostic inference in a single framework. We propose a novel multimodal training approach and release a curated open-source data suite covering reasoning, detection, segmentation, and document understanding tasks. Evaluations demonstrate that Citrus-V outperforms existing open-source medical models and expert-level imaging systems across multiple benchmarks, delivering a unified pipeline from visual grounding to clinical reasoning and supporting precise lesion quantification, automated reporting, and reliable second opinions.</li>
<li><strong>摘要：</strong>医学成像为临床诊断，治疗计划和手术决策提供了关键的证据，但是大多数现有的成像模型都狭窄地集中并且需要多个专业网络，从而限制了它们的概括。尽管大规模的语言和多模型模型表现出强大的推理和多任务功能，但现实世界中的临床应用需要精确的视觉接地，多模式整合和经过思考的推理。我们介绍了Citrus-V，这是一种将图像分析与文本推理相结合的多模式医学基础模型。该模型集成了检测，分割和多模式链的推理，从而使像素级病变定位，结构化报告生成以及在单个框架中类似医师的诊断推断。我们提出了一种新型的多模式训练方法，并发布了一个精心策划的开源数据套件，涵盖了推理，检测，细分和文档理解任务。评估表明，柑橘类V的表现优于多个基准的现有开源医学模型和专家级成像系统，从而提供了从视觉接地到临床推理的统一管道，并支持精确的病变量化，自动化报告，自动化报告和可靠的第二意见。</li>
</ul>

<h3>Title: PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Piché, Ehsan Kamaloo, Rafael Pardinas, Dzmitry Bahdanau</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19128">https://arxiv.org/abs/2509.19128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19128">https://arxiv.org/pdf/2509.19128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19128]] PipelineRL: Faster On-policy Reinforcement Learning for Long Sequence Generatio(https://arxiv.org/abs/2509.19128)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning (RL) is increasingly utilized to enhance the reasoning capabilities of Large Language Models (LLMs). However, effectively scaling these RL methods presents significant challenges, primarily due to the difficulty in maintaining high AI accelerator utilization without generating stale, off-policy data that harms common RL algorithms. This paper introduces PipelineRL, an approach designed to achieve a superior trade-off between hardware efficiency and data on-policyness for LLM training. PipelineRL employs concurrent asynchronous data generation and model training, distinguished by the novel in-flight weight updates. This mechanism allows the LLM generation engine to receive updated model weights with minimal interruption during the generation of token sequences, thereby maximizing both the accelerator utilization and the freshness of training data. Experiments conducted on long-form reasoning tasks using 128 H100 GPUs demonstrate that PipelineRL achieves approximately $\sim 2x$ faster learning compared to conventional RL baselines while maintaining highly on-policy training data. A scalable and modular open-source implementation of PipelineRL is also released as a key contribution.</li>
<li><strong>摘要：</strong>加强学习（RL）越来越多地用于增强大语言模型（LLMS）的推理能力。但是，有效地缩放这些RL方法提出了重大挑战，这主要是由于难以维持高AI加速器利用率而不会产生损害常见RL算法的陈旧的，违反政策数据。本文介绍了Pipelinerl，该方法旨在实现硬件效率和LLM培训的数据上的数据之间的较高权衡。 Pipelinerl采用同步的异步数据生成和模型培训，以新颖的飞行中重量更新为特色。该机制使LLM生成引擎可以在代币序列的生成过程中接收最小的中断模型权重，从而最大程度地提高加速器利用率和训练数据的新鲜度。使用128 H100 GPU对长形的推理任务进行的实验表明，与传统的RL基线相比，Pipelinerl在维持高度的policy培训数据的同时，Pipelinerl实现了大约$ \ sim 2x $的学习。 Pipelinerl的可扩展和模块化开源实现也被发布为关键贡献。</li>
</ul>

<h3>Title: GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding</h3>
<ul>
<li><strong>Authors: </strong>Wenying Luo, Zhiyuan Lin, Wenhao Xu, Minghao Liu, Zhi Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19135">https://arxiv.org/abs/2509.19135</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19135">https://arxiv.org/pdf/2509.19135</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19135]] GSTM-HMU: Generative Spatio-Temporal Modeling for Human Mobility Understanding(https://arxiv.org/abs/2509.19135)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Human mobility traces, often recorded as sequences of check-ins, provide a unique window into both short-term visiting patterns and persistent lifestyle regularities. In this work we introduce GSTM-HMU, a generative spatio-temporal framework designed to advance mobility analysis by explicitly modeling the semantic and temporal complexity of human movement. The framework consists of four key innovations. First, a Spatio-Temporal Concept Encoder (STCE) integrates geographic location, POI category semantics, and periodic temporal rhythms into unified vector representations. Second, a Cognitive Trajectory Memory (CTM) adaptively filters historical visits, emphasizing recent and behaviorally salient events in order to capture user intent more effectively. Third, a Lifestyle Concept Bank (LCB) contributes structured human preference cues, such as activity types and lifestyle patterns, to enhance interpretability and personalization. Finally, task-oriented generative heads transform the learned representations into predictions for multiple downstream tasks. We conduct extensive experiments on four widely used real-world datasets, including Gowalla, WeePlace, Brightkite, and FourSquare, and evaluate performance on three benchmark tasks: next-location prediction, trajectory-user identification, and time estimation. The results demonstrate consistent and substantial improvements over strong baselines, confirming the effectiveness of GSTM-HMU in extracting semantic regularities from complex mobility data. Beyond raw performance gains, our findings also suggest that generative modeling provides a promising foundation for building more robust, interpretable, and generalizable systems for human mobility intelligence.</li>
<li><strong>摘要：</strong>人类流动性痕迹通常被记录为校验序列，为短期访问模式和持续的生活方式规律提供了独特的窗口。在这项工作中，我们介绍了GSTM-HMU，这是一种生成时空框架，旨在通过明确建模人类运动的语义和时间复杂性来提高移动性分析。该框架由四个关键创新组成。首先，时空概念编码器（STCE）将地理位置，POI类别语义和定期时间节奏整合到统一的矢量表示中。其次，认知轨迹内存（CTM）适应过滤历史访问，强调最近和行为显着的事件，以便更有效地捕获用户。第三，生活方式概念库（LCB）贡献了结构化的人类偏好线索，例如活动类型和生活方式模式，以增强可解释性和个性化。最后，面向任务的生成头将学习的表示形式转变为多个下游任务的预测。我们对四个广泛使用的现实世界数据集进行了广泛的实验，包括Gowalla，Weeplace，Brightkite和Foursquare，并在三个基准任务上评估了性能：下一个位置预测，轨迹 - 用户识别和时间估计。结果表明，对强基础的一致和实质性改进，证实了GSTM-HMU从复杂的迁移率数据中提取语义规律性的有效性。除了原始的性能增长之外，我们的发现还表明，生成建模为建立更强大，可解释和可推广的人类流动性智能系统提供了有希望的基础。</li>
</ul>

<h3>Title: Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data</h3>
<ul>
<li><strong>Authors: </strong>Earl Ranario, Ismael Mayanja, Heesup Yun, Brian N. Bailey, J. Mason Earles</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19208">https://arxiv.org/abs/2509.19208</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19208">https://arxiv.org/pdf/2509.19208</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19208]] Enabling Plant Phenotyping in Weedy Environments using Multi-Modal Imagery via Synthetic and Generated Training Data(https://arxiv.org/abs/2509.19208)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Accurate plant segmentation in thermal imagery remains a significant challenge for high throughput field phenotyping, particularly in outdoor environments where low contrast between plants and weeds and frequent occlusions hinder performance. To address this, we present a framework that leverages synthetic RGB imagery, a limited set of real annotations, and GAN-based cross-modality alignment to enhance semantic segmentation in thermal images. We trained models on 1,128 synthetic images containing complex mixtures of crop and weed plants in order to generate image segmentation masks for crop and weed plants. We additionally evaluated the benefit of integrating as few as five real, manually segmented field images within the training process using various sampling strategies. When combining all the synthetic images with a few labeled real images, we observed a maximum relative improvement of 22% for the weed class and 17% for the plant class compared to the full real-data baseline. Cross-modal alignment was enabled by translating RGB to thermal using CycleGAN-turbo, allowing robust template matching without calibration. Results demonstrated that combining synthetic data with limited manual annotations and cross-domain translation via generative models can significantly boost segmentation performance in complex field environments for multi-model imagery.</li>
<li><strong>摘要：</strong>热图像中的准确植物分割仍然是高吞吐量表型的重大挑战，尤其是在室外环境中，植物与杂草之间的对比度较低，并且频繁的闭塞阻碍了性能。为了解决这个问题，我们提出了一个框架，该框架利用合成RGB图像，有限的真实注释和基于GAN的跨模式对齐，以增强热图像中的语义分割。我们在1,128张合成图像上训练了模型，其中包含农作物和杂草植物的复杂混合物，以生成用于作物和杂草植物的图像分割面罩。我们还评估了使用各种抽样策略在训练过程中将五个真实的，手动分割的现场图像集成的好处。当将所有合成图像与一些标记的真实图像相结合时，与完整的Real-Data基线相比，我们观察到杂草类别的最大相对改善为22％，而工厂类别的最大相对改善为17％。通过使用Cyclegan-Turbo将RGB转换为热模式，从而允许稳定的模板匹配而无需校准，可以实现跨模式对齐。结果表明，通过生成模型将合成数据与有限的手动注释和跨域翻译相结合可以显着提高多模型图像的复杂场环境中的分割性能。</li>
</ul>

<h3>Title: HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus</h3>
<ul>
<li><strong>Authors: </strong>Yunzhi Xu, Yushuang Ding, Hu Sun, Hongxi Zhang, Li Zhao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19218">https://arxiv.org/abs/2509.19218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19218">https://arxiv.org/pdf/2509.19218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19218]] HyKid: An Open MRI Dataset with Expert-Annotated Multi-Structure and Choroid Plexus in Pediatric Hydrocephalus(https://arxiv.org/abs/2509.19218)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Evaluation of hydrocephalus in children is challenging, and the related research is limited by a lack of publicly available, expert-annotated datasets, particularly those with segmentation of the choroid plexus. To address this, we present HyKid, an open-source dataset from 48 pediatric patients with hydrocephalus. 3D MRIs were provided with 1mm isotropic resolution, which was reconstructed from routine low-resolution images using a slice-to-volume algorithm. Manually corrected segmentations of brain tissues, including white matter, grey matter, lateral ventricle, external CSF, and the choroid plexus, were provided by an experienced neurologist. Additionally, structured data was extracted from clinical radiology reports using a Retrieval-Augmented Generation framework. The strong correlation between choroid plexus volume and total CSF volume provided a potential biomarker for hydrocephalus evaluation, achieving excellent performance in a predictive model (AUC = 0.87). The proposed HyKid dataset provided a high-quality benchmark for neuroimaging algorithms development, and it revealed the choroid plexus-related features in hydrocephalus assessments. Our datasets are publicly available at this https URL.</li>
<li><strong>摘要：</strong>对儿童中脑积水的评估是具有挑战性的，相关研究受到缺乏公开可获得的专家注释的数据集的限制，尤其是那些脉络丛分割的数据集。为了解决这个问题，我们提出了来自48名脑积水患者的开源数据集Hykid。向3D MRI提供了1mm的各向同性分辨率，该分辨率是使用切片到体积算法从常规低分辨率图像中重建的。经验丰富的神经科医生提供了手动校正的脑组织的分割，包括白质，灰质，外侧心室，外部CSF和脉络膜丛。此外，使用检索增强的生成框架从临床放射学报告中提取结构化数据。脉络丛体积与总CSF体积之间的强相关性为脑积水评估提供了潜在的生物标志物，在预测模型中实现了出色的性能（AUC = 0.87）。拟议的HYKID数据集为神经影像学算法开发提供了高质量的基准，并揭示了脑积水评估中与脉络丛相关的特征。我们的数据集可在此HTTPS URL上公开获取。</li>
</ul>

<h3>Title: Video Killed the Energy Budget: Characterizing the Latency and Power Regimes of Open Text-to-Video Models</h3>
<ul>
<li><strong>Authors: </strong>Julien Delavande, Regis Pierrard, Sasha Luccioni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19222">https://arxiv.org/abs/2509.19222</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19222">https://arxiv.org/pdf/2509.19222</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19222]] Video Killed the Energy Budget: Characterizing the Latency and Power Regimes of Open Text-to-Video Models(https://arxiv.org/abs/2509.19222)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Recent advances in text-to-video (T2V) generation have enabled the creation of high-fidelity, temporally coherent clips from natural language prompts. Yet these systems come with significant computational costs, and their energy demands remain poorly understood. In this paper, we present a systematic study of the latency and energy consumption of state-of-the-art open-source T2V models. We first develop a compute-bound analytical model that predicts scaling laws with respect to spatial resolution, temporal length, and denoising steps. We then validate these predictions through fine-grained experiments on WAN2.1-T2V, showing quadratic growth with spatial and temporal dimensions, and linear scaling with the number of denoising steps. Finally, we extend our analysis to six diverse T2V models, comparing their runtime and energy profiles under default settings. Our results provide both a benchmark reference and practical insights for designing and deploying more sustainable generative video systems.</li>
<li><strong>摘要：</strong>文本到视频（T2V）生成的最新进展使得从自然语言提示中创建了高保真，暂时连贯的剪辑。然而，这些系统具有巨大的计算成本，其能源需求仍然很少理解。在本文中，我们介绍了最先进的开源T2V模型的潜伏期和能源消耗的系统研究。我们首先开发了一个计算结合的分析模型，该模型可预测有关空间分辨率，时间长度和降解步骤的规模定律。然后，我们通过对WAN2.1-T2V的细粒实验来验证这些预测，显示二次生长具有空间和时间尺寸，并以剥离步骤的数量进行线性缩放。最后，我们将分析扩展到六种不同的T2V模型，比较了它们在默认设置下的运行时和能量配置文件。我们的结果既提供了设计和部署更可持续的生成视频系统的基准参考和实用见解。</li>
</ul>

<h3>Title: DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces</h3>
<ul>
<li><strong>Authors: </strong>Tianshuo Zhang, Li Gao, Siran Peng, Xiangyu Zhu, Zhen Lei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19230">https://arxiv.org/abs/2509.19230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19230">https://arxiv.org/pdf/2509.19230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19230]] DevFD: Developmental Face Forgery Detection by Learning Shared and Orthogonal LoRA Subspaces(https://arxiv.org/abs/2509.19230)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>The rise of realistic digital face generation and manipulation poses significant social risks. The primary challenge lies in the rapid and diverse evolution of generation techniques, which often outstrip the detection capabilities of existing models. To defend against the ever-evolving new types of forgery, we need to enable our model to quickly adapt to new domains with limited computation and data while avoiding forgetting previously learned forgery types. In this work, we posit that genuine facial samples are abundant and relatively stable in acquisition methods, while forgery faces continuously evolve with the iteration of manipulation techniques. Given the practical infeasibility of exhaustively collecting all forgery variants, we frame face forgery detection as a continual learning problem and allow the model to develop as new forgery types emerge. Specifically, we employ a Developmental Mixture of Experts (MoE) architecture that uses LoRA models as its individual experts. These experts are organized into two groups: a Real-LoRA to learn and refine knowledge of real faces, and multiple Fake-LoRAs to capture incremental information from different forgery types. To prevent catastrophic forgetting, we ensure that the learning direction of Fake-LoRAs is orthogonal to the established subspace. Moreover, we integrate orthogonal gradients into the orthogonal loss of Fake-LoRAs, preventing gradient interference throughout the training process of each task. Experimental results under both the datasets and manipulation types incremental protocols demonstrate the effectiveness of our method.</li>
<li><strong>摘要：</strong>现实的数字面部产生和操纵的兴起带来了重大的社会风险。主要挑战在于发电技术的快速发展，这通常超过了现有模型的检测能力。为了防止不断发展的新型伪造类型，我们需要使我们的模型能够快速适应有限的计算和数据，同时避免忘记先前学习的伪造类型。在这项工作中，我们认为，真正的面部样品在采集方法中具有丰富的且相对稳定，而伪造的面部则随着操纵技术的迭代而不断发展。鉴于详尽收集所有伪造变体的实际不可行，我们将伪造的检测构架为持续学习问题，并允许该模型随着新的伪造类型的出现而发展。具体来说，我们采用了使用Lora模型作为个人专家的专家（MOE）体系结构的发展混合物。这些专家分为两组：一个真实的洛拉，以学习和完善对真实面孔的知识，以及多个假 - 洛拉斯，以捕获不同伪造类型的增量信息。为了防止灾难性的遗忘，我们确保假路线的学习方向与已建立的子空间正交。此外，我们将正交梯度集成到假路线的正交损失中，以防止在每个任务的整个训练过程中梯度干扰。数据集和操纵类型的实验结果增量协议证明了我们方法的有效性。</li>
</ul>

<h3>Title: Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation</h3>
<ul>
<li><strong>Authors: </strong>Shufan Li, Jiuxiang Gu, Kangning Liu, Zhe Lin, Zijun Wei, Aditya Grover, Jason Kuen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19244">https://arxiv.org/abs/2509.19244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19244">https://arxiv.org/pdf/2509.19244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19244]] Lavida-O: Elastic Masked Diffusion Models for Unified Multimodal Understanding and Generation(https://arxiv.org/abs/2509.19244)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>We proposed Lavida-O, a unified multi-modal Masked Diffusion Model (MDM) capable of image understanding and generation tasks. Unlike existing multimodal diffsion language models such as MMaDa and Muddit which only support simple image-level understanding tasks and low-resolution image generation, Lavida-O exhibits many new capabilities such as object grounding, image-editing, and high-resolution (1024px) image synthesis. It is also the first unified MDM that uses its understanding capabilities to improve image generation and editing results through planning and iterative self-reflection. To allow effective and efficient training and sampling, Lavida-O ntroduces many novel techniques such as Elastic Mixture-of-Transformer architecture, universal text conditioning, and stratified sampling. \ours~achieves state-of-the-art performance on a wide range of benchmarks such as RefCOCO object grounding, GenEval text-to-image generation, and ImgEdit image editing, outperforming existing autoregressive and continuous diffusion models such as Qwen2.5-VL and FluxKontext-dev, while offering considerable speedup at inference.</li>
<li><strong>摘要：</strong>我们提出了Lavida-O，这是一种能够理解和生成任务的统一的多模式掩盖扩散模型（MDM）。与现有的多模式差异语言模型（例如MMADA和MUDDIT）不同，仅支持简单的图像级理解任务和低分辨率图像生成，Lavida-O展示了许多新功能，例如对象接地，图像编辑和高分辨率（1024px）图像合成。这也是第一个利用其理解能力来通过计划和迭代自我反射来改善图像产生和编辑结果的统一MDM。为了允许有效，有效的训练和抽样，Lavida-O Nrowdroductoductiques-o nrowdroductuctucter-nrowdodroductuctuctiques-o nrowsovering of-troce-trowsiquant和分层的采样，例如弹性混合物结构，通用文本调节和分层采样。 \我们的〜在诸如reccoco对象接地，文本到图像生成以及Imgedit图像编辑之类的广泛基准上实现了最先进的性能，超过了现有的自动化且连续的扩散模型，例如qwen2.5-vl和Fluxkontext-dev，同时提供相当大的加速。</li>
</ul>

<h3>Title: Moving by Looking: Towards Vision-Driven Avatar Motion Generation</h3>
<ul>
<li><strong>Authors: </strong>Markos Diomataris, Berat Mert Albaba, Giorgio Becherini, Partha Ghosh, Omid Taheri, Michael J. Black</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19259">https://arxiv.org/abs/2509.19259</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19259">https://arxiv.org/pdf/2509.19259</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19259]] Moving by Looking: Towards Vision-Driven Avatar Motion Generation(https://arxiv.org/abs/2509.19259)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>The way we perceive the world fundamentally shapes how we move, whether it is how we navigate in a room or how we interact with other humans. Current human motion generation methods, neglect this interdependency and use task-specific ``perception'' that differs radically from that of humans. We argue that the generation of human-like avatar behavior requires human-like perception. Consequently, in this work we present CLOPS, the first human avatar that solely uses egocentric vision to perceive its surroundings and navigate. Using vision as the primary driver of motion however, gives rise to a significant challenge for training avatars: existing datasets have either isolated human motion, without the context of a scene, or lack scale. We overcome this challenge by decoupling the learning of low-level motion skills from learning of high-level control that maps visual input to motion. First, we train a motion prior model on a large motion capture dataset. Then, a policy is trained using Q-learning to map egocentric visual inputs to high-level control commands for the motion prior. Our experiments empirically demonstrate that egocentric vision can give rise to human-like motion characteristics in our avatars. For example, the avatars walk such that they avoid obstacles present in their visual field. These findings suggest that equipping avatars with human-like sensors, particularly egocentric vision, holds promise for training avatars that behave like humans.</li>
<li><strong>摘要：</strong>我们对世界的看法从根本上塑造了我们的移动方式，无论是我们在房间中导航还是与其他人类互动的方式。当前的人类运动产生方法，忽略了这种相互依存关系，并使用特定于任务的``感知''与人类的不同。我们认为，类似人类的化身行为的产生需要类似人类的感知。因此，在这项工作中，我们提出了Clops，这是第一个仅利用以自我为中心的视野来感知周围环境和导航的人类化身。然而，将视觉作为运动的主要驱动力，对训练头像带来了重大挑战：现有的数据集要么具有隔离的人类运动，而没有场景的背景，要么缺乏规模。我们通过学习将视觉输入映射到运动的高级控制的学习来克服这一挑战。首先，我们在大型运动捕获数据集上训练运动模型。然后，使用Q-学习训练策略，以将自我中心的视觉输入映射到高级控制命令中的高级控制命令。我们的实验从经验上表明，以自我为中心的视力会导致我们的化身中类似人类的运动特征。例如，头像行走以避免视野中存在障碍。这些发现表明，为化身为人类般的传感器（尤其是以自负的视野）提供了对训练像人类一样行为的化身的希望。</li>
</ul>

<h3>Title: OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps</h3>
<ul>
<li><strong>Authors: </strong>Bingnan Li, Chen-Yu Wang, Haiyang Xu, Xiang Zhang, Ethan Armand, Divyansh Srivastava, Xiaojun Shan, Zeyuan Chen, Jianwen Xie, Zhuowen Tu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19282">https://arxiv.org/abs/2509.19282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19282">https://arxiv.org/pdf/2509.19282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19282]] OverLayBench: A Benchmark for Layout-to-Image Generation with Dense Overlaps(https://arxiv.org/abs/2509.19282)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Despite steady progress in layout-to-image generation, current methods still struggle with layouts containing significant overlap between bounding boxes. We identify two primary challenges: (1) large overlapping regions and (2) overlapping instances with minimal semantic distinction. Through both qualitative examples and quantitative analysis, we demonstrate how these factors degrade generation quality. To systematically assess this issue, we introduce OverLayScore, a novel metric that quantifies the complexity of overlapping bounding boxes. Our analysis reveals that existing benchmarks are biased toward simpler cases with low OverLayScore values, limiting their effectiveness in evaluating model performance under more challenging conditions. To bridge this gap, we present OverLayBench, a new benchmark featuring high-quality annotations and a balanced distribution across different levels of OverLayScore. As an initial step toward improving performance on complex overlaps, we also propose CreatiLayout-AM, a model fine-tuned on a curated amodal mask dataset. Together, our contributions lay the groundwork for more robust layout-to-image generation under realistic and challenging scenarios. Project link: this https URL.</li>
<li><strong>摘要：</strong>尽管在布局到图像生成方面稳定进展，但当前的方法仍在与包含边界框之间有显着重叠的布局困难。我们确定了两个主要挑战：（1）大型重叠区域和（2）以最小的语义区别重叠实例。通过定性示例和定量分析，我们证明了这些因素如何降低产生质量。为了系统地评估此问题，我们引入了RylayCore，这是一个新颖的指标，可以量化重叠边界框的复杂性。我们的分析表明，现有的基准有偏向于更简单的覆盖层值的案例，从而限制了它们在更具挑战性条件下评估模型性能的有效性。为了弥合这一差距，我们介绍了OverlayBench，这是一种新的基准测试，具有高质量的注释和在不同级别的覆盖层上的平衡分布。为了提高复杂重叠的性能的第一步，我们还提出了creatilayout-am，这是一个在策划的Amodal蒙版数据集中进行微调的模型。共同，我们的贡献为在现实且具有挑战性的情况下为更强大的布局到图像的生成奠定了基础。项目链接：此HTTPS URL。</li>
</ul>

<h3>Title: Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation</h3>
<ul>
<li><strong>Authors: </strong>Sherwin Bahmani, Tianchang Shen, Jiawei Ren, Jiahui Huang, Yifeng Jiang, Haithem Turki, Andrea Tagliasacchi, David B. Lindell, Zan Gojcic, Sanja Fidler, Huan Ling, Jun Gao, Xuanchi Ren</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.GR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19296">https://arxiv.org/abs/2509.19296</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19296">https://arxiv.org/pdf/2509.19296</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19296]] Lyra: Generative 3D Scene Reconstruction via Video Diffusion Model Self-Distillation(https://arxiv.org/abs/2509.19296)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>The ability to generate virtual environments is crucial for applications ranging from gaming to physical AI domains such as robotics, autonomous driving, and industrial AI. Current learning-based 3D reconstruction methods rely on the availability of captured real-world multi-view data, which is not always readily available. Recent advancements in video diffusion models have shown remarkable imagination capabilities, yet their 2D nature limits the applications to simulation where a robot needs to navigate and interact with the environment. In this paper, we propose a self-distillation framework that aims to distill the implicit 3D knowledge in the video diffusion models into an explicit 3D Gaussian Splatting (3DGS) representation, eliminating the need for multi-view training data. Specifically, we augment the typical RGB decoder with a 3DGS decoder, which is supervised by the output of the RGB decoder. In this approach, the 3DGS decoder can be purely trained with synthetic data generated by video diffusion models. At inference time, our model can synthesize 3D scenes from either a text prompt or a single image for real-time rendering. Our framework further extends to dynamic 3D scene generation from a monocular input video. Experimental results show that our framework achieves state-of-the-art performance in static and dynamic 3D scene generation.</li>
<li><strong>摘要：</strong>生成虚拟环境的能力对于从游戏到物理AI领域（例如机器人技术，自动驾驶和工业AI）等应用至关重要。当前基于学习的3D重建方法取决于捕获的现实世界多视图数据的可用性，这并不总是很容易获得。视频扩散模型的最新进展显示出了显着的想象力，但是它们的2D性质将应用程序限制为模拟机器人需要导航和与环境交互的模拟。在本文中，我们提出了一个自distillation框架，旨在将视频扩散模型中的隐式3D知识提炼成明显的3D高斯分裂（3DGS）表示，从而消除了对多视图训练数据的需求。具体来说，我们使用3DGS解码器增强了典型的RGB解码器，该解码器由RGB解码器的输出进行监督。在这种方法中，3DGS解码器可以通过视频扩散模型生成的合成数据纯粹训练。在推理时，我们的模型可以从文本提示或单个图像中合成3D场景以进行实时渲染。我们的框架进一步扩展到单眼输入视频的动态3D场景生成。实验结果表明，我们的框架在静态和动态的3D场景生成中实现了最先进的性能。</li>
</ul>

<h3>Title: CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching</h3>
<ul>
<li><strong>Authors: </strong>Chen Chen, Pengsheng Guo, Liangchen Song, Jiasen Lu, Rui Qian, Xinze Wang, Tsu-Jui Fu, Wei Liu, Yinfei Yang, Alex Schwing</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2509.19300">https://arxiv.org/abs/2509.19300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2509.19300">https://arxiv.org/pdf/2509.19300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2509.19300]] CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching(https://arxiv.org/abs/2509.19300)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Conditional generative modeling aims to learn a conditional data distribution from samples containing data-condition pairs. For this, diffusion and flow-based methods have attained compelling results. These methods use a learned (flow) model to transport an initial standard Gaussian noise that ignores the condition to the conditional data distribution. The model is hence required to learn both mass transport and conditional injection. To ease the demand on the model, we propose Condition-Aware Reparameterization for Flow Matching (CAR-Flow) -- a lightweight, learned shift that conditions the source, the target, or both distributions. By relocating these distributions, CAR-Flow shortens the probability path the model must learn, leading to faster training in practice. On low-dimensional synthetic data, we visualize and quantify the effects of CAR. On higher-dimensional natural image data (ImageNet-256), equipping SiT-XL/2 with CAR-Flow reduces FID from 2.07 to 1.68, while introducing less than 0.6% additional parameters.</li>
<li><strong>摘要：</strong>有条件的生成建模旨在从包含数据条件对的样本中学习条件数据分布。为此，扩散和基于流动的方法已取得了令人信服的结果。这些方法使用学习的（流）模型运输初始标准高斯噪声，该噪声忽略了条件数据分布的条件。因此，该模型是学习大规模运输和有条件注入所需的。为了减轻模型的需求，我们提出了流动匹配（CAR-FLOW）的条件感知的重新聚集化 - 轻巧，学习的转移，以验证源，目标或两个分布的条件。通过搬迁这些分布，汽车流缩短了模型必须学习的概率路径，从而在实践中更快地训练。在低维合成数据上，我们可视化和量化了汽车的影响。在较高维的自然图像数据（Imagenet-256）上，将SIT-XL/2配备CAR-FLOW将FID从2.07降低到1.68，同时引入了少于0.6％的其他参数。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
